{"text": " Welcome to lesson 7, the last lesson of part 1. This will be a pretty intense lesson. And so don't let that bother you because partly what I want to do is to kind of give you enough things to think about to keep you busy until part 2. And so in fact some of the things we covered today I'm not going to tell you about some of the details, I'll just point out a few things where I'll say like okay that we're not talking about yet, that we're not talking about yet. And so then come back in part 2 to get the details on some of these extra pieces. So today will be a lot of material, pretty quickly, might require a few viewings to fully understand it all, a few experiments and so forth. And that's kind of intentional, I'm trying to give you stuff to keep you amused for a couple of months. Wanted to start by showing some cool work done by a couple of students, Reshma and Npatta01, who have developed an Android and an iOS app. And so check out Reshma's post on the forum about that because they have a demonstration of how to create both Android and iOS apps that are actually on the Play Store and on the Apple App Store. So that's pretty cool. First ones I know of that are on the App Store that are using Fast AI. Let me also say a huge thank you to Reshma for all of the work she does both for the Fast AI community and the machine learning community more generally and also the women in the machine learning community in particular. She does a lot of fantastic work including providing lots of fantastic documentation and tutorials and community organising and so many other things. So thank you Reshma and congrats on getting this app out there. We have lots of Lesson 7 notebooks today as you see. We're going to start with the one... So the first notebook we're going to look at is Lesson 7 ResNet MNIST. And what I want to do is look at some of the stuff we started talking about last week around convolutions and convolutional neural networks and start building on top of them to create a fairly modern deep learning architecture largely from scratch. When I say from scratch I'm not going to re-implement things we already know how to implement but kind of use the pre-existing PyTorch bits of those. So we're going to use the MNIST dataset which... so urls.mnist has the whole MNIST dataset. Often we've done stuff with a subset of it. So in there there's a training folder and a testing folder. And as I read this in I'm going to show some more details about pieces of the data blocks API so that you see how to kind of see what's going on. Normally with the data blocks API we've kind of said blah dot blah dot blah dot blah and done it all in one cell but let's do them one cell at a time. So first thing you say is what kind of item list do you have? So in this case it's an item list of images. And then where are you getting the list of file names from? In this case by looking in a folder recursively and that's where it's coming from. You can pass in arguments that end up going to PILO because PILO or P-I-L is the thing that actually opens that for us and in this case these are black and white rather than RGB. So you have to use PILO's convert mode equals L for more details refer to the Python imaging library documentation to see what their convert modes are. But this one is going to be grayscale which is what MNIST is. So inside an item list is an items attribute and the items attribute is kind of the thing that you gave it. It's the thing that it's going to use to create your item. So in this case the thing you gave it really is a list of file names. That's what it got from the folder. When you show images normally it shows them in RGB and so in this case we want to use a binary color map. So in Fast.ai you can set a default color map. For more information about CMAP and color maps refer to the map plot lib documentation and so this will set the default color map for Fast.ai. So our image item list contains 70,000 items and it's a bunch of images that are 1 by 28 by 28. Remember that PyTorch puts channel first so they're one channel 28 by 28. You might think why aren't they just 28 by 28 matrices rather than a 1 by 28 by 28 rank 3 tensor. It's just easier that way. All the conv2d stuff and so forth works on rank 3 tensors so you want to include that unit axis at the start and so Fast.ai will do that for you even when it's reading one channel images. So the.items attribute contains the thing that's kind of read to build the image which in this case is the file name but if you just index into an item list directly you'll get the actual image object. So the actual image object has a show method and so there's the image. So once you've got an image item list you then split it into training versus validation. You nearly always want validation. If you don't you can actually use the.no split method to create a kind of empty validation set. You can't skip it entirely. You have to say how to split and one of the options is no split. And so remember that's always the order. First create your item list then decide how to split. In this case we're going to do it based on folders. In this case the validation folder for MNIST is called testing. So in kind of Fast.ai parlance we use the same kind of parlance that Kaggle does which is the training set is what you train on. The validation set has labels and you do it for testing that your model's working. The test set doesn't have labels and you use it for doing inference or submitting to a competition or sending it off to somebody who's held out those labels for vendor testing or whatever. So just because a folder in your data set is called testing doesn't mean it's a test set. This one has labels so it's a validation set. So if you want to do inference on lots of things at a time rather than one thing at a time you want to use the test equals in Fast.ai to say this is stuff which has no labels and I'm just using for inference. So my split data is a training set and a validation set as you can see. So inside the training set there's a folder for each class. So now we can take that split data and say label from folder. So first you create the item list then you split it then you label it. And so you can see now we have an X and a Y and the Y are category objects. Category object is just a class basically. So if you index into a label list such as ll.train as a label list you will get back an independent variable, independent variable, X and Y. So in this case the X will be an image object which I can show and the Y will be a category object which I can print. That's the number 8 category and there's the 8. Next thing we can do is to add transforms. In this case we're not going to use the normal getTransforms function because we're doing digit recognition and digit recognition like you wouldn't want to flip it left right that would change the meaning of it. You wouldn't want to rotate it too much that would change the meaning of it. Also because these images are so small, kind of doing zooms and stuff is going to make them so fuzzy as to be unreadable. So normally for small images of digits like this you just add a bit of random padding. So I'll use the random padding function which actually returns two transforms, the bit that does the padding and the bit that does the random crop. So you have to use star to say put both these transforms in this list. So now we can call transform. This empty array here is referring to the validation set transforms. So no transforms with the validation set. Now we've got a transformed labelled list. We can pick a batch size and choose data bunch. We can choose normalise. In this case we're not using a pre-trained model so there's no reason to use ImageNet stats here. And so if you call normalise like this without passing in stats it will grab a batch of data at random and use that to decide what normalisation stats to use. That's a good idea if you're not using a pre-trained model. Okay so we've got a data bunch and so in that data bunch is a data set which we've seen already. What is interesting is that the training data set now has data augmentation because we've got transforms. So plotMulti is a fast AI function that will plot the result of calling some function for each of this row by column grid. So in this case my function is just grab the first image from the training set and because each time you grab something from the training set it's going to load it from disk and it's going to transform it on the fly. So people sometimes ask like how many transformed versions of the image do you create and the answer is kind of infinite. Each time we grab one thing from the data set we do a random transform on the fly. So potentially everyone will look a little bit different. So you can see here if we plot the result of that lots of times we get eights in slightly different positions because we did random padding. You can always grab a batch of data then from the data bunch because remember a data bunch has data loaders and data loaders are things that you grab a batch at a time and so you can then grab an X batch and a Y batch, look at their shape, batch size by channel by row by column. All fast AI data bunches have a show batch which will show you what's in it in some sensible way. So that's a quick walk through of the data block API stuff to grab our data. So let's start out creating a simple CNN, simple confnet. So the input is 28 by 28. So let's define, I like to define when I'm creating architectures a function which kind of does the things that I do again and again and again. I don't want to call it with the same arguments because I'll forget, I'll make a mistake. So in this case all of my convolutions are going to be kernel size 3, stride 2, padding 1. So let's just create a simple function to do a conv with those parameters. So each time I have a convolution it's skipping over one pixel so it's jumping two steps each time. So that means that each time we have a convolution it's going to halve the grid size. So I've put a comment here showing what the new grid size is after each one. So after the first convolution we have one channel coming in because it's, remember it's a grayscale image with one channel. And then how many channels coming out, whatever you like. So remember you always get to pick how many filters you create regardless of whether it's a fully connected layer, in which case it's just the width of the matrix you're multiplying by or in this case with a 2D conv it's just how many filters do you want. So I picked 8 and so after this it's stride 2. So the 28 by 28 image is now a 14 by 14 feature map with 8 channels. So specifically therefore it's an 8 by 14 by 14 tensor of activations. Then we'll do batch norm, then we'll do relu. So the number of input filters to the next conv has to equal the number of output filters from the previous conv and we can just keep increasing the number of channels. Because we're doing stride 2 it's going to keep decreasing the grid size. Notice here it goes from 7 to 4 because if you're doing a stride 2 conv over 7 it's going to be kind of math dot ceiling of 7 divided by 2. Batch norm relu conv we're now down to 2 by 2, batch norm relu conv we're now down to 1 by 1. So after this we have a picture map of let's see 10 by 1 by 1. Does that make sense? We've got a grid size of 1 now. So it's not a vector of length 10, it's a rank 3 tensor of 10 by 1 by 1. So our loss functions expect generally a vector, not a rank 3 tensor. So you can chuck flatten at the end and flatten just means remove any unit axes. So that will make it now just a vector of length 10 which is what we always expect. So that's how we can create a CNN. So then we can return that into a learner by passing in the data and the model and the loss function and if optionally some metrics. So we're going to use cross entropy as usual. So we can then call learn.summary and confirm. After that first conv we're down to 14 by 14 and after the second conv 7 by 7 and 4 by 4, 2 by 2, 1 by 1. The flatten comes out calling it a lambda but that as you can see it gets rid of the 1 by 1 and it's now just a length 10 vector for each item in the batch. So 128 by 10 matrix in the whole mini-batch. So just to confirm that this is working okay we can grab that mini-batch of x that we created earlier. There's our mini-batch of x. Pop it onto the GPU and call the model directly. Remember any PyTorch module we can pretend it's a function and that gives us back as we hoped a 128 by 10 result. So that's how you can directly get some predictions out. LR find, fit one cycle and bang we already have a 98.6% accurate conv net and this is trained from scratch of course it's not pre-trained. We literally created our own architecture. It's about the simplest possible architecture you can imagine. 18 seconds to train. So that's how easy it is to create a pretty accurate digit detector. So let's refactor that a little rather than saying conv batch norm relu all the time. Fast.ai already has something called conv underscore layer which lets you create conv batch norm relu combinations and it has various other options to do other tweaks to it but the basic version is just exactly what I just showed you. So we can refactor that like so, that's exactly the same neural net. And so let's just train it a little bit longer and it's actually 99.1% accurate if we train it for all of a minute. So that's cool. So how can we improve this? Well what we really want to do is create a deeper network. And so a very easy way to create a deeper network would be after every stride 2 conv add a stride 1 conv because the stride 1 conv doesn't change the feature map size at all so you can add as many as you like. But there's a problem. And the problem was pointed out in this paper, very very very influential paper called Deep Residual Learning for Image Recognition by Kai Ming He and colleagues then at Microsoft Research. And they did something interesting. They said let's look at the training error. So forget generalisation even. Let's just look at the training error of a network trained on Cypher 10 and let's try one network of 20 layers, just basic 3x3 convs, just basically the same network I just showed you but without batch norm. Let's try a 20 layer one and a 56 layer one on the training set. So the 56 layer one has a lot more parameters. It's got a lot more of these stride 1 convs in the middle. So the one with more parameters should seriously overfit. So you would expect the 56 layer one to zip down to zero-ish training error pretty quickly and that is not what happens. It is worse than the shallower network. So when you see something weird happen, really good researchers don't go oh no, it's not working. They go that's interesting. So Kai Ming He said that's interesting. What's going on? And he said I don't know but what I do know is this. I could take this 56 layer network and make a new version of it which is identical but has to be at least as good as the 20 layer network and here's how. Every two convolutions I'm going to add together the input to those two convolutions, add it together with the result of those two convolutions. So in other words he's saying instead of saying output equals conv2 of conv1 of x, instead he's saying output equals x plus conv2 of conv1 of x. So that 56 layers worth of convolutions in that, his theory was has to be at least as good as the 20 layer version because it could always just set conv2 and conv1 to a bunch of zero weights for everything except for the first 20 layers because the x, the input could just go straight through. So this thing here is, as you see, called an identity connection. It's the identity function. Nothing happens at all. It's also known as a skip connection. So that was a theory. That's what the paper describes as the intuition behind this is what would happen if we created something which has to train at least as well as a 20 layer neural network because it kind of contains that 20 layer neural network. There's literally a path you can just skip over all the convolutions. And so what happens? And what happened was he won ImageNet that year. He easily won ImageNet that year. And in fact, even today, we had that record breaking result on ImageNet speed training ourselves. In the last year we used this too. ResNet has been revolutionary. And here's a trick. If you're interested in doing some research, some novel research, any time you find some model for anything, whether it's like medical image segmentation or some kind of GAN or whatever, and it was written a couple of years ago, they might have forgotten to put ResNets in, ResBlocks. This is what we normally call a ResBlock. They might have forgotten to put ResBlocks in. So replace their convolutional path with a bunch of ResBlocks and you'll almost always get better results faster. It's a good trick. So at NeurIPS, which Rachel and I and David all just came back from, and Sylvain, we saw a new presentation where they actually figured out how to visualize the loss surface of a neural net, which is really cool. This is a fantastic paper. And anybody who's watching this, lesson seven, is at a point where they will understand most of the most important concepts in this paper. You can read this now. You won't necessarily get all of it, but I'm sure you'll find it good enough to find it interesting. And so the big picture was this one. Here's what happens if you draw a picture where kind of X and Y here are two projections of the weight space and Z is the loss. And so as you move through the weight space, a 56-layer neural network without skip connections is very, very bumpy. And that's why this got nowhere because it just got stuck in all these hills and valleys. The exact same network with identity connections, with skip connections, has this lost landscape. So it's kind of interesting how Hurt recognized back in 2015, this shouldn't happen. Here's a way that must fix it. And it took three years before people were able to say, oh, this is kind of why it fixed it. And then with the batch norm discussion we had a couple of weeks ago, people realizing a little bit after the fact sometimes what's going on and why it helps. So in our code, we can create a res block in just the way I described. We create an nn.module. We create two conv layers. Remember, a conv layer is conv2d batch norm relu. Sorry, conv2d relu batch norm. So create two of those. And then in forward, we go conv1 of x, conv2 of that, and then add x. There's a res block function already in fast AI. So you can just call res block instead. And you just pass in something saying how many filters do you want? So yeah, so there's the res block that I defined in our notebook. And so with that res block, we can now take every one of those, just copy the previous cnn, and after every conv2, except the last one, I added a res block. So this has now got three times as many layers. So it should be able to do more compute. But it shouldn't be any harder to optimize. So what happens? Well, let's just refactor it one more time. Since I go conv2 res block so many times, let's just pop that into a little mini sequential model here. And so I can refactor that like so. Keep refactoring your architectures if you're trying novel architectures, because you'll make less mistakes. Very few people do this. Most research code you look at is clunky as all hell. And people often make mistakes in that way, so don't do that. You know, you're all coders, so use your coding skills to make life easier. OK, so there's my resnet-ish architecture. And lr find as usual, fit for a while. And I get 99.54. So that's interesting, because we've trained this literally from scratch with an architecture we built from scratch. I didn't look up this architecture anywhere. It's just the first thing that came to mind. But in terms of where that puts us, 0.45% error is around about the state of the art for this data set as of three or four years ago. Now, you know, today MNIST is considered a kind of trivially easy data set. So I'm not saying, like, wow, we've broken some records here. People have got beyond 0.45% error. But what I'm saying is that this kind of resnet is a genuinely, extremely useful network still today. And this is really all we use in our fast ImageNet training still. And one of the reasons as well is that it's so popular, so the vendors of the library spend a lot of time optimizing it. So things tend to work fast. Whereas some more modern style architectures using things like separable or grouped convolutions tend not to actually train very quickly in practice. If you look at the definition of resblock in the fast AI code, you'll see it looks a little bit different to this. And that's because I've created something called a merge layer. And a merge layer is something which in the forward, just skip dense for a moment, the forward says x plus x.orig. So you can see there's something resnet-ish going on here. What is x.orig? Well, if you create a special kind of sequential model called a sequential ex, so this is like fast AI's sequential extended, it's just like a normal sequential model. But we store the input in x.orig, right? And so this here, sequential ex, conv layer, conv layer, merge layer, will do exactly the same as this. So you can create your own variations of resnet blocks very easily with just sequential ex and merge layer. So there's something else here, which is when you create your merge layer, you can optionally set dense equals true. What happens if you do? Well, if you do, it doesn't go x plus x.orig, it goes cat x, x.orig. In other words, rather than putting a plus in this connection, it does a concatenate. So that's pretty interesting because what happens is that you have your input coming into your res block. And once you use concatenate instead of plus, it's not called a res block anymore, it's called a dense block. And it's not called a resnet anymore, it's called a densenet. So the densenet was invented about a year after the resnet. And if you read the densenet paper, it can sound incredibly complex and different, but actually it's literally identical, but plus here is replaced with cat. So you have your input coming into your dense block, right, and you've got a few convolutions in here, and then you've got some output coming out, and then you've got your identity connection. And remember, it doesn't plus, it concats, so if this is the channel axis, it gets a little bit bigger. And then so we do another dense block, and at the end of that we have all of this coming in. So at the end of that we have the result of the convolution as per usual, but this time the identity block is that big. So you can see that what happens is that with dense blocks it's getting bigger and bigger and bigger, and kind of interestingly the exact input is still here. But actually no matter how deep you get, the original input pixels are still there, and the original layer one features are still there, and the original layer two features are still there. So as you can imagine, densenets are very memory intensive. There are ways to manage this, just from time to time, you can have a regular convolution that squishes your channels back down, but they are memory intensive. But they have very few parameters. So for dealing with small datasets, you should definitely experiment with dense blocks and densenets. They tend to work really well on small datasets. Also because it's possible to keep those original input pixels all the way down the path, they work really well for segmentation. Because for segmentation you want to be able to reconstruct the original resolution of your picture, so having all of those original pixels still there is super helpful. So that's ResNets, and one of the main reasons other than the fact that ResNets are awesome to tell you about them is that these skip connections are useful in other places as well. And it's particularly useful in other places and other ways of designing architectures for segmentation. So in building this lesson, I keep trying to take old papers and saying, imagining, what would that person have done if they had access to all the modern techniques we have now, and I try to rebuild them in a more modern style. So I've been really rebuilding this next architecture we're going to look at called a UNET in a more modern style recently. And got to the point now, I keep showing you this semantic segmentation paper with the state of the art for CanVid, which was 91.5. This week I got it up to 94.1 using the architecture I'm about to show you. So we keep pushing this further and further and further. And it really was all about adding all of the modern tricks, many of which I'll show you today, some of which we'll see in part two. So what we're going to do to get there is we're going to use this UNET. So we've used a UNET before. I've improved it a bit since then. So we've used a UNET before. We used it when we did the CanVid segmentation, but we didn't understand what it was doing. So we're now in a position where we can understand what it was doing. And so the first thing we need to do is kind of understand the basic idea of how you can do segmentation. So if we go back to our CanVid notebook, in our CanVid notebook you'll remember that basically what we were doing is we were taking these photos and adding a class to every single pixel. And so when you go data.showbatch for something which is a segmentation item list, it will automatically show you these color-coded pixels. So here's the thing. In order to color-code this as a pedestrian, but this as a bicyclist, it needs to know what it is. It needs to actually know that's what a pedestrian looks like. And it needs to know that's exactly where the pedestrian is. And this is the arm of the pedestrian and not part of their shopping basket. It needs to really understand a lot about this picture to do this task. And it really does do this task. Like when you looked at the results of our top model, it's, you know, I can't see a single pixel by looking at it by eye. I know there's a few wrong, but I can't see the ones that are wrong. It's that accurate. So how does it do that? So the way that we're doing it to get these really, really good results is, not surprisingly, using pre-training. So we start with a ResNet 34, and you can see that here, UNET learner data, comma, models.resnet34. And if you don't say pre-trained equals false, by default you get pre-trained equals true, because why not? So we start with a ResNet 34, which starts with a big image. So in this case, this is from the UNET paper now. Their images, they started with one channel by 572 by 572. This is for medical imaging segmentation. So after your stride two conv, they're doubling the number of channels to 128, and they're halving the size, so they're now down to 280 by 280. In this original UNET paper, they didn't add any padding, so they lost a pixel on each side each time they did a conv. That's why you're losing these two. So basically half the size, and then half the size, and then half the size, and then half the size, until they're down to 28 by 28 with 1,024 channels. So that's what the UNET's downsampling path, this is what the downsampling path looked like. Ours is just a ResNet 34. So you can see it here, learn.summary. This is literally a ResNet 34. So you can see that the size keeps halving, channels keep going up, and so forth. So eventually you've got down to a point where if you use a UNET architecture, it's 28 by 28 with 1,024 channels. With the ResNet architecture, with a 224 pixel input, it would be 512 channels by 7 by 7. So it's a pretty small grid size on this feature map. Somehow we've got to end up with something which is the same size as our original picture. So how do we do that? How do you do computation which increases the grid size? Well we don't have a way to do that in our current bag of tricks. We can use a stride 1 conv to do computation and keep grid size, or a stride 2 conv to do computation and halve the grid size. So how do we double the grid size? We do a stride half conv, also known as a deconvolution, also known as a transposed convolution. There is a fantastic paper called A Guide to Convolution Arithmetic for Deep Learning that shows a great picture of exactly what does a 3 by 3 kernel stride half conv look like. And it's literally this. If you have a 2 by 2 input, so the blue squares are the 2 by 2 input, you add not only 2 pixels of padding all around the outside, but you also add a pixel of padding between every pixel. And so now if we put this 3 by 3 kernel here and then here and then here, you see how the 3 by 3 kernel is just moving across it in the usual way? You will end up going from a 2 by 2 output to a 5 by 5 output. So if you only added one pixel of padding around the outside, you would end up with a 3 by 3 output. So sorry, 4 by 4. So this is how you can increase the resolution. This was the way people did it until maybe a year or two ago. That's another trick for improving things you find online, because this is actually a dumb way to do it. And it's kind of obvious it's a dumb way to do it for a couple of reasons. One is that, have a look at this. Nearly all of those pixels are white. They're nearly all zeros. So what a waste. What a waste of time. What a waste of computation. There's just nothing going on there. Also this one, when you get down to that 3 by 3 area, 2 out of the 9 pixels are non-white, but this one, 1 out of the 9 are non-white. So there's different amounts of information going into different parts of your convolution. So it just doesn't make any sense to throw away information like this and to do all this unnecessary computation and have different parts of the convolution having access to different amounts of information. So what people generally do nowadays is something really simple, which is if you have a 2 by 2 input with these are your pixel values, a, b, c, and d, and you want to create a 4 by 4, why not just do this? A, a, a, a, b, b, b, b, c, c, c, c, d, d, d, d. So I've now upscaled from 2 by 2 to 4 by 4. I haven't done any interesting computation, but now on top of that I could just do a stride 1 convolution, and now I have done some computation. So an up sample, this is called nearest neighbor interpolation, nearest neighbor interpolation. So you can just do, and that's super fast, which is nice. So you can do a nearest neighbor interpolation and then a stride 1 conv, and now you've got some computation which is actually kind of using, you know, there's no zeros here. This is kind of nice because it gets a mixture of a's and b's, which is kind of what you would want, and so forth. Another approach is instead of using nearest neighbor interpolation, you can use bilinear interpolation, which basically means instead of copying a to all those different cells, you take a kind of a weighted average of the cells around it. So for example, if you were, you know, looking at what should go here, you would kind of go like, oh, it's about three a's, two c's, one d, and two b's, and you kind of take the average. Not exactly, but roughly, just a weighted average. Bilinear interpolation you'll find in any, you know, all over the place. It's a pretty standard technique. Anytime you look at a picture on your computer screen and change its size, it's doing bilinear interpolation. So you can do that, and then a stride one conv. So that was what people were using. That's what people still tend to use. That's as much as I'm going to teach you this part. In part two, we'll actually learn what the Fast AI library is actually doing behind the scenes, which is something called a pixel shuffle, also known as subpixel convolutions. It's not dramatically more complex, but complex enough that I won't cover it today. There's the same basic idea. All of these things is something which is basically letting us do a convolution that ends up with something that's twice the size. And so that gives us our upsampling path. So that lets us go from 28 by 28 to 54 by 54 and keep on doubling the size. So that's good. And that was it until UNet came along. That's what people did. And it didn't work real well. Which is not surprising, because in this 28 by 28 feature map, how the hell is it going to have enough information to reconstruct a 572 by 572 output space? That's a really tough ask. So you tended to end up with these things that lacked fine detail. So what Olaf R\u00f6nerberger and Et al did was they said, hey, let's add a skip connection, an identity connection. And amazingly enough, this was before ResNets existed. So this was like a really big leap, really impressive. And so but rather than adding a skip connection that skipped every two convolutions, they added skip connections where these gray lines are. In other words, they added a skip connection from the same part of the downsampling path to the same sized bit in the upsampling path. And they didn't add. That's why you can see the white and the blue next to each other. They didn't add. They concatenated. So basically, these are like dense blocks. But the skip connections are skipping over larger and larger amounts of the architecture so that over here, you've literally got nearly the input pixels themselves coming into the computation of these last couple of layers. And so that's going to make it super handy for resolving the fine details in these segmentation tasks because you've literally got all of the fine details. On the downside, you don't have very many layers of computation going on here, just four. So you better hope that by that stage, you've done all the computation necessary to figure out is this a bicyclist or is this a pedestrian. But you can then add on top of that something saying, is this exact pixel where their nose finishes or is that the start of the tree? So that works out really well. And that's a UNET. So this is the UNET code from Fast AI. And the key thing that comes in is the encoder. The encoder refers to that part. In other words, in our case, a ResNet 34. In most cases, they have this specific older style architecture. But like I said, replace any older style architecture bits with ResNet bits and life improves, particularly if they're pre-trained. So that certainly happened for us. So we start with our encoder. So our layers of our UNET is an encoder, then batch norm, then ReLU, and then middle conv, which is just conv layer, comma, conv layer. Remember, conv layer is a conv ReLU batch norm in Fast AI. And so that middle conv is these two extra steps here at the bottom. Just doing a little bit of computation. It's kind of nice to add more layers of computation where you can. So encoder batch norm ReLU, and then two convolutions. And then we enumerate through these indexes. What are these indexes? I haven't included the code. But these are basically we figure out what is the layer number where each of these stride two comms occurs. And we just store it in an array of indexes. So then we can loop through that, and we can basically say for each one of those points, create a UNET block, telling us how many upsampling channels there are and how many cross-connection. These things here are called cross-connections, or at least that's what I call them. So that's really the main works going on in the UNET block. As I said, there's quite a few tweaks we do, as well as the fact we use a much better encoder. We also use some tweaks in all of our upsampling using this pixel shuffle. We use another tweak called ICNR. And then another tweak, which I just did in the last week, is to not just take the result of the convolutions and pass it across, but we actually grab the input pixels and make them another cross-connection. That's what this last cross is here. You can see we're literally appending a res block with the original inputs. So you can see our merge layer. So really all the work is going on in UNET block. And UNET block has to store the activations at each of these downsampling points. And the way to do that, as we learned in the last lesson, is with hooks. So we put hooks into the ResNet34 to store the activations each time there's a Stride2 conv. And so you can see here we grab the hook. And we grab the result of the stored value in that hook. And we literally just go torch.cat so we concatenate the upsampled convolution with the result of the hook, which we chuck through BatchNorm. And then we do two convolutions to it. And actually, something you could play with at home is pretty obvious here. Anytime you see two convolutions like this, there's an obvious question is what if we used a ResNet block instead? So you could try replacing those two convs with a ResNet block. You might find you get even better results. They're the kind of things I look for when I look at an architecture is like, oh, two convs in a row probably should be a ResNet block. OK. So that's UNET. And it's amazing to think it preceded ResNet, it preceded DenseNet. It wasn't even published in a major machine learning venue. It was actually published in Micai, which is a specialized medical image computing conference. For years, actually, it was largely unknown outside of the medical imaging community. And actually, what happened was Kaggle competitions for segmentation kept on being easily won by people using UNET. And that was the first time I saw it getting noticed outside the medical imaging community. And then gradually, a few people in the academic machine learning community started noticing. And now everybody loves UNET, which I'm glad, because it's just awesome. So identity connections, regardless of whether they're a plus style or a concat style, are incredibly useful. They can basically get us close to the state of the art on lots of important tasks. So I want to use them on another task now. And so the next task I want to look at is image restoration. So image restoration refers to starting with an image. At this time, we're not going to create a segmentation mask, but we're going to try and create a better image. And there's lots of versions of better. They could be different image. So the kind of things we can do with this kind of image generation would be take a low res image, make it high res, take a black and white image, make it color, take an image where something's being cut out of it and try and replace the cut out thing. Take a photo and try and turn it into what looks like a line drawing. Take a photo and try and make it look like a Monet painting. These are all examples of image to image generation tasks, which you'll know how to do after this part of the class. So in our case, we're going to try to do image restoration, which is going to start with low resolution, poor quality JPEGs with writing written over the top of them and get them to replace them with high resolution, good quality pictures in which the text has been removed. Two questions? Okay, let's go. Why do you concat before calling Conf2, Conf1, not after? Because if you did your convs before you concat, then there's no way for the channels of the two parts to interact with each other. Remember in a 2D conv, it's really 3D. It's moving across two dimensions, but in each case, it's doing a dot product of all three dimensions of a rank three tensor, row by column by channel. So generally speaking, we want as much interaction as possible. We want to say this part of the down sampling path and this part of the up sampling path, if you look at the combination of them, you find these interesting things. So generally, you want to have as many interactions going on as possible in each computation that you do. How does concatenating every layer together in a dense net work when the size of the image feature maps is changing through the layers? That's a great question. So if you have a stride two conv, you can't keep dense netting. So that's what actually happens in a dense net, is you kind of go like dense block growing, dense block growing, dense block growing, so you're getting more and more channels. And then you do a stride two conv without a dense block. And so now it's kind of gone. And then you just do a few more dense blocks and then it's gone. So in practice, a dense block doesn't actually keep all the information all the way through, but it just every up into every one of these stride two cons. And there's kind of various ways of doing these bottlenecking layers where you're basically saying, hey, let's reset. It also helps us keep memory under control because at that point we can decide how many channels we actually want. Good questions. Thank you. All right. So in order to create something which can turn crappy images into nice images, we need a data set containing nice versions of images and crappy versions of the same images. So the easiest way to do that is to start with some nice images and crapify them. And so the way to crapify them is to create a function called crapify, which contains your crapification logic. So my crapification logic, you can pick your own, is that I open up my nice image. I resize it to be really small, 96 by 96 pixels with bilinear interpolation. I then pick a random number between 10 and 70. I draw that number into my image at some random location. And then I save that image with a JPEG quality of that random number. And a JPEG quality of 10 is like absolute rubbish. A JPEG quality of 70 is not bad at all. So I end up with high quality images, low quality images that look something like these. And so you can see this one, there's the image. And this is after transformation, so that's why it's been flipped. And you won't always see the image because we're zooming into them. So a lot of the time the image is cropped out. So yeah, it's trying to figure out how to take this incredibly JPEG artifact-y thing with text written over the top and turn it into this. So I'm using the Oxford Pets data set again, the same one we used in lesson one. So there's nothing more high quality than pictures of dogs and cats. I think we can all agree with that. The crappification process can take a while, but Fast.ai has a function called parallel. And if you pass parallel a function name and a list of things to run that function on, it will run that function on them all in parallel. So this actually can run pretty quickly. The way you write this function is where you get to do all the interesting stuff in this assignment. Try and think of an interesting crappification which does something that you want to do. So if you want to colorize black and white images, you would replace it with black and white. If you want something which can take large cutout blocks of image and replace them with kind of hallucinated image, add a big black box to these. If you want something which can take old family photo scans that have been folded up and have crinkles in, try and find a way of adding dust prints and crinkles and so forth. Anything that you don't include in Crappify, your model won't learn to fix because every time it sees that in your photos, the input and output will be the same. So it won't consider that to be something worthy of fixing. So we now want to create a model which can take an input photo that looks like that and output something that looks like that. So obviously what we want to do is use a unit because we already know that units can do exactly that kind of thing. And we just need to pass the unit that data. So our data is just literally the file names of each of those two folders. Do some transforms, data bunch, normalize, or use ImageNet stats because we're going to use a pre-trained model. Why are we using a pre-trained model? Well, because if you're going to get rid of this 46, you need to know what probably was there and to know what probably was there, you need to know what this is a picture of. Because otherwise how can you possibly know what it ought to look like? So let's use a pre-trained model that knows about these kinds of things. So we create our unit with that data. The architecture is ResNet34. These three things are important and interesting and useful, but I'm going to leave them to part two. For now, you should always include them when you use a unit for this kind of problem. And so now we're going to... This whole thing I'm calling a generator. It's going to generate. This is generative modeling. There's not a really formal definition, but it's basically something where the thing we're outputting is like a real object, in this case an image. It's not just a number. So we're going to create a generator learner, which is this unit learner, and then we can fit. We're using MSC loss. So in other words, what's the mean squared error between the actual pixel value that it should be and the pixel value that we predicted? MSC loss normally expects two vectors. In our case, we have two images. So we have a version called MSC loss flat, which simply flattens out those images into a big long vector. There's never any reason not to use this. Even if you do have a vector, it works fine. If you don't have a vector, it'll also work fine. So we're already down to.05 mean squared error on the pixel values, which is not bad after 1 minute 35. Like all things in Fast.ai pretty much, because we're doing transfer learning by default, when you create this, it'll freeze the pre-trained part. And the pre-trained part of a UNet is this part, the downsampling part. That's where the ResNet is. So let's unfreeze that and train a little more. And look at that. So with four minutes of training, we've got something which is basically doing a perfect job of removing numbers. It's certainly not doing a good job of upsampling, but it's definitely doing a nice... Sometimes when it removes a number, it maybe leaves a little bit of JPEG artifact, but it's certainly doing something pretty useful. And so if all we wanted to do was kind of watermark removal, we'd be finished. We're not finished because we actually want this thing to look more like this thing. So how are we going to do that? The problem, the reason that we're not making as much progress with that as we'd like is that our loss function doesn't really describe what we want, because actually the mean squared error between the pixels of this and this is actually very small. If you actually think about it, most of the pixels are very nearly the right color. But we're missing the texture of the pillow, and we're missing the eyeballs entirely pretty much. And we're missing the texture of the fur. So we want some loss function that does a better job than pixel mean squared error loss of saying, is this a good quality picture of this thing? So there's a fairly general way of answering that question, and it's something called a Generative Adversarial Network, or GAN. And a GAN tries to solve this problem by using a loss function which actually calls another model. And let me describe it to you. So we've got our crappy image, and we've already created a generator. It's not a great one, but it's not terrible. And that's creating predictions like this. We have a high-res image like that, and we can compare the high-res image to the prediction with pixel MSE. We could also train another model which we would variously call either the discriminator or the critic. They've both been the same thing. I'll call it a critic. We could try and build a binary classification model that takes all the pairs of the generated image and the real high-res image and tries to learn to classify which is which. So look at some picture and say, hey, what do you think? Is that a high-res cat or is that a generated cat? How about this one? Is that a high-res cat or a generated cat? So just a regular standard binary cross-entropy classifier. So we know how to do that already. So if we had one of those, we could now train, we could fine-tune the generator, and rather than using pixel MSE as the loss, the loss could be how good are we at fooling the critic? So can we create generated images that the critic thinks are real? So that would be a very good plan, right? Because if it can do that, if the loss function is am I fooling the critic, then it's going to learn to create images which the critic can't tell whether they're real or fake. So we could do that for a while, train a few batches. But the critic isn't that great. The reason the critic isn't that great is because it wasn't that hard. These images are really shitty, so it's really easy to tell the difference. So after we train the generator a little bit more using the critic as the loss function, the generator is going to get really good at fooling the critic. So now we're going to stop training the generator and we'll drain the critic some more on these newly generated images. So now that the generator is better, it's now a tougher task for the critic to decide which is real and which is fake. So we'll train that a little bit more. And then once we've done that and the critic is now pretty good at recognising the difference between the better generated images and the originals, we'll go back and we'll fine tune the generator some more using the better discriminator, the better critic as the loss function. And so we'll just go ping pong, ping pong, backwards and forwards. That's a GAN. That's our version of GAN. I don't know if anybody's written this before. We've created a new version of a GAN which is kind of a lot like the original GANs, but we have this neat trick where we pre-train the generator and we pre-train the critic. I mean GANs have been kind of in the news a lot. They're a pretty fashionable tool and if you've seen them you may have heard that they're a real pain to train. But it turns out, we realised that really most of the pain of training them was at the start. If you don't have a pre-train generator and you don't have a pre-train critic, then it's basically the blind leading the blind. The generator is trying to generate something which fools the critic, but the critic doesn't know anything at all, so it's basically got nothing to do. And then the critic's kind of trying to decide whether the generated images are real or not, and that's really obvious, so that just does it. And so they kind of like don't go anywhere for ages, and then once they finally start picking up steam, they go along pretty quickly. So if you can find a way to generate things without using a GAN, like mean squared error pixel loss, and discriminate things without using a GAN, like predict on that first generator, you can make a lot of progress. So let's create the critic. So to create just a totally standard Fast.ai binary classification model, we need two folders, one folder is containing high-res images, one folder containing generated images. We already have the folder with the high-res images, so we just have to save our generated images. So here's a teeny tiny bit of code that does that. We're going to create a directory called imagegen, pop it into a variable called pathgen. We've got a little function called savePreds that takes a data loader, and we're going to grab all of the file names, because remember that in an item list, the dot items contains the file names, if it's an image item list. So here's the file names in that data loader's data set. And so now let's go through each batch of the data loader, and let's grab a batch of predictions for that batch, and then reconstruct equals true, means it's actually going to create Fast.ai image objects for each thing in the batch. And so then we'll go through each of those predictions and save them. And the name we'll save it with is the name of the original file, but we're going to pop it into our new directory. So that's it. That's how you save predictions. And so you can see I'm kind of increasingly not just using stuff that's already in the Fast.ai library, but trying to show you how to write stuff yourself. And generally it doesn't require heaps of code to do that. And so if you come back to part two, this is what, lots of part two were kind of like, here's how you use things inside the library, and of course here's how we wrote the library. So we're increasingly writing our own code. So save those predictions, and then let's just do a pil.image.open on the first one, and yep, there it is. Okay, so there's an example of a generated image. So now I can train a critic in the usual way. It's really annoying to have to restart Jupyter Notebook to reclaim GPU memory. So one easy way to handle this is if you just set something that you knew was using a lot of GPU to none, like this learner, and then just go gc.collect, that tells Python to do memory garbage collection, and after that you'll generally be fine. You'll be able to use all of your GPU memory again. If you're using NVIDIA SMI to actually look at your GPU memory, you won't see it clear, because PyTorch still has a kind of allocated cache, but it makes it available. So you should find this is how you can avoid restarting your notebook. Okay, so we're going to create our critic. It's just an image item list from folder in the totally usual way, and the classes will be the image gen and images. We'll do a random split, because we want to know how well we're doing with the critic to have a validation set. We just label it from folder in the usual way. Add some transforms, data bunch normalized. So it's a totally standard object classifier. Okay, so we've got a totally standard classifier. So here's what some of it looks like. So here's one from the real images, real images, generated images, generated images. So it's got to try and figure out which class is which. Okay, so we're going to use binary cross entropy as usual. However, we're not going to use a ResNet here. And the reason we'll get into in more detail in part two, but basically when you're doing a GAN, you need to be particularly careful that the generator and the critic can't kind of both push in the same direction and increase the weights out of control. So we have to use something called spectral normalization to make GANs work nowadays. We'll learn about that in part two. So anyway, if you say GAN critic, Fast.AI will give you a binary classifier. I strongly suspect we probably can use a ResNet here. We just have to create a pre-trained ResNet with SpectroNorm. Hope to do that pretty soon. We'll see how we go. But as of now, this is kind of the best approach is this thing called GAN critic. A GAN critic uses a slightly different way of averaging the different parts of the image when it does the loss. So anytime you're doing a GAN at the moment, you have to wrap your loss function with adaptive loss. Again, we'll look at the details in part two. For now, just know this is what you have to do and it'll work. So other than that, slightly odd loss function and that slightly odd architecture, everything else is the same. We can call that to create our critic. Because we have this slightly different architecture and slightly different loss function, we did a slightly different metric. This is the equivalent GAN version of accuracy for critics. And then we can train it. And you can see it's 98% accurate at recognizing that kind of crappy thing from that kind of nice thing. And of course, we don't see the numbers here anymore, right? Because these are the generated images. The generator already knows how to get rid of those numbers that are written on top. So let's finish up this GAN. Now that we have pre-trained the generator and pre-trained the critic, we now need to get it to kind of ping pong between training a little bit of each. And the amount of time you spend on each of those things and the learning rates you use is still a little bit on the fussy side. So we've created a GAN learner for you, which you just pass in your generator and your critic, which we've just simply loaded here from the ones we just trained. And it will go ahead and when you go learn.fit, it will do that for you. It will figure out how much time to train the generator, and then when to switch to training the discriminator, the critic, and it'll go back on and forward. These weights here is that what we actually do is we don't only use the critic as the loss function. If we only use the critic as the loss function, the GAN could get very good at creating pictures that look like real pictures, but they actually have nothing to do with the original photo at all. So we actually add together the pixel loss and the critic loss. And so those two losses are kind of on different scales. So we multiply the pixel loss by something between about 50 and about 200. And something in that range generally works pretty well. Something else with GANs. GANs hate momentum when you're training them. It kind of doesn't make sense to train them with momentum because you keep switching between generator and critic, so it's kind of tough. Maybe there are ways to use momentum, but I'm not sure anybody's figured it out. So this number here, when you create an atom optimizer, is where the momentum goes. So you should set that to zero. So anyway, if you're doing GANs, use these hyperparameters. It should work. So that's what GANLearner does. And so then you can go fit, and it trains for a while. And one of the tough things about GANs is that these loss numbers, they're meaningless. You can't expect them to go down. Because as the generator gets better, it gets harder for the discriminator, the critic. And then as the critic gets better, it gets harder for the generator. So the numbers should stay about the same. So that's one of the tough things about training GANs, is it's kind of hard to know how are they doing. So the only way to know how are they doing is to actually take a look at the results from time to time. And so if you put show image equals true here, it'll actually print out a sample after every epoch. I haven't put that in the notebook because it makes it too big for the repo, but you can try that. So I've just put the results at the bottom, and here it is. So pretty beautiful, I would say. We already knew how to get rid of the numbers, but we now don't really have that kind of artifact of where it used to be, and it's definitely sharpening up this little kitty cat quite nicely. It's not great always. Like there's some weird kind of noise going on here. Certainly a lot better than the horrible original. Like this is a tough job to turn that into that. But there are some really obvious problems. Like here, these things ought to be eyeballs, and they're not. So why aren't they? Well, our critic doesn't know anything about eyeballs, and even if it did, it wouldn't know that eyeballs are particularly important. We care about eyes. Like when we see a cat without eyes, it's a lot less cute. I mean I'm more of a dog person. It just doesn't know that this is a feature that matters, particularly because the critic, remember, is not a pre-trained network. So I kind of suspect that if we replace the critic with a pre-trained network that's been pre-trained on ImageNet but is also compatible with GANs, it might do a better job here. But it's definitely a shortcoming of this approach. So we're going to have a break. Oh, question first, and then we'll have a break, and then after the break I will show you how to find the cat's eyeballs again. For what kind of problems do you not want to use UNETs? Well UNETs are for when the size of your output is similar to the size of your input and kind of aligned with it. There's no point having cross connections if that level of spatial resolution in the output isn't necessary or useful. So yeah, any kind of generative modeling, and segmentation is kind of generative modeling, it's generating a picture which is a mask of the original objects. So probably anything where you want that kind of resolution of the output to be the same kind of fidelity as resolution of the input. Obviously something like a classifier makes no sense. In a classifier you just want the downsampling path because at the end you just want a single number which is like is it a dog or a cat or what kind of pet is it or whatever. Great. Okay, so let's get back together at 5 past 8. Just before we leave GANs I just mentioned there's another notebook you might be interested in looking at which is lesson 7W GAN. When GANs started a few years ago people generally used them to kind of create images out of thin air which I personally don't think is a particularly useful or interesting thing to do but it's kind of a good, I don't know, it's a good research exercise I guess. So we implemented this WGAN paper which was kind of really the first one to do a somewhat adequate job somewhat easily and so you can see how to do that with the Fast AI library. It's kind of interesting because the dataset we use is this Lsun Bedrooms dataset which we provided in our URLs which just as you can see has lots and lots and lots of bedrooms. And the approach, you'll see in the pros here that Sylvain wrote, the approach that we use in this case is to just say can we create a bedroom? And so what we actually do is that the input to the generator isn't an image that we clean up. We actually feed to the generator random noise. And so then the generator's task is can you turn random noise into something which the critic can't tell the difference between that output and a real bedroom. And so we're not doing any pre-training here or any of the stuff that makes this kind of fast and easy. So this is a very traditional approach but you can see you still just go GAN learner and there's actually a WGAN version which is this kind of older style approach. You just pass in the data and the generator and the critic in the usual way and you call fit. And you'll see in this case we have show image on. After epoch one it's not creating great bedrooms or two or three. And you can really see that in the early days of these kinds of GANs it doesn't do a great job of anything. But eventually after a couple of hours of training producing somewhat like bedroom-ish things. So anyway it's a notebook you can never play with and it's a bit of fun. So I was very excited when we got fast AI to the point in the last week or so that we had GANs working in a way where kind of API-wise they're far more concise and more flexible than any other library that exists. But also kind of disappointed with they take a long time to train and the outputs are still like so-so. And so the next step was like well can we get rid of GANs entirely. So the first step with that, I mean obviously the thing we really want to do is come up with a better loss function. We want a loss function that does a good job of saying this is a high quality image without having to go all the GAN trouble and preferably it also doesn't just say it's a high quality image but it's an image which actually looks like the thing it's meant to. So the real trick here comes back to this paper from a couple of years ago, Perceptual Losses for Real-Time Style Transfer and Super Resolution. Justin Johnson et al. created this thing they call perceptual losses. It's a nice paper but I hate this term because they're nothing particularly perceptual about them. I would call them feature losses. So in the Fast AI library you'll see this referred to as feature losses. And it shares something with GANs which is that after we go through our generator which they call the Image Transform Net and you can see it's got this kind of U-net shaped thing they didn't actually use U-nets because at the time this came out nobody in the machine learning world much knew about U-nets. Nowadays of course we use U-nets. But anyway something U-net-ish. I should mention in these kind of these architectures where you have a downsampling path followed by an upsampling path, the downsampling path is very often called the encoder. As you saw in our code actually we called that the encoder. And the upsampling path is very often called the decoder. In generative models generally including generative text models, neural translation, stuff like that they tend to be called the encoder and the decoder, two pieces. So we have this generator and we want a loss function that says is the thing that it's created like the thing that we want. And so the way they do that is they take the prediction, remember y hat is what we normally use for a prediction from a model. We take the prediction and we put it through a pre-trained image net network. So at the time that this came out the pre-trained image network they were using was VGG. People still, it's kind of old now but people still tend to use it because it works fine for this process. So they take the prediction and they put it through VGG, the pre-trained image net network. It doesn't matter too much which one it is. And so normally the output of that would tell you hey, is this generated thing a dog or a cat or an airplane or a fire engine or whatever. But in the process of getting to that final classification it goes through lots of different layers and in this case they've color coded all the layers with the same grid size and the feature map with the same color. So every time we switch colors we're switching grid size. So there's a stride to conv or in VGG's case they still used to use max pooling layers which is a similar idea. And so what we could do is say let's not take the final output of the VGG model on this generated image but let's take something in the middle. Let's take the activations of some layer in the middle. So those activations might be a feature map of 256 channels by 28 by 28. And so those 28 by 28 grid cells will kind of roughly semantically say things like hey, in this part of that 28 by 28 grid is there something that looks kind of furry or is there something that looks kind of shiny or is there something that looks kind of circular or is there something that kind of looks like an eyeball or whatever. So what we do is we then take the target, so the actual Y value, and we put it through the same pre-trained VGG network and we pull out the activations of the same layer and then we do a mean squared error comparison. So it'll say like okay, in the real image grid cell 1,1 of that 28 by 28 feature map cell is furry and blue and round shaped and in the generated image it's furry and blue and not round shaped. So it's kind of like an okay match. So that ought to go a long way towards fixing our eyeball problem because in this case the feature map is going to say there's eyeballs here, sorry here, but there isn't here. So do a better job of that please, make better eyeballs. So that's the idea. And so that's what we call feature losses or Johnson et al. called perceptual losses. So to do that we're going to use the Lesson 7 super res notebook and this time the task we're going to do is kind of the same as the previous task, but I wrote this notebook a little bit before, the GAN notebook, before I came up with the idea of like putting text on it and having a random JPEG quality. So the JPEG quality is always 60, there's no text written on top and it's 96 by 96. So and it's before I realized what a great word crapify is, so it's called resize. So here's our crappy images and our original images, kind of a similar task to what we had before. So I'm going to try and create a loss function which does this. So the first thing I do is I define a base loss function which is basically like how am I going to compare the pixels and the features, you know, and the choices mainly are like MSE or L1, doesn't matter too much which you choose. I tend to like L1 better than MSE actually, so I picked L1. So anytime you see base loss we mean L1 loss, you could use MSE loss as well. So let's create a VGG model, right, so just using the pre-trained model. In VGG there's an attribute called dot features which contains the convolutional part of the model. So here's the convolutional part of the VGG model because we don't need the head because we only want the intermediate activations. So then we'll chuck that on the GPU, we'll put it into eval mode because we're not training it, and we'll turn off requires grad because we don't want to update the weights of this model, we're just using it for inference, right, for the loss. So then let's enumerate through all the children of that model and find all of the max pooling layers because in the VGG model that's where the grid size changes and as you can see from this picture we kind of want to grab features from every time just before the grid size changes. So we grab layer i minus 1, so that's the layer before it changes. So there's our list of layer numbers just before the max pooling layers. And so all of those are values, not surprisingly. So those are where we want to grab some features from. And so we put that in blocks, it's just a list of IDs. So here's our feature loss class which is going to implement this idea. So basically when we call the feature loss class we're going to pass it some pre-trained model. And so that's going to be called mfit. That's the model which contains the features which we want to generate for, want our feature loss on. So we can go ahead and grab all of the layers from that network that we want the features for to create the losses. So we're going to need to hook all of those outputs because remember that's how we grab intermediate layers in PyTorch is by hooking them. So this is going to contain our hooked outputs. So now in the forward feature loss we're going to make features passing in the target, so this is our actual y, which is just going to call that VGG model and go through all of the stored activations and just grab a copy of them. And so we're going to do that both for the target, call that outfit, and for the input, so that's the output of a generator, in fit. And so now let's calculate the L1 loss between the pixels because we still want the pixel loss a little bit. And then let's also go through all of those layers' features and get the L1 loss on them. So we're basically going through every one of these, end of each block, and grabbing the activations and getting the L1 on each one. So that's going to end up in this list called feature losses, which I then sum them all up. And by the way, the reason I do it as a list is because we've got this nice little callback that if you put them into a thing called.metrics in your loss function, it'll print out all of the separate layer loss amounts for you, which is super handy. So that's it, that's our perceptual loss or feature loss class. And so now we can just go ahead and train a unit in the usual way with our data and our pre-trained architecture, which is a ResNet-34, passing in our loss function, which is using our pre-trained VGG model. And this is that callback I mentioned, lossmetrics, which is going to print out all the different layers' losses for us. These are two things that we'll learn about in part two of the course, but you should use them. LR find, I just created a little function called do fit that does fit one cycle and then saves the model and then shows the results. So as per usual, because we're using a pre-trained network in our unit, we start with frozen layers for the downsampling path, train for a while, and as you can see, we get not only the loss, but also the pixel loss and the loss at each of our feature layers. And then also something we'll learn about in part two called gram loss, which I don't think anybody's used for super res before as far as I know, but as you'll see, it turns out great. So that's eight minutes, so much faster than a GAN, and already, as you can see, this is our output, model output, pretty good. So then we unfreeze and train some more, and it's a little bit better. And then let's switch up to double the size, and so we need to also halve the batch size to avoid running out of GPU memory, and freeze again and train some more, so it's now taking half an hour, even better, and then unfreeze and train some more. So all in all, we've done about an hour and 20 minutes of training, and look at that! It's done it. It knows that eyes are important, so it's really made an effort. It knows that fur is important, so it's really made an effort. So it started with something with like JPEG artifacts around the ears, and all this mess, and like eyes that are just kind of vague light blue things, and it just, it really created a lot of texture. This cat is clearly kind of like looking over the top of one of those little chlorine frames covered in fuzz, so it actually recognized that this thing is probably kind of a carpety material that's created a carpety material for us, so I mean that's just remarkable. So talking of remarkable, we can now, so I've never seen outputs like this before without again, so I was just so excited when we were able to generate this, and so quickly, one GPU, hour and a half. So like if you create your own crapification functions and train this model, you'll build stuff that nobody's built before, because like nobody else that I know of is doing it this way, so there are huge opportunities I think. So check this out. What we can now do is we can now, instead of starting with our low res, I actually stored another set at size 256 which are called medium res, so let's see what happens if we upsize the medium res. So we're going to grab our medium res data, and here is our medium res stored photo, and so can we improve this? So you can see there's still a lot of room for improvement, like you see the lashes here are very pixelated, the place where there should be hair here is just kind of fuzzy, so watch this area as I hit down on my keyboard, look at that, it's done it, it's taken a medium res image and it's made a totally clear thing here, the furs reappeared, look at the eyeball, let's go back, the eyeball here is just kind of a general blue thing, here it's added all the right texture. So I just think this is super exciting, here's a model I trained in an hour and a half using standard stuff that you've all learnt about, a unit, a pre-trained model, feature loss function, and we've got something which can turn that into that, or this absolute mess into this. And it's really exciting to think what could you do with that. So one of the inspirations here has been a guy called Jason Antich, and Jason was a student in the course last year, and what he did, very sensibly, was decide to focus, basically nearly quit his job and work four days a week, or really six days a week on studying deep learning, and as you should do, he created a kind of capstone project, and his project was to combine GANs and feature losses together. And his crappification approach was to take colour pictures and make them black and white. So he took the whole of ImageNet, created a black and white ImageNet, and then trained a model to recolourise it, and he's put this up as De-Oldify, and now he's got these actual old photos from the 19th century that he's turning into colour. And what this is doing is incredible. Look at this. The model thought, oh, that's probably some kind of copper kettle, so I'll make it copper coloured. And oh, these pictures are on the wall, they're probably different colours to the wall, and maybe that looks a bit like a mirror. Maybe it would be reflecting stuff outside. These things might be vegetables. Vegetables are often red. Let's make them red. It's extraordinary what it's done. And you could totally do this too. You can take our feature loss and our GAN loss and combine them. So I'm very grateful to Jason because he's helped us build this lesson, and it's been really nice because we've been able to help him too, because he hadn't realised that he can use all this pre-training and stuff, and so hopefully you'll see De-Oldify in the next couple of weeks be even better at De-Oldification. But hopefully you all can now add other kinds of de-crapification methods as well. I like every course, if possible, to show something totally new, because then every student has the chance to basically build things that had never been built before. So this is kind of that thing. But between the much better segmentation results and these much simpler and faster de-crapification results, I think you can build some really cool stuff. Did you have a question? Is it possible to use similar ideas to UNET and GANs for NLP? For example, if I want to tag the verbs and nouns in a sentence or create a really good Shakespeare generator? Yeah, pretty much. We don't fully know yet. It's a pretty new area, but there's a lot of opportunities there, and we'll be looking at some in a moment, actually. So I actually tried testing this on this. Remember this picture I showed you of a slide last lesson? And it's a really rubbishy-looking picture, and I thought, what would happen if we tried running this just through the exact same model, and it changed it from that to that? So I thought that was a really good example. You can see something it didn't do, which is this weird discoloration. It didn't fix it, because I didn't crapify things with weird discoloration. So if you want to create really good image restoration, like I say, you need really good crapification. OK, so here's what we've learned so far in the course, some of the main things. So we've learned that neural nets consist of sandwich layers of affine functions, which are basically matrix multiplications, slightly more general version, and nonlinearities, like ReLU. And we learned that the results of those calculations are called activations, and the things that go into those calculations that we learn are called parameters, and that the parameters are initially randomly initialized, or we copy them over from a pre-trained model, and then we train them with SGD or faster versions. And we learned that convolutions are a particular affine function that work great for autocorrelated data, so things like images and stuff. We learned about batch norm, dropout, data augmentation, and weight decay as ways of regularizing models, and also batch norm helps train models more quickly. And then today we've learned about res slash dense blocks. We've obviously learned a lot about image classification regression, embeddings, categorical and continuous variables, collaborative filtering, language models and NLP classification, and then kind of segmentation, neural net and GANs. So go over these things and make sure that you feel comfortable with each of them. If you've only watched this series once, you definitely won't. People normally watch it three times or so to really understand the detail. So one thing that doesn't get here is RNNs. So that's the last thing we're going to do, RNNs. So RNNs, I'm going to introduce a little kind of diagrammatic method here to explain RNNs. In the diagrammatic method, I'll start by showing you a basic neural net with a single hidden layer. Square means an input. So that'll be batch size by number of inputs. So kind of batch size by number of inputs. An arrow means a layer, broadly defined, such as matrix product followed by value. A circle is activations. So in this case, we have one set of hidden activations. And so given that the input was number of inputs, this here is a matrix of number of inputs by number of activations. So the output will be batch size by number of activations. It's really important you know how to calculate these shapes. So go learn.summary lots to see all the shapes. So then here's another arrow. So that means it's another layer, matrix product followed by nonlinearity. In this case, we go into the output, so we use softmax. And then triangle means an output. And so this matrix product will be number of activations by number of classes. So our output is batch size by number of classes. So let's reuse that key, remember, triangle output, circle is activations, hidden state we also call that, and rectangle is input. So let's now imagine that we wanted to get a big document, split it into sets of three words at a time, and grab each set of three words and then try to predict the third word using the first two words. So if we had the data set in place, we could grab word one as an input, chuck it through an embedding, right, create some activations, pass that through a matrix product and nonlinearity, grab the second word, put it through an embedding, and then we could either add those two things together or concatenate them. Generally speaking, when you see kind of two sets of activations coming together in a diagram, you normally have a choice of concatenate or add. And that's going to create a second bunch of activations, and then you can put it through one more fully connected layer and softmax to create an output. So that would be a totally standard, fully connected neural net with one very minor tweak, which is concatenating or adding at this point, which we could use to try to predict the third word from pairs of two words. Okay. So remember, arrows represent layer operations, and I removed in this one the specifics of what they are because they're always an affine function followed by nonlinearity. Okay. Let's go further. What if we wanted to predict word four using words one and two and three? It's basically the same picture as last time except with one extra input and one extra circle. But I want to point something out, which is each time we go from rectangle to circle, we're doing the same thing. We're doing an embedding, which is just a particular kind of matrix multiply where you have one hot encoded input. Each time we go from circle to circle, we're basically taking one piece of hidden state, one set of activations, and turning it into another set of activations by saying we're now at the next word. And then when we go from circle to triangle, we're doing something else again, which is we're saying let's convert the hidden state, these activations, into an output. So it makes sense. So you can see I've colored each of those arrows differently. So each of those arrows should probably use the same weight matrix because it's doing the same thing. So why would you have a different set of embeddings for each word or a different set of a different matrix to multiply by to go from this hidden state to this hidden state versus this one? So this is what we're going to build. So we're now going to jump into human numbers, which is less than seven human numbers. And this is a data set that I created which literally just contains all the numbers from one to 9,999 written out in English. And we're going to try and create a language model that can predict the next word in this document. It's just a toy example for this purpose. So in this case, we only have one document. That one document is the list of numbers. So we can use a text list to create an item list with text in for the training and the validation. In this case, the validation set is the numbers from 8,000 onwards and the training set is 1 to 8,000. We can combine them together, turn that into a data bunch. So we only have one document. So train zero is the document. Grab its dot text. That's how you grab the contents of a text list. And here are the first 80 characters. It starts with a special token, XXBOS. Anything starting with XX is a special fast AI token. BOS is the beginning of stream token. It basically says this is the start of a document. It's very helpful in NLP to know when documents start so that your models can learn to recognize them. The validation set contains 13,000 tokens. So 13,000 words or punctuation marks. Because everything between spaces is a separate token. The batch size that we asked for was 64. And then by default it uses something called BPTT of 70. BPTT, as we briefly mentioned, stands for back prop through time. That's the sequence length. So with each of our 64 document segments, we split it up into lists of 70 words that we look at at one time. So what we do is we grab this for the validation set, entire string of 13,000 tokens. And then we split it into 64 roughly equal sized sections. People very, very, very often think I'm saying something different. I did not say they are of length 64. They're not. They're 64 equally sized roughly segments. So we take the first 1.64th of the document, piece 1. Second 64th, piece 2. And then for each of those 1.64th of the document, we then split those into pieces of length 70. So each batch, so let's now say, OK, for those 13,000 tokens, how many batches are there? Well divide by batch size and divide by 70. So there's about 2.9 batches. So there's going to be three batches. So let's grab an iterator for our data loader. Grab one, two, three batches, the X and the Y. And let's add up the number of elements. And we get back slightly less than this because there's a little bit left over at the end that doesn't quite make up a full batch. So this is the kind of stuff you should play around with a lot, lots of shapes and sizes and stuff and iterators. As you can see, it's 95 by 64. I claimed it was going to be 70 by 64. That's because our data loader for language models slightly randomizes BPTT, just to give you a bit more shuffling, get a bit more randomization. It helps the model. And so here you can see the first batch of X. Remember we've numericalized all these. And here's the first batch of Y. And you'll see here this is 2, 18, 10, 11, 8. This is 18, 10, 11, 8. So this one is offset by 1 from here because that's what we want to do with a language model. We want to predict the next word. So after 2 should come after 18. And after 18 should come 10. You can grab the vocab for this data set. And a vocab has a textify. So if we look at the same thing but with textify, that'll just look it up in the vocab. So here you can see XXBOS 8001. Whereas in the Y, there's no XXBOS. It's just 8001. So after XXBOS is 8. After 8 is 1000. After 1000 is 1. And so then after we get 8023 comes X2. And look at this. We're always looking at column 0. So this is the first batch, the first mini-batch. Comes 8024. And then X3 all the way up to 8040. And so then we can go right back to the start but look at batch 1. So index 1, which is batch number 2. And now we can continue. A slight skip from 8040 to 8046. That's because the last mini-batch wasn't quite complete. So what this means is that every mini-batch joins up with the previous mini-batch. So you can go straight from X1, 0 to X2, 0. It continues. 8023, 8024. And so if you look at the same thing for column, comma, 1, you'll also see they join up. So all the mini-batches join up. So that's the data. We can do show batch to see it. And here is our model, which is doing this. So here is just the code copied over. So it contains one embedding, i.e. the green arrow, one hidden to hidden brown arrow layer, and one hidden to output. So each coloured arrow has a single matrix. And so then in the forward pass, we take our first input, X0, and put it through input to hidden, the green arrow. Create our first set of activations, which we call H. Assuming that there is a second word, because sometimes we might be at the end of a batch where there isn't a second word, assuming there is a second word, then we would add to H the result of X1 put through the green arrow. Remember that's iH. And then we would say, OK, our new H is the result of those two added together, put through our hidden to hidden, orange arrow, and then ReLU, then batched on. And then for the second word, do exactly the same thing. And then finally, blue arrow, put it through HO. So that's how we convert our diagram to code. So nothing new here at all. So now let's do, and just so we can chuck that in the learner and we can train it, 46%. Let's take this code and recognise it's pretty awful. There's a lot of duplicate code. And as coders, when we see duplicate code, what do we do? We refactor. So we should refactor this into a loop. So here we are. We've refactored it into a loop. So now we're going for each X, i, and X, and doing it in the loop. Guess what? That's an RNN. An RNN is just a refactoring. It's not anything new. This is now an RNN. And let's refactor our diagram from this to this. This is the same diagram. But I've just replaced it with my loop. It does the same thing. So here it is. It's got exactly the same in it, literally exactly the same. Just popped a loop here. Before I start, I just have to make sure that I've got a bunch of zeros to add to. And of course, I get exactly the same result when I train it. So next thing that you might think then, and one nice thing about the loop, though, is now this will work even if I'm not predicting the fourth word from the previous three, but the ninth word from the previous eight. It'll work for any arbitrarily length long sequence, which is nice. So let's up the BPTT to 20, since we can now. And let's now say, OK, instead of just predicting the nth word from the previous n minus 1, let's try to predict the second word from the first, and the third from the second, and the fourth from the third, and so forth. Because previously, look at our loss function. Previously we were comparing the result of our model to just the last word of the sequence. It's just very wasteful, because there's a lot of words in the sequence. So let's compare every word in x to every word in y. So to do that, we need to change this so it's not just one triangle at the end of the loop, but the triangle is inside this, right? So that in other words, after every loop, predict, loop, predict, loop, predict. So here's this code. It's the same as the previous code, but now I've created an array. And every time I go through the loop, I append ho, h to the array. So now for n inputs, I create n outputs. So I'm predicting after every word. Previously I had 46%. Now I have 40%. Why is it worse? Well, it's worse because now, when I'm trying to predict the second word, I only have one word of state to use. So when I'm looking at the third word, I only have two words of state to use. So it's a much harder problem for it to solve. So the obvious way to fix this then, the key problem is here. I go h equals torch.zeros. I reset my state to zero every time I start another BPTT sequence. Well let's not do that. Let's keep h. And we can, because remember each batch connects to the previous batch. It's not shuffled like happens in image classification. So let's take this exact model and replicate it again, but let's move the creation of h into the constructor. Okay, there it is. So it's now self.h. And so this is now exactly the same code, but at the end, let's put the new h back into self.h. So it's now doing the same thing, but it's not throwing away that state. And so therefore now we actually get above the original. We get all the way up to 54% accuracy. So this is what a real RNN looks like. You always want to keep that state. But just keep remembering, there's nothing different about an RNN. It's a totally normal, fully connected neural net. It's just that you've got a loop you refactored. What you could do though is at the end of your every loop, you could not just spit out an output, but you could spit it out into another RNN. So you'd have an RNN going into an RNN. And that's nice because we've now got more layers of computation. You would expect that to work better. Well to get there, let's do some more refactoring. So let's take this code and replace it with the equivalent built-in PyTorch code, which is you just say that. So nn.rnn basically says do the loop for me. We've still got the same embedding. We've still got the same output. We've still got the same batch norm. We've still got the same initialization of h, but we just got rid of the loop. So one of the nice things about RNN is that you can now say how many layers you want. So this is the same accuracy of course. So here I'm going to do it with two layers. But here's the thing. When you think about this, think about it without the loop. It looks like this. It keeps on going. And we've got a BPTT of 20, so there's 20 layers of this. And we know from that visualizing the loss landscapes paper that deep networks have awful bumpy loss surfaces. So when you start creating long time scales and multiple layers, these things get impossible to train. So there's a few tricks you can do. One thing is you can add skip connections, of course. But what people normally do is instead they put inside, instead of just adding these together, they actually use a little mini neural net to decide how much of the green arrow to keep and how much of the orange arrow to keep. And when you do that, you get something that's either called a GRU or an LSTM, depending on the details of that little neural net. And we'll learn about the details of those neural nets in part two. They really don't matter though, frankly. So we can now say let's create a GRU instead. So it's just like what we had before, but it'll handle longer sequences and deeper networks. Let's use two layers. Boom. And we're up to 75%. So that's RNNs. And the main reason I wanted to show it to you was to remove the last remaining piece of magic. And this is one of the least magical things we have in deep learning. It's just a refactored, fully connected network. So don't let RNNs ever put you off. And with this approach, where you basically have a sequence of N inputs and a sequence of N outputs we've been using for language modeling, you can use that for other tasks. For example, the sequence of outputs could be for every word. There could be something saying, is this something that is sensitive and I want to anonymize or not? You know, so like is this private data or not? Or it could be a part of speech tag for that word. Or it could be something saying, you know, how should that word be formatted or whatever? And so these are called sequence labeling tasks. And so you can use this same approach for pretty much any sequence labeling task. Or you can do what I did in the earlier lesson, which is once you finish building your language model, you can throw away this HO bit and instead pop there a standard classification head and then you can now do NLP classification, which as you saw earlier will give you state of the art results even on long documents. So this is a super valuable technique and not remotely magical. So that's it. That's deep learning or at least the kind of the practical pieces from my point of view. Having watched this one time, you won't get it all. And I don't recommend that you do watch this so slowly that you get it all the first time, but that you go back and look at it again, take your time, and there will be bits that you go like, oh, now I see what he's saying. And then you'll be able to implement things you couldn't implement before and you'll be able to dig in more than you thought. So definitely go back and do it again. And as you do, write code, not just for yourself, but put it on GitHub. It doesn't matter if you think it's great code or not. The fact that you're writing code and sharing it is impressive. And the feedback you'll get if you tell people on the forum, hey, I wrote this code. It's not great, but it's my first effort. Anything you see, jump out at you. People will say, oh, that bit was done well. Hey, but did you know for this bit you could have used this library and saved you some time? You'll learn a lot by interacting with your peers. As you've noticed, I've started introducing more and more papers. Now, part two will be a lot of papers. And so it's a good time to start reading some of the papers that have been introduced in this section. All the bits that say derivation and theorems and lemmas, you can skip them. I do. They add almost nothing to your understanding of practical deep learning. But the bits that say why are we solving this problem and what are the results and so forth are really interesting. And then try and write English prose. Not English prose that you want to be read by Geoff Hinton and Jan LeCun, but English prose that you want to be read by you as of six months ago. Because there's a lot more people in the audience of you as of six months ago than there is of Geoffrey Hinton and Jan LeCun. That's the person you best understand. You know what they need. Go and get help and help others. Tell us about your success stories. But perhaps the most important one is get together with others. People's learning works much better if you've got that social experience. So start a book club, get involved in meetups, create study groups, and build things. And again, it doesn't have to be amazing. Just build something that you think the world would be a little bit better if that existed. Or you think it would be slightly delightful to your two-year-old to see that thing. Or you just want to show it to your brother the next time they come around to see what you're doing. Whatever. Just finish something. Finish something. And then try and make it a bit better. So for example, something I just saw this afternoon is the Elon Musk tweet generator. So looking at lots of older tweets, creating a language model from Elon Musk, and then creating new tweets such as humanity will also have an option to publish on its own journey as an alien civilization. It will always, like all human beings, Mars is no longer possible. AI will definitely be the central intelligence agency. So this is great. I love this. And I love that Dave Smith wrote and said, these are my first ever commits. Thanks for teaching a finance guy how to build an app in eight weeks. So I think this is awesome. And I think clearly a lot of care and passion has been put into this project. Will it systematically change the future direction of society as a whole? Maybe not. But maybe Elon will look at this and think, oh, maybe I need to rethink my method of prose. I don't know. I think it's great. And so yeah, create something. Put it out there. Put a bit of yourself into it. Or get involved in Fast AI. The Fast AI project, there's a lot going on. You can help with documentation and tests, which might sound boring. But you'd be surprised how incredibly not boring it is to take a piece of code that hasn't been properly documented and research it and understand it and ask Sylvia and I on the forum what's going on. Why did you write it this way? We'll send you off to the papers that we were implementing. Writing a test requires deeply understanding that part of the machine learning world to really understand how it's meant to work. So that's always interesting. Stas Beckman has created this nice dev projects index, which you can go onto the forum in the Fast AI dev section and find, actually the dev project section, and find here's some stuff going on that you might want to get involved in. Or maybe there's stuff you want to exist. You could add your own. Create a study group. You know, Dean has already created a study group for San Francisco starting in January. This is how easy it is to create a study group. Go on the forum, find your little time zone subcategory, and add a post saying, let's create a study group. But make sure you give people a little Google sheet to sign up, some way to actually do something. A great example is Pierre, who's been doing a fantastic job in Brazil of running study groups for the last couple of parts of the course. And he keeps posting these pictures of people having a good time and learning deep learning together, creating wikis together, creating projects together. Great experience. And then come back for part two, right, where we'll be looking at all of this interesting stuff. In particular, going deep into the Fast AI code base to understand how did we build it exactly. We'll actually go through, as we were building it, we created notebooks of like here is where we were at each stage. So we're actually going to see the software development process itself. We'll talk about the process of doing research, how to read academic papers, how to turn math into code, and then a whole bunch of additional types of models that we haven't seen yet. So it'll be kind of like going beyond practical deep learning into actually cutting edge research. So we've got five minutes to take some questions. We had an AMA going on online. And so we're going to have time for a couple of the highest ranked AMA questions from the community. The first one is by Jeremy's request, although it's not the highest ranked. What's your typical day like? How do you manage your time across so many things that you do? Yeah, I thought that I hear that all the time. So I thought I should answer it. And I think I got a few votes. Because I think people who come to our study group are always shocked at how disorganized and incompetent I am. And so I often hear people saying, oh, wow, I thought you were like this deep learning role model. And I'd get to see how to be like you. And now I'm not sure I want to be like you at all. So yeah, for me, it's all about just having a good time with it. I never really have many plans. I just try to finish what I start. If you're not having fun with it, it's really, really hard to continue. Because there's a lot of frustration in deep learning. Because it's not like writing a web app, where it's like, authentication, check. Backend service watchdog, check. OK. User credentials, check. You're making progress. Where else? For stuff like this, and stuff that we've been doing the last couple of weeks, it's just like, it's not working. It's not working. It's not working. No, that also didn't work. Oh, that also didn't work until, oh, my god, it's amazing. It's a cat. That's kind of what it is. So you don't get that regular feedback. So yeah, you've got to have fun with it. And so my day is kind of, you know, I mean, the other thing I'll say, I don't do any meetings. I don't do phone calls. I don't do coffees. I don't watch TV. I don't play computer games. I spend a lot of time with my family, a lot of time exercising, and a lot of time reading and coding and doing things I like. So I think the main thing is just finish something. Finish something. Like, properly finish it. So when you get to that point where you think you're 80% of the way through, but you haven't quite created a readme yet, and the install process is still a bit clunky, and you know, this is what 99% of GitHub projects look like. You'll see the readme says, to do, you know, complete baseline experiments, document, blah, blah, blah. It's like, don't be that person. Just do something properly and finish it, and maybe get some other people around you to work with you so that you're all doing it together and get it done. What are the up and coming deep learning, machine learning things that you are most excited about? Also, you've mentioned last year that you are not a believer in reinforcement learning. Do you still feel the same way? I still feel exactly the same way as I did three years ago when we started this, which is it's all about transfer learning. It's underappreciated. It's under-researched. Every time we put transfer learning into anything, we make it much better. You know, our academic paper on transfer learning for NLP has, you know, helped be one piece of kind of changing the direction of NLP this year. It made it all the way to the New York Times. Just a stupid, obvious little thing that we threw together. So I remain excited about that. I remain unexcited about reinforcement learning for most things. I don't see it used by normal people for normal things for nearly anything. It's an incredibly inefficient way to solve problems which are often solved more simply and more quickly in other ways. It probably has maybe a role in the world, but a limited one and not in most people's day-to-day work. For someone planning to take part two in 2019, what would you recommend doing learning practicing until the part two course starts? Just code. Yeah, just code all the time. I know it's perfectly possible. I hear from people who get to this point of the course and they haven't actually written any code yet. And if that's you, it's okay. You know, you just go through and do it again and this time do code. And look at the input, the shapes of your inputs and look at your outputs and make sure you know how to grab a mini-batch and look at its mean and standard deviation and plot it and, you know, there's so much material that we've covered. If you can get to a point where you can, you know, rebuild those notebooks from scratch without too much cheating. When I say from scratch, I mean using the Fast AI library, not from scratch from scratch, you know, you'll be in the top echelon of practitioners because you'll be able to do all of these things yourself and that's really, really rare. And that'll put you in a great position for part two. Should we do one more? Nine o'clock, yeah, let's do one more. Where do you see the Fast AI library going in the future, say in five years? Well, like I said, I don't make plans. I just piss around. So I mean our only plan for Fast AI, you know, as an organization is to make deep learning accessible as a tool for normal people to use for normal stuff. So as long as we need to code, we failed at that. So the big goal, you know, because 99.8% of the world can't code. So the main goal would be to get to a point where it's not a library but it's a piece of software that doesn't require code. It certainly shouldn't require a goddamn lengthy, hardworking course like this one, you know. So I want to get rid of the course, I want to get rid of the code, I want to make it so you can just do useful stuff quickly and easily. So that's maybe five years, yeah, maybe longer. All right. Well, I hope to see you all back here for part two. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.8, "text": " Welcome to lesson 7, the last lesson of part 1.", "tokens": [4027, 281, 6898, 1614, 11, 264, 1036, 6898, 295, 644, 502, 13], "temperature": 0.0, "avg_logprob": -0.12314162143441133, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.00590866431593895}, {"id": 1, "seek": 0, "start": 8.8, "end": 13.48, "text": " This will be a pretty intense lesson.", "tokens": [639, 486, 312, 257, 1238, 9447, 6898, 13], "temperature": 0.0, "avg_logprob": -0.12314162143441133, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.00590866431593895}, {"id": 2, "seek": 0, "start": 13.48, "end": 18.98, "text": " And so don't let that bother you because partly what I want to do is to kind of give you enough", "tokens": [400, 370, 500, 380, 718, 300, 8677, 291, 570, 17031, 437, 286, 528, 281, 360, 307, 281, 733, 295, 976, 291, 1547], "temperature": 0.0, "avg_logprob": -0.12314162143441133, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.00590866431593895}, {"id": 3, "seek": 0, "start": 18.98, "end": 24.26, "text": " things to think about to keep you busy until part 2.", "tokens": [721, 281, 519, 466, 281, 1066, 291, 5856, 1826, 644, 568, 13], "temperature": 0.0, "avg_logprob": -0.12314162143441133, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.00590866431593895}, {"id": 4, "seek": 0, "start": 24.26, "end": 28.76, "text": " And so in fact some of the things we covered today I'm not going to tell you about some", "tokens": [400, 370, 294, 1186, 512, 295, 264, 721, 321, 5343, 965, 286, 478, 406, 516, 281, 980, 291, 466, 512], "temperature": 0.0, "avg_logprob": -0.12314162143441133, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.00590866431593895}, {"id": 5, "seek": 2876, "start": 28.76, "end": 31.840000000000003, "text": " of the details, I'll just point out a few things where I'll say like okay that we're", "tokens": [295, 264, 4365, 11, 286, 603, 445, 935, 484, 257, 1326, 721, 689, 286, 603, 584, 411, 1392, 300, 321, 434], "temperature": 0.0, "avg_logprob": -0.16227486554314108, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.00018197311146650463}, {"id": 6, "seek": 2876, "start": 31.840000000000003, "end": 34.36, "text": " not talking about yet, that we're not talking about yet.", "tokens": [406, 1417, 466, 1939, 11, 300, 321, 434, 406, 1417, 466, 1939, 13], "temperature": 0.0, "avg_logprob": -0.16227486554314108, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.00018197311146650463}, {"id": 7, "seek": 2876, "start": 34.36, "end": 40.28, "text": " And so then come back in part 2 to get the details on some of these extra pieces.", "tokens": [400, 370, 550, 808, 646, 294, 644, 568, 281, 483, 264, 4365, 322, 512, 295, 613, 2857, 3755, 13], "temperature": 0.0, "avg_logprob": -0.16227486554314108, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.00018197311146650463}, {"id": 8, "seek": 2876, "start": 40.28, "end": 48.52, "text": " So today will be a lot of material, pretty quickly, might require a few viewings to fully", "tokens": [407, 965, 486, 312, 257, 688, 295, 2527, 11, 1238, 2661, 11, 1062, 3651, 257, 1326, 1910, 1109, 281, 4498], "temperature": 0.0, "avg_logprob": -0.16227486554314108, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.00018197311146650463}, {"id": 9, "seek": 2876, "start": 48.52, "end": 50.88, "text": " understand it all, a few experiments and so forth.", "tokens": [1223, 309, 439, 11, 257, 1326, 12050, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.16227486554314108, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.00018197311146650463}, {"id": 10, "seek": 2876, "start": 50.88, "end": 55.480000000000004, "text": " And that's kind of intentional, I'm trying to give you stuff to keep you amused for a", "tokens": [400, 300, 311, 733, 295, 21935, 11, 286, 478, 1382, 281, 976, 291, 1507, 281, 1066, 291, 669, 4717, 337, 257], "temperature": 0.0, "avg_logprob": -0.16227486554314108, "compression_ratio": 1.6917293233082706, "no_speech_prob": 0.00018197311146650463}, {"id": 11, "seek": 5548, "start": 55.48, "end": 59.599999999999994, "text": " couple of months.", "tokens": [1916, 295, 2493, 13], "temperature": 0.0, "avg_logprob": -0.1433914206748785, "compression_ratio": 1.5539906103286385, "no_speech_prob": 0.00010875620500883088}, {"id": 12, "seek": 5548, "start": 59.599999999999994, "end": 67.56, "text": " Wanted to start by showing some cool work done by a couple of students, Reshma and Npatta01,", "tokens": [11773, 292, 281, 722, 538, 4099, 512, 1627, 589, 1096, 538, 257, 1916, 295, 1731, 11, 5015, 22061, 293, 426, 11584, 1328, 10607, 11], "temperature": 0.0, "avg_logprob": -0.1433914206748785, "compression_ratio": 1.5539906103286385, "no_speech_prob": 0.00010875620500883088}, {"id": 13, "seek": 5548, "start": 67.56, "end": 72.14, "text": " who have developed an Android and an iOS app.", "tokens": [567, 362, 4743, 364, 8853, 293, 364, 17430, 724, 13], "temperature": 0.0, "avg_logprob": -0.1433914206748785, "compression_ratio": 1.5539906103286385, "no_speech_prob": 0.00010875620500883088}, {"id": 14, "seek": 5548, "start": 72.14, "end": 77.8, "text": " And so check out Reshma's post on the forum about that because they have a demonstration", "tokens": [400, 370, 1520, 484, 5015, 22061, 311, 2183, 322, 264, 17542, 466, 300, 570, 436, 362, 257, 16520], "temperature": 0.0, "avg_logprob": -0.1433914206748785, "compression_ratio": 1.5539906103286385, "no_speech_prob": 0.00010875620500883088}, {"id": 15, "seek": 5548, "start": 77.8, "end": 83.19999999999999, "text": " of how to create both Android and iOS apps that are actually on the Play Store and on", "tokens": [295, 577, 281, 1884, 1293, 8853, 293, 17430, 7733, 300, 366, 767, 322, 264, 5506, 17242, 293, 322], "temperature": 0.0, "avg_logprob": -0.1433914206748785, "compression_ratio": 1.5539906103286385, "no_speech_prob": 0.00010875620500883088}, {"id": 16, "seek": 8320, "start": 83.2, "end": 85.78, "text": " the Apple App Store.", "tokens": [264, 6373, 3132, 17242, 13], "temperature": 0.0, "avg_logprob": -0.16424909591674805, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0004329717194195837}, {"id": 17, "seek": 8320, "start": 85.78, "end": 87.52000000000001, "text": " So that's pretty cool.", "tokens": [407, 300, 311, 1238, 1627, 13], "temperature": 0.0, "avg_logprob": -0.16424909591674805, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0004329717194195837}, {"id": 18, "seek": 8320, "start": 87.52000000000001, "end": 92.16, "text": " First ones I know of that are on the App Store that are using Fast AI.", "tokens": [2386, 2306, 286, 458, 295, 300, 366, 322, 264, 3132, 17242, 300, 366, 1228, 15968, 7318, 13], "temperature": 0.0, "avg_logprob": -0.16424909591674805, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0004329717194195837}, {"id": 19, "seek": 8320, "start": 92.16, "end": 96.2, "text": " Let me also say a huge thank you to Reshma for all of the work she does both for the", "tokens": [961, 385, 611, 584, 257, 2603, 1309, 291, 281, 5015, 22061, 337, 439, 295, 264, 589, 750, 775, 1293, 337, 264], "temperature": 0.0, "avg_logprob": -0.16424909591674805, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0004329717194195837}, {"id": 20, "seek": 8320, "start": 96.2, "end": 101.04, "text": " Fast AI community and the machine learning community more generally and also the women", "tokens": [15968, 7318, 1768, 293, 264, 3479, 2539, 1768, 544, 5101, 293, 611, 264, 2266], "temperature": 0.0, "avg_logprob": -0.16424909591674805, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0004329717194195837}, {"id": 21, "seek": 8320, "start": 101.04, "end": 103.60000000000001, "text": " in the machine learning community in particular.", "tokens": [294, 264, 3479, 2539, 1768, 294, 1729, 13], "temperature": 0.0, "avg_logprob": -0.16424909591674805, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0004329717194195837}, {"id": 22, "seek": 8320, "start": 103.60000000000001, "end": 109.48, "text": " She does a lot of fantastic work including providing lots of fantastic documentation", "tokens": [1240, 775, 257, 688, 295, 5456, 589, 3009, 6530, 3195, 295, 5456, 14333], "temperature": 0.0, "avg_logprob": -0.16424909591674805, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0004329717194195837}, {"id": 23, "seek": 10948, "start": 109.48, "end": 113.36, "text": " and tutorials and community organising and so many other things.", "tokens": [293, 17616, 293, 1768, 1798, 3436, 293, 370, 867, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.1728907455632716, "compression_ratio": 1.5792349726775956, "no_speech_prob": 1.3628970918944106e-05}, {"id": 24, "seek": 10948, "start": 113.36, "end": 124.24000000000001, "text": " So thank you Reshma and congrats on getting this app out there.", "tokens": [407, 1309, 291, 5015, 22061, 293, 8882, 1720, 322, 1242, 341, 724, 484, 456, 13], "temperature": 0.0, "avg_logprob": -0.1728907455632716, "compression_ratio": 1.5792349726775956, "no_speech_prob": 1.3628970918944106e-05}, {"id": 25, "seek": 10948, "start": 124.24000000000001, "end": 128.4, "text": " We have lots of Lesson 7 notebooks today as you see.", "tokens": [492, 362, 3195, 295, 18649, 266, 1614, 43782, 965, 382, 291, 536, 13], "temperature": 0.0, "avg_logprob": -0.1728907455632716, "compression_ratio": 1.5792349726775956, "no_speech_prob": 1.3628970918944106e-05}, {"id": 26, "seek": 10948, "start": 128.4, "end": 133.76, "text": " We're going to start with the one...", "tokens": [492, 434, 516, 281, 722, 365, 264, 472, 485], "temperature": 0.0, "avg_logprob": -0.1728907455632716, "compression_ratio": 1.5792349726775956, "no_speech_prob": 1.3628970918944106e-05}, {"id": 27, "seek": 10948, "start": 133.76, "end": 138.52, "text": " So the first notebook we're going to look at is Lesson 7 ResNet MNIST.", "tokens": [407, 264, 700, 21060, 321, 434, 516, 281, 574, 412, 307, 18649, 266, 1614, 5015, 31890, 376, 45, 19756, 13], "temperature": 0.0, "avg_logprob": -0.1728907455632716, "compression_ratio": 1.5792349726775956, "no_speech_prob": 1.3628970918944106e-05}, {"id": 28, "seek": 13852, "start": 138.52, "end": 143.60000000000002, "text": " And what I want to do is look at some of the stuff we started talking about last week around", "tokens": [400, 437, 286, 528, 281, 360, 307, 574, 412, 512, 295, 264, 1507, 321, 1409, 1417, 466, 1036, 1243, 926], "temperature": 0.0, "avg_logprob": -0.08105334733661852, "compression_ratio": 1.6311475409836065, "no_speech_prob": 1.4056516192795243e-05}, {"id": 29, "seek": 13852, "start": 143.60000000000002, "end": 148.64000000000001, "text": " convolutions and convolutional neural networks and start building on top of them to create", "tokens": [3754, 15892, 293, 45216, 304, 18161, 9590, 293, 722, 2390, 322, 1192, 295, 552, 281, 1884], "temperature": 0.0, "avg_logprob": -0.08105334733661852, "compression_ratio": 1.6311475409836065, "no_speech_prob": 1.4056516192795243e-05}, {"id": 30, "seek": 13852, "start": 148.64000000000001, "end": 154.04000000000002, "text": " a fairly modern deep learning architecture largely from scratch.", "tokens": [257, 6457, 4363, 2452, 2539, 9482, 11611, 490, 8459, 13], "temperature": 0.0, "avg_logprob": -0.08105334733661852, "compression_ratio": 1.6311475409836065, "no_speech_prob": 1.4056516192795243e-05}, {"id": 31, "seek": 13852, "start": 154.04000000000002, "end": 157.8, "text": " When I say from scratch I'm not going to re-implement things we already know how to implement but", "tokens": [1133, 286, 584, 490, 8459, 286, 478, 406, 516, 281, 319, 12, 332, 43704, 721, 321, 1217, 458, 577, 281, 4445, 457], "temperature": 0.0, "avg_logprob": -0.08105334733661852, "compression_ratio": 1.6311475409836065, "no_speech_prob": 1.4056516192795243e-05}, {"id": 32, "seek": 13852, "start": 157.8, "end": 162.68, "text": " kind of use the pre-existing PyTorch bits of those.", "tokens": [733, 295, 764, 264, 659, 12, 36447, 9953, 51, 284, 339, 9239, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.08105334733661852, "compression_ratio": 1.6311475409836065, "no_speech_prob": 1.4056516192795243e-05}, {"id": 33, "seek": 16268, "start": 162.68, "end": 169.92000000000002, "text": " So we're going to use the MNIST dataset which... so urls.mnist has the whole MNIST dataset.", "tokens": [407, 321, 434, 516, 281, 764, 264, 376, 45, 19756, 28872, 597, 485, 370, 4038, 11784, 13, 76, 77, 468, 575, 264, 1379, 376, 45, 19756, 28872, 13], "temperature": 0.0, "avg_logprob": -0.14335558225782655, "compression_ratio": 1.8222222222222222, "no_speech_prob": 5.3000763728050515e-05}, {"id": 34, "seek": 16268, "start": 169.92000000000002, "end": 172.56, "text": " Often we've done stuff with a subset of it.", "tokens": [20043, 321, 600, 1096, 1507, 365, 257, 25993, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.14335558225782655, "compression_ratio": 1.8222222222222222, "no_speech_prob": 5.3000763728050515e-05}, {"id": 35, "seek": 16268, "start": 172.56, "end": 177.48000000000002, "text": " So in there there's a training folder and a testing folder.", "tokens": [407, 294, 456, 456, 311, 257, 3097, 10820, 293, 257, 4997, 10820, 13], "temperature": 0.0, "avg_logprob": -0.14335558225782655, "compression_ratio": 1.8222222222222222, "no_speech_prob": 5.3000763728050515e-05}, {"id": 36, "seek": 16268, "start": 177.48000000000002, "end": 182.04000000000002, "text": " And as I read this in I'm going to show some more details about pieces of the data blocks", "tokens": [400, 382, 286, 1401, 341, 294, 286, 478, 516, 281, 855, 512, 544, 4365, 466, 3755, 295, 264, 1412, 8474], "temperature": 0.0, "avg_logprob": -0.14335558225782655, "compression_ratio": 1.8222222222222222, "no_speech_prob": 5.3000763728050515e-05}, {"id": 37, "seek": 16268, "start": 182.04000000000002, "end": 185.56, "text": " API so that you see how to kind of see what's going on.", "tokens": [9362, 370, 300, 291, 536, 577, 281, 733, 295, 536, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.14335558225782655, "compression_ratio": 1.8222222222222222, "no_speech_prob": 5.3000763728050515e-05}, {"id": 38, "seek": 16268, "start": 185.56, "end": 189.52, "text": " Normally with the data blocks API we've kind of said blah dot blah dot blah dot blah and", "tokens": [17424, 365, 264, 1412, 8474, 9362, 321, 600, 733, 295, 848, 12288, 5893, 12288, 5893, 12288, 5893, 12288, 293], "temperature": 0.0, "avg_logprob": -0.14335558225782655, "compression_ratio": 1.8222222222222222, "no_speech_prob": 5.3000763728050515e-05}, {"id": 39, "seek": 16268, "start": 189.52, "end": 192.36, "text": " done it all in one cell but let's do them one cell at a time.", "tokens": [1096, 309, 439, 294, 472, 2815, 457, 718, 311, 360, 552, 472, 2815, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.14335558225782655, "compression_ratio": 1.8222222222222222, "no_speech_prob": 5.3000763728050515e-05}, {"id": 40, "seek": 19236, "start": 192.36, "end": 196.68, "text": " So first thing you say is what kind of item list do you have?", "tokens": [407, 700, 551, 291, 584, 307, 437, 733, 295, 3174, 1329, 360, 291, 362, 30], "temperature": 0.0, "avg_logprob": -0.13300418853759766, "compression_ratio": 1.671875, "no_speech_prob": 3.3703592634992674e-05}, {"id": 41, "seek": 19236, "start": 196.68, "end": 199.72000000000003, "text": " So in this case it's an item list of images.", "tokens": [407, 294, 341, 1389, 309, 311, 364, 3174, 1329, 295, 5267, 13], "temperature": 0.0, "avg_logprob": -0.13300418853759766, "compression_ratio": 1.671875, "no_speech_prob": 3.3703592634992674e-05}, {"id": 42, "seek": 19236, "start": 199.72000000000003, "end": 202.60000000000002, "text": " And then where are you getting the list of file names from?", "tokens": [400, 550, 689, 366, 291, 1242, 264, 1329, 295, 3991, 5288, 490, 30], "temperature": 0.0, "avg_logprob": -0.13300418853759766, "compression_ratio": 1.671875, "no_speech_prob": 3.3703592634992674e-05}, {"id": 43, "seek": 19236, "start": 202.60000000000002, "end": 208.92000000000002, "text": " In this case by looking in a folder recursively and that's where it's coming from.", "tokens": [682, 341, 1389, 538, 1237, 294, 257, 10820, 20560, 3413, 293, 300, 311, 689, 309, 311, 1348, 490, 13], "temperature": 0.0, "avg_logprob": -0.13300418853759766, "compression_ratio": 1.671875, "no_speech_prob": 3.3703592634992674e-05}, {"id": 44, "seek": 19236, "start": 208.92000000000002, "end": 213.12, "text": " You can pass in arguments that end up going to PILO because PILO or P-I-L is the thing", "tokens": [509, 393, 1320, 294, 12869, 300, 917, 493, 516, 281, 430, 4620, 46, 570, 430, 4620, 46, 420, 430, 12, 40, 12, 43, 307, 264, 551], "temperature": 0.0, "avg_logprob": -0.13300418853759766, "compression_ratio": 1.671875, "no_speech_prob": 3.3703592634992674e-05}, {"id": 45, "seek": 19236, "start": 213.12, "end": 218.20000000000002, "text": " that actually opens that for us and in this case these are black and white rather than", "tokens": [300, 767, 9870, 300, 337, 505, 293, 294, 341, 1389, 613, 366, 2211, 293, 2418, 2831, 813], "temperature": 0.0, "avg_logprob": -0.13300418853759766, "compression_ratio": 1.671875, "no_speech_prob": 3.3703592634992674e-05}, {"id": 46, "seek": 19236, "start": 218.20000000000002, "end": 219.52, "text": " RGB.", "tokens": [31231, 13], "temperature": 0.0, "avg_logprob": -0.13300418853759766, "compression_ratio": 1.671875, "no_speech_prob": 3.3703592634992674e-05}, {"id": 47, "seek": 21952, "start": 219.52, "end": 225.38000000000002, "text": " So you have to use PILO's convert mode equals L for more details refer to the Python imaging", "tokens": [407, 291, 362, 281, 764, 430, 4620, 46, 311, 7620, 4391, 6915, 441, 337, 544, 4365, 2864, 281, 264, 15329, 25036], "temperature": 0.0, "avg_logprob": -0.1201614538828532, "compression_ratio": 1.7786561264822134, "no_speech_prob": 5.862311809323728e-06}, {"id": 48, "seek": 21952, "start": 225.38000000000002, "end": 229.08, "text": " library documentation to see what their convert modes are.", "tokens": [6405, 14333, 281, 536, 437, 641, 7620, 14068, 366, 13], "temperature": 0.0, "avg_logprob": -0.1201614538828532, "compression_ratio": 1.7786561264822134, "no_speech_prob": 5.862311809323728e-06}, {"id": 49, "seek": 21952, "start": 229.08, "end": 234.88, "text": " But this one is going to be grayscale which is what MNIST is.", "tokens": [583, 341, 472, 307, 516, 281, 312, 677, 3772, 37088, 597, 307, 437, 376, 45, 19756, 307, 13], "temperature": 0.0, "avg_logprob": -0.1201614538828532, "compression_ratio": 1.7786561264822134, "no_speech_prob": 5.862311809323728e-06}, {"id": 50, "seek": 21952, "start": 234.88, "end": 241.68, "text": " So inside an item list is an items attribute and the items attribute is kind of the thing", "tokens": [407, 1854, 364, 3174, 1329, 307, 364, 4754, 19667, 293, 264, 4754, 19667, 307, 733, 295, 264, 551], "temperature": 0.0, "avg_logprob": -0.1201614538828532, "compression_ratio": 1.7786561264822134, "no_speech_prob": 5.862311809323728e-06}, {"id": 51, "seek": 21952, "start": 241.68, "end": 242.68, "text": " that you gave it.", "tokens": [300, 291, 2729, 309, 13], "temperature": 0.0, "avg_logprob": -0.1201614538828532, "compression_ratio": 1.7786561264822134, "no_speech_prob": 5.862311809323728e-06}, {"id": 52, "seek": 21952, "start": 242.68, "end": 245.52, "text": " It's the thing that it's going to use to create your item.", "tokens": [467, 311, 264, 551, 300, 309, 311, 516, 281, 764, 281, 1884, 428, 3174, 13], "temperature": 0.0, "avg_logprob": -0.1201614538828532, "compression_ratio": 1.7786561264822134, "no_speech_prob": 5.862311809323728e-06}, {"id": 53, "seek": 21952, "start": 245.52, "end": 248.4, "text": " So in this case the thing you gave it really is a list of file names.", "tokens": [407, 294, 341, 1389, 264, 551, 291, 2729, 309, 534, 307, 257, 1329, 295, 3991, 5288, 13], "temperature": 0.0, "avg_logprob": -0.1201614538828532, "compression_ratio": 1.7786561264822134, "no_speech_prob": 5.862311809323728e-06}, {"id": 54, "seek": 24840, "start": 248.4, "end": 253.64000000000001, "text": " That's what it got from the folder.", "tokens": [663, 311, 437, 309, 658, 490, 264, 10820, 13], "temperature": 0.0, "avg_logprob": -0.14453565809461805, "compression_ratio": 1.6067961165048543, "no_speech_prob": 2.012489494518377e-05}, {"id": 55, "seek": 24840, "start": 253.64000000000001, "end": 259.04, "text": " When you show images normally it shows them in RGB and so in this case we want to use", "tokens": [1133, 291, 855, 5267, 5646, 309, 3110, 552, 294, 31231, 293, 370, 294, 341, 1389, 321, 528, 281, 764], "temperature": 0.0, "avg_logprob": -0.14453565809461805, "compression_ratio": 1.6067961165048543, "no_speech_prob": 2.012489494518377e-05}, {"id": 56, "seek": 24840, "start": 259.04, "end": 260.4, "text": " a binary color map.", "tokens": [257, 17434, 2017, 4471, 13], "temperature": 0.0, "avg_logprob": -0.14453565809461805, "compression_ratio": 1.6067961165048543, "no_speech_prob": 2.012489494518377e-05}, {"id": 57, "seek": 24840, "start": 260.4, "end": 263.26, "text": " So in Fast.ai you can set a default color map.", "tokens": [407, 294, 15968, 13, 1301, 291, 393, 992, 257, 7576, 2017, 4471, 13], "temperature": 0.0, "avg_logprob": -0.14453565809461805, "compression_ratio": 1.6067961165048543, "no_speech_prob": 2.012489494518377e-05}, {"id": 58, "seek": 24840, "start": 263.26, "end": 268.28000000000003, "text": " For more information about CMAP and color maps refer to the map plot lib documentation", "tokens": [1171, 544, 1589, 466, 20424, 4715, 293, 2017, 11317, 2864, 281, 264, 4471, 7542, 22854, 14333], "temperature": 0.0, "avg_logprob": -0.14453565809461805, "compression_ratio": 1.6067961165048543, "no_speech_prob": 2.012489494518377e-05}, {"id": 59, "seek": 24840, "start": 268.28000000000003, "end": 273.32, "text": " and so this will set the default color map for Fast.ai.", "tokens": [293, 370, 341, 486, 992, 264, 7576, 2017, 4471, 337, 15968, 13, 1301, 13], "temperature": 0.0, "avg_logprob": -0.14453565809461805, "compression_ratio": 1.6067961165048543, "no_speech_prob": 2.012489494518377e-05}, {"id": 60, "seek": 27332, "start": 273.32, "end": 279.36, "text": " So our image item list contains 70,000 items and it's a bunch of images that are 1 by 28", "tokens": [407, 527, 3256, 3174, 1329, 8306, 5285, 11, 1360, 4754, 293, 309, 311, 257, 3840, 295, 5267, 300, 366, 502, 538, 7562], "temperature": 0.0, "avg_logprob": -0.16115405108477618, "compression_ratio": 1.623931623931624, "no_speech_prob": 1.4282800293585751e-05}, {"id": 61, "seek": 27332, "start": 279.36, "end": 280.36, "text": " by 28.", "tokens": [538, 7562, 13], "temperature": 0.0, "avg_logprob": -0.16115405108477618, "compression_ratio": 1.623931623931624, "no_speech_prob": 1.4282800293585751e-05}, {"id": 62, "seek": 27332, "start": 280.36, "end": 285.21999999999997, "text": " Remember that PyTorch puts channel first so they're one channel 28 by 28.", "tokens": [5459, 300, 9953, 51, 284, 339, 8137, 2269, 700, 370, 436, 434, 472, 2269, 7562, 538, 7562, 13], "temperature": 0.0, "avg_logprob": -0.16115405108477618, "compression_ratio": 1.623931623931624, "no_speech_prob": 1.4282800293585751e-05}, {"id": 63, "seek": 27332, "start": 285.21999999999997, "end": 292.0, "text": " You might think why aren't they just 28 by 28 matrices rather than a 1 by 28 by 28 rank", "tokens": [509, 1062, 519, 983, 3212, 380, 436, 445, 7562, 538, 7562, 32284, 2831, 813, 257, 502, 538, 7562, 538, 7562, 6181], "temperature": 0.0, "avg_logprob": -0.16115405108477618, "compression_ratio": 1.623931623931624, "no_speech_prob": 1.4282800293585751e-05}, {"id": 64, "seek": 27332, "start": 292.0, "end": 293.44, "text": " 3 tensor.", "tokens": [805, 40863, 13], "temperature": 0.0, "avg_logprob": -0.16115405108477618, "compression_ratio": 1.623931623931624, "no_speech_prob": 1.4282800293585751e-05}, {"id": 65, "seek": 27332, "start": 293.44, "end": 294.84, "text": " It's just easier that way.", "tokens": [467, 311, 445, 3571, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.16115405108477618, "compression_ratio": 1.623931623931624, "no_speech_prob": 1.4282800293585751e-05}, {"id": 66, "seek": 27332, "start": 294.84, "end": 302.68, "text": " All the conv2d stuff and so forth works on rank 3 tensors so you want to include that", "tokens": [1057, 264, 3754, 17, 67, 1507, 293, 370, 5220, 1985, 322, 6181, 805, 10688, 830, 370, 291, 528, 281, 4090, 300], "temperature": 0.0, "avg_logprob": -0.16115405108477618, "compression_ratio": 1.623931623931624, "no_speech_prob": 1.4282800293585751e-05}, {"id": 67, "seek": 30268, "start": 302.68, "end": 307.84000000000003, "text": " unit axis at the start and so Fast.ai will do that for you even when it's reading one", "tokens": [4985, 10298, 412, 264, 722, 293, 370, 15968, 13, 1301, 486, 360, 300, 337, 291, 754, 562, 309, 311, 3760, 472], "temperature": 0.0, "avg_logprob": -0.14063596725463867, "compression_ratio": 1.7077625570776256, "no_speech_prob": 5.1433758926577866e-05}, {"id": 68, "seek": 30268, "start": 307.84000000000003, "end": 311.12, "text": " channel images.", "tokens": [2269, 5267, 13], "temperature": 0.0, "avg_logprob": -0.14063596725463867, "compression_ratio": 1.7077625570776256, "no_speech_prob": 5.1433758926577866e-05}, {"id": 69, "seek": 30268, "start": 311.12, "end": 316.8, "text": " So the.items attribute contains the thing that's kind of read to build the image which", "tokens": [407, 264, 2411, 270, 9097, 19667, 8306, 264, 551, 300, 311, 733, 295, 1401, 281, 1322, 264, 3256, 597], "temperature": 0.0, "avg_logprob": -0.14063596725463867, "compression_ratio": 1.7077625570776256, "no_speech_prob": 5.1433758926577866e-05}, {"id": 70, "seek": 30268, "start": 316.8, "end": 321.36, "text": " in this case is the file name but if you just index into an item list directly you'll get", "tokens": [294, 341, 1389, 307, 264, 3991, 1315, 457, 498, 291, 445, 8186, 666, 364, 3174, 1329, 3838, 291, 603, 483], "temperature": 0.0, "avg_logprob": -0.14063596725463867, "compression_ratio": 1.7077625570776256, "no_speech_prob": 5.1433758926577866e-05}, {"id": 71, "seek": 30268, "start": 321.36, "end": 323.48, "text": " the actual image object.", "tokens": [264, 3539, 3256, 2657, 13], "temperature": 0.0, "avg_logprob": -0.14063596725463867, "compression_ratio": 1.7077625570776256, "no_speech_prob": 5.1433758926577866e-05}, {"id": 72, "seek": 30268, "start": 323.48, "end": 328.16, "text": " So the actual image object has a show method and so there's the image.", "tokens": [407, 264, 3539, 3256, 2657, 575, 257, 855, 3170, 293, 370, 456, 311, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.14063596725463867, "compression_ratio": 1.7077625570776256, "no_speech_prob": 5.1433758926577866e-05}, {"id": 73, "seek": 32816, "start": 328.16, "end": 333.76000000000005, "text": " So once you've got an image item list you then split it into training versus validation.", "tokens": [407, 1564, 291, 600, 658, 364, 3256, 3174, 1329, 291, 550, 7472, 309, 666, 3097, 5717, 24071, 13], "temperature": 0.0, "avg_logprob": -0.13303941195128394, "compression_ratio": 1.751908396946565, "no_speech_prob": 3.340384637340321e-06}, {"id": 74, "seek": 32816, "start": 333.76000000000005, "end": 335.44, "text": " You nearly always want validation.", "tokens": [509, 6217, 1009, 528, 24071, 13], "temperature": 0.0, "avg_logprob": -0.13303941195128394, "compression_ratio": 1.751908396946565, "no_speech_prob": 3.340384637340321e-06}, {"id": 75, "seek": 32816, "start": 335.44, "end": 341.44000000000005, "text": " If you don't you can actually use the.no split method to create a kind of empty validation", "tokens": [759, 291, 500, 380, 291, 393, 767, 764, 264, 2411, 1771, 7472, 3170, 281, 1884, 257, 733, 295, 6707, 24071], "temperature": 0.0, "avg_logprob": -0.13303941195128394, "compression_ratio": 1.751908396946565, "no_speech_prob": 3.340384637340321e-06}, {"id": 76, "seek": 32816, "start": 341.44000000000005, "end": 342.84000000000003, "text": " set.", "tokens": [992, 13], "temperature": 0.0, "avg_logprob": -0.13303941195128394, "compression_ratio": 1.751908396946565, "no_speech_prob": 3.340384637340321e-06}, {"id": 77, "seek": 32816, "start": 342.84000000000003, "end": 344.6, "text": " You can't skip it entirely.", "tokens": [509, 393, 380, 10023, 309, 7696, 13], "temperature": 0.0, "avg_logprob": -0.13303941195128394, "compression_ratio": 1.751908396946565, "no_speech_prob": 3.340384637340321e-06}, {"id": 78, "seek": 32816, "start": 344.6, "end": 348.92, "text": " You have to say how to split and one of the options is no split.", "tokens": [509, 362, 281, 584, 577, 281, 7472, 293, 472, 295, 264, 3956, 307, 572, 7472, 13], "temperature": 0.0, "avg_logprob": -0.13303941195128394, "compression_ratio": 1.751908396946565, "no_speech_prob": 3.340384637340321e-06}, {"id": 79, "seek": 32816, "start": 348.92, "end": 350.44000000000005, "text": " And so remember that's always the order.", "tokens": [400, 370, 1604, 300, 311, 1009, 264, 1668, 13], "temperature": 0.0, "avg_logprob": -0.13303941195128394, "compression_ratio": 1.751908396946565, "no_speech_prob": 3.340384637340321e-06}, {"id": 80, "seek": 32816, "start": 350.44000000000005, "end": 353.44000000000005, "text": " First create your item list then decide how to split.", "tokens": [2386, 1884, 428, 3174, 1329, 550, 4536, 577, 281, 7472, 13], "temperature": 0.0, "avg_logprob": -0.13303941195128394, "compression_ratio": 1.751908396946565, "no_speech_prob": 3.340384637340321e-06}, {"id": 81, "seek": 32816, "start": 353.44000000000005, "end": 358.0, "text": " In this case we're going to do it based on folders.", "tokens": [682, 341, 1389, 321, 434, 516, 281, 360, 309, 2361, 322, 31082, 13], "temperature": 0.0, "avg_logprob": -0.13303941195128394, "compression_ratio": 1.751908396946565, "no_speech_prob": 3.340384637340321e-06}, {"id": 82, "seek": 35800, "start": 358.0, "end": 364.52, "text": " In this case the validation folder for MNIST is called testing.", "tokens": [682, 341, 1389, 264, 24071, 10820, 337, 376, 45, 19756, 307, 1219, 4997, 13], "temperature": 0.0, "avg_logprob": -0.0866663327781103, "compression_ratio": 1.723809523809524, "no_speech_prob": 1.5197811080724932e-05}, {"id": 83, "seek": 35800, "start": 364.52, "end": 368.84, "text": " So in kind of Fast.ai parlance we use the same kind of parlance that Kaggle does which", "tokens": [407, 294, 733, 295, 15968, 13, 1301, 13734, 719, 321, 764, 264, 912, 733, 295, 13734, 719, 300, 48751, 22631, 775, 597], "temperature": 0.0, "avg_logprob": -0.0866663327781103, "compression_ratio": 1.723809523809524, "no_speech_prob": 1.5197811080724932e-05}, {"id": 84, "seek": 35800, "start": 368.84, "end": 371.68, "text": " is the training set is what you train on.", "tokens": [307, 264, 3097, 992, 307, 437, 291, 3847, 322, 13], "temperature": 0.0, "avg_logprob": -0.0866663327781103, "compression_ratio": 1.723809523809524, "no_speech_prob": 1.5197811080724932e-05}, {"id": 85, "seek": 35800, "start": 371.68, "end": 376.44, "text": " The validation set has labels and you do it for testing that your model's working.", "tokens": [440, 24071, 992, 575, 16949, 293, 291, 360, 309, 337, 4997, 300, 428, 2316, 311, 1364, 13], "temperature": 0.0, "avg_logprob": -0.0866663327781103, "compression_ratio": 1.723809523809524, "no_speech_prob": 1.5197811080724932e-05}, {"id": 86, "seek": 35800, "start": 376.44, "end": 382.76, "text": " The test set doesn't have labels and you use it for doing inference or submitting to a", "tokens": [440, 1500, 992, 1177, 380, 362, 16949, 293, 291, 764, 309, 337, 884, 38253, 420, 31836, 281, 257], "temperature": 0.0, "avg_logprob": -0.0866663327781103, "compression_ratio": 1.723809523809524, "no_speech_prob": 1.5197811080724932e-05}, {"id": 87, "seek": 38276, "start": 382.76, "end": 388.56, "text": " competition or sending it off to somebody who's held out those labels for vendor testing", "tokens": [6211, 420, 7750, 309, 766, 281, 2618, 567, 311, 5167, 484, 729, 16949, 337, 24321, 4997], "temperature": 0.0, "avg_logprob": -0.08513602140907929, "compression_ratio": 1.6945606694560669, "no_speech_prob": 5.337177753972355e-06}, {"id": 88, "seek": 38276, "start": 388.56, "end": 389.88, "text": " or whatever.", "tokens": [420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.08513602140907929, "compression_ratio": 1.6945606694560669, "no_speech_prob": 5.337177753972355e-06}, {"id": 89, "seek": 38276, "start": 389.88, "end": 394.12, "text": " So just because a folder in your data set is called testing doesn't mean it's a test", "tokens": [407, 445, 570, 257, 10820, 294, 428, 1412, 992, 307, 1219, 4997, 1177, 380, 914, 309, 311, 257, 1500], "temperature": 0.0, "avg_logprob": -0.08513602140907929, "compression_ratio": 1.6945606694560669, "no_speech_prob": 5.337177753972355e-06}, {"id": 90, "seek": 38276, "start": 394.12, "end": 395.12, "text": " set.", "tokens": [992, 13], "temperature": 0.0, "avg_logprob": -0.08513602140907929, "compression_ratio": 1.6945606694560669, "no_speech_prob": 5.337177753972355e-06}, {"id": 91, "seek": 38276, "start": 395.12, "end": 399.52, "text": " This one has labels so it's a validation set.", "tokens": [639, 472, 575, 16949, 370, 309, 311, 257, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.08513602140907929, "compression_ratio": 1.6945606694560669, "no_speech_prob": 5.337177753972355e-06}, {"id": 92, "seek": 38276, "start": 399.52, "end": 403.71999999999997, "text": " So if you want to do inference on lots of things at a time rather than one thing at", "tokens": [407, 498, 291, 528, 281, 360, 38253, 322, 3195, 295, 721, 412, 257, 565, 2831, 813, 472, 551, 412], "temperature": 0.0, "avg_logprob": -0.08513602140907929, "compression_ratio": 1.6945606694560669, "no_speech_prob": 5.337177753972355e-06}, {"id": 93, "seek": 38276, "start": 403.71999999999997, "end": 410.68, "text": " a time you want to use the test equals in Fast.ai to say this is stuff which has no", "tokens": [257, 565, 291, 528, 281, 764, 264, 1500, 6915, 294, 15968, 13, 1301, 281, 584, 341, 307, 1507, 597, 575, 572], "temperature": 0.0, "avg_logprob": -0.08513602140907929, "compression_ratio": 1.6945606694560669, "no_speech_prob": 5.337177753972355e-06}, {"id": 94, "seek": 41068, "start": 410.68, "end": 415.08, "text": " labels and I'm just using for inference.", "tokens": [16949, 293, 286, 478, 445, 1228, 337, 38253, 13], "temperature": 0.0, "avg_logprob": -0.11532783508300781, "compression_ratio": 1.7732558139534884, "no_speech_prob": 1.9515557141858153e-05}, {"id": 95, "seek": 41068, "start": 415.08, "end": 422.68, "text": " So my split data is a training set and a validation set as you can see.", "tokens": [407, 452, 7472, 1412, 307, 257, 3097, 992, 293, 257, 24071, 992, 382, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.11532783508300781, "compression_ratio": 1.7732558139534884, "no_speech_prob": 1.9515557141858153e-05}, {"id": 96, "seek": 41068, "start": 422.68, "end": 429.12, "text": " So inside the training set there's a folder for each class.", "tokens": [407, 1854, 264, 3097, 992, 456, 311, 257, 10820, 337, 1184, 1508, 13], "temperature": 0.0, "avg_logprob": -0.11532783508300781, "compression_ratio": 1.7732558139534884, "no_speech_prob": 1.9515557141858153e-05}, {"id": 97, "seek": 41068, "start": 429.12, "end": 433.92, "text": " So now we can take that split data and say label from folder.", "tokens": [407, 586, 321, 393, 747, 300, 7472, 1412, 293, 584, 7645, 490, 10820, 13], "temperature": 0.0, "avg_logprob": -0.11532783508300781, "compression_ratio": 1.7732558139534884, "no_speech_prob": 1.9515557141858153e-05}, {"id": 98, "seek": 41068, "start": 433.92, "end": 438.2, "text": " So first you create the item list then you split it then you label it.", "tokens": [407, 700, 291, 1884, 264, 3174, 1329, 550, 291, 7472, 309, 550, 291, 7645, 309, 13], "temperature": 0.0, "avg_logprob": -0.11532783508300781, "compression_ratio": 1.7732558139534884, "no_speech_prob": 1.9515557141858153e-05}, {"id": 99, "seek": 43820, "start": 438.2, "end": 446.09999999999997, "text": " And so you can see now we have an X and a Y and the Y are category objects.", "tokens": [400, 370, 291, 393, 536, 586, 321, 362, 364, 1783, 293, 257, 398, 293, 264, 398, 366, 7719, 6565, 13], "temperature": 0.0, "avg_logprob": -0.1168064574400584, "compression_ratio": 1.763819095477387, "no_speech_prob": 5.421771220426308e-06}, {"id": 100, "seek": 43820, "start": 446.09999999999997, "end": 450.3, "text": " Category object is just a class basically.", "tokens": [383, 48701, 2657, 307, 445, 257, 1508, 1936, 13], "temperature": 0.0, "avg_logprob": -0.1168064574400584, "compression_ratio": 1.763819095477387, "no_speech_prob": 5.421771220426308e-06}, {"id": 101, "seek": 43820, "start": 450.3, "end": 459.68, "text": " So if you index into a label list such as ll.train as a label list you will get back", "tokens": [407, 498, 291, 8186, 666, 257, 7645, 1329, 1270, 382, 4849, 13, 83, 7146, 382, 257, 7645, 1329, 291, 486, 483, 646], "temperature": 0.0, "avg_logprob": -0.1168064574400584, "compression_ratio": 1.763819095477387, "no_speech_prob": 5.421771220426308e-06}, {"id": 102, "seek": 43820, "start": 459.68, "end": 462.56, "text": " an independent variable, independent variable, X and Y.", "tokens": [364, 6695, 7006, 11, 6695, 7006, 11, 1783, 293, 398, 13], "temperature": 0.0, "avg_logprob": -0.1168064574400584, "compression_ratio": 1.763819095477387, "no_speech_prob": 5.421771220426308e-06}, {"id": 103, "seek": 43820, "start": 462.56, "end": 468.0, "text": " So in this case the X will be an image object which I can show and the Y will be a category", "tokens": [407, 294, 341, 1389, 264, 1783, 486, 312, 364, 3256, 2657, 597, 286, 393, 855, 293, 264, 398, 486, 312, 257, 7719], "temperature": 0.0, "avg_logprob": -0.1168064574400584, "compression_ratio": 1.763819095477387, "no_speech_prob": 5.421771220426308e-06}, {"id": 104, "seek": 46800, "start": 468.0, "end": 471.36, "text": " object which I can print.", "tokens": [2657, 597, 286, 393, 4482, 13], "temperature": 0.0, "avg_logprob": -0.1611766264988826, "compression_ratio": 1.832579185520362, "no_speech_prob": 9.971550753107294e-06}, {"id": 105, "seek": 46800, "start": 471.36, "end": 476.92, "text": " That's the number 8 category and there's the 8.", "tokens": [663, 311, 264, 1230, 1649, 7719, 293, 456, 311, 264, 1649, 13], "temperature": 0.0, "avg_logprob": -0.1611766264988826, "compression_ratio": 1.832579185520362, "no_speech_prob": 9.971550753107294e-06}, {"id": 106, "seek": 46800, "start": 476.92, "end": 479.88, "text": " Next thing we can do is to add transforms.", "tokens": [3087, 551, 321, 393, 360, 307, 281, 909, 35592, 13], "temperature": 0.0, "avg_logprob": -0.1611766264988826, "compression_ratio": 1.832579185520362, "no_speech_prob": 9.971550753107294e-06}, {"id": 107, "seek": 46800, "start": 479.88, "end": 485.4, "text": " In this case we're not going to use the normal getTransforms function because we're doing", "tokens": [682, 341, 1389, 321, 434, 406, 516, 281, 764, 264, 2710, 483, 33339, 837, 82, 2445, 570, 321, 434, 884], "temperature": 0.0, "avg_logprob": -0.1611766264988826, "compression_ratio": 1.832579185520362, "no_speech_prob": 9.971550753107294e-06}, {"id": 108, "seek": 46800, "start": 485.4, "end": 489.92, "text": " digit recognition and digit recognition like you wouldn't want to flip it left right that", "tokens": [14293, 11150, 293, 14293, 11150, 411, 291, 2759, 380, 528, 281, 7929, 309, 1411, 558, 300], "temperature": 0.0, "avg_logprob": -0.1611766264988826, "compression_ratio": 1.832579185520362, "no_speech_prob": 9.971550753107294e-06}, {"id": 109, "seek": 46800, "start": 489.92, "end": 491.52, "text": " would change the meaning of it.", "tokens": [576, 1319, 264, 3620, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.1611766264988826, "compression_ratio": 1.832579185520362, "no_speech_prob": 9.971550753107294e-06}, {"id": 110, "seek": 46800, "start": 491.52, "end": 494.84, "text": " You wouldn't want to rotate it too much that would change the meaning of it.", "tokens": [509, 2759, 380, 528, 281, 13121, 309, 886, 709, 300, 576, 1319, 264, 3620, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.1611766264988826, "compression_ratio": 1.832579185520362, "no_speech_prob": 9.971550753107294e-06}, {"id": 111, "seek": 49484, "start": 494.84, "end": 498.28, "text": " Also because these images are so small, kind of doing zooms and stuff is going to make", "tokens": [2743, 570, 613, 5267, 366, 370, 1359, 11, 733, 295, 884, 5721, 4785, 293, 1507, 307, 516, 281, 652], "temperature": 0.0, "avg_logprob": -0.10237479002579399, "compression_ratio": 1.7992125984251968, "no_speech_prob": 4.784738393937005e-06}, {"id": 112, "seek": 49484, "start": 498.28, "end": 500.32, "text": " them so fuzzy as to be unreadable.", "tokens": [552, 370, 34710, 382, 281, 312, 517, 2538, 712, 13], "temperature": 0.0, "avg_logprob": -0.10237479002579399, "compression_ratio": 1.7992125984251968, "no_speech_prob": 4.784738393937005e-06}, {"id": 113, "seek": 49484, "start": 500.32, "end": 505.96, "text": " So normally for small images of digits like this you just add a bit of random padding.", "tokens": [407, 5646, 337, 1359, 5267, 295, 27011, 411, 341, 291, 445, 909, 257, 857, 295, 4974, 39562, 13], "temperature": 0.0, "avg_logprob": -0.10237479002579399, "compression_ratio": 1.7992125984251968, "no_speech_prob": 4.784738393937005e-06}, {"id": 114, "seek": 49484, "start": 505.96, "end": 512.28, "text": " So I'll use the random padding function which actually returns two transforms, the bit that", "tokens": [407, 286, 603, 764, 264, 4974, 39562, 2445, 597, 767, 11247, 732, 35592, 11, 264, 857, 300], "temperature": 0.0, "avg_logprob": -0.10237479002579399, "compression_ratio": 1.7992125984251968, "no_speech_prob": 4.784738393937005e-06}, {"id": 115, "seek": 49484, "start": 512.28, "end": 514.52, "text": " does the padding and the bit that does the random crop.", "tokens": [775, 264, 39562, 293, 264, 857, 300, 775, 264, 4974, 9086, 13], "temperature": 0.0, "avg_logprob": -0.10237479002579399, "compression_ratio": 1.7992125984251968, "no_speech_prob": 4.784738393937005e-06}, {"id": 116, "seek": 49484, "start": 514.52, "end": 519.4399999999999, "text": " So you have to use star to say put both these transforms in this list.", "tokens": [407, 291, 362, 281, 764, 3543, 281, 584, 829, 1293, 613, 35592, 294, 341, 1329, 13], "temperature": 0.0, "avg_logprob": -0.10237479002579399, "compression_ratio": 1.7992125984251968, "no_speech_prob": 4.784738393937005e-06}, {"id": 117, "seek": 49484, "start": 519.4399999999999, "end": 521.9599999999999, "text": " So now we can call transform.", "tokens": [407, 586, 321, 393, 818, 4088, 13], "temperature": 0.0, "avg_logprob": -0.10237479002579399, "compression_ratio": 1.7992125984251968, "no_speech_prob": 4.784738393937005e-06}, {"id": 118, "seek": 52196, "start": 521.96, "end": 525.6, "text": " This empty array here is referring to the validation set transforms.", "tokens": [639, 6707, 10225, 510, 307, 13761, 281, 264, 24071, 992, 35592, 13], "temperature": 0.0, "avg_logprob": -0.15714470906691116, "compression_ratio": 1.603960396039604, "no_speech_prob": 7.181699857028434e-06}, {"id": 119, "seek": 52196, "start": 525.6, "end": 529.32, "text": " So no transforms with the validation set.", "tokens": [407, 572, 35592, 365, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.15714470906691116, "compression_ratio": 1.603960396039604, "no_speech_prob": 7.181699857028434e-06}, {"id": 120, "seek": 52196, "start": 529.32, "end": 533.38, "text": " Now we've got a transformed labelled list.", "tokens": [823, 321, 600, 658, 257, 16894, 2715, 41307, 1329, 13], "temperature": 0.0, "avg_logprob": -0.15714470906691116, "compression_ratio": 1.603960396039604, "no_speech_prob": 7.181699857028434e-06}, {"id": 121, "seek": 52196, "start": 533.38, "end": 537.0600000000001, "text": " We can pick a batch size and choose data bunch.", "tokens": [492, 393, 1888, 257, 15245, 2744, 293, 2826, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.15714470906691116, "compression_ratio": 1.603960396039604, "no_speech_prob": 7.181699857028434e-06}, {"id": 122, "seek": 52196, "start": 537.0600000000001, "end": 539.48, "text": " We can choose normalise.", "tokens": [492, 393, 2826, 2710, 908, 13], "temperature": 0.0, "avg_logprob": -0.15714470906691116, "compression_ratio": 1.603960396039604, "no_speech_prob": 7.181699857028434e-06}, {"id": 123, "seek": 52196, "start": 539.48, "end": 543.76, "text": " In this case we're not using a pre-trained model so there's no reason to use ImageNet", "tokens": [682, 341, 1389, 321, 434, 406, 1228, 257, 659, 12, 17227, 2001, 2316, 370, 456, 311, 572, 1778, 281, 764, 29903, 31890], "temperature": 0.0, "avg_logprob": -0.15714470906691116, "compression_ratio": 1.603960396039604, "no_speech_prob": 7.181699857028434e-06}, {"id": 124, "seek": 52196, "start": 543.76, "end": 546.0, "text": " stats here.", "tokens": [18152, 510, 13], "temperature": 0.0, "avg_logprob": -0.15714470906691116, "compression_ratio": 1.603960396039604, "no_speech_prob": 7.181699857028434e-06}, {"id": 125, "seek": 54600, "start": 546.0, "end": 553.6, "text": " And so if you call normalise like this without passing in stats it will grab a batch of data", "tokens": [400, 370, 498, 291, 818, 2710, 908, 411, 341, 1553, 8437, 294, 18152, 309, 486, 4444, 257, 15245, 295, 1412], "temperature": 0.0, "avg_logprob": -0.15620093510068697, "compression_ratio": 1.598984771573604, "no_speech_prob": 3.3928365610336186e-06}, {"id": 126, "seek": 54600, "start": 553.6, "end": 558.56, "text": " at random and use that to decide what normalisation stats to use.", "tokens": [412, 4974, 293, 764, 300, 281, 4536, 437, 2710, 7623, 18152, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.15620093510068697, "compression_ratio": 1.598984771573604, "no_speech_prob": 3.3928365610336186e-06}, {"id": 127, "seek": 54600, "start": 558.56, "end": 563.92, "text": " That's a good idea if you're not using a pre-trained model.", "tokens": [663, 311, 257, 665, 1558, 498, 291, 434, 406, 1228, 257, 659, 12, 17227, 2001, 2316, 13], "temperature": 0.0, "avg_logprob": -0.15620093510068697, "compression_ratio": 1.598984771573604, "no_speech_prob": 3.3928365610336186e-06}, {"id": 128, "seek": 54600, "start": 563.92, "end": 570.12, "text": " Okay so we've got a data bunch and so in that data bunch is a data set which we've seen", "tokens": [1033, 370, 321, 600, 658, 257, 1412, 3840, 293, 370, 294, 300, 1412, 3840, 307, 257, 1412, 992, 597, 321, 600, 1612], "temperature": 0.0, "avg_logprob": -0.15620093510068697, "compression_ratio": 1.598984771573604, "no_speech_prob": 3.3928365610336186e-06}, {"id": 129, "seek": 54600, "start": 570.12, "end": 573.88, "text": " already.", "tokens": [1217, 13], "temperature": 0.0, "avg_logprob": -0.15620093510068697, "compression_ratio": 1.598984771573604, "no_speech_prob": 3.3928365610336186e-06}, {"id": 130, "seek": 57388, "start": 573.88, "end": 577.56, "text": " What is interesting is that the training data set now has data augmentation because we've", "tokens": [708, 307, 1880, 307, 300, 264, 3097, 1412, 992, 586, 575, 1412, 14501, 19631, 570, 321, 600], "temperature": 0.0, "avg_logprob": -0.10417490005493164, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.1329647501697764e-05}, {"id": 131, "seek": 57388, "start": 577.56, "end": 579.24, "text": " got transforms.", "tokens": [658, 35592, 13], "temperature": 0.0, "avg_logprob": -0.10417490005493164, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.1329647501697764e-05}, {"id": 132, "seek": 57388, "start": 579.24, "end": 585.36, "text": " So plotMulti is a fast AI function that will plot the result of calling some function for", "tokens": [407, 7542, 44, 723, 72, 307, 257, 2370, 7318, 2445, 300, 486, 7542, 264, 1874, 295, 5141, 512, 2445, 337], "temperature": 0.0, "avg_logprob": -0.10417490005493164, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.1329647501697764e-05}, {"id": 133, "seek": 57388, "start": 585.36, "end": 587.96, "text": " each of this row by column grid.", "tokens": [1184, 295, 341, 5386, 538, 7738, 10748, 13], "temperature": 0.0, "avg_logprob": -0.10417490005493164, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.1329647501697764e-05}, {"id": 134, "seek": 57388, "start": 587.96, "end": 593.56, "text": " So in this case my function is just grab the first image from the training set and because", "tokens": [407, 294, 341, 1389, 452, 2445, 307, 445, 4444, 264, 700, 3256, 490, 264, 3097, 992, 293, 570], "temperature": 0.0, "avg_logprob": -0.10417490005493164, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.1329647501697764e-05}, {"id": 135, "seek": 57388, "start": 593.56, "end": 597.96, "text": " each time you grab something from the training set it's going to load it from disk and it's", "tokens": [1184, 565, 291, 4444, 746, 490, 264, 3097, 992, 309, 311, 516, 281, 3677, 309, 490, 12355, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.10417490005493164, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.1329647501697764e-05}, {"id": 136, "seek": 57388, "start": 597.96, "end": 601.36, "text": " going to transform it on the fly.", "tokens": [516, 281, 4088, 309, 322, 264, 3603, 13], "temperature": 0.0, "avg_logprob": -0.10417490005493164, "compression_ratio": 1.8619246861924685, "no_speech_prob": 4.1329647501697764e-05}, {"id": 137, "seek": 60136, "start": 601.36, "end": 607.4, "text": " So people sometimes ask like how many transformed versions of the image do you create and the", "tokens": [407, 561, 2171, 1029, 411, 577, 867, 16894, 9606, 295, 264, 3256, 360, 291, 1884, 293, 264], "temperature": 0.0, "avg_logprob": -0.08370102832191868, "compression_ratio": 1.6791666666666667, "no_speech_prob": 7.409649697365239e-06}, {"id": 138, "seek": 60136, "start": 607.4, "end": 609.52, "text": " answer is kind of infinite.", "tokens": [1867, 307, 733, 295, 13785, 13], "temperature": 0.0, "avg_logprob": -0.08370102832191868, "compression_ratio": 1.6791666666666667, "no_speech_prob": 7.409649697365239e-06}, {"id": 139, "seek": 60136, "start": 609.52, "end": 615.34, "text": " Each time we grab one thing from the data set we do a random transform on the fly.", "tokens": [6947, 565, 321, 4444, 472, 551, 490, 264, 1412, 992, 321, 360, 257, 4974, 4088, 322, 264, 3603, 13], "temperature": 0.0, "avg_logprob": -0.08370102832191868, "compression_ratio": 1.6791666666666667, "no_speech_prob": 7.409649697365239e-06}, {"id": 140, "seek": 60136, "start": 615.34, "end": 619.12, "text": " So potentially everyone will look a little bit different.", "tokens": [407, 7263, 1518, 486, 574, 257, 707, 857, 819, 13], "temperature": 0.0, "avg_logprob": -0.08370102832191868, "compression_ratio": 1.6791666666666667, "no_speech_prob": 7.409649697365239e-06}, {"id": 141, "seek": 60136, "start": 619.12, "end": 624.32, "text": " So you can see here if we plot the result of that lots of times we get eights in slightly", "tokens": [407, 291, 393, 536, 510, 498, 321, 7542, 264, 1874, 295, 300, 3195, 295, 1413, 321, 483, 3180, 82, 294, 4748], "temperature": 0.0, "avg_logprob": -0.08370102832191868, "compression_ratio": 1.6791666666666667, "no_speech_prob": 7.409649697365239e-06}, {"id": 142, "seek": 60136, "start": 624.32, "end": 628.72, "text": " different positions because we did random padding.", "tokens": [819, 8432, 570, 321, 630, 4974, 39562, 13], "temperature": 0.0, "avg_logprob": -0.08370102832191868, "compression_ratio": 1.6791666666666667, "no_speech_prob": 7.409649697365239e-06}, {"id": 143, "seek": 62872, "start": 628.72, "end": 634.64, "text": " You can always grab a batch of data then from the data bunch because remember a data bunch", "tokens": [509, 393, 1009, 4444, 257, 15245, 295, 1412, 550, 490, 264, 1412, 3840, 570, 1604, 257, 1412, 3840], "temperature": 0.0, "avg_logprob": -0.1508420717598188, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.1476235158625059e-05}, {"id": 144, "seek": 62872, "start": 634.64, "end": 639.9200000000001, "text": " has data loaders and data loaders are things that you grab a batch at a time and so you", "tokens": [575, 1412, 3677, 433, 293, 1412, 3677, 433, 366, 721, 300, 291, 4444, 257, 15245, 412, 257, 565, 293, 370, 291], "temperature": 0.0, "avg_logprob": -0.1508420717598188, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.1476235158625059e-05}, {"id": 145, "seek": 62872, "start": 639.9200000000001, "end": 645.5600000000001, "text": " can then grab an X batch and a Y batch, look at their shape, batch size by channel by row", "tokens": [393, 550, 4444, 364, 1783, 15245, 293, 257, 398, 15245, 11, 574, 412, 641, 3909, 11, 15245, 2744, 538, 2269, 538, 5386], "temperature": 0.0, "avg_logprob": -0.1508420717598188, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.1476235158625059e-05}, {"id": 146, "seek": 62872, "start": 645.5600000000001, "end": 647.64, "text": " by column.", "tokens": [538, 7738, 13], "temperature": 0.0, "avg_logprob": -0.1508420717598188, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.1476235158625059e-05}, {"id": 147, "seek": 62872, "start": 647.64, "end": 654.9200000000001, "text": " All fast AI data bunches have a show batch which will show you what's in it in some sensible", "tokens": [1057, 2370, 7318, 1412, 3840, 279, 362, 257, 855, 15245, 597, 486, 855, 291, 437, 311, 294, 309, 294, 512, 25380], "temperature": 0.0, "avg_logprob": -0.1508420717598188, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.1476235158625059e-05}, {"id": 148, "seek": 62872, "start": 654.9200000000001, "end": 657.24, "text": " way.", "tokens": [636, 13], "temperature": 0.0, "avg_logprob": -0.1508420717598188, "compression_ratio": 1.7534883720930232, "no_speech_prob": 1.1476235158625059e-05}, {"id": 149, "seek": 65724, "start": 657.24, "end": 662.12, "text": " So that's a quick walk through of the data block API stuff to grab our data.", "tokens": [407, 300, 311, 257, 1702, 1792, 807, 295, 264, 1412, 3461, 9362, 1507, 281, 4444, 527, 1412, 13], "temperature": 0.0, "avg_logprob": -0.13848869888870805, "compression_ratio": 1.6016260162601625, "no_speech_prob": 4.637576694221934e-06}, {"id": 150, "seek": 65724, "start": 662.12, "end": 668.34, "text": " So let's start out creating a simple CNN, simple confnet.", "tokens": [407, 718, 311, 722, 484, 4084, 257, 2199, 24859, 11, 2199, 1497, 7129, 13], "temperature": 0.0, "avg_logprob": -0.13848869888870805, "compression_ratio": 1.6016260162601625, "no_speech_prob": 4.637576694221934e-06}, {"id": 151, "seek": 65724, "start": 668.34, "end": 672.96, "text": " So the input is 28 by 28.", "tokens": [407, 264, 4846, 307, 7562, 538, 7562, 13], "temperature": 0.0, "avg_logprob": -0.13848869888870805, "compression_ratio": 1.6016260162601625, "no_speech_prob": 4.637576694221934e-06}, {"id": 152, "seek": 65724, "start": 672.96, "end": 678.7, "text": " So let's define, I like to define when I'm creating architectures a function which kind", "tokens": [407, 718, 311, 6964, 11, 286, 411, 281, 6964, 562, 286, 478, 4084, 6331, 1303, 257, 2445, 597, 733], "temperature": 0.0, "avg_logprob": -0.13848869888870805, "compression_ratio": 1.6016260162601625, "no_speech_prob": 4.637576694221934e-06}, {"id": 153, "seek": 65724, "start": 678.7, "end": 680.88, "text": " of does the things that I do again and again and again.", "tokens": [295, 775, 264, 721, 300, 286, 360, 797, 293, 797, 293, 797, 13], "temperature": 0.0, "avg_logprob": -0.13848869888870805, "compression_ratio": 1.6016260162601625, "no_speech_prob": 4.637576694221934e-06}, {"id": 154, "seek": 65724, "start": 680.88, "end": 684.52, "text": " I don't want to call it with the same arguments because I'll forget, I'll make a mistake.", "tokens": [286, 500, 380, 528, 281, 818, 309, 365, 264, 912, 12869, 570, 286, 603, 2870, 11, 286, 603, 652, 257, 6146, 13], "temperature": 0.0, "avg_logprob": -0.13848869888870805, "compression_ratio": 1.6016260162601625, "no_speech_prob": 4.637576694221934e-06}, {"id": 155, "seek": 68452, "start": 684.52, "end": 690.8, "text": " So in this case all of my convolutions are going to be kernel size 3, stride 2, padding", "tokens": [407, 294, 341, 1389, 439, 295, 452, 3754, 15892, 366, 516, 281, 312, 28256, 2744, 805, 11, 1056, 482, 568, 11, 39562], "temperature": 0.0, "avg_logprob": -0.14516547322273254, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.5074187912396155e-06}, {"id": 156, "seek": 68452, "start": 690.8, "end": 691.8, "text": " 1.", "tokens": [502, 13], "temperature": 0.0, "avg_logprob": -0.14516547322273254, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.5074187912396155e-06}, {"id": 157, "seek": 68452, "start": 691.8, "end": 694.88, "text": " So let's just create a simple function to do a conv with those parameters.", "tokens": [407, 718, 311, 445, 1884, 257, 2199, 2445, 281, 360, 257, 3754, 365, 729, 9834, 13], "temperature": 0.0, "avg_logprob": -0.14516547322273254, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.5074187912396155e-06}, {"id": 158, "seek": 68452, "start": 694.88, "end": 704.16, "text": " So each time I have a convolution it's skipping over one pixel so it's jumping two steps each", "tokens": [407, 1184, 565, 286, 362, 257, 45216, 309, 311, 31533, 670, 472, 19261, 370, 309, 311, 11233, 732, 4439, 1184], "temperature": 0.0, "avg_logprob": -0.14516547322273254, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.5074187912396155e-06}, {"id": 159, "seek": 68452, "start": 704.16, "end": 705.24, "text": " time.", "tokens": [565, 13], "temperature": 0.0, "avg_logprob": -0.14516547322273254, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.5074187912396155e-06}, {"id": 160, "seek": 68452, "start": 705.24, "end": 710.12, "text": " So that means that each time we have a convolution it's going to halve the grid size.", "tokens": [407, 300, 1355, 300, 1184, 565, 321, 362, 257, 45216, 309, 311, 516, 281, 7523, 303, 264, 10748, 2744, 13], "temperature": 0.0, "avg_logprob": -0.14516547322273254, "compression_ratio": 1.6714285714285715, "no_speech_prob": 5.5074187912396155e-06}, {"id": 161, "seek": 71012, "start": 710.12, "end": 714.98, "text": " So I've put a comment here showing what the new grid size is after each one.", "tokens": [407, 286, 600, 829, 257, 2871, 510, 4099, 437, 264, 777, 10748, 2744, 307, 934, 1184, 472, 13], "temperature": 0.0, "avg_logprob": -0.12447601389662127, "compression_ratio": 1.6768060836501901, "no_speech_prob": 3.1873473744781222e-06}, {"id": 162, "seek": 71012, "start": 714.98, "end": 719.68, "text": " So after the first convolution we have one channel coming in because it's, remember it's", "tokens": [407, 934, 264, 700, 45216, 321, 362, 472, 2269, 1348, 294, 570, 309, 311, 11, 1604, 309, 311], "temperature": 0.0, "avg_logprob": -0.12447601389662127, "compression_ratio": 1.6768060836501901, "no_speech_prob": 3.1873473744781222e-06}, {"id": 163, "seek": 71012, "start": 719.68, "end": 722.48, "text": " a grayscale image with one channel.", "tokens": [257, 677, 3772, 37088, 3256, 365, 472, 2269, 13], "temperature": 0.0, "avg_logprob": -0.12447601389662127, "compression_ratio": 1.6768060836501901, "no_speech_prob": 3.1873473744781222e-06}, {"id": 164, "seek": 71012, "start": 722.48, "end": 725.64, "text": " And then how many channels coming out, whatever you like.", "tokens": [400, 550, 577, 867, 9235, 1348, 484, 11, 2035, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.12447601389662127, "compression_ratio": 1.6768060836501901, "no_speech_prob": 3.1873473744781222e-06}, {"id": 165, "seek": 71012, "start": 725.64, "end": 731.6, "text": " So remember you always get to pick how many filters you create regardless of whether it's", "tokens": [407, 1604, 291, 1009, 483, 281, 1888, 577, 867, 15995, 291, 1884, 10060, 295, 1968, 309, 311], "temperature": 0.0, "avg_logprob": -0.12447601389662127, "compression_ratio": 1.6768060836501901, "no_speech_prob": 3.1873473744781222e-06}, {"id": 166, "seek": 71012, "start": 731.6, "end": 736.8, "text": " a fully connected layer, in which case it's just the width of the matrix you're multiplying", "tokens": [257, 4498, 4582, 4583, 11, 294, 597, 1389, 309, 311, 445, 264, 11402, 295, 264, 8141, 291, 434, 30955], "temperature": 0.0, "avg_logprob": -0.12447601389662127, "compression_ratio": 1.6768060836501901, "no_speech_prob": 3.1873473744781222e-06}, {"id": 167, "seek": 73680, "start": 736.8, "end": 743.92, "text": " by or in this case with a 2D conv it's just how many filters do you want.", "tokens": [538, 420, 294, 341, 1389, 365, 257, 568, 35, 3754, 309, 311, 445, 577, 867, 15995, 360, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.11985806201366668, "compression_ratio": 1.4926829268292683, "no_speech_prob": 6.338187176879728e-06}, {"id": 168, "seek": 73680, "start": 743.92, "end": 746.56, "text": " So I picked 8 and so after this it's stride 2.", "tokens": [407, 286, 6183, 1649, 293, 370, 934, 341, 309, 311, 1056, 482, 568, 13], "temperature": 0.0, "avg_logprob": -0.11985806201366668, "compression_ratio": 1.4926829268292683, "no_speech_prob": 6.338187176879728e-06}, {"id": 169, "seek": 73680, "start": 746.56, "end": 753.4799999999999, "text": " So the 28 by 28 image is now a 14 by 14 feature map with 8 channels.", "tokens": [407, 264, 7562, 538, 7562, 3256, 307, 586, 257, 3499, 538, 3499, 4111, 4471, 365, 1649, 9235, 13], "temperature": 0.0, "avg_logprob": -0.11985806201366668, "compression_ratio": 1.4926829268292683, "no_speech_prob": 6.338187176879728e-06}, {"id": 170, "seek": 73680, "start": 753.4799999999999, "end": 761.3199999999999, "text": " So specifically therefore it's an 8 by 14 by 14 tensor of activations.", "tokens": [407, 4682, 4412, 309, 311, 364, 1649, 538, 3499, 538, 3499, 40863, 295, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.11985806201366668, "compression_ratio": 1.4926829268292683, "no_speech_prob": 6.338187176879728e-06}, {"id": 171, "seek": 73680, "start": 761.3199999999999, "end": 763.7199999999999, "text": " Then we'll do batch norm, then we'll do relu.", "tokens": [1396, 321, 603, 360, 15245, 2026, 11, 550, 321, 603, 360, 1039, 84, 13], "temperature": 0.0, "avg_logprob": -0.11985806201366668, "compression_ratio": 1.4926829268292683, "no_speech_prob": 6.338187176879728e-06}, {"id": 172, "seek": 76372, "start": 763.72, "end": 767.98, "text": " So the number of input filters to the next conv has to equal the number of output filters", "tokens": [407, 264, 1230, 295, 4846, 15995, 281, 264, 958, 3754, 575, 281, 2681, 264, 1230, 295, 5598, 15995], "temperature": 0.0, "avg_logprob": -0.09712890702850964, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.320934734394541e-05}, {"id": 173, "seek": 76372, "start": 767.98, "end": 773.38, "text": " from the previous conv and we can just keep increasing the number of channels.", "tokens": [490, 264, 3894, 3754, 293, 321, 393, 445, 1066, 5662, 264, 1230, 295, 9235, 13], "temperature": 0.0, "avg_logprob": -0.09712890702850964, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.320934734394541e-05}, {"id": 174, "seek": 76372, "start": 773.38, "end": 778.08, "text": " Because we're doing stride 2 it's going to keep decreasing the grid size.", "tokens": [1436, 321, 434, 884, 1056, 482, 568, 309, 311, 516, 281, 1066, 23223, 264, 10748, 2744, 13], "temperature": 0.0, "avg_logprob": -0.09712890702850964, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.320934734394541e-05}, {"id": 175, "seek": 76372, "start": 778.08, "end": 784.44, "text": " Notice here it goes from 7 to 4 because if you're doing a stride 2 conv over 7 it's going", "tokens": [13428, 510, 309, 1709, 490, 1614, 281, 1017, 570, 498, 291, 434, 884, 257, 1056, 482, 568, 3754, 670, 1614, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.09712890702850964, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.320934734394541e-05}, {"id": 176, "seek": 76372, "start": 784.44, "end": 791.64, "text": " to be kind of math dot ceiling of 7 divided by 2.", "tokens": [281, 312, 733, 295, 5221, 5893, 13655, 295, 1614, 6666, 538, 568, 13], "temperature": 0.0, "avg_logprob": -0.09712890702850964, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.320934734394541e-05}, {"id": 177, "seek": 79164, "start": 791.64, "end": 796.76, "text": " Batch norm relu conv we're now down to 2 by 2, batch norm relu conv we're now down to", "tokens": [363, 852, 2026, 1039, 84, 3754, 321, 434, 586, 760, 281, 568, 538, 568, 11, 15245, 2026, 1039, 84, 3754, 321, 434, 586, 760, 281], "temperature": 0.0, "avg_logprob": -0.17917432011784734, "compression_ratio": 1.5, "no_speech_prob": 1.2028282071696594e-05}, {"id": 178, "seek": 79164, "start": 796.76, "end": 798.96, "text": " 1 by 1.", "tokens": [502, 538, 502, 13], "temperature": 0.0, "avg_logprob": -0.17917432011784734, "compression_ratio": 1.5, "no_speech_prob": 1.2028282071696594e-05}, {"id": 179, "seek": 79164, "start": 798.96, "end": 812.68, "text": " So after this we have a picture map of let's see 10 by 1 by 1.", "tokens": [407, 934, 341, 321, 362, 257, 3036, 4471, 295, 718, 311, 536, 1266, 538, 502, 538, 502, 13], "temperature": 0.0, "avg_logprob": -0.17917432011784734, "compression_ratio": 1.5, "no_speech_prob": 1.2028282071696594e-05}, {"id": 180, "seek": 79164, "start": 812.68, "end": 814.92, "text": " Does that make sense?", "tokens": [4402, 300, 652, 2020, 30], "temperature": 0.0, "avg_logprob": -0.17917432011784734, "compression_ratio": 1.5, "no_speech_prob": 1.2028282071696594e-05}, {"id": 181, "seek": 79164, "start": 814.92, "end": 816.56, "text": " We've got a grid size of 1 now.", "tokens": [492, 600, 658, 257, 10748, 2744, 295, 502, 586, 13], "temperature": 0.0, "avg_logprob": -0.17917432011784734, "compression_ratio": 1.5, "no_speech_prob": 1.2028282071696594e-05}, {"id": 182, "seek": 81656, "start": 816.56, "end": 826.1199999999999, "text": " So it's not a vector of length 10, it's a rank 3 tensor of 10 by 1 by 1.", "tokens": [407, 309, 311, 406, 257, 8062, 295, 4641, 1266, 11, 309, 311, 257, 6181, 805, 40863, 295, 1266, 538, 502, 538, 502, 13], "temperature": 0.0, "avg_logprob": -0.06541703428540911, "compression_ratio": 1.6505376344086022, "no_speech_prob": 3.340328703416162e-06}, {"id": 183, "seek": 81656, "start": 826.1199999999999, "end": 831.8399999999999, "text": " So our loss functions expect generally a vector, not a rank 3 tensor.", "tokens": [407, 527, 4470, 6828, 2066, 5101, 257, 8062, 11, 406, 257, 6181, 805, 40863, 13], "temperature": 0.0, "avg_logprob": -0.06541703428540911, "compression_ratio": 1.6505376344086022, "no_speech_prob": 3.340328703416162e-06}, {"id": 184, "seek": 81656, "start": 831.8399999999999, "end": 839.4, "text": " So you can chuck flatten at the end and flatten just means remove any unit axes.", "tokens": [407, 291, 393, 20870, 24183, 412, 264, 917, 293, 24183, 445, 1355, 4159, 604, 4985, 35387, 13], "temperature": 0.0, "avg_logprob": -0.06541703428540911, "compression_ratio": 1.6505376344086022, "no_speech_prob": 3.340328703416162e-06}, {"id": 185, "seek": 81656, "start": 839.4, "end": 846.0799999999999, "text": " So that will make it now just a vector of length 10 which is what we always expect.", "tokens": [407, 300, 486, 652, 309, 586, 445, 257, 8062, 295, 4641, 1266, 597, 307, 437, 321, 1009, 2066, 13], "temperature": 0.0, "avg_logprob": -0.06541703428540911, "compression_ratio": 1.6505376344086022, "no_speech_prob": 3.340328703416162e-06}, {"id": 186, "seek": 84608, "start": 846.08, "end": 850.2800000000001, "text": " So that's how we can create a CNN.", "tokens": [407, 300, 311, 577, 321, 393, 1884, 257, 24859, 13], "temperature": 0.0, "avg_logprob": -0.1310548585714753, "compression_ratio": 1.645933014354067, "no_speech_prob": 6.143910468381364e-06}, {"id": 187, "seek": 84608, "start": 850.2800000000001, "end": 854.98, "text": " So then we can return that into a learner by passing in the data and the model and the", "tokens": [407, 550, 321, 393, 2736, 300, 666, 257, 33347, 538, 8437, 294, 264, 1412, 293, 264, 2316, 293, 264], "temperature": 0.0, "avg_logprob": -0.1310548585714753, "compression_ratio": 1.645933014354067, "no_speech_prob": 6.143910468381364e-06}, {"id": 188, "seek": 84608, "start": 854.98, "end": 859.2800000000001, "text": " loss function and if optionally some metrics.", "tokens": [4470, 2445, 293, 498, 3614, 379, 512, 16367, 13], "temperature": 0.0, "avg_logprob": -0.1310548585714753, "compression_ratio": 1.645933014354067, "no_speech_prob": 6.143910468381364e-06}, {"id": 189, "seek": 84608, "start": 859.2800000000001, "end": 862.2800000000001, "text": " So we're going to use cross entropy as usual.", "tokens": [407, 321, 434, 516, 281, 764, 3278, 30867, 382, 7713, 13], "temperature": 0.0, "avg_logprob": -0.1310548585714753, "compression_ratio": 1.645933014354067, "no_speech_prob": 6.143910468381364e-06}, {"id": 190, "seek": 84608, "start": 862.2800000000001, "end": 864.72, "text": " So we can then call learn.summary and confirm.", "tokens": [407, 321, 393, 550, 818, 1466, 13, 82, 40879, 822, 293, 9064, 13], "temperature": 0.0, "avg_logprob": -0.1310548585714753, "compression_ratio": 1.645933014354067, "no_speech_prob": 6.143910468381364e-06}, {"id": 191, "seek": 84608, "start": 864.72, "end": 871.4000000000001, "text": " After that first conv we're down to 14 by 14 and after the second conv 7 by 7 and 4", "tokens": [2381, 300, 700, 3754, 321, 434, 760, 281, 3499, 538, 3499, 293, 934, 264, 1150, 3754, 1614, 538, 1614, 293, 1017], "temperature": 0.0, "avg_logprob": -0.1310548585714753, "compression_ratio": 1.645933014354067, "no_speech_prob": 6.143910468381364e-06}, {"id": 192, "seek": 87140, "start": 871.4, "end": 876.1999999999999, "text": " by 4, 2 by 2, 1 by 1.", "tokens": [538, 1017, 11, 568, 538, 568, 11, 502, 538, 502, 13], "temperature": 0.0, "avg_logprob": -0.15066972732543946, "compression_ratio": 1.5598086124401913, "no_speech_prob": 1.9830462406389415e-05}, {"id": 193, "seek": 87140, "start": 876.1999999999999, "end": 880.1999999999999, "text": " The flatten comes out calling it a lambda but that as you can see it gets rid of the", "tokens": [440, 24183, 1487, 484, 5141, 309, 257, 13607, 457, 300, 382, 291, 393, 536, 309, 2170, 3973, 295, 264], "temperature": 0.0, "avg_logprob": -0.15066972732543946, "compression_ratio": 1.5598086124401913, "no_speech_prob": 1.9830462406389415e-05}, {"id": 194, "seek": 87140, "start": 880.1999999999999, "end": 886.54, "text": " 1 by 1 and it's now just a length 10 vector for each item in the batch.", "tokens": [502, 538, 502, 293, 309, 311, 586, 445, 257, 4641, 1266, 8062, 337, 1184, 3174, 294, 264, 15245, 13], "temperature": 0.0, "avg_logprob": -0.15066972732543946, "compression_ratio": 1.5598086124401913, "no_speech_prob": 1.9830462406389415e-05}, {"id": 195, "seek": 87140, "start": 886.54, "end": 891.48, "text": " So 128 by 10 matrix in the whole mini-batch.", "tokens": [407, 29810, 538, 1266, 8141, 294, 264, 1379, 8382, 12, 65, 852, 13], "temperature": 0.0, "avg_logprob": -0.15066972732543946, "compression_ratio": 1.5598086124401913, "no_speech_prob": 1.9830462406389415e-05}, {"id": 196, "seek": 87140, "start": 891.48, "end": 897.52, "text": " So just to confirm that this is working okay we can grab that mini-batch of x that we created", "tokens": [407, 445, 281, 9064, 300, 341, 307, 1364, 1392, 321, 393, 4444, 300, 8382, 12, 65, 852, 295, 2031, 300, 321, 2942], "temperature": 0.0, "avg_logprob": -0.15066972732543946, "compression_ratio": 1.5598086124401913, "no_speech_prob": 1.9830462406389415e-05}, {"id": 197, "seek": 87140, "start": 897.52, "end": 898.52, "text": " earlier.", "tokens": [3071, 13], "temperature": 0.0, "avg_logprob": -0.15066972732543946, "compression_ratio": 1.5598086124401913, "no_speech_prob": 1.9830462406389415e-05}, {"id": 198, "seek": 89852, "start": 898.52, "end": 901.72, "text": " There's our mini-batch of x.", "tokens": [821, 311, 527, 8382, 12, 65, 852, 295, 2031, 13], "temperature": 0.0, "avg_logprob": -0.19039223292102553, "compression_ratio": 1.3854748603351956, "no_speech_prob": 8.93822198122507e-06}, {"id": 199, "seek": 89852, "start": 901.72, "end": 905.56, "text": " Pop it onto the GPU and call the model directly.", "tokens": [10215, 309, 3911, 264, 18407, 293, 818, 264, 2316, 3838, 13], "temperature": 0.0, "avg_logprob": -0.19039223292102553, "compression_ratio": 1.3854748603351956, "no_speech_prob": 8.93822198122507e-06}, {"id": 200, "seek": 89852, "start": 905.56, "end": 911.16, "text": " Remember any PyTorch module we can pretend it's a function and that gives us back as", "tokens": [5459, 604, 9953, 51, 284, 339, 10088, 321, 393, 11865, 309, 311, 257, 2445, 293, 300, 2709, 505, 646, 382], "temperature": 0.0, "avg_logprob": -0.19039223292102553, "compression_ratio": 1.3854748603351956, "no_speech_prob": 8.93822198122507e-06}, {"id": 201, "seek": 89852, "start": 911.16, "end": 914.88, "text": " we hoped a 128 by 10 result.", "tokens": [321, 19737, 257, 29810, 538, 1266, 1874, 13], "temperature": 0.0, "avg_logprob": -0.19039223292102553, "compression_ratio": 1.3854748603351956, "no_speech_prob": 8.93822198122507e-06}, {"id": 202, "seek": 89852, "start": 914.88, "end": 917.92, "text": " So that's how you can directly get some predictions out.", "tokens": [407, 300, 311, 577, 291, 393, 3838, 483, 512, 21264, 484, 13], "temperature": 0.0, "avg_logprob": -0.19039223292102553, "compression_ratio": 1.3854748603351956, "no_speech_prob": 8.93822198122507e-06}, {"id": 203, "seek": 91792, "start": 917.92, "end": 929.4399999999999, "text": " LR find, fit one cycle and bang we already have a 98.6% accurate conv net and this is", "tokens": [441, 49, 915, 11, 3318, 472, 6586, 293, 8550, 321, 1217, 362, 257, 20860, 13, 21, 4, 8559, 3754, 2533, 293, 341, 307], "temperature": 0.0, "avg_logprob": -0.20474449071017178, "compression_ratio": 1.5045045045045045, "no_speech_prob": 4.565731160255382e-06}, {"id": 204, "seek": 91792, "start": 929.4399999999999, "end": 931.8399999999999, "text": " trained from scratch of course it's not pre-trained.", "tokens": [8895, 490, 8459, 295, 1164, 309, 311, 406, 659, 12, 17227, 2001, 13], "temperature": 0.0, "avg_logprob": -0.20474449071017178, "compression_ratio": 1.5045045045045045, "no_speech_prob": 4.565731160255382e-06}, {"id": 205, "seek": 91792, "start": 931.8399999999999, "end": 933.36, "text": " We literally created our own architecture.", "tokens": [492, 3736, 2942, 527, 1065, 9482, 13], "temperature": 0.0, "avg_logprob": -0.20474449071017178, "compression_ratio": 1.5045045045045045, "no_speech_prob": 4.565731160255382e-06}, {"id": 206, "seek": 91792, "start": 933.36, "end": 935.9599999999999, "text": " It's about the simplest possible architecture you can imagine.", "tokens": [467, 311, 466, 264, 22811, 1944, 9482, 291, 393, 3811, 13], "temperature": 0.0, "avg_logprob": -0.20474449071017178, "compression_ratio": 1.5045045045045045, "no_speech_prob": 4.565731160255382e-06}, {"id": 207, "seek": 91792, "start": 935.9599999999999, "end": 937.4799999999999, "text": " 18 seconds to train.", "tokens": [2443, 3949, 281, 3847, 13], "temperature": 0.0, "avg_logprob": -0.20474449071017178, "compression_ratio": 1.5045045045045045, "no_speech_prob": 4.565731160255382e-06}, {"id": 208, "seek": 91792, "start": 937.4799999999999, "end": 942.8, "text": " So that's how easy it is to create a pretty accurate digit detector.", "tokens": [407, 300, 311, 577, 1858, 309, 307, 281, 1884, 257, 1238, 8559, 14293, 25712, 13], "temperature": 0.0, "avg_logprob": -0.20474449071017178, "compression_ratio": 1.5045045045045045, "no_speech_prob": 4.565731160255382e-06}, {"id": 209, "seek": 94280, "start": 942.8, "end": 950.8, "text": " So let's refactor that a little rather than saying conv batch norm relu all the time.", "tokens": [407, 718, 311, 1895, 15104, 300, 257, 707, 2831, 813, 1566, 3754, 15245, 2026, 1039, 84, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.1511229705810547, "compression_ratio": 1.6326530612244898, "no_speech_prob": 8.267532393801957e-06}, {"id": 210, "seek": 94280, "start": 950.8, "end": 957.4799999999999, "text": " Fast.ai already has something called conv underscore layer which lets you create conv", "tokens": [15968, 13, 1301, 1217, 575, 746, 1219, 3754, 37556, 4583, 597, 6653, 291, 1884, 3754], "temperature": 0.0, "avg_logprob": -0.1511229705810547, "compression_ratio": 1.6326530612244898, "no_speech_prob": 8.267532393801957e-06}, {"id": 211, "seek": 94280, "start": 957.4799999999999, "end": 963.24, "text": " batch norm relu combinations and it has various other options to do other tweaks to it but", "tokens": [15245, 2026, 1039, 84, 21267, 293, 309, 575, 3683, 661, 3956, 281, 360, 661, 46664, 281, 309, 457], "temperature": 0.0, "avg_logprob": -0.1511229705810547, "compression_ratio": 1.6326530612244898, "no_speech_prob": 8.267532393801957e-06}, {"id": 212, "seek": 94280, "start": 963.24, "end": 966.52, "text": " the basic version is just exactly what I just showed you.", "tokens": [264, 3875, 3037, 307, 445, 2293, 437, 286, 445, 4712, 291, 13], "temperature": 0.0, "avg_logprob": -0.1511229705810547, "compression_ratio": 1.6326530612244898, "no_speech_prob": 8.267532393801957e-06}, {"id": 213, "seek": 96652, "start": 966.52, "end": 974.28, "text": " So we can refactor that like so, that's exactly the same neural net.", "tokens": [407, 321, 393, 1895, 15104, 300, 411, 370, 11, 300, 311, 2293, 264, 912, 18161, 2533, 13], "temperature": 0.0, "avg_logprob": -0.14632728487946267, "compression_ratio": 1.5026178010471205, "no_speech_prob": 2.857182607840514e-06}, {"id": 214, "seek": 96652, "start": 974.28, "end": 980.28, "text": " And so let's just train it a little bit longer and it's actually 99.1% accurate if we train", "tokens": [400, 370, 718, 311, 445, 3847, 309, 257, 707, 857, 2854, 293, 309, 311, 767, 11803, 13, 16, 4, 8559, 498, 321, 3847], "temperature": 0.0, "avg_logprob": -0.14632728487946267, "compression_ratio": 1.5026178010471205, "no_speech_prob": 2.857182607840514e-06}, {"id": 215, "seek": 96652, "start": 980.28, "end": 982.1999999999999, "text": " it for all of a minute.", "tokens": [309, 337, 439, 295, 257, 3456, 13], "temperature": 0.0, "avg_logprob": -0.14632728487946267, "compression_ratio": 1.5026178010471205, "no_speech_prob": 2.857182607840514e-06}, {"id": 216, "seek": 96652, "start": 982.1999999999999, "end": 985.0799999999999, "text": " So that's cool.", "tokens": [407, 300, 311, 1627, 13], "temperature": 0.0, "avg_logprob": -0.14632728487946267, "compression_ratio": 1.5026178010471205, "no_speech_prob": 2.857182607840514e-06}, {"id": 217, "seek": 96652, "start": 985.0799999999999, "end": 988.28, "text": " So how can we improve this?", "tokens": [407, 577, 393, 321, 3470, 341, 30], "temperature": 0.0, "avg_logprob": -0.14632728487946267, "compression_ratio": 1.5026178010471205, "no_speech_prob": 2.857182607840514e-06}, {"id": 218, "seek": 96652, "start": 988.28, "end": 994.0, "text": " Well what we really want to do is create a deeper network.", "tokens": [1042, 437, 321, 534, 528, 281, 360, 307, 1884, 257, 7731, 3209, 13], "temperature": 0.0, "avg_logprob": -0.14632728487946267, "compression_ratio": 1.5026178010471205, "no_speech_prob": 2.857182607840514e-06}, {"id": 219, "seek": 99400, "start": 994.0, "end": 1000.12, "text": " And so a very easy way to create a deeper network would be after every stride 2 conv", "tokens": [400, 370, 257, 588, 1858, 636, 281, 1884, 257, 7731, 3209, 576, 312, 934, 633, 1056, 482, 568, 3754], "temperature": 0.0, "avg_logprob": -0.12621226591222426, "compression_ratio": 1.603960396039604, "no_speech_prob": 8.138341399899218e-06}, {"id": 220, "seek": 99400, "start": 1000.12, "end": 1005.92, "text": " add a stride 1 conv because the stride 1 conv doesn't change the feature map size at all", "tokens": [909, 257, 1056, 482, 502, 3754, 570, 264, 1056, 482, 502, 3754, 1177, 380, 1319, 264, 4111, 4471, 2744, 412, 439], "temperature": 0.0, "avg_logprob": -0.12621226591222426, "compression_ratio": 1.603960396039604, "no_speech_prob": 8.138341399899218e-06}, {"id": 221, "seek": 99400, "start": 1005.92, "end": 1009.32, "text": " so you can add as many as you like.", "tokens": [370, 291, 393, 909, 382, 867, 382, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.12621226591222426, "compression_ratio": 1.603960396039604, "no_speech_prob": 8.138341399899218e-06}, {"id": 222, "seek": 99400, "start": 1009.32, "end": 1014.12, "text": " But there's a problem.", "tokens": [583, 456, 311, 257, 1154, 13], "temperature": 0.0, "avg_logprob": -0.12621226591222426, "compression_ratio": 1.603960396039604, "no_speech_prob": 8.138341399899218e-06}, {"id": 223, "seek": 99400, "start": 1014.12, "end": 1019.6, "text": " And the problem was pointed out in this paper, very very very influential paper called Deep", "tokens": [400, 264, 1154, 390, 10932, 484, 294, 341, 3035, 11, 588, 588, 588, 22215, 3035, 1219, 14895], "temperature": 0.0, "avg_logprob": -0.12621226591222426, "compression_ratio": 1.603960396039604, "no_speech_prob": 8.138341399899218e-06}, {"id": 224, "seek": 101960, "start": 1019.6, "end": 1025.28, "text": " Residual Learning for Image Recognition by Kai Ming He and colleagues then at Microsoft", "tokens": [5015, 327, 901, 15205, 337, 29903, 44682, 849, 538, 20753, 19352, 634, 293, 7734, 550, 412, 8116], "temperature": 0.0, "avg_logprob": -0.21474725723266602, "compression_ratio": 1.6371308016877637, "no_speech_prob": 8.52722496347269e-06}, {"id": 225, "seek": 101960, "start": 1025.28, "end": 1026.28, "text": " Research.", "tokens": [10303, 13], "temperature": 0.0, "avg_logprob": -0.21474725723266602, "compression_ratio": 1.6371308016877637, "no_speech_prob": 8.52722496347269e-06}, {"id": 226, "seek": 101960, "start": 1026.28, "end": 1027.8, "text": " And they did something interesting.", "tokens": [400, 436, 630, 746, 1880, 13], "temperature": 0.0, "avg_logprob": -0.21474725723266602, "compression_ratio": 1.6371308016877637, "no_speech_prob": 8.52722496347269e-06}, {"id": 227, "seek": 101960, "start": 1027.8, "end": 1029.72, "text": " They said let's look at the training error.", "tokens": [814, 848, 718, 311, 574, 412, 264, 3097, 6713, 13], "temperature": 0.0, "avg_logprob": -0.21474725723266602, "compression_ratio": 1.6371308016877637, "no_speech_prob": 8.52722496347269e-06}, {"id": 228, "seek": 101960, "start": 1029.72, "end": 1031.56, "text": " So forget generalisation even.", "tokens": [407, 2870, 2674, 7623, 754, 13], "temperature": 0.0, "avg_logprob": -0.21474725723266602, "compression_ratio": 1.6371308016877637, "no_speech_prob": 8.52722496347269e-06}, {"id": 229, "seek": 101960, "start": 1031.56, "end": 1038.68, "text": " Let's just look at the training error of a network trained on Cypher 10 and let's try", "tokens": [961, 311, 445, 574, 412, 264, 3097, 6713, 295, 257, 3209, 8895, 322, 10295, 79, 511, 1266, 293, 718, 311, 853], "temperature": 0.0, "avg_logprob": -0.21474725723266602, "compression_ratio": 1.6371308016877637, "no_speech_prob": 8.52722496347269e-06}, {"id": 230, "seek": 101960, "start": 1038.68, "end": 1044.16, "text": " one network of 20 layers, just basic 3x3 convs, just basically the same network I just showed", "tokens": [472, 3209, 295, 945, 7914, 11, 445, 3875, 805, 87, 18, 3754, 82, 11, 445, 1936, 264, 912, 3209, 286, 445, 4712], "temperature": 0.0, "avg_logprob": -0.21474725723266602, "compression_ratio": 1.6371308016877637, "no_speech_prob": 8.52722496347269e-06}, {"id": 231, "seek": 104416, "start": 1044.16, "end": 1049.76, "text": " you but without batch norm.", "tokens": [291, 457, 1553, 15245, 2026, 13], "temperature": 0.0, "avg_logprob": -0.14991299922649676, "compression_ratio": 1.721461187214612, "no_speech_prob": 5.421930381999118e-06}, {"id": 232, "seek": 104416, "start": 1049.76, "end": 1054.76, "text": " Let's try a 20 layer one and a 56 layer one on the training set.", "tokens": [961, 311, 853, 257, 945, 4583, 472, 293, 257, 19687, 4583, 472, 322, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.14991299922649676, "compression_ratio": 1.721461187214612, "no_speech_prob": 5.421930381999118e-06}, {"id": 233, "seek": 104416, "start": 1054.76, "end": 1056.76, "text": " So the 56 layer one has a lot more parameters.", "tokens": [407, 264, 19687, 4583, 472, 575, 257, 688, 544, 9834, 13], "temperature": 0.0, "avg_logprob": -0.14991299922649676, "compression_ratio": 1.721461187214612, "no_speech_prob": 5.421930381999118e-06}, {"id": 234, "seek": 104416, "start": 1056.76, "end": 1060.5600000000002, "text": " It's got a lot more of these stride 1 convs in the middle.", "tokens": [467, 311, 658, 257, 688, 544, 295, 613, 1056, 482, 502, 3754, 82, 294, 264, 2808, 13], "temperature": 0.0, "avg_logprob": -0.14991299922649676, "compression_ratio": 1.721461187214612, "no_speech_prob": 5.421930381999118e-06}, {"id": 235, "seek": 104416, "start": 1060.5600000000002, "end": 1065.0600000000002, "text": " So the one with more parameters should seriously overfit.", "tokens": [407, 264, 472, 365, 544, 9834, 820, 6638, 670, 6845, 13], "temperature": 0.0, "avg_logprob": -0.14991299922649676, "compression_ratio": 1.721461187214612, "no_speech_prob": 5.421930381999118e-06}, {"id": 236, "seek": 104416, "start": 1065.0600000000002, "end": 1071.18, "text": " So you would expect the 56 layer one to zip down to zero-ish training error pretty quickly", "tokens": [407, 291, 576, 2066, 264, 19687, 4583, 472, 281, 20730, 760, 281, 4018, 12, 742, 3097, 6713, 1238, 2661], "temperature": 0.0, "avg_logprob": -0.14991299922649676, "compression_ratio": 1.721461187214612, "no_speech_prob": 5.421930381999118e-06}, {"id": 237, "seek": 104416, "start": 1071.18, "end": 1072.46, "text": " and that is not what happens.", "tokens": [293, 300, 307, 406, 437, 2314, 13], "temperature": 0.0, "avg_logprob": -0.14991299922649676, "compression_ratio": 1.721461187214612, "no_speech_prob": 5.421930381999118e-06}, {"id": 238, "seek": 107246, "start": 1072.46, "end": 1075.8, "text": " It is worse than the shallower network.", "tokens": [467, 307, 5324, 813, 264, 4393, 968, 3209, 13], "temperature": 0.0, "avg_logprob": -0.11120071643736304, "compression_ratio": 1.5536723163841808, "no_speech_prob": 1.1838033969979733e-05}, {"id": 239, "seek": 107246, "start": 1075.8, "end": 1081.92, "text": " So when you see something weird happen, really good researchers don't go oh no, it's not", "tokens": [407, 562, 291, 536, 746, 3657, 1051, 11, 534, 665, 10309, 500, 380, 352, 1954, 572, 11, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.11120071643736304, "compression_ratio": 1.5536723163841808, "no_speech_prob": 1.1838033969979733e-05}, {"id": 240, "seek": 107246, "start": 1081.92, "end": 1082.92, "text": " working.", "tokens": [1364, 13], "temperature": 0.0, "avg_logprob": -0.11120071643736304, "compression_ratio": 1.5536723163841808, "no_speech_prob": 1.1838033969979733e-05}, {"id": 241, "seek": 107246, "start": 1082.92, "end": 1085.54, "text": " They go that's interesting.", "tokens": [814, 352, 300, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.11120071643736304, "compression_ratio": 1.5536723163841808, "no_speech_prob": 1.1838033969979733e-05}, {"id": 242, "seek": 107246, "start": 1085.54, "end": 1089.3600000000001, "text": " So Kai Ming He said that's interesting.", "tokens": [407, 20753, 19352, 634, 848, 300, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.11120071643736304, "compression_ratio": 1.5536723163841808, "no_speech_prob": 1.1838033969979733e-05}, {"id": 243, "seek": 107246, "start": 1089.3600000000001, "end": 1091.64, "text": " What's going on?", "tokens": [708, 311, 516, 322, 30], "temperature": 0.0, "avg_logprob": -0.11120071643736304, "compression_ratio": 1.5536723163841808, "no_speech_prob": 1.1838033969979733e-05}, {"id": 244, "seek": 107246, "start": 1091.64, "end": 1096.6000000000001, "text": " And he said I don't know but what I do know is this.", "tokens": [400, 415, 848, 286, 500, 380, 458, 457, 437, 286, 360, 458, 307, 341, 13], "temperature": 0.0, "avg_logprob": -0.11120071643736304, "compression_ratio": 1.5536723163841808, "no_speech_prob": 1.1838033969979733e-05}, {"id": 245, "seek": 109660, "start": 1096.6, "end": 1104.36, "text": " I could take this 56 layer network and make a new version of it which is identical but", "tokens": [286, 727, 747, 341, 19687, 4583, 3209, 293, 652, 257, 777, 3037, 295, 309, 597, 307, 14800, 457], "temperature": 0.0, "avg_logprob": -0.07081789652506511, "compression_ratio": 1.6931818181818181, "no_speech_prob": 9.663114724389743e-06}, {"id": 246, "seek": 109660, "start": 1104.36, "end": 1109.9599999999998, "text": " has to be at least as good as the 20 layer network and here's how.", "tokens": [575, 281, 312, 412, 1935, 382, 665, 382, 264, 945, 4583, 3209, 293, 510, 311, 577, 13], "temperature": 0.0, "avg_logprob": -0.07081789652506511, "compression_ratio": 1.6931818181818181, "no_speech_prob": 9.663114724389743e-06}, {"id": 247, "seek": 109660, "start": 1109.9599999999998, "end": 1118.8799999999999, "text": " Every two convolutions I'm going to add together the input to those two convolutions, add it", "tokens": [2048, 732, 3754, 15892, 286, 478, 516, 281, 909, 1214, 264, 4846, 281, 729, 732, 3754, 15892, 11, 909, 309], "temperature": 0.0, "avg_logprob": -0.07081789652506511, "compression_ratio": 1.6931818181818181, "no_speech_prob": 9.663114724389743e-06}, {"id": 248, "seek": 109660, "start": 1118.8799999999999, "end": 1124.74, "text": " together with the result of those two convolutions.", "tokens": [1214, 365, 264, 1874, 295, 729, 732, 3754, 15892, 13], "temperature": 0.0, "avg_logprob": -0.07081789652506511, "compression_ratio": 1.6931818181818181, "no_speech_prob": 9.663114724389743e-06}, {"id": 249, "seek": 112474, "start": 1124.74, "end": 1139.56, "text": " So in other words he's saying instead of saying output equals conv2 of conv1 of x, instead", "tokens": [407, 294, 661, 2283, 415, 311, 1566, 2602, 295, 1566, 5598, 6915, 3754, 17, 295, 3754, 16, 295, 2031, 11, 2602], "temperature": 0.0, "avg_logprob": -0.11968441236586798, "compression_ratio": 1.6, "no_speech_prob": 4.936258847010322e-06}, {"id": 250, "seek": 112474, "start": 1139.56, "end": 1149.76, "text": " he's saying output equals x plus conv2 of conv1 of x.", "tokens": [415, 311, 1566, 5598, 6915, 2031, 1804, 3754, 17, 295, 3754, 16, 295, 2031, 13], "temperature": 0.0, "avg_logprob": -0.11968441236586798, "compression_ratio": 1.6, "no_speech_prob": 4.936258847010322e-06}, {"id": 251, "seek": 114976, "start": 1149.76, "end": 1160.6, "text": " So that 56 layers worth of convolutions in that, his theory was has to be at least as", "tokens": [407, 300, 19687, 7914, 3163, 295, 3754, 15892, 294, 300, 11, 702, 5261, 390, 575, 281, 312, 412, 1935, 382], "temperature": 0.0, "avg_logprob": -0.07726950188205667, "compression_ratio": 1.5837837837837838, "no_speech_prob": 1.4593193782275193e-06}, {"id": 252, "seek": 114976, "start": 1160.6, "end": 1167.96, "text": " good as the 20 layer version because it could always just set conv2 and conv1 to a bunch", "tokens": [665, 382, 264, 945, 4583, 3037, 570, 309, 727, 1009, 445, 992, 3754, 17, 293, 3754, 16, 281, 257, 3840], "temperature": 0.0, "avg_logprob": -0.07726950188205667, "compression_ratio": 1.5837837837837838, "no_speech_prob": 1.4593193782275193e-06}, {"id": 253, "seek": 114976, "start": 1167.96, "end": 1175.04, "text": " of zero weights for everything except for the first 20 layers because the x, the input", "tokens": [295, 4018, 17443, 337, 1203, 3993, 337, 264, 700, 945, 7914, 570, 264, 2031, 11, 264, 4846], "temperature": 0.0, "avg_logprob": -0.07726950188205667, "compression_ratio": 1.5837837837837838, "no_speech_prob": 1.4593193782275193e-06}, {"id": 254, "seek": 114976, "start": 1175.04, "end": 1178.04, "text": " could just go straight through.", "tokens": [727, 445, 352, 2997, 807, 13], "temperature": 0.0, "avg_logprob": -0.07726950188205667, "compression_ratio": 1.5837837837837838, "no_speech_prob": 1.4593193782275193e-06}, {"id": 255, "seek": 117804, "start": 1178.04, "end": 1183.54, "text": " So this thing here is, as you see, called an identity connection.", "tokens": [407, 341, 551, 510, 307, 11, 382, 291, 536, 11, 1219, 364, 6575, 4984, 13], "temperature": 0.0, "avg_logprob": -0.1208233879607858, "compression_ratio": 1.75, "no_speech_prob": 7.1825070335762575e-06}, {"id": 256, "seek": 117804, "start": 1183.54, "end": 1186.04, "text": " It's the identity function.", "tokens": [467, 311, 264, 6575, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1208233879607858, "compression_ratio": 1.75, "no_speech_prob": 7.1825070335762575e-06}, {"id": 257, "seek": 117804, "start": 1186.04, "end": 1187.04, "text": " Nothing happens at all.", "tokens": [6693, 2314, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.1208233879607858, "compression_ratio": 1.75, "no_speech_prob": 7.1825070335762575e-06}, {"id": 258, "seek": 117804, "start": 1187.04, "end": 1189.8, "text": " It's also known as a skip connection.", "tokens": [467, 311, 611, 2570, 382, 257, 10023, 4984, 13], "temperature": 0.0, "avg_logprob": -0.1208233879607858, "compression_ratio": 1.75, "no_speech_prob": 7.1825070335762575e-06}, {"id": 259, "seek": 117804, "start": 1189.8, "end": 1191.44, "text": " So that was a theory.", "tokens": [407, 300, 390, 257, 5261, 13], "temperature": 0.0, "avg_logprob": -0.1208233879607858, "compression_ratio": 1.75, "no_speech_prob": 7.1825070335762575e-06}, {"id": 260, "seek": 117804, "start": 1191.44, "end": 1197.44, "text": " That's what the paper describes as the intuition behind this is what would happen if we created", "tokens": [663, 311, 437, 264, 3035, 15626, 382, 264, 24002, 2261, 341, 307, 437, 576, 1051, 498, 321, 2942], "temperature": 0.0, "avg_logprob": -0.1208233879607858, "compression_ratio": 1.75, "no_speech_prob": 7.1825070335762575e-06}, {"id": 261, "seek": 117804, "start": 1197.44, "end": 1203.24, "text": " something which has to train at least as well as a 20 layer neural network because it kind", "tokens": [746, 597, 575, 281, 3847, 412, 1935, 382, 731, 382, 257, 945, 4583, 18161, 3209, 570, 309, 733], "temperature": 0.0, "avg_logprob": -0.1208233879607858, "compression_ratio": 1.75, "no_speech_prob": 7.1825070335762575e-06}, {"id": 262, "seek": 117804, "start": 1203.24, "end": 1205.32, "text": " of contains that 20 layer neural network.", "tokens": [295, 8306, 300, 945, 4583, 18161, 3209, 13], "temperature": 0.0, "avg_logprob": -0.1208233879607858, "compression_ratio": 1.75, "no_speech_prob": 7.1825070335762575e-06}, {"id": 263, "seek": 120532, "start": 1205.32, "end": 1211.1599999999999, "text": " There's literally a path you can just skip over all the convolutions.", "tokens": [821, 311, 3736, 257, 3100, 291, 393, 445, 10023, 670, 439, 264, 3754, 15892, 13], "temperature": 0.0, "avg_logprob": -0.17910880134219215, "compression_ratio": 1.59375, "no_speech_prob": 2.8571651000675047e-06}, {"id": 264, "seek": 120532, "start": 1211.1599999999999, "end": 1213.8, "text": " And so what happens?", "tokens": [400, 370, 437, 2314, 30], "temperature": 0.0, "avg_logprob": -0.17910880134219215, "compression_ratio": 1.59375, "no_speech_prob": 2.8571651000675047e-06}, {"id": 265, "seek": 120532, "start": 1213.8, "end": 1218.0, "text": " And what happened was he won ImageNet that year.", "tokens": [400, 437, 2011, 390, 415, 1582, 29903, 31890, 300, 1064, 13], "temperature": 0.0, "avg_logprob": -0.17910880134219215, "compression_ratio": 1.59375, "no_speech_prob": 2.8571651000675047e-06}, {"id": 266, "seek": 120532, "start": 1218.0, "end": 1220.32, "text": " He easily won ImageNet that year.", "tokens": [634, 3612, 1582, 29903, 31890, 300, 1064, 13], "temperature": 0.0, "avg_logprob": -0.17910880134219215, "compression_ratio": 1.59375, "no_speech_prob": 2.8571651000675047e-06}, {"id": 267, "seek": 120532, "start": 1220.32, "end": 1228.6399999999999, "text": " And in fact, even today, we had that record breaking result on ImageNet speed training", "tokens": [400, 294, 1186, 11, 754, 965, 11, 321, 632, 300, 2136, 7697, 1874, 322, 29903, 31890, 3073, 3097], "temperature": 0.0, "avg_logprob": -0.17910880134219215, "compression_ratio": 1.59375, "no_speech_prob": 2.8571651000675047e-06}, {"id": 268, "seek": 120532, "start": 1228.6399999999999, "end": 1229.6399999999999, "text": " ourselves.", "tokens": [4175, 13], "temperature": 0.0, "avg_logprob": -0.17910880134219215, "compression_ratio": 1.59375, "no_speech_prob": 2.8571651000675047e-06}, {"id": 269, "seek": 120532, "start": 1229.6399999999999, "end": 1233.4399999999998, "text": " In the last year we used this too.", "tokens": [682, 264, 1036, 1064, 321, 1143, 341, 886, 13], "temperature": 0.0, "avg_logprob": -0.17910880134219215, "compression_ratio": 1.59375, "no_speech_prob": 2.8571651000675047e-06}, {"id": 270, "seek": 123344, "start": 1233.44, "end": 1237.68, "text": " ResNet has been revolutionary.", "tokens": [5015, 31890, 575, 668, 22687, 13], "temperature": 0.0, "avg_logprob": -0.18552992078993055, "compression_ratio": 1.509009009009009, "no_speech_prob": 1.3005321306991391e-05}, {"id": 271, "seek": 123344, "start": 1237.68, "end": 1239.72, "text": " And here's a trick.", "tokens": [400, 510, 311, 257, 4282, 13], "temperature": 0.0, "avg_logprob": -0.18552992078993055, "compression_ratio": 1.509009009009009, "no_speech_prob": 1.3005321306991391e-05}, {"id": 272, "seek": 123344, "start": 1239.72, "end": 1245.68, "text": " If you're interested in doing some research, some novel research, any time you find some", "tokens": [759, 291, 434, 3102, 294, 884, 512, 2132, 11, 512, 7613, 2132, 11, 604, 565, 291, 915, 512], "temperature": 0.0, "avg_logprob": -0.18552992078993055, "compression_ratio": 1.509009009009009, "no_speech_prob": 1.3005321306991391e-05}, {"id": 273, "seek": 123344, "start": 1245.68, "end": 1252.1200000000001, "text": " model for anything, whether it's like medical image segmentation or some kind of GAN or", "tokens": [2316, 337, 1340, 11, 1968, 309, 311, 411, 4625, 3256, 9469, 399, 420, 512, 733, 295, 460, 1770, 420], "temperature": 0.0, "avg_logprob": -0.18552992078993055, "compression_ratio": 1.509009009009009, "no_speech_prob": 1.3005321306991391e-05}, {"id": 274, "seek": 123344, "start": 1252.1200000000001, "end": 1259.4, "text": " whatever, and it was written a couple of years ago, they might have forgotten to put ResNets", "tokens": [2035, 11, 293, 309, 390, 3720, 257, 1916, 295, 924, 2057, 11, 436, 1062, 362, 11832, 281, 829, 5015, 45, 1385], "temperature": 0.0, "avg_logprob": -0.18552992078993055, "compression_ratio": 1.509009009009009, "no_speech_prob": 1.3005321306991391e-05}, {"id": 275, "seek": 123344, "start": 1259.4, "end": 1261.76, "text": " in, ResBlocks.", "tokens": [294, 11, 5015, 33, 34896, 13], "temperature": 0.0, "avg_logprob": -0.18552992078993055, "compression_ratio": 1.509009009009009, "no_speech_prob": 1.3005321306991391e-05}, {"id": 276, "seek": 126176, "start": 1261.76, "end": 1264.08, "text": " This is what we normally call a ResBlock.", "tokens": [639, 307, 437, 321, 5646, 818, 257, 5015, 33, 4102, 13], "temperature": 0.0, "avg_logprob": -0.16708807892851776, "compression_ratio": 1.4485981308411215, "no_speech_prob": 4.0289114622282796e-06}, {"id": 277, "seek": 126176, "start": 1264.08, "end": 1265.92, "text": " They might have forgotten to put ResBlocks in.", "tokens": [814, 1062, 362, 11832, 281, 829, 5015, 33, 34896, 294, 13], "temperature": 0.0, "avg_logprob": -0.16708807892851776, "compression_ratio": 1.4485981308411215, "no_speech_prob": 4.0289114622282796e-06}, {"id": 278, "seek": 126176, "start": 1265.92, "end": 1272.68, "text": " So replace their convolutional path with a bunch of ResBlocks and you'll almost always", "tokens": [407, 7406, 641, 45216, 304, 3100, 365, 257, 3840, 295, 5015, 33, 34896, 293, 291, 603, 1920, 1009], "temperature": 0.0, "avg_logprob": -0.16708807892851776, "compression_ratio": 1.4485981308411215, "no_speech_prob": 4.0289114622282796e-06}, {"id": 279, "seek": 126176, "start": 1272.68, "end": 1274.08, "text": " get better results faster.", "tokens": [483, 1101, 3542, 4663, 13], "temperature": 0.0, "avg_logprob": -0.16708807892851776, "compression_ratio": 1.4485981308411215, "no_speech_prob": 4.0289114622282796e-06}, {"id": 280, "seek": 126176, "start": 1274.08, "end": 1277.04, "text": " It's a good trick.", "tokens": [467, 311, 257, 665, 4282, 13], "temperature": 0.0, "avg_logprob": -0.16708807892851776, "compression_ratio": 1.4485981308411215, "no_speech_prob": 4.0289114622282796e-06}, {"id": 281, "seek": 126176, "start": 1277.04, "end": 1284.16, "text": " So at NeurIPS, which Rachel and I and David all just came back from, and Sylvain, we saw", "tokens": [407, 412, 1734, 374, 40, 6273, 11, 597, 14246, 293, 286, 293, 4389, 439, 445, 1361, 646, 490, 11, 293, 3902, 14574, 491, 11, 321, 1866], "temperature": 0.0, "avg_logprob": -0.16708807892851776, "compression_ratio": 1.4485981308411215, "no_speech_prob": 4.0289114622282796e-06}, {"id": 282, "seek": 128416, "start": 1284.16, "end": 1292.0, "text": " a new presentation where they actually figured out how to visualize the loss surface of a", "tokens": [257, 777, 5860, 689, 436, 767, 8932, 484, 577, 281, 23273, 264, 4470, 3753, 295, 257], "temperature": 0.0, "avg_logprob": -0.1389199933435163, "compression_ratio": 1.6245487364620939, "no_speech_prob": 9.073582987184636e-06}, {"id": 283, "seek": 128416, "start": 1292.0, "end": 1294.24, "text": " neural net, which is really cool.", "tokens": [18161, 2533, 11, 597, 307, 534, 1627, 13], "temperature": 0.0, "avg_logprob": -0.1389199933435163, "compression_ratio": 1.6245487364620939, "no_speech_prob": 9.073582987184636e-06}, {"id": 284, "seek": 128416, "start": 1294.24, "end": 1295.96, "text": " This is a fantastic paper.", "tokens": [639, 307, 257, 5456, 3035, 13], "temperature": 0.0, "avg_logprob": -0.1389199933435163, "compression_ratio": 1.6245487364620939, "no_speech_prob": 9.073582987184636e-06}, {"id": 285, "seek": 128416, "start": 1295.96, "end": 1301.8400000000001, "text": " And anybody who's watching this, lesson seven, is at a point where they will understand most", "tokens": [400, 4472, 567, 311, 1976, 341, 11, 6898, 3407, 11, 307, 412, 257, 935, 689, 436, 486, 1223, 881], "temperature": 0.0, "avg_logprob": -0.1389199933435163, "compression_ratio": 1.6245487364620939, "no_speech_prob": 9.073582987184636e-06}, {"id": 286, "seek": 128416, "start": 1301.8400000000001, "end": 1304.1200000000001, "text": " of the most important concepts in this paper.", "tokens": [295, 264, 881, 1021, 10392, 294, 341, 3035, 13], "temperature": 0.0, "avg_logprob": -0.1389199933435163, "compression_ratio": 1.6245487364620939, "no_speech_prob": 9.073582987184636e-06}, {"id": 287, "seek": 128416, "start": 1304.1200000000001, "end": 1305.76, "text": " You can read this now.", "tokens": [509, 393, 1401, 341, 586, 13], "temperature": 0.0, "avg_logprob": -0.1389199933435163, "compression_ratio": 1.6245487364620939, "no_speech_prob": 9.073582987184636e-06}, {"id": 288, "seek": 128416, "start": 1305.76, "end": 1310.3200000000002, "text": " You won't necessarily get all of it, but I'm sure you'll find it good enough to find it", "tokens": [509, 1582, 380, 4725, 483, 439, 295, 309, 11, 457, 286, 478, 988, 291, 603, 915, 309, 665, 1547, 281, 915, 309], "temperature": 0.0, "avg_logprob": -0.1389199933435163, "compression_ratio": 1.6245487364620939, "no_speech_prob": 9.073582987184636e-06}, {"id": 289, "seek": 128416, "start": 1310.3200000000002, "end": 1311.3200000000002, "text": " interesting.", "tokens": [1880, 13], "temperature": 0.0, "avg_logprob": -0.1389199933435163, "compression_ratio": 1.6245487364620939, "no_speech_prob": 9.073582987184636e-06}, {"id": 290, "seek": 128416, "start": 1311.3200000000002, "end": 1314.0, "text": " And so the big picture was this one.", "tokens": [400, 370, 264, 955, 3036, 390, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.1389199933435163, "compression_ratio": 1.6245487364620939, "no_speech_prob": 9.073582987184636e-06}, {"id": 291, "seek": 131400, "start": 1314.0, "end": 1320.56, "text": " Here's what happens if you draw a picture where kind of X and Y here are two projections", "tokens": [1692, 311, 437, 2314, 498, 291, 2642, 257, 3036, 689, 733, 295, 1783, 293, 398, 510, 366, 732, 32371], "temperature": 0.0, "avg_logprob": -0.09809652594632881, "compression_ratio": 1.568075117370892, "no_speech_prob": 1.6185666027013212e-05}, {"id": 292, "seek": 131400, "start": 1320.56, "end": 1324.92, "text": " of the weight space and Z is the loss.", "tokens": [295, 264, 3364, 1901, 293, 1176, 307, 264, 4470, 13], "temperature": 0.0, "avg_logprob": -0.09809652594632881, "compression_ratio": 1.568075117370892, "no_speech_prob": 1.6185666027013212e-05}, {"id": 293, "seek": 131400, "start": 1324.92, "end": 1331.48, "text": " And so as you move through the weight space, a 56-layer neural network without skip connections", "tokens": [400, 370, 382, 291, 1286, 807, 264, 3364, 1901, 11, 257, 19687, 12, 8376, 260, 18161, 3209, 1553, 10023, 9271], "temperature": 0.0, "avg_logprob": -0.09809652594632881, "compression_ratio": 1.568075117370892, "no_speech_prob": 1.6185666027013212e-05}, {"id": 294, "seek": 131400, "start": 1331.48, "end": 1333.68, "text": " is very, very bumpy.", "tokens": [307, 588, 11, 588, 49400, 13], "temperature": 0.0, "avg_logprob": -0.09809652594632881, "compression_ratio": 1.568075117370892, "no_speech_prob": 1.6185666027013212e-05}, {"id": 295, "seek": 131400, "start": 1333.68, "end": 1341.4, "text": " And that's why this got nowhere because it just got stuck in all these hills and valleys.", "tokens": [400, 300, 311, 983, 341, 658, 11159, 570, 309, 445, 658, 5541, 294, 439, 613, 21379, 293, 45614, 13], "temperature": 0.0, "avg_logprob": -0.09809652594632881, "compression_ratio": 1.568075117370892, "no_speech_prob": 1.6185666027013212e-05}, {"id": 296, "seek": 134140, "start": 1341.4, "end": 1349.52, "text": " The exact same network with identity connections, with skip connections, has this lost landscape.", "tokens": [440, 1900, 912, 3209, 365, 6575, 9271, 11, 365, 10023, 9271, 11, 575, 341, 2731, 9661, 13], "temperature": 0.0, "avg_logprob": -0.1529611825942993, "compression_ratio": 1.4854368932038835, "no_speech_prob": 7.295609975699335e-06}, {"id": 297, "seek": 134140, "start": 1349.52, "end": 1359.88, "text": " So it's kind of interesting how Hurt recognized back in 2015, this shouldn't happen.", "tokens": [407, 309, 311, 733, 295, 1880, 577, 389, 6224, 9823, 646, 294, 7546, 11, 341, 4659, 380, 1051, 13], "temperature": 0.0, "avg_logprob": -0.1529611825942993, "compression_ratio": 1.4854368932038835, "no_speech_prob": 7.295609975699335e-06}, {"id": 298, "seek": 134140, "start": 1359.88, "end": 1361.24, "text": " Here's a way that must fix it.", "tokens": [1692, 311, 257, 636, 300, 1633, 3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.1529611825942993, "compression_ratio": 1.4854368932038835, "no_speech_prob": 7.295609975699335e-06}, {"id": 299, "seek": 134140, "start": 1361.24, "end": 1367.52, "text": " And it took three years before people were able to say, oh, this is kind of why it fixed", "tokens": [400, 309, 1890, 1045, 924, 949, 561, 645, 1075, 281, 584, 11, 1954, 11, 341, 307, 733, 295, 983, 309, 6806], "temperature": 0.0, "avg_logprob": -0.1529611825942993, "compression_ratio": 1.4854368932038835, "no_speech_prob": 7.295609975699335e-06}, {"id": 300, "seek": 134140, "start": 1367.52, "end": 1368.52, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.1529611825942993, "compression_ratio": 1.4854368932038835, "no_speech_prob": 7.295609975699335e-06}, {"id": 301, "seek": 136852, "start": 1368.52, "end": 1373.04, "text": " And then with the batch norm discussion we had a couple of weeks ago, people realizing", "tokens": [400, 550, 365, 264, 15245, 2026, 5017, 321, 632, 257, 1916, 295, 3259, 2057, 11, 561, 16734], "temperature": 0.0, "avg_logprob": -0.19659943458361503, "compression_ratio": 1.4736842105263157, "no_speech_prob": 8.529827027814463e-06}, {"id": 302, "seek": 136852, "start": 1373.04, "end": 1377.92, "text": " a little bit after the fact sometimes what's going on and why it helps.", "tokens": [257, 707, 857, 934, 264, 1186, 2171, 437, 311, 516, 322, 293, 983, 309, 3665, 13], "temperature": 0.0, "avg_logprob": -0.19659943458361503, "compression_ratio": 1.4736842105263157, "no_speech_prob": 8.529827027814463e-06}, {"id": 303, "seek": 136852, "start": 1377.92, "end": 1390.24, "text": " So in our code, we can create a res block in just the way I described.", "tokens": [407, 294, 527, 3089, 11, 321, 393, 1884, 257, 725, 3461, 294, 445, 264, 636, 286, 7619, 13], "temperature": 0.0, "avg_logprob": -0.19659943458361503, "compression_ratio": 1.4736842105263157, "no_speech_prob": 8.529827027814463e-06}, {"id": 304, "seek": 136852, "start": 1390.24, "end": 1392.4, "text": " We create an nn.module.", "tokens": [492, 1884, 364, 297, 77, 13, 8014, 2271, 13], "temperature": 0.0, "avg_logprob": -0.19659943458361503, "compression_ratio": 1.4736842105263157, "no_speech_prob": 8.529827027814463e-06}, {"id": 305, "seek": 136852, "start": 1392.4, "end": 1393.8, "text": " We create two conv layers.", "tokens": [492, 1884, 732, 3754, 7914, 13], "temperature": 0.0, "avg_logprob": -0.19659943458361503, "compression_ratio": 1.4736842105263157, "no_speech_prob": 8.529827027814463e-06}, {"id": 306, "seek": 139380, "start": 1393.8, "end": 1399.44, "text": " Remember, a conv layer is conv2d batch norm relu.", "tokens": [5459, 11, 257, 3754, 4583, 307, 3754, 17, 67, 15245, 2026, 1039, 84, 13], "temperature": 0.0, "avg_logprob": -0.22766692139381586, "compression_ratio": 1.5562130177514792, "no_speech_prob": 4.565406470646849e-06}, {"id": 307, "seek": 139380, "start": 1399.44, "end": 1403.8, "text": " Sorry, conv2d relu batch norm.", "tokens": [4919, 11, 3754, 17, 67, 1039, 84, 15245, 2026, 13], "temperature": 0.0, "avg_logprob": -0.22766692139381586, "compression_ratio": 1.5562130177514792, "no_speech_prob": 4.565406470646849e-06}, {"id": 308, "seek": 139380, "start": 1403.8, "end": 1404.8, "text": " So create two of those.", "tokens": [407, 1884, 732, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.22766692139381586, "compression_ratio": 1.5562130177514792, "no_speech_prob": 4.565406470646849e-06}, {"id": 309, "seek": 139380, "start": 1404.8, "end": 1413.52, "text": " And then in forward, we go conv1 of x, conv2 of that, and then add x.", "tokens": [400, 550, 294, 2128, 11, 321, 352, 3754, 16, 295, 2031, 11, 3754, 17, 295, 300, 11, 293, 550, 909, 2031, 13], "temperature": 0.0, "avg_logprob": -0.22766692139381586, "compression_ratio": 1.5562130177514792, "no_speech_prob": 4.565406470646849e-06}, {"id": 310, "seek": 139380, "start": 1413.52, "end": 1416.52, "text": " There's a res block function already in fast AI.", "tokens": [821, 311, 257, 725, 3461, 2445, 1217, 294, 2370, 7318, 13], "temperature": 0.0, "avg_logprob": -0.22766692139381586, "compression_ratio": 1.5562130177514792, "no_speech_prob": 4.565406470646849e-06}, {"id": 311, "seek": 139380, "start": 1416.52, "end": 1420.22, "text": " So you can just call res block instead.", "tokens": [407, 291, 393, 445, 818, 725, 3461, 2602, 13], "temperature": 0.0, "avg_logprob": -0.22766692139381586, "compression_ratio": 1.5562130177514792, "no_speech_prob": 4.565406470646849e-06}, {"id": 312, "seek": 142022, "start": 1420.22, "end": 1426.0, "text": " And you just pass in something saying how many filters do you want?", "tokens": [400, 291, 445, 1320, 294, 746, 1566, 577, 867, 15995, 360, 291, 528, 30], "temperature": 0.0, "avg_logprob": -0.15240658351353237, "compression_ratio": 1.5726141078838174, "no_speech_prob": 2.0904442408209434e-06}, {"id": 313, "seek": 142022, "start": 1426.0, "end": 1431.2, "text": " So yeah, so there's the res block that I defined in our notebook.", "tokens": [407, 1338, 11, 370, 456, 311, 264, 725, 3461, 300, 286, 7642, 294, 527, 21060, 13], "temperature": 0.0, "avg_logprob": -0.15240658351353237, "compression_ratio": 1.5726141078838174, "no_speech_prob": 2.0904442408209434e-06}, {"id": 314, "seek": 142022, "start": 1431.2, "end": 1437.04, "text": " And so with that res block, we can now take every one of those, just copy the previous", "tokens": [400, 370, 365, 300, 725, 3461, 11, 321, 393, 586, 747, 633, 472, 295, 729, 11, 445, 5055, 264, 3894], "temperature": 0.0, "avg_logprob": -0.15240658351353237, "compression_ratio": 1.5726141078838174, "no_speech_prob": 2.0904442408209434e-06}, {"id": 315, "seek": 142022, "start": 1437.04, "end": 1443.28, "text": " cnn, and after every conv2, except the last one, I added a res block.", "tokens": [269, 26384, 11, 293, 934, 633, 3754, 17, 11, 3993, 264, 1036, 472, 11, 286, 3869, 257, 725, 3461, 13], "temperature": 0.0, "avg_logprob": -0.15240658351353237, "compression_ratio": 1.5726141078838174, "no_speech_prob": 2.0904442408209434e-06}, {"id": 316, "seek": 142022, "start": 1443.28, "end": 1446.6200000000001, "text": " So this has now got three times as many layers.", "tokens": [407, 341, 575, 586, 658, 1045, 1413, 382, 867, 7914, 13], "temperature": 0.0, "avg_logprob": -0.15240658351353237, "compression_ratio": 1.5726141078838174, "no_speech_prob": 2.0904442408209434e-06}, {"id": 317, "seek": 142022, "start": 1446.6200000000001, "end": 1449.16, "text": " So it should be able to do more compute.", "tokens": [407, 309, 820, 312, 1075, 281, 360, 544, 14722, 13], "temperature": 0.0, "avg_logprob": -0.15240658351353237, "compression_ratio": 1.5726141078838174, "no_speech_prob": 2.0904442408209434e-06}, {"id": 318, "seek": 144916, "start": 1449.16, "end": 1452.3400000000001, "text": " But it shouldn't be any harder to optimize.", "tokens": [583, 309, 4659, 380, 312, 604, 6081, 281, 19719, 13], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 319, "seek": 144916, "start": 1452.3400000000001, "end": 1454.0, "text": " So what happens?", "tokens": [407, 437, 2314, 30], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 320, "seek": 144916, "start": 1454.0, "end": 1456.98, "text": " Well, let's just refactor it one more time.", "tokens": [1042, 11, 718, 311, 445, 1895, 15104, 309, 472, 544, 565, 13], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 321, "seek": 144916, "start": 1456.98, "end": 1463.2, "text": " Since I go conv2 res block so many times, let's just pop that into a little mini sequential", "tokens": [4162, 286, 352, 3754, 17, 725, 3461, 370, 867, 1413, 11, 718, 311, 445, 1665, 300, 666, 257, 707, 8382, 42881], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 322, "seek": 144916, "start": 1463.2, "end": 1464.3200000000002, "text": " model here.", "tokens": [2316, 510, 13], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 323, "seek": 144916, "start": 1464.3200000000002, "end": 1466.88, "text": " And so I can refactor that like so.", "tokens": [400, 370, 286, 393, 1895, 15104, 300, 411, 370, 13], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 324, "seek": 144916, "start": 1466.88, "end": 1470.0800000000002, "text": " Keep refactoring your architectures if you're trying novel architectures, because you'll", "tokens": [5527, 1895, 578, 3662, 428, 6331, 1303, 498, 291, 434, 1382, 7613, 6331, 1303, 11, 570, 291, 603], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 325, "seek": 144916, "start": 1470.0800000000002, "end": 1471.88, "text": " make less mistakes.", "tokens": [652, 1570, 8038, 13], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 326, "seek": 144916, "start": 1471.88, "end": 1472.88, "text": " Very few people do this.", "tokens": [4372, 1326, 561, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 327, "seek": 144916, "start": 1472.88, "end": 1477.5600000000002, "text": " Most research code you look at is clunky as all hell.", "tokens": [4534, 2132, 3089, 291, 574, 412, 307, 596, 25837, 382, 439, 4921, 13], "temperature": 0.0, "avg_logprob": -0.12726603872407743, "compression_ratio": 1.6119402985074627, "no_speech_prob": 5.5073028306651395e-06}, {"id": 328, "seek": 147756, "start": 1477.56, "end": 1480.76, "text": " And people often make mistakes in that way, so don't do that.", "tokens": [400, 561, 2049, 652, 8038, 294, 300, 636, 11, 370, 500, 380, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.19888079011595095, "compression_ratio": 1.3801169590643274, "no_speech_prob": 4.936826371704228e-06}, {"id": 329, "seek": 147756, "start": 1480.76, "end": 1487.1599999999999, "text": " You know, you're all coders, so use your coding skills to make life easier.", "tokens": [509, 458, 11, 291, 434, 439, 17656, 433, 11, 370, 764, 428, 17720, 3942, 281, 652, 993, 3571, 13], "temperature": 0.0, "avg_logprob": -0.19888079011595095, "compression_ratio": 1.3801169590643274, "no_speech_prob": 4.936826371704228e-06}, {"id": 330, "seek": 147756, "start": 1487.1599999999999, "end": 1494.44, "text": " OK, so there's my resnet-ish architecture.", "tokens": [2264, 11, 370, 456, 311, 452, 725, 7129, 12, 742, 9482, 13], "temperature": 0.0, "avg_logprob": -0.19888079011595095, "compression_ratio": 1.3801169590643274, "no_speech_prob": 4.936826371704228e-06}, {"id": 331, "seek": 147756, "start": 1494.44, "end": 1500.32, "text": " And lr find as usual, fit for a while.", "tokens": [400, 287, 81, 915, 382, 7713, 11, 3318, 337, 257, 1339, 13], "temperature": 0.0, "avg_logprob": -0.19888079011595095, "compression_ratio": 1.3801169590643274, "no_speech_prob": 4.936826371704228e-06}, {"id": 332, "seek": 147756, "start": 1500.32, "end": 1505.12, "text": " And I get 99.54.", "tokens": [400, 286, 483, 11803, 13, 19563, 13], "temperature": 0.0, "avg_logprob": -0.19888079011595095, "compression_ratio": 1.3801169590643274, "no_speech_prob": 4.936826371704228e-06}, {"id": 333, "seek": 150512, "start": 1505.12, "end": 1511.02, "text": " So that's interesting, because we've trained this literally from scratch with an architecture", "tokens": [407, 300, 311, 1880, 11, 570, 321, 600, 8895, 341, 3736, 490, 8459, 365, 364, 9482], "temperature": 0.0, "avg_logprob": -0.16019628729139054, "compression_ratio": 1.6186770428015564, "no_speech_prob": 1.1298825484118424e-05}, {"id": 334, "seek": 150512, "start": 1511.02, "end": 1512.36, "text": " we built from scratch.", "tokens": [321, 3094, 490, 8459, 13], "temperature": 0.0, "avg_logprob": -0.16019628729139054, "compression_ratio": 1.6186770428015564, "no_speech_prob": 1.1298825484118424e-05}, {"id": 335, "seek": 150512, "start": 1512.36, "end": 1514.3999999999999, "text": " I didn't look up this architecture anywhere.", "tokens": [286, 994, 380, 574, 493, 341, 9482, 4992, 13], "temperature": 0.0, "avg_logprob": -0.16019628729139054, "compression_ratio": 1.6186770428015564, "no_speech_prob": 1.1298825484118424e-05}, {"id": 336, "seek": 150512, "start": 1514.3999999999999, "end": 1517.56, "text": " It's just the first thing that came to mind.", "tokens": [467, 311, 445, 264, 700, 551, 300, 1361, 281, 1575, 13], "temperature": 0.0, "avg_logprob": -0.16019628729139054, "compression_ratio": 1.6186770428015564, "no_speech_prob": 1.1298825484118424e-05}, {"id": 337, "seek": 150512, "start": 1517.56, "end": 1524.3999999999999, "text": " But in terms of where that puts us, 0.45% error is around about the state of the art", "tokens": [583, 294, 2115, 295, 689, 300, 8137, 505, 11, 1958, 13, 8465, 4, 6713, 307, 926, 466, 264, 1785, 295, 264, 1523], "temperature": 0.0, "avg_logprob": -0.16019628729139054, "compression_ratio": 1.6186770428015564, "no_speech_prob": 1.1298825484118424e-05}, {"id": 338, "seek": 150512, "start": 1524.3999999999999, "end": 1528.6, "text": " for this data set as of three or four years ago.", "tokens": [337, 341, 1412, 992, 382, 295, 1045, 420, 1451, 924, 2057, 13], "temperature": 0.0, "avg_logprob": -0.16019628729139054, "compression_ratio": 1.6186770428015564, "no_speech_prob": 1.1298825484118424e-05}, {"id": 339, "seek": 150512, "start": 1528.6, "end": 1534.6, "text": " Now, you know, today MNIST is considered a kind of trivially easy data set.", "tokens": [823, 11, 291, 458, 11, 965, 376, 45, 19756, 307, 4888, 257, 733, 295, 1376, 85, 2270, 1858, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.16019628729139054, "compression_ratio": 1.6186770428015564, "no_speech_prob": 1.1298825484118424e-05}, {"id": 340, "seek": 153460, "start": 1534.6, "end": 1537.3999999999999, "text": " So I'm not saying, like, wow, we've broken some records here.", "tokens": [407, 286, 478, 406, 1566, 11, 411, 11, 6076, 11, 321, 600, 5463, 512, 7724, 510, 13], "temperature": 0.0, "avg_logprob": -0.13002493916725627, "compression_ratio": 1.4978723404255319, "no_speech_prob": 1.321021954936441e-05}, {"id": 341, "seek": 153460, "start": 1537.3999999999999, "end": 1540.04, "text": " People have got beyond 0.45% error.", "tokens": [3432, 362, 658, 4399, 1958, 13, 8465, 4, 6713, 13], "temperature": 0.0, "avg_logprob": -0.13002493916725627, "compression_ratio": 1.4978723404255319, "no_speech_prob": 1.321021954936441e-05}, {"id": 342, "seek": 153460, "start": 1540.04, "end": 1551.56, "text": " But what I'm saying is that this kind of resnet is a genuinely, extremely useful network still", "tokens": [583, 437, 286, 478, 1566, 307, 300, 341, 733, 295, 725, 7129, 307, 257, 17839, 11, 4664, 4420, 3209, 920], "temperature": 0.0, "avg_logprob": -0.13002493916725627, "compression_ratio": 1.4978723404255319, "no_speech_prob": 1.321021954936441e-05}, {"id": 343, "seek": 153460, "start": 1551.56, "end": 1552.56, "text": " today.", "tokens": [965, 13], "temperature": 0.0, "avg_logprob": -0.13002493916725627, "compression_ratio": 1.4978723404255319, "no_speech_prob": 1.321021954936441e-05}, {"id": 344, "seek": 153460, "start": 1552.56, "end": 1557.56, "text": " And this is really all we use in our fast ImageNet training still.", "tokens": [400, 341, 307, 534, 439, 321, 764, 294, 527, 2370, 29903, 31890, 3097, 920, 13], "temperature": 0.0, "avg_logprob": -0.13002493916725627, "compression_ratio": 1.4978723404255319, "no_speech_prob": 1.321021954936441e-05}, {"id": 345, "seek": 153460, "start": 1557.56, "end": 1562.6, "text": " And one of the reasons as well is that it's so popular, so the vendors of the library", "tokens": [400, 472, 295, 264, 4112, 382, 731, 307, 300, 309, 311, 370, 3743, 11, 370, 264, 22056, 295, 264, 6405], "temperature": 0.0, "avg_logprob": -0.13002493916725627, "compression_ratio": 1.4978723404255319, "no_speech_prob": 1.321021954936441e-05}, {"id": 346, "seek": 156260, "start": 1562.6, "end": 1564.9599999999998, "text": " spend a lot of time optimizing it.", "tokens": [3496, 257, 688, 295, 565, 40425, 309, 13], "temperature": 0.0, "avg_logprob": -0.13388218830541238, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6696065358701162e-05}, {"id": 347, "seek": 156260, "start": 1564.9599999999998, "end": 1567.4399999999998, "text": " So things tend to work fast.", "tokens": [407, 721, 3928, 281, 589, 2370, 13], "temperature": 0.0, "avg_logprob": -0.13388218830541238, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6696065358701162e-05}, {"id": 348, "seek": 156260, "start": 1567.4399999999998, "end": 1574.62, "text": " Whereas some more modern style architectures using things like separable or grouped convolutions", "tokens": [13813, 512, 544, 4363, 3758, 6331, 1303, 1228, 721, 411, 3128, 712, 420, 41877, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.13388218830541238, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6696065358701162e-05}, {"id": 349, "seek": 156260, "start": 1574.62, "end": 1579.6, "text": " tend not to actually train very quickly in practice.", "tokens": [3928, 406, 281, 767, 3847, 588, 2661, 294, 3124, 13], "temperature": 0.0, "avg_logprob": -0.13388218830541238, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6696065358701162e-05}, {"id": 350, "seek": 156260, "start": 1579.6, "end": 1585.24, "text": " If you look at the definition of resblock in the fast AI code, you'll see it looks a", "tokens": [759, 291, 574, 412, 264, 7123, 295, 725, 28830, 294, 264, 2370, 7318, 3089, 11, 291, 603, 536, 309, 1542, 257], "temperature": 0.0, "avg_logprob": -0.13388218830541238, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6696065358701162e-05}, {"id": 351, "seek": 156260, "start": 1585.24, "end": 1587.76, "text": " little bit different to this.", "tokens": [707, 857, 819, 281, 341, 13], "temperature": 0.0, "avg_logprob": -0.13388218830541238, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6696065358701162e-05}, {"id": 352, "seek": 156260, "start": 1587.76, "end": 1590.84, "text": " And that's because I've created something called a merge layer.", "tokens": [400, 300, 311, 570, 286, 600, 2942, 746, 1219, 257, 22183, 4583, 13], "temperature": 0.0, "avg_logprob": -0.13388218830541238, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6696065358701162e-05}, {"id": 353, "seek": 159084, "start": 1590.84, "end": 1596.1999999999998, "text": " And a merge layer is something which in the forward, just skip dense for a moment, the", "tokens": [400, 257, 22183, 4583, 307, 746, 597, 294, 264, 2128, 11, 445, 10023, 18011, 337, 257, 1623, 11, 264], "temperature": 0.0, "avg_logprob": -0.1935492446742107, "compression_ratio": 1.6682242990654206, "no_speech_prob": 8.800261639407836e-06}, {"id": 354, "seek": 159084, "start": 1596.1999999999998, "end": 1601.28, "text": " forward says x plus x.orig.", "tokens": [2128, 1619, 2031, 1804, 2031, 13, 20632, 13], "temperature": 0.0, "avg_logprob": -0.1935492446742107, "compression_ratio": 1.6682242990654206, "no_speech_prob": 8.800261639407836e-06}, {"id": 355, "seek": 159084, "start": 1601.28, "end": 1604.4399999999998, "text": " So you can see there's something resnet-ish going on here.", "tokens": [407, 291, 393, 536, 456, 311, 746, 725, 7129, 12, 742, 516, 322, 510, 13], "temperature": 0.0, "avg_logprob": -0.1935492446742107, "compression_ratio": 1.6682242990654206, "no_speech_prob": 8.800261639407836e-06}, {"id": 356, "seek": 159084, "start": 1604.4399999999998, "end": 1605.8799999999999, "text": " What is x.orig?", "tokens": [708, 307, 2031, 13, 20632, 30], "temperature": 0.0, "avg_logprob": -0.1935492446742107, "compression_ratio": 1.6682242990654206, "no_speech_prob": 8.800261639407836e-06}, {"id": 357, "seek": 159084, "start": 1605.8799999999999, "end": 1611.32, "text": " Well, if you create a special kind of sequential model called a sequential ex, so this is like", "tokens": [1042, 11, 498, 291, 1884, 257, 2121, 733, 295, 42881, 2316, 1219, 257, 42881, 454, 11, 370, 341, 307, 411], "temperature": 0.0, "avg_logprob": -0.1935492446742107, "compression_ratio": 1.6682242990654206, "no_speech_prob": 8.800261639407836e-06}, {"id": 358, "seek": 159084, "start": 1611.32, "end": 1616.54, "text": " fast AI's sequential extended, it's just like a normal sequential model.", "tokens": [2370, 7318, 311, 42881, 10913, 11, 309, 311, 445, 411, 257, 2710, 42881, 2316, 13], "temperature": 0.0, "avg_logprob": -0.1935492446742107, "compression_ratio": 1.6682242990654206, "no_speech_prob": 8.800261639407836e-06}, {"id": 359, "seek": 161654, "start": 1616.54, "end": 1621.44, "text": " But we store the input in x.orig, right?", "tokens": [583, 321, 3531, 264, 4846, 294, 2031, 13, 20632, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14586026772208835, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.9637602690636413e-06}, {"id": 360, "seek": 161654, "start": 1621.44, "end": 1629.8799999999999, "text": " And so this here, sequential ex, conv layer, conv layer, merge layer, will do exactly the", "tokens": [400, 370, 341, 510, 11, 42881, 454, 11, 3754, 4583, 11, 3754, 4583, 11, 22183, 4583, 11, 486, 360, 2293, 264], "temperature": 0.0, "avg_logprob": -0.14586026772208835, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.9637602690636413e-06}, {"id": 361, "seek": 161654, "start": 1629.8799999999999, "end": 1632.62, "text": " same as this.", "tokens": [912, 382, 341, 13], "temperature": 0.0, "avg_logprob": -0.14586026772208835, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.9637602690636413e-06}, {"id": 362, "seek": 161654, "start": 1632.62, "end": 1638.5, "text": " So you can create your own variations of resnet blocks very easily with just sequential ex", "tokens": [407, 291, 393, 1884, 428, 1065, 17840, 295, 725, 7129, 8474, 588, 3612, 365, 445, 42881, 454], "temperature": 0.0, "avg_logprob": -0.14586026772208835, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.9637602690636413e-06}, {"id": 363, "seek": 161654, "start": 1638.5, "end": 1642.24, "text": " and merge layer.", "tokens": [293, 22183, 4583, 13], "temperature": 0.0, "avg_logprob": -0.14586026772208835, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.9637602690636413e-06}, {"id": 364, "seek": 161654, "start": 1642.24, "end": 1646.2, "text": " So there's something else here, which is when you create your merge layer, you can optionally", "tokens": [407, 456, 311, 746, 1646, 510, 11, 597, 307, 562, 291, 1884, 428, 22183, 4583, 11, 291, 393, 3614, 379], "temperature": 0.0, "avg_logprob": -0.14586026772208835, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.9637602690636413e-06}, {"id": 365, "seek": 164620, "start": 1646.2, "end": 1648.68, "text": " set dense equals true.", "tokens": [992, 18011, 6915, 2074, 13], "temperature": 0.0, "avg_logprob": -0.10878903071085612, "compression_ratio": 1.5906735751295338, "no_speech_prob": 7.766816452203784e-06}, {"id": 366, "seek": 164620, "start": 1648.68, "end": 1649.68, "text": " What happens if you do?", "tokens": [708, 2314, 498, 291, 360, 30], "temperature": 0.0, "avg_logprob": -0.10878903071085612, "compression_ratio": 1.5906735751295338, "no_speech_prob": 7.766816452203784e-06}, {"id": 367, "seek": 164620, "start": 1649.68, "end": 1656.1200000000001, "text": " Well, if you do, it doesn't go x plus x.orig, it goes cat x, x.orig.", "tokens": [1042, 11, 498, 291, 360, 11, 309, 1177, 380, 352, 2031, 1804, 2031, 13, 20632, 11, 309, 1709, 3857, 2031, 11, 2031, 13, 20632, 13], "temperature": 0.0, "avg_logprob": -0.10878903071085612, "compression_ratio": 1.5906735751295338, "no_speech_prob": 7.766816452203784e-06}, {"id": 368, "seek": 164620, "start": 1656.1200000000001, "end": 1663.96, "text": " In other words, rather than putting a plus in this connection, it does a concatenate.", "tokens": [682, 661, 2283, 11, 2831, 813, 3372, 257, 1804, 294, 341, 4984, 11, 309, 775, 257, 1588, 7186, 473, 13], "temperature": 0.0, "avg_logprob": -0.10878903071085612, "compression_ratio": 1.5906735751295338, "no_speech_prob": 7.766816452203784e-06}, {"id": 369, "seek": 164620, "start": 1663.96, "end": 1671.8, "text": " So that's pretty interesting because what happens is that you have your input coming", "tokens": [407, 300, 311, 1238, 1880, 570, 437, 2314, 307, 300, 291, 362, 428, 4846, 1348], "temperature": 0.0, "avg_logprob": -0.10878903071085612, "compression_ratio": 1.5906735751295338, "no_speech_prob": 7.766816452203784e-06}, {"id": 370, "seek": 164620, "start": 1671.8, "end": 1673.74, "text": " into your res block.", "tokens": [666, 428, 725, 3461, 13], "temperature": 0.0, "avg_logprob": -0.10878903071085612, "compression_ratio": 1.5906735751295338, "no_speech_prob": 7.766816452203784e-06}, {"id": 371, "seek": 167374, "start": 1673.74, "end": 1678.1200000000001, "text": " And once you use concatenate instead of plus, it's not called a res block anymore, it's", "tokens": [400, 1564, 291, 764, 1588, 7186, 473, 2602, 295, 1804, 11, 309, 311, 406, 1219, 257, 725, 3461, 3602, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.10269529636089618, "compression_ratio": 1.872093023255814, "no_speech_prob": 6.143986865936313e-06}, {"id": 372, "seek": 167374, "start": 1678.1200000000001, "end": 1679.1200000000001, "text": " called a dense block.", "tokens": [1219, 257, 18011, 3461, 13], "temperature": 0.0, "avg_logprob": -0.10269529636089618, "compression_ratio": 1.872093023255814, "no_speech_prob": 6.143986865936313e-06}, {"id": 373, "seek": 167374, "start": 1679.1200000000001, "end": 1683.0, "text": " And it's not called a resnet anymore, it's called a densenet.", "tokens": [400, 309, 311, 406, 1219, 257, 725, 7129, 3602, 11, 309, 311, 1219, 257, 24505, 268, 302, 13], "temperature": 0.0, "avg_logprob": -0.10269529636089618, "compression_ratio": 1.872093023255814, "no_speech_prob": 6.143986865936313e-06}, {"id": 374, "seek": 167374, "start": 1683.0, "end": 1687.54, "text": " So the densenet was invented about a year after the resnet.", "tokens": [407, 264, 24505, 268, 302, 390, 14479, 466, 257, 1064, 934, 264, 725, 7129, 13], "temperature": 0.0, "avg_logprob": -0.10269529636089618, "compression_ratio": 1.872093023255814, "no_speech_prob": 6.143986865936313e-06}, {"id": 375, "seek": 167374, "start": 1687.54, "end": 1691.28, "text": " And if you read the densenet paper, it can sound incredibly complex and different, but", "tokens": [400, 498, 291, 1401, 264, 24505, 268, 302, 3035, 11, 309, 393, 1626, 6252, 3997, 293, 819, 11, 457], "temperature": 0.0, "avg_logprob": -0.10269529636089618, "compression_ratio": 1.872093023255814, "no_speech_prob": 6.143986865936313e-06}, {"id": 376, "seek": 167374, "start": 1691.28, "end": 1697.36, "text": " actually it's literally identical, but plus here is replaced with cat.", "tokens": [767, 309, 311, 3736, 14800, 11, 457, 1804, 510, 307, 10772, 365, 3857, 13], "temperature": 0.0, "avg_logprob": -0.10269529636089618, "compression_ratio": 1.872093023255814, "no_speech_prob": 6.143986865936313e-06}, {"id": 377, "seek": 167374, "start": 1697.36, "end": 1702.2, "text": " So you have your input coming into your dense block, right, and you've got a few convolutions", "tokens": [407, 291, 362, 428, 4846, 1348, 666, 428, 18011, 3461, 11, 558, 11, 293, 291, 600, 658, 257, 1326, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.10269529636089618, "compression_ratio": 1.872093023255814, "no_speech_prob": 6.143986865936313e-06}, {"id": 378, "seek": 170220, "start": 1702.2, "end": 1708.46, "text": " in here, and then you've got some output coming out, and then you've got your identity connection.", "tokens": [294, 510, 11, 293, 550, 291, 600, 658, 512, 5598, 1348, 484, 11, 293, 550, 291, 600, 658, 428, 6575, 4984, 13], "temperature": 0.0, "avg_logprob": -0.16751053219749815, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.6185898857656866e-05}, {"id": 379, "seek": 170220, "start": 1708.46, "end": 1713.68, "text": " And remember, it doesn't plus, it concats, so if this is the channel axis, it gets a", "tokens": [400, 1604, 11, 309, 1177, 380, 1804, 11, 309, 1588, 1720, 11, 370, 498, 341, 307, 264, 2269, 10298, 11, 309, 2170, 257], "temperature": 0.0, "avg_logprob": -0.16751053219749815, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.6185898857656866e-05}, {"id": 380, "seek": 170220, "start": 1713.68, "end": 1715.88, "text": " little bit bigger.", "tokens": [707, 857, 3801, 13], "temperature": 0.0, "avg_logprob": -0.16751053219749815, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.6185898857656866e-05}, {"id": 381, "seek": 170220, "start": 1715.88, "end": 1723.16, "text": " And then so we do another dense block, and at the end of that we have all of this coming", "tokens": [400, 550, 370, 321, 360, 1071, 18011, 3461, 11, 293, 412, 264, 917, 295, 300, 321, 362, 439, 295, 341, 1348], "temperature": 0.0, "avg_logprob": -0.16751053219749815, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.6185898857656866e-05}, {"id": 382, "seek": 170220, "start": 1723.16, "end": 1724.16, "text": " in.", "tokens": [294, 13], "temperature": 0.0, "avg_logprob": -0.16751053219749815, "compression_ratio": 1.6480446927374302, "no_speech_prob": 1.6185898857656866e-05}, {"id": 383, "seek": 172416, "start": 1724.16, "end": 1732.68, "text": " So at the end of that we have the result of the convolution as per usual, but this time", "tokens": [407, 412, 264, 917, 295, 300, 321, 362, 264, 1874, 295, 264, 45216, 382, 680, 7713, 11, 457, 341, 565], "temperature": 0.0, "avg_logprob": -0.11437963402789572, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.844785169349052e-06}, {"id": 384, "seek": 172416, "start": 1732.68, "end": 1737.48, "text": " the identity block is that big.", "tokens": [264, 6575, 3461, 307, 300, 955, 13], "temperature": 0.0, "avg_logprob": -0.11437963402789572, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.844785169349052e-06}, {"id": 385, "seek": 172416, "start": 1737.48, "end": 1741.68, "text": " So you can see that what happens is that with dense blocks it's getting bigger and bigger", "tokens": [407, 291, 393, 536, 300, 437, 2314, 307, 300, 365, 18011, 8474, 309, 311, 1242, 3801, 293, 3801], "temperature": 0.0, "avg_logprob": -0.11437963402789572, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.844785169349052e-06}, {"id": 386, "seek": 172416, "start": 1741.68, "end": 1749.24, "text": " and bigger, and kind of interestingly the exact input is still here.", "tokens": [293, 3801, 11, 293, 733, 295, 25873, 264, 1900, 4846, 307, 920, 510, 13], "temperature": 0.0, "avg_logprob": -0.11437963402789572, "compression_ratio": 1.6449704142011834, "no_speech_prob": 3.844785169349052e-06}, {"id": 387, "seek": 174924, "start": 1749.24, "end": 1754.16, "text": " But actually no matter how deep you get, the original input pixels are still there, and", "tokens": [583, 767, 572, 1871, 577, 2452, 291, 483, 11, 264, 3380, 4846, 18668, 366, 920, 456, 11, 293], "temperature": 0.0, "avg_logprob": -0.12915697721677405, "compression_ratio": 1.8974358974358974, "no_speech_prob": 4.222652023599949e-06}, {"id": 388, "seek": 174924, "start": 1754.16, "end": 1756.96, "text": " the original layer one features are still there, and the original layer two features", "tokens": [264, 3380, 4583, 472, 4122, 366, 920, 456, 11, 293, 264, 3380, 4583, 732, 4122], "temperature": 0.0, "avg_logprob": -0.12915697721677405, "compression_ratio": 1.8974358974358974, "no_speech_prob": 4.222652023599949e-06}, {"id": 389, "seek": 174924, "start": 1756.96, "end": 1757.96, "text": " are still there.", "tokens": [366, 920, 456, 13], "temperature": 0.0, "avg_logprob": -0.12915697721677405, "compression_ratio": 1.8974358974358974, "no_speech_prob": 4.222652023599949e-06}, {"id": 390, "seek": 174924, "start": 1757.96, "end": 1764.04, "text": " So as you can imagine, densenets are very memory intensive.", "tokens": [407, 382, 291, 393, 3811, 11, 24505, 268, 1385, 366, 588, 4675, 18957, 13], "temperature": 0.0, "avg_logprob": -0.12915697721677405, "compression_ratio": 1.8974358974358974, "no_speech_prob": 4.222652023599949e-06}, {"id": 391, "seek": 174924, "start": 1764.04, "end": 1768.84, "text": " There are ways to manage this, just from time to time, you can have a regular convolution", "tokens": [821, 366, 2098, 281, 3067, 341, 11, 445, 490, 565, 281, 565, 11, 291, 393, 362, 257, 3890, 45216], "temperature": 0.0, "avg_logprob": -0.12915697721677405, "compression_ratio": 1.8974358974358974, "no_speech_prob": 4.222652023599949e-06}, {"id": 392, "seek": 174924, "start": 1768.84, "end": 1772.8, "text": " that squishes your channels back down, but they are memory intensive.", "tokens": [300, 2339, 16423, 428, 9235, 646, 760, 11, 457, 436, 366, 4675, 18957, 13], "temperature": 0.0, "avg_logprob": -0.12915697721677405, "compression_ratio": 1.8974358974358974, "no_speech_prob": 4.222652023599949e-06}, {"id": 393, "seek": 174924, "start": 1772.8, "end": 1776.6, "text": " But they have very few parameters.", "tokens": [583, 436, 362, 588, 1326, 9834, 13], "temperature": 0.0, "avg_logprob": -0.12915697721677405, "compression_ratio": 1.8974358974358974, "no_speech_prob": 4.222652023599949e-06}, {"id": 394, "seek": 177660, "start": 1776.6, "end": 1783.6399999999999, "text": " So for dealing with small datasets, you should definitely experiment with dense blocks and", "tokens": [407, 337, 6260, 365, 1359, 42856, 11, 291, 820, 2138, 5120, 365, 18011, 8474, 293], "temperature": 0.0, "avg_logprob": -0.14041931288582937, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.178081740566995e-05}, {"id": 395, "seek": 177660, "start": 1783.6399999999999, "end": 1785.48, "text": " densenets.", "tokens": [24505, 268, 1385, 13], "temperature": 0.0, "avg_logprob": -0.14041931288582937, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.178081740566995e-05}, {"id": 396, "seek": 177660, "start": 1785.48, "end": 1789.52, "text": " They tend to work really well on small datasets.", "tokens": [814, 3928, 281, 589, 534, 731, 322, 1359, 42856, 13], "temperature": 0.0, "avg_logprob": -0.14041931288582937, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.178081740566995e-05}, {"id": 397, "seek": 177660, "start": 1789.52, "end": 1794.6, "text": " Also because it's possible to keep those original input pixels all the way down the path, they", "tokens": [2743, 570, 309, 311, 1944, 281, 1066, 729, 3380, 4846, 18668, 439, 264, 636, 760, 264, 3100, 11, 436], "temperature": 0.0, "avg_logprob": -0.14041931288582937, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.178081740566995e-05}, {"id": 398, "seek": 177660, "start": 1794.6, "end": 1796.9399999999998, "text": " work really well for segmentation.", "tokens": [589, 534, 731, 337, 9469, 399, 13], "temperature": 0.0, "avg_logprob": -0.14041931288582937, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.178081740566995e-05}, {"id": 399, "seek": 177660, "start": 1796.9399999999998, "end": 1803.28, "text": " Because for segmentation you want to be able to reconstruct the original resolution of", "tokens": [1436, 337, 9469, 399, 291, 528, 281, 312, 1075, 281, 31499, 264, 3380, 8669, 295], "temperature": 0.0, "avg_logprob": -0.14041931288582937, "compression_ratio": 1.6990740740740742, "no_speech_prob": 2.178081740566995e-05}, {"id": 400, "seek": 180328, "start": 1803.28, "end": 1817.68, "text": " your picture, so having all of those original pixels still there is super helpful.", "tokens": [428, 3036, 11, 370, 1419, 439, 295, 729, 3380, 18668, 920, 456, 307, 1687, 4961, 13], "temperature": 0.0, "avg_logprob": -0.16501906939915248, "compression_ratio": 1.6635071090047393, "no_speech_prob": 9.971282452170271e-06}, {"id": 401, "seek": 180328, "start": 1817.68, "end": 1822.48, "text": " So that's ResNets, and one of the main reasons other than the fact that ResNets are awesome", "tokens": [407, 300, 311, 5015, 45, 1385, 11, 293, 472, 295, 264, 2135, 4112, 661, 813, 264, 1186, 300, 5015, 45, 1385, 366, 3476], "temperature": 0.0, "avg_logprob": -0.16501906939915248, "compression_ratio": 1.6635071090047393, "no_speech_prob": 9.971282452170271e-06}, {"id": 402, "seek": 180328, "start": 1822.48, "end": 1826.84, "text": " to tell you about them is that these skip connections are useful in other places as", "tokens": [281, 980, 291, 466, 552, 307, 300, 613, 10023, 9271, 366, 4420, 294, 661, 3190, 382], "temperature": 0.0, "avg_logprob": -0.16501906939915248, "compression_ratio": 1.6635071090047393, "no_speech_prob": 9.971282452170271e-06}, {"id": 403, "seek": 180328, "start": 1826.84, "end": 1828.68, "text": " well.", "tokens": [731, 13], "temperature": 0.0, "avg_logprob": -0.16501906939915248, "compression_ratio": 1.6635071090047393, "no_speech_prob": 9.971282452170271e-06}, {"id": 404, "seek": 180328, "start": 1828.68, "end": 1833.0, "text": " And it's particularly useful in other places and other ways of designing architectures", "tokens": [400, 309, 311, 4098, 4420, 294, 661, 3190, 293, 661, 2098, 295, 14685, 6331, 1303], "temperature": 0.0, "avg_logprob": -0.16501906939915248, "compression_ratio": 1.6635071090047393, "no_speech_prob": 9.971282452170271e-06}, {"id": 405, "seek": 183300, "start": 1833.0, "end": 1835.32, "text": " for segmentation.", "tokens": [337, 9469, 399, 13], "temperature": 0.0, "avg_logprob": -0.14900824844196278, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.4261480323038995e-05}, {"id": 406, "seek": 183300, "start": 1835.32, "end": 1843.92, "text": " So in building this lesson, I keep trying to take old papers and saying, imagining,", "tokens": [407, 294, 2390, 341, 6898, 11, 286, 1066, 1382, 281, 747, 1331, 10577, 293, 1566, 11, 27798, 11], "temperature": 0.0, "avg_logprob": -0.14900824844196278, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.4261480323038995e-05}, {"id": 407, "seek": 183300, "start": 1843.92, "end": 1848.12, "text": " what would that person have done if they had access to all the modern techniques we have", "tokens": [437, 576, 300, 954, 362, 1096, 498, 436, 632, 2105, 281, 439, 264, 4363, 7512, 321, 362], "temperature": 0.0, "avg_logprob": -0.14900824844196278, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.4261480323038995e-05}, {"id": 408, "seek": 183300, "start": 1848.12, "end": 1851.64, "text": " now, and I try to rebuild them in a more modern style.", "tokens": [586, 11, 293, 286, 853, 281, 16877, 552, 294, 257, 544, 4363, 3758, 13], "temperature": 0.0, "avg_logprob": -0.14900824844196278, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.4261480323038995e-05}, {"id": 409, "seek": 183300, "start": 1851.64, "end": 1856.48, "text": " So I've been really rebuilding this next architecture we're going to look at called a UNET in a", "tokens": [407, 286, 600, 668, 534, 36717, 341, 958, 9482, 321, 434, 516, 281, 574, 412, 1219, 257, 8229, 4850, 294, 257], "temperature": 0.0, "avg_logprob": -0.14900824844196278, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.4261480323038995e-05}, {"id": 410, "seek": 183300, "start": 1856.48, "end": 1859.28, "text": " more modern style recently.", "tokens": [544, 4363, 3758, 3938, 13], "temperature": 0.0, "avg_logprob": -0.14900824844196278, "compression_ratio": 1.6473214285714286, "no_speech_prob": 3.4261480323038995e-05}, {"id": 411, "seek": 185928, "start": 1859.28, "end": 1866.92, "text": " And got to the point now, I keep showing you this semantic segmentation paper with the", "tokens": [400, 658, 281, 264, 935, 586, 11, 286, 1066, 4099, 291, 341, 47982, 9469, 399, 3035, 365, 264], "temperature": 0.0, "avg_logprob": -0.15698588861001506, "compression_ratio": 1.4831460674157304, "no_speech_prob": 1.69490394910099e-05}, {"id": 412, "seek": 185928, "start": 1866.92, "end": 1871.16, "text": " state of the art for CanVid, which was 91.5.", "tokens": [1785, 295, 264, 1523, 337, 1664, 53, 327, 11, 597, 390, 31064, 13, 20, 13], "temperature": 0.0, "avg_logprob": -0.15698588861001506, "compression_ratio": 1.4831460674157304, "no_speech_prob": 1.69490394910099e-05}, {"id": 413, "seek": 185928, "start": 1871.16, "end": 1877.56, "text": " This week I got it up to 94.1 using the architecture I'm about to show you.", "tokens": [639, 1243, 286, 658, 309, 493, 281, 30849, 13, 16, 1228, 264, 9482, 286, 478, 466, 281, 855, 291, 13], "temperature": 0.0, "avg_logprob": -0.15698588861001506, "compression_ratio": 1.4831460674157304, "no_speech_prob": 1.69490394910099e-05}, {"id": 414, "seek": 185928, "start": 1877.56, "end": 1881.44, "text": " So we keep pushing this further and further and further.", "tokens": [407, 321, 1066, 7380, 341, 3052, 293, 3052, 293, 3052, 13], "temperature": 0.0, "avg_logprob": -0.15698588861001506, "compression_ratio": 1.4831460674157304, "no_speech_prob": 1.69490394910099e-05}, {"id": 415, "seek": 188144, "start": 1881.44, "end": 1890.44, "text": " And it really was all about adding all of the modern tricks, many of which I'll show", "tokens": [400, 309, 534, 390, 439, 466, 5127, 439, 295, 264, 4363, 11733, 11, 867, 295, 597, 286, 603, 855], "temperature": 0.0, "avg_logprob": -0.1125750380047297, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.321056333836168e-05}, {"id": 416, "seek": 188144, "start": 1890.44, "end": 1895.04, "text": " you today, some of which we'll see in part two.", "tokens": [291, 965, 11, 512, 295, 597, 321, 603, 536, 294, 644, 732, 13], "temperature": 0.0, "avg_logprob": -0.1125750380047297, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.321056333836168e-05}, {"id": 417, "seek": 188144, "start": 1895.04, "end": 1899.64, "text": " So what we're going to do to get there is we're going to use this UNET.", "tokens": [407, 437, 321, 434, 516, 281, 360, 281, 483, 456, 307, 321, 434, 516, 281, 764, 341, 8229, 4850, 13], "temperature": 0.0, "avg_logprob": -0.1125750380047297, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.321056333836168e-05}, {"id": 418, "seek": 188144, "start": 1899.64, "end": 1901.6000000000001, "text": " So we've used a UNET before.", "tokens": [407, 321, 600, 1143, 257, 8229, 4850, 949, 13], "temperature": 0.0, "avg_logprob": -0.1125750380047297, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.321056333836168e-05}, {"id": 419, "seek": 188144, "start": 1901.6000000000001, "end": 1905.48, "text": " I've improved it a bit since then.", "tokens": [286, 600, 9689, 309, 257, 857, 1670, 550, 13], "temperature": 0.0, "avg_logprob": -0.1125750380047297, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.321056333836168e-05}, {"id": 420, "seek": 188144, "start": 1905.48, "end": 1906.72, "text": " So we've used a UNET before.", "tokens": [407, 321, 600, 1143, 257, 8229, 4850, 949, 13], "temperature": 0.0, "avg_logprob": -0.1125750380047297, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.321056333836168e-05}, {"id": 421, "seek": 188144, "start": 1906.72, "end": 1911.28, "text": " We used it when we did the CanVid segmentation, but we didn't understand what it was doing.", "tokens": [492, 1143, 309, 562, 321, 630, 264, 1664, 53, 327, 9469, 399, 11, 457, 321, 994, 380, 1223, 437, 309, 390, 884, 13], "temperature": 0.0, "avg_logprob": -0.1125750380047297, "compression_ratio": 1.706140350877193, "no_speech_prob": 1.321056333836168e-05}, {"id": 422, "seek": 191128, "start": 1911.28, "end": 1918.92, "text": " So we're now in a position where we can understand what it was doing.", "tokens": [407, 321, 434, 586, 294, 257, 2535, 689, 321, 393, 1223, 437, 309, 390, 884, 13], "temperature": 0.0, "avg_logprob": -0.07399193228107609, "compression_ratio": 1.560693641618497, "no_speech_prob": 9.971804502129089e-06}, {"id": 423, "seek": 191128, "start": 1918.92, "end": 1923.6399999999999, "text": " And so the first thing we need to do is kind of understand the basic idea of how you can", "tokens": [400, 370, 264, 700, 551, 321, 643, 281, 360, 307, 733, 295, 1223, 264, 3875, 1558, 295, 577, 291, 393], "temperature": 0.0, "avg_logprob": -0.07399193228107609, "compression_ratio": 1.560693641618497, "no_speech_prob": 9.971804502129089e-06}, {"id": 424, "seek": 191128, "start": 1923.6399999999999, "end": 1926.84, "text": " do segmentation.", "tokens": [360, 9469, 399, 13], "temperature": 0.0, "avg_logprob": -0.07399193228107609, "compression_ratio": 1.560693641618497, "no_speech_prob": 9.971804502129089e-06}, {"id": 425, "seek": 191128, "start": 1926.84, "end": 1937.04, "text": " So if we go back to our CanVid notebook, in our CanVid notebook you'll remember that basically", "tokens": [407, 498, 321, 352, 646, 281, 527, 1664, 53, 327, 21060, 11, 294, 527, 1664, 53, 327, 21060, 291, 603, 1604, 300, 1936], "temperature": 0.0, "avg_logprob": -0.07399193228107609, "compression_ratio": 1.560693641618497, "no_speech_prob": 9.971804502129089e-06}, {"id": 426, "seek": 193704, "start": 1937.04, "end": 1942.96, "text": " what we were doing is we were taking these photos and adding a class to every single", "tokens": [437, 321, 645, 884, 307, 321, 645, 1940, 613, 5787, 293, 5127, 257, 1508, 281, 633, 2167], "temperature": 0.0, "avg_logprob": -0.12978562064792798, "compression_ratio": 1.4911242603550297, "no_speech_prob": 4.356410045147641e-06}, {"id": 427, "seek": 193704, "start": 1942.96, "end": 1943.96, "text": " pixel.", "tokens": [19261, 13], "temperature": 0.0, "avg_logprob": -0.12978562064792798, "compression_ratio": 1.4911242603550297, "no_speech_prob": 4.356410045147641e-06}, {"id": 428, "seek": 193704, "start": 1943.96, "end": 1950.28, "text": " And so when you go data.showbatch for something which is a segmentation item list, it will", "tokens": [400, 370, 562, 291, 352, 1412, 13, 34436, 65, 852, 337, 746, 597, 307, 257, 9469, 399, 3174, 1329, 11, 309, 486], "temperature": 0.0, "avg_logprob": -0.12978562064792798, "compression_ratio": 1.4911242603550297, "no_speech_prob": 4.356410045147641e-06}, {"id": 429, "seek": 193704, "start": 1950.28, "end": 1955.8799999999999, "text": " automatically show you these color-coded pixels.", "tokens": [6772, 855, 291, 613, 2017, 12, 66, 12340, 18668, 13], "temperature": 0.0, "avg_logprob": -0.12978562064792798, "compression_ratio": 1.4911242603550297, "no_speech_prob": 4.356410045147641e-06}, {"id": 430, "seek": 193704, "start": 1955.8799999999999, "end": 1958.7, "text": " So here's the thing.", "tokens": [407, 510, 311, 264, 551, 13], "temperature": 0.0, "avg_logprob": -0.12978562064792798, "compression_ratio": 1.4911242603550297, "no_speech_prob": 4.356410045147641e-06}, {"id": 431, "seek": 195870, "start": 1958.7, "end": 1967.8, "text": " In order to color-code this as a pedestrian, but this as a bicyclist, it needs to know", "tokens": [682, 1668, 281, 2017, 12, 22332, 341, 382, 257, 33947, 11, 457, 341, 382, 257, 16703, 3474, 468, 11, 309, 2203, 281, 458], "temperature": 0.0, "avg_logprob": -0.12224803147492586, "compression_ratio": 1.9707317073170731, "no_speech_prob": 1.5056631355037098e-06}, {"id": 432, "seek": 195870, "start": 1967.8, "end": 1968.8, "text": " what it is.", "tokens": [437, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.12224803147492586, "compression_ratio": 1.9707317073170731, "no_speech_prob": 1.5056631355037098e-06}, {"id": 433, "seek": 195870, "start": 1968.8, "end": 1971.2, "text": " It needs to actually know that's what a pedestrian looks like.", "tokens": [467, 2203, 281, 767, 458, 300, 311, 437, 257, 33947, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.12224803147492586, "compression_ratio": 1.9707317073170731, "no_speech_prob": 1.5056631355037098e-06}, {"id": 434, "seek": 195870, "start": 1971.2, "end": 1973.2, "text": " And it needs to know that's exactly where the pedestrian is.", "tokens": [400, 309, 2203, 281, 458, 300, 311, 2293, 689, 264, 33947, 307, 13], "temperature": 0.0, "avg_logprob": -0.12224803147492586, "compression_ratio": 1.9707317073170731, "no_speech_prob": 1.5056631355037098e-06}, {"id": 435, "seek": 195870, "start": 1973.2, "end": 1976.6000000000001, "text": " And this is the arm of the pedestrian and not part of their shopping basket.", "tokens": [400, 341, 307, 264, 3726, 295, 264, 33947, 293, 406, 644, 295, 641, 8688, 8390, 13], "temperature": 0.0, "avg_logprob": -0.12224803147492586, "compression_ratio": 1.9707317073170731, "no_speech_prob": 1.5056631355037098e-06}, {"id": 436, "seek": 195870, "start": 1976.6000000000001, "end": 1981.96, "text": " It needs to really understand a lot about this picture to do this task.", "tokens": [467, 2203, 281, 534, 1223, 257, 688, 466, 341, 3036, 281, 360, 341, 5633, 13], "temperature": 0.0, "avg_logprob": -0.12224803147492586, "compression_ratio": 1.9707317073170731, "no_speech_prob": 1.5056631355037098e-06}, {"id": 437, "seek": 195870, "start": 1981.96, "end": 1983.56, "text": " And it really does do this task.", "tokens": [400, 309, 534, 775, 360, 341, 5633, 13], "temperature": 0.0, "avg_logprob": -0.12224803147492586, "compression_ratio": 1.9707317073170731, "no_speech_prob": 1.5056631355037098e-06}, {"id": 438, "seek": 198356, "start": 1983.56, "end": 1991.36, "text": " Like when you looked at the results of our top model, it's, you know, I can't see a single", "tokens": [1743, 562, 291, 2956, 412, 264, 3542, 295, 527, 1192, 2316, 11, 309, 311, 11, 291, 458, 11, 286, 393, 380, 536, 257, 2167], "temperature": 0.0, "avg_logprob": -0.13502488046322228, "compression_ratio": 1.6186046511627907, "no_speech_prob": 4.637750407709973e-06}, {"id": 439, "seek": 198356, "start": 1991.36, "end": 1993.76, "text": " pixel by looking at it by eye.", "tokens": [19261, 538, 1237, 412, 309, 538, 3313, 13], "temperature": 0.0, "avg_logprob": -0.13502488046322228, "compression_ratio": 1.6186046511627907, "no_speech_prob": 4.637750407709973e-06}, {"id": 440, "seek": 198356, "start": 1993.76, "end": 1996.48, "text": " I know there's a few wrong, but I can't see the ones that are wrong.", "tokens": [286, 458, 456, 311, 257, 1326, 2085, 11, 457, 286, 393, 380, 536, 264, 2306, 300, 366, 2085, 13], "temperature": 0.0, "avg_logprob": -0.13502488046322228, "compression_ratio": 1.6186046511627907, "no_speech_prob": 4.637750407709973e-06}, {"id": 441, "seek": 198356, "start": 1996.48, "end": 1998.58, "text": " It's that accurate.", "tokens": [467, 311, 300, 8559, 13], "temperature": 0.0, "avg_logprob": -0.13502488046322228, "compression_ratio": 1.6186046511627907, "no_speech_prob": 4.637750407709973e-06}, {"id": 442, "seek": 198356, "start": 1998.58, "end": 1999.6799999999998, "text": " So how does it do that?", "tokens": [407, 577, 775, 309, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.13502488046322228, "compression_ratio": 1.6186046511627907, "no_speech_prob": 4.637750407709973e-06}, {"id": 443, "seek": 198356, "start": 1999.6799999999998, "end": 2007.32, "text": " So the way that we're doing it to get these really, really good results is, not surprisingly,", "tokens": [407, 264, 636, 300, 321, 434, 884, 309, 281, 483, 613, 534, 11, 534, 665, 3542, 307, 11, 406, 17600, 11], "temperature": 0.0, "avg_logprob": -0.13502488046322228, "compression_ratio": 1.6186046511627907, "no_speech_prob": 4.637750407709973e-06}, {"id": 444, "seek": 198356, "start": 2007.32, "end": 2009.28, "text": " using pre-training.", "tokens": [1228, 659, 12, 17227, 1760, 13], "temperature": 0.0, "avg_logprob": -0.13502488046322228, "compression_ratio": 1.6186046511627907, "no_speech_prob": 4.637750407709973e-06}, {"id": 445, "seek": 200928, "start": 2009.28, "end": 2020.94, "text": " So we start with a ResNet 34, and you can see that here, UNET learner data, comma, models.resnet34.", "tokens": [407, 321, 722, 365, 257, 5015, 31890, 12790, 11, 293, 291, 393, 536, 300, 510, 11, 8229, 4850, 33347, 1412, 11, 22117, 11, 5245, 13, 495, 7129, 12249, 13], "temperature": 0.0, "avg_logprob": -0.17072573052831444, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.966905751440208e-06}, {"id": 446, "seek": 200928, "start": 2020.94, "end": 2025.6399999999999, "text": " And if you don't say pre-trained equals false, by default you get pre-trained equals true,", "tokens": [400, 498, 291, 500, 380, 584, 659, 12, 17227, 2001, 6915, 7908, 11, 538, 7576, 291, 483, 659, 12, 17227, 2001, 6915, 2074, 11], "temperature": 0.0, "avg_logprob": -0.17072573052831444, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.966905751440208e-06}, {"id": 447, "seek": 200928, "start": 2025.6399999999999, "end": 2028.8799999999999, "text": " because why not?", "tokens": [570, 983, 406, 30], "temperature": 0.0, "avg_logprob": -0.17072573052831444, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.966905751440208e-06}, {"id": 448, "seek": 200928, "start": 2028.8799999999999, "end": 2037.36, "text": " So we start with a ResNet 34, which starts with a big image.", "tokens": [407, 321, 722, 365, 257, 5015, 31890, 12790, 11, 597, 3719, 365, 257, 955, 3256, 13], "temperature": 0.0, "avg_logprob": -0.17072573052831444, "compression_ratio": 1.558139534883721, "no_speech_prob": 3.966905751440208e-06}, {"id": 449, "seek": 203736, "start": 2037.36, "end": 2040.3999999999999, "text": " So in this case, this is from the UNET paper now.", "tokens": [407, 294, 341, 1389, 11, 341, 307, 490, 264, 8229, 4850, 3035, 586, 13], "temperature": 0.0, "avg_logprob": -0.13805416883048366, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.7761767594492994e-05}, {"id": 450, "seek": 203736, "start": 2040.3999999999999, "end": 2045.04, "text": " Their images, they started with one channel by 572 by 572.", "tokens": [6710, 5267, 11, 436, 1409, 365, 472, 2269, 538, 21423, 17, 538, 21423, 17, 13], "temperature": 0.0, "avg_logprob": -0.13805416883048366, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.7761767594492994e-05}, {"id": 451, "seek": 203736, "start": 2045.04, "end": 2048.48, "text": " This is for medical imaging segmentation.", "tokens": [639, 307, 337, 4625, 25036, 9469, 399, 13], "temperature": 0.0, "avg_logprob": -0.13805416883048366, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.7761767594492994e-05}, {"id": 452, "seek": 203736, "start": 2048.48, "end": 2055.2, "text": " So after your stride two conv, they're doubling the number of channels to 128, and they're", "tokens": [407, 934, 428, 1056, 482, 732, 3754, 11, 436, 434, 33651, 264, 1230, 295, 9235, 281, 29810, 11, 293, 436, 434], "temperature": 0.0, "avg_logprob": -0.13805416883048366, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.7761767594492994e-05}, {"id": 453, "seek": 203736, "start": 2055.2, "end": 2059.72, "text": " halving the size, so they're now down to 280 by 280.", "tokens": [7523, 798, 264, 2744, 11, 370, 436, 434, 586, 760, 281, 41229, 538, 41229, 13], "temperature": 0.0, "avg_logprob": -0.13805416883048366, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.7761767594492994e-05}, {"id": 454, "seek": 203736, "start": 2059.72, "end": 2064.48, "text": " In this original UNET paper, they didn't add any padding, so they lost a pixel on each", "tokens": [682, 341, 3380, 8229, 4850, 3035, 11, 436, 994, 380, 909, 604, 39562, 11, 370, 436, 2731, 257, 19261, 322, 1184], "temperature": 0.0, "avg_logprob": -0.13805416883048366, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.7761767594492994e-05}, {"id": 455, "seek": 203736, "start": 2064.48, "end": 2066.08, "text": " side each time they did a conv.", "tokens": [1252, 1184, 565, 436, 630, 257, 3754, 13], "temperature": 0.0, "avg_logprob": -0.13805416883048366, "compression_ratio": 1.6454183266932272, "no_speech_prob": 1.7761767594492994e-05}, {"id": 456, "seek": 206608, "start": 2066.08, "end": 2067.96, "text": " That's why you're losing these two.", "tokens": [663, 311, 983, 291, 434, 7027, 613, 732, 13], "temperature": 0.0, "avg_logprob": -0.13922827460549095, "compression_ratio": 1.751269035532995, "no_speech_prob": 4.49496837973129e-06}, {"id": 457, "seek": 206608, "start": 2067.96, "end": 2073.04, "text": " So basically half the size, and then half the size, and then half the size, and then", "tokens": [407, 1936, 1922, 264, 2744, 11, 293, 550, 1922, 264, 2744, 11, 293, 550, 1922, 264, 2744, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.13922827460549095, "compression_ratio": 1.751269035532995, "no_speech_prob": 4.49496837973129e-06}, {"id": 458, "seek": 206608, "start": 2073.04, "end": 2079.7799999999997, "text": " half the size, until they're down to 28 by 28 with 1,024 channels.", "tokens": [1922, 264, 2744, 11, 1826, 436, 434, 760, 281, 7562, 538, 7562, 365, 502, 11, 15, 7911, 9235, 13], "temperature": 0.0, "avg_logprob": -0.13922827460549095, "compression_ratio": 1.751269035532995, "no_speech_prob": 4.49496837973129e-06}, {"id": 459, "seek": 206608, "start": 2079.7799999999997, "end": 2086.56, "text": " So that's what the UNET's downsampling path, this is what the downsampling path looked", "tokens": [407, 300, 311, 437, 264, 8229, 4850, 311, 760, 19988, 11970, 3100, 11, 341, 307, 437, 264, 760, 19988, 11970, 3100, 2956], "temperature": 0.0, "avg_logprob": -0.13922827460549095, "compression_ratio": 1.751269035532995, "no_speech_prob": 4.49496837973129e-06}, {"id": 460, "seek": 206608, "start": 2086.56, "end": 2087.56, "text": " like.", "tokens": [411, 13], "temperature": 0.0, "avg_logprob": -0.13922827460549095, "compression_ratio": 1.751269035532995, "no_speech_prob": 4.49496837973129e-06}, {"id": 461, "seek": 206608, "start": 2087.56, "end": 2090.7599999999998, "text": " Ours is just a ResNet 34.", "tokens": [422, 2156, 307, 445, 257, 5015, 31890, 12790, 13], "temperature": 0.0, "avg_logprob": -0.13922827460549095, "compression_ratio": 1.751269035532995, "no_speech_prob": 4.49496837973129e-06}, {"id": 462, "seek": 206608, "start": 2090.7599999999998, "end": 2095.52, "text": " So you can see it here, learn.summary.", "tokens": [407, 291, 393, 536, 309, 510, 11, 1466, 13, 82, 40879, 822, 13], "temperature": 0.0, "avg_logprob": -0.13922827460549095, "compression_ratio": 1.751269035532995, "no_speech_prob": 4.49496837973129e-06}, {"id": 463, "seek": 209552, "start": 2095.52, "end": 2101.08, "text": " This is literally a ResNet 34.", "tokens": [639, 307, 3736, 257, 5015, 31890, 12790, 13], "temperature": 0.0, "avg_logprob": -0.1294825330693671, "compression_ratio": 1.4976303317535544, "no_speech_prob": 5.3380181270767935e-06}, {"id": 464, "seek": 209552, "start": 2101.08, "end": 2108.16, "text": " So you can see that the size keeps halving, channels keep going up, and so forth.", "tokens": [407, 291, 393, 536, 300, 264, 2744, 5965, 7523, 798, 11, 9235, 1066, 516, 493, 11, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.1294825330693671, "compression_ratio": 1.4976303317535544, "no_speech_prob": 5.3380181270767935e-06}, {"id": 465, "seek": 209552, "start": 2108.16, "end": 2114.48, "text": " So eventually you've got down to a point where if you use a UNET architecture, it's 28 by", "tokens": [407, 4728, 291, 600, 658, 760, 281, 257, 935, 689, 498, 291, 764, 257, 8229, 4850, 9482, 11, 309, 311, 7562, 538], "temperature": 0.0, "avg_logprob": -0.1294825330693671, "compression_ratio": 1.4976303317535544, "no_speech_prob": 5.3380181270767935e-06}, {"id": 466, "seek": 209552, "start": 2114.48, "end": 2116.48, "text": " 28 with 1,024 channels.", "tokens": [7562, 365, 502, 11, 15, 7911, 9235, 13], "temperature": 0.0, "avg_logprob": -0.1294825330693671, "compression_ratio": 1.4976303317535544, "no_speech_prob": 5.3380181270767935e-06}, {"id": 467, "seek": 209552, "start": 2116.48, "end": 2124.74, "text": " With the ResNet architecture, with a 224 pixel input, it would be 512 channels by 7 by 7.", "tokens": [2022, 264, 5015, 31890, 9482, 11, 365, 257, 5853, 19, 19261, 4846, 11, 309, 576, 312, 1025, 4762, 9235, 538, 1614, 538, 1614, 13], "temperature": 0.0, "avg_logprob": -0.1294825330693671, "compression_ratio": 1.4976303317535544, "no_speech_prob": 5.3380181270767935e-06}, {"id": 468, "seek": 212474, "start": 2124.74, "end": 2129.68, "text": " So it's a pretty small grid size on this feature map.", "tokens": [407, 309, 311, 257, 1238, 1359, 10748, 2744, 322, 341, 4111, 4471, 13], "temperature": 0.0, "avg_logprob": -0.08492011058179638, "compression_ratio": 1.5372340425531914, "no_speech_prob": 2.0580268937919755e-06}, {"id": 469, "seek": 212474, "start": 2129.68, "end": 2137.68, "text": " Somehow we've got to end up with something which is the same size as our original picture.", "tokens": [28357, 321, 600, 658, 281, 917, 493, 365, 746, 597, 307, 264, 912, 2744, 382, 527, 3380, 3036, 13], "temperature": 0.0, "avg_logprob": -0.08492011058179638, "compression_ratio": 1.5372340425531914, "no_speech_prob": 2.0580268937919755e-06}, {"id": 470, "seek": 212474, "start": 2137.68, "end": 2138.8599999999997, "text": " So how do we do that?", "tokens": [407, 577, 360, 321, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.08492011058179638, "compression_ratio": 1.5372340425531914, "no_speech_prob": 2.0580268937919755e-06}, {"id": 471, "seek": 212474, "start": 2138.8599999999997, "end": 2144.8399999999997, "text": " How do you do computation which increases the grid size?", "tokens": [1012, 360, 291, 360, 24903, 597, 8637, 264, 10748, 2744, 30], "temperature": 0.0, "avg_logprob": -0.08492011058179638, "compression_ratio": 1.5372340425531914, "no_speech_prob": 2.0580268937919755e-06}, {"id": 472, "seek": 212474, "start": 2144.8399999999997, "end": 2149.3599999999997, "text": " Well we don't have a way to do that in our current bag of tricks.", "tokens": [1042, 321, 500, 380, 362, 257, 636, 281, 360, 300, 294, 527, 2190, 3411, 295, 11733, 13], "temperature": 0.0, "avg_logprob": -0.08492011058179638, "compression_ratio": 1.5372340425531914, "no_speech_prob": 2.0580268937919755e-06}, {"id": 473, "seek": 214936, "start": 2149.36, "end": 2156.08, "text": " We can use a stride 1 conv to do computation and keep grid size, or a stride 2 conv to", "tokens": [492, 393, 764, 257, 1056, 482, 502, 3754, 281, 360, 24903, 293, 1066, 10748, 2744, 11, 420, 257, 1056, 482, 568, 3754, 281], "temperature": 0.0, "avg_logprob": -0.11465401993584387, "compression_ratio": 1.7731958762886597, "no_speech_prob": 4.784954398928676e-06}, {"id": 474, "seek": 214936, "start": 2156.08, "end": 2158.7200000000003, "text": " do computation and halve the grid size.", "tokens": [360, 24903, 293, 7523, 303, 264, 10748, 2744, 13], "temperature": 0.0, "avg_logprob": -0.11465401993584387, "compression_ratio": 1.7731958762886597, "no_speech_prob": 4.784954398928676e-06}, {"id": 475, "seek": 214936, "start": 2158.7200000000003, "end": 2160.48, "text": " So how do we double the grid size?", "tokens": [407, 577, 360, 321, 3834, 264, 10748, 2744, 30], "temperature": 0.0, "avg_logprob": -0.11465401993584387, "compression_ratio": 1.7731958762886597, "no_speech_prob": 4.784954398928676e-06}, {"id": 476, "seek": 214936, "start": 2160.48, "end": 2169.1200000000003, "text": " We do a stride half conv, also known as a deconvolution, also known as a transposed", "tokens": [492, 360, 257, 1056, 482, 1922, 3754, 11, 611, 2570, 382, 257, 979, 266, 85, 3386, 11, 611, 2570, 382, 257, 7132, 1744], "temperature": 0.0, "avg_logprob": -0.11465401993584387, "compression_ratio": 1.7731958762886597, "no_speech_prob": 4.784954398928676e-06}, {"id": 477, "seek": 214936, "start": 2169.1200000000003, "end": 2171.36, "text": " convolution.", "tokens": [45216, 13], "temperature": 0.0, "avg_logprob": -0.11465401993584387, "compression_ratio": 1.7731958762886597, "no_speech_prob": 4.784954398928676e-06}, {"id": 478, "seek": 214936, "start": 2171.36, "end": 2176.1400000000003, "text": " There is a fantastic paper called A Guide to Convolution Arithmetic for Deep Learning", "tokens": [821, 307, 257, 5456, 3035, 1219, 316, 18727, 281, 2656, 85, 3386, 1587, 41179, 337, 14895, 15205], "temperature": 0.0, "avg_logprob": -0.11465401993584387, "compression_ratio": 1.7731958762886597, "no_speech_prob": 4.784954398928676e-06}, {"id": 479, "seek": 217614, "start": 2176.14, "end": 2182.3199999999997, "text": " that shows a great picture of exactly what does a 3 by 3 kernel stride half conv look", "tokens": [300, 3110, 257, 869, 3036, 295, 2293, 437, 775, 257, 805, 538, 805, 28256, 1056, 482, 1922, 3754, 574], "temperature": 0.0, "avg_logprob": -0.10641888685004655, "compression_ratio": 1.5670103092783505, "no_speech_prob": 5.173818863113411e-06}, {"id": 480, "seek": 217614, "start": 2182.3199999999997, "end": 2183.3199999999997, "text": " like.", "tokens": [411, 13], "temperature": 0.0, "avg_logprob": -0.10641888685004655, "compression_ratio": 1.5670103092783505, "no_speech_prob": 5.173818863113411e-06}, {"id": 481, "seek": 217614, "start": 2183.3199999999997, "end": 2184.3199999999997, "text": " And it's literally this.", "tokens": [400, 309, 311, 3736, 341, 13], "temperature": 0.0, "avg_logprob": -0.10641888685004655, "compression_ratio": 1.5670103092783505, "no_speech_prob": 5.173818863113411e-06}, {"id": 482, "seek": 217614, "start": 2184.3199999999997, "end": 2192.6, "text": " If you have a 2 by 2 input, so the blue squares are the 2 by 2 input, you add not only 2 pixels", "tokens": [759, 291, 362, 257, 568, 538, 568, 4846, 11, 370, 264, 3344, 19368, 366, 264, 568, 538, 568, 4846, 11, 291, 909, 406, 787, 568, 18668], "temperature": 0.0, "avg_logprob": -0.10641888685004655, "compression_ratio": 1.5670103092783505, "no_speech_prob": 5.173818863113411e-06}, {"id": 483, "seek": 217614, "start": 2192.6, "end": 2201.24, "text": " of padding all around the outside, but you also add a pixel of padding between every", "tokens": [295, 39562, 439, 926, 264, 2380, 11, 457, 291, 611, 909, 257, 19261, 295, 39562, 1296, 633], "temperature": 0.0, "avg_logprob": -0.10641888685004655, "compression_ratio": 1.5670103092783505, "no_speech_prob": 5.173818863113411e-06}, {"id": 484, "seek": 217614, "start": 2201.24, "end": 2203.48, "text": " pixel.", "tokens": [19261, 13], "temperature": 0.0, "avg_logprob": -0.10641888685004655, "compression_ratio": 1.5670103092783505, "no_speech_prob": 5.173818863113411e-06}, {"id": 485, "seek": 220348, "start": 2203.48, "end": 2209.16, "text": " And so now if we put this 3 by 3 kernel here and then here and then here, you see how the", "tokens": [400, 370, 586, 498, 321, 829, 341, 805, 538, 805, 28256, 510, 293, 550, 510, 293, 550, 510, 11, 291, 536, 577, 264], "temperature": 0.0, "avg_logprob": -0.12337353706359863, "compression_ratio": 1.6734693877551021, "no_speech_prob": 9.516124919173308e-06}, {"id": 486, "seek": 220348, "start": 2209.16, "end": 2212.16, "text": " 3 by 3 kernel is just moving across it in the usual way?", "tokens": [805, 538, 805, 28256, 307, 445, 2684, 2108, 309, 294, 264, 7713, 636, 30], "temperature": 0.0, "avg_logprob": -0.12337353706359863, "compression_ratio": 1.6734693877551021, "no_speech_prob": 9.516124919173308e-06}, {"id": 487, "seek": 220348, "start": 2212.16, "end": 2219.04, "text": " You will end up going from a 2 by 2 output to a 5 by 5 output.", "tokens": [509, 486, 917, 493, 516, 490, 257, 568, 538, 568, 5598, 281, 257, 1025, 538, 1025, 5598, 13], "temperature": 0.0, "avg_logprob": -0.12337353706359863, "compression_ratio": 1.6734693877551021, "no_speech_prob": 9.516124919173308e-06}, {"id": 488, "seek": 220348, "start": 2219.04, "end": 2223.2400000000002, "text": " So if you only added one pixel of padding around the outside, you would end up with", "tokens": [407, 498, 291, 787, 3869, 472, 19261, 295, 39562, 926, 264, 2380, 11, 291, 576, 917, 493, 365], "temperature": 0.0, "avg_logprob": -0.12337353706359863, "compression_ratio": 1.6734693877551021, "no_speech_prob": 9.516124919173308e-06}, {"id": 489, "seek": 220348, "start": 2223.2400000000002, "end": 2227.6, "text": " a 3 by 3 output.", "tokens": [257, 805, 538, 805, 5598, 13], "temperature": 0.0, "avg_logprob": -0.12337353706359863, "compression_ratio": 1.6734693877551021, "no_speech_prob": 9.516124919173308e-06}, {"id": 490, "seek": 220348, "start": 2227.6, "end": 2230.64, "text": " So sorry, 4 by 4.", "tokens": [407, 2597, 11, 1017, 538, 1017, 13], "temperature": 0.0, "avg_logprob": -0.12337353706359863, "compression_ratio": 1.6734693877551021, "no_speech_prob": 9.516124919173308e-06}, {"id": 491, "seek": 223064, "start": 2230.64, "end": 2238.2799999999997, "text": " So this is how you can increase the resolution.", "tokens": [407, 341, 307, 577, 291, 393, 3488, 264, 8669, 13], "temperature": 0.0, "avg_logprob": -0.14383771159861347, "compression_ratio": 1.6044444444444443, "no_speech_prob": 3.393097813386703e-06}, {"id": 492, "seek": 223064, "start": 2238.2799999999997, "end": 2247.2, "text": " This was the way people did it until maybe a year or two ago.", "tokens": [639, 390, 264, 636, 561, 630, 309, 1826, 1310, 257, 1064, 420, 732, 2057, 13], "temperature": 0.0, "avg_logprob": -0.14383771159861347, "compression_ratio": 1.6044444444444443, "no_speech_prob": 3.393097813386703e-06}, {"id": 493, "seek": 223064, "start": 2247.2, "end": 2251.6, "text": " That's another trick for improving things you find online, because this is actually", "tokens": [663, 311, 1071, 4282, 337, 11470, 721, 291, 915, 2950, 11, 570, 341, 307, 767], "temperature": 0.0, "avg_logprob": -0.14383771159861347, "compression_ratio": 1.6044444444444443, "no_speech_prob": 3.393097813386703e-06}, {"id": 494, "seek": 223064, "start": 2251.6, "end": 2252.6, "text": " a dumb way to do it.", "tokens": [257, 10316, 636, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.14383771159861347, "compression_ratio": 1.6044444444444443, "no_speech_prob": 3.393097813386703e-06}, {"id": 495, "seek": 223064, "start": 2252.6, "end": 2255.46, "text": " And it's kind of obvious it's a dumb way to do it for a couple of reasons.", "tokens": [400, 309, 311, 733, 295, 6322, 309, 311, 257, 10316, 636, 281, 360, 309, 337, 257, 1916, 295, 4112, 13], "temperature": 0.0, "avg_logprob": -0.14383771159861347, "compression_ratio": 1.6044444444444443, "no_speech_prob": 3.393097813386703e-06}, {"id": 496, "seek": 223064, "start": 2255.46, "end": 2258.4, "text": " One is that, have a look at this.", "tokens": [1485, 307, 300, 11, 362, 257, 574, 412, 341, 13], "temperature": 0.0, "avg_logprob": -0.14383771159861347, "compression_ratio": 1.6044444444444443, "no_speech_prob": 3.393097813386703e-06}, {"id": 497, "seek": 223064, "start": 2258.4, "end": 2260.48, "text": " Nearly all of those pixels are white.", "tokens": [38000, 439, 295, 729, 18668, 366, 2418, 13], "temperature": 0.0, "avg_logprob": -0.14383771159861347, "compression_ratio": 1.6044444444444443, "no_speech_prob": 3.393097813386703e-06}, {"id": 498, "seek": 226048, "start": 2260.48, "end": 2262.48, "text": " They're nearly all zeros.", "tokens": [814, 434, 6217, 439, 35193, 13], "temperature": 0.0, "avg_logprob": -0.13804779602931097, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.3006784683966544e-05}, {"id": 499, "seek": 226048, "start": 2262.48, "end": 2264.2, "text": " So what a waste.", "tokens": [407, 437, 257, 5964, 13], "temperature": 0.0, "avg_logprob": -0.13804779602931097, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.3006784683966544e-05}, {"id": 500, "seek": 226048, "start": 2264.2, "end": 2265.6, "text": " What a waste of time.", "tokens": [708, 257, 5964, 295, 565, 13], "temperature": 0.0, "avg_logprob": -0.13804779602931097, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.3006784683966544e-05}, {"id": 501, "seek": 226048, "start": 2265.6, "end": 2267.08, "text": " What a waste of computation.", "tokens": [708, 257, 5964, 295, 24903, 13], "temperature": 0.0, "avg_logprob": -0.13804779602931097, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.3006784683966544e-05}, {"id": 502, "seek": 226048, "start": 2267.08, "end": 2269.32, "text": " There's just nothing going on there.", "tokens": [821, 311, 445, 1825, 516, 322, 456, 13], "temperature": 0.0, "avg_logprob": -0.13804779602931097, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.3006784683966544e-05}, {"id": 503, "seek": 226048, "start": 2269.32, "end": 2280.6, "text": " Also this one, when you get down to that 3 by 3 area, 2 out of the 9 pixels are non-white,", "tokens": [2743, 341, 472, 11, 562, 291, 483, 760, 281, 300, 805, 538, 805, 1859, 11, 568, 484, 295, 264, 1722, 18668, 366, 2107, 12, 28865, 11], "temperature": 0.0, "avg_logprob": -0.13804779602931097, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.3006784683966544e-05}, {"id": 504, "seek": 226048, "start": 2280.6, "end": 2283.56, "text": " but this one, 1 out of the 9 are non-white.", "tokens": [457, 341, 472, 11, 502, 484, 295, 264, 1722, 366, 2107, 12, 28865, 13], "temperature": 0.0, "avg_logprob": -0.13804779602931097, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.3006784683966544e-05}, {"id": 505, "seek": 226048, "start": 2283.56, "end": 2289.12, "text": " So there's different amounts of information going into different parts of your convolution.", "tokens": [407, 456, 311, 819, 11663, 295, 1589, 516, 666, 819, 3166, 295, 428, 45216, 13], "temperature": 0.0, "avg_logprob": -0.13804779602931097, "compression_ratio": 1.6919431279620853, "no_speech_prob": 1.3006784683966544e-05}, {"id": 506, "seek": 228912, "start": 2289.12, "end": 2295.6, "text": " So it just doesn't make any sense to throw away information like this and to do all this", "tokens": [407, 309, 445, 1177, 380, 652, 604, 2020, 281, 3507, 1314, 1589, 411, 341, 293, 281, 360, 439, 341], "temperature": 0.0, "avg_logprob": -0.14302877279428336, "compression_ratio": 1.5957446808510638, "no_speech_prob": 3.668747467600042e-06}, {"id": 507, "seek": 228912, "start": 2295.6, "end": 2299.2799999999997, "text": " unnecessary computation and have different parts of the convolution having access to", "tokens": [19350, 24903, 293, 362, 819, 3166, 295, 264, 45216, 1419, 2105, 281], "temperature": 0.0, "avg_logprob": -0.14302877279428336, "compression_ratio": 1.5957446808510638, "no_speech_prob": 3.668747467600042e-06}, {"id": 508, "seek": 228912, "start": 2299.2799999999997, "end": 2302.22, "text": " different amounts of information.", "tokens": [819, 11663, 295, 1589, 13], "temperature": 0.0, "avg_logprob": -0.14302877279428336, "compression_ratio": 1.5957446808510638, "no_speech_prob": 3.668747467600042e-06}, {"id": 509, "seek": 228912, "start": 2302.22, "end": 2309.88, "text": " So what people generally do nowadays is something really simple, which is if you have a 2 by", "tokens": [407, 437, 561, 5101, 360, 13434, 307, 746, 534, 2199, 11, 597, 307, 498, 291, 362, 257, 568, 538], "temperature": 0.0, "avg_logprob": -0.14302877279428336, "compression_ratio": 1.5957446808510638, "no_speech_prob": 3.668747467600042e-06}, {"id": 510, "seek": 230988, "start": 2309.88, "end": 2319.8, "text": " 2 input with these are your pixel values, a, b, c, and d, and you want to create a 4", "tokens": [568, 4846, 365, 613, 366, 428, 19261, 4190, 11, 257, 11, 272, 11, 269, 11, 293, 274, 11, 293, 291, 528, 281, 1884, 257, 1017], "temperature": 0.0, "avg_logprob": -0.17509016783341116, "compression_ratio": 1.457142857142857, "no_speech_prob": 3.3930987228814047e-06}, {"id": 511, "seek": 230988, "start": 2319.8, "end": 2326.2400000000002, "text": " by 4, why not just do this?", "tokens": [538, 1017, 11, 983, 406, 445, 360, 341, 30], "temperature": 0.0, "avg_logprob": -0.17509016783341116, "compression_ratio": 1.457142857142857, "no_speech_prob": 3.3930987228814047e-06}, {"id": 512, "seek": 230988, "start": 2326.2400000000002, "end": 2335.6800000000003, "text": " A, a, a, a, b, b, b, b, c, c, c, c, d, d, d, d.", "tokens": [316, 11, 257, 11, 257, 11, 257, 11, 272, 11, 272, 11, 272, 11, 272, 11, 269, 11, 269, 11, 269, 11, 269, 11, 274, 11, 274, 11, 274, 11, 274, 13], "temperature": 0.0, "avg_logprob": -0.17509016783341116, "compression_ratio": 1.457142857142857, "no_speech_prob": 3.3930987228814047e-06}, {"id": 513, "seek": 230988, "start": 2335.6800000000003, "end": 2339.0, "text": " So I've now upscaled from 2 by 2 to 4 by 4.", "tokens": [407, 286, 600, 586, 493, 4417, 5573, 490, 568, 538, 568, 281, 1017, 538, 1017, 13], "temperature": 0.0, "avg_logprob": -0.17509016783341116, "compression_ratio": 1.457142857142857, "no_speech_prob": 3.3930987228814047e-06}, {"id": 514, "seek": 233900, "start": 2339.0, "end": 2345.56, "text": " I haven't done any interesting computation, but now on top of that I could just do a stride", "tokens": [286, 2378, 380, 1096, 604, 1880, 24903, 11, 457, 586, 322, 1192, 295, 300, 286, 727, 445, 360, 257, 1056, 482], "temperature": 0.0, "avg_logprob": -0.17875288009643556, "compression_ratio": 1.95, "no_speech_prob": 1.6187279470614158e-05}, {"id": 515, "seek": 233900, "start": 2345.56, "end": 2349.28, "text": " 1 convolution, and now I have done some computation.", "tokens": [502, 45216, 11, 293, 586, 286, 362, 1096, 512, 24903, 13], "temperature": 0.0, "avg_logprob": -0.17875288009643556, "compression_ratio": 1.95, "no_speech_prob": 1.6187279470614158e-05}, {"id": 516, "seek": 233900, "start": 2349.28, "end": 2360.76, "text": " So an up sample, this is called nearest neighbor interpolation, nearest neighbor interpolation.", "tokens": [407, 364, 493, 6889, 11, 341, 307, 1219, 23831, 5987, 44902, 399, 11, 23831, 5987, 44902, 399, 13], "temperature": 0.0, "avg_logprob": -0.17875288009643556, "compression_ratio": 1.95, "no_speech_prob": 1.6187279470614158e-05}, {"id": 517, "seek": 233900, "start": 2360.76, "end": 2363.24, "text": " So you can just do, and that's super fast, which is nice.", "tokens": [407, 291, 393, 445, 360, 11, 293, 300, 311, 1687, 2370, 11, 597, 307, 1481, 13], "temperature": 0.0, "avg_logprob": -0.17875288009643556, "compression_ratio": 1.95, "no_speech_prob": 1.6187279470614158e-05}, {"id": 518, "seek": 233900, "start": 2363.24, "end": 2368.16, "text": " So you can do a nearest neighbor interpolation and then a stride 1 conv, and now you've got", "tokens": [407, 291, 393, 360, 257, 23831, 5987, 44902, 399, 293, 550, 257, 1056, 482, 502, 3754, 11, 293, 586, 291, 600, 658], "temperature": 0.0, "avg_logprob": -0.17875288009643556, "compression_ratio": 1.95, "no_speech_prob": 1.6187279470614158e-05}, {"id": 519, "seek": 236816, "start": 2368.16, "end": 2374.3199999999997, "text": " some computation which is actually kind of using, you know, there's no zeros here.", "tokens": [512, 24903, 597, 307, 767, 733, 295, 1228, 11, 291, 458, 11, 456, 311, 572, 35193, 510, 13], "temperature": 0.0, "avg_logprob": -0.09274149378505323, "compression_ratio": 1.7550200803212852, "no_speech_prob": 1.4062709851714317e-05}, {"id": 520, "seek": 236816, "start": 2374.3199999999997, "end": 2377.52, "text": " This is kind of nice because it gets a mixture of a's and b's, which is kind of what you", "tokens": [639, 307, 733, 295, 1481, 570, 309, 2170, 257, 9925, 295, 257, 311, 293, 272, 311, 11, 597, 307, 733, 295, 437, 291], "temperature": 0.0, "avg_logprob": -0.09274149378505323, "compression_ratio": 1.7550200803212852, "no_speech_prob": 1.4062709851714317e-05}, {"id": 521, "seek": 236816, "start": 2377.52, "end": 2380.96, "text": " would want, and so forth.", "tokens": [576, 528, 11, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.09274149378505323, "compression_ratio": 1.7550200803212852, "no_speech_prob": 1.4062709851714317e-05}, {"id": 522, "seek": 236816, "start": 2380.96, "end": 2385.08, "text": " Another approach is instead of using nearest neighbor interpolation, you can use bilinear", "tokens": [3996, 3109, 307, 2602, 295, 1228, 23831, 5987, 44902, 399, 11, 291, 393, 764, 8588, 533, 289], "temperature": 0.0, "avg_logprob": -0.09274149378505323, "compression_ratio": 1.7550200803212852, "no_speech_prob": 1.4062709851714317e-05}, {"id": 523, "seek": 236816, "start": 2385.08, "end": 2390.48, "text": " interpolation, which basically means instead of copying a to all those different cells,", "tokens": [44902, 399, 11, 597, 1936, 1355, 2602, 295, 27976, 257, 281, 439, 729, 819, 5438, 11], "temperature": 0.0, "avg_logprob": -0.09274149378505323, "compression_ratio": 1.7550200803212852, "no_speech_prob": 1.4062709851714317e-05}, {"id": 524, "seek": 236816, "start": 2390.48, "end": 2393.8799999999997, "text": " you take a kind of a weighted average of the cells around it.", "tokens": [291, 747, 257, 733, 295, 257, 32807, 4274, 295, 264, 5438, 926, 309, 13], "temperature": 0.0, "avg_logprob": -0.09274149378505323, "compression_ratio": 1.7550200803212852, "no_speech_prob": 1.4062709851714317e-05}, {"id": 525, "seek": 239388, "start": 2393.88, "end": 2400.48, "text": " So for example, if you were, you know, looking at what should go here, you would kind of", "tokens": [407, 337, 1365, 11, 498, 291, 645, 11, 291, 458, 11, 1237, 412, 437, 820, 352, 510, 11, 291, 576, 733, 295], "temperature": 0.0, "avg_logprob": -0.1424755727438102, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.664528079156298e-06}, {"id": 526, "seek": 239388, "start": 2400.48, "end": 2406.6400000000003, "text": " go like, oh, it's about three a's, two c's, one d, and two b's, and you kind of take the", "tokens": [352, 411, 11, 1954, 11, 309, 311, 466, 1045, 257, 311, 11, 732, 269, 311, 11, 472, 274, 11, 293, 732, 272, 311, 11, 293, 291, 733, 295, 747, 264], "temperature": 0.0, "avg_logprob": -0.1424755727438102, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.664528079156298e-06}, {"id": 527, "seek": 239388, "start": 2406.6400000000003, "end": 2407.6400000000003, "text": " average.", "tokens": [4274, 13], "temperature": 0.0, "avg_logprob": -0.1424755727438102, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.664528079156298e-06}, {"id": 528, "seek": 239388, "start": 2407.6400000000003, "end": 2410.96, "text": " Not exactly, but roughly, just a weighted average.", "tokens": [1726, 2293, 11, 457, 9810, 11, 445, 257, 32807, 4274, 13], "temperature": 0.0, "avg_logprob": -0.1424755727438102, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.664528079156298e-06}, {"id": 529, "seek": 239388, "start": 2410.96, "end": 2414.1600000000003, "text": " Bilinear interpolation you'll find in any, you know, all over the place.", "tokens": [22879, 533, 289, 44902, 399, 291, 603, 915, 294, 604, 11, 291, 458, 11, 439, 670, 264, 1081, 13], "temperature": 0.0, "avg_logprob": -0.1424755727438102, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.664528079156298e-06}, {"id": 530, "seek": 239388, "start": 2414.1600000000003, "end": 2416.32, "text": " It's a pretty standard technique.", "tokens": [467, 311, 257, 1238, 3832, 6532, 13], "temperature": 0.0, "avg_logprob": -0.1424755727438102, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.664528079156298e-06}, {"id": 531, "seek": 239388, "start": 2416.32, "end": 2421.12, "text": " Anytime you look at a picture on your computer screen and change its size, it's doing bilinear", "tokens": [39401, 291, 574, 412, 257, 3036, 322, 428, 3820, 2568, 293, 1319, 1080, 2744, 11, 309, 311, 884, 8588, 533, 289], "temperature": 0.0, "avg_logprob": -0.1424755727438102, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.664528079156298e-06}, {"id": 532, "seek": 239388, "start": 2421.12, "end": 2422.12, "text": " interpolation.", "tokens": [44902, 399, 13], "temperature": 0.0, "avg_logprob": -0.1424755727438102, "compression_ratio": 1.700374531835206, "no_speech_prob": 9.664528079156298e-06}, {"id": 533, "seek": 242212, "start": 2422.12, "end": 2426.24, "text": " So you can do that, and then a stride one conv.", "tokens": [407, 291, 393, 360, 300, 11, 293, 550, 257, 1056, 482, 472, 3754, 13], "temperature": 0.0, "avg_logprob": -0.16016964721679688, "compression_ratio": 1.6618705035971224, "no_speech_prob": 3.844820639642421e-06}, {"id": 534, "seek": 242212, "start": 2426.24, "end": 2428.24, "text": " So that was what people were using.", "tokens": [407, 300, 390, 437, 561, 645, 1228, 13], "temperature": 0.0, "avg_logprob": -0.16016964721679688, "compression_ratio": 1.6618705035971224, "no_speech_prob": 3.844820639642421e-06}, {"id": 535, "seek": 242212, "start": 2428.24, "end": 2431.4, "text": " That's what people still tend to use.", "tokens": [663, 311, 437, 561, 920, 3928, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.16016964721679688, "compression_ratio": 1.6618705035971224, "no_speech_prob": 3.844820639642421e-06}, {"id": 536, "seek": 242212, "start": 2431.4, "end": 2434.4, "text": " That's as much as I'm going to teach you this part.", "tokens": [663, 311, 382, 709, 382, 286, 478, 516, 281, 2924, 291, 341, 644, 13], "temperature": 0.0, "avg_logprob": -0.16016964721679688, "compression_ratio": 1.6618705035971224, "no_speech_prob": 3.844820639642421e-06}, {"id": 537, "seek": 242212, "start": 2434.4, "end": 2439.16, "text": " In part two, we'll actually learn what the Fast AI library is actually doing behind the", "tokens": [682, 644, 732, 11, 321, 603, 767, 1466, 437, 264, 15968, 7318, 6405, 307, 767, 884, 2261, 264], "temperature": 0.0, "avg_logprob": -0.16016964721679688, "compression_ratio": 1.6618705035971224, "no_speech_prob": 3.844820639642421e-06}, {"id": 538, "seek": 242212, "start": 2439.16, "end": 2444.92, "text": " scenes, which is something called a pixel shuffle, also known as subpixel convolutions.", "tokens": [8026, 11, 597, 307, 746, 1219, 257, 19261, 39426, 11, 611, 2570, 382, 1422, 79, 34599, 3754, 15892, 13], "temperature": 0.0, "avg_logprob": -0.16016964721679688, "compression_ratio": 1.6618705035971224, "no_speech_prob": 3.844820639642421e-06}, {"id": 539, "seek": 242212, "start": 2444.92, "end": 2448.56, "text": " It's not dramatically more complex, but complex enough that I won't cover it today.", "tokens": [467, 311, 406, 17548, 544, 3997, 11, 457, 3997, 1547, 300, 286, 1582, 380, 2060, 309, 965, 13], "temperature": 0.0, "avg_logprob": -0.16016964721679688, "compression_ratio": 1.6618705035971224, "no_speech_prob": 3.844820639642421e-06}, {"id": 540, "seek": 242212, "start": 2448.56, "end": 2449.8399999999997, "text": " There's the same basic idea.", "tokens": [821, 311, 264, 912, 3875, 1558, 13], "temperature": 0.0, "avg_logprob": -0.16016964721679688, "compression_ratio": 1.6618705035971224, "no_speech_prob": 3.844820639642421e-06}, {"id": 541, "seek": 244984, "start": 2449.84, "end": 2454.7200000000003, "text": " All of these things is something which is basically letting us do a convolution that", "tokens": [1057, 295, 613, 721, 307, 746, 597, 307, 1936, 8295, 505, 360, 257, 45216, 300], "temperature": 0.0, "avg_logprob": -0.11029796600341797, "compression_ratio": 1.5303030303030303, "no_speech_prob": 4.02917339670239e-06}, {"id": 542, "seek": 244984, "start": 2454.7200000000003, "end": 2457.96, "text": " ends up with something that's twice the size.", "tokens": [5314, 493, 365, 746, 300, 311, 6091, 264, 2744, 13], "temperature": 0.0, "avg_logprob": -0.11029796600341797, "compression_ratio": 1.5303030303030303, "no_speech_prob": 4.02917339670239e-06}, {"id": 543, "seek": 244984, "start": 2457.96, "end": 2462.6400000000003, "text": " And so that gives us our upsampling path.", "tokens": [400, 370, 300, 2709, 505, 527, 15497, 335, 11970, 3100, 13], "temperature": 0.0, "avg_logprob": -0.11029796600341797, "compression_ratio": 1.5303030303030303, "no_speech_prob": 4.02917339670239e-06}, {"id": 544, "seek": 244984, "start": 2462.6400000000003, "end": 2471.28, "text": " So that lets us go from 28 by 28 to 54 by 54 and keep on doubling the size.", "tokens": [407, 300, 6653, 505, 352, 490, 7562, 538, 7562, 281, 20793, 538, 20793, 293, 1066, 322, 33651, 264, 2744, 13], "temperature": 0.0, "avg_logprob": -0.11029796600341797, "compression_ratio": 1.5303030303030303, "no_speech_prob": 4.02917339670239e-06}, {"id": 545, "seek": 244984, "start": 2471.28, "end": 2474.2000000000003, "text": " So that's good.", "tokens": [407, 300, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.11029796600341797, "compression_ratio": 1.5303030303030303, "no_speech_prob": 4.02917339670239e-06}, {"id": 546, "seek": 244984, "start": 2474.2000000000003, "end": 2479.56, "text": " And that was it until UNet came along.", "tokens": [400, 300, 390, 309, 1826, 8229, 302, 1361, 2051, 13], "temperature": 0.0, "avg_logprob": -0.11029796600341797, "compression_ratio": 1.5303030303030303, "no_speech_prob": 4.02917339670239e-06}, {"id": 547, "seek": 247956, "start": 2479.56, "end": 2481.12, "text": " That's what people did.", "tokens": [663, 311, 437, 561, 630, 13], "temperature": 0.0, "avg_logprob": -0.10885002499534971, "compression_ratio": 1.4272300469483568, "no_speech_prob": 6.048819614079548e-06}, {"id": 548, "seek": 247956, "start": 2481.12, "end": 2482.7599999999998, "text": " And it didn't work real well.", "tokens": [400, 309, 994, 380, 589, 957, 731, 13], "temperature": 0.0, "avg_logprob": -0.10885002499534971, "compression_ratio": 1.4272300469483568, "no_speech_prob": 6.048819614079548e-06}, {"id": 549, "seek": 247956, "start": 2482.7599999999998, "end": 2488.68, "text": " Which is not surprising, because in this 28 by 28 feature map, how the hell is it going", "tokens": [3013, 307, 406, 8830, 11, 570, 294, 341, 7562, 538, 7562, 4111, 4471, 11, 577, 264, 4921, 307, 309, 516], "temperature": 0.0, "avg_logprob": -0.10885002499534971, "compression_ratio": 1.4272300469483568, "no_speech_prob": 6.048819614079548e-06}, {"id": 550, "seek": 247956, "start": 2488.68, "end": 2495.6, "text": " to have enough information to reconstruct a 572 by 572 output space?", "tokens": [281, 362, 1547, 1589, 281, 31499, 257, 21423, 17, 538, 21423, 17, 5598, 1901, 30], "temperature": 0.0, "avg_logprob": -0.10885002499534971, "compression_ratio": 1.4272300469483568, "no_speech_prob": 6.048819614079548e-06}, {"id": 551, "seek": 247956, "start": 2495.6, "end": 2497.7599999999998, "text": " That's a really tough ask.", "tokens": [663, 311, 257, 534, 4930, 1029, 13], "temperature": 0.0, "avg_logprob": -0.10885002499534971, "compression_ratio": 1.4272300469483568, "no_speech_prob": 6.048819614079548e-06}, {"id": 552, "seek": 247956, "start": 2497.7599999999998, "end": 2505.08, "text": " So you tended to end up with these things that lacked fine detail.", "tokens": [407, 291, 34732, 281, 917, 493, 365, 613, 721, 300, 41481, 2489, 2607, 13], "temperature": 0.0, "avg_logprob": -0.10885002499534971, "compression_ratio": 1.4272300469483568, "no_speech_prob": 6.048819614079548e-06}, {"id": 553, "seek": 250508, "start": 2505.08, "end": 2516.48, "text": " So what Olaf R\u00f6nerberger and Et al did was they said, hey, let's add a skip connection,", "tokens": [407, 437, 48961, 497, 973, 1193, 42226, 293, 3790, 419, 630, 390, 436, 848, 11, 4177, 11, 718, 311, 909, 257, 10023, 4984, 11], "temperature": 0.0, "avg_logprob": -0.19323316032503857, "compression_ratio": 1.5072463768115942, "no_speech_prob": 1.2679023484452046e-06}, {"id": 554, "seek": 250508, "start": 2516.48, "end": 2518.2799999999997, "text": " an identity connection.", "tokens": [364, 6575, 4984, 13], "temperature": 0.0, "avg_logprob": -0.19323316032503857, "compression_ratio": 1.5072463768115942, "no_speech_prob": 1.2679023484452046e-06}, {"id": 555, "seek": 250508, "start": 2518.2799999999997, "end": 2522.7599999999998, "text": " And amazingly enough, this was before ResNets existed.", "tokens": [400, 31762, 1547, 11, 341, 390, 949, 5015, 45, 1385, 13135, 13], "temperature": 0.0, "avg_logprob": -0.19323316032503857, "compression_ratio": 1.5072463768115942, "no_speech_prob": 1.2679023484452046e-06}, {"id": 556, "seek": 250508, "start": 2522.7599999999998, "end": 2528.04, "text": " So this was like a really big leap, really impressive.", "tokens": [407, 341, 390, 411, 257, 534, 955, 19438, 11, 534, 8992, 13], "temperature": 0.0, "avg_logprob": -0.19323316032503857, "compression_ratio": 1.5072463768115942, "no_speech_prob": 1.2679023484452046e-06}, {"id": 557, "seek": 250508, "start": 2528.04, "end": 2533.7999999999997, "text": " And so but rather than adding a skip connection that skipped every two convolutions, they", "tokens": [400, 370, 457, 2831, 813, 5127, 257, 10023, 4984, 300, 30193, 633, 732, 3754, 15892, 11, 436], "temperature": 0.0, "avg_logprob": -0.19323316032503857, "compression_ratio": 1.5072463768115942, "no_speech_prob": 1.2679023484452046e-06}, {"id": 558, "seek": 253380, "start": 2533.8, "end": 2537.6800000000003, "text": " added skip connections where these gray lines are.", "tokens": [3869, 10023, 9271, 689, 613, 10855, 3876, 366, 13], "temperature": 0.0, "avg_logprob": -0.10938113668690556, "compression_ratio": 1.8106995884773662, "no_speech_prob": 6.048193881724728e-06}, {"id": 559, "seek": 253380, "start": 2537.6800000000003, "end": 2542.4, "text": " In other words, they added a skip connection from the same part of the downsampling path", "tokens": [682, 661, 2283, 11, 436, 3869, 257, 10023, 4984, 490, 264, 912, 644, 295, 264, 760, 19988, 11970, 3100], "temperature": 0.0, "avg_logprob": -0.10938113668690556, "compression_ratio": 1.8106995884773662, "no_speech_prob": 6.048193881724728e-06}, {"id": 560, "seek": 253380, "start": 2542.4, "end": 2546.92, "text": " to the same sized bit in the upsampling path.", "tokens": [281, 264, 912, 20004, 857, 294, 264, 15497, 335, 11970, 3100, 13], "temperature": 0.0, "avg_logprob": -0.10938113668690556, "compression_ratio": 1.8106995884773662, "no_speech_prob": 6.048193881724728e-06}, {"id": 561, "seek": 253380, "start": 2546.92, "end": 2548.28, "text": " And they didn't add.", "tokens": [400, 436, 994, 380, 909, 13], "temperature": 0.0, "avg_logprob": -0.10938113668690556, "compression_ratio": 1.8106995884773662, "no_speech_prob": 6.048193881724728e-06}, {"id": 562, "seek": 253380, "start": 2548.28, "end": 2550.96, "text": " That's why you can see the white and the blue next to each other.", "tokens": [663, 311, 983, 291, 393, 536, 264, 2418, 293, 264, 3344, 958, 281, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.10938113668690556, "compression_ratio": 1.8106995884773662, "no_speech_prob": 6.048193881724728e-06}, {"id": 563, "seek": 253380, "start": 2550.96, "end": 2551.96, "text": " They didn't add.", "tokens": [814, 994, 380, 909, 13], "temperature": 0.0, "avg_logprob": -0.10938113668690556, "compression_ratio": 1.8106995884773662, "no_speech_prob": 6.048193881724728e-06}, {"id": 564, "seek": 253380, "start": 2551.96, "end": 2553.42, "text": " They concatenated.", "tokens": [814, 1588, 7186, 770, 13], "temperature": 0.0, "avg_logprob": -0.10938113668690556, "compression_ratio": 1.8106995884773662, "no_speech_prob": 6.048193881724728e-06}, {"id": 565, "seek": 253380, "start": 2553.42, "end": 2556.84, "text": " So basically, these are like dense blocks.", "tokens": [407, 1936, 11, 613, 366, 411, 18011, 8474, 13], "temperature": 0.0, "avg_logprob": -0.10938113668690556, "compression_ratio": 1.8106995884773662, "no_speech_prob": 6.048193881724728e-06}, {"id": 566, "seek": 253380, "start": 2556.84, "end": 2562.96, "text": " But the skip connections are skipping over larger and larger amounts of the architecture", "tokens": [583, 264, 10023, 9271, 366, 31533, 670, 4833, 293, 4833, 11663, 295, 264, 9482], "temperature": 0.0, "avg_logprob": -0.10938113668690556, "compression_ratio": 1.8106995884773662, "no_speech_prob": 6.048193881724728e-06}, {"id": 567, "seek": 256296, "start": 2562.96, "end": 2573.32, "text": " so that over here, you've literally got nearly the input pixels themselves coming into the", "tokens": [370, 300, 670, 510, 11, 291, 600, 3736, 658, 6217, 264, 4846, 18668, 2969, 1348, 666, 264], "temperature": 0.0, "avg_logprob": -0.11435182359483508, "compression_ratio": 1.7511520737327189, "no_speech_prob": 4.092724793736124e-06}, {"id": 568, "seek": 256296, "start": 2573.32, "end": 2575.92, "text": " computation of these last couple of layers.", "tokens": [24903, 295, 613, 1036, 1916, 295, 7914, 13], "temperature": 0.0, "avg_logprob": -0.11435182359483508, "compression_ratio": 1.7511520737327189, "no_speech_prob": 4.092724793736124e-06}, {"id": 569, "seek": 256296, "start": 2575.92, "end": 2580.96, "text": " And so that's going to make it super handy for resolving the fine details in these segmentation", "tokens": [400, 370, 300, 311, 516, 281, 652, 309, 1687, 13239, 337, 49940, 264, 2489, 4365, 294, 613, 9469, 399], "temperature": 0.0, "avg_logprob": -0.11435182359483508, "compression_ratio": 1.7511520737327189, "no_speech_prob": 4.092724793736124e-06}, {"id": 570, "seek": 256296, "start": 2580.96, "end": 2584.6, "text": " tasks because you've literally got all of the fine details.", "tokens": [9608, 570, 291, 600, 3736, 658, 439, 295, 264, 2489, 4365, 13], "temperature": 0.0, "avg_logprob": -0.11435182359483508, "compression_ratio": 1.7511520737327189, "no_speech_prob": 4.092724793736124e-06}, {"id": 571, "seek": 256296, "start": 2584.6, "end": 2590.2, "text": " On the downside, you don't have very many layers of computation going on here, just", "tokens": [1282, 264, 25060, 11, 291, 500, 380, 362, 588, 867, 7914, 295, 24903, 516, 322, 510, 11, 445], "temperature": 0.0, "avg_logprob": -0.11435182359483508, "compression_ratio": 1.7511520737327189, "no_speech_prob": 4.092724793736124e-06}, {"id": 572, "seek": 256296, "start": 2590.2, "end": 2591.52, "text": " four.", "tokens": [1451, 13], "temperature": 0.0, "avg_logprob": -0.11435182359483508, "compression_ratio": 1.7511520737327189, "no_speech_prob": 4.092724793736124e-06}, {"id": 573, "seek": 259152, "start": 2591.52, "end": 2595.78, "text": " So you better hope that by that stage, you've done all the computation necessary to figure", "tokens": [407, 291, 1101, 1454, 300, 538, 300, 3233, 11, 291, 600, 1096, 439, 264, 24903, 4818, 281, 2573], "temperature": 0.0, "avg_logprob": -0.13883227168923556, "compression_ratio": 1.5739130434782609, "no_speech_prob": 3.5007578844670206e-06}, {"id": 574, "seek": 259152, "start": 2595.78, "end": 2598.96, "text": " out is this a bicyclist or is this a pedestrian.", "tokens": [484, 307, 341, 257, 16703, 3474, 468, 420, 307, 341, 257, 33947, 13], "temperature": 0.0, "avg_logprob": -0.13883227168923556, "compression_ratio": 1.5739130434782609, "no_speech_prob": 3.5007578844670206e-06}, {"id": 575, "seek": 259152, "start": 2598.96, "end": 2604.08, "text": " But you can then add on top of that something saying, is this exact pixel where their nose", "tokens": [583, 291, 393, 550, 909, 322, 1192, 295, 300, 746, 1566, 11, 307, 341, 1900, 19261, 689, 641, 6690], "temperature": 0.0, "avg_logprob": -0.13883227168923556, "compression_ratio": 1.5739130434782609, "no_speech_prob": 3.5007578844670206e-06}, {"id": 576, "seek": 259152, "start": 2604.08, "end": 2607.94, "text": " finishes or is that the start of the tree?", "tokens": [23615, 420, 307, 300, 264, 722, 295, 264, 4230, 30], "temperature": 0.0, "avg_logprob": -0.13883227168923556, "compression_ratio": 1.5739130434782609, "no_speech_prob": 3.5007578844670206e-06}, {"id": 577, "seek": 259152, "start": 2607.94, "end": 2611.32, "text": " So that works out really well.", "tokens": [407, 300, 1985, 484, 534, 731, 13], "temperature": 0.0, "avg_logprob": -0.13883227168923556, "compression_ratio": 1.5739130434782609, "no_speech_prob": 3.5007578844670206e-06}, {"id": 578, "seek": 259152, "start": 2611.32, "end": 2614.68, "text": " And that's a UNET.", "tokens": [400, 300, 311, 257, 8229, 4850, 13], "temperature": 0.0, "avg_logprob": -0.13883227168923556, "compression_ratio": 1.5739130434782609, "no_speech_prob": 3.5007578844670206e-06}, {"id": 579, "seek": 259152, "start": 2614.68, "end": 2619.64, "text": " So this is the UNET code from Fast AI.", "tokens": [407, 341, 307, 264, 8229, 4850, 3089, 490, 15968, 7318, 13], "temperature": 0.0, "avg_logprob": -0.13883227168923556, "compression_ratio": 1.5739130434782609, "no_speech_prob": 3.5007578844670206e-06}, {"id": 580, "seek": 261964, "start": 2619.64, "end": 2624.2799999999997, "text": " And the key thing that comes in is the encoder.", "tokens": [400, 264, 2141, 551, 300, 1487, 294, 307, 264, 2058, 19866, 13], "temperature": 0.0, "avg_logprob": -0.12123392916273797, "compression_ratio": 1.5637254901960784, "no_speech_prob": 5.255183168628719e-06}, {"id": 581, "seek": 261964, "start": 2624.2799999999997, "end": 2631.48, "text": " The encoder refers to that part.", "tokens": [440, 2058, 19866, 14942, 281, 300, 644, 13], "temperature": 0.0, "avg_logprob": -0.12123392916273797, "compression_ratio": 1.5637254901960784, "no_speech_prob": 5.255183168628719e-06}, {"id": 582, "seek": 261964, "start": 2631.48, "end": 2636.52, "text": " In other words, in our case, a ResNet 34.", "tokens": [682, 661, 2283, 11, 294, 527, 1389, 11, 257, 5015, 31890, 12790, 13], "temperature": 0.0, "avg_logprob": -0.12123392916273797, "compression_ratio": 1.5637254901960784, "no_speech_prob": 5.255183168628719e-06}, {"id": 583, "seek": 261964, "start": 2636.52, "end": 2641.08, "text": " In most cases, they have this specific older style architecture.", "tokens": [682, 881, 3331, 11, 436, 362, 341, 2685, 4906, 3758, 9482, 13], "temperature": 0.0, "avg_logprob": -0.12123392916273797, "compression_ratio": 1.5637254901960784, "no_speech_prob": 5.255183168628719e-06}, {"id": 584, "seek": 261964, "start": 2641.08, "end": 2647.44, "text": " But like I said, replace any older style architecture bits with ResNet bits and life improves, particularly", "tokens": [583, 411, 286, 848, 11, 7406, 604, 4906, 3758, 9482, 9239, 365, 5015, 31890, 9239, 293, 993, 24771, 11, 4098], "temperature": 0.0, "avg_logprob": -0.12123392916273797, "compression_ratio": 1.5637254901960784, "no_speech_prob": 5.255183168628719e-06}, {"id": 585, "seek": 261964, "start": 2647.44, "end": 2648.44, "text": " if they're pre-trained.", "tokens": [498, 436, 434, 659, 12, 17227, 2001, 13], "temperature": 0.0, "avg_logprob": -0.12123392916273797, "compression_ratio": 1.5637254901960784, "no_speech_prob": 5.255183168628719e-06}, {"id": 586, "seek": 264844, "start": 2648.44, "end": 2649.92, "text": " So that certainly happened for us.", "tokens": [407, 300, 3297, 2011, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.18652247491283952, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.800830983091146e-06}, {"id": 587, "seek": 264844, "start": 2649.92, "end": 2651.12, "text": " So we start with our encoder.", "tokens": [407, 321, 722, 365, 527, 2058, 19866, 13], "temperature": 0.0, "avg_logprob": -0.18652247491283952, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.800830983091146e-06}, {"id": 588, "seek": 264844, "start": 2651.12, "end": 2657.92, "text": " So our layers of our UNET is an encoder, then batch norm, then ReLU, and then middle conv,", "tokens": [407, 527, 7914, 295, 527, 8229, 4850, 307, 364, 2058, 19866, 11, 550, 15245, 2026, 11, 550, 1300, 43, 52, 11, 293, 550, 2808, 3754, 11], "temperature": 0.0, "avg_logprob": -0.18652247491283952, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.800830983091146e-06}, {"id": 589, "seek": 264844, "start": 2657.92, "end": 2660.76, "text": " which is just conv layer, comma, conv layer.", "tokens": [597, 307, 445, 3754, 4583, 11, 22117, 11, 3754, 4583, 13], "temperature": 0.0, "avg_logprob": -0.18652247491283952, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.800830983091146e-06}, {"id": 590, "seek": 264844, "start": 2660.76, "end": 2666.7200000000003, "text": " Remember, conv layer is a conv ReLU batch norm in Fast AI.", "tokens": [5459, 11, 3754, 4583, 307, 257, 3754, 1300, 43, 52, 15245, 2026, 294, 15968, 7318, 13], "temperature": 0.0, "avg_logprob": -0.18652247491283952, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.800830983091146e-06}, {"id": 591, "seek": 264844, "start": 2666.7200000000003, "end": 2672.44, "text": " And so that middle conv is these two extra steps here at the bottom.", "tokens": [400, 370, 300, 2808, 3754, 307, 613, 732, 2857, 4439, 510, 412, 264, 2767, 13], "temperature": 0.0, "avg_logprob": -0.18652247491283952, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.800830983091146e-06}, {"id": 592, "seek": 264844, "start": 2672.44, "end": 2674.44, "text": " Just doing a little bit of computation.", "tokens": [1449, 884, 257, 707, 857, 295, 24903, 13], "temperature": 0.0, "avg_logprob": -0.18652247491283952, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.800830983091146e-06}, {"id": 593, "seek": 267444, "start": 2674.44, "end": 2679.0, "text": " It's kind of nice to add more layers of computation where you can.", "tokens": [467, 311, 733, 295, 1481, 281, 909, 544, 7914, 295, 24903, 689, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.14777125599228333, "compression_ratio": 1.5965665236051503, "no_speech_prob": 1.8161792922910536e-06}, {"id": 594, "seek": 267444, "start": 2679.0, "end": 2682.12, "text": " So encoder batch norm ReLU, and then two convolutions.", "tokens": [407, 2058, 19866, 15245, 2026, 1300, 43, 52, 11, 293, 550, 732, 3754, 15892, 13], "temperature": 0.0, "avg_logprob": -0.14777125599228333, "compression_ratio": 1.5965665236051503, "no_speech_prob": 1.8161792922910536e-06}, {"id": 595, "seek": 267444, "start": 2682.12, "end": 2686.0, "text": " And then we enumerate through these indexes.", "tokens": [400, 550, 321, 465, 15583, 473, 807, 613, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.14777125599228333, "compression_ratio": 1.5965665236051503, "no_speech_prob": 1.8161792922910536e-06}, {"id": 596, "seek": 267444, "start": 2686.0, "end": 2687.0, "text": " What are these indexes?", "tokens": [708, 366, 613, 8186, 279, 30], "temperature": 0.0, "avg_logprob": -0.14777125599228333, "compression_ratio": 1.5965665236051503, "no_speech_prob": 1.8161792922910536e-06}, {"id": 597, "seek": 267444, "start": 2687.0, "end": 2688.16, "text": " I haven't included the code.", "tokens": [286, 2378, 380, 5556, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.14777125599228333, "compression_ratio": 1.5965665236051503, "no_speech_prob": 1.8161792922910536e-06}, {"id": 598, "seek": 267444, "start": 2688.16, "end": 2695.2400000000002, "text": " But these are basically we figure out what is the layer number where each of these stride", "tokens": [583, 613, 366, 1936, 321, 2573, 484, 437, 307, 264, 4583, 1230, 689, 1184, 295, 613, 1056, 482], "temperature": 0.0, "avg_logprob": -0.14777125599228333, "compression_ratio": 1.5965665236051503, "no_speech_prob": 1.8161792922910536e-06}, {"id": 599, "seek": 267444, "start": 2695.2400000000002, "end": 2696.2400000000002, "text": " two comms occurs.", "tokens": [732, 800, 82, 11843, 13], "temperature": 0.0, "avg_logprob": -0.14777125599228333, "compression_ratio": 1.5965665236051503, "no_speech_prob": 1.8161792922910536e-06}, {"id": 600, "seek": 267444, "start": 2696.2400000000002, "end": 2699.5, "text": " And we just store it in an array of indexes.", "tokens": [400, 321, 445, 3531, 309, 294, 364, 10225, 295, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.14777125599228333, "compression_ratio": 1.5965665236051503, "no_speech_prob": 1.8161792922910536e-06}, {"id": 601, "seek": 269950, "start": 2699.5, "end": 2704.6, "text": " So then we can loop through that, and we can basically say for each one of those points,", "tokens": [407, 550, 321, 393, 6367, 807, 300, 11, 293, 321, 393, 1936, 584, 337, 1184, 472, 295, 729, 2793, 11], "temperature": 0.0, "avg_logprob": -0.09528037829276843, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.637710389943095e-06}, {"id": 602, "seek": 269950, "start": 2704.6, "end": 2712.4, "text": " create a UNET block, telling us how many upsampling channels there are and how many cross-connection.", "tokens": [1884, 257, 8229, 4850, 3461, 11, 3585, 505, 577, 867, 15497, 335, 11970, 9235, 456, 366, 293, 577, 867, 3278, 12, 9826, 313, 13], "temperature": 0.0, "avg_logprob": -0.09528037829276843, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.637710389943095e-06}, {"id": 603, "seek": 269950, "start": 2712.4, "end": 2716.96, "text": " These things here are called cross-connections, or at least that's what I call them.", "tokens": [1981, 721, 510, 366, 1219, 3278, 12, 9826, 626, 11, 420, 412, 1935, 300, 311, 437, 286, 818, 552, 13], "temperature": 0.0, "avg_logprob": -0.09528037829276843, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.637710389943095e-06}, {"id": 604, "seek": 269950, "start": 2716.96, "end": 2722.72, "text": " So that's really the main works going on in the UNET block.", "tokens": [407, 300, 311, 534, 264, 2135, 1985, 516, 322, 294, 264, 8229, 4850, 3461, 13], "temperature": 0.0, "avg_logprob": -0.09528037829276843, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.637710389943095e-06}, {"id": 605, "seek": 269950, "start": 2722.72, "end": 2727.3, "text": " As I said, there's quite a few tweaks we do, as well as the fact we use a much better encoder.", "tokens": [1018, 286, 848, 11, 456, 311, 1596, 257, 1326, 46664, 321, 360, 11, 382, 731, 382, 264, 1186, 321, 764, 257, 709, 1101, 2058, 19866, 13], "temperature": 0.0, "avg_logprob": -0.09528037829276843, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.637710389943095e-06}, {"id": 606, "seek": 272730, "start": 2727.3, "end": 2731.48, "text": " We also use some tweaks in all of our upsampling using this pixel shuffle.", "tokens": [492, 611, 764, 512, 46664, 294, 439, 295, 527, 15497, 335, 11970, 1228, 341, 19261, 39426, 13], "temperature": 0.0, "avg_logprob": -0.10633419781196408, "compression_ratio": 1.6642599277978338, "no_speech_prob": 4.356185854703654e-06}, {"id": 607, "seek": 272730, "start": 2731.48, "end": 2734.2400000000002, "text": " We use another tweak called ICNR.", "tokens": [492, 764, 1071, 29879, 1219, 14360, 45, 49, 13], "temperature": 0.0, "avg_logprob": -0.10633419781196408, "compression_ratio": 1.6642599277978338, "no_speech_prob": 4.356185854703654e-06}, {"id": 608, "seek": 272730, "start": 2734.2400000000002, "end": 2739.0800000000004, "text": " And then another tweak, which I just did in the last week, is to not just take the result", "tokens": [400, 550, 1071, 29879, 11, 597, 286, 445, 630, 294, 264, 1036, 1243, 11, 307, 281, 406, 445, 747, 264, 1874], "temperature": 0.0, "avg_logprob": -0.10633419781196408, "compression_ratio": 1.6642599277978338, "no_speech_prob": 4.356185854703654e-06}, {"id": 609, "seek": 272730, "start": 2739.0800000000004, "end": 2743.8, "text": " of the convolutions and pass it across, but we actually grab the input pixels and make", "tokens": [295, 264, 3754, 15892, 293, 1320, 309, 2108, 11, 457, 321, 767, 4444, 264, 4846, 18668, 293, 652], "temperature": 0.0, "avg_logprob": -0.10633419781196408, "compression_ratio": 1.6642599277978338, "no_speech_prob": 4.356185854703654e-06}, {"id": 610, "seek": 272730, "start": 2743.8, "end": 2745.76, "text": " them another cross-connection.", "tokens": [552, 1071, 3278, 12, 9826, 313, 13], "temperature": 0.0, "avg_logprob": -0.10633419781196408, "compression_ratio": 1.6642599277978338, "no_speech_prob": 4.356185854703654e-06}, {"id": 611, "seek": 272730, "start": 2745.76, "end": 2748.04, "text": " That's what this last cross is here.", "tokens": [663, 311, 437, 341, 1036, 3278, 307, 510, 13], "temperature": 0.0, "avg_logprob": -0.10633419781196408, "compression_ratio": 1.6642599277978338, "no_speech_prob": 4.356185854703654e-06}, {"id": 612, "seek": 272730, "start": 2748.04, "end": 2752.44, "text": " You can see we're literally appending a res block with the original inputs.", "tokens": [509, 393, 536, 321, 434, 3736, 724, 2029, 257, 725, 3461, 365, 264, 3380, 15743, 13], "temperature": 0.0, "avg_logprob": -0.10633419781196408, "compression_ratio": 1.6642599277978338, "no_speech_prob": 4.356185854703654e-06}, {"id": 613, "seek": 272730, "start": 2752.44, "end": 2757.04, "text": " So you can see our merge layer.", "tokens": [407, 291, 393, 536, 527, 22183, 4583, 13], "temperature": 0.0, "avg_logprob": -0.10633419781196408, "compression_ratio": 1.6642599277978338, "no_speech_prob": 4.356185854703654e-06}, {"id": 614, "seek": 275704, "start": 2757.04, "end": 2760.24, "text": " So really all the work is going on in UNET block.", "tokens": [407, 534, 439, 264, 589, 307, 516, 322, 294, 8229, 4850, 3461, 13], "temperature": 0.0, "avg_logprob": -0.17525163650512696, "compression_ratio": 1.6298076923076923, "no_speech_prob": 4.784956217918079e-06}, {"id": 615, "seek": 275704, "start": 2760.24, "end": 2768.12, "text": " And UNET block has to store the activations at each of these downsampling points.", "tokens": [400, 8229, 4850, 3461, 575, 281, 3531, 264, 2430, 763, 412, 1184, 295, 613, 760, 19988, 11970, 2793, 13], "temperature": 0.0, "avg_logprob": -0.17525163650512696, "compression_ratio": 1.6298076923076923, "no_speech_prob": 4.784956217918079e-06}, {"id": 616, "seek": 275704, "start": 2768.12, "end": 2773.16, "text": " And the way to do that, as we learned in the last lesson, is with hooks.", "tokens": [400, 264, 636, 281, 360, 300, 11, 382, 321, 3264, 294, 264, 1036, 6898, 11, 307, 365, 26485, 13], "temperature": 0.0, "avg_logprob": -0.17525163650512696, "compression_ratio": 1.6298076923076923, "no_speech_prob": 4.784956217918079e-06}, {"id": 617, "seek": 275704, "start": 2773.16, "end": 2780.72, "text": " So we put hooks into the ResNet34 to store the activations each time there's a Stride2", "tokens": [407, 321, 829, 26485, 666, 264, 5015, 31890, 12249, 281, 3531, 264, 2430, 763, 1184, 565, 456, 311, 257, 8251, 482, 17], "temperature": 0.0, "avg_logprob": -0.17525163650512696, "compression_ratio": 1.6298076923076923, "no_speech_prob": 4.784956217918079e-06}, {"id": 618, "seek": 275704, "start": 2780.72, "end": 2781.7599999999998, "text": " conv.", "tokens": [3754, 13], "temperature": 0.0, "avg_logprob": -0.17525163650512696, "compression_ratio": 1.6298076923076923, "no_speech_prob": 4.784956217918079e-06}, {"id": 619, "seek": 275704, "start": 2781.7599999999998, "end": 2785.8, "text": " And so you can see here we grab the hook.", "tokens": [400, 370, 291, 393, 536, 510, 321, 4444, 264, 6328, 13], "temperature": 0.0, "avg_logprob": -0.17525163650512696, "compression_ratio": 1.6298076923076923, "no_speech_prob": 4.784956217918079e-06}, {"id": 620, "seek": 278580, "start": 2785.8, "end": 2789.92, "text": " And we grab the result of the stored value in that hook.", "tokens": [400, 321, 4444, 264, 1874, 295, 264, 12187, 2158, 294, 300, 6328, 13], "temperature": 0.0, "avg_logprob": -0.11577750387645903, "compression_ratio": 1.6051282051282052, "no_speech_prob": 4.289116077416111e-06}, {"id": 621, "seek": 278580, "start": 2789.92, "end": 2803.1200000000003, "text": " And we literally just go torch.cat so we concatenate the upsampled convolution with the result", "tokens": [400, 321, 3736, 445, 352, 27822, 13, 18035, 370, 321, 1588, 7186, 473, 264, 15497, 335, 15551, 45216, 365, 264, 1874], "temperature": 0.0, "avg_logprob": -0.11577750387645903, "compression_ratio": 1.6051282051282052, "no_speech_prob": 4.289116077416111e-06}, {"id": 622, "seek": 278580, "start": 2803.1200000000003, "end": 2806.04, "text": " of the hook, which we chuck through BatchNorm.", "tokens": [295, 264, 6328, 11, 597, 321, 20870, 807, 363, 852, 45, 687, 13], "temperature": 0.0, "avg_logprob": -0.11577750387645903, "compression_ratio": 1.6051282051282052, "no_speech_prob": 4.289116077416111e-06}, {"id": 623, "seek": 278580, "start": 2806.04, "end": 2808.6000000000004, "text": " And then we do two convolutions to it.", "tokens": [400, 550, 321, 360, 732, 3754, 15892, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.11577750387645903, "compression_ratio": 1.6051282051282052, "no_speech_prob": 4.289116077416111e-06}, {"id": 624, "seek": 278580, "start": 2808.6000000000004, "end": 2813.6800000000003, "text": " And actually, something you could play with at home is pretty obvious here.", "tokens": [400, 767, 11, 746, 291, 727, 862, 365, 412, 1280, 307, 1238, 6322, 510, 13], "temperature": 0.0, "avg_logprob": -0.11577750387645903, "compression_ratio": 1.6051282051282052, "no_speech_prob": 4.289116077416111e-06}, {"id": 625, "seek": 281368, "start": 2813.68, "end": 2816.8399999999997, "text": " Anytime you see two convolutions like this, there's an obvious question is what if we", "tokens": [39401, 291, 536, 732, 3754, 15892, 411, 341, 11, 456, 311, 364, 6322, 1168, 307, 437, 498, 321], "temperature": 0.0, "avg_logprob": -0.20355525585489537, "compression_ratio": 1.56198347107438, "no_speech_prob": 8.93923788680695e-06}, {"id": 626, "seek": 281368, "start": 2816.8399999999997, "end": 2819.06, "text": " used a ResNet block instead?", "tokens": [1143, 257, 5015, 31890, 3461, 2602, 30], "temperature": 0.0, "avg_logprob": -0.20355525585489537, "compression_ratio": 1.56198347107438, "no_speech_prob": 8.93923788680695e-06}, {"id": 627, "seek": 281368, "start": 2819.06, "end": 2822.44, "text": " So you could try replacing those two convs with a ResNet block.", "tokens": [407, 291, 727, 853, 19139, 729, 732, 3754, 82, 365, 257, 5015, 31890, 3461, 13], "temperature": 0.0, "avg_logprob": -0.20355525585489537, "compression_ratio": 1.56198347107438, "no_speech_prob": 8.93923788680695e-06}, {"id": 628, "seek": 281368, "start": 2822.44, "end": 2824.2, "text": " You might find you get even better results.", "tokens": [509, 1062, 915, 291, 483, 754, 1101, 3542, 13], "temperature": 0.0, "avg_logprob": -0.20355525585489537, "compression_ratio": 1.56198347107438, "no_speech_prob": 8.93923788680695e-06}, {"id": 629, "seek": 281368, "start": 2824.2, "end": 2828.8799999999997, "text": " They're the kind of things I look for when I look at an architecture is like, oh, two", "tokens": [814, 434, 264, 733, 295, 721, 286, 574, 337, 562, 286, 574, 412, 364, 9482, 307, 411, 11, 1954, 11, 732], "temperature": 0.0, "avg_logprob": -0.20355525585489537, "compression_ratio": 1.56198347107438, "no_speech_prob": 8.93923788680695e-06}, {"id": 630, "seek": 281368, "start": 2828.8799999999997, "end": 2834.7999999999997, "text": " convs in a row probably should be a ResNet block.", "tokens": [3754, 82, 294, 257, 5386, 1391, 820, 312, 257, 5015, 31890, 3461, 13], "temperature": 0.0, "avg_logprob": -0.20355525585489537, "compression_ratio": 1.56198347107438, "no_speech_prob": 8.93923788680695e-06}, {"id": 631, "seek": 281368, "start": 2834.7999999999997, "end": 2836.2799999999997, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.20355525585489537, "compression_ratio": 1.56198347107438, "no_speech_prob": 8.93923788680695e-06}, {"id": 632, "seek": 281368, "start": 2836.2799999999997, "end": 2840.16, "text": " So that's UNET.", "tokens": [407, 300, 311, 8229, 4850, 13], "temperature": 0.0, "avg_logprob": -0.20355525585489537, "compression_ratio": 1.56198347107438, "no_speech_prob": 8.93923788680695e-06}, {"id": 633, "seek": 284016, "start": 2840.16, "end": 2849.24, "text": " And it's amazing to think it preceded ResNet, it preceded DenseNet.", "tokens": [400, 309, 311, 2243, 281, 519, 309, 16969, 292, 5015, 31890, 11, 309, 16969, 292, 413, 1288, 31890, 13], "temperature": 0.0, "avg_logprob": -0.17916883004678263, "compression_ratio": 1.5477386934673367, "no_speech_prob": 1.921157308970578e-05}, {"id": 634, "seek": 284016, "start": 2849.24, "end": 2853.04, "text": " It wasn't even published in a major machine learning venue.", "tokens": [467, 2067, 380, 754, 6572, 294, 257, 2563, 3479, 2539, 21645, 13], "temperature": 0.0, "avg_logprob": -0.17916883004678263, "compression_ratio": 1.5477386934673367, "no_speech_prob": 1.921157308970578e-05}, {"id": 635, "seek": 284016, "start": 2853.04, "end": 2859.64, "text": " It was actually published in Micai, which is a specialized medical image computing conference.", "tokens": [467, 390, 767, 6572, 294, 5818, 1301, 11, 597, 307, 257, 19813, 4625, 3256, 15866, 7586, 13], "temperature": 0.0, "avg_logprob": -0.17916883004678263, "compression_ratio": 1.5477386934673367, "no_speech_prob": 1.921157308970578e-05}, {"id": 636, "seek": 284016, "start": 2859.64, "end": 2864.52, "text": " For years, actually, it was largely unknown outside of the medical imaging community.", "tokens": [1171, 924, 11, 767, 11, 309, 390, 11611, 9841, 2380, 295, 264, 4625, 25036, 1768, 13], "temperature": 0.0, "avg_logprob": -0.17916883004678263, "compression_ratio": 1.5477386934673367, "no_speech_prob": 1.921157308970578e-05}, {"id": 637, "seek": 286452, "start": 2864.52, "end": 2871.24, "text": " And actually, what happened was Kaggle competitions for segmentation kept on being easily won", "tokens": [400, 767, 11, 437, 2011, 390, 48751, 22631, 26185, 337, 9469, 399, 4305, 322, 885, 3612, 1582], "temperature": 0.0, "avg_logprob": -0.13718172561290654, "compression_ratio": 1.5518672199170125, "no_speech_prob": 9.221163963957224e-06}, {"id": 638, "seek": 286452, "start": 2871.24, "end": 2872.24, "text": " by people using UNET.", "tokens": [538, 561, 1228, 8229, 4850, 13], "temperature": 0.0, "avg_logprob": -0.13718172561290654, "compression_ratio": 1.5518672199170125, "no_speech_prob": 9.221163963957224e-06}, {"id": 639, "seek": 286452, "start": 2872.24, "end": 2876.24, "text": " And that was the first time I saw it getting noticed outside the medical imaging community.", "tokens": [400, 300, 390, 264, 700, 565, 286, 1866, 309, 1242, 5694, 2380, 264, 4625, 25036, 1768, 13], "temperature": 0.0, "avg_logprob": -0.13718172561290654, "compression_ratio": 1.5518672199170125, "no_speech_prob": 9.221163963957224e-06}, {"id": 640, "seek": 286452, "start": 2876.24, "end": 2880.52, "text": " And then gradually, a few people in the academic machine learning community started noticing.", "tokens": [400, 550, 13145, 11, 257, 1326, 561, 294, 264, 7778, 3479, 2539, 1768, 1409, 21814, 13], "temperature": 0.0, "avg_logprob": -0.13718172561290654, "compression_ratio": 1.5518672199170125, "no_speech_prob": 9.221163963957224e-06}, {"id": 641, "seek": 286452, "start": 2880.52, "end": 2889.34, "text": " And now everybody loves UNET, which I'm glad, because it's just awesome.", "tokens": [400, 586, 2201, 6752, 8229, 4850, 11, 597, 286, 478, 5404, 11, 570, 309, 311, 445, 3476, 13], "temperature": 0.0, "avg_logprob": -0.13718172561290654, "compression_ratio": 1.5518672199170125, "no_speech_prob": 9.221163963957224e-06}, {"id": 642, "seek": 288934, "start": 2889.34, "end": 2898.92, "text": " So identity connections, regardless of whether they're a plus style or a concat style, are", "tokens": [407, 6575, 9271, 11, 10060, 295, 1968, 436, 434, 257, 1804, 3758, 420, 257, 1588, 267, 3758, 11, 366], "temperature": 0.0, "avg_logprob": -0.07869756995857537, "compression_ratio": 1.538860103626943, "no_speech_prob": 1.553393417452753e-06}, {"id": 643, "seek": 288934, "start": 2898.92, "end": 2899.92, "text": " incredibly useful.", "tokens": [6252, 4420, 13], "temperature": 0.0, "avg_logprob": -0.07869756995857537, "compression_ratio": 1.538860103626943, "no_speech_prob": 1.553393417452753e-06}, {"id": 644, "seek": 288934, "start": 2899.92, "end": 2907.7000000000003, "text": " They can basically get us close to the state of the art on lots of important tasks.", "tokens": [814, 393, 1936, 483, 505, 1998, 281, 264, 1785, 295, 264, 1523, 322, 3195, 295, 1021, 9608, 13], "temperature": 0.0, "avg_logprob": -0.07869756995857537, "compression_ratio": 1.538860103626943, "no_speech_prob": 1.553393417452753e-06}, {"id": 645, "seek": 288934, "start": 2907.7000000000003, "end": 2911.48, "text": " So I want to use them on another task now.", "tokens": [407, 286, 528, 281, 764, 552, 322, 1071, 5633, 586, 13], "temperature": 0.0, "avg_logprob": -0.07869756995857537, "compression_ratio": 1.538860103626943, "no_speech_prob": 1.553393417452753e-06}, {"id": 646, "seek": 288934, "start": 2911.48, "end": 2916.1600000000003, "text": " And so the next task I want to look at is image restoration.", "tokens": [400, 370, 264, 958, 5633, 286, 528, 281, 574, 412, 307, 3256, 23722, 13], "temperature": 0.0, "avg_logprob": -0.07869756995857537, "compression_ratio": 1.538860103626943, "no_speech_prob": 1.553393417452753e-06}, {"id": 647, "seek": 291616, "start": 2916.16, "end": 2920.16, "text": " So image restoration refers to starting with an image.", "tokens": [407, 3256, 23722, 14942, 281, 2891, 365, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1523292064666748, "compression_ratio": 1.8914728682170543, "no_speech_prob": 6.853721970401239e-06}, {"id": 648, "seek": 291616, "start": 2920.16, "end": 2923.7999999999997, "text": " At this time, we're not going to create a segmentation mask, but we're going to try", "tokens": [1711, 341, 565, 11, 321, 434, 406, 516, 281, 1884, 257, 9469, 399, 6094, 11, 457, 321, 434, 516, 281, 853], "temperature": 0.0, "avg_logprob": -0.1523292064666748, "compression_ratio": 1.8914728682170543, "no_speech_prob": 6.853721970401239e-06}, {"id": 649, "seek": 291616, "start": 2923.7999999999997, "end": 2927.48, "text": " and create a better image.", "tokens": [293, 1884, 257, 1101, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1523292064666748, "compression_ratio": 1.8914728682170543, "no_speech_prob": 6.853721970401239e-06}, {"id": 650, "seek": 291616, "start": 2927.48, "end": 2928.92, "text": " And there's lots of versions of better.", "tokens": [400, 456, 311, 3195, 295, 9606, 295, 1101, 13], "temperature": 0.0, "avg_logprob": -0.1523292064666748, "compression_ratio": 1.8914728682170543, "no_speech_prob": 6.853721970401239e-06}, {"id": 651, "seek": 291616, "start": 2928.92, "end": 2930.72, "text": " They could be different image.", "tokens": [814, 727, 312, 819, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1523292064666748, "compression_ratio": 1.8914728682170543, "no_speech_prob": 6.853721970401239e-06}, {"id": 652, "seek": 291616, "start": 2930.72, "end": 2934.48, "text": " So the kind of things we can do with this kind of image generation would be take a low", "tokens": [407, 264, 733, 295, 721, 321, 393, 360, 365, 341, 733, 295, 3256, 5125, 576, 312, 747, 257, 2295], "temperature": 0.0, "avg_logprob": -0.1523292064666748, "compression_ratio": 1.8914728682170543, "no_speech_prob": 6.853721970401239e-06}, {"id": 653, "seek": 291616, "start": 2934.48, "end": 2940.7599999999998, "text": " res image, make it high res, take a black and white image, make it color, take an image", "tokens": [725, 3256, 11, 652, 309, 1090, 725, 11, 747, 257, 2211, 293, 2418, 3256, 11, 652, 309, 2017, 11, 747, 364, 3256], "temperature": 0.0, "avg_logprob": -0.1523292064666748, "compression_ratio": 1.8914728682170543, "no_speech_prob": 6.853721970401239e-06}, {"id": 654, "seek": 291616, "start": 2940.7599999999998, "end": 2945.8599999999997, "text": " where something's being cut out of it and try and replace the cut out thing.", "tokens": [689, 746, 311, 885, 1723, 484, 295, 309, 293, 853, 293, 7406, 264, 1723, 484, 551, 13], "temperature": 0.0, "avg_logprob": -0.1523292064666748, "compression_ratio": 1.8914728682170543, "no_speech_prob": 6.853721970401239e-06}, {"id": 655, "seek": 294586, "start": 2945.86, "end": 2949.2400000000002, "text": " Take a photo and try and turn it into what looks like a line drawing.", "tokens": [3664, 257, 5052, 293, 853, 293, 1261, 309, 666, 437, 1542, 411, 257, 1622, 6316, 13], "temperature": 0.0, "avg_logprob": -0.10610618066350254, "compression_ratio": 1.7530864197530864, "no_speech_prob": 3.2376822218793677e-06}, {"id": 656, "seek": 294586, "start": 2949.2400000000002, "end": 2952.48, "text": " Take a photo and try and make it look like a Monet painting.", "tokens": [3664, 257, 5052, 293, 853, 293, 652, 309, 574, 411, 257, 47871, 5370, 13], "temperature": 0.0, "avg_logprob": -0.10610618066350254, "compression_ratio": 1.7530864197530864, "no_speech_prob": 3.2376822218793677e-06}, {"id": 657, "seek": 294586, "start": 2952.48, "end": 2957.7200000000003, "text": " These are all examples of image to image generation tasks, which you'll know how to do after this", "tokens": [1981, 366, 439, 5110, 295, 3256, 281, 3256, 5125, 9608, 11, 597, 291, 603, 458, 577, 281, 360, 934, 341], "temperature": 0.0, "avg_logprob": -0.10610618066350254, "compression_ratio": 1.7530864197530864, "no_speech_prob": 3.2376822218793677e-06}, {"id": 658, "seek": 294586, "start": 2957.7200000000003, "end": 2961.08, "text": " part of the class.", "tokens": [644, 295, 264, 1508, 13], "temperature": 0.0, "avg_logprob": -0.10610618066350254, "compression_ratio": 1.7530864197530864, "no_speech_prob": 3.2376822218793677e-06}, {"id": 659, "seek": 294586, "start": 2961.08, "end": 2967.6400000000003, "text": " So in our case, we're going to try to do image restoration, which is going to start with", "tokens": [407, 294, 527, 1389, 11, 321, 434, 516, 281, 853, 281, 360, 3256, 23722, 11, 597, 307, 516, 281, 722, 365], "temperature": 0.0, "avg_logprob": -0.10610618066350254, "compression_ratio": 1.7530864197530864, "no_speech_prob": 3.2376822218793677e-06}, {"id": 660, "seek": 294586, "start": 2967.6400000000003, "end": 2975.56, "text": " low resolution, poor quality JPEGs with writing written over the top of them and get them", "tokens": [2295, 8669, 11, 4716, 3125, 508, 5208, 33715, 365, 3579, 3720, 670, 264, 1192, 295, 552, 293, 483, 552], "temperature": 0.0, "avg_logprob": -0.10610618066350254, "compression_ratio": 1.7530864197530864, "no_speech_prob": 3.2376822218793677e-06}, {"id": 661, "seek": 297556, "start": 2975.56, "end": 2981.2799999999997, "text": " to replace them with high resolution, good quality pictures in which the text has been", "tokens": [281, 7406, 552, 365, 1090, 8669, 11, 665, 3125, 5242, 294, 597, 264, 2487, 575, 668], "temperature": 0.0, "avg_logprob": -0.26172757582231, "compression_ratio": 1.251700680272109, "no_speech_prob": 1.3005865184823051e-05}, {"id": 662, "seek": 297556, "start": 2981.2799999999997, "end": 2983.48, "text": " removed.", "tokens": [7261, 13], "temperature": 0.0, "avg_logprob": -0.26172757582231, "compression_ratio": 1.251700680272109, "no_speech_prob": 1.3005865184823051e-05}, {"id": 663, "seek": 297556, "start": 2983.48, "end": 2986.7599999999998, "text": " Two questions?", "tokens": [4453, 1651, 30], "temperature": 0.0, "avg_logprob": -0.26172757582231, "compression_ratio": 1.251700680272109, "no_speech_prob": 1.3005865184823051e-05}, {"id": 664, "seek": 297556, "start": 2986.7599999999998, "end": 2991.72, "text": " Okay, let's go.", "tokens": [1033, 11, 718, 311, 352, 13], "temperature": 0.0, "avg_logprob": -0.26172757582231, "compression_ratio": 1.251700680272109, "no_speech_prob": 1.3005865184823051e-05}, {"id": 665, "seek": 297556, "start": 2991.72, "end": 3000.36, "text": " Why do you concat before calling Conf2, Conf1, not after?", "tokens": [1545, 360, 291, 1588, 267, 949, 5141, 11701, 17, 11, 11701, 16, 11, 406, 934, 30], "temperature": 0.0, "avg_logprob": -0.26172757582231, "compression_ratio": 1.251700680272109, "no_speech_prob": 1.3005865184823051e-05}, {"id": 666, "seek": 300036, "start": 3000.36, "end": 3008.2400000000002, "text": " Because if you did your convs before you concat, then there's no way for the channels of the", "tokens": [1436, 498, 291, 630, 428, 3754, 82, 949, 291, 1588, 267, 11, 550, 456, 311, 572, 636, 337, 264, 9235, 295, 264], "temperature": 0.0, "avg_logprob": -0.1806819340954088, "compression_ratio": 1.4655172413793103, "no_speech_prob": 2.0143028450547718e-05}, {"id": 667, "seek": 300036, "start": 3008.2400000000002, "end": 3013.84, "text": " two parts to interact with each other.", "tokens": [732, 3166, 281, 4648, 365, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.1806819340954088, "compression_ratio": 1.4655172413793103, "no_speech_prob": 2.0143028450547718e-05}, {"id": 668, "seek": 300036, "start": 3013.84, "end": 3018.36, "text": " Remember in a 2D conv, it's really 3D.", "tokens": [5459, 294, 257, 568, 35, 3754, 11, 309, 311, 534, 805, 35, 13], "temperature": 0.0, "avg_logprob": -0.1806819340954088, "compression_ratio": 1.4655172413793103, "no_speech_prob": 2.0143028450547718e-05}, {"id": 669, "seek": 300036, "start": 3018.36, "end": 3025.76, "text": " It's moving across two dimensions, but in each case, it's doing a dot product of all", "tokens": [467, 311, 2684, 2108, 732, 12819, 11, 457, 294, 1184, 1389, 11, 309, 311, 884, 257, 5893, 1674, 295, 439], "temperature": 0.0, "avg_logprob": -0.1806819340954088, "compression_ratio": 1.4655172413793103, "no_speech_prob": 2.0143028450547718e-05}, {"id": 670, "seek": 302576, "start": 3025.76, "end": 3030.48, "text": " three dimensions of a rank three tensor, row by column by channel.", "tokens": [1045, 12819, 295, 257, 6181, 1045, 40863, 11, 5386, 538, 7738, 538, 2269, 13], "temperature": 0.0, "avg_logprob": -0.10614940524101257, "compression_ratio": 1.8564814814814814, "no_speech_prob": 1.2217513358336873e-05}, {"id": 671, "seek": 302576, "start": 3030.48, "end": 3035.0400000000004, "text": " So generally speaking, we want as much interaction as possible.", "tokens": [407, 5101, 4124, 11, 321, 528, 382, 709, 9285, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.10614940524101257, "compression_ratio": 1.8564814814814814, "no_speech_prob": 1.2217513358336873e-05}, {"id": 672, "seek": 302576, "start": 3035.0400000000004, "end": 3040.5600000000004, "text": " We want to say this part of the down sampling path and this part of the up sampling path,", "tokens": [492, 528, 281, 584, 341, 644, 295, 264, 760, 21179, 3100, 293, 341, 644, 295, 264, 493, 21179, 3100, 11], "temperature": 0.0, "avg_logprob": -0.10614940524101257, "compression_ratio": 1.8564814814814814, "no_speech_prob": 1.2217513358336873e-05}, {"id": 673, "seek": 302576, "start": 3040.5600000000004, "end": 3043.5200000000004, "text": " if you look at the combination of them, you find these interesting things.", "tokens": [498, 291, 574, 412, 264, 6562, 295, 552, 11, 291, 915, 613, 1880, 721, 13], "temperature": 0.0, "avg_logprob": -0.10614940524101257, "compression_ratio": 1.8564814814814814, "no_speech_prob": 1.2217513358336873e-05}, {"id": 674, "seek": 302576, "start": 3043.5200000000004, "end": 3051.2400000000002, "text": " So generally, you want to have as many interactions going on as possible in each computation that", "tokens": [407, 5101, 11, 291, 528, 281, 362, 382, 867, 13280, 516, 322, 382, 1944, 294, 1184, 24903, 300], "temperature": 0.0, "avg_logprob": -0.10614940524101257, "compression_ratio": 1.8564814814814814, "no_speech_prob": 1.2217513358336873e-05}, {"id": 675, "seek": 302576, "start": 3051.2400000000002, "end": 3055.5, "text": " you do.", "tokens": [291, 360, 13], "temperature": 0.0, "avg_logprob": -0.10614940524101257, "compression_ratio": 1.8564814814814814, "no_speech_prob": 1.2217513358336873e-05}, {"id": 676, "seek": 305550, "start": 3055.5, "end": 3060.0, "text": " How does concatenating every layer together in a dense net work when the size of the image", "tokens": [1012, 775, 1588, 7186, 990, 633, 4583, 1214, 294, 257, 18011, 2533, 589, 562, 264, 2744, 295, 264, 3256], "temperature": 0.0, "avg_logprob": -0.12733827979819287, "compression_ratio": 1.7621145374449338, "no_speech_prob": 7.41102485335432e-06}, {"id": 677, "seek": 305550, "start": 3060.0, "end": 3066.8, "text": " feature maps is changing through the layers?", "tokens": [4111, 11317, 307, 4473, 807, 264, 7914, 30], "temperature": 0.0, "avg_logprob": -0.12733827979819287, "compression_ratio": 1.7621145374449338, "no_speech_prob": 7.41102485335432e-06}, {"id": 678, "seek": 305550, "start": 3066.8, "end": 3067.8, "text": " That's a great question.", "tokens": [663, 311, 257, 869, 1168, 13], "temperature": 0.0, "avg_logprob": -0.12733827979819287, "compression_ratio": 1.7621145374449338, "no_speech_prob": 7.41102485335432e-06}, {"id": 679, "seek": 305550, "start": 3067.8, "end": 3073.56, "text": " So if you have a stride two conv, you can't keep dense netting.", "tokens": [407, 498, 291, 362, 257, 1056, 482, 732, 3754, 11, 291, 393, 380, 1066, 18011, 2533, 783, 13], "temperature": 0.0, "avg_logprob": -0.12733827979819287, "compression_ratio": 1.7621145374449338, "no_speech_prob": 7.41102485335432e-06}, {"id": 680, "seek": 305550, "start": 3073.56, "end": 3079.04, "text": " So that's what actually happens in a dense net, is you kind of go like dense block growing,", "tokens": [407, 300, 311, 437, 767, 2314, 294, 257, 18011, 2533, 11, 307, 291, 733, 295, 352, 411, 18011, 3461, 4194, 11], "temperature": 0.0, "avg_logprob": -0.12733827979819287, "compression_ratio": 1.7621145374449338, "no_speech_prob": 7.41102485335432e-06}, {"id": 681, "seek": 305550, "start": 3079.04, "end": 3082.04, "text": " dense block growing, dense block growing, so you're getting more and more channels.", "tokens": [18011, 3461, 4194, 11, 18011, 3461, 4194, 11, 370, 291, 434, 1242, 544, 293, 544, 9235, 13], "temperature": 0.0, "avg_logprob": -0.12733827979819287, "compression_ratio": 1.7621145374449338, "no_speech_prob": 7.41102485335432e-06}, {"id": 682, "seek": 308204, "start": 3082.04, "end": 3087.4, "text": " And then you do a stride two conv without a dense block.", "tokens": [400, 550, 291, 360, 257, 1056, 482, 732, 3754, 1553, 257, 18011, 3461, 13], "temperature": 0.0, "avg_logprob": -0.14443502059349647, "compression_ratio": 1.8009049773755657, "no_speech_prob": 5.1735032684518956e-06}, {"id": 683, "seek": 308204, "start": 3087.4, "end": 3089.6, "text": " And so now it's kind of gone.", "tokens": [400, 370, 586, 309, 311, 733, 295, 2780, 13], "temperature": 0.0, "avg_logprob": -0.14443502059349647, "compression_ratio": 1.8009049773755657, "no_speech_prob": 5.1735032684518956e-06}, {"id": 684, "seek": 308204, "start": 3089.6, "end": 3092.32, "text": " And then you just do a few more dense blocks and then it's gone.", "tokens": [400, 550, 291, 445, 360, 257, 1326, 544, 18011, 8474, 293, 550, 309, 311, 2780, 13], "temperature": 0.0, "avg_logprob": -0.14443502059349647, "compression_ratio": 1.8009049773755657, "no_speech_prob": 5.1735032684518956e-06}, {"id": 685, "seek": 308204, "start": 3092.32, "end": 3098.92, "text": " So in practice, a dense block doesn't actually keep all the information all the way through,", "tokens": [407, 294, 3124, 11, 257, 18011, 3461, 1177, 380, 767, 1066, 439, 264, 1589, 439, 264, 636, 807, 11], "temperature": 0.0, "avg_logprob": -0.14443502059349647, "compression_ratio": 1.8009049773755657, "no_speech_prob": 5.1735032684518956e-06}, {"id": 686, "seek": 308204, "start": 3098.92, "end": 3105.44, "text": " but it just every up into every one of these stride two cons.", "tokens": [457, 309, 445, 633, 493, 666, 633, 472, 295, 613, 1056, 482, 732, 1014, 13], "temperature": 0.0, "avg_logprob": -0.14443502059349647, "compression_ratio": 1.8009049773755657, "no_speech_prob": 5.1735032684518956e-06}, {"id": 687, "seek": 308204, "start": 3105.44, "end": 3108.88, "text": " And there's kind of various ways of doing these bottlenecking layers where you're basically", "tokens": [400, 456, 311, 733, 295, 3683, 2098, 295, 884, 613, 44641, 25723, 7914, 689, 291, 434, 1936], "temperature": 0.0, "avg_logprob": -0.14443502059349647, "compression_ratio": 1.8009049773755657, "no_speech_prob": 5.1735032684518956e-06}, {"id": 688, "seek": 310888, "start": 3108.88, "end": 3112.2000000000003, "text": " saying, hey, let's reset.", "tokens": [1566, 11, 4177, 11, 718, 311, 14322, 13], "temperature": 0.0, "avg_logprob": -0.167204835679796, "compression_ratio": 1.6027397260273972, "no_speech_prob": 9.079390110855456e-06}, {"id": 689, "seek": 310888, "start": 3112.2000000000003, "end": 3115.32, "text": " It also helps us keep memory under control because at that point we can decide how many", "tokens": [467, 611, 3665, 505, 1066, 4675, 833, 1969, 570, 412, 300, 935, 321, 393, 4536, 577, 867], "temperature": 0.0, "avg_logprob": -0.167204835679796, "compression_ratio": 1.6027397260273972, "no_speech_prob": 9.079390110855456e-06}, {"id": 690, "seek": 310888, "start": 3115.32, "end": 3118.32, "text": " channels we actually want.", "tokens": [9235, 321, 767, 528, 13], "temperature": 0.0, "avg_logprob": -0.167204835679796, "compression_ratio": 1.6027397260273972, "no_speech_prob": 9.079390110855456e-06}, {"id": 691, "seek": 310888, "start": 3118.32, "end": 3119.32, "text": " Good questions.", "tokens": [2205, 1651, 13], "temperature": 0.0, "avg_logprob": -0.167204835679796, "compression_ratio": 1.6027397260273972, "no_speech_prob": 9.079390110855456e-06}, {"id": 692, "seek": 310888, "start": 3119.32, "end": 3120.32, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.167204835679796, "compression_ratio": 1.6027397260273972, "no_speech_prob": 9.079390110855456e-06}, {"id": 693, "seek": 310888, "start": 3120.32, "end": 3121.7000000000003, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.167204835679796, "compression_ratio": 1.6027397260273972, "no_speech_prob": 9.079390110855456e-06}, {"id": 694, "seek": 310888, "start": 3121.7000000000003, "end": 3130.0, "text": " So in order to create something which can turn crappy images into nice images, we need a", "tokens": [407, 294, 1668, 281, 1884, 746, 597, 393, 1261, 36531, 5267, 666, 1481, 5267, 11, 321, 643, 257], "temperature": 0.0, "avg_logprob": -0.167204835679796, "compression_ratio": 1.6027397260273972, "no_speech_prob": 9.079390110855456e-06}, {"id": 695, "seek": 310888, "start": 3130.0, "end": 3135.08, "text": " data set containing nice versions of images and crappy versions of the same images.", "tokens": [1412, 992, 19273, 1481, 9606, 295, 5267, 293, 36531, 9606, 295, 264, 912, 5267, 13], "temperature": 0.0, "avg_logprob": -0.167204835679796, "compression_ratio": 1.6027397260273972, "no_speech_prob": 9.079390110855456e-06}, {"id": 696, "seek": 313508, "start": 3135.08, "end": 3140.0, "text": " So the easiest way to do that is to start with some nice images and crapify them.", "tokens": [407, 264, 12889, 636, 281, 360, 300, 307, 281, 722, 365, 512, 1481, 5267, 293, 12426, 2505, 552, 13], "temperature": 0.0, "avg_logprob": -0.10011734209562603, "compression_ratio": 1.7053140096618358, "no_speech_prob": 1.3709098993786029e-06}, {"id": 697, "seek": 313508, "start": 3140.0, "end": 3144.68, "text": " And so the way to crapify them is to create a function called crapify, which contains", "tokens": [400, 370, 264, 636, 281, 12426, 2505, 552, 307, 281, 1884, 257, 2445, 1219, 12426, 2505, 11, 597, 8306], "temperature": 0.0, "avg_logprob": -0.10011734209562603, "compression_ratio": 1.7053140096618358, "no_speech_prob": 1.3709098993786029e-06}, {"id": 698, "seek": 313508, "start": 3144.68, "end": 3147.22, "text": " your crapification logic.", "tokens": [428, 12426, 3774, 9952, 13], "temperature": 0.0, "avg_logprob": -0.10011734209562603, "compression_ratio": 1.7053140096618358, "no_speech_prob": 1.3709098993786029e-06}, {"id": 699, "seek": 313508, "start": 3147.22, "end": 3153.84, "text": " So my crapification logic, you can pick your own, is that I open up my nice image.", "tokens": [407, 452, 12426, 3774, 9952, 11, 291, 393, 1888, 428, 1065, 11, 307, 300, 286, 1269, 493, 452, 1481, 3256, 13], "temperature": 0.0, "avg_logprob": -0.10011734209562603, "compression_ratio": 1.7053140096618358, "no_speech_prob": 1.3709098993786029e-06}, {"id": 700, "seek": 313508, "start": 3153.84, "end": 3161.08, "text": " I resize it to be really small, 96 by 96 pixels with bilinear interpolation.", "tokens": [286, 50069, 309, 281, 312, 534, 1359, 11, 24124, 538, 24124, 18668, 365, 8588, 533, 289, 44902, 399, 13], "temperature": 0.0, "avg_logprob": -0.10011734209562603, "compression_ratio": 1.7053140096618358, "no_speech_prob": 1.3709098993786029e-06}, {"id": 701, "seek": 316108, "start": 3161.08, "end": 3165.08, "text": " I then pick a random number between 10 and 70.", "tokens": [286, 550, 1888, 257, 4974, 1230, 1296, 1266, 293, 5285, 13], "temperature": 0.0, "avg_logprob": -0.09890541663536659, "compression_ratio": 1.6459627329192548, "no_speech_prob": 7.071771506161895e-06}, {"id": 702, "seek": 316108, "start": 3165.08, "end": 3171.72, "text": " I draw that number into my image at some random location.", "tokens": [286, 2642, 300, 1230, 666, 452, 3256, 412, 512, 4974, 4914, 13], "temperature": 0.0, "avg_logprob": -0.09890541663536659, "compression_ratio": 1.6459627329192548, "no_speech_prob": 7.071771506161895e-06}, {"id": 703, "seek": 316108, "start": 3171.72, "end": 3176.7999999999997, "text": " And then I save that image with a JPEG quality of that random number.", "tokens": [400, 550, 286, 3155, 300, 3256, 365, 257, 508, 5208, 38, 3125, 295, 300, 4974, 1230, 13], "temperature": 0.0, "avg_logprob": -0.09890541663536659, "compression_ratio": 1.6459627329192548, "no_speech_prob": 7.071771506161895e-06}, {"id": 704, "seek": 316108, "start": 3176.7999999999997, "end": 3181.88, "text": " And a JPEG quality of 10 is like absolute rubbish.", "tokens": [400, 257, 508, 5208, 38, 3125, 295, 1266, 307, 411, 8236, 29978, 13], "temperature": 0.0, "avg_logprob": -0.09890541663536659, "compression_ratio": 1.6459627329192548, "no_speech_prob": 7.071771506161895e-06}, {"id": 705, "seek": 316108, "start": 3181.88, "end": 3186.16, "text": " A JPEG quality of 70 is not bad at all.", "tokens": [316, 508, 5208, 38, 3125, 295, 5285, 307, 406, 1578, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.09890541663536659, "compression_ratio": 1.6459627329192548, "no_speech_prob": 7.071771506161895e-06}, {"id": 706, "seek": 318616, "start": 3186.16, "end": 3195.3599999999997, "text": " So I end up with high quality images, low quality images that look something like these.", "tokens": [407, 286, 917, 493, 365, 1090, 3125, 5267, 11, 2295, 3125, 5267, 300, 574, 746, 411, 613, 13], "temperature": 0.0, "avg_logprob": -0.11860859722172448, "compression_ratio": 1.6382113821138211, "no_speech_prob": 5.014213911636034e-06}, {"id": 707, "seek": 318616, "start": 3195.3599999999997, "end": 3198.7999999999997, "text": " And so you can see this one, there's the image.", "tokens": [400, 370, 291, 393, 536, 341, 472, 11, 456, 311, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.11860859722172448, "compression_ratio": 1.6382113821138211, "no_speech_prob": 5.014213911636034e-06}, {"id": 708, "seek": 318616, "start": 3198.7999999999997, "end": 3202.52, "text": " And this is after transformation, so that's why it's been flipped.", "tokens": [400, 341, 307, 934, 9887, 11, 370, 300, 311, 983, 309, 311, 668, 26273, 13], "temperature": 0.0, "avg_logprob": -0.11860859722172448, "compression_ratio": 1.6382113821138211, "no_speech_prob": 5.014213911636034e-06}, {"id": 709, "seek": 318616, "start": 3202.52, "end": 3206.3599999999997, "text": " And you won't always see the image because we're zooming into them.", "tokens": [400, 291, 1582, 380, 1009, 536, 264, 3256, 570, 321, 434, 48226, 666, 552, 13], "temperature": 0.0, "avg_logprob": -0.11860859722172448, "compression_ratio": 1.6382113821138211, "no_speech_prob": 5.014213911636034e-06}, {"id": 710, "seek": 318616, "start": 3206.3599999999997, "end": 3210.6, "text": " So a lot of the time the image is cropped out.", "tokens": [407, 257, 688, 295, 264, 565, 264, 3256, 307, 4848, 3320, 484, 13], "temperature": 0.0, "avg_logprob": -0.11860859722172448, "compression_ratio": 1.6382113821138211, "no_speech_prob": 5.014213911636034e-06}, {"id": 711, "seek": 318616, "start": 3210.6, "end": 3214.2, "text": " So yeah, it's trying to figure out how to take this incredibly JPEG artifact-y thing", "tokens": [407, 1338, 11, 309, 311, 1382, 281, 2573, 484, 577, 281, 747, 341, 6252, 508, 5208, 38, 34806, 12, 88, 551], "temperature": 0.0, "avg_logprob": -0.11860859722172448, "compression_ratio": 1.6382113821138211, "no_speech_prob": 5.014213911636034e-06}, {"id": 712, "seek": 321420, "start": 3214.2, "end": 3218.2799999999997, "text": " with text written over the top and turn it into this.", "tokens": [365, 2487, 3720, 670, 264, 1192, 293, 1261, 309, 666, 341, 13], "temperature": 0.0, "avg_logprob": -0.15074602179571028, "compression_ratio": 1.6085271317829457, "no_speech_prob": 2.5068131435546093e-05}, {"id": 713, "seek": 321420, "start": 3218.2799999999997, "end": 3223.24, "text": " So I'm using the Oxford Pets data set again, the same one we used in lesson one.", "tokens": [407, 286, 478, 1228, 264, 24786, 430, 1385, 1412, 992, 797, 11, 264, 912, 472, 321, 1143, 294, 6898, 472, 13], "temperature": 0.0, "avg_logprob": -0.15074602179571028, "compression_ratio": 1.6085271317829457, "no_speech_prob": 2.5068131435546093e-05}, {"id": 714, "seek": 321420, "start": 3223.24, "end": 3226.0, "text": " So there's nothing more high quality than pictures of dogs and cats.", "tokens": [407, 456, 311, 1825, 544, 1090, 3125, 813, 5242, 295, 7197, 293, 11111, 13], "temperature": 0.0, "avg_logprob": -0.15074602179571028, "compression_ratio": 1.6085271317829457, "no_speech_prob": 2.5068131435546093e-05}, {"id": 715, "seek": 321420, "start": 3226.0, "end": 3229.4399999999996, "text": " I think we can all agree with that.", "tokens": [286, 519, 321, 393, 439, 3986, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.15074602179571028, "compression_ratio": 1.6085271317829457, "no_speech_prob": 2.5068131435546093e-05}, {"id": 716, "seek": 321420, "start": 3229.4399999999996, "end": 3236.24, "text": " The crappification process can take a while, but Fast.ai has a function called parallel.", "tokens": [440, 2094, 427, 3774, 1399, 393, 747, 257, 1339, 11, 457, 15968, 13, 1301, 575, 257, 2445, 1219, 8952, 13], "temperature": 0.0, "avg_logprob": -0.15074602179571028, "compression_ratio": 1.6085271317829457, "no_speech_prob": 2.5068131435546093e-05}, {"id": 717, "seek": 321420, "start": 3236.24, "end": 3241.58, "text": " And if you pass parallel a function name and a list of things to run that function on,", "tokens": [400, 498, 291, 1320, 8952, 257, 2445, 1315, 293, 257, 1329, 295, 721, 281, 1190, 300, 2445, 322, 11], "temperature": 0.0, "avg_logprob": -0.15074602179571028, "compression_ratio": 1.6085271317829457, "no_speech_prob": 2.5068131435546093e-05}, {"id": 718, "seek": 324158, "start": 3241.58, "end": 3245.3199999999997, "text": " it will run that function on them all in parallel.", "tokens": [309, 486, 1190, 300, 2445, 322, 552, 439, 294, 8952, 13], "temperature": 0.0, "avg_logprob": -0.0682637336406302, "compression_ratio": 1.7605633802816902, "no_speech_prob": 5.681213224306703e-06}, {"id": 719, "seek": 324158, "start": 3245.3199999999997, "end": 3252.04, "text": " So this actually can run pretty quickly.", "tokens": [407, 341, 767, 393, 1190, 1238, 2661, 13], "temperature": 0.0, "avg_logprob": -0.0682637336406302, "compression_ratio": 1.7605633802816902, "no_speech_prob": 5.681213224306703e-06}, {"id": 720, "seek": 324158, "start": 3252.04, "end": 3256.16, "text": " The way you write this function is where you get to do all the interesting stuff in this", "tokens": [440, 636, 291, 2464, 341, 2445, 307, 689, 291, 483, 281, 360, 439, 264, 1880, 1507, 294, 341], "temperature": 0.0, "avg_logprob": -0.0682637336406302, "compression_ratio": 1.7605633802816902, "no_speech_prob": 5.681213224306703e-06}, {"id": 721, "seek": 324158, "start": 3256.16, "end": 3259.0, "text": " assignment.", "tokens": [15187, 13], "temperature": 0.0, "avg_logprob": -0.0682637336406302, "compression_ratio": 1.7605633802816902, "no_speech_prob": 5.681213224306703e-06}, {"id": 722, "seek": 324158, "start": 3259.0, "end": 3263.24, "text": " Try and think of an interesting crappification which does something that you want to do.", "tokens": [6526, 293, 519, 295, 364, 1880, 2094, 427, 3774, 597, 775, 746, 300, 291, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.0682637336406302, "compression_ratio": 1.7605633802816902, "no_speech_prob": 5.681213224306703e-06}, {"id": 723, "seek": 324158, "start": 3263.24, "end": 3268.08, "text": " So if you want to colorize black and white images, you would replace it with black and", "tokens": [407, 498, 291, 528, 281, 2017, 1125, 2211, 293, 2418, 5267, 11, 291, 576, 7406, 309, 365, 2211, 293], "temperature": 0.0, "avg_logprob": -0.0682637336406302, "compression_ratio": 1.7605633802816902, "no_speech_prob": 5.681213224306703e-06}, {"id": 724, "seek": 324158, "start": 3268.08, "end": 3269.08, "text": " white.", "tokens": [2418, 13], "temperature": 0.0, "avg_logprob": -0.0682637336406302, "compression_ratio": 1.7605633802816902, "no_speech_prob": 5.681213224306703e-06}, {"id": 725, "seek": 326908, "start": 3269.08, "end": 3275.4, "text": " If you want something which can take large cutout blocks of image and replace them with", "tokens": [759, 291, 528, 746, 597, 393, 747, 2416, 1723, 346, 8474, 295, 3256, 293, 7406, 552, 365], "temperature": 0.0, "avg_logprob": -0.11975809607175317, "compression_ratio": 1.7041666666666666, "no_speech_prob": 1.0615216524456628e-05}, {"id": 726, "seek": 326908, "start": 3275.4, "end": 3280.6, "text": " kind of hallucinated image, add a big black box to these.", "tokens": [733, 295, 35212, 5410, 3256, 11, 909, 257, 955, 2211, 2424, 281, 613, 13], "temperature": 0.0, "avg_logprob": -0.11975809607175317, "compression_ratio": 1.7041666666666666, "no_speech_prob": 1.0615216524456628e-05}, {"id": 727, "seek": 326908, "start": 3280.6, "end": 3285.4, "text": " If you want something which can take old family photo scans that have been folded up and have", "tokens": [759, 291, 528, 746, 597, 393, 747, 1331, 1605, 5052, 35116, 300, 362, 668, 23940, 493, 293, 362], "temperature": 0.0, "avg_logprob": -0.11975809607175317, "compression_ratio": 1.7041666666666666, "no_speech_prob": 1.0615216524456628e-05}, {"id": 728, "seek": 326908, "start": 3285.4, "end": 3292.04, "text": " crinkles in, try and find a way of adding dust prints and crinkles and so forth.", "tokens": [941, 23870, 294, 11, 853, 293, 915, 257, 636, 295, 5127, 8634, 22305, 293, 941, 23870, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.11975809607175317, "compression_ratio": 1.7041666666666666, "no_speech_prob": 1.0615216524456628e-05}, {"id": 729, "seek": 326908, "start": 3292.04, "end": 3299.0, "text": " Anything that you don't include in Crappify, your model won't learn to fix because every", "tokens": [11998, 300, 291, 500, 380, 4090, 294, 11138, 427, 2505, 11, 428, 2316, 1582, 380, 1466, 281, 3191, 570, 633], "temperature": 0.0, "avg_logprob": -0.11975809607175317, "compression_ratio": 1.7041666666666666, "no_speech_prob": 1.0615216524456628e-05}, {"id": 730, "seek": 329900, "start": 3299.0, "end": 3302.24, "text": " time it sees that in your photos, the input and output will be the same.", "tokens": [565, 309, 8194, 300, 294, 428, 5787, 11, 264, 4846, 293, 5598, 486, 312, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.08816715039704975, "compression_ratio": 1.7688679245283019, "no_speech_prob": 8.26721043267753e-06}, {"id": 731, "seek": 329900, "start": 3302.24, "end": 3309.8, "text": " So it won't consider that to be something worthy of fixing.", "tokens": [407, 309, 1582, 380, 1949, 300, 281, 312, 746, 14829, 295, 19442, 13], "temperature": 0.0, "avg_logprob": -0.08816715039704975, "compression_ratio": 1.7688679245283019, "no_speech_prob": 8.26721043267753e-06}, {"id": 732, "seek": 329900, "start": 3309.8, "end": 3317.52, "text": " So we now want to create a model which can take an input photo that looks like that and", "tokens": [407, 321, 586, 528, 281, 1884, 257, 2316, 597, 393, 747, 364, 4846, 5052, 300, 1542, 411, 300, 293], "temperature": 0.0, "avg_logprob": -0.08816715039704975, "compression_ratio": 1.7688679245283019, "no_speech_prob": 8.26721043267753e-06}, {"id": 733, "seek": 329900, "start": 3317.52, "end": 3319.88, "text": " output something that looks like that.", "tokens": [5598, 746, 300, 1542, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.08816715039704975, "compression_ratio": 1.7688679245283019, "no_speech_prob": 8.26721043267753e-06}, {"id": 734, "seek": 329900, "start": 3319.88, "end": 3324.12, "text": " So obviously what we want to do is use a unit because we already know that units can do", "tokens": [407, 2745, 437, 321, 528, 281, 360, 307, 764, 257, 4985, 570, 321, 1217, 458, 300, 6815, 393, 360], "temperature": 0.0, "avg_logprob": -0.08816715039704975, "compression_ratio": 1.7688679245283019, "no_speech_prob": 8.26721043267753e-06}, {"id": 735, "seek": 329900, "start": 3324.12, "end": 3325.84, "text": " exactly that kind of thing.", "tokens": [2293, 300, 733, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.08816715039704975, "compression_ratio": 1.7688679245283019, "no_speech_prob": 8.26721043267753e-06}, {"id": 736, "seek": 332584, "start": 3325.84, "end": 3330.52, "text": " And we just need to pass the unit that data.", "tokens": [400, 321, 445, 643, 281, 1320, 264, 4985, 300, 1412, 13], "temperature": 0.0, "avg_logprob": -0.15737255965128982, "compression_ratio": 1.584070796460177, "no_speech_prob": 7.889047083153855e-06}, {"id": 737, "seek": 332584, "start": 3330.52, "end": 3337.6400000000003, "text": " So our data is just literally the file names of each of those two folders.", "tokens": [407, 527, 1412, 307, 445, 3736, 264, 3991, 5288, 295, 1184, 295, 729, 732, 31082, 13], "temperature": 0.0, "avg_logprob": -0.15737255965128982, "compression_ratio": 1.584070796460177, "no_speech_prob": 7.889047083153855e-06}, {"id": 738, "seek": 332584, "start": 3337.6400000000003, "end": 3343.28, "text": " Do some transforms, data bunch, normalize, or use ImageNet stats because we're going", "tokens": [1144, 512, 35592, 11, 1412, 3840, 11, 2710, 1125, 11, 420, 764, 29903, 31890, 18152, 570, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.15737255965128982, "compression_ratio": 1.584070796460177, "no_speech_prob": 7.889047083153855e-06}, {"id": 739, "seek": 332584, "start": 3343.28, "end": 3345.4, "text": " to use a pre-trained model.", "tokens": [281, 764, 257, 659, 12, 17227, 2001, 2316, 13], "temperature": 0.0, "avg_logprob": -0.15737255965128982, "compression_ratio": 1.584070796460177, "no_speech_prob": 7.889047083153855e-06}, {"id": 740, "seek": 332584, "start": 3345.4, "end": 3347.04, "text": " Why are we using a pre-trained model?", "tokens": [1545, 366, 321, 1228, 257, 659, 12, 17227, 2001, 2316, 30], "temperature": 0.0, "avg_logprob": -0.15737255965128982, "compression_ratio": 1.584070796460177, "no_speech_prob": 7.889047083153855e-06}, {"id": 741, "seek": 332584, "start": 3347.04, "end": 3352.28, "text": " Well, because if you're going to get rid of this 46, you need to know what probably was", "tokens": [1042, 11, 570, 498, 291, 434, 516, 281, 483, 3973, 295, 341, 17835, 11, 291, 643, 281, 458, 437, 1391, 390], "temperature": 0.0, "avg_logprob": -0.15737255965128982, "compression_ratio": 1.584070796460177, "no_speech_prob": 7.889047083153855e-06}, {"id": 742, "seek": 335228, "start": 3352.28, "end": 3356.0, "text": " there and to know what probably was there, you need to know what this is a picture of.", "tokens": [456, 293, 281, 458, 437, 1391, 390, 456, 11, 291, 643, 281, 458, 437, 341, 307, 257, 3036, 295, 13], "temperature": 0.0, "avg_logprob": -0.12367968786330451, "compression_ratio": 1.597609561752988, "no_speech_prob": 4.565701601677574e-06}, {"id": 743, "seek": 335228, "start": 3356.0, "end": 3359.1200000000003, "text": " Because otherwise how can you possibly know what it ought to look like?", "tokens": [1436, 5911, 577, 393, 291, 6264, 458, 437, 309, 13416, 281, 574, 411, 30], "temperature": 0.0, "avg_logprob": -0.12367968786330451, "compression_ratio": 1.597609561752988, "no_speech_prob": 4.565701601677574e-06}, {"id": 744, "seek": 335228, "start": 3359.1200000000003, "end": 3364.6600000000003, "text": " So let's use a pre-trained model that knows about these kinds of things.", "tokens": [407, 718, 311, 764, 257, 659, 12, 17227, 2001, 2316, 300, 3255, 466, 613, 3685, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.12367968786330451, "compression_ratio": 1.597609561752988, "no_speech_prob": 4.565701601677574e-06}, {"id": 745, "seek": 335228, "start": 3364.6600000000003, "end": 3367.44, "text": " So we create our unit with that data.", "tokens": [407, 321, 1884, 527, 4985, 365, 300, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12367968786330451, "compression_ratio": 1.597609561752988, "no_speech_prob": 4.565701601677574e-06}, {"id": 746, "seek": 335228, "start": 3367.44, "end": 3372.76, "text": " The architecture is ResNet34.", "tokens": [440, 9482, 307, 5015, 31890, 12249, 13], "temperature": 0.0, "avg_logprob": -0.12367968786330451, "compression_ratio": 1.597609561752988, "no_speech_prob": 4.565701601677574e-06}, {"id": 747, "seek": 335228, "start": 3372.76, "end": 3377.1200000000003, "text": " These three things are important and interesting and useful, but I'm going to leave them to", "tokens": [1981, 1045, 721, 366, 1021, 293, 1880, 293, 4420, 11, 457, 286, 478, 516, 281, 1856, 552, 281], "temperature": 0.0, "avg_logprob": -0.12367968786330451, "compression_ratio": 1.597609561752988, "no_speech_prob": 4.565701601677574e-06}, {"id": 748, "seek": 335228, "start": 3377.1200000000003, "end": 3378.1200000000003, "text": " part two.", "tokens": [644, 732, 13], "temperature": 0.0, "avg_logprob": -0.12367968786330451, "compression_ratio": 1.597609561752988, "no_speech_prob": 4.565701601677574e-06}, {"id": 749, "seek": 337812, "start": 3378.12, "end": 3386.96, "text": " For now, you should always include them when you use a unit for this kind of problem.", "tokens": [1171, 586, 11, 291, 820, 1009, 4090, 552, 562, 291, 764, 257, 4985, 337, 341, 733, 295, 1154, 13], "temperature": 0.0, "avg_logprob": -0.21048851013183595, "compression_ratio": 1.6351931330472103, "no_speech_prob": 2.8129966267442796e-06}, {"id": 750, "seek": 337812, "start": 3386.96, "end": 3388.56, "text": " And so now we're going to...", "tokens": [400, 370, 586, 321, 434, 516, 281, 485], "temperature": 0.0, "avg_logprob": -0.21048851013183595, "compression_ratio": 1.6351931330472103, "no_speech_prob": 2.8129966267442796e-06}, {"id": 751, "seek": 337812, "start": 3388.56, "end": 3390.24, "text": " This whole thing I'm calling a generator.", "tokens": [639, 1379, 551, 286, 478, 5141, 257, 19265, 13], "temperature": 0.0, "avg_logprob": -0.21048851013183595, "compression_ratio": 1.6351931330472103, "no_speech_prob": 2.8129966267442796e-06}, {"id": 752, "seek": 337812, "start": 3390.24, "end": 3391.24, "text": " It's going to generate.", "tokens": [467, 311, 516, 281, 8460, 13], "temperature": 0.0, "avg_logprob": -0.21048851013183595, "compression_ratio": 1.6351931330472103, "no_speech_prob": 2.8129966267442796e-06}, {"id": 753, "seek": 337812, "start": 3391.24, "end": 3394.3599999999997, "text": " This is generative modeling.", "tokens": [639, 307, 1337, 1166, 15983, 13], "temperature": 0.0, "avg_logprob": -0.21048851013183595, "compression_ratio": 1.6351931330472103, "no_speech_prob": 2.8129966267442796e-06}, {"id": 754, "seek": 337812, "start": 3394.3599999999997, "end": 3397.3199999999997, "text": " There's not a really formal definition, but it's basically something where the thing we're", "tokens": [821, 311, 406, 257, 534, 9860, 7123, 11, 457, 309, 311, 1936, 746, 689, 264, 551, 321, 434], "temperature": 0.0, "avg_logprob": -0.21048851013183595, "compression_ratio": 1.6351931330472103, "no_speech_prob": 2.8129966267442796e-06}, {"id": 755, "seek": 337812, "start": 3397.3199999999997, "end": 3401.68, "text": " outputting is like a real object, in this case an image.", "tokens": [5598, 783, 307, 411, 257, 957, 2657, 11, 294, 341, 1389, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.21048851013183595, "compression_ratio": 1.6351931330472103, "no_speech_prob": 2.8129966267442796e-06}, {"id": 756, "seek": 337812, "start": 3401.68, "end": 3404.02, "text": " It's not just a number.", "tokens": [467, 311, 406, 445, 257, 1230, 13], "temperature": 0.0, "avg_logprob": -0.21048851013183595, "compression_ratio": 1.6351931330472103, "no_speech_prob": 2.8129966267442796e-06}, {"id": 757, "seek": 340402, "start": 3404.02, "end": 3409.64, "text": " So we're going to create a generator learner, which is this unit learner, and then we can", "tokens": [407, 321, 434, 516, 281, 1884, 257, 19265, 33347, 11, 597, 307, 341, 4985, 33347, 11, 293, 550, 321, 393], "temperature": 0.0, "avg_logprob": -0.14145713293251871, "compression_ratio": 1.6770428015564203, "no_speech_prob": 3.7851893921470037e-06}, {"id": 758, "seek": 340402, "start": 3409.64, "end": 3410.64, "text": " fit.", "tokens": [3318, 13], "temperature": 0.0, "avg_logprob": -0.14145713293251871, "compression_ratio": 1.6770428015564203, "no_speech_prob": 3.7851893921470037e-06}, {"id": 759, "seek": 340402, "start": 3410.64, "end": 3413.52, "text": " We're using MSC loss.", "tokens": [492, 434, 1228, 7395, 34, 4470, 13], "temperature": 0.0, "avg_logprob": -0.14145713293251871, "compression_ratio": 1.6770428015564203, "no_speech_prob": 3.7851893921470037e-06}, {"id": 760, "seek": 340402, "start": 3413.52, "end": 3417.36, "text": " So in other words, what's the mean squared error between the actual pixel value that", "tokens": [407, 294, 661, 2283, 11, 437, 311, 264, 914, 8889, 6713, 1296, 264, 3539, 19261, 2158, 300], "temperature": 0.0, "avg_logprob": -0.14145713293251871, "compression_ratio": 1.6770428015564203, "no_speech_prob": 3.7851893921470037e-06}, {"id": 761, "seek": 340402, "start": 3417.36, "end": 3419.84, "text": " it should be and the pixel value that we predicted?", "tokens": [309, 820, 312, 293, 264, 19261, 2158, 300, 321, 19147, 30], "temperature": 0.0, "avg_logprob": -0.14145713293251871, "compression_ratio": 1.6770428015564203, "no_speech_prob": 3.7851893921470037e-06}, {"id": 762, "seek": 340402, "start": 3419.84, "end": 3423.48, "text": " MSC loss normally expects two vectors.", "tokens": [7395, 34, 4470, 5646, 33280, 732, 18875, 13], "temperature": 0.0, "avg_logprob": -0.14145713293251871, "compression_ratio": 1.6770428015564203, "no_speech_prob": 3.7851893921470037e-06}, {"id": 763, "seek": 340402, "start": 3423.48, "end": 3426.32, "text": " In our case, we have two images.", "tokens": [682, 527, 1389, 11, 321, 362, 732, 5267, 13], "temperature": 0.0, "avg_logprob": -0.14145713293251871, "compression_ratio": 1.6770428015564203, "no_speech_prob": 3.7851893921470037e-06}, {"id": 764, "seek": 340402, "start": 3426.32, "end": 3431.28, "text": " So we have a version called MSC loss flat, which simply flattens out those images into", "tokens": [407, 321, 362, 257, 3037, 1219, 7395, 34, 4470, 4962, 11, 597, 2935, 932, 1591, 694, 484, 729, 5267, 666], "temperature": 0.0, "avg_logprob": -0.14145713293251871, "compression_ratio": 1.6770428015564203, "no_speech_prob": 3.7851893921470037e-06}, {"id": 765, "seek": 340402, "start": 3431.28, "end": 3433.88, "text": " a big long vector.", "tokens": [257, 955, 938, 8062, 13], "temperature": 0.0, "avg_logprob": -0.14145713293251871, "compression_ratio": 1.6770428015564203, "no_speech_prob": 3.7851893921470037e-06}, {"id": 766, "seek": 343388, "start": 3433.88, "end": 3435.88, "text": " There's never any reason not to use this.", "tokens": [821, 311, 1128, 604, 1778, 406, 281, 764, 341, 13], "temperature": 0.0, "avg_logprob": -0.13182922741314312, "compression_ratio": 1.5542168674698795, "no_speech_prob": 1.0782320714497473e-05}, {"id": 767, "seek": 343388, "start": 3435.88, "end": 3437.36, "text": " Even if you do have a vector, it works fine.", "tokens": [2754, 498, 291, 360, 362, 257, 8062, 11, 309, 1985, 2489, 13], "temperature": 0.0, "avg_logprob": -0.13182922741314312, "compression_ratio": 1.5542168674698795, "no_speech_prob": 1.0782320714497473e-05}, {"id": 768, "seek": 343388, "start": 3437.36, "end": 3440.36, "text": " If you don't have a vector, it'll also work fine.", "tokens": [759, 291, 500, 380, 362, 257, 8062, 11, 309, 603, 611, 589, 2489, 13], "temperature": 0.0, "avg_logprob": -0.13182922741314312, "compression_ratio": 1.5542168674698795, "no_speech_prob": 1.0782320714497473e-05}, {"id": 769, "seek": 343388, "start": 3440.36, "end": 3446.44, "text": " So we're already down to.05 mean squared error on the pixel values, which is not bad", "tokens": [407, 321, 434, 1217, 760, 281, 2411, 13328, 914, 8889, 6713, 322, 264, 19261, 4190, 11, 597, 307, 406, 1578], "temperature": 0.0, "avg_logprob": -0.13182922741314312, "compression_ratio": 1.5542168674698795, "no_speech_prob": 1.0782320714497473e-05}, {"id": 770, "seek": 343388, "start": 3446.44, "end": 3449.56, "text": " after 1 minute 35.", "tokens": [934, 502, 3456, 6976, 13], "temperature": 0.0, "avg_logprob": -0.13182922741314312, "compression_ratio": 1.5542168674698795, "no_speech_prob": 1.0782320714497473e-05}, {"id": 771, "seek": 343388, "start": 3449.56, "end": 3454.6800000000003, "text": " Like all things in Fast.ai pretty much, because we're doing transfer learning by default,", "tokens": [1743, 439, 721, 294, 15968, 13, 1301, 1238, 709, 11, 570, 321, 434, 884, 5003, 2539, 538, 7576, 11], "temperature": 0.0, "avg_logprob": -0.13182922741314312, "compression_ratio": 1.5542168674698795, "no_speech_prob": 1.0782320714497473e-05}, {"id": 772, "seek": 343388, "start": 3454.6800000000003, "end": 3460.2000000000003, "text": " when you create this, it'll freeze the pre-trained part.", "tokens": [562, 291, 1884, 341, 11, 309, 603, 15959, 264, 659, 12, 17227, 2001, 644, 13], "temperature": 0.0, "avg_logprob": -0.13182922741314312, "compression_ratio": 1.5542168674698795, "no_speech_prob": 1.0782320714497473e-05}, {"id": 773, "seek": 346020, "start": 3460.2, "end": 3466.0, "text": " And the pre-trained part of a UNet is this part, the downsampling part.", "tokens": [400, 264, 659, 12, 17227, 2001, 644, 295, 257, 8229, 302, 307, 341, 644, 11, 264, 760, 19988, 11970, 644, 13], "temperature": 0.0, "avg_logprob": -0.11404208677360811, "compression_ratio": 1.4684210526315788, "no_speech_prob": 3.6687811189040076e-06}, {"id": 774, "seek": 346020, "start": 3466.0, "end": 3467.22, "text": " That's where the ResNet is.", "tokens": [663, 311, 689, 264, 5015, 31890, 307, 13], "temperature": 0.0, "avg_logprob": -0.11404208677360811, "compression_ratio": 1.4684210526315788, "no_speech_prob": 3.6687811189040076e-06}, {"id": 775, "seek": 346020, "start": 3467.22, "end": 3473.7599999999998, "text": " So let's unfreeze that and train a little more.", "tokens": [407, 718, 311, 3971, 701, 1381, 300, 293, 3847, 257, 707, 544, 13], "temperature": 0.0, "avg_logprob": -0.11404208677360811, "compression_ratio": 1.4684210526315788, "no_speech_prob": 3.6687811189040076e-06}, {"id": 776, "seek": 346020, "start": 3473.7599999999998, "end": 3475.64, "text": " And look at that.", "tokens": [400, 574, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.11404208677360811, "compression_ratio": 1.4684210526315788, "no_speech_prob": 3.6687811189040076e-06}, {"id": 777, "seek": 346020, "start": 3475.64, "end": 3483.7999999999997, "text": " So with four minutes of training, we've got something which is basically doing a perfect", "tokens": [407, 365, 1451, 2077, 295, 3097, 11, 321, 600, 658, 746, 597, 307, 1936, 884, 257, 2176], "temperature": 0.0, "avg_logprob": -0.11404208677360811, "compression_ratio": 1.4684210526315788, "no_speech_prob": 3.6687811189040076e-06}, {"id": 778, "seek": 346020, "start": 3483.7999999999997, "end": 3487.6, "text": " job of removing numbers.", "tokens": [1691, 295, 12720, 3547, 13], "temperature": 0.0, "avg_logprob": -0.11404208677360811, "compression_ratio": 1.4684210526315788, "no_speech_prob": 3.6687811189040076e-06}, {"id": 779, "seek": 348760, "start": 3487.6, "end": 3494.96, "text": " It's certainly not doing a good job of upsampling, but it's definitely doing a nice...", "tokens": [467, 311, 3297, 406, 884, 257, 665, 1691, 295, 15497, 335, 11970, 11, 457, 309, 311, 2138, 884, 257, 1481, 485], "temperature": 0.0, "avg_logprob": -0.14588377427081672, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.6685471513919765e-06}, {"id": 780, "seek": 348760, "start": 3494.96, "end": 3499.2, "text": " Sometimes when it removes a number, it maybe leaves a little bit of JPEG artifact, but", "tokens": [4803, 562, 309, 30445, 257, 1230, 11, 309, 1310, 5510, 257, 707, 857, 295, 508, 5208, 38, 34806, 11, 457], "temperature": 0.0, "avg_logprob": -0.14588377427081672, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.6685471513919765e-06}, {"id": 781, "seek": 348760, "start": 3499.2, "end": 3501.12, "text": " it's certainly doing something pretty useful.", "tokens": [309, 311, 3297, 884, 746, 1238, 4420, 13], "temperature": 0.0, "avg_logprob": -0.14588377427081672, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.6685471513919765e-06}, {"id": 782, "seek": 348760, "start": 3501.12, "end": 3508.3199999999997, "text": " And so if all we wanted to do was kind of watermark removal, we'd be finished.", "tokens": [400, 370, 498, 439, 321, 1415, 281, 360, 390, 733, 295, 1281, 5638, 17933, 11, 321, 1116, 312, 4335, 13], "temperature": 0.0, "avg_logprob": -0.14588377427081672, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.6685471513919765e-06}, {"id": 783, "seek": 348760, "start": 3508.3199999999997, "end": 3514.92, "text": " We're not finished because we actually want this thing to look more like this thing.", "tokens": [492, 434, 406, 4335, 570, 321, 767, 528, 341, 551, 281, 574, 544, 411, 341, 551, 13], "temperature": 0.0, "avg_logprob": -0.14588377427081672, "compression_ratio": 1.6160337552742616, "no_speech_prob": 3.6685471513919765e-06}, {"id": 784, "seek": 351492, "start": 3514.92, "end": 3518.56, "text": " So how are we going to do that?", "tokens": [407, 577, 366, 321, 516, 281, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.13956645650601168, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.601558662718162e-06}, {"id": 785, "seek": 351492, "start": 3518.56, "end": 3523.44, "text": " The problem, the reason that we're not making as much progress with that as we'd like is", "tokens": [440, 1154, 11, 264, 1778, 300, 321, 434, 406, 1455, 382, 709, 4205, 365, 300, 382, 321, 1116, 411, 307], "temperature": 0.0, "avg_logprob": -0.13956645650601168, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.601558662718162e-06}, {"id": 786, "seek": 351492, "start": 3523.44, "end": 3528.76, "text": " that our loss function doesn't really describe what we want, because actually the mean squared", "tokens": [300, 527, 4470, 2445, 1177, 380, 534, 6786, 437, 321, 528, 11, 570, 767, 264, 914, 8889], "temperature": 0.0, "avg_logprob": -0.13956645650601168, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.601558662718162e-06}, {"id": 787, "seek": 351492, "start": 3528.76, "end": 3534.32, "text": " error between the pixels of this and this is actually very small.", "tokens": [6713, 1296, 264, 18668, 295, 341, 293, 341, 307, 767, 588, 1359, 13], "temperature": 0.0, "avg_logprob": -0.13956645650601168, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.601558662718162e-06}, {"id": 788, "seek": 351492, "start": 3534.32, "end": 3539.96, "text": " If you actually think about it, most of the pixels are very nearly the right color.", "tokens": [759, 291, 767, 519, 466, 309, 11, 881, 295, 264, 18668, 366, 588, 6217, 264, 558, 2017, 13], "temperature": 0.0, "avg_logprob": -0.13956645650601168, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.601558662718162e-06}, {"id": 789, "seek": 351492, "start": 3539.96, "end": 3544.52, "text": " But we're missing the texture of the pillow, and we're missing the eyeballs entirely pretty", "tokens": [583, 321, 434, 5361, 264, 8091, 295, 264, 18581, 11, 293, 321, 434, 5361, 264, 43758, 7696, 1238], "temperature": 0.0, "avg_logprob": -0.13956645650601168, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.601558662718162e-06}, {"id": 790, "seek": 354452, "start": 3544.52, "end": 3545.9, "text": " much.", "tokens": [709, 13], "temperature": 0.0, "avg_logprob": -0.1224423779381646, "compression_ratio": 1.5053763440860215, "no_speech_prob": 3.726606109921704e-06}, {"id": 791, "seek": 354452, "start": 3545.9, "end": 3548.84, "text": " And we're missing the texture of the fur.", "tokens": [400, 321, 434, 5361, 264, 8091, 295, 264, 2687, 13], "temperature": 0.0, "avg_logprob": -0.1224423779381646, "compression_ratio": 1.5053763440860215, "no_speech_prob": 3.726606109921704e-06}, {"id": 792, "seek": 354452, "start": 3548.84, "end": 3556.92, "text": " So we want some loss function that does a better job than pixel mean squared error loss", "tokens": [407, 321, 528, 512, 4470, 2445, 300, 775, 257, 1101, 1691, 813, 19261, 914, 8889, 6713, 4470], "temperature": 0.0, "avg_logprob": -0.1224423779381646, "compression_ratio": 1.5053763440860215, "no_speech_prob": 3.726606109921704e-06}, {"id": 793, "seek": 354452, "start": 3556.92, "end": 3563.7, "text": " of saying, is this a good quality picture of this thing?", "tokens": [295, 1566, 11, 307, 341, 257, 665, 3125, 3036, 295, 341, 551, 30], "temperature": 0.0, "avg_logprob": -0.1224423779381646, "compression_ratio": 1.5053763440860215, "no_speech_prob": 3.726606109921704e-06}, {"id": 794, "seek": 354452, "start": 3563.7, "end": 3571.96, "text": " So there's a fairly general way of answering that question, and it's something called a", "tokens": [407, 456, 311, 257, 6457, 2674, 636, 295, 13430, 300, 1168, 11, 293, 309, 311, 746, 1219, 257], "temperature": 0.0, "avg_logprob": -0.1224423779381646, "compression_ratio": 1.5053763440860215, "no_speech_prob": 3.726606109921704e-06}, {"id": 795, "seek": 357196, "start": 3571.96, "end": 3576.76, "text": " Generative Adversarial Network, or GAN.", "tokens": [15409, 1166, 1999, 840, 44745, 12640, 11, 420, 460, 1770, 13], "temperature": 0.0, "avg_logprob": -0.14944301000455532, "compression_ratio": 1.4639175257731958, "no_speech_prob": 3.1381184726342326e-06}, {"id": 796, "seek": 357196, "start": 3576.76, "end": 3584.92, "text": " And a GAN tries to solve this problem by using a loss function which actually calls another", "tokens": [400, 257, 460, 1770, 9898, 281, 5039, 341, 1154, 538, 1228, 257, 4470, 2445, 597, 767, 5498, 1071], "temperature": 0.0, "avg_logprob": -0.14944301000455532, "compression_ratio": 1.4639175257731958, "no_speech_prob": 3.1381184726342326e-06}, {"id": 797, "seek": 357196, "start": 3584.92, "end": 3586.32, "text": " model.", "tokens": [2316, 13], "temperature": 0.0, "avg_logprob": -0.14944301000455532, "compression_ratio": 1.4639175257731958, "no_speech_prob": 3.1381184726342326e-06}, {"id": 798, "seek": 357196, "start": 3586.32, "end": 3592.78, "text": " And let me describe it to you.", "tokens": [400, 718, 385, 6786, 309, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.14944301000455532, "compression_ratio": 1.4639175257731958, "no_speech_prob": 3.1381184726342326e-06}, {"id": 799, "seek": 357196, "start": 3592.78, "end": 3597.56, "text": " So we've got our crappy image, and we've already created a generator.", "tokens": [407, 321, 600, 658, 527, 36531, 3256, 11, 293, 321, 600, 1217, 2942, 257, 19265, 13], "temperature": 0.0, "avg_logprob": -0.14944301000455532, "compression_ratio": 1.4639175257731958, "no_speech_prob": 3.1381184726342326e-06}, {"id": 800, "seek": 357196, "start": 3597.56, "end": 3600.0, "text": " It's not a great one, but it's not terrible.", "tokens": [467, 311, 406, 257, 869, 472, 11, 457, 309, 311, 406, 6237, 13], "temperature": 0.0, "avg_logprob": -0.14944301000455532, "compression_ratio": 1.4639175257731958, "no_speech_prob": 3.1381184726342326e-06}, {"id": 801, "seek": 360000, "start": 3600.0, "end": 3608.2, "text": " And that's creating predictions like this.", "tokens": [400, 300, 311, 4084, 21264, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.14849102961552607, "compression_ratio": 1.5401069518716577, "no_speech_prob": 4.7107532736845315e-06}, {"id": 802, "seek": 360000, "start": 3608.2, "end": 3614.24, "text": " We have a high-res image like that, and we can compare the high-res image to the prediction", "tokens": [492, 362, 257, 1090, 12, 495, 3256, 411, 300, 11, 293, 321, 393, 6794, 264, 1090, 12, 495, 3256, 281, 264, 17630], "temperature": 0.0, "avg_logprob": -0.14849102961552607, "compression_ratio": 1.5401069518716577, "no_speech_prob": 4.7107532736845315e-06}, {"id": 803, "seek": 360000, "start": 3614.24, "end": 3620.04, "text": " with pixel MSE.", "tokens": [365, 19261, 376, 5879, 13], "temperature": 0.0, "avg_logprob": -0.14849102961552607, "compression_ratio": 1.5401069518716577, "no_speech_prob": 4.7107532736845315e-06}, {"id": 804, "seek": 360000, "start": 3620.04, "end": 3626.6, "text": " We could also train another model which we would variously call either the discriminator", "tokens": [492, 727, 611, 3847, 1071, 2316, 597, 321, 576, 3683, 356, 818, 2139, 264, 20828, 1639], "temperature": 0.0, "avg_logprob": -0.14849102961552607, "compression_ratio": 1.5401069518716577, "no_speech_prob": 4.7107532736845315e-06}, {"id": 805, "seek": 360000, "start": 3626.6, "end": 3627.6, "text": " or the critic.", "tokens": [420, 264, 7850, 13], "temperature": 0.0, "avg_logprob": -0.14849102961552607, "compression_ratio": 1.5401069518716577, "no_speech_prob": 4.7107532736845315e-06}, {"id": 806, "seek": 360000, "start": 3627.6, "end": 3628.6, "text": " They've both been the same thing.", "tokens": [814, 600, 1293, 668, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.14849102961552607, "compression_ratio": 1.5401069518716577, "no_speech_prob": 4.7107532736845315e-06}, {"id": 807, "seek": 362860, "start": 3628.6, "end": 3631.16, "text": " I'll call it a critic.", "tokens": [286, 603, 818, 309, 257, 7850, 13], "temperature": 0.0, "avg_logprob": -0.13150387543898362, "compression_ratio": 1.7826086956521738, "no_speech_prob": 8.139453711919487e-06}, {"id": 808, "seek": 362860, "start": 3631.16, "end": 3637.68, "text": " We could try and build a binary classification model that takes all the pairs of the generated", "tokens": [492, 727, 853, 293, 1322, 257, 17434, 21538, 2316, 300, 2516, 439, 264, 15494, 295, 264, 10833], "temperature": 0.0, "avg_logprob": -0.13150387543898362, "compression_ratio": 1.7826086956521738, "no_speech_prob": 8.139453711919487e-06}, {"id": 809, "seek": 362860, "start": 3637.68, "end": 3645.44, "text": " image and the real high-res image and tries to learn to classify which is which.", "tokens": [3256, 293, 264, 957, 1090, 12, 495, 3256, 293, 9898, 281, 1466, 281, 33872, 597, 307, 597, 13], "temperature": 0.0, "avg_logprob": -0.13150387543898362, "compression_ratio": 1.7826086956521738, "no_speech_prob": 8.139453711919487e-06}, {"id": 810, "seek": 362860, "start": 3645.44, "end": 3650.36, "text": " So look at some picture and say, hey, what do you think?", "tokens": [407, 574, 412, 512, 3036, 293, 584, 11, 4177, 11, 437, 360, 291, 519, 30], "temperature": 0.0, "avg_logprob": -0.13150387543898362, "compression_ratio": 1.7826086956521738, "no_speech_prob": 8.139453711919487e-06}, {"id": 811, "seek": 362860, "start": 3650.36, "end": 3652.68, "text": " Is that a high-res cat or is that a generated cat?", "tokens": [1119, 300, 257, 1090, 12, 495, 3857, 420, 307, 300, 257, 10833, 3857, 30], "temperature": 0.0, "avg_logprob": -0.13150387543898362, "compression_ratio": 1.7826086956521738, "no_speech_prob": 8.139453711919487e-06}, {"id": 812, "seek": 362860, "start": 3652.68, "end": 3653.68, "text": " How about this one?", "tokens": [1012, 466, 341, 472, 30], "temperature": 0.0, "avg_logprob": -0.13150387543898362, "compression_ratio": 1.7826086956521738, "no_speech_prob": 8.139453711919487e-06}, {"id": 813, "seek": 362860, "start": 3653.68, "end": 3655.24, "text": " Is that a high-res cat or a generated cat?", "tokens": [1119, 300, 257, 1090, 12, 495, 3857, 420, 257, 10833, 3857, 30], "temperature": 0.0, "avg_logprob": -0.13150387543898362, "compression_ratio": 1.7826086956521738, "no_speech_prob": 8.139453711919487e-06}, {"id": 814, "seek": 365524, "start": 3655.24, "end": 3661.3399999999997, "text": " So just a regular standard binary cross-entropy classifier.", "tokens": [407, 445, 257, 3890, 3832, 17434, 3278, 12, 317, 27514, 1508, 9902, 13], "temperature": 0.0, "avg_logprob": -0.10845996760114839, "compression_ratio": 1.521978021978022, "no_speech_prob": 6.577909061888931e-07}, {"id": 815, "seek": 365524, "start": 3661.3399999999997, "end": 3664.5, "text": " So we know how to do that already.", "tokens": [407, 321, 458, 577, 281, 360, 300, 1217, 13], "temperature": 0.0, "avg_logprob": -0.10845996760114839, "compression_ratio": 1.521978021978022, "no_speech_prob": 6.577909061888931e-07}, {"id": 816, "seek": 365524, "start": 3664.5, "end": 3671.8799999999997, "text": " So if we had one of those, we could now train, we could fine-tune the generator, and rather", "tokens": [407, 498, 321, 632, 472, 295, 729, 11, 321, 727, 586, 3847, 11, 321, 727, 2489, 12, 83, 2613, 264, 19265, 11, 293, 2831], "temperature": 0.0, "avg_logprob": -0.10845996760114839, "compression_ratio": 1.521978021978022, "no_speech_prob": 6.577909061888931e-07}, {"id": 817, "seek": 365524, "start": 3671.8799999999997, "end": 3679.8799999999997, "text": " than using pixel MSE as the loss, the loss could be how good are we at fooling the critic?", "tokens": [813, 1228, 19261, 376, 5879, 382, 264, 4470, 11, 264, 4470, 727, 312, 577, 665, 366, 321, 412, 7979, 278, 264, 7850, 30], "temperature": 0.0, "avg_logprob": -0.10845996760114839, "compression_ratio": 1.521978021978022, "no_speech_prob": 6.577909061888931e-07}, {"id": 818, "seek": 367988, "start": 3679.88, "end": 3687.76, "text": " So can we create generated images that the critic thinks are real?", "tokens": [407, 393, 321, 1884, 10833, 5267, 300, 264, 7850, 7309, 366, 957, 30], "temperature": 0.0, "avg_logprob": -0.09134184795877208, "compression_ratio": 1.6407766990291262, "no_speech_prob": 5.714982762583531e-07}, {"id": 819, "seek": 367988, "start": 3687.76, "end": 3690.88, "text": " So that would be a very good plan, right?", "tokens": [407, 300, 576, 312, 257, 588, 665, 1393, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.09134184795877208, "compression_ratio": 1.6407766990291262, "no_speech_prob": 5.714982762583531e-07}, {"id": 820, "seek": 367988, "start": 3690.88, "end": 3696.88, "text": " Because if it can do that, if the loss function is am I fooling the critic, then it's going", "tokens": [1436, 498, 309, 393, 360, 300, 11, 498, 264, 4470, 2445, 307, 669, 286, 7979, 278, 264, 7850, 11, 550, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.09134184795877208, "compression_ratio": 1.6407766990291262, "no_speech_prob": 5.714982762583531e-07}, {"id": 821, "seek": 367988, "start": 3696.88, "end": 3703.8, "text": " to learn to create images which the critic can't tell whether they're real or fake.", "tokens": [281, 1466, 281, 1884, 5267, 597, 264, 7850, 393, 380, 980, 1968, 436, 434, 957, 420, 7592, 13], "temperature": 0.0, "avg_logprob": -0.09134184795877208, "compression_ratio": 1.6407766990291262, "no_speech_prob": 5.714982762583531e-07}, {"id": 822, "seek": 367988, "start": 3703.8, "end": 3709.56, "text": " So we could do that for a while, train a few batches.", "tokens": [407, 321, 727, 360, 300, 337, 257, 1339, 11, 3847, 257, 1326, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.09134184795877208, "compression_ratio": 1.6407766990291262, "no_speech_prob": 5.714982762583531e-07}, {"id": 823, "seek": 370956, "start": 3709.56, "end": 3712.32, "text": " But the critic isn't that great.", "tokens": [583, 264, 7850, 1943, 380, 300, 869, 13], "temperature": 0.0, "avg_logprob": -0.09695882456643241, "compression_ratio": 1.9781659388646289, "no_speech_prob": 1.1125292076030746e-05}, {"id": 824, "seek": 370956, "start": 3712.32, "end": 3715.4, "text": " The reason the critic isn't that great is because it wasn't that hard.", "tokens": [440, 1778, 264, 7850, 1943, 380, 300, 869, 307, 570, 309, 2067, 380, 300, 1152, 13], "temperature": 0.0, "avg_logprob": -0.09695882456643241, "compression_ratio": 1.9781659388646289, "no_speech_prob": 1.1125292076030746e-05}, {"id": 825, "seek": 370956, "start": 3715.4, "end": 3719.36, "text": " These images are really shitty, so it's really easy to tell the difference.", "tokens": [1981, 5267, 366, 534, 30748, 11, 370, 309, 311, 534, 1858, 281, 980, 264, 2649, 13], "temperature": 0.0, "avg_logprob": -0.09695882456643241, "compression_ratio": 1.9781659388646289, "no_speech_prob": 1.1125292076030746e-05}, {"id": 826, "seek": 370956, "start": 3719.36, "end": 3725.72, "text": " So after we train the generator a little bit more using the critic as the loss function,", "tokens": [407, 934, 321, 3847, 264, 19265, 257, 707, 857, 544, 1228, 264, 7850, 382, 264, 4470, 2445, 11], "temperature": 0.0, "avg_logprob": -0.09695882456643241, "compression_ratio": 1.9781659388646289, "no_speech_prob": 1.1125292076030746e-05}, {"id": 827, "seek": 370956, "start": 3725.72, "end": 3729.64, "text": " the generator is going to get really good at fooling the critic.", "tokens": [264, 19265, 307, 516, 281, 483, 534, 665, 412, 7979, 278, 264, 7850, 13], "temperature": 0.0, "avg_logprob": -0.09695882456643241, "compression_ratio": 1.9781659388646289, "no_speech_prob": 1.1125292076030746e-05}, {"id": 828, "seek": 370956, "start": 3729.64, "end": 3734.58, "text": " So now we're going to stop training the generator and we'll drain the critic some more on these", "tokens": [407, 586, 321, 434, 516, 281, 1590, 3097, 264, 19265, 293, 321, 603, 12339, 264, 7850, 512, 544, 322, 613], "temperature": 0.0, "avg_logprob": -0.09695882456643241, "compression_ratio": 1.9781659388646289, "no_speech_prob": 1.1125292076030746e-05}, {"id": 829, "seek": 370956, "start": 3734.58, "end": 3736.84, "text": " newly generated images.", "tokens": [15109, 10833, 5267, 13], "temperature": 0.0, "avg_logprob": -0.09695882456643241, "compression_ratio": 1.9781659388646289, "no_speech_prob": 1.1125292076030746e-05}, {"id": 830, "seek": 373684, "start": 3736.84, "end": 3741.52, "text": " So now that the generator is better, it's now a tougher task for the critic to decide", "tokens": [407, 586, 300, 264, 19265, 307, 1101, 11, 309, 311, 586, 257, 30298, 5633, 337, 264, 7850, 281, 4536], "temperature": 0.0, "avg_logprob": -0.11061366271972656, "compression_ratio": 1.8838951310861423, "no_speech_prob": 4.860208264290122e-06}, {"id": 831, "seek": 373684, "start": 3741.52, "end": 3743.0, "text": " which is real and which is fake.", "tokens": [597, 307, 957, 293, 597, 307, 7592, 13], "temperature": 0.0, "avg_logprob": -0.11061366271972656, "compression_ratio": 1.8838951310861423, "no_speech_prob": 4.860208264290122e-06}, {"id": 832, "seek": 373684, "start": 3743.0, "end": 3745.92, "text": " So we'll train that a little bit more.", "tokens": [407, 321, 603, 3847, 300, 257, 707, 857, 544, 13], "temperature": 0.0, "avg_logprob": -0.11061366271972656, "compression_ratio": 1.8838951310861423, "no_speech_prob": 4.860208264290122e-06}, {"id": 833, "seek": 373684, "start": 3745.92, "end": 3749.04, "text": " And then once we've done that and the critic is now pretty good at recognising the difference", "tokens": [400, 550, 1564, 321, 600, 1096, 300, 293, 264, 7850, 307, 586, 1238, 665, 412, 3068, 3436, 264, 2649], "temperature": 0.0, "avg_logprob": -0.11061366271972656, "compression_ratio": 1.8838951310861423, "no_speech_prob": 4.860208264290122e-06}, {"id": 834, "seek": 373684, "start": 3749.04, "end": 3754.52, "text": " between the better generated images and the originals, we'll go back and we'll fine tune", "tokens": [1296, 264, 1101, 10833, 5267, 293, 264, 4957, 1124, 11, 321, 603, 352, 646, 293, 321, 603, 2489, 10864], "temperature": 0.0, "avg_logprob": -0.11061366271972656, "compression_ratio": 1.8838951310861423, "no_speech_prob": 4.860208264290122e-06}, {"id": 835, "seek": 373684, "start": 3754.52, "end": 3760.08, "text": " the generator some more using the better discriminator, the better critic as the loss function.", "tokens": [264, 19265, 512, 544, 1228, 264, 1101, 20828, 1639, 11, 264, 1101, 7850, 382, 264, 4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.11061366271972656, "compression_ratio": 1.8838951310861423, "no_speech_prob": 4.860208264290122e-06}, {"id": 836, "seek": 373684, "start": 3760.08, "end": 3764.4, "text": " And so we'll just go ping pong, ping pong, backwards and forwards.", "tokens": [400, 370, 321, 603, 445, 352, 26151, 36164, 11, 26151, 36164, 11, 12204, 293, 30126, 13], "temperature": 0.0, "avg_logprob": -0.11061366271972656, "compression_ratio": 1.8838951310861423, "no_speech_prob": 4.860208264290122e-06}, {"id": 837, "seek": 376440, "start": 3764.4, "end": 3767.88, "text": " That's a GAN.", "tokens": [663, 311, 257, 460, 1770, 13], "temperature": 0.0, "avg_logprob": -0.17394295999826478, "compression_ratio": 1.694915254237288, "no_speech_prob": 2.0460905943764374e-05}, {"id": 838, "seek": 376440, "start": 3767.88, "end": 3768.88, "text": " That's our version of GAN.", "tokens": [663, 311, 527, 3037, 295, 460, 1770, 13], "temperature": 0.0, "avg_logprob": -0.17394295999826478, "compression_ratio": 1.694915254237288, "no_speech_prob": 2.0460905943764374e-05}, {"id": 839, "seek": 376440, "start": 3768.88, "end": 3772.84, "text": " I don't know if anybody's written this before.", "tokens": [286, 500, 380, 458, 498, 4472, 311, 3720, 341, 949, 13], "temperature": 0.0, "avg_logprob": -0.17394295999826478, "compression_ratio": 1.694915254237288, "no_speech_prob": 2.0460905943764374e-05}, {"id": 840, "seek": 376440, "start": 3772.84, "end": 3777.88, "text": " We've created a new version of a GAN which is kind of a lot like the original GANs, but", "tokens": [492, 600, 2942, 257, 777, 3037, 295, 257, 460, 1770, 597, 307, 733, 295, 257, 688, 411, 264, 3380, 460, 1770, 82, 11, 457], "temperature": 0.0, "avg_logprob": -0.17394295999826478, "compression_ratio": 1.694915254237288, "no_speech_prob": 2.0460905943764374e-05}, {"id": 841, "seek": 376440, "start": 3777.88, "end": 3782.2400000000002, "text": " we have this neat trick where we pre-train the generator and we pre-train the critic.", "tokens": [321, 362, 341, 10654, 4282, 689, 321, 659, 12, 83, 7146, 264, 19265, 293, 321, 659, 12, 83, 7146, 264, 7850, 13], "temperature": 0.0, "avg_logprob": -0.17394295999826478, "compression_ratio": 1.694915254237288, "no_speech_prob": 2.0460905943764374e-05}, {"id": 842, "seek": 376440, "start": 3782.2400000000002, "end": 3787.32, "text": " I mean GANs have been kind of in the news a lot.", "tokens": [286, 914, 460, 1770, 82, 362, 668, 733, 295, 294, 264, 2583, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.17394295999826478, "compression_ratio": 1.694915254237288, "no_speech_prob": 2.0460905943764374e-05}, {"id": 843, "seek": 376440, "start": 3787.32, "end": 3791.08, "text": " They're a pretty fashionable tool and if you've seen them you may have heard that they're", "tokens": [814, 434, 257, 1238, 40735, 2290, 293, 498, 291, 600, 1612, 552, 291, 815, 362, 2198, 300, 436, 434], "temperature": 0.0, "avg_logprob": -0.17394295999826478, "compression_ratio": 1.694915254237288, "no_speech_prob": 2.0460905943764374e-05}, {"id": 844, "seek": 379108, "start": 3791.08, "end": 3794.92, "text": " a real pain to train.", "tokens": [257, 957, 1822, 281, 3847, 13], "temperature": 0.0, "avg_logprob": -0.14528146386146545, "compression_ratio": 1.9137254901960785, "no_speech_prob": 1.6698586478014477e-05}, {"id": 845, "seek": 379108, "start": 3794.92, "end": 3799.3199999999997, "text": " But it turns out, we realised that really most of the pain of training them was at the", "tokens": [583, 309, 4523, 484, 11, 321, 21337, 300, 534, 881, 295, 264, 1822, 295, 3097, 552, 390, 412, 264], "temperature": 0.0, "avg_logprob": -0.14528146386146545, "compression_ratio": 1.9137254901960785, "no_speech_prob": 1.6698586478014477e-05}, {"id": 846, "seek": 379108, "start": 3799.3199999999997, "end": 3800.3199999999997, "text": " start.", "tokens": [722, 13], "temperature": 0.0, "avg_logprob": -0.14528146386146545, "compression_ratio": 1.9137254901960785, "no_speech_prob": 1.6698586478014477e-05}, {"id": 847, "seek": 379108, "start": 3800.3199999999997, "end": 3804.36, "text": " If you don't have a pre-train generator and you don't have a pre-train critic, then it's", "tokens": [759, 291, 500, 380, 362, 257, 659, 12, 83, 7146, 19265, 293, 291, 500, 380, 362, 257, 659, 12, 83, 7146, 7850, 11, 550, 309, 311], "temperature": 0.0, "avg_logprob": -0.14528146386146545, "compression_ratio": 1.9137254901960785, "no_speech_prob": 1.6698586478014477e-05}, {"id": 848, "seek": 379108, "start": 3804.36, "end": 3809.68, "text": " basically the blind leading the blind.", "tokens": [1936, 264, 6865, 5775, 264, 6865, 13], "temperature": 0.0, "avg_logprob": -0.14528146386146545, "compression_ratio": 1.9137254901960785, "no_speech_prob": 1.6698586478014477e-05}, {"id": 849, "seek": 379108, "start": 3809.68, "end": 3812.72, "text": " The generator is trying to generate something which fools the critic, but the critic doesn't", "tokens": [440, 19265, 307, 1382, 281, 8460, 746, 597, 38625, 264, 7850, 11, 457, 264, 7850, 1177, 380], "temperature": 0.0, "avg_logprob": -0.14528146386146545, "compression_ratio": 1.9137254901960785, "no_speech_prob": 1.6698586478014477e-05}, {"id": 850, "seek": 379108, "start": 3812.72, "end": 3815.68, "text": " know anything at all, so it's basically got nothing to do.", "tokens": [458, 1340, 412, 439, 11, 370, 309, 311, 1936, 658, 1825, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.14528146386146545, "compression_ratio": 1.9137254901960785, "no_speech_prob": 1.6698586478014477e-05}, {"id": 851, "seek": 379108, "start": 3815.68, "end": 3819.0, "text": " And then the critic's kind of trying to decide whether the generated images are real or not,", "tokens": [400, 550, 264, 7850, 311, 733, 295, 1382, 281, 4536, 1968, 264, 10833, 5267, 366, 957, 420, 406, 11], "temperature": 0.0, "avg_logprob": -0.14528146386146545, "compression_ratio": 1.9137254901960785, "no_speech_prob": 1.6698586478014477e-05}, {"id": 852, "seek": 381900, "start": 3819.0, "end": 3821.36, "text": " and that's really obvious, so that just does it.", "tokens": [293, 300, 311, 534, 6322, 11, 370, 300, 445, 775, 309, 13], "temperature": 0.0, "avg_logprob": -0.12532833889798, "compression_ratio": 1.7246963562753037, "no_speech_prob": 8.266613804153167e-06}, {"id": 853, "seek": 381900, "start": 3821.36, "end": 3827.68, "text": " And so they kind of like don't go anywhere for ages, and then once they finally start", "tokens": [400, 370, 436, 733, 295, 411, 500, 380, 352, 4992, 337, 12357, 11, 293, 550, 1564, 436, 2721, 722], "temperature": 0.0, "avg_logprob": -0.12532833889798, "compression_ratio": 1.7246963562753037, "no_speech_prob": 8.266613804153167e-06}, {"id": 854, "seek": 381900, "start": 3827.68, "end": 3830.44, "text": " picking up steam, they go along pretty quickly.", "tokens": [8867, 493, 11952, 11, 436, 352, 2051, 1238, 2661, 13], "temperature": 0.0, "avg_logprob": -0.12532833889798, "compression_ratio": 1.7246963562753037, "no_speech_prob": 8.266613804153167e-06}, {"id": 855, "seek": 381900, "start": 3830.44, "end": 3836.84, "text": " So if you can find a way to generate things without using a GAN, like mean squared error", "tokens": [407, 498, 291, 393, 915, 257, 636, 281, 8460, 721, 1553, 1228, 257, 460, 1770, 11, 411, 914, 8889, 6713], "temperature": 0.0, "avg_logprob": -0.12532833889798, "compression_ratio": 1.7246963562753037, "no_speech_prob": 8.266613804153167e-06}, {"id": 856, "seek": 381900, "start": 3836.84, "end": 3843.36, "text": " pixel loss, and discriminate things without using a GAN, like predict on that first generator,", "tokens": [19261, 4470, 11, 293, 47833, 721, 1553, 1228, 257, 460, 1770, 11, 411, 6069, 322, 300, 700, 19265, 11], "temperature": 0.0, "avg_logprob": -0.12532833889798, "compression_ratio": 1.7246963562753037, "no_speech_prob": 8.266613804153167e-06}, {"id": 857, "seek": 381900, "start": 3843.36, "end": 3845.06, "text": " you can make a lot of progress.", "tokens": [291, 393, 652, 257, 688, 295, 4205, 13], "temperature": 0.0, "avg_logprob": -0.12532833889798, "compression_ratio": 1.7246963562753037, "no_speech_prob": 8.266613804153167e-06}, {"id": 858, "seek": 381900, "start": 3845.06, "end": 3848.04, "text": " So let's create the critic.", "tokens": [407, 718, 311, 1884, 264, 7850, 13], "temperature": 0.0, "avg_logprob": -0.12532833889798, "compression_ratio": 1.7246963562753037, "no_speech_prob": 8.266613804153167e-06}, {"id": 859, "seek": 384804, "start": 3848.04, "end": 3855.7599999999998, "text": " So to create just a totally standard Fast.ai binary classification model, we need two folders,", "tokens": [407, 281, 1884, 445, 257, 3879, 3832, 15968, 13, 1301, 17434, 21538, 2316, 11, 321, 643, 732, 31082, 11], "temperature": 0.0, "avg_logprob": -0.16390661591465033, "compression_ratio": 1.800865800865801, "no_speech_prob": 5.862513717147522e-06}, {"id": 860, "seek": 384804, "start": 3855.7599999999998, "end": 3860.68, "text": " one folder is containing high-res images, one folder containing generated images.", "tokens": [472, 10820, 307, 19273, 1090, 12, 495, 5267, 11, 472, 10820, 19273, 10833, 5267, 13], "temperature": 0.0, "avg_logprob": -0.16390661591465033, "compression_ratio": 1.800865800865801, "no_speech_prob": 5.862513717147522e-06}, {"id": 861, "seek": 384804, "start": 3860.68, "end": 3864.48, "text": " We already have the folder with the high-res images, so we just have to save our generated", "tokens": [492, 1217, 362, 264, 10820, 365, 264, 1090, 12, 495, 5267, 11, 370, 321, 445, 362, 281, 3155, 527, 10833], "temperature": 0.0, "avg_logprob": -0.16390661591465033, "compression_ratio": 1.800865800865801, "no_speech_prob": 5.862513717147522e-06}, {"id": 862, "seek": 384804, "start": 3864.48, "end": 3866.16, "text": " images.", "tokens": [5267, 13], "temperature": 0.0, "avg_logprob": -0.16390661591465033, "compression_ratio": 1.800865800865801, "no_speech_prob": 5.862513717147522e-06}, {"id": 863, "seek": 384804, "start": 3866.16, "end": 3870.4, "text": " So here's a teeny tiny bit of code that does that.", "tokens": [407, 510, 311, 257, 48232, 5870, 857, 295, 3089, 300, 775, 300, 13], "temperature": 0.0, "avg_logprob": -0.16390661591465033, "compression_ratio": 1.800865800865801, "no_speech_prob": 5.862513717147522e-06}, {"id": 864, "seek": 384804, "start": 3870.4, "end": 3877.56, "text": " We're going to create a directory called imagegen, pop it into a variable called pathgen.", "tokens": [492, 434, 516, 281, 1884, 257, 21120, 1219, 3256, 1766, 11, 1665, 309, 666, 257, 7006, 1219, 3100, 1766, 13], "temperature": 0.0, "avg_logprob": -0.16390661591465033, "compression_ratio": 1.800865800865801, "no_speech_prob": 5.862513717147522e-06}, {"id": 865, "seek": 387756, "start": 3877.56, "end": 3882.0, "text": " We've got a little function called savePreds that takes a data loader, and we're going", "tokens": [492, 600, 658, 257, 707, 2445, 1219, 3155, 47, 986, 82, 300, 2516, 257, 1412, 3677, 260, 11, 293, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.12162067851082223, "compression_ratio": 1.8461538461538463, "no_speech_prob": 6.540327831316972e-06}, {"id": 866, "seek": 387756, "start": 3882.0, "end": 3887.0, "text": " to grab all of the file names, because remember that in an item list, the dot items contains", "tokens": [281, 4444, 439, 295, 264, 3991, 5288, 11, 570, 1604, 300, 294, 364, 3174, 1329, 11, 264, 5893, 4754, 8306], "temperature": 0.0, "avg_logprob": -0.12162067851082223, "compression_ratio": 1.8461538461538463, "no_speech_prob": 6.540327831316972e-06}, {"id": 867, "seek": 387756, "start": 3887.0, "end": 3890.36, "text": " the file names, if it's an image item list.", "tokens": [264, 3991, 5288, 11, 498, 309, 311, 364, 3256, 3174, 1329, 13], "temperature": 0.0, "avg_logprob": -0.12162067851082223, "compression_ratio": 1.8461538461538463, "no_speech_prob": 6.540327831316972e-06}, {"id": 868, "seek": 387756, "start": 3890.36, "end": 3895.1, "text": " So here's the file names in that data loader's data set.", "tokens": [407, 510, 311, 264, 3991, 5288, 294, 300, 1412, 3677, 260, 311, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.12162067851082223, "compression_ratio": 1.8461538461538463, "no_speech_prob": 6.540327831316972e-06}, {"id": 869, "seek": 387756, "start": 3895.1, "end": 3900.68, "text": " And so now let's go through each batch of the data loader, and let's grab a batch of", "tokens": [400, 370, 586, 718, 311, 352, 807, 1184, 15245, 295, 264, 1412, 3677, 260, 11, 293, 718, 311, 4444, 257, 15245, 295], "temperature": 0.0, "avg_logprob": -0.12162067851082223, "compression_ratio": 1.8461538461538463, "no_speech_prob": 6.540327831316972e-06}, {"id": 870, "seek": 387756, "start": 3900.68, "end": 3906.2799999999997, "text": " predictions for that batch, and then reconstruct equals true, means it's actually going to", "tokens": [21264, 337, 300, 15245, 11, 293, 550, 31499, 6915, 2074, 11, 1355, 309, 311, 767, 516, 281], "temperature": 0.0, "avg_logprob": -0.12162067851082223, "compression_ratio": 1.8461538461538463, "no_speech_prob": 6.540327831316972e-06}, {"id": 871, "seek": 390628, "start": 3906.28, "end": 3912.0400000000004, "text": " create Fast.ai image objects for each thing in the batch.", "tokens": [1884, 15968, 13, 1301, 3256, 6565, 337, 1184, 551, 294, 264, 15245, 13], "temperature": 0.0, "avg_logprob": -0.09399633500182512, "compression_ratio": 1.668141592920354, "no_speech_prob": 2.368721197854029e-06}, {"id": 872, "seek": 390628, "start": 3912.0400000000004, "end": 3916.0400000000004, "text": " And so then we'll go through each of those predictions and save them.", "tokens": [400, 370, 550, 321, 603, 352, 807, 1184, 295, 729, 21264, 293, 3155, 552, 13], "temperature": 0.0, "avg_logprob": -0.09399633500182512, "compression_ratio": 1.668141592920354, "no_speech_prob": 2.368721197854029e-06}, {"id": 873, "seek": 390628, "start": 3916.0400000000004, "end": 3921.1800000000003, "text": " And the name we'll save it with is the name of the original file, but we're going to pop", "tokens": [400, 264, 1315, 321, 603, 3155, 309, 365, 307, 264, 1315, 295, 264, 3380, 3991, 11, 457, 321, 434, 516, 281, 1665], "temperature": 0.0, "avg_logprob": -0.09399633500182512, "compression_ratio": 1.668141592920354, "no_speech_prob": 2.368721197854029e-06}, {"id": 874, "seek": 390628, "start": 3921.1800000000003, "end": 3924.2000000000003, "text": " it into our new directory.", "tokens": [309, 666, 527, 777, 21120, 13], "temperature": 0.0, "avg_logprob": -0.09399633500182512, "compression_ratio": 1.668141592920354, "no_speech_prob": 2.368721197854029e-06}, {"id": 875, "seek": 390628, "start": 3924.2000000000003, "end": 3926.9, "text": " So that's it.", "tokens": [407, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.09399633500182512, "compression_ratio": 1.668141592920354, "no_speech_prob": 2.368721197854029e-06}, {"id": 876, "seek": 390628, "start": 3926.9, "end": 3928.36, "text": " That's how you save predictions.", "tokens": [663, 311, 577, 291, 3155, 21264, 13], "temperature": 0.0, "avg_logprob": -0.09399633500182512, "compression_ratio": 1.668141592920354, "no_speech_prob": 2.368721197854029e-06}, {"id": 877, "seek": 390628, "start": 3928.36, "end": 3933.48, "text": " And so you can see I'm kind of increasingly not just using stuff that's already in the", "tokens": [400, 370, 291, 393, 536, 286, 478, 733, 295, 12980, 406, 445, 1228, 1507, 300, 311, 1217, 294, 264], "temperature": 0.0, "avg_logprob": -0.09399633500182512, "compression_ratio": 1.668141592920354, "no_speech_prob": 2.368721197854029e-06}, {"id": 878, "seek": 393348, "start": 3933.48, "end": 3937.04, "text": " Fast.ai library, but trying to show you how to write stuff yourself.", "tokens": [15968, 13, 1301, 6405, 11, 457, 1382, 281, 855, 291, 577, 281, 2464, 1507, 1803, 13], "temperature": 0.0, "avg_logprob": -0.19260549043354236, "compression_ratio": 1.6401869158878504, "no_speech_prob": 6.0488218878163025e-06}, {"id": 879, "seek": 393348, "start": 3937.04, "end": 3941.96, "text": " And generally it doesn't require heaps of code to do that.", "tokens": [400, 5101, 309, 1177, 380, 3651, 415, 2382, 295, 3089, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.19260549043354236, "compression_ratio": 1.6401869158878504, "no_speech_prob": 6.0488218878163025e-06}, {"id": 880, "seek": 393348, "start": 3941.96, "end": 3947.8, "text": " And so if you come back to part two, this is what, lots of part two were kind of like,", "tokens": [400, 370, 498, 291, 808, 646, 281, 644, 732, 11, 341, 307, 437, 11, 3195, 295, 644, 732, 645, 733, 295, 411, 11], "temperature": 0.0, "avg_logprob": -0.19260549043354236, "compression_ratio": 1.6401869158878504, "no_speech_prob": 6.0488218878163025e-06}, {"id": 881, "seek": 393348, "start": 3947.8, "end": 3952.48, "text": " here's how you use things inside the library, and of course here's how we wrote the library.", "tokens": [510, 311, 577, 291, 764, 721, 1854, 264, 6405, 11, 293, 295, 1164, 510, 311, 577, 321, 4114, 264, 6405, 13], "temperature": 0.0, "avg_logprob": -0.19260549043354236, "compression_ratio": 1.6401869158878504, "no_speech_prob": 6.0488218878163025e-06}, {"id": 882, "seek": 393348, "start": 3952.48, "end": 3957.54, "text": " So we're increasingly writing our own code.", "tokens": [407, 321, 434, 12980, 3579, 527, 1065, 3089, 13], "temperature": 0.0, "avg_logprob": -0.19260549043354236, "compression_ratio": 1.6401869158878504, "no_speech_prob": 6.0488218878163025e-06}, {"id": 883, "seek": 395754, "start": 3957.54, "end": 3963.8, "text": " So save those predictions, and then let's just do a pil.image.open on the first one,", "tokens": [407, 3155, 729, 21264, 11, 293, 550, 718, 311, 445, 360, 257, 6429, 13, 26624, 13, 15752, 322, 264, 700, 472, 11], "temperature": 0.0, "avg_logprob": -0.10051057906377883, "compression_ratio": 1.576271186440678, "no_speech_prob": 5.862619673280278e-06}, {"id": 884, "seek": 395754, "start": 3963.8, "end": 3965.04, "text": " and yep, there it is.", "tokens": [293, 18633, 11, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.10051057906377883, "compression_ratio": 1.576271186440678, "no_speech_prob": 5.862619673280278e-06}, {"id": 885, "seek": 395754, "start": 3965.04, "end": 3968.16, "text": " Okay, so there's an example of a generated image.", "tokens": [1033, 11, 370, 456, 311, 364, 1365, 295, 257, 10833, 3256, 13], "temperature": 0.0, "avg_logprob": -0.10051057906377883, "compression_ratio": 1.576271186440678, "no_speech_prob": 5.862619673280278e-06}, {"id": 886, "seek": 395754, "start": 3968.16, "end": 3973.36, "text": " So now I can train a critic in the usual way.", "tokens": [407, 586, 286, 393, 3847, 257, 7850, 294, 264, 7713, 636, 13], "temperature": 0.0, "avg_logprob": -0.10051057906377883, "compression_ratio": 1.576271186440678, "no_speech_prob": 5.862619673280278e-06}, {"id": 887, "seek": 395754, "start": 3973.36, "end": 3978.48, "text": " It's really annoying to have to restart Jupyter Notebook to reclaim GPU memory.", "tokens": [467, 311, 534, 11304, 281, 362, 281, 21022, 22125, 88, 391, 11633, 2939, 281, 40074, 18407, 4675, 13], "temperature": 0.0, "avg_logprob": -0.10051057906377883, "compression_ratio": 1.576271186440678, "no_speech_prob": 5.862619673280278e-06}, {"id": 888, "seek": 395754, "start": 3978.48, "end": 3982.6, "text": " So one easy way to handle this is if you just set something that you knew was using a lot", "tokens": [407, 472, 1858, 636, 281, 4813, 341, 307, 498, 291, 445, 992, 746, 300, 291, 2586, 390, 1228, 257, 688], "temperature": 0.0, "avg_logprob": -0.10051057906377883, "compression_ratio": 1.576271186440678, "no_speech_prob": 5.862619673280278e-06}, {"id": 889, "seek": 398260, "start": 3982.6, "end": 3990.24, "text": " of GPU to none, like this learner, and then just go gc.collect, that tells Python to do", "tokens": [295, 18407, 281, 6022, 11, 411, 341, 33347, 11, 293, 550, 445, 352, 290, 66, 13, 33891, 557, 11, 300, 5112, 15329, 281, 360], "temperature": 0.0, "avg_logprob": -0.10795704069591704, "compression_ratio": 1.5495867768595042, "no_speech_prob": 1.5445164535776712e-05}, {"id": 890, "seek": 398260, "start": 3990.24, "end": 3996.96, "text": " memory garbage collection, and after that you'll generally be fine.", "tokens": [4675, 14150, 5765, 11, 293, 934, 300, 291, 603, 5101, 312, 2489, 13], "temperature": 0.0, "avg_logprob": -0.10795704069591704, "compression_ratio": 1.5495867768595042, "no_speech_prob": 1.5445164535776712e-05}, {"id": 891, "seek": 398260, "start": 3996.96, "end": 4000.36, "text": " You'll be able to use all of your GPU memory again.", "tokens": [509, 603, 312, 1075, 281, 764, 439, 295, 428, 18407, 4675, 797, 13], "temperature": 0.0, "avg_logprob": -0.10795704069591704, "compression_ratio": 1.5495867768595042, "no_speech_prob": 1.5445164535776712e-05}, {"id": 892, "seek": 398260, "start": 4000.36, "end": 4005.88, "text": " If you're using NVIDIA SMI to actually look at your GPU memory, you won't see it clear,", "tokens": [759, 291, 434, 1228, 426, 3958, 6914, 13115, 40, 281, 767, 574, 412, 428, 18407, 4675, 11, 291, 1582, 380, 536, 309, 1850, 11], "temperature": 0.0, "avg_logprob": -0.10795704069591704, "compression_ratio": 1.5495867768595042, "no_speech_prob": 1.5445164535776712e-05}, {"id": 893, "seek": 398260, "start": 4005.88, "end": 4011.72, "text": " because PyTorch still has a kind of allocated cache, but it makes it available.", "tokens": [570, 9953, 51, 284, 339, 920, 575, 257, 733, 295, 29772, 19459, 11, 457, 309, 1669, 309, 2435, 13], "temperature": 0.0, "avg_logprob": -0.10795704069591704, "compression_ratio": 1.5495867768595042, "no_speech_prob": 1.5445164535776712e-05}, {"id": 894, "seek": 401172, "start": 4011.72, "end": 4015.3199999999997, "text": " So you should find this is how you can avoid restarting your notebook.", "tokens": [407, 291, 820, 915, 341, 307, 577, 291, 393, 5042, 21022, 278, 428, 21060, 13], "temperature": 0.0, "avg_logprob": -0.15830310323963995, "compression_ratio": 1.6339622641509435, "no_speech_prob": 3.4465131193428533e-06}, {"id": 895, "seek": 401172, "start": 4015.3199999999997, "end": 4017.8399999999997, "text": " Okay, so we're going to create our critic.", "tokens": [1033, 11, 370, 321, 434, 516, 281, 1884, 527, 7850, 13], "temperature": 0.0, "avg_logprob": -0.15830310323963995, "compression_ratio": 1.6339622641509435, "no_speech_prob": 3.4465131193428533e-06}, {"id": 896, "seek": 401172, "start": 4017.8399999999997, "end": 4023.64, "text": " It's just an image item list from folder in the totally usual way, and the classes will", "tokens": [467, 311, 445, 364, 3256, 3174, 1329, 490, 10820, 294, 264, 3879, 7713, 636, 11, 293, 264, 5359, 486], "temperature": 0.0, "avg_logprob": -0.15830310323963995, "compression_ratio": 1.6339622641509435, "no_speech_prob": 3.4465131193428533e-06}, {"id": 897, "seek": 401172, "start": 4023.64, "end": 4027.9599999999996, "text": " be the image gen and images.", "tokens": [312, 264, 3256, 1049, 293, 5267, 13], "temperature": 0.0, "avg_logprob": -0.15830310323963995, "compression_ratio": 1.6339622641509435, "no_speech_prob": 3.4465131193428533e-06}, {"id": 898, "seek": 401172, "start": 4027.9599999999996, "end": 4031.0, "text": " We'll do a random split, because we want to know how well we're doing with the critic", "tokens": [492, 603, 360, 257, 4974, 7472, 11, 570, 321, 528, 281, 458, 577, 731, 321, 434, 884, 365, 264, 7850], "temperature": 0.0, "avg_logprob": -0.15830310323963995, "compression_ratio": 1.6339622641509435, "no_speech_prob": 3.4465131193428533e-06}, {"id": 899, "seek": 401172, "start": 4031.0, "end": 4032.7999999999997, "text": " to have a validation set.", "tokens": [281, 362, 257, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.15830310323963995, "compression_ratio": 1.6339622641509435, "no_speech_prob": 3.4465131193428533e-06}, {"id": 900, "seek": 401172, "start": 4032.7999999999997, "end": 4035.7599999999998, "text": " We just label it from folder in the usual way.", "tokens": [492, 445, 7645, 309, 490, 10820, 294, 264, 7713, 636, 13], "temperature": 0.0, "avg_logprob": -0.15830310323963995, "compression_ratio": 1.6339622641509435, "no_speech_prob": 3.4465131193428533e-06}, {"id": 901, "seek": 401172, "start": 4035.7599999999998, "end": 4037.8799999999997, "text": " Add some transforms, data bunch normalized.", "tokens": [5349, 512, 35592, 11, 1412, 3840, 48704, 13], "temperature": 0.0, "avg_logprob": -0.15830310323963995, "compression_ratio": 1.6339622641509435, "no_speech_prob": 3.4465131193428533e-06}, {"id": 902, "seek": 403788, "start": 4037.88, "end": 4041.88, "text": " So it's a totally standard object classifier.", "tokens": [407, 309, 311, 257, 3879, 3832, 2657, 1508, 9902, 13], "temperature": 0.0, "avg_logprob": -0.19346449249669126, "compression_ratio": 1.7908496732026145, "no_speech_prob": 6.643363576586125e-06}, {"id": 903, "seek": 403788, "start": 4041.88, "end": 4050.04, "text": " Okay, so we've got a totally standard classifier.", "tokens": [1033, 11, 370, 321, 600, 658, 257, 3879, 3832, 1508, 9902, 13], "temperature": 0.0, "avg_logprob": -0.19346449249669126, "compression_ratio": 1.7908496732026145, "no_speech_prob": 6.643363576586125e-06}, {"id": 904, "seek": 403788, "start": 4050.04, "end": 4051.92, "text": " So here's what some of it looks like.", "tokens": [407, 510, 311, 437, 512, 295, 309, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.19346449249669126, "compression_ratio": 1.7908496732026145, "no_speech_prob": 6.643363576586125e-06}, {"id": 905, "seek": 403788, "start": 4051.92, "end": 4058.08, "text": " So here's one from the real images, real images, generated images, generated images.", "tokens": [407, 510, 311, 472, 490, 264, 957, 5267, 11, 957, 5267, 11, 10833, 5267, 11, 10833, 5267, 13], "temperature": 0.0, "avg_logprob": -0.19346449249669126, "compression_ratio": 1.7908496732026145, "no_speech_prob": 6.643363576586125e-06}, {"id": 906, "seek": 403788, "start": 4058.08, "end": 4062.96, "text": " So it's got to try and figure out which class is which.", "tokens": [407, 309, 311, 658, 281, 853, 293, 2573, 484, 597, 1508, 307, 597, 13], "temperature": 0.0, "avg_logprob": -0.19346449249669126, "compression_ratio": 1.7908496732026145, "no_speech_prob": 6.643363576586125e-06}, {"id": 907, "seek": 406296, "start": 4062.96, "end": 4071.68, "text": " Okay, so we're going to use binary cross entropy as usual.", "tokens": [1033, 11, 370, 321, 434, 516, 281, 764, 17434, 3278, 30867, 382, 7713, 13], "temperature": 0.0, "avg_logprob": -0.18584936315363104, "compression_ratio": 1.3829787234042554, "no_speech_prob": 3.84475333703449e-06}, {"id": 908, "seek": 406296, "start": 4071.68, "end": 4079.2400000000002, "text": " However, we're not going to use a ResNet here.", "tokens": [2908, 11, 321, 434, 406, 516, 281, 764, 257, 5015, 31890, 510, 13], "temperature": 0.0, "avg_logprob": -0.18584936315363104, "compression_ratio": 1.3829787234042554, "no_speech_prob": 3.84475333703449e-06}, {"id": 909, "seek": 406296, "start": 4079.2400000000002, "end": 4083.76, "text": " And the reason we'll get into in more detail in part two, but basically when you're doing", "tokens": [400, 264, 1778, 321, 603, 483, 666, 294, 544, 2607, 294, 644, 732, 11, 457, 1936, 562, 291, 434, 884], "temperature": 0.0, "avg_logprob": -0.18584936315363104, "compression_ratio": 1.3829787234042554, "no_speech_prob": 3.84475333703449e-06}, {"id": 910, "seek": 408376, "start": 4083.76, "end": 4094.44, "text": " a GAN, you need to be particularly careful that the generator and the critic can't kind", "tokens": [257, 460, 1770, 11, 291, 643, 281, 312, 4098, 5026, 300, 264, 19265, 293, 264, 7850, 393, 380, 733], "temperature": 0.0, "avg_logprob": -0.15429116309957303, "compression_ratio": 1.5210084033613445, "no_speech_prob": 6.747945462848293e-06}, {"id": 911, "seek": 408376, "start": 4094.44, "end": 4099.96, "text": " of both push in the same direction and increase the weights out of control.", "tokens": [295, 1293, 2944, 294, 264, 912, 3513, 293, 3488, 264, 17443, 484, 295, 1969, 13], "temperature": 0.0, "avg_logprob": -0.15429116309957303, "compression_ratio": 1.5210084033613445, "no_speech_prob": 6.747945462848293e-06}, {"id": 912, "seek": 408376, "start": 4099.96, "end": 4104.6, "text": " So we have to use something called spectral normalization to make GANs work nowadays.", "tokens": [407, 321, 362, 281, 764, 746, 1219, 42761, 2710, 2144, 281, 652, 460, 1770, 82, 589, 13434, 13], "temperature": 0.0, "avg_logprob": -0.15429116309957303, "compression_ratio": 1.5210084033613445, "no_speech_prob": 6.747945462848293e-06}, {"id": 913, "seek": 408376, "start": 4104.6, "end": 4107.4400000000005, "text": " We'll learn about that in part two.", "tokens": [492, 603, 1466, 466, 300, 294, 644, 732, 13], "temperature": 0.0, "avg_logprob": -0.15429116309957303, "compression_ratio": 1.5210084033613445, "no_speech_prob": 6.747945462848293e-06}, {"id": 914, "seek": 408376, "start": 4107.4400000000005, "end": 4113.68, "text": " So anyway, if you say GAN critic, Fast.AI will give you a binary classifier.", "tokens": [407, 4033, 11, 498, 291, 584, 460, 1770, 7850, 11, 15968, 13, 48698, 486, 976, 291, 257, 17434, 1508, 9902, 13], "temperature": 0.0, "avg_logprob": -0.15429116309957303, "compression_ratio": 1.5210084033613445, "no_speech_prob": 6.747945462848293e-06}, {"id": 915, "seek": 411368, "start": 4113.68, "end": 4118.16, "text": " I strongly suspect we probably can use a ResNet here.", "tokens": [286, 10613, 9091, 321, 1391, 393, 764, 257, 5015, 31890, 510, 13], "temperature": 0.0, "avg_logprob": -0.18155646092683367, "compression_ratio": 1.5541125541125542, "no_speech_prob": 1.280521337321261e-05}, {"id": 916, "seek": 411368, "start": 4118.16, "end": 4120.64, "text": " We just have to create a pre-trained ResNet with SpectroNorm.", "tokens": [492, 445, 362, 281, 1884, 257, 659, 12, 17227, 2001, 5015, 31890, 365, 27078, 340, 45, 687, 13], "temperature": 0.0, "avg_logprob": -0.18155646092683367, "compression_ratio": 1.5541125541125542, "no_speech_prob": 1.280521337321261e-05}, {"id": 917, "seek": 411368, "start": 4120.64, "end": 4123.08, "text": " Hope to do that pretty soon.", "tokens": [6483, 281, 360, 300, 1238, 2321, 13], "temperature": 0.0, "avg_logprob": -0.18155646092683367, "compression_ratio": 1.5541125541125542, "no_speech_prob": 1.280521337321261e-05}, {"id": 918, "seek": 411368, "start": 4123.08, "end": 4124.08, "text": " We'll see how we go.", "tokens": [492, 603, 536, 577, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.18155646092683367, "compression_ratio": 1.5541125541125542, "no_speech_prob": 1.280521337321261e-05}, {"id": 919, "seek": 411368, "start": 4124.08, "end": 4131.72, "text": " But as of now, this is kind of the best approach is this thing called GAN critic.", "tokens": [583, 382, 295, 586, 11, 341, 307, 733, 295, 264, 1151, 3109, 307, 341, 551, 1219, 460, 1770, 7850, 13], "temperature": 0.0, "avg_logprob": -0.18155646092683367, "compression_ratio": 1.5541125541125542, "no_speech_prob": 1.280521337321261e-05}, {"id": 920, "seek": 411368, "start": 4131.72, "end": 4141.8, "text": " A GAN critic uses a slightly different way of averaging the different parts of the image", "tokens": [316, 460, 1770, 7850, 4960, 257, 4748, 819, 636, 295, 47308, 264, 819, 3166, 295, 264, 3256], "temperature": 0.0, "avg_logprob": -0.18155646092683367, "compression_ratio": 1.5541125541125542, "no_speech_prob": 1.280521337321261e-05}, {"id": 921, "seek": 411368, "start": 4141.8, "end": 4143.240000000001, "text": " when it does the loss.", "tokens": [562, 309, 775, 264, 4470, 13], "temperature": 0.0, "avg_logprob": -0.18155646092683367, "compression_ratio": 1.5541125541125542, "no_speech_prob": 1.280521337321261e-05}, {"id": 922, "seek": 414324, "start": 4143.24, "end": 4147.639999999999, "text": " So anytime you're doing a GAN at the moment, you have to wrap your loss function with adaptive", "tokens": [407, 13038, 291, 434, 884, 257, 460, 1770, 412, 264, 1623, 11, 291, 362, 281, 7019, 428, 4470, 2445, 365, 27912], "temperature": 0.0, "avg_logprob": -0.09051222097678263, "compression_ratio": 1.8446969696969697, "no_speech_prob": 1.8341443137614988e-05}, {"id": 923, "seek": 414324, "start": 4147.639999999999, "end": 4148.639999999999, "text": " loss.", "tokens": [4470, 13], "temperature": 0.0, "avg_logprob": -0.09051222097678263, "compression_ratio": 1.8446969696969697, "no_speech_prob": 1.8341443137614988e-05}, {"id": 924, "seek": 414324, "start": 4148.639999999999, "end": 4150.599999999999, "text": " Again, we'll look at the details in part two.", "tokens": [3764, 11, 321, 603, 574, 412, 264, 4365, 294, 644, 732, 13], "temperature": 0.0, "avg_logprob": -0.09051222097678263, "compression_ratio": 1.8446969696969697, "no_speech_prob": 1.8341443137614988e-05}, {"id": 925, "seek": 414324, "start": 4150.599999999999, "end": 4154.719999999999, "text": " For now, just know this is what you have to do and it'll work.", "tokens": [1171, 586, 11, 445, 458, 341, 307, 437, 291, 362, 281, 360, 293, 309, 603, 589, 13], "temperature": 0.0, "avg_logprob": -0.09051222097678263, "compression_ratio": 1.8446969696969697, "no_speech_prob": 1.8341443137614988e-05}, {"id": 926, "seek": 414324, "start": 4154.719999999999, "end": 4159.32, "text": " So other than that, slightly odd loss function and that slightly odd architecture, everything", "tokens": [407, 661, 813, 300, 11, 4748, 7401, 4470, 2445, 293, 300, 4748, 7401, 9482, 11, 1203], "temperature": 0.0, "avg_logprob": -0.09051222097678263, "compression_ratio": 1.8446969696969697, "no_speech_prob": 1.8341443137614988e-05}, {"id": 927, "seek": 414324, "start": 4159.32, "end": 4160.32, "text": " else is the same.", "tokens": [1646, 307, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.09051222097678263, "compression_ratio": 1.8446969696969697, "no_speech_prob": 1.8341443137614988e-05}, {"id": 928, "seek": 414324, "start": 4160.32, "end": 4164.099999999999, "text": " We can call that to create our critic.", "tokens": [492, 393, 818, 300, 281, 1884, 527, 7850, 13], "temperature": 0.0, "avg_logprob": -0.09051222097678263, "compression_ratio": 1.8446969696969697, "no_speech_prob": 1.8341443137614988e-05}, {"id": 929, "seek": 414324, "start": 4164.099999999999, "end": 4167.94, "text": " Because we have this slightly different architecture and slightly different loss function, we did", "tokens": [1436, 321, 362, 341, 4748, 819, 9482, 293, 4748, 819, 4470, 2445, 11, 321, 630], "temperature": 0.0, "avg_logprob": -0.09051222097678263, "compression_ratio": 1.8446969696969697, "no_speech_prob": 1.8341443137614988e-05}, {"id": 930, "seek": 414324, "start": 4167.94, "end": 4170.599999999999, "text": " a slightly different metric.", "tokens": [257, 4748, 819, 20678, 13], "temperature": 0.0, "avg_logprob": -0.09051222097678263, "compression_ratio": 1.8446969696969697, "no_speech_prob": 1.8341443137614988e-05}, {"id": 931, "seek": 417060, "start": 4170.6, "end": 4174.320000000001, "text": " This is the equivalent GAN version of accuracy for critics.", "tokens": [639, 307, 264, 10344, 460, 1770, 3037, 295, 14170, 337, 22503, 13], "temperature": 0.0, "avg_logprob": -0.17257653342352974, "compression_ratio": 1.6135458167330676, "no_speech_prob": 9.223133929481264e-06}, {"id": 932, "seek": 417060, "start": 4174.320000000001, "end": 4175.88, "text": " And then we can train it.", "tokens": [400, 550, 321, 393, 3847, 309, 13], "temperature": 0.0, "avg_logprob": -0.17257653342352974, "compression_ratio": 1.6135458167330676, "no_speech_prob": 9.223133929481264e-06}, {"id": 933, "seek": 417060, "start": 4175.88, "end": 4183.320000000001, "text": " And you can see it's 98% accurate at recognizing that kind of crappy thing from that kind of", "tokens": [400, 291, 393, 536, 309, 311, 20860, 4, 8559, 412, 18538, 300, 733, 295, 36531, 551, 490, 300, 733, 295], "temperature": 0.0, "avg_logprob": -0.17257653342352974, "compression_ratio": 1.6135458167330676, "no_speech_prob": 9.223133929481264e-06}, {"id": 934, "seek": 417060, "start": 4183.320000000001, "end": 4184.320000000001, "text": " nice thing.", "tokens": [1481, 551, 13], "temperature": 0.0, "avg_logprob": -0.17257653342352974, "compression_ratio": 1.6135458167330676, "no_speech_prob": 9.223133929481264e-06}, {"id": 935, "seek": 417060, "start": 4184.320000000001, "end": 4187.200000000001, "text": " And of course, we don't see the numbers here anymore, right?", "tokens": [400, 295, 1164, 11, 321, 500, 380, 536, 264, 3547, 510, 3602, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17257653342352974, "compression_ratio": 1.6135458167330676, "no_speech_prob": 9.223133929481264e-06}, {"id": 936, "seek": 417060, "start": 4187.200000000001, "end": 4188.56, "text": " Because these are the generated images.", "tokens": [1436, 613, 366, 264, 10833, 5267, 13], "temperature": 0.0, "avg_logprob": -0.17257653342352974, "compression_ratio": 1.6135458167330676, "no_speech_prob": 9.223133929481264e-06}, {"id": 937, "seek": 417060, "start": 4188.56, "end": 4194.68, "text": " The generator already knows how to get rid of those numbers that are written on top.", "tokens": [440, 19265, 1217, 3255, 577, 281, 483, 3973, 295, 729, 3547, 300, 366, 3720, 322, 1192, 13], "temperature": 0.0, "avg_logprob": -0.17257653342352974, "compression_ratio": 1.6135458167330676, "no_speech_prob": 9.223133929481264e-06}, {"id": 938, "seek": 417060, "start": 4194.68, "end": 4198.240000000001, "text": " So let's finish up this GAN.", "tokens": [407, 718, 311, 2413, 493, 341, 460, 1770, 13], "temperature": 0.0, "avg_logprob": -0.17257653342352974, "compression_ratio": 1.6135458167330676, "no_speech_prob": 9.223133929481264e-06}, {"id": 939, "seek": 419824, "start": 4198.24, "end": 4204.76, "text": " Now that we have pre-trained the generator and pre-trained the critic, we now need to", "tokens": [823, 300, 321, 362, 659, 12, 17227, 2001, 264, 19265, 293, 659, 12, 17227, 2001, 264, 7850, 11, 321, 586, 643, 281], "temperature": 0.0, "avg_logprob": -0.06094655036926269, "compression_ratio": 1.7407407407407407, "no_speech_prob": 1.805469764804002e-05}, {"id": 940, "seek": 419824, "start": 4204.76, "end": 4208.32, "text": " get it to kind of ping pong between training a little bit of each.", "tokens": [483, 309, 281, 733, 295, 26151, 36164, 1296, 3097, 257, 707, 857, 295, 1184, 13], "temperature": 0.0, "avg_logprob": -0.06094655036926269, "compression_ratio": 1.7407407407407407, "no_speech_prob": 1.805469764804002e-05}, {"id": 941, "seek": 419824, "start": 4208.32, "end": 4214.5199999999995, "text": " And the amount of time you spend on each of those things and the learning rates you use", "tokens": [400, 264, 2372, 295, 565, 291, 3496, 322, 1184, 295, 729, 721, 293, 264, 2539, 6846, 291, 764], "temperature": 0.0, "avg_logprob": -0.06094655036926269, "compression_ratio": 1.7407407407407407, "no_speech_prob": 1.805469764804002e-05}, {"id": 942, "seek": 419824, "start": 4214.5199999999995, "end": 4217.5599999999995, "text": " is still a little bit on the fussy side.", "tokens": [307, 920, 257, 707, 857, 322, 264, 283, 26394, 1252, 13], "temperature": 0.0, "avg_logprob": -0.06094655036926269, "compression_ratio": 1.7407407407407407, "no_speech_prob": 1.805469764804002e-05}, {"id": 943, "seek": 419824, "start": 4217.5599999999995, "end": 4227.44, "text": " So we've created a GAN learner for you, which you just pass in your generator and your critic,", "tokens": [407, 321, 600, 2942, 257, 460, 1770, 33347, 337, 291, 11, 597, 291, 445, 1320, 294, 428, 19265, 293, 428, 7850, 11], "temperature": 0.0, "avg_logprob": -0.06094655036926269, "compression_ratio": 1.7407407407407407, "no_speech_prob": 1.805469764804002e-05}, {"id": 944, "seek": 422744, "start": 4227.44, "end": 4233.04, "text": " which we've just simply loaded here from the ones we just trained.", "tokens": [597, 321, 600, 445, 2935, 13210, 510, 490, 264, 2306, 321, 445, 8895, 13], "temperature": 0.0, "avg_logprob": -0.09866977483034134, "compression_ratio": 1.8198529411764706, "no_speech_prob": 1.147848252003314e-05}, {"id": 945, "seek": 422744, "start": 4233.04, "end": 4237.4, "text": " And it will go ahead and when you go learn.fit, it will do that for you.", "tokens": [400, 309, 486, 352, 2286, 293, 562, 291, 352, 1466, 13, 6845, 11, 309, 486, 360, 300, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.09866977483034134, "compression_ratio": 1.8198529411764706, "no_speech_prob": 1.147848252003314e-05}, {"id": 946, "seek": 422744, "start": 4237.4, "end": 4240.5199999999995, "text": " It will figure out how much time to train the generator, and then when to switch to", "tokens": [467, 486, 2573, 484, 577, 709, 565, 281, 3847, 264, 19265, 11, 293, 550, 562, 281, 3679, 281], "temperature": 0.0, "avg_logprob": -0.09866977483034134, "compression_ratio": 1.8198529411764706, "no_speech_prob": 1.147848252003314e-05}, {"id": 947, "seek": 422744, "start": 4240.5199999999995, "end": 4245.24, "text": " training the discriminator, the critic, and it'll go back on and forward.", "tokens": [3097, 264, 20828, 1639, 11, 264, 7850, 11, 293, 309, 603, 352, 646, 322, 293, 2128, 13], "temperature": 0.0, "avg_logprob": -0.09866977483034134, "compression_ratio": 1.8198529411764706, "no_speech_prob": 1.147848252003314e-05}, {"id": 948, "seek": 422744, "start": 4245.24, "end": 4250.919999999999, "text": " These weights here is that what we actually do is we don't only use the critic as the", "tokens": [1981, 17443, 510, 307, 300, 437, 321, 767, 360, 307, 321, 500, 380, 787, 764, 264, 7850, 382, 264], "temperature": 0.0, "avg_logprob": -0.09866977483034134, "compression_ratio": 1.8198529411764706, "no_speech_prob": 1.147848252003314e-05}, {"id": 949, "seek": 422744, "start": 4250.919999999999, "end": 4251.919999999999, "text": " loss function.", "tokens": [4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.09866977483034134, "compression_ratio": 1.8198529411764706, "no_speech_prob": 1.147848252003314e-05}, {"id": 950, "seek": 422744, "start": 4251.919999999999, "end": 4257.4, "text": " If we only use the critic as the loss function, the GAN could get very good at creating pictures", "tokens": [759, 321, 787, 764, 264, 7850, 382, 264, 4470, 2445, 11, 264, 460, 1770, 727, 483, 588, 665, 412, 4084, 5242], "temperature": 0.0, "avg_logprob": -0.09866977483034134, "compression_ratio": 1.8198529411764706, "no_speech_prob": 1.147848252003314e-05}, {"id": 951, "seek": 425740, "start": 4257.4, "end": 4264.879999999999, "text": " that look like real pictures, but they actually have nothing to do with the original photo", "tokens": [300, 574, 411, 957, 5242, 11, 457, 436, 767, 362, 1825, 281, 360, 365, 264, 3380, 5052], "temperature": 0.0, "avg_logprob": -0.10223417811923557, "compression_ratio": 1.5638297872340425, "no_speech_prob": 9.223117558576632e-06}, {"id": 952, "seek": 425740, "start": 4264.879999999999, "end": 4265.879999999999, "text": " at all.", "tokens": [412, 439, 13], "temperature": 0.0, "avg_logprob": -0.10223417811923557, "compression_ratio": 1.5638297872340425, "no_speech_prob": 9.223117558576632e-06}, {"id": 953, "seek": 425740, "start": 4265.879999999999, "end": 4270.599999999999, "text": " So we actually add together the pixel loss and the critic loss.", "tokens": [407, 321, 767, 909, 1214, 264, 19261, 4470, 293, 264, 7850, 4470, 13], "temperature": 0.0, "avg_logprob": -0.10223417811923557, "compression_ratio": 1.5638297872340425, "no_speech_prob": 9.223117558576632e-06}, {"id": 954, "seek": 425740, "start": 4270.599999999999, "end": 4275.28, "text": " And so those two losses are kind of on different scales.", "tokens": [400, 370, 729, 732, 15352, 366, 733, 295, 322, 819, 17408, 13], "temperature": 0.0, "avg_logprob": -0.10223417811923557, "compression_ratio": 1.5638297872340425, "no_speech_prob": 9.223117558576632e-06}, {"id": 955, "seek": 425740, "start": 4275.28, "end": 4281.36, "text": " So we multiply the pixel loss by something between about 50 and about 200.", "tokens": [407, 321, 12972, 264, 19261, 4470, 538, 746, 1296, 466, 2625, 293, 466, 2331, 13], "temperature": 0.0, "avg_logprob": -0.10223417811923557, "compression_ratio": 1.5638297872340425, "no_speech_prob": 9.223117558576632e-06}, {"id": 956, "seek": 428136, "start": 4281.36, "end": 4287.719999999999, "text": " And something in that range generally works pretty well.", "tokens": [400, 746, 294, 300, 3613, 5101, 1985, 1238, 731, 13], "temperature": 0.0, "avg_logprob": -0.11341863473256429, "compression_ratio": 1.6714801444043321, "no_speech_prob": 1.1842867934319656e-05}, {"id": 957, "seek": 428136, "start": 4287.719999999999, "end": 4290.2, "text": " Something else with GANs.", "tokens": [6595, 1646, 365, 460, 1770, 82, 13], "temperature": 0.0, "avg_logprob": -0.11341863473256429, "compression_ratio": 1.6714801444043321, "no_speech_prob": 1.1842867934319656e-05}, {"id": 958, "seek": 428136, "start": 4290.2, "end": 4293.04, "text": " GANs hate momentum when you're training them.", "tokens": [460, 1770, 82, 4700, 11244, 562, 291, 434, 3097, 552, 13], "temperature": 0.0, "avg_logprob": -0.11341863473256429, "compression_ratio": 1.6714801444043321, "no_speech_prob": 1.1842867934319656e-05}, {"id": 959, "seek": 428136, "start": 4293.04, "end": 4296.36, "text": " It kind of doesn't make sense to train them with momentum because you keep switching between", "tokens": [467, 733, 295, 1177, 380, 652, 2020, 281, 3847, 552, 365, 11244, 570, 291, 1066, 16493, 1296], "temperature": 0.0, "avg_logprob": -0.11341863473256429, "compression_ratio": 1.6714801444043321, "no_speech_prob": 1.1842867934319656e-05}, {"id": 960, "seek": 428136, "start": 4296.36, "end": 4299.16, "text": " generator and critic, so it's kind of tough.", "tokens": [19265, 293, 7850, 11, 370, 309, 311, 733, 295, 4930, 13], "temperature": 0.0, "avg_logprob": -0.11341863473256429, "compression_ratio": 1.6714801444043321, "no_speech_prob": 1.1842867934319656e-05}, {"id": 961, "seek": 428136, "start": 4299.16, "end": 4301.719999999999, "text": " Maybe there are ways to use momentum, but I'm not sure anybody's figured it out.", "tokens": [2704, 456, 366, 2098, 281, 764, 11244, 11, 457, 286, 478, 406, 988, 4472, 311, 8932, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.11341863473256429, "compression_ratio": 1.6714801444043321, "no_speech_prob": 1.1842867934319656e-05}, {"id": 962, "seek": 428136, "start": 4301.719999999999, "end": 4307.36, "text": " So this number here, when you create an atom optimizer, is where the momentum goes.", "tokens": [407, 341, 1230, 510, 11, 562, 291, 1884, 364, 12018, 5028, 6545, 11, 307, 689, 264, 11244, 1709, 13], "temperature": 0.0, "avg_logprob": -0.11341863473256429, "compression_ratio": 1.6714801444043321, "no_speech_prob": 1.1842867934319656e-05}, {"id": 963, "seek": 428136, "start": 4307.36, "end": 4308.799999999999, "text": " So you should set that to zero.", "tokens": [407, 291, 820, 992, 300, 281, 4018, 13], "temperature": 0.0, "avg_logprob": -0.11341863473256429, "compression_ratio": 1.6714801444043321, "no_speech_prob": 1.1842867934319656e-05}, {"id": 964, "seek": 430880, "start": 4308.8, "end": 4312.88, "text": " So anyway, if you're doing GANs, use these hyperparameters.", "tokens": [407, 4033, 11, 498, 291, 434, 884, 460, 1770, 82, 11, 764, 613, 9848, 2181, 335, 6202, 13], "temperature": 0.0, "avg_logprob": -0.1523317019144694, "compression_ratio": 1.4489795918367347, "no_speech_prob": 4.092875315109268e-06}, {"id": 965, "seek": 430880, "start": 4312.88, "end": 4317.72, "text": " It should work.", "tokens": [467, 820, 589, 13], "temperature": 0.0, "avg_logprob": -0.1523317019144694, "compression_ratio": 1.4489795918367347, "no_speech_prob": 4.092875315109268e-06}, {"id": 966, "seek": 430880, "start": 4317.72, "end": 4321.84, "text": " So that's what GANLearner does.", "tokens": [407, 300, 311, 437, 460, 1770, 11020, 22916, 775, 13], "temperature": 0.0, "avg_logprob": -0.1523317019144694, "compression_ratio": 1.4489795918367347, "no_speech_prob": 4.092875315109268e-06}, {"id": 967, "seek": 430880, "start": 4321.84, "end": 4325.7, "text": " And so then you can go fit, and it trains for a while.", "tokens": [400, 370, 550, 291, 393, 352, 3318, 11, 293, 309, 16329, 337, 257, 1339, 13], "temperature": 0.0, "avg_logprob": -0.1523317019144694, "compression_ratio": 1.4489795918367347, "no_speech_prob": 4.092875315109268e-06}, {"id": 968, "seek": 430880, "start": 4325.7, "end": 4334.360000000001, "text": " And one of the tough things about GANs is that these loss numbers, they're meaningless.", "tokens": [400, 472, 295, 264, 4930, 721, 466, 460, 1770, 82, 307, 300, 613, 4470, 3547, 11, 436, 434, 33232, 13], "temperature": 0.0, "avg_logprob": -0.1523317019144694, "compression_ratio": 1.4489795918367347, "no_speech_prob": 4.092875315109268e-06}, {"id": 969, "seek": 430880, "start": 4334.360000000001, "end": 4336.56, "text": " You can't expect them to go down.", "tokens": [509, 393, 380, 2066, 552, 281, 352, 760, 13], "temperature": 0.0, "avg_logprob": -0.1523317019144694, "compression_ratio": 1.4489795918367347, "no_speech_prob": 4.092875315109268e-06}, {"id": 970, "seek": 433656, "start": 4336.56, "end": 4342.160000000001, "text": " Because as the generator gets better, it gets harder for the discriminator, the critic.", "tokens": [1436, 382, 264, 19265, 2170, 1101, 11, 309, 2170, 6081, 337, 264, 20828, 1639, 11, 264, 7850, 13], "temperature": 0.0, "avg_logprob": -0.10829164347517381, "compression_ratio": 1.871559633027523, "no_speech_prob": 5.255347332422389e-06}, {"id": 971, "seek": 433656, "start": 4342.160000000001, "end": 4345.6, "text": " And then as the critic gets better, it gets harder for the generator.", "tokens": [400, 550, 382, 264, 7850, 2170, 1101, 11, 309, 2170, 6081, 337, 264, 19265, 13], "temperature": 0.0, "avg_logprob": -0.10829164347517381, "compression_ratio": 1.871559633027523, "no_speech_prob": 5.255347332422389e-06}, {"id": 972, "seek": 433656, "start": 4345.6, "end": 4351.4800000000005, "text": " So the numbers should stay about the same.", "tokens": [407, 264, 3547, 820, 1754, 466, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.10829164347517381, "compression_ratio": 1.871559633027523, "no_speech_prob": 5.255347332422389e-06}, {"id": 973, "seek": 433656, "start": 4351.4800000000005, "end": 4356.0, "text": " So that's one of the tough things about training GANs, is it's kind of hard to know how are", "tokens": [407, 300, 311, 472, 295, 264, 4930, 721, 466, 3097, 460, 1770, 82, 11, 307, 309, 311, 733, 295, 1152, 281, 458, 577, 366], "temperature": 0.0, "avg_logprob": -0.10829164347517381, "compression_ratio": 1.871559633027523, "no_speech_prob": 5.255347332422389e-06}, {"id": 974, "seek": 433656, "start": 4356.0, "end": 4357.0, "text": " they doing.", "tokens": [436, 884, 13], "temperature": 0.0, "avg_logprob": -0.10829164347517381, "compression_ratio": 1.871559633027523, "no_speech_prob": 5.255347332422389e-06}, {"id": 975, "seek": 433656, "start": 4357.0, "end": 4361.4400000000005, "text": " So the only way to know how are they doing is to actually take a look at the results", "tokens": [407, 264, 787, 636, 281, 458, 577, 366, 436, 884, 307, 281, 767, 747, 257, 574, 412, 264, 3542], "temperature": 0.0, "avg_logprob": -0.10829164347517381, "compression_ratio": 1.871559633027523, "no_speech_prob": 5.255347332422389e-06}, {"id": 976, "seek": 433656, "start": 4361.4400000000005, "end": 4363.200000000001, "text": " from time to time.", "tokens": [490, 565, 281, 565, 13], "temperature": 0.0, "avg_logprob": -0.10829164347517381, "compression_ratio": 1.871559633027523, "no_speech_prob": 5.255347332422389e-06}, {"id": 977, "seek": 436320, "start": 4363.2, "end": 4369.12, "text": " And so if you put show image equals true here, it'll actually print out a sample after every", "tokens": [400, 370, 498, 291, 829, 855, 3256, 6915, 2074, 510, 11, 309, 603, 767, 4482, 484, 257, 6889, 934, 633], "temperature": 0.0, "avg_logprob": -0.10753332244025336, "compression_ratio": 1.5679012345679013, "no_speech_prob": 3.0415294531849213e-06}, {"id": 978, "seek": 436320, "start": 4369.12, "end": 4370.12, "text": " epoch.", "tokens": [30992, 339, 13], "temperature": 0.0, "avg_logprob": -0.10753332244025336, "compression_ratio": 1.5679012345679013, "no_speech_prob": 3.0415294531849213e-06}, {"id": 979, "seek": 436320, "start": 4370.12, "end": 4374.32, "text": " I haven't put that in the notebook because it makes it too big for the repo, but you", "tokens": [286, 2378, 380, 829, 300, 294, 264, 21060, 570, 309, 1669, 309, 886, 955, 337, 264, 49040, 11, 457, 291], "temperature": 0.0, "avg_logprob": -0.10753332244025336, "compression_ratio": 1.5679012345679013, "no_speech_prob": 3.0415294531849213e-06}, {"id": 980, "seek": 436320, "start": 4374.32, "end": 4375.679999999999, "text": " can try that.", "tokens": [393, 853, 300, 13], "temperature": 0.0, "avg_logprob": -0.10753332244025336, "compression_ratio": 1.5679012345679013, "no_speech_prob": 3.0415294531849213e-06}, {"id": 981, "seek": 436320, "start": 4375.679999999999, "end": 4381.0, "text": " So I've just put the results at the bottom, and here it is.", "tokens": [407, 286, 600, 445, 829, 264, 3542, 412, 264, 2767, 11, 293, 510, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.10753332244025336, "compression_ratio": 1.5679012345679013, "no_speech_prob": 3.0415294531849213e-06}, {"id": 982, "seek": 436320, "start": 4381.0, "end": 4385.92, "text": " So pretty beautiful, I would say.", "tokens": [407, 1238, 2238, 11, 286, 576, 584, 13], "temperature": 0.0, "avg_logprob": -0.10753332244025336, "compression_ratio": 1.5679012345679013, "no_speech_prob": 3.0415294531849213e-06}, {"id": 983, "seek": 436320, "start": 4385.92, "end": 4389.84, "text": " We already knew how to get rid of the numbers, but we now don't really have that kind of", "tokens": [492, 1217, 2586, 577, 281, 483, 3973, 295, 264, 3547, 11, 457, 321, 586, 500, 380, 534, 362, 300, 733, 295], "temperature": 0.0, "avg_logprob": -0.10753332244025336, "compression_ratio": 1.5679012345679013, "no_speech_prob": 3.0415294531849213e-06}, {"id": 984, "seek": 438984, "start": 4389.84, "end": 4395.96, "text": " artifact of where it used to be, and it's definitely sharpening up this little kitty", "tokens": [34806, 295, 689, 309, 1143, 281, 312, 11, 293, 309, 311, 2138, 8199, 4559, 493, 341, 707, 33026], "temperature": 0.0, "avg_logprob": -0.18435775756835937, "compression_ratio": 1.470899470899471, "no_speech_prob": 5.682177288690582e-06}, {"id": 985, "seek": 438984, "start": 4395.96, "end": 4402.04, "text": " cat quite nicely.", "tokens": [3857, 1596, 9594, 13], "temperature": 0.0, "avg_logprob": -0.18435775756835937, "compression_ratio": 1.470899470899471, "no_speech_prob": 5.682177288690582e-06}, {"id": 986, "seek": 438984, "start": 4402.04, "end": 4403.6, "text": " It's not great always.", "tokens": [467, 311, 406, 869, 1009, 13], "temperature": 0.0, "avg_logprob": -0.18435775756835937, "compression_ratio": 1.470899470899471, "no_speech_prob": 5.682177288690582e-06}, {"id": 987, "seek": 438984, "start": 4403.6, "end": 4410.56, "text": " Like there's some weird kind of noise going on here.", "tokens": [1743, 456, 311, 512, 3657, 733, 295, 5658, 516, 322, 510, 13], "temperature": 0.0, "avg_logprob": -0.18435775756835937, "compression_ratio": 1.470899470899471, "no_speech_prob": 5.682177288690582e-06}, {"id": 988, "seek": 438984, "start": 4410.56, "end": 4411.96, "text": " Certainly a lot better than the horrible original.", "tokens": [16628, 257, 688, 1101, 813, 264, 9263, 3380, 13], "temperature": 0.0, "avg_logprob": -0.18435775756835937, "compression_ratio": 1.470899470899471, "no_speech_prob": 5.682177288690582e-06}, {"id": 989, "seek": 438984, "start": 4411.96, "end": 4416.24, "text": " Like this is a tough job to turn that into that.", "tokens": [1743, 341, 307, 257, 4930, 1691, 281, 1261, 300, 666, 300, 13], "temperature": 0.0, "avg_logprob": -0.18435775756835937, "compression_ratio": 1.470899470899471, "no_speech_prob": 5.682177288690582e-06}, {"id": 990, "seek": 441624, "start": 4416.24, "end": 4420.16, "text": " But there are some really obvious problems.", "tokens": [583, 456, 366, 512, 534, 6322, 2740, 13], "temperature": 0.0, "avg_logprob": -0.1462378946940104, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.0952855518553406e-05}, {"id": 991, "seek": 441624, "start": 4420.16, "end": 4426.12, "text": " Like here, these things ought to be eyeballs, and they're not.", "tokens": [1743, 510, 11, 613, 721, 13416, 281, 312, 43758, 11, 293, 436, 434, 406, 13], "temperature": 0.0, "avg_logprob": -0.1462378946940104, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.0952855518553406e-05}, {"id": 992, "seek": 441624, "start": 4426.12, "end": 4428.0, "text": " So why aren't they?", "tokens": [407, 983, 3212, 380, 436, 30], "temperature": 0.0, "avg_logprob": -0.1462378946940104, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.0952855518553406e-05}, {"id": 993, "seek": 441624, "start": 4428.0, "end": 4434.2, "text": " Well, our critic doesn't know anything about eyeballs, and even if it did, it wouldn't", "tokens": [1042, 11, 527, 7850, 1177, 380, 458, 1340, 466, 43758, 11, 293, 754, 498, 309, 630, 11, 309, 2759, 380], "temperature": 0.0, "avg_logprob": -0.1462378946940104, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.0952855518553406e-05}, {"id": 994, "seek": 441624, "start": 4434.2, "end": 4436.5599999999995, "text": " know that eyeballs are particularly important.", "tokens": [458, 300, 43758, 366, 4098, 1021, 13], "temperature": 0.0, "avg_logprob": -0.1462378946940104, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.0952855518553406e-05}, {"id": 995, "seek": 441624, "start": 4436.5599999999995, "end": 4437.76, "text": " We care about eyes.", "tokens": [492, 1127, 466, 2575, 13], "temperature": 0.0, "avg_logprob": -0.1462378946940104, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.0952855518553406e-05}, {"id": 996, "seek": 443776, "start": 4437.76, "end": 4446.12, "text": " Like when we see a cat without eyes, it's a lot less cute.", "tokens": [1743, 562, 321, 536, 257, 3857, 1553, 2575, 11, 309, 311, 257, 688, 1570, 4052, 13], "temperature": 0.0, "avg_logprob": -0.11277824098413641, "compression_ratio": 1.5757575757575757, "no_speech_prob": 1.6027653373384965e-06}, {"id": 997, "seek": 443776, "start": 4446.12, "end": 4452.76, "text": " I mean I'm more of a dog person.", "tokens": [286, 914, 286, 478, 544, 295, 257, 3000, 954, 13], "temperature": 0.0, "avg_logprob": -0.11277824098413641, "compression_ratio": 1.5757575757575757, "no_speech_prob": 1.6027653373384965e-06}, {"id": 998, "seek": 443776, "start": 4452.76, "end": 4459.52, "text": " It just doesn't know that this is a feature that matters, particularly because the critic,", "tokens": [467, 445, 1177, 380, 458, 300, 341, 307, 257, 4111, 300, 7001, 11, 4098, 570, 264, 7850, 11], "temperature": 0.0, "avg_logprob": -0.11277824098413641, "compression_ratio": 1.5757575757575757, "no_speech_prob": 1.6027653373384965e-06}, {"id": 999, "seek": 443776, "start": 4459.52, "end": 4461.46, "text": " remember, is not a pre-trained network.", "tokens": [1604, 11, 307, 406, 257, 659, 12, 17227, 2001, 3209, 13], "temperature": 0.0, "avg_logprob": -0.11277824098413641, "compression_ratio": 1.5757575757575757, "no_speech_prob": 1.6027653373384965e-06}, {"id": 1000, "seek": 443776, "start": 4461.46, "end": 4466.16, "text": " So I kind of suspect that if we replace the critic with a pre-trained network that's been", "tokens": [407, 286, 733, 295, 9091, 300, 498, 321, 7406, 264, 7850, 365, 257, 659, 12, 17227, 2001, 3209, 300, 311, 668], "temperature": 0.0, "avg_logprob": -0.11277824098413641, "compression_ratio": 1.5757575757575757, "no_speech_prob": 1.6027653373384965e-06}, {"id": 1001, "seek": 446616, "start": 4466.16, "end": 4471.76, "text": " pre-trained on ImageNet but is also compatible with GANs, it might do a better job here.", "tokens": [659, 12, 17227, 2001, 322, 29903, 31890, 457, 307, 611, 18218, 365, 460, 1770, 82, 11, 309, 1062, 360, 257, 1101, 1691, 510, 13], "temperature": 0.0, "avg_logprob": -0.12182153504470299, "compression_ratio": 1.477832512315271, "no_speech_prob": 1.6963176676654257e-05}, {"id": 1002, "seek": 446616, "start": 4471.76, "end": 4476.84, "text": " But it's definitely a shortcoming of this approach.", "tokens": [583, 309, 311, 2138, 257, 2099, 6590, 295, 341, 3109, 13], "temperature": 0.0, "avg_logprob": -0.12182153504470299, "compression_ratio": 1.477832512315271, "no_speech_prob": 1.6963176676654257e-05}, {"id": 1003, "seek": 446616, "start": 4476.84, "end": 4478.32, "text": " So we're going to have a break.", "tokens": [407, 321, 434, 516, 281, 362, 257, 1821, 13], "temperature": 0.0, "avg_logprob": -0.12182153504470299, "compression_ratio": 1.477832512315271, "no_speech_prob": 1.6963176676654257e-05}, {"id": 1004, "seek": 446616, "start": 4478.32, "end": 4483.599999999999, "text": " Oh, question first, and then we'll have a break, and then after the break I will show", "tokens": [876, 11, 1168, 700, 11, 293, 550, 321, 603, 362, 257, 1821, 11, 293, 550, 934, 264, 1821, 286, 486, 855], "temperature": 0.0, "avg_logprob": -0.12182153504470299, "compression_ratio": 1.477832512315271, "no_speech_prob": 1.6963176676654257e-05}, {"id": 1005, "seek": 446616, "start": 4483.599999999999, "end": 4488.88, "text": " you how to find the cat's eyeballs again.", "tokens": [291, 577, 281, 915, 264, 3857, 311, 43758, 797, 13], "temperature": 0.0, "avg_logprob": -0.12182153504470299, "compression_ratio": 1.477832512315271, "no_speech_prob": 1.6963176676654257e-05}, {"id": 1006, "seek": 448888, "start": 4488.88, "end": 4496.64, "text": " For what kind of problems do you not want to use UNETs?", "tokens": [1171, 437, 733, 295, 2740, 360, 291, 406, 528, 281, 764, 8229, 4850, 82, 30], "temperature": 0.0, "avg_logprob": -0.11928057670593262, "compression_ratio": 1.5238095238095237, "no_speech_prob": 1.892217005661223e-05}, {"id": 1007, "seek": 448888, "start": 4496.64, "end": 4506.28, "text": " Well UNETs are for when the size of your output is similar to the size of your input and kind", "tokens": [1042, 8229, 4850, 82, 366, 337, 562, 264, 2744, 295, 428, 5598, 307, 2531, 281, 264, 2744, 295, 428, 4846, 293, 733], "temperature": 0.0, "avg_logprob": -0.11928057670593262, "compression_ratio": 1.5238095238095237, "no_speech_prob": 1.892217005661223e-05}, {"id": 1008, "seek": 448888, "start": 4506.28, "end": 4508.88, "text": " of aligned with it.", "tokens": [295, 17962, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.11928057670593262, "compression_ratio": 1.5238095238095237, "no_speech_prob": 1.892217005661223e-05}, {"id": 1009, "seek": 448888, "start": 4508.88, "end": 4513.52, "text": " There's no point having cross connections if that level of spatial resolution in the", "tokens": [821, 311, 572, 935, 1419, 3278, 9271, 498, 300, 1496, 295, 23598, 8669, 294, 264], "temperature": 0.0, "avg_logprob": -0.11928057670593262, "compression_ratio": 1.5238095238095237, "no_speech_prob": 1.892217005661223e-05}, {"id": 1010, "seek": 448888, "start": 4513.52, "end": 4516.64, "text": " output isn't necessary or useful.", "tokens": [5598, 1943, 380, 4818, 420, 4420, 13], "temperature": 0.0, "avg_logprob": -0.11928057670593262, "compression_ratio": 1.5238095238095237, "no_speech_prob": 1.892217005661223e-05}, {"id": 1011, "seek": 451664, "start": 4516.64, "end": 4523.4800000000005, "text": " So yeah, any kind of generative modeling, and segmentation is kind of generative modeling,", "tokens": [407, 1338, 11, 604, 733, 295, 1337, 1166, 15983, 11, 293, 9469, 399, 307, 733, 295, 1337, 1166, 15983, 11], "temperature": 0.0, "avg_logprob": -0.19988239102247285, "compression_ratio": 1.751269035532995, "no_speech_prob": 7.1828958425612655e-06}, {"id": 1012, "seek": 451664, "start": 4523.4800000000005, "end": 4529.84, "text": " it's generating a picture which is a mask of the original objects.", "tokens": [309, 311, 17746, 257, 3036, 597, 307, 257, 6094, 295, 264, 3380, 6565, 13], "temperature": 0.0, "avg_logprob": -0.19988239102247285, "compression_ratio": 1.751269035532995, "no_speech_prob": 7.1828958425612655e-06}, {"id": 1013, "seek": 451664, "start": 4529.84, "end": 4537.04, "text": " So probably anything where you want that kind of resolution of the output to be the same", "tokens": [407, 1391, 1340, 689, 291, 528, 300, 733, 295, 8669, 295, 264, 5598, 281, 312, 264, 912], "temperature": 0.0, "avg_logprob": -0.19988239102247285, "compression_ratio": 1.751269035532995, "no_speech_prob": 7.1828958425612655e-06}, {"id": 1014, "seek": 451664, "start": 4537.04, "end": 4539.64, "text": " kind of fidelity as resolution of the input.", "tokens": [733, 295, 46404, 382, 8669, 295, 264, 4846, 13], "temperature": 0.0, "avg_logprob": -0.19988239102247285, "compression_ratio": 1.751269035532995, "no_speech_prob": 7.1828958425612655e-06}, {"id": 1015, "seek": 451664, "start": 4539.64, "end": 4542.200000000001, "text": " Obviously something like a classifier makes no sense.", "tokens": [7580, 746, 411, 257, 1508, 9902, 1669, 572, 2020, 13], "temperature": 0.0, "avg_logprob": -0.19988239102247285, "compression_ratio": 1.751269035532995, "no_speech_prob": 7.1828958425612655e-06}, {"id": 1016, "seek": 454220, "start": 4542.2, "end": 4548.5199999999995, "text": " In a classifier you just want the downsampling path because at the end you just want a single", "tokens": [682, 257, 1508, 9902, 291, 445, 528, 264, 760, 19988, 11970, 3100, 570, 412, 264, 917, 291, 445, 528, 257, 2167], "temperature": 0.0, "avg_logprob": -0.1704164505004883, "compression_ratio": 1.5589519650655022, "no_speech_prob": 1.0782930985442363e-05}, {"id": 1017, "seek": 454220, "start": 4548.5199999999995, "end": 4553.8, "text": " number which is like is it a dog or a cat or what kind of pet is it or whatever.", "tokens": [1230, 597, 307, 411, 307, 309, 257, 3000, 420, 257, 3857, 420, 437, 733, 295, 3817, 307, 309, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1704164505004883, "compression_ratio": 1.5589519650655022, "no_speech_prob": 1.0782930985442363e-05}, {"id": 1018, "seek": 454220, "start": 4553.8, "end": 4554.8, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.1704164505004883, "compression_ratio": 1.5589519650655022, "no_speech_prob": 1.0782930985442363e-05}, {"id": 1019, "seek": 454220, "start": 4554.8, "end": 4560.2, "text": " Okay, so let's get back together at 5 past 8.", "tokens": [1033, 11, 370, 718, 311, 483, 646, 1214, 412, 1025, 1791, 1649, 13], "temperature": 0.0, "avg_logprob": -0.1704164505004883, "compression_ratio": 1.5589519650655022, "no_speech_prob": 1.0782930985442363e-05}, {"id": 1020, "seek": 454220, "start": 4560.2, "end": 4563.96, "text": " Just before we leave GANs I just mentioned there's another notebook you might be interested", "tokens": [1449, 949, 321, 1856, 460, 1770, 82, 286, 445, 2835, 456, 311, 1071, 21060, 291, 1062, 312, 3102], "temperature": 0.0, "avg_logprob": -0.1704164505004883, "compression_ratio": 1.5589519650655022, "no_speech_prob": 1.0782930985442363e-05}, {"id": 1021, "seek": 454220, "start": 4563.96, "end": 4569.96, "text": " in looking at which is lesson 7W GAN.", "tokens": [294, 1237, 412, 597, 307, 6898, 1614, 54, 460, 1770, 13], "temperature": 0.0, "avg_logprob": -0.1704164505004883, "compression_ratio": 1.5589519650655022, "no_speech_prob": 1.0782930985442363e-05}, {"id": 1022, "seek": 456996, "start": 4569.96, "end": 4578.36, "text": " When GANs started a few years ago people generally used them to kind of create images out of", "tokens": [1133, 460, 1770, 82, 1409, 257, 1326, 924, 2057, 561, 5101, 1143, 552, 281, 733, 295, 1884, 5267, 484, 295], "temperature": 0.0, "avg_logprob": -0.11214957453987816, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.2804206562577747e-05}, {"id": 1023, "seek": 456996, "start": 4578.36, "end": 4584.04, "text": " thin air which I personally don't think is a particularly useful or interesting thing", "tokens": [5862, 1988, 597, 286, 5665, 500, 380, 519, 307, 257, 4098, 4420, 420, 1880, 551], "temperature": 0.0, "avg_logprob": -0.11214957453987816, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.2804206562577747e-05}, {"id": 1024, "seek": 456996, "start": 4584.04, "end": 4590.04, "text": " to do but it's kind of a good, I don't know, it's a good research exercise I guess.", "tokens": [281, 360, 457, 309, 311, 733, 295, 257, 665, 11, 286, 500, 380, 458, 11, 309, 311, 257, 665, 2132, 5380, 286, 2041, 13], "temperature": 0.0, "avg_logprob": -0.11214957453987816, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.2804206562577747e-05}, {"id": 1025, "seek": 456996, "start": 4590.04, "end": 4596.72, "text": " So we implemented this WGAN paper which was kind of really the first one to do a somewhat", "tokens": [407, 321, 12270, 341, 343, 27699, 3035, 597, 390, 733, 295, 534, 264, 700, 472, 281, 360, 257, 8344], "temperature": 0.0, "avg_logprob": -0.11214957453987816, "compression_ratio": 1.5855855855855856, "no_speech_prob": 1.2804206562577747e-05}, {"id": 1026, "seek": 459672, "start": 4596.72, "end": 4603.3, "text": " adequate job somewhat easily and so you can see how to do that with the Fast AI library.", "tokens": [20927, 1691, 8344, 3612, 293, 370, 291, 393, 536, 577, 281, 360, 300, 365, 264, 15968, 7318, 6405, 13], "temperature": 0.0, "avg_logprob": -0.2203397457416241, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.4284634744399227e-05}, {"id": 1027, "seek": 459672, "start": 4603.3, "end": 4611.06, "text": " It's kind of interesting because the dataset we use is this Lsun Bedrooms dataset which", "tokens": [467, 311, 733, 295, 1880, 570, 264, 28872, 321, 764, 307, 341, 441, 11314, 19893, 32346, 28872, 597], "temperature": 0.0, "avg_logprob": -0.2203397457416241, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.4284634744399227e-05}, {"id": 1028, "seek": 459672, "start": 4611.06, "end": 4619.56, "text": " we provided in our URLs which just as you can see has lots and lots and lots of bedrooms.", "tokens": [321, 5649, 294, 527, 43267, 597, 445, 382, 291, 393, 536, 575, 3195, 293, 3195, 293, 3195, 295, 39955, 13], "temperature": 0.0, "avg_logprob": -0.2203397457416241, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.4284634744399227e-05}, {"id": 1029, "seek": 461956, "start": 4619.56, "end": 4628.52, "text": " And the approach, you'll see in the pros here that Sylvain wrote, the approach that we use", "tokens": [400, 264, 3109, 11, 291, 603, 536, 294, 264, 6267, 510, 300, 3902, 14574, 491, 4114, 11, 264, 3109, 300, 321, 764], "temperature": 0.0, "avg_logprob": -0.11150541061010116, "compression_ratio": 1.672514619883041, "no_speech_prob": 1.9332585452502826e-06}, {"id": 1030, "seek": 461956, "start": 4628.52, "end": 4634.160000000001, "text": " in this case is to just say can we create a bedroom?", "tokens": [294, 341, 1389, 307, 281, 445, 584, 393, 321, 1884, 257, 11211, 30], "temperature": 0.0, "avg_logprob": -0.11150541061010116, "compression_ratio": 1.672514619883041, "no_speech_prob": 1.9332585452502826e-06}, {"id": 1031, "seek": 461956, "start": 4634.160000000001, "end": 4642.96, "text": " And so what we actually do is that the input to the generator isn't an image that we clean", "tokens": [400, 370, 437, 321, 767, 360, 307, 300, 264, 4846, 281, 264, 19265, 1943, 380, 364, 3256, 300, 321, 2541], "temperature": 0.0, "avg_logprob": -0.11150541061010116, "compression_ratio": 1.672514619883041, "no_speech_prob": 1.9332585452502826e-06}, {"id": 1032, "seek": 461956, "start": 4642.96, "end": 4643.96, "text": " up.", "tokens": [493, 13], "temperature": 0.0, "avg_logprob": -0.11150541061010116, "compression_ratio": 1.672514619883041, "no_speech_prob": 1.9332585452502826e-06}, {"id": 1033, "seek": 461956, "start": 4643.96, "end": 4647.84, "text": " We actually feed to the generator random noise.", "tokens": [492, 767, 3154, 281, 264, 19265, 4974, 5658, 13], "temperature": 0.0, "avg_logprob": -0.11150541061010116, "compression_ratio": 1.672514619883041, "no_speech_prob": 1.9332585452502826e-06}, {"id": 1034, "seek": 464784, "start": 4647.84, "end": 4653.32, "text": " And so then the generator's task is can you turn random noise into something which the", "tokens": [400, 370, 550, 264, 19265, 311, 5633, 307, 393, 291, 1261, 4974, 5658, 666, 746, 597, 264], "temperature": 0.0, "avg_logprob": -0.09837259095290611, "compression_ratio": 1.5605381165919283, "no_speech_prob": 4.936563527735416e-06}, {"id": 1035, "seek": 464784, "start": 4653.32, "end": 4658.88, "text": " critic can't tell the difference between that output and a real bedroom.", "tokens": [7850, 393, 380, 980, 264, 2649, 1296, 300, 5598, 293, 257, 957, 11211, 13], "temperature": 0.0, "avg_logprob": -0.09837259095290611, "compression_ratio": 1.5605381165919283, "no_speech_prob": 4.936563527735416e-06}, {"id": 1036, "seek": 464784, "start": 4658.88, "end": 4662.400000000001, "text": " And so we're not doing any pre-training here or any of the stuff that makes this kind of", "tokens": [400, 370, 321, 434, 406, 884, 604, 659, 12, 17227, 1760, 510, 420, 604, 295, 264, 1507, 300, 1669, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.09837259095290611, "compression_ratio": 1.5605381165919283, "no_speech_prob": 4.936563527735416e-06}, {"id": 1037, "seek": 464784, "start": 4662.400000000001, "end": 4668.400000000001, "text": " fast and easy.", "tokens": [2370, 293, 1858, 13], "temperature": 0.0, "avg_logprob": -0.09837259095290611, "compression_ratio": 1.5605381165919283, "no_speech_prob": 4.936563527735416e-06}, {"id": 1038, "seek": 464784, "start": 4668.400000000001, "end": 4672.96, "text": " So this is a very traditional approach but you can see you still just go GAN learner", "tokens": [407, 341, 307, 257, 588, 5164, 3109, 457, 291, 393, 536, 291, 920, 445, 352, 460, 1770, 33347], "temperature": 0.0, "avg_logprob": -0.09837259095290611, "compression_ratio": 1.5605381165919283, "no_speech_prob": 4.936563527735416e-06}, {"id": 1039, "seek": 467296, "start": 4672.96, "end": 4677.84, "text": " and there's actually a WGAN version which is this kind of older style approach.", "tokens": [293, 456, 311, 767, 257, 343, 27699, 3037, 597, 307, 341, 733, 295, 4906, 3758, 3109, 13], "temperature": 0.0, "avg_logprob": -0.20130929159461905, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.921217335620895e-05}, {"id": 1040, "seek": 467296, "start": 4677.84, "end": 4683.88, "text": " You just pass in the data and the generator and the critic in the usual way and you call", "tokens": [509, 445, 1320, 294, 264, 1412, 293, 264, 19265, 293, 264, 7850, 294, 264, 7713, 636, 293, 291, 818], "temperature": 0.0, "avg_logprob": -0.20130929159461905, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.921217335620895e-05}, {"id": 1041, "seek": 467296, "start": 4683.88, "end": 4684.88, "text": " fit.", "tokens": [3318, 13], "temperature": 0.0, "avg_logprob": -0.20130929159461905, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.921217335620895e-05}, {"id": 1042, "seek": 467296, "start": 4684.88, "end": 4688.84, "text": " And you'll see in this case we have show image on.", "tokens": [400, 291, 603, 536, 294, 341, 1389, 321, 362, 855, 3256, 322, 13], "temperature": 0.0, "avg_logprob": -0.20130929159461905, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.921217335620895e-05}, {"id": 1043, "seek": 467296, "start": 4688.84, "end": 4692.36, "text": " After epoch one it's not creating great bedrooms or two or three.", "tokens": [2381, 30992, 339, 472, 309, 311, 406, 4084, 869, 39955, 420, 732, 420, 1045, 13], "temperature": 0.0, "avg_logprob": -0.20130929159461905, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.921217335620895e-05}, {"id": 1044, "seek": 467296, "start": 4692.36, "end": 4696.2, "text": " And you can really see that in the early days of these kinds of GANs it doesn't do a great", "tokens": [400, 291, 393, 534, 536, 300, 294, 264, 2440, 1708, 295, 613, 3685, 295, 460, 1770, 82, 309, 1177, 380, 360, 257, 869], "temperature": 0.0, "avg_logprob": -0.20130929159461905, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.921217335620895e-05}, {"id": 1045, "seek": 467296, "start": 4696.2, "end": 4698.16, "text": " job of anything.", "tokens": [1691, 295, 1340, 13], "temperature": 0.0, "avg_logprob": -0.20130929159461905, "compression_ratio": 1.6446280991735538, "no_speech_prob": 1.921217335620895e-05}, {"id": 1046, "seek": 469816, "start": 4698.16, "end": 4707.48, "text": " But eventually after a couple of hours of training producing somewhat like bedroom-ish", "tokens": [583, 4728, 934, 257, 1916, 295, 2496, 295, 3097, 10501, 8344, 411, 11211, 12, 742], "temperature": 0.0, "avg_logprob": -0.12874765538457614, "compression_ratio": 1.4375, "no_speech_prob": 3.3929782148334198e-06}, {"id": 1047, "seek": 469816, "start": 4707.48, "end": 4709.48, "text": " things.", "tokens": [721, 13], "temperature": 0.0, "avg_logprob": -0.12874765538457614, "compression_ratio": 1.4375, "no_speech_prob": 3.3929782148334198e-06}, {"id": 1048, "seek": 469816, "start": 4709.48, "end": 4715.5599999999995, "text": " So anyway it's a notebook you can never play with and it's a bit of fun.", "tokens": [407, 4033, 309, 311, 257, 21060, 291, 393, 1128, 862, 365, 293, 309, 311, 257, 857, 295, 1019, 13], "temperature": 0.0, "avg_logprob": -0.12874765538457614, "compression_ratio": 1.4375, "no_speech_prob": 3.3929782148334198e-06}, {"id": 1049, "seek": 469816, "start": 4715.5599999999995, "end": 4727.76, "text": " So I was very excited when we got fast AI to the point in the last week or so that we", "tokens": [407, 286, 390, 588, 2919, 562, 321, 658, 2370, 7318, 281, 264, 935, 294, 264, 1036, 1243, 420, 370, 300, 321], "temperature": 0.0, "avg_logprob": -0.12874765538457614, "compression_ratio": 1.4375, "no_speech_prob": 3.3929782148334198e-06}, {"id": 1050, "seek": 472776, "start": 4727.76, "end": 4733.76, "text": " had GANs working in a way where kind of API-wise they're far more concise and more flexible", "tokens": [632, 460, 1770, 82, 1364, 294, 257, 636, 689, 733, 295, 9362, 12, 3711, 436, 434, 1400, 544, 44882, 293, 544, 11358], "temperature": 0.0, "avg_logprob": -0.11650436265127999, "compression_ratio": 1.5938697318007662, "no_speech_prob": 2.9303426344995387e-05}, {"id": 1051, "seek": 472776, "start": 4733.76, "end": 4737.72, "text": " than any other library that exists.", "tokens": [813, 604, 661, 6405, 300, 8198, 13], "temperature": 0.0, "avg_logprob": -0.11650436265127999, "compression_ratio": 1.5938697318007662, "no_speech_prob": 2.9303426344995387e-05}, {"id": 1052, "seek": 472776, "start": 4737.72, "end": 4741.92, "text": " But also kind of disappointed with they take a long time to train and the outputs are still", "tokens": [583, 611, 733, 295, 13856, 365, 436, 747, 257, 938, 565, 281, 3847, 293, 264, 23930, 366, 920], "temperature": 0.0, "avg_logprob": -0.11650436265127999, "compression_ratio": 1.5938697318007662, "no_speech_prob": 2.9303426344995387e-05}, {"id": 1053, "seek": 472776, "start": 4741.92, "end": 4743.56, "text": " like so-so.", "tokens": [411, 370, 12, 539, 13], "temperature": 0.0, "avg_logprob": -0.11650436265127999, "compression_ratio": 1.5938697318007662, "no_speech_prob": 2.9303426344995387e-05}, {"id": 1054, "seek": 472776, "start": 4743.56, "end": 4747.96, "text": " And so the next step was like well can we get rid of GANs entirely.", "tokens": [400, 370, 264, 958, 1823, 390, 411, 731, 393, 321, 483, 3973, 295, 460, 1770, 82, 7696, 13], "temperature": 0.0, "avg_logprob": -0.11650436265127999, "compression_ratio": 1.5938697318007662, "no_speech_prob": 2.9303426344995387e-05}, {"id": 1055, "seek": 472776, "start": 4747.96, "end": 4752.08, "text": " So the first step with that, I mean obviously the thing we really want to do is come up", "tokens": [407, 264, 700, 1823, 365, 300, 11, 286, 914, 2745, 264, 551, 321, 534, 528, 281, 360, 307, 808, 493], "temperature": 0.0, "avg_logprob": -0.11650436265127999, "compression_ratio": 1.5938697318007662, "no_speech_prob": 2.9303426344995387e-05}, {"id": 1056, "seek": 472776, "start": 4752.08, "end": 4753.08, "text": " with a better loss function.", "tokens": [365, 257, 1101, 4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.11650436265127999, "compression_ratio": 1.5938697318007662, "no_speech_prob": 2.9303426344995387e-05}, {"id": 1057, "seek": 475308, "start": 4753.08, "end": 4759.48, "text": " We want a loss function that does a good job of saying this is a high quality image without", "tokens": [492, 528, 257, 4470, 2445, 300, 775, 257, 665, 1691, 295, 1566, 341, 307, 257, 1090, 3125, 3256, 1553], "temperature": 0.0, "avg_logprob": -0.13028661743933415, "compression_ratio": 1.6401384083044983, "no_speech_prob": 1.11249091787613e-05}, {"id": 1058, "seek": 475308, "start": 4759.48, "end": 4764.12, "text": " having to go all the GAN trouble and preferably it also doesn't just say it's a high quality", "tokens": [1419, 281, 352, 439, 264, 460, 1770, 5253, 293, 45916, 309, 611, 1177, 380, 445, 584, 309, 311, 257, 1090, 3125], "temperature": 0.0, "avg_logprob": -0.13028661743933415, "compression_ratio": 1.6401384083044983, "no_speech_prob": 1.11249091787613e-05}, {"id": 1059, "seek": 475308, "start": 4764.12, "end": 4769.2, "text": " image but it's an image which actually looks like the thing it's meant to.", "tokens": [3256, 457, 309, 311, 364, 3256, 597, 767, 1542, 411, 264, 551, 309, 311, 4140, 281, 13], "temperature": 0.0, "avg_logprob": -0.13028661743933415, "compression_ratio": 1.6401384083044983, "no_speech_prob": 1.11249091787613e-05}, {"id": 1060, "seek": 475308, "start": 4769.2, "end": 4773.74, "text": " So the real trick here comes back to this paper from a couple of years ago, Perceptual", "tokens": [407, 264, 957, 4282, 510, 1487, 646, 281, 341, 3035, 490, 257, 1916, 295, 924, 2057, 11, 3026, 1336, 901], "temperature": 0.0, "avg_logprob": -0.13028661743933415, "compression_ratio": 1.6401384083044983, "no_speech_prob": 1.11249091787613e-05}, {"id": 1061, "seek": 475308, "start": 4773.74, "end": 4777.64, "text": " Losses for Real-Time Style Transfer and Super Resolution.", "tokens": [441, 772, 279, 337, 8467, 12, 22233, 27004, 35025, 293, 4548, 5015, 3386, 13], "temperature": 0.0, "avg_logprob": -0.13028661743933415, "compression_ratio": 1.6401384083044983, "no_speech_prob": 1.11249091787613e-05}, {"id": 1062, "seek": 475308, "start": 4777.64, "end": 4782.08, "text": " Justin Johnson et al. created this thing they call perceptual losses.", "tokens": [11320, 9779, 1030, 419, 13, 2942, 341, 551, 436, 818, 43276, 901, 15352, 13], "temperature": 0.0, "avg_logprob": -0.13028661743933415, "compression_ratio": 1.6401384083044983, "no_speech_prob": 1.11249091787613e-05}, {"id": 1063, "seek": 478208, "start": 4782.08, "end": 4786.92, "text": " It's a nice paper but I hate this term because they're nothing particularly perceptual about", "tokens": [467, 311, 257, 1481, 3035, 457, 286, 4700, 341, 1433, 570, 436, 434, 1825, 4098, 43276, 901, 466], "temperature": 0.0, "avg_logprob": -0.15500819866473858, "compression_ratio": 1.7033333333333334, "no_speech_prob": 2.7960586521658115e-05}, {"id": 1064, "seek": 478208, "start": 4786.92, "end": 4787.92, "text": " them.", "tokens": [552, 13], "temperature": 0.0, "avg_logprob": -0.15500819866473858, "compression_ratio": 1.7033333333333334, "no_speech_prob": 2.7960586521658115e-05}, {"id": 1065, "seek": 478208, "start": 4787.92, "end": 4789.04, "text": " I would call them feature losses.", "tokens": [286, 576, 818, 552, 4111, 15352, 13], "temperature": 0.0, "avg_logprob": -0.15500819866473858, "compression_ratio": 1.7033333333333334, "no_speech_prob": 2.7960586521658115e-05}, {"id": 1066, "seek": 478208, "start": 4789.04, "end": 4793.82, "text": " So in the Fast AI library you'll see this referred to as feature losses.", "tokens": [407, 294, 264, 15968, 7318, 6405, 291, 603, 536, 341, 10839, 281, 382, 4111, 15352, 13], "temperature": 0.0, "avg_logprob": -0.15500819866473858, "compression_ratio": 1.7033333333333334, "no_speech_prob": 2.7960586521658115e-05}, {"id": 1067, "seek": 478208, "start": 4793.82, "end": 4799.92, "text": " And it shares something with GANs which is that after we go through our generator which", "tokens": [400, 309, 12182, 746, 365, 460, 1770, 82, 597, 307, 300, 934, 321, 352, 807, 527, 19265, 597], "temperature": 0.0, "avg_logprob": -0.15500819866473858, "compression_ratio": 1.7033333333333334, "no_speech_prob": 2.7960586521658115e-05}, {"id": 1068, "seek": 478208, "start": 4799.92, "end": 4803.84, "text": " they call the Image Transform Net and you can see it's got this kind of U-net shaped", "tokens": [436, 818, 264, 29903, 27938, 6188, 293, 291, 393, 536, 309, 311, 658, 341, 733, 295, 624, 12, 7129, 13475], "temperature": 0.0, "avg_logprob": -0.15500819866473858, "compression_ratio": 1.7033333333333334, "no_speech_prob": 2.7960586521658115e-05}, {"id": 1069, "seek": 478208, "start": 4803.84, "end": 4807.96, "text": " thing they didn't actually use U-nets because at the time this came out nobody in the machine", "tokens": [551, 436, 994, 380, 767, 764, 624, 12, 77, 1385, 570, 412, 264, 565, 341, 1361, 484, 5079, 294, 264, 3479], "temperature": 0.0, "avg_logprob": -0.15500819866473858, "compression_ratio": 1.7033333333333334, "no_speech_prob": 2.7960586521658115e-05}, {"id": 1070, "seek": 478208, "start": 4807.96, "end": 4810.64, "text": " learning world much knew about U-nets.", "tokens": [2539, 1002, 709, 2586, 466, 624, 12, 77, 1385, 13], "temperature": 0.0, "avg_logprob": -0.15500819866473858, "compression_ratio": 1.7033333333333334, "no_speech_prob": 2.7960586521658115e-05}, {"id": 1071, "seek": 481064, "start": 4810.64, "end": 4813.0, "text": " Nowadays of course we use U-nets.", "tokens": [28908, 295, 1164, 321, 764, 624, 12, 77, 1385, 13], "temperature": 0.0, "avg_logprob": -0.1715802574157715, "compression_ratio": 1.8274111675126903, "no_speech_prob": 4.005788287031464e-05}, {"id": 1072, "seek": 481064, "start": 4813.0, "end": 4815.6, "text": " But anyway something U-net-ish.", "tokens": [583, 4033, 746, 624, 12, 7129, 12, 742, 13], "temperature": 0.0, "avg_logprob": -0.1715802574157715, "compression_ratio": 1.8274111675126903, "no_speech_prob": 4.005788287031464e-05}, {"id": 1073, "seek": 481064, "start": 4815.6, "end": 4821.08, "text": " I should mention in these kind of these architectures where you have a downsampling path followed", "tokens": [286, 820, 2152, 294, 613, 733, 295, 613, 6331, 1303, 689, 291, 362, 257, 760, 19988, 11970, 3100, 6263], "temperature": 0.0, "avg_logprob": -0.1715802574157715, "compression_ratio": 1.8274111675126903, "no_speech_prob": 4.005788287031464e-05}, {"id": 1074, "seek": 481064, "start": 4821.08, "end": 4827.04, "text": " by an upsampling path, the downsampling path is very often called the encoder.", "tokens": [538, 364, 15497, 335, 11970, 3100, 11, 264, 21554, 335, 11970, 3100, 307, 588, 2049, 1219, 264, 2058, 19866, 13], "temperature": 0.0, "avg_logprob": -0.1715802574157715, "compression_ratio": 1.8274111675126903, "no_speech_prob": 4.005788287031464e-05}, {"id": 1075, "seek": 481064, "start": 4827.04, "end": 4830.22, "text": " As you saw in our code actually we called that the encoder.", "tokens": [1018, 291, 1866, 294, 527, 3089, 767, 321, 1219, 300, 264, 2058, 19866, 13], "temperature": 0.0, "avg_logprob": -0.1715802574157715, "compression_ratio": 1.8274111675126903, "no_speech_prob": 4.005788287031464e-05}, {"id": 1076, "seek": 481064, "start": 4830.22, "end": 4835.08, "text": " And the upsampling path is very often called the decoder.", "tokens": [400, 264, 15497, 335, 11970, 3100, 307, 588, 2049, 1219, 264, 979, 19866, 13], "temperature": 0.0, "avg_logprob": -0.1715802574157715, "compression_ratio": 1.8274111675126903, "no_speech_prob": 4.005788287031464e-05}, {"id": 1077, "seek": 483508, "start": 4835.08, "end": 4841.96, "text": " In generative models generally including generative text models, neural translation, stuff like", "tokens": [682, 1337, 1166, 5245, 5101, 3009, 1337, 1166, 2487, 5245, 11, 18161, 12853, 11, 1507, 411], "temperature": 0.0, "avg_logprob": -0.1334692450130687, "compression_ratio": 1.836283185840708, "no_speech_prob": 4.86016597278649e-06}, {"id": 1078, "seek": 483508, "start": 4841.96, "end": 4845.88, "text": " that they tend to be called the encoder and the decoder, two pieces.", "tokens": [300, 436, 3928, 281, 312, 1219, 264, 2058, 19866, 293, 264, 979, 19866, 11, 732, 3755, 13], "temperature": 0.0, "avg_logprob": -0.1334692450130687, "compression_ratio": 1.836283185840708, "no_speech_prob": 4.86016597278649e-06}, {"id": 1079, "seek": 483508, "start": 4845.88, "end": 4853.22, "text": " So we have this generator and we want a loss function that says is the thing that it's", "tokens": [407, 321, 362, 341, 19265, 293, 321, 528, 257, 4470, 2445, 300, 1619, 307, 264, 551, 300, 309, 311], "temperature": 0.0, "avg_logprob": -0.1334692450130687, "compression_ratio": 1.836283185840708, "no_speech_prob": 4.86016597278649e-06}, {"id": 1080, "seek": 483508, "start": 4853.22, "end": 4856.32, "text": " created like the thing that we want.", "tokens": [2942, 411, 264, 551, 300, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.1334692450130687, "compression_ratio": 1.836283185840708, "no_speech_prob": 4.86016597278649e-06}, {"id": 1081, "seek": 483508, "start": 4856.32, "end": 4860.64, "text": " And so the way they do that is they take the prediction, remember y hat is what we normally", "tokens": [400, 370, 264, 636, 436, 360, 300, 307, 436, 747, 264, 17630, 11, 1604, 288, 2385, 307, 437, 321, 5646], "temperature": 0.0, "avg_logprob": -0.1334692450130687, "compression_ratio": 1.836283185840708, "no_speech_prob": 4.86016597278649e-06}, {"id": 1082, "seek": 483508, "start": 4860.64, "end": 4862.72, "text": " use for a prediction from a model.", "tokens": [764, 337, 257, 17630, 490, 257, 2316, 13], "temperature": 0.0, "avg_logprob": -0.1334692450130687, "compression_ratio": 1.836283185840708, "no_speech_prob": 4.86016597278649e-06}, {"id": 1083, "seek": 486272, "start": 4862.72, "end": 4869.08, "text": " We take the prediction and we put it through a pre-trained image net network.", "tokens": [492, 747, 264, 17630, 293, 321, 829, 309, 807, 257, 659, 12, 17227, 2001, 3256, 2533, 3209, 13], "temperature": 0.0, "avg_logprob": -0.10706638645481419, "compression_ratio": 1.8675799086757991, "no_speech_prob": 1.2804513062292244e-05}, {"id": 1084, "seek": 486272, "start": 4869.08, "end": 4875.12, "text": " So at the time that this came out the pre-trained image network they were using was VGG.", "tokens": [407, 412, 264, 565, 300, 341, 1361, 484, 264, 659, 12, 17227, 2001, 3256, 3209, 436, 645, 1228, 390, 691, 27561, 13], "temperature": 0.0, "avg_logprob": -0.10706638645481419, "compression_ratio": 1.8675799086757991, "no_speech_prob": 1.2804513062292244e-05}, {"id": 1085, "seek": 486272, "start": 4875.12, "end": 4879.56, "text": " People still, it's kind of old now but people still tend to use it because it works fine", "tokens": [3432, 920, 11, 309, 311, 733, 295, 1331, 586, 457, 561, 920, 3928, 281, 764, 309, 570, 309, 1985, 2489], "temperature": 0.0, "avg_logprob": -0.10706638645481419, "compression_ratio": 1.8675799086757991, "no_speech_prob": 1.2804513062292244e-05}, {"id": 1086, "seek": 486272, "start": 4879.56, "end": 4883.320000000001, "text": " for this process.", "tokens": [337, 341, 1399, 13], "temperature": 0.0, "avg_logprob": -0.10706638645481419, "compression_ratio": 1.8675799086757991, "no_speech_prob": 1.2804513062292244e-05}, {"id": 1087, "seek": 486272, "start": 4883.320000000001, "end": 4888.2, "text": " So they take the prediction and they put it through VGG, the pre-trained image net network.", "tokens": [407, 436, 747, 264, 17630, 293, 436, 829, 309, 807, 691, 27561, 11, 264, 659, 12, 17227, 2001, 3256, 2533, 3209, 13], "temperature": 0.0, "avg_logprob": -0.10706638645481419, "compression_ratio": 1.8675799086757991, "no_speech_prob": 1.2804513062292244e-05}, {"id": 1088, "seek": 486272, "start": 4888.2, "end": 4890.96, "text": " It doesn't matter too much which one it is.", "tokens": [467, 1177, 380, 1871, 886, 709, 597, 472, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.10706638645481419, "compression_ratio": 1.8675799086757991, "no_speech_prob": 1.2804513062292244e-05}, {"id": 1089, "seek": 489096, "start": 4890.96, "end": 4897.36, "text": " And so normally the output of that would tell you hey, is this generated thing a dog or", "tokens": [400, 370, 5646, 264, 5598, 295, 300, 576, 980, 291, 4177, 11, 307, 341, 10833, 551, 257, 3000, 420], "temperature": 0.0, "avg_logprob": -0.15296301215586036, "compression_ratio": 1.7066115702479339, "no_speech_prob": 8.664077540743165e-06}, {"id": 1090, "seek": 489096, "start": 4897.36, "end": 4902.2, "text": " a cat or an airplane or a fire engine or whatever.", "tokens": [257, 3857, 420, 364, 17130, 420, 257, 2610, 2848, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.15296301215586036, "compression_ratio": 1.7066115702479339, "no_speech_prob": 8.664077540743165e-06}, {"id": 1091, "seek": 489096, "start": 4902.2, "end": 4906.64, "text": " But in the process of getting to that final classification it goes through lots of different", "tokens": [583, 294, 264, 1399, 295, 1242, 281, 300, 2572, 21538, 309, 1709, 807, 3195, 295, 819], "temperature": 0.0, "avg_logprob": -0.15296301215586036, "compression_ratio": 1.7066115702479339, "no_speech_prob": 8.664077540743165e-06}, {"id": 1092, "seek": 489096, "start": 4906.64, "end": 4911.96, "text": " layers and in this case they've color coded all the layers with the same grid size and", "tokens": [7914, 293, 294, 341, 1389, 436, 600, 2017, 34874, 439, 264, 7914, 365, 264, 912, 10748, 2744, 293], "temperature": 0.0, "avg_logprob": -0.15296301215586036, "compression_ratio": 1.7066115702479339, "no_speech_prob": 8.664077540743165e-06}, {"id": 1093, "seek": 489096, "start": 4911.96, "end": 4913.68, "text": " the feature map with the same color.", "tokens": [264, 4111, 4471, 365, 264, 912, 2017, 13], "temperature": 0.0, "avg_logprob": -0.15296301215586036, "compression_ratio": 1.7066115702479339, "no_speech_prob": 8.664077540743165e-06}, {"id": 1094, "seek": 489096, "start": 4913.68, "end": 4916.54, "text": " So every time we switch colors we're switching grid size.", "tokens": [407, 633, 565, 321, 3679, 4577, 321, 434, 16493, 10748, 2744, 13], "temperature": 0.0, "avg_logprob": -0.15296301215586036, "compression_ratio": 1.7066115702479339, "no_speech_prob": 8.664077540743165e-06}, {"id": 1095, "seek": 491654, "start": 4916.54, "end": 4921.36, "text": " So there's a stride to conv or in VGG's case they still used to use max pooling layers", "tokens": [407, 456, 311, 257, 1056, 482, 281, 3754, 420, 294, 691, 27561, 311, 1389, 436, 920, 1143, 281, 764, 11469, 7005, 278, 7914], "temperature": 0.0, "avg_logprob": -0.1697164403981176, "compression_ratio": 1.594871794871795, "no_speech_prob": 3.237717237425386e-06}, {"id": 1096, "seek": 491654, "start": 4921.36, "end": 4924.88, "text": " which is a similar idea.", "tokens": [597, 307, 257, 2531, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1697164403981176, "compression_ratio": 1.594871794871795, "no_speech_prob": 3.237717237425386e-06}, {"id": 1097, "seek": 491654, "start": 4924.88, "end": 4931.3, "text": " And so what we could do is say let's not take the final output of the VGG model on this", "tokens": [400, 370, 437, 321, 727, 360, 307, 584, 718, 311, 406, 747, 264, 2572, 5598, 295, 264, 691, 27561, 2316, 322, 341], "temperature": 0.0, "avg_logprob": -0.1697164403981176, "compression_ratio": 1.594871794871795, "no_speech_prob": 3.237717237425386e-06}, {"id": 1098, "seek": 491654, "start": 4931.3, "end": 4937.04, "text": " generated image but let's take something in the middle.", "tokens": [10833, 3256, 457, 718, 311, 747, 746, 294, 264, 2808, 13], "temperature": 0.0, "avg_logprob": -0.1697164403981176, "compression_ratio": 1.594871794871795, "no_speech_prob": 3.237717237425386e-06}, {"id": 1099, "seek": 491654, "start": 4937.04, "end": 4940.98, "text": " Let's take the activations of some layer in the middle.", "tokens": [961, 311, 747, 264, 2430, 763, 295, 512, 4583, 294, 264, 2808, 13], "temperature": 0.0, "avg_logprob": -0.1697164403981176, "compression_ratio": 1.594871794871795, "no_speech_prob": 3.237717237425386e-06}, {"id": 1100, "seek": 494098, "start": 4940.98, "end": 4950.5199999999995, "text": " So those activations might be a feature map of 256 channels by 28 by 28.", "tokens": [407, 729, 2430, 763, 1062, 312, 257, 4111, 4471, 295, 38882, 9235, 538, 7562, 538, 7562, 13], "temperature": 0.0, "avg_logprob": -0.12729574970363342, "compression_ratio": 2.0609137055837565, "no_speech_prob": 8.664235792821273e-06}, {"id": 1101, "seek": 494098, "start": 4950.5199999999995, "end": 4955.879999999999, "text": " And so those 28 by 28 grid cells will kind of roughly semantically say things like hey,", "tokens": [400, 370, 729, 7562, 538, 7562, 10748, 5438, 486, 733, 295, 9810, 4361, 49505, 584, 721, 411, 4177, 11], "temperature": 0.0, "avg_logprob": -0.12729574970363342, "compression_ratio": 2.0609137055837565, "no_speech_prob": 8.664235792821273e-06}, {"id": 1102, "seek": 494098, "start": 4955.879999999999, "end": 4960.599999999999, "text": " in this part of that 28 by 28 grid is there something that looks kind of furry or is there", "tokens": [294, 341, 644, 295, 300, 7562, 538, 7562, 10748, 307, 456, 746, 300, 1542, 733, 295, 47073, 420, 307, 456], "temperature": 0.0, "avg_logprob": -0.12729574970363342, "compression_ratio": 2.0609137055837565, "no_speech_prob": 8.664235792821273e-06}, {"id": 1103, "seek": 494098, "start": 4960.599999999999, "end": 4963.759999999999, "text": " something that looks kind of shiny or is there something that looks kind of circular or is", "tokens": [746, 300, 1542, 733, 295, 16997, 420, 307, 456, 746, 300, 1542, 733, 295, 16476, 420, 307], "temperature": 0.0, "avg_logprob": -0.12729574970363342, "compression_ratio": 2.0609137055837565, "no_speech_prob": 8.664235792821273e-06}, {"id": 1104, "seek": 494098, "start": 4963.759999999999, "end": 4967.0199999999995, "text": " there something that kind of looks like an eyeball or whatever.", "tokens": [456, 746, 300, 733, 295, 1542, 411, 364, 38868, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.12729574970363342, "compression_ratio": 2.0609137055837565, "no_speech_prob": 8.664235792821273e-06}, {"id": 1105, "seek": 496702, "start": 4967.02, "end": 4973.4800000000005, "text": " So what we do is we then take the target, so the actual Y value, and we put it through", "tokens": [407, 437, 321, 360, 307, 321, 550, 747, 264, 3779, 11, 370, 264, 3539, 398, 2158, 11, 293, 321, 829, 309, 807], "temperature": 0.0, "avg_logprob": -0.17994260226978975, "compression_ratio": 1.5024875621890548, "no_speech_prob": 4.222679763188353e-06}, {"id": 1106, "seek": 496702, "start": 4973.4800000000005, "end": 4978.0, "text": " the same pre-trained VGG network and we pull out the activations of the same layer and", "tokens": [264, 912, 659, 12, 17227, 2001, 691, 27561, 3209, 293, 321, 2235, 484, 264, 2430, 763, 295, 264, 912, 4583, 293], "temperature": 0.0, "avg_logprob": -0.17994260226978975, "compression_ratio": 1.5024875621890548, "no_speech_prob": 4.222679763188353e-06}, {"id": 1107, "seek": 496702, "start": 4978.0, "end": 4981.0, "text": " then we do a mean squared error comparison.", "tokens": [550, 321, 360, 257, 914, 8889, 6713, 9660, 13], "temperature": 0.0, "avg_logprob": -0.17994260226978975, "compression_ratio": 1.5024875621890548, "no_speech_prob": 4.222679763188353e-06}, {"id": 1108, "seek": 496702, "start": 4981.0, "end": 4988.72, "text": " So it'll say like okay, in the real image grid cell 1,1 of that 28 by 28 feature map", "tokens": [407, 309, 603, 584, 411, 1392, 11, 294, 264, 957, 3256, 10748, 2815, 502, 11, 16, 295, 300, 7562, 538, 7562, 4111, 4471], "temperature": 0.0, "avg_logprob": -0.17994260226978975, "compression_ratio": 1.5024875621890548, "no_speech_prob": 4.222679763188353e-06}, {"id": 1109, "seek": 498872, "start": 4988.72, "end": 4998.84, "text": " cell is furry and blue and round shaped and in the generated image it's furry and blue", "tokens": [2815, 307, 47073, 293, 3344, 293, 3098, 13475, 293, 294, 264, 10833, 3256, 309, 311, 47073, 293, 3344], "temperature": 0.0, "avg_logprob": -0.12724059461111045, "compression_ratio": 1.702127659574468, "no_speech_prob": 5.682205937773688e-06}, {"id": 1110, "seek": 498872, "start": 4998.84, "end": 5000.3, "text": " and not round shaped.", "tokens": [293, 406, 3098, 13475, 13], "temperature": 0.0, "avg_logprob": -0.12724059461111045, "compression_ratio": 1.702127659574468, "no_speech_prob": 5.682205937773688e-06}, {"id": 1111, "seek": 498872, "start": 5000.3, "end": 5003.62, "text": " So it's kind of like an okay match.", "tokens": [407, 309, 311, 733, 295, 411, 364, 1392, 2995, 13], "temperature": 0.0, "avg_logprob": -0.12724059461111045, "compression_ratio": 1.702127659574468, "no_speech_prob": 5.682205937773688e-06}, {"id": 1112, "seek": 498872, "start": 5003.62, "end": 5010.04, "text": " So that ought to go a long way towards fixing our eyeball problem because in this case the", "tokens": [407, 300, 13416, 281, 352, 257, 938, 636, 3030, 19442, 527, 38868, 1154, 570, 294, 341, 1389, 264], "temperature": 0.0, "avg_logprob": -0.12724059461111045, "compression_ratio": 1.702127659574468, "no_speech_prob": 5.682205937773688e-06}, {"id": 1113, "seek": 498872, "start": 5010.04, "end": 5016.240000000001, "text": " feature map is going to say there's eyeballs here, sorry here, but there isn't here.", "tokens": [4111, 4471, 307, 516, 281, 584, 456, 311, 43758, 510, 11, 2597, 510, 11, 457, 456, 1943, 380, 510, 13], "temperature": 0.0, "avg_logprob": -0.12724059461111045, "compression_ratio": 1.702127659574468, "no_speech_prob": 5.682205937773688e-06}, {"id": 1114, "seek": 501624, "start": 5016.24, "end": 5019.58, "text": " So do a better job of that please, make better eyeballs.", "tokens": [407, 360, 257, 1101, 1691, 295, 300, 1767, 11, 652, 1101, 43758, 13], "temperature": 0.0, "avg_logprob": -0.1286474863688151, "compression_ratio": 1.524390243902439, "no_speech_prob": 4.425316546985414e-06}, {"id": 1115, "seek": 501624, "start": 5019.58, "end": 5021.139999999999, "text": " So that's the idea.", "tokens": [407, 300, 311, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1286474863688151, "compression_ratio": 1.524390243902439, "no_speech_prob": 4.425316546985414e-06}, {"id": 1116, "seek": 501624, "start": 5021.139999999999, "end": 5032.8, "text": " And so that's what we call feature losses or Johnson et al. called perceptual losses.", "tokens": [400, 370, 300, 311, 437, 321, 818, 4111, 15352, 420, 9779, 1030, 419, 13, 1219, 43276, 901, 15352, 13], "temperature": 0.0, "avg_logprob": -0.1286474863688151, "compression_ratio": 1.524390243902439, "no_speech_prob": 4.425316546985414e-06}, {"id": 1117, "seek": 501624, "start": 5032.8, "end": 5044.5, "text": " So to do that we're going to use the Lesson 7 super res notebook and this time the task", "tokens": [407, 281, 360, 300, 321, 434, 516, 281, 764, 264, 18649, 266, 1614, 1687, 725, 21060, 293, 341, 565, 264, 5633], "temperature": 0.0, "avg_logprob": -0.1286474863688151, "compression_ratio": 1.524390243902439, "no_speech_prob": 4.425316546985414e-06}, {"id": 1118, "seek": 504450, "start": 5044.5, "end": 5048.96, "text": " we're going to do is kind of the same as the previous task, but I wrote this notebook a", "tokens": [321, 434, 516, 281, 360, 307, 733, 295, 264, 912, 382, 264, 3894, 5633, 11, 457, 286, 4114, 341, 21060, 257], "temperature": 0.0, "avg_logprob": -0.13458167959790712, "compression_ratio": 1.5958333333333334, "no_speech_prob": 1.0288968951499555e-05}, {"id": 1119, "seek": 504450, "start": 5048.96, "end": 5053.72, "text": " little bit before, the GAN notebook, before I came up with the idea of like putting text", "tokens": [707, 857, 949, 11, 264, 460, 1770, 21060, 11, 949, 286, 1361, 493, 365, 264, 1558, 295, 411, 3372, 2487], "temperature": 0.0, "avg_logprob": -0.13458167959790712, "compression_ratio": 1.5958333333333334, "no_speech_prob": 1.0288968951499555e-05}, {"id": 1120, "seek": 504450, "start": 5053.72, "end": 5056.26, "text": " on it and having a random JPEG quality.", "tokens": [322, 309, 293, 1419, 257, 4974, 508, 5208, 38, 3125, 13], "temperature": 0.0, "avg_logprob": -0.13458167959790712, "compression_ratio": 1.5958333333333334, "no_speech_prob": 1.0288968951499555e-05}, {"id": 1121, "seek": 504450, "start": 5056.26, "end": 5062.72, "text": " So the JPEG quality is always 60, there's no text written on top and it's 96 by 96.", "tokens": [407, 264, 508, 5208, 38, 3125, 307, 1009, 4060, 11, 456, 311, 572, 2487, 3720, 322, 1192, 293, 309, 311, 24124, 538, 24124, 13], "temperature": 0.0, "avg_logprob": -0.13458167959790712, "compression_ratio": 1.5958333333333334, "no_speech_prob": 1.0288968951499555e-05}, {"id": 1122, "seek": 504450, "start": 5062.72, "end": 5069.12, "text": " So and it's before I realized what a great word crapify is, so it's called resize.", "tokens": [407, 293, 309, 311, 949, 286, 5334, 437, 257, 869, 1349, 12426, 2505, 307, 11, 370, 309, 311, 1219, 50069, 13], "temperature": 0.0, "avg_logprob": -0.13458167959790712, "compression_ratio": 1.5958333333333334, "no_speech_prob": 1.0288968951499555e-05}, {"id": 1123, "seek": 506912, "start": 5069.12, "end": 5076.599999999999, "text": " So here's our crappy images and our original images, kind of a similar task to what we", "tokens": [407, 510, 311, 527, 36531, 5267, 293, 527, 3380, 5267, 11, 733, 295, 257, 2531, 5633, 281, 437, 321], "temperature": 0.0, "avg_logprob": -0.09584666032057543, "compression_ratio": 1.5341614906832297, "no_speech_prob": 2.5612139324948657e-06}, {"id": 1124, "seek": 506912, "start": 5076.599999999999, "end": 5078.24, "text": " had before.", "tokens": [632, 949, 13], "temperature": 0.0, "avg_logprob": -0.09584666032057543, "compression_ratio": 1.5341614906832297, "no_speech_prob": 2.5612139324948657e-06}, {"id": 1125, "seek": 506912, "start": 5078.24, "end": 5087.36, "text": " So I'm going to try and create a loss function which does this.", "tokens": [407, 286, 478, 516, 281, 853, 293, 1884, 257, 4470, 2445, 597, 775, 341, 13], "temperature": 0.0, "avg_logprob": -0.09584666032057543, "compression_ratio": 1.5341614906832297, "no_speech_prob": 2.5612139324948657e-06}, {"id": 1126, "seek": 506912, "start": 5087.36, "end": 5094.64, "text": " So the first thing I do is I define a base loss function which is basically like how", "tokens": [407, 264, 700, 551, 286, 360, 307, 286, 6964, 257, 3096, 4470, 2445, 597, 307, 1936, 411, 577], "temperature": 0.0, "avg_logprob": -0.09584666032057543, "compression_ratio": 1.5341614906832297, "no_speech_prob": 2.5612139324948657e-06}, {"id": 1127, "seek": 509464, "start": 5094.64, "end": 5099.280000000001, "text": " am I going to compare the pixels and the features, you know, and the choices mainly are like", "tokens": [669, 286, 516, 281, 6794, 264, 18668, 293, 264, 4122, 11, 291, 458, 11, 293, 264, 7994, 8704, 366, 411], "temperature": 0.0, "avg_logprob": -0.13116455078125, "compression_ratio": 1.5411255411255411, "no_speech_prob": 8.664255801704712e-06}, {"id": 1128, "seek": 509464, "start": 5099.280000000001, "end": 5103.88, "text": " MSE or L1, doesn't matter too much which you choose.", "tokens": [376, 5879, 420, 441, 16, 11, 1177, 380, 1871, 886, 709, 597, 291, 2826, 13], "temperature": 0.0, "avg_logprob": -0.13116455078125, "compression_ratio": 1.5411255411255411, "no_speech_prob": 8.664255801704712e-06}, {"id": 1129, "seek": 509464, "start": 5103.88, "end": 5108.240000000001, "text": " I tend to like L1 better than MSE actually, so I picked L1.", "tokens": [286, 3928, 281, 411, 441, 16, 1101, 813, 376, 5879, 767, 11, 370, 286, 6183, 441, 16, 13], "temperature": 0.0, "avg_logprob": -0.13116455078125, "compression_ratio": 1.5411255411255411, "no_speech_prob": 8.664255801704712e-06}, {"id": 1130, "seek": 509464, "start": 5108.240000000001, "end": 5115.02, "text": " So anytime you see base loss we mean L1 loss, you could use MSE loss as well.", "tokens": [407, 13038, 291, 536, 3096, 4470, 321, 914, 441, 16, 4470, 11, 291, 727, 764, 376, 5879, 4470, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.13116455078125, "compression_ratio": 1.5411255411255411, "no_speech_prob": 8.664255801704712e-06}, {"id": 1131, "seek": 509464, "start": 5115.02, "end": 5120.280000000001, "text": " So let's create a VGG model, right, so just using the pre-trained model.", "tokens": [407, 718, 311, 1884, 257, 691, 27561, 2316, 11, 558, 11, 370, 445, 1228, 264, 659, 12, 17227, 2001, 2316, 13], "temperature": 0.0, "avg_logprob": -0.13116455078125, "compression_ratio": 1.5411255411255411, "no_speech_prob": 8.664255801704712e-06}, {"id": 1132, "seek": 512028, "start": 5120.28, "end": 5125.96, "text": " In VGG there's an attribute called dot features which contains the convolutional part of the", "tokens": [682, 691, 27561, 456, 311, 364, 19667, 1219, 5893, 4122, 597, 8306, 264, 45216, 304, 644, 295, 264], "temperature": 0.0, "avg_logprob": -0.1058423087710426, "compression_ratio": 1.7835497835497836, "no_speech_prob": 9.515760211797897e-06}, {"id": 1133, "seek": 512028, "start": 5125.96, "end": 5126.96, "text": " model.", "tokens": [2316, 13], "temperature": 0.0, "avg_logprob": -0.1058423087710426, "compression_ratio": 1.7835497835497836, "no_speech_prob": 9.515760211797897e-06}, {"id": 1134, "seek": 512028, "start": 5126.96, "end": 5132.4, "text": " So here's the convolutional part of the VGG model because we don't need the head because", "tokens": [407, 510, 311, 264, 45216, 304, 644, 295, 264, 691, 27561, 2316, 570, 321, 500, 380, 643, 264, 1378, 570], "temperature": 0.0, "avg_logprob": -0.1058423087710426, "compression_ratio": 1.7835497835497836, "no_speech_prob": 9.515760211797897e-06}, {"id": 1135, "seek": 512028, "start": 5132.4, "end": 5135.84, "text": " we only want the intermediate activations.", "tokens": [321, 787, 528, 264, 19376, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.1058423087710426, "compression_ratio": 1.7835497835497836, "no_speech_prob": 9.515760211797897e-06}, {"id": 1136, "seek": 512028, "start": 5135.84, "end": 5140.08, "text": " So then we'll chuck that on the GPU, we'll put it into eval mode because we're not training", "tokens": [407, 550, 321, 603, 20870, 300, 322, 264, 18407, 11, 321, 603, 829, 309, 666, 1073, 304, 4391, 570, 321, 434, 406, 3097], "temperature": 0.0, "avg_logprob": -0.1058423087710426, "compression_ratio": 1.7835497835497836, "no_speech_prob": 9.515760211797897e-06}, {"id": 1137, "seek": 512028, "start": 5140.08, "end": 5145.8, "text": " it, and we'll turn off requires grad because we don't want to update the weights of this", "tokens": [309, 11, 293, 321, 603, 1261, 766, 7029, 2771, 570, 321, 500, 380, 528, 281, 5623, 264, 17443, 295, 341], "temperature": 0.0, "avg_logprob": -0.1058423087710426, "compression_ratio": 1.7835497835497836, "no_speech_prob": 9.515760211797897e-06}, {"id": 1138, "seek": 514580, "start": 5145.8, "end": 5150.8, "text": " model, we're just using it for inference, right, for the loss.", "tokens": [2316, 11, 321, 434, 445, 1228, 309, 337, 38253, 11, 558, 11, 337, 264, 4470, 13], "temperature": 0.0, "avg_logprob": -0.10811142568235044, "compression_ratio": 1.7238493723849373, "no_speech_prob": 1.568767947901506e-05}, {"id": 1139, "seek": 514580, "start": 5150.8, "end": 5155.72, "text": " So then let's enumerate through all the children of that model and find all of the max pooling", "tokens": [407, 550, 718, 311, 465, 15583, 473, 807, 439, 264, 2227, 295, 300, 2316, 293, 915, 439, 295, 264, 11469, 7005, 278], "temperature": 0.0, "avg_logprob": -0.10811142568235044, "compression_ratio": 1.7238493723849373, "no_speech_prob": 1.568767947901506e-05}, {"id": 1140, "seek": 514580, "start": 5155.72, "end": 5161.92, "text": " layers because in the VGG model that's where the grid size changes and as you can see from", "tokens": [7914, 570, 294, 264, 691, 27561, 2316, 300, 311, 689, 264, 10748, 2744, 2962, 293, 382, 291, 393, 536, 490], "temperature": 0.0, "avg_logprob": -0.10811142568235044, "compression_ratio": 1.7238493723849373, "no_speech_prob": 1.568767947901506e-05}, {"id": 1141, "seek": 514580, "start": 5161.92, "end": 5168.18, "text": " this picture we kind of want to grab features from every time just before the grid size", "tokens": [341, 3036, 321, 733, 295, 528, 281, 4444, 4122, 490, 633, 565, 445, 949, 264, 10748, 2744], "temperature": 0.0, "avg_logprob": -0.10811142568235044, "compression_ratio": 1.7238493723849373, "no_speech_prob": 1.568767947901506e-05}, {"id": 1142, "seek": 514580, "start": 5168.18, "end": 5169.18, "text": " changes.", "tokens": [2962, 13], "temperature": 0.0, "avg_logprob": -0.10811142568235044, "compression_ratio": 1.7238493723849373, "no_speech_prob": 1.568767947901506e-05}, {"id": 1143, "seek": 514580, "start": 5169.18, "end": 5173.26, "text": " So we grab layer i minus 1, so that's the layer before it changes.", "tokens": [407, 321, 4444, 4583, 741, 3175, 502, 11, 370, 300, 311, 264, 4583, 949, 309, 2962, 13], "temperature": 0.0, "avg_logprob": -0.10811142568235044, "compression_ratio": 1.7238493723849373, "no_speech_prob": 1.568767947901506e-05}, {"id": 1144, "seek": 517326, "start": 5173.26, "end": 5181.16, "text": " So there's our list of layer numbers just before the max pooling layers.", "tokens": [407, 456, 311, 527, 1329, 295, 4583, 3547, 445, 949, 264, 11469, 7005, 278, 7914, 13], "temperature": 0.0, "avg_logprob": -0.1418279205880514, "compression_ratio": 1.5670103092783505, "no_speech_prob": 1.873617975434172e-06}, {"id": 1145, "seek": 517326, "start": 5181.16, "end": 5187.2, "text": " And so all of those are values, not surprisingly.", "tokens": [400, 370, 439, 295, 729, 366, 4190, 11, 406, 17600, 13], "temperature": 0.0, "avg_logprob": -0.1418279205880514, "compression_ratio": 1.5670103092783505, "no_speech_prob": 1.873617975434172e-06}, {"id": 1146, "seek": 517326, "start": 5187.2, "end": 5190.360000000001, "text": " So those are where we want to grab some features from.", "tokens": [407, 729, 366, 689, 321, 528, 281, 4444, 512, 4122, 490, 13], "temperature": 0.0, "avg_logprob": -0.1418279205880514, "compression_ratio": 1.5670103092783505, "no_speech_prob": 1.873617975434172e-06}, {"id": 1147, "seek": 517326, "start": 5190.360000000001, "end": 5194.360000000001, "text": " And so we put that in blocks, it's just a list of IDs.", "tokens": [400, 370, 321, 829, 300, 294, 8474, 11, 309, 311, 445, 257, 1329, 295, 48212, 13], "temperature": 0.0, "avg_logprob": -0.1418279205880514, "compression_ratio": 1.5670103092783505, "no_speech_prob": 1.873617975434172e-06}, {"id": 1148, "seek": 517326, "start": 5194.360000000001, "end": 5200.14, "text": " So here's our feature loss class which is going to implement this idea.", "tokens": [407, 510, 311, 527, 4111, 4470, 1508, 597, 307, 516, 281, 4445, 341, 1558, 13], "temperature": 0.0, "avg_logprob": -0.1418279205880514, "compression_ratio": 1.5670103092783505, "no_speech_prob": 1.873617975434172e-06}, {"id": 1149, "seek": 520014, "start": 5200.14, "end": 5206.92, "text": " So basically when we call the feature loss class we're going to pass it some pre-trained", "tokens": [407, 1936, 562, 321, 818, 264, 4111, 4470, 1508, 321, 434, 516, 281, 1320, 309, 512, 659, 12, 17227, 2001], "temperature": 0.0, "avg_logprob": -0.13357762788471422, "compression_ratio": 1.7425742574257426, "no_speech_prob": 3.611846523199347e-06}, {"id": 1150, "seek": 520014, "start": 5206.92, "end": 5207.92, "text": " model.", "tokens": [2316, 13], "temperature": 0.0, "avg_logprob": -0.13357762788471422, "compression_ratio": 1.7425742574257426, "no_speech_prob": 3.611846523199347e-06}, {"id": 1151, "seek": 520014, "start": 5207.92, "end": 5210.360000000001, "text": " And so that's going to be called mfit.", "tokens": [400, 370, 300, 311, 516, 281, 312, 1219, 275, 6845, 13], "temperature": 0.0, "avg_logprob": -0.13357762788471422, "compression_ratio": 1.7425742574257426, "no_speech_prob": 3.611846523199347e-06}, {"id": 1152, "seek": 520014, "start": 5210.360000000001, "end": 5215.04, "text": " That's the model which contains the features which we want to generate for, want our feature", "tokens": [663, 311, 264, 2316, 597, 8306, 264, 4122, 597, 321, 528, 281, 8460, 337, 11, 528, 527, 4111], "temperature": 0.0, "avg_logprob": -0.13357762788471422, "compression_ratio": 1.7425742574257426, "no_speech_prob": 3.611846523199347e-06}, {"id": 1153, "seek": 520014, "start": 5215.04, "end": 5216.160000000001, "text": " loss on.", "tokens": [4470, 322, 13], "temperature": 0.0, "avg_logprob": -0.13357762788471422, "compression_ratio": 1.7425742574257426, "no_speech_prob": 3.611846523199347e-06}, {"id": 1154, "seek": 520014, "start": 5216.160000000001, "end": 5224.96, "text": " So we can go ahead and grab all of the layers from that network that we want the features", "tokens": [407, 321, 393, 352, 2286, 293, 4444, 439, 295, 264, 7914, 490, 300, 3209, 300, 321, 528, 264, 4122], "temperature": 0.0, "avg_logprob": -0.13357762788471422, "compression_ratio": 1.7425742574257426, "no_speech_prob": 3.611846523199347e-06}, {"id": 1155, "seek": 520014, "start": 5224.96, "end": 5227.76, "text": " for to create the losses.", "tokens": [337, 281, 1884, 264, 15352, 13], "temperature": 0.0, "avg_logprob": -0.13357762788471422, "compression_ratio": 1.7425742574257426, "no_speech_prob": 3.611846523199347e-06}, {"id": 1156, "seek": 522776, "start": 5227.76, "end": 5232.18, "text": " So we're going to need to hook all of those outputs because remember that's how we grab", "tokens": [407, 321, 434, 516, 281, 643, 281, 6328, 439, 295, 729, 23930, 570, 1604, 300, 311, 577, 321, 4444], "temperature": 0.0, "avg_logprob": -0.10941131140596123, "compression_ratio": 1.6589861751152073, "no_speech_prob": 2.6425452688272344e-06}, {"id": 1157, "seek": 522776, "start": 5232.18, "end": 5235.76, "text": " intermediate layers in PyTorch is by hooking them.", "tokens": [19376, 7914, 294, 9953, 51, 284, 339, 307, 538, 1106, 5953, 552, 13], "temperature": 0.0, "avg_logprob": -0.10941131140596123, "compression_ratio": 1.6589861751152073, "no_speech_prob": 2.6425452688272344e-06}, {"id": 1158, "seek": 522776, "start": 5235.76, "end": 5242.16, "text": " So this is going to contain our hooked outputs.", "tokens": [407, 341, 307, 516, 281, 5304, 527, 20410, 23930, 13], "temperature": 0.0, "avg_logprob": -0.10941131140596123, "compression_ratio": 1.6589861751152073, "no_speech_prob": 2.6425452688272344e-06}, {"id": 1159, "seek": 522776, "start": 5242.16, "end": 5249.04, "text": " So now in the forward feature loss we're going to make features passing in the target, so", "tokens": [407, 586, 294, 264, 2128, 4111, 4470, 321, 434, 516, 281, 652, 4122, 8437, 294, 264, 3779, 11, 370], "temperature": 0.0, "avg_logprob": -0.10941131140596123, "compression_ratio": 1.6589861751152073, "no_speech_prob": 2.6425452688272344e-06}, {"id": 1160, "seek": 522776, "start": 5249.04, "end": 5253.76, "text": " this is our actual y, which is just going to call that VGG model and go through all", "tokens": [341, 307, 527, 3539, 288, 11, 597, 307, 445, 516, 281, 818, 300, 691, 27561, 2316, 293, 352, 807, 439], "temperature": 0.0, "avg_logprob": -0.10941131140596123, "compression_ratio": 1.6589861751152073, "no_speech_prob": 2.6425452688272344e-06}, {"id": 1161, "seek": 525376, "start": 5253.76, "end": 5259.320000000001, "text": " of the stored activations and just grab a copy of them.", "tokens": [295, 264, 12187, 2430, 763, 293, 445, 4444, 257, 5055, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.13056488264174687, "compression_ratio": 1.6229508196721312, "no_speech_prob": 2.99437738249253e-06}, {"id": 1162, "seek": 525376, "start": 5259.320000000001, "end": 5263.96, "text": " And so we're going to do that both for the target, call that outfit, and for the input,", "tokens": [400, 370, 321, 434, 516, 281, 360, 300, 1293, 337, 264, 3779, 11, 818, 300, 484, 6845, 11, 293, 337, 264, 4846, 11], "temperature": 0.0, "avg_logprob": -0.13056488264174687, "compression_ratio": 1.6229508196721312, "no_speech_prob": 2.99437738249253e-06}, {"id": 1163, "seek": 525376, "start": 5263.96, "end": 5268.52, "text": " so that's the output of a generator, in fit.", "tokens": [370, 300, 311, 264, 5598, 295, 257, 19265, 11, 294, 3318, 13], "temperature": 0.0, "avg_logprob": -0.13056488264174687, "compression_ratio": 1.6229508196721312, "no_speech_prob": 2.99437738249253e-06}, {"id": 1164, "seek": 525376, "start": 5268.52, "end": 5276.6, "text": " And so now let's calculate the L1 loss between the pixels because we still want the pixel", "tokens": [400, 370, 586, 718, 311, 8873, 264, 441, 16, 4470, 1296, 264, 18668, 570, 321, 920, 528, 264, 19261], "temperature": 0.0, "avg_logprob": -0.13056488264174687, "compression_ratio": 1.6229508196721312, "no_speech_prob": 2.99437738249253e-06}, {"id": 1165, "seek": 525376, "start": 5276.6, "end": 5278.14, "text": " loss a little bit.", "tokens": [4470, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.13056488264174687, "compression_ratio": 1.6229508196721312, "no_speech_prob": 2.99437738249253e-06}, {"id": 1166, "seek": 527814, "start": 5278.14, "end": 5288.0, "text": " And then let's also go through all of those layers' features and get the L1 loss on them.", "tokens": [400, 550, 718, 311, 611, 352, 807, 439, 295, 729, 7914, 6, 4122, 293, 483, 264, 441, 16, 4470, 322, 552, 13], "temperature": 0.0, "avg_logprob": -0.06352595885594686, "compression_ratio": 1.4899328859060403, "no_speech_prob": 2.684119408513652e-06}, {"id": 1167, "seek": 527814, "start": 5288.0, "end": 5294.64, "text": " So we're basically going through every one of these, end of each block, and grabbing", "tokens": [407, 321, 434, 1936, 516, 807, 633, 472, 295, 613, 11, 917, 295, 1184, 3461, 11, 293, 23771], "temperature": 0.0, "avg_logprob": -0.06352595885594686, "compression_ratio": 1.4899328859060403, "no_speech_prob": 2.684119408513652e-06}, {"id": 1168, "seek": 527814, "start": 5294.64, "end": 5299.360000000001, "text": " the activations and getting the L1 on each one.", "tokens": [264, 2430, 763, 293, 1242, 264, 441, 16, 322, 1184, 472, 13], "temperature": 0.0, "avg_logprob": -0.06352595885594686, "compression_ratio": 1.4899328859060403, "no_speech_prob": 2.684119408513652e-06}, {"id": 1169, "seek": 529936, "start": 5299.36, "end": 5308.36, "text": " So that's going to end up in this list called feature losses, which I then sum them all", "tokens": [407, 300, 311, 516, 281, 917, 493, 294, 341, 1329, 1219, 4111, 15352, 11, 597, 286, 550, 2408, 552, 439], "temperature": 0.0, "avg_logprob": -0.1142710203765541, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.905330231646076e-06}, {"id": 1170, "seek": 529936, "start": 5308.36, "end": 5309.36, "text": " up.", "tokens": [493, 13], "temperature": 0.0, "avg_logprob": -0.1142710203765541, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.905330231646076e-06}, {"id": 1171, "seek": 529936, "start": 5309.36, "end": 5313.16, "text": " And by the way, the reason I do it as a list is because we've got this nice little callback", "tokens": [400, 538, 264, 636, 11, 264, 1778, 286, 360, 309, 382, 257, 1329, 307, 570, 321, 600, 658, 341, 1481, 707, 818, 3207], "temperature": 0.0, "avg_logprob": -0.1142710203765541, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.905330231646076e-06}, {"id": 1172, "seek": 529936, "start": 5313.16, "end": 5318.24, "text": " that if you put them into a thing called.metrics in your loss function, it'll print out all", "tokens": [300, 498, 291, 829, 552, 666, 257, 551, 1219, 2411, 5537, 10716, 294, 428, 4470, 2445, 11, 309, 603, 4482, 484, 439], "temperature": 0.0, "avg_logprob": -0.1142710203765541, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.905330231646076e-06}, {"id": 1173, "seek": 529936, "start": 5318.24, "end": 5326.88, "text": " of the separate layer loss amounts for you, which is super handy.", "tokens": [295, 264, 4994, 4583, 4470, 11663, 337, 291, 11, 597, 307, 1687, 13239, 13], "temperature": 0.0, "avg_logprob": -0.1142710203765541, "compression_ratio": 1.5934579439252337, "no_speech_prob": 3.905330231646076e-06}, {"id": 1174, "seek": 532688, "start": 5326.88, "end": 5331.08, "text": " So that's it, that's our perceptual loss or feature loss class.", "tokens": [407, 300, 311, 309, 11, 300, 311, 527, 43276, 901, 4470, 420, 4111, 4470, 1508, 13], "temperature": 0.0, "avg_logprob": -0.1103152114979542, "compression_ratio": 1.6769759450171822, "no_speech_prob": 9.515772944723722e-06}, {"id": 1175, "seek": 532688, "start": 5331.08, "end": 5335.06, "text": " And so now we can just go ahead and train a unit in the usual way with our data and", "tokens": [400, 370, 586, 321, 393, 445, 352, 2286, 293, 3847, 257, 4985, 294, 264, 7713, 636, 365, 527, 1412, 293], "temperature": 0.0, "avg_logprob": -0.1103152114979542, "compression_ratio": 1.6769759450171822, "no_speech_prob": 9.515772944723722e-06}, {"id": 1176, "seek": 532688, "start": 5335.06, "end": 5340.68, "text": " our pre-trained architecture, which is a ResNet-34, passing in our loss function, which is using", "tokens": [527, 659, 12, 17227, 2001, 9482, 11, 597, 307, 257, 5015, 31890, 12, 12249, 11, 8437, 294, 527, 4470, 2445, 11, 597, 307, 1228], "temperature": 0.0, "avg_logprob": -0.1103152114979542, "compression_ratio": 1.6769759450171822, "no_speech_prob": 9.515772944723722e-06}, {"id": 1177, "seek": 532688, "start": 5340.68, "end": 5342.96, "text": " our pre-trained VGG model.", "tokens": [527, 659, 12, 17227, 2001, 691, 27561, 2316, 13], "temperature": 0.0, "avg_logprob": -0.1103152114979542, "compression_ratio": 1.6769759450171822, "no_speech_prob": 9.515772944723722e-06}, {"id": 1178, "seek": 532688, "start": 5342.96, "end": 5346.92, "text": " And this is that callback I mentioned, lossmetrics, which is going to print out all the different", "tokens": [400, 341, 307, 300, 818, 3207, 286, 2835, 11, 4470, 5537, 10716, 11, 597, 307, 516, 281, 4482, 484, 439, 264, 819], "temperature": 0.0, "avg_logprob": -0.1103152114979542, "compression_ratio": 1.6769759450171822, "no_speech_prob": 9.515772944723722e-06}, {"id": 1179, "seek": 532688, "start": 5346.92, "end": 5349.78, "text": " layers' losses for us.", "tokens": [7914, 6, 15352, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.1103152114979542, "compression_ratio": 1.6769759450171822, "no_speech_prob": 9.515772944723722e-06}, {"id": 1180, "seek": 532688, "start": 5349.78, "end": 5352.76, "text": " These are two things that we'll learn about in part two of the course, but you should", "tokens": [1981, 366, 732, 721, 300, 321, 603, 1466, 466, 294, 644, 732, 295, 264, 1164, 11, 457, 291, 820], "temperature": 0.0, "avg_logprob": -0.1103152114979542, "compression_ratio": 1.6769759450171822, "no_speech_prob": 9.515772944723722e-06}, {"id": 1181, "seek": 532688, "start": 5352.76, "end": 5353.76, "text": " use them.", "tokens": [764, 552, 13], "temperature": 0.0, "avg_logprob": -0.1103152114979542, "compression_ratio": 1.6769759450171822, "no_speech_prob": 9.515772944723722e-06}, {"id": 1182, "seek": 535376, "start": 5353.76, "end": 5359.56, "text": " LR find, I just created a little function called do fit that does fit one cycle and", "tokens": [441, 49, 915, 11, 286, 445, 2942, 257, 707, 2445, 1219, 360, 3318, 300, 775, 3318, 472, 6586, 293], "temperature": 0.0, "avg_logprob": -0.1172915049961635, "compression_ratio": 1.6198347107438016, "no_speech_prob": 1.028856058837846e-05}, {"id": 1183, "seek": 535376, "start": 5359.56, "end": 5363.08, "text": " then saves the model and then shows the results.", "tokens": [550, 19155, 264, 2316, 293, 550, 3110, 264, 3542, 13], "temperature": 0.0, "avg_logprob": -0.1172915049961635, "compression_ratio": 1.6198347107438016, "no_speech_prob": 1.028856058837846e-05}, {"id": 1184, "seek": 535376, "start": 5363.08, "end": 5369.280000000001, "text": " So as per usual, because we're using a pre-trained network in our unit, we start with frozen", "tokens": [407, 382, 680, 7713, 11, 570, 321, 434, 1228, 257, 659, 12, 17227, 2001, 3209, 294, 527, 4985, 11, 321, 722, 365, 12496], "temperature": 0.0, "avg_logprob": -0.1172915049961635, "compression_ratio": 1.6198347107438016, "no_speech_prob": 1.028856058837846e-05}, {"id": 1185, "seek": 535376, "start": 5369.280000000001, "end": 5374.76, "text": " layers for the downsampling path, train for a while, and as you can see, we get not only", "tokens": [7914, 337, 264, 760, 19988, 11970, 3100, 11, 3847, 337, 257, 1339, 11, 293, 382, 291, 393, 536, 11, 321, 483, 406, 787], "temperature": 0.0, "avg_logprob": -0.1172915049961635, "compression_ratio": 1.6198347107438016, "no_speech_prob": 1.028856058837846e-05}, {"id": 1186, "seek": 535376, "start": 5374.76, "end": 5380.04, "text": " the loss, but also the pixel loss and the loss at each of our feature layers.", "tokens": [264, 4470, 11, 457, 611, 264, 19261, 4470, 293, 264, 4470, 412, 1184, 295, 527, 4111, 7914, 13], "temperature": 0.0, "avg_logprob": -0.1172915049961635, "compression_ratio": 1.6198347107438016, "no_speech_prob": 1.028856058837846e-05}, {"id": 1187, "seek": 538004, "start": 5380.04, "end": 5385.6, "text": " And then also something we'll learn about in part two called gram loss, which I don't", "tokens": [400, 550, 611, 746, 321, 603, 1466, 466, 294, 644, 732, 1219, 21353, 4470, 11, 597, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.13237265673550694, "compression_ratio": 1.5443548387096775, "no_speech_prob": 2.2252418148127617e-06}, {"id": 1188, "seek": 538004, "start": 5385.6, "end": 5390.72, "text": " think anybody's used for super res before as far as I know, but as you'll see, it turns", "tokens": [519, 4472, 311, 1143, 337, 1687, 725, 949, 382, 1400, 382, 286, 458, 11, 457, 382, 291, 603, 536, 11, 309, 4523], "temperature": 0.0, "avg_logprob": -0.13237265673550694, "compression_ratio": 1.5443548387096775, "no_speech_prob": 2.2252418148127617e-06}, {"id": 1189, "seek": 538004, "start": 5390.72, "end": 5392.2, "text": " out great.", "tokens": [484, 869, 13], "temperature": 0.0, "avg_logprob": -0.13237265673550694, "compression_ratio": 1.5443548387096775, "no_speech_prob": 2.2252418148127617e-06}, {"id": 1190, "seek": 538004, "start": 5392.2, "end": 5397.92, "text": " So that's eight minutes, so much faster than a GAN, and already, as you can see, this is", "tokens": [407, 300, 311, 3180, 2077, 11, 370, 709, 4663, 813, 257, 460, 1770, 11, 293, 1217, 11, 382, 291, 393, 536, 11, 341, 307], "temperature": 0.0, "avg_logprob": -0.13237265673550694, "compression_ratio": 1.5443548387096775, "no_speech_prob": 2.2252418148127617e-06}, {"id": 1191, "seek": 538004, "start": 5397.92, "end": 5401.54, "text": " our output, model output, pretty good.", "tokens": [527, 5598, 11, 2316, 5598, 11, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.13237265673550694, "compression_ratio": 1.5443548387096775, "no_speech_prob": 2.2252418148127617e-06}, {"id": 1192, "seek": 538004, "start": 5401.54, "end": 5407.76, "text": " So then we unfreeze and train some more, and it's a little bit better.", "tokens": [407, 550, 321, 3971, 701, 1381, 293, 3847, 512, 544, 11, 293, 309, 311, 257, 707, 857, 1101, 13], "temperature": 0.0, "avg_logprob": -0.13237265673550694, "compression_ratio": 1.5443548387096775, "no_speech_prob": 2.2252418148127617e-06}, {"id": 1193, "seek": 540776, "start": 5407.76, "end": 5412.400000000001, "text": " And then let's switch up to double the size, and so we need to also halve the batch size", "tokens": [400, 550, 718, 311, 3679, 493, 281, 3834, 264, 2744, 11, 293, 370, 321, 643, 281, 611, 7523, 303, 264, 15245, 2744], "temperature": 0.0, "avg_logprob": -0.10386686489499848, "compression_ratio": 1.6816326530612244, "no_speech_prob": 1.7603219930606429e-06}, {"id": 1194, "seek": 540776, "start": 5412.400000000001, "end": 5418.04, "text": " to avoid running out of GPU memory, and freeze again and train some more, so it's now taking", "tokens": [281, 5042, 2614, 484, 295, 18407, 4675, 11, 293, 15959, 797, 293, 3847, 512, 544, 11, 370, 309, 311, 586, 1940], "temperature": 0.0, "avg_logprob": -0.10386686489499848, "compression_ratio": 1.6816326530612244, "no_speech_prob": 1.7603219930606429e-06}, {"id": 1195, "seek": 540776, "start": 5418.04, "end": 5424.34, "text": " half an hour, even better, and then unfreeze and train some more.", "tokens": [1922, 364, 1773, 11, 754, 1101, 11, 293, 550, 3971, 701, 1381, 293, 3847, 512, 544, 13], "temperature": 0.0, "avg_logprob": -0.10386686489499848, "compression_ratio": 1.6816326530612244, "no_speech_prob": 1.7603219930606429e-06}, {"id": 1196, "seek": 540776, "start": 5424.34, "end": 5431.96, "text": " So all in all, we've done about an hour and 20 minutes of training, and look at that!", "tokens": [407, 439, 294, 439, 11, 321, 600, 1096, 466, 364, 1773, 293, 945, 2077, 295, 3097, 11, 293, 574, 412, 300, 0], "temperature": 0.0, "avg_logprob": -0.10386686489499848, "compression_ratio": 1.6816326530612244, "no_speech_prob": 1.7603219930606429e-06}, {"id": 1197, "seek": 540776, "start": 5431.96, "end": 5433.96, "text": " It's done it.", "tokens": [467, 311, 1096, 309, 13], "temperature": 0.0, "avg_logprob": -0.10386686489499848, "compression_ratio": 1.6816326530612244, "no_speech_prob": 1.7603219930606429e-06}, {"id": 1198, "seek": 540776, "start": 5433.96, "end": 5436.96, "text": " It knows that eyes are important, so it's really made an effort.", "tokens": [467, 3255, 300, 2575, 366, 1021, 11, 370, 309, 311, 534, 1027, 364, 4630, 13], "temperature": 0.0, "avg_logprob": -0.10386686489499848, "compression_ratio": 1.6816326530612244, "no_speech_prob": 1.7603219930606429e-06}, {"id": 1199, "seek": 543696, "start": 5436.96, "end": 5439.8, "text": " It knows that fur is important, so it's really made an effort.", "tokens": [467, 3255, 300, 2687, 307, 1021, 11, 370, 309, 311, 534, 1027, 364, 4630, 13], "temperature": 0.0, "avg_logprob": -0.12719097652950803, "compression_ratio": 1.6754716981132076, "no_speech_prob": 9.817591489991173e-06}, {"id": 1200, "seek": 543696, "start": 5439.8, "end": 5446.68, "text": " So it started with something with like JPEG artifacts around the ears, and all this mess,", "tokens": [407, 309, 1409, 365, 746, 365, 411, 508, 5208, 38, 24617, 926, 264, 8798, 11, 293, 439, 341, 2082, 11], "temperature": 0.0, "avg_logprob": -0.12719097652950803, "compression_ratio": 1.6754716981132076, "no_speech_prob": 9.817591489991173e-06}, {"id": 1201, "seek": 543696, "start": 5446.68, "end": 5450.96, "text": " and like eyes that are just kind of vague light blue things, and it just, it really", "tokens": [293, 411, 2575, 300, 366, 445, 733, 295, 24247, 1442, 3344, 721, 11, 293, 309, 445, 11, 309, 534], "temperature": 0.0, "avg_logprob": -0.12719097652950803, "compression_ratio": 1.6754716981132076, "no_speech_prob": 9.817591489991173e-06}, {"id": 1202, "seek": 543696, "start": 5450.96, "end": 5453.92, "text": " created a lot of texture.", "tokens": [2942, 257, 688, 295, 8091, 13], "temperature": 0.0, "avg_logprob": -0.12719097652950803, "compression_ratio": 1.6754716981132076, "no_speech_prob": 9.817591489991173e-06}, {"id": 1203, "seek": 543696, "start": 5453.92, "end": 5459.52, "text": " This cat is clearly kind of like looking over the top of one of those little chlorine frames", "tokens": [639, 3857, 307, 4448, 733, 295, 411, 1237, 670, 264, 1192, 295, 472, 295, 729, 707, 39888, 12083], "temperature": 0.0, "avg_logprob": -0.12719097652950803, "compression_ratio": 1.6754716981132076, "no_speech_prob": 9.817591489991173e-06}, {"id": 1204, "seek": 543696, "start": 5459.52, "end": 5464.4800000000005, "text": " covered in fuzz, so it actually recognized that this thing is probably kind of a carpety", "tokens": [5343, 294, 283, 16740, 11, 370, 309, 767, 9823, 300, 341, 551, 307, 1391, 733, 295, 257, 18119, 88], "temperature": 0.0, "avg_logprob": -0.12719097652950803, "compression_ratio": 1.6754716981132076, "no_speech_prob": 9.817591489991173e-06}, {"id": 1205, "seek": 546448, "start": 5464.48, "end": 5472.08, "text": " material that's created a carpety material for us, so I mean that's just remarkable.", "tokens": [2527, 300, 311, 2942, 257, 18119, 88, 2527, 337, 505, 11, 370, 286, 914, 300, 311, 445, 12802, 13], "temperature": 0.0, "avg_logprob": -0.17193831895527087, "compression_ratio": 1.5106382978723405, "no_speech_prob": 8.80083280208055e-06}, {"id": 1206, "seek": 546448, "start": 5472.08, "end": 5483.44, "text": " So talking of remarkable, we can now, so I've never seen outputs like this before without", "tokens": [407, 1417, 295, 12802, 11, 321, 393, 586, 11, 370, 286, 600, 1128, 1612, 23930, 411, 341, 949, 1553], "temperature": 0.0, "avg_logprob": -0.17193831895527087, "compression_ratio": 1.5106382978723405, "no_speech_prob": 8.80083280208055e-06}, {"id": 1207, "seek": 546448, "start": 5483.44, "end": 5488.16, "text": " again, so I was just so excited when we were able to generate this, and so quickly, one", "tokens": [797, 11, 370, 286, 390, 445, 370, 2919, 562, 321, 645, 1075, 281, 8460, 341, 11, 293, 370, 2661, 11, 472], "temperature": 0.0, "avg_logprob": -0.17193831895527087, "compression_ratio": 1.5106382978723405, "no_speech_prob": 8.80083280208055e-06}, {"id": 1208, "seek": 546448, "start": 5488.16, "end": 5491.24, "text": " GPU, hour and a half.", "tokens": [18407, 11, 1773, 293, 257, 1922, 13], "temperature": 0.0, "avg_logprob": -0.17193831895527087, "compression_ratio": 1.5106382978723405, "no_speech_prob": 8.80083280208055e-06}, {"id": 1209, "seek": 549124, "start": 5491.24, "end": 5496.719999999999, "text": " So like if you create your own crapification functions and train this model, you'll build", "tokens": [407, 411, 498, 291, 1884, 428, 1065, 12426, 3774, 6828, 293, 3847, 341, 2316, 11, 291, 603, 1322], "temperature": 0.0, "avg_logprob": -0.12810778617858887, "compression_ratio": 1.5932835820895523, "no_speech_prob": 1.4284823919297196e-05}, {"id": 1210, "seek": 549124, "start": 5496.719999999999, "end": 5501.92, "text": " stuff that nobody's built before, because like nobody else that I know of is doing it", "tokens": [1507, 300, 5079, 311, 3094, 949, 11, 570, 411, 5079, 1646, 300, 286, 458, 295, 307, 884, 309], "temperature": 0.0, "avg_logprob": -0.12810778617858887, "compression_ratio": 1.5932835820895523, "no_speech_prob": 1.4284823919297196e-05}, {"id": 1211, "seek": 549124, "start": 5501.92, "end": 5504.679999999999, "text": " this way, so there are huge opportunities I think.", "tokens": [341, 636, 11, 370, 456, 366, 2603, 4786, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.12810778617858887, "compression_ratio": 1.5932835820895523, "no_speech_prob": 1.4284823919297196e-05}, {"id": 1212, "seek": 549124, "start": 5504.679999999999, "end": 5505.679999999999, "text": " So check this out.", "tokens": [407, 1520, 341, 484, 13], "temperature": 0.0, "avg_logprob": -0.12810778617858887, "compression_ratio": 1.5932835820895523, "no_speech_prob": 1.4284823919297196e-05}, {"id": 1213, "seek": 549124, "start": 5505.679999999999, "end": 5513.44, "text": " What we can now do is we can now, instead of starting with our low res, I actually stored", "tokens": [708, 321, 393, 586, 360, 307, 321, 393, 586, 11, 2602, 295, 2891, 365, 527, 2295, 725, 11, 286, 767, 12187], "temperature": 0.0, "avg_logprob": -0.12810778617858887, "compression_ratio": 1.5932835820895523, "no_speech_prob": 1.4284823919297196e-05}, {"id": 1214, "seek": 549124, "start": 5513.44, "end": 5519.28, "text": " another set at size 256 which are called medium res, so let's see what happens if we upsize", "tokens": [1071, 992, 412, 2744, 38882, 597, 366, 1219, 6399, 725, 11, 370, 718, 311, 536, 437, 2314, 498, 321, 15497, 1125], "temperature": 0.0, "avg_logprob": -0.12810778617858887, "compression_ratio": 1.5932835820895523, "no_speech_prob": 1.4284823919297196e-05}, {"id": 1215, "seek": 551928, "start": 5519.28, "end": 5521.58, "text": " the medium res.", "tokens": [264, 6399, 725, 13], "temperature": 0.0, "avg_logprob": -0.12938999548190977, "compression_ratio": 1.6149732620320856, "no_speech_prob": 6.438907348638168e-06}, {"id": 1216, "seek": 551928, "start": 5521.58, "end": 5533.12, "text": " So we're going to grab our medium res data, and here is our medium res stored photo, and", "tokens": [407, 321, 434, 516, 281, 4444, 527, 6399, 725, 1412, 11, 293, 510, 307, 527, 6399, 725, 12187, 5052, 11, 293], "temperature": 0.0, "avg_logprob": -0.12938999548190977, "compression_ratio": 1.6149732620320856, "no_speech_prob": 6.438907348638168e-06}, {"id": 1217, "seek": 551928, "start": 5533.12, "end": 5534.88, "text": " so can we improve this?", "tokens": [370, 393, 321, 3470, 341, 30], "temperature": 0.0, "avg_logprob": -0.12938999548190977, "compression_ratio": 1.6149732620320856, "no_speech_prob": 6.438907348638168e-06}, {"id": 1218, "seek": 551928, "start": 5534.88, "end": 5540.04, "text": " So you can see there's still a lot of room for improvement, like you see the lashes here", "tokens": [407, 291, 393, 536, 456, 311, 920, 257, 688, 295, 1808, 337, 10444, 11, 411, 291, 536, 264, 25552, 510], "temperature": 0.0, "avg_logprob": -0.12938999548190977, "compression_ratio": 1.6149732620320856, "no_speech_prob": 6.438907348638168e-06}, {"id": 1219, "seek": 551928, "start": 5540.04, "end": 5544.92, "text": " are very pixelated, the place where there should be hair here is just kind of fuzzy,", "tokens": [366, 588, 19261, 770, 11, 264, 1081, 689, 456, 820, 312, 2578, 510, 307, 445, 733, 295, 34710, 11], "temperature": 0.0, "avg_logprob": -0.12938999548190977, "compression_ratio": 1.6149732620320856, "no_speech_prob": 6.438907348638168e-06}, {"id": 1220, "seek": 554492, "start": 5544.92, "end": 5552.38, "text": " so watch this area as I hit down on my keyboard, look at that, it's done it, it's taken a medium", "tokens": [370, 1159, 341, 1859, 382, 286, 2045, 760, 322, 452, 10186, 11, 574, 412, 300, 11, 309, 311, 1096, 309, 11, 309, 311, 2726, 257, 6399], "temperature": 0.0, "avg_logprob": -0.15516435268313386, "compression_ratio": 1.6162162162162161, "no_speech_prob": 4.860326953348704e-06}, {"id": 1221, "seek": 554492, "start": 5552.38, "end": 5559.84, "text": " res image and it's made a totally clear thing here, the furs reappeared, look at the eyeball,", "tokens": [725, 3256, 293, 309, 311, 1027, 257, 3879, 1850, 551, 510, 11, 264, 283, 2156, 35638, 68, 1642, 11, 574, 412, 264, 38868, 11], "temperature": 0.0, "avg_logprob": -0.15516435268313386, "compression_ratio": 1.6162162162162161, "no_speech_prob": 4.860326953348704e-06}, {"id": 1222, "seek": 554492, "start": 5559.84, "end": 5568.12, "text": " let's go back, the eyeball here is just kind of a general blue thing, here it's added all", "tokens": [718, 311, 352, 646, 11, 264, 38868, 510, 307, 445, 733, 295, 257, 2674, 3344, 551, 11, 510, 309, 311, 3869, 439], "temperature": 0.0, "avg_logprob": -0.15516435268313386, "compression_ratio": 1.6162162162162161, "no_speech_prob": 4.860326953348704e-06}, {"id": 1223, "seek": 554492, "start": 5568.12, "end": 5569.82, "text": " the right texture.", "tokens": [264, 558, 8091, 13], "temperature": 0.0, "avg_logprob": -0.15516435268313386, "compression_ratio": 1.6162162162162161, "no_speech_prob": 4.860326953348704e-06}, {"id": 1224, "seek": 556982, "start": 5569.82, "end": 5578.28, "text": " So I just think this is super exciting, here's a model I trained in an hour and a half using", "tokens": [407, 286, 445, 519, 341, 307, 1687, 4670, 11, 510, 311, 257, 2316, 286, 8895, 294, 364, 1773, 293, 257, 1922, 1228], "temperature": 0.0, "avg_logprob": -0.13988206651475693, "compression_ratio": 1.5740740740740742, "no_speech_prob": 5.014582711737603e-06}, {"id": 1225, "seek": 556982, "start": 5578.28, "end": 5583.719999999999, "text": " standard stuff that you've all learnt about, a unit, a pre-trained model, feature loss", "tokens": [3832, 1507, 300, 291, 600, 439, 18991, 466, 11, 257, 4985, 11, 257, 659, 12, 17227, 2001, 2316, 11, 4111, 4470], "temperature": 0.0, "avg_logprob": -0.13988206651475693, "compression_ratio": 1.5740740740740742, "no_speech_prob": 5.014582711737603e-06}, {"id": 1226, "seek": 556982, "start": 5583.719999999999, "end": 5593.599999999999, "text": " function, and we've got something which can turn that into that, or this absolute mess", "tokens": [2445, 11, 293, 321, 600, 658, 746, 597, 393, 1261, 300, 666, 300, 11, 420, 341, 8236, 2082], "temperature": 0.0, "avg_logprob": -0.13988206651475693, "compression_ratio": 1.5740740740740742, "no_speech_prob": 5.014582711737603e-06}, {"id": 1227, "seek": 556982, "start": 5593.599999999999, "end": 5594.7, "text": " into this.", "tokens": [666, 341, 13], "temperature": 0.0, "avg_logprob": -0.13988206651475693, "compression_ratio": 1.5740740740740742, "no_speech_prob": 5.014582711737603e-06}, {"id": 1228, "seek": 556982, "start": 5594.7, "end": 5599.679999999999, "text": " And it's really exciting to think what could you do with that.", "tokens": [400, 309, 311, 534, 4670, 281, 519, 437, 727, 291, 360, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.13988206651475693, "compression_ratio": 1.5740740740740742, "no_speech_prob": 5.014582711737603e-06}, {"id": 1229, "seek": 559968, "start": 5599.68, "end": 5610.400000000001, "text": " So one of the inspirations here has been a guy called Jason Antich, and Jason was a student", "tokens": [407, 472, 295, 264, 17432, 763, 510, 575, 668, 257, 2146, 1219, 11181, 5130, 480, 11, 293, 11181, 390, 257, 3107], "temperature": 0.0, "avg_logprob": -0.12112456730433872, "compression_ratio": 1.5197740112994351, "no_speech_prob": 2.505522752471734e-05}, {"id": 1230, "seek": 559968, "start": 5610.400000000001, "end": 5623.08, "text": " in the course last year, and what he did, very sensibly, was decide to focus, basically", "tokens": [294, 264, 1164, 1036, 1064, 11, 293, 437, 415, 630, 11, 588, 2923, 3545, 11, 390, 4536, 281, 1879, 11, 1936], "temperature": 0.0, "avg_logprob": -0.12112456730433872, "compression_ratio": 1.5197740112994351, "no_speech_prob": 2.505522752471734e-05}, {"id": 1231, "seek": 559968, "start": 5623.08, "end": 5626.68, "text": " nearly quit his job and work four days a week, or really six days a week on studying deep", "tokens": [6217, 10366, 702, 1691, 293, 589, 1451, 1708, 257, 1243, 11, 420, 534, 2309, 1708, 257, 1243, 322, 7601, 2452], "temperature": 0.0, "avg_logprob": -0.12112456730433872, "compression_ratio": 1.5197740112994351, "no_speech_prob": 2.505522752471734e-05}, {"id": 1232, "seek": 562668, "start": 5626.68, "end": 5631.88, "text": " learning, and as you should do, he created a kind of capstone project, and his project", "tokens": [2539, 11, 293, 382, 291, 820, 360, 11, 415, 2942, 257, 733, 295, 1410, 11243, 1716, 11, 293, 702, 1716], "temperature": 0.0, "avg_logprob": -0.12376874521237995, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.862611861724872e-05}, {"id": 1233, "seek": 562668, "start": 5631.88, "end": 5637.360000000001, "text": " was to combine GANs and feature losses together.", "tokens": [390, 281, 10432, 460, 1770, 82, 293, 4111, 15352, 1214, 13], "temperature": 0.0, "avg_logprob": -0.12376874521237995, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.862611861724872e-05}, {"id": 1234, "seek": 562668, "start": 5637.360000000001, "end": 5645.240000000001, "text": " And his crappification approach was to take colour pictures and make them black and white.", "tokens": [400, 702, 2094, 427, 3774, 3109, 390, 281, 747, 8267, 5242, 293, 652, 552, 2211, 293, 2418, 13], "temperature": 0.0, "avg_logprob": -0.12376874521237995, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.862611861724872e-05}, {"id": 1235, "seek": 562668, "start": 5645.240000000001, "end": 5648.740000000001, "text": " So he took the whole of ImageNet, created a black and white ImageNet, and then trained", "tokens": [407, 415, 1890, 264, 1379, 295, 29903, 31890, 11, 2942, 257, 2211, 293, 2418, 29903, 31890, 11, 293, 550, 8895], "temperature": 0.0, "avg_logprob": -0.12376874521237995, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.862611861724872e-05}, {"id": 1236, "seek": 562668, "start": 5648.740000000001, "end": 5654.96, "text": " a model to recolourise it, and he's put this up as De-Oldify, and now he's got these actual", "tokens": [257, 2316, 281, 850, 401, 396, 908, 309, 11, 293, 415, 311, 829, 341, 493, 382, 1346, 12, 49032, 2505, 11, 293, 586, 415, 311, 658, 613, 3539], "temperature": 0.0, "avg_logprob": -0.12376874521237995, "compression_ratio": 1.6945606694560669, "no_speech_prob": 1.862611861724872e-05}, {"id": 1237, "seek": 565496, "start": 5654.96, "end": 5660.68, "text": " old photos from the 19th century that he's turning into colour.", "tokens": [1331, 5787, 490, 264, 1294, 392, 4901, 300, 415, 311, 6246, 666, 8267, 13], "temperature": 0.0, "avg_logprob": -0.143361006464277, "compression_ratio": 1.6395348837209303, "no_speech_prob": 1.9828943550237454e-05}, {"id": 1238, "seek": 565496, "start": 5660.68, "end": 5664.76, "text": " And what this is doing is incredible.", "tokens": [400, 437, 341, 307, 884, 307, 4651, 13], "temperature": 0.0, "avg_logprob": -0.143361006464277, "compression_ratio": 1.6395348837209303, "no_speech_prob": 1.9828943550237454e-05}, {"id": 1239, "seek": 565496, "start": 5664.76, "end": 5665.76, "text": " Look at this.", "tokens": [2053, 412, 341, 13], "temperature": 0.0, "avg_logprob": -0.143361006464277, "compression_ratio": 1.6395348837209303, "no_speech_prob": 1.9828943550237454e-05}, {"id": 1240, "seek": 565496, "start": 5665.76, "end": 5669.16, "text": " The model thought, oh, that's probably some kind of copper kettle, so I'll make it copper", "tokens": [440, 2316, 1194, 11, 1954, 11, 300, 311, 1391, 512, 733, 295, 15007, 39088, 11, 370, 286, 603, 652, 309, 15007], "temperature": 0.0, "avg_logprob": -0.143361006464277, "compression_ratio": 1.6395348837209303, "no_speech_prob": 1.9828943550237454e-05}, {"id": 1241, "seek": 565496, "start": 5669.16, "end": 5670.16, "text": " coloured.", "tokens": [42042, 13], "temperature": 0.0, "avg_logprob": -0.143361006464277, "compression_ratio": 1.6395348837209303, "no_speech_prob": 1.9828943550237454e-05}, {"id": 1242, "seek": 565496, "start": 5670.16, "end": 5674.88, "text": " And oh, these pictures are on the wall, they're probably different colours to the wall, and", "tokens": [400, 1954, 11, 613, 5242, 366, 322, 264, 2929, 11, 436, 434, 1391, 819, 16484, 281, 264, 2929, 11, 293], "temperature": 0.0, "avg_logprob": -0.143361006464277, "compression_ratio": 1.6395348837209303, "no_speech_prob": 1.9828943550237454e-05}, {"id": 1243, "seek": 565496, "start": 5674.88, "end": 5678.24, "text": " maybe that looks a bit like a mirror.", "tokens": [1310, 300, 1542, 257, 857, 411, 257, 8013, 13], "temperature": 0.0, "avg_logprob": -0.143361006464277, "compression_ratio": 1.6395348837209303, "no_speech_prob": 1.9828943550237454e-05}, {"id": 1244, "seek": 565496, "start": 5678.24, "end": 5682.76, "text": " Maybe it would be reflecting stuff outside.", "tokens": [2704, 309, 576, 312, 23543, 1507, 2380, 13], "temperature": 0.0, "avg_logprob": -0.143361006464277, "compression_ratio": 1.6395348837209303, "no_speech_prob": 1.9828943550237454e-05}, {"id": 1245, "seek": 565496, "start": 5682.76, "end": 5684.44, "text": " These things might be vegetables.", "tokens": [1981, 721, 1062, 312, 9320, 13], "temperature": 0.0, "avg_logprob": -0.143361006464277, "compression_ratio": 1.6395348837209303, "no_speech_prob": 1.9828943550237454e-05}, {"id": 1246, "seek": 568444, "start": 5684.44, "end": 5685.799999999999, "text": " Vegetables are often red.", "tokens": [28092, 2965, 366, 2049, 2182, 13], "temperature": 0.0, "avg_logprob": -0.1643562009257655, "compression_ratio": 1.6218181818181818, "no_speech_prob": 3.702320100273937e-05}, {"id": 1247, "seek": 568444, "start": 5685.799999999999, "end": 5688.44, "text": " Let's make them red.", "tokens": [961, 311, 652, 552, 2182, 13], "temperature": 0.0, "avg_logprob": -0.1643562009257655, "compression_ratio": 1.6218181818181818, "no_speech_prob": 3.702320100273937e-05}, {"id": 1248, "seek": 568444, "start": 5688.44, "end": 5691.599999999999, "text": " It's extraordinary what it's done.", "tokens": [467, 311, 10581, 437, 309, 311, 1096, 13], "temperature": 0.0, "avg_logprob": -0.1643562009257655, "compression_ratio": 1.6218181818181818, "no_speech_prob": 3.702320100273937e-05}, {"id": 1249, "seek": 568444, "start": 5691.599999999999, "end": 5693.759999999999, "text": " And you could totally do this too.", "tokens": [400, 291, 727, 3879, 360, 341, 886, 13], "temperature": 0.0, "avg_logprob": -0.1643562009257655, "compression_ratio": 1.6218181818181818, "no_speech_prob": 3.702320100273937e-05}, {"id": 1250, "seek": 568444, "start": 5693.759999999999, "end": 5698.679999999999, "text": " You can take our feature loss and our GAN loss and combine them.", "tokens": [509, 393, 747, 527, 4111, 4470, 293, 527, 460, 1770, 4470, 293, 10432, 552, 13], "temperature": 0.0, "avg_logprob": -0.1643562009257655, "compression_ratio": 1.6218181818181818, "no_speech_prob": 3.702320100273937e-05}, {"id": 1251, "seek": 568444, "start": 5698.679999999999, "end": 5704.12, "text": " So I'm very grateful to Jason because he's helped us build this lesson, and it's been", "tokens": [407, 286, 478, 588, 7941, 281, 11181, 570, 415, 311, 4254, 505, 1322, 341, 6898, 11, 293, 309, 311, 668], "temperature": 0.0, "avg_logprob": -0.1643562009257655, "compression_ratio": 1.6218181818181818, "no_speech_prob": 3.702320100273937e-05}, {"id": 1252, "seek": 568444, "start": 5704.12, "end": 5708.679999999999, "text": " really nice because we've been able to help him too, because he hadn't realised that he", "tokens": [534, 1481, 570, 321, 600, 668, 1075, 281, 854, 796, 886, 11, 570, 415, 8782, 380, 21337, 300, 415], "temperature": 0.0, "avg_logprob": -0.1643562009257655, "compression_ratio": 1.6218181818181818, "no_speech_prob": 3.702320100273937e-05}, {"id": 1253, "seek": 568444, "start": 5708.679999999999, "end": 5712.719999999999, "text": " can use all this pre-training and stuff, and so hopefully you'll see De-Oldify in the next", "tokens": [393, 764, 439, 341, 659, 12, 17227, 1760, 293, 1507, 11, 293, 370, 4696, 291, 603, 536, 1346, 12, 49032, 2505, 294, 264, 958], "temperature": 0.0, "avg_logprob": -0.1643562009257655, "compression_ratio": 1.6218181818181818, "no_speech_prob": 3.702320100273937e-05}, {"id": 1254, "seek": 571272, "start": 5712.72, "end": 5716.6, "text": " couple of weeks be even better at De-Oldification.", "tokens": [1916, 295, 3259, 312, 754, 1101, 412, 1346, 12, 49032, 3774, 13], "temperature": 0.0, "avg_logprob": -0.1531411825892437, "compression_ratio": 1.5324074074074074, "no_speech_prob": 8.79745221027406e-06}, {"id": 1255, "seek": 571272, "start": 5716.6, "end": 5725.96, "text": " But hopefully you all can now add other kinds of de-crapification methods as well.", "tokens": [583, 4696, 291, 439, 393, 586, 909, 661, 3685, 295, 368, 12, 66, 4007, 3774, 7150, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1531411825892437, "compression_ratio": 1.5324074074074074, "no_speech_prob": 8.79745221027406e-06}, {"id": 1256, "seek": 571272, "start": 5725.96, "end": 5733.64, "text": " I like every course, if possible, to show something totally new, because then every", "tokens": [286, 411, 633, 1164, 11, 498, 1944, 11, 281, 855, 746, 3879, 777, 11, 570, 550, 633], "temperature": 0.0, "avg_logprob": -0.1531411825892437, "compression_ratio": 1.5324074074074074, "no_speech_prob": 8.79745221027406e-06}, {"id": 1257, "seek": 571272, "start": 5733.64, "end": 5736.96, "text": " student has the chance to basically build things that had never been built before.", "tokens": [3107, 575, 264, 2931, 281, 1936, 1322, 721, 300, 632, 1128, 668, 3094, 949, 13], "temperature": 0.0, "avg_logprob": -0.1531411825892437, "compression_ratio": 1.5324074074074074, "no_speech_prob": 8.79745221027406e-06}, {"id": 1258, "seek": 571272, "start": 5736.96, "end": 5740.0, "text": " So this is kind of that thing.", "tokens": [407, 341, 307, 733, 295, 300, 551, 13], "temperature": 0.0, "avg_logprob": -0.1531411825892437, "compression_ratio": 1.5324074074074074, "no_speech_prob": 8.79745221027406e-06}, {"id": 1259, "seek": 574000, "start": 5740.0, "end": 5745.24, "text": " But between the much better segmentation results and these much simpler and faster de-crapification", "tokens": [583, 1296, 264, 709, 1101, 9469, 399, 3542, 293, 613, 709, 18587, 293, 4663, 368, 12, 66, 4007, 3774], "temperature": 0.0, "avg_logprob": -0.16337582339411197, "compression_ratio": 1.4915254237288136, "no_speech_prob": 2.8779046260751784e-05}, {"id": 1260, "seek": 574000, "start": 5745.24, "end": 5747.76, "text": " results, I think you can build some really cool stuff.", "tokens": [3542, 11, 286, 519, 291, 393, 1322, 512, 534, 1627, 1507, 13], "temperature": 0.0, "avg_logprob": -0.16337582339411197, "compression_ratio": 1.4915254237288136, "no_speech_prob": 2.8779046260751784e-05}, {"id": 1261, "seek": 574000, "start": 5747.76, "end": 5755.08, "text": " Did you have a question?", "tokens": [2589, 291, 362, 257, 1168, 30], "temperature": 0.0, "avg_logprob": -0.16337582339411197, "compression_ratio": 1.4915254237288136, "no_speech_prob": 2.8779046260751784e-05}, {"id": 1262, "seek": 574000, "start": 5755.08, "end": 5760.0, "text": " Is it possible to use similar ideas to UNET and GANs for NLP?", "tokens": [1119, 309, 1944, 281, 764, 2531, 3487, 281, 8229, 4850, 293, 460, 1770, 82, 337, 426, 45196, 30], "temperature": 0.0, "avg_logprob": -0.16337582339411197, "compression_ratio": 1.4915254237288136, "no_speech_prob": 2.8779046260751784e-05}, {"id": 1263, "seek": 574000, "start": 5760.0, "end": 5763.88, "text": " For example, if I want to tag the verbs and nouns in a sentence or create a really good", "tokens": [1171, 1365, 11, 498, 286, 528, 281, 6162, 264, 30051, 293, 48184, 294, 257, 8174, 420, 1884, 257, 534, 665], "temperature": 0.0, "avg_logprob": -0.16337582339411197, "compression_ratio": 1.4915254237288136, "no_speech_prob": 2.8779046260751784e-05}, {"id": 1264, "seek": 574000, "start": 5763.88, "end": 5766.68, "text": " Shakespeare generator?", "tokens": [22825, 19265, 30], "temperature": 0.0, "avg_logprob": -0.16337582339411197, "compression_ratio": 1.4915254237288136, "no_speech_prob": 2.8779046260751784e-05}, {"id": 1265, "seek": 576668, "start": 5766.68, "end": 5770.16, "text": " Yeah, pretty much.", "tokens": [865, 11, 1238, 709, 13], "temperature": 0.0, "avg_logprob": -0.15501419221511994, "compression_ratio": 1.56, "no_speech_prob": 3.8145040889503434e-05}, {"id": 1266, "seek": 576668, "start": 5770.16, "end": 5771.96, "text": " We don't fully know yet.", "tokens": [492, 500, 380, 4498, 458, 1939, 13], "temperature": 0.0, "avg_logprob": -0.15501419221511994, "compression_ratio": 1.56, "no_speech_prob": 3.8145040889503434e-05}, {"id": 1267, "seek": 576668, "start": 5771.96, "end": 5776.62, "text": " It's a pretty new area, but there's a lot of opportunities there, and we'll be looking", "tokens": [467, 311, 257, 1238, 777, 1859, 11, 457, 456, 311, 257, 688, 295, 4786, 456, 11, 293, 321, 603, 312, 1237], "temperature": 0.0, "avg_logprob": -0.15501419221511994, "compression_ratio": 1.56, "no_speech_prob": 3.8145040889503434e-05}, {"id": 1268, "seek": 576668, "start": 5776.62, "end": 5784.04, "text": " at some in a moment, actually.", "tokens": [412, 512, 294, 257, 1623, 11, 767, 13], "temperature": 0.0, "avg_logprob": -0.15501419221511994, "compression_ratio": 1.56, "no_speech_prob": 3.8145040889503434e-05}, {"id": 1269, "seek": 576668, "start": 5784.04, "end": 5789.4800000000005, "text": " So I actually tried testing this on this.", "tokens": [407, 286, 767, 3031, 4997, 341, 322, 341, 13], "temperature": 0.0, "avg_logprob": -0.15501419221511994, "compression_ratio": 1.56, "no_speech_prob": 3.8145040889503434e-05}, {"id": 1270, "seek": 576668, "start": 5789.4800000000005, "end": 5793.38, "text": " Remember this picture I showed you of a slide last lesson?", "tokens": [5459, 341, 3036, 286, 4712, 291, 295, 257, 4137, 1036, 6898, 30], "temperature": 0.0, "avg_logprob": -0.15501419221511994, "compression_ratio": 1.56, "no_speech_prob": 3.8145040889503434e-05}, {"id": 1271, "seek": 576668, "start": 5793.38, "end": 5796.4800000000005, "text": " And it's a really rubbishy-looking picture, and I thought, what would happen if we tried", "tokens": [400, 309, 311, 257, 534, 29978, 88, 12, 16129, 3036, 11, 293, 286, 1194, 11, 437, 576, 1051, 498, 321, 3031], "temperature": 0.0, "avg_logprob": -0.15501419221511994, "compression_ratio": 1.56, "no_speech_prob": 3.8145040889503434e-05}, {"id": 1272, "seek": 579648, "start": 5796.48, "end": 5803.759999999999, "text": " running this just through the exact same model, and it changed it from that to that?", "tokens": [2614, 341, 445, 807, 264, 1900, 912, 2316, 11, 293, 309, 3105, 309, 490, 300, 281, 300, 30], "temperature": 0.0, "avg_logprob": -0.10058547973632813, "compression_ratio": 1.7194570135746607, "no_speech_prob": 9.079092706087977e-06}, {"id": 1273, "seek": 579648, "start": 5803.759999999999, "end": 5805.5199999999995, "text": " So I thought that was a really good example.", "tokens": [407, 286, 1194, 300, 390, 257, 534, 665, 1365, 13], "temperature": 0.0, "avg_logprob": -0.10058547973632813, "compression_ratio": 1.7194570135746607, "no_speech_prob": 9.079092706087977e-06}, {"id": 1274, "seek": 579648, "start": 5805.5199999999995, "end": 5809.32, "text": " You can see something it didn't do, which is this weird discoloration.", "tokens": [509, 393, 536, 746, 309, 994, 380, 360, 11, 597, 307, 341, 3657, 2983, 401, 9357, 13], "temperature": 0.0, "avg_logprob": -0.10058547973632813, "compression_ratio": 1.7194570135746607, "no_speech_prob": 9.079092706087977e-06}, {"id": 1275, "seek": 579648, "start": 5809.32, "end": 5813.5599999999995, "text": " It didn't fix it, because I didn't crapify things with weird discoloration.", "tokens": [467, 994, 380, 3191, 309, 11, 570, 286, 994, 380, 12426, 2505, 721, 365, 3657, 2983, 401, 9357, 13], "temperature": 0.0, "avg_logprob": -0.10058547973632813, "compression_ratio": 1.7194570135746607, "no_speech_prob": 9.079092706087977e-06}, {"id": 1276, "seek": 579648, "start": 5813.5599999999995, "end": 5817.679999999999, "text": " So if you want to create really good image restoration, like I say, you need really good", "tokens": [407, 498, 291, 528, 281, 1884, 534, 665, 3256, 23722, 11, 411, 286, 584, 11, 291, 643, 534, 665], "temperature": 0.0, "avg_logprob": -0.10058547973632813, "compression_ratio": 1.7194570135746607, "no_speech_prob": 9.079092706087977e-06}, {"id": 1277, "seek": 579648, "start": 5817.679999999999, "end": 5820.2, "text": " crapification.", "tokens": [12426, 3774, 13], "temperature": 0.0, "avg_logprob": -0.10058547973632813, "compression_ratio": 1.7194570135746607, "no_speech_prob": 9.079092706087977e-06}, {"id": 1278, "seek": 582020, "start": 5820.2, "end": 5828.24, "text": " OK, so here's what we've learned so far in the course, some of the main things.", "tokens": [2264, 11, 370, 510, 311, 437, 321, 600, 3264, 370, 1400, 294, 264, 1164, 11, 512, 295, 264, 2135, 721, 13], "temperature": 0.0, "avg_logprob": -0.11239131113116661, "compression_ratio": 1.6743119266055047, "no_speech_prob": 1.3419152310234495e-05}, {"id": 1279, "seek": 582020, "start": 5828.24, "end": 5835.72, "text": " So we've learned that neural nets consist of sandwich layers of affine functions, which", "tokens": [407, 321, 600, 3264, 300, 18161, 36170, 4603, 295, 11141, 7914, 295, 2096, 533, 6828, 11, 597], "temperature": 0.0, "avg_logprob": -0.11239131113116661, "compression_ratio": 1.6743119266055047, "no_speech_prob": 1.3419152310234495e-05}, {"id": 1280, "seek": 582020, "start": 5835.72, "end": 5840.36, "text": " are basically matrix multiplications, slightly more general version, and nonlinearities,", "tokens": [366, 1936, 8141, 17596, 763, 11, 4748, 544, 2674, 3037, 11, 293, 2107, 28263, 1088, 11], "temperature": 0.0, "avg_logprob": -0.11239131113116661, "compression_ratio": 1.6743119266055047, "no_speech_prob": 1.3419152310234495e-05}, {"id": 1281, "seek": 582020, "start": 5840.36, "end": 5841.48, "text": " like ReLU.", "tokens": [411, 1300, 43, 52, 13], "temperature": 0.0, "avg_logprob": -0.11239131113116661, "compression_ratio": 1.6743119266055047, "no_speech_prob": 1.3419152310234495e-05}, {"id": 1282, "seek": 582020, "start": 5841.48, "end": 5846.679999999999, "text": " And we learned that the results of those calculations are called activations, and the things that", "tokens": [400, 321, 3264, 300, 264, 3542, 295, 729, 20448, 366, 1219, 2430, 763, 11, 293, 264, 721, 300], "temperature": 0.0, "avg_logprob": -0.11239131113116661, "compression_ratio": 1.6743119266055047, "no_speech_prob": 1.3419152310234495e-05}, {"id": 1283, "seek": 584668, "start": 5846.68, "end": 5851.400000000001, "text": " go into those calculations that we learn are called parameters, and that the parameters", "tokens": [352, 666, 729, 20448, 300, 321, 1466, 366, 1219, 9834, 11, 293, 300, 264, 9834], "temperature": 0.0, "avg_logprob": -0.10755925757862697, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.7774535081116483e-05}, {"id": 1284, "seek": 584668, "start": 5851.400000000001, "end": 5856.52, "text": " are initially randomly initialized, or we copy them over from a pre-trained model, and", "tokens": [366, 9105, 16979, 5883, 1602, 11, 420, 321, 5055, 552, 670, 490, 257, 659, 12, 17227, 2001, 2316, 11, 293], "temperature": 0.0, "avg_logprob": -0.10755925757862697, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.7774535081116483e-05}, {"id": 1285, "seek": 584668, "start": 5856.52, "end": 5860.4400000000005, "text": " then we train them with SGD or faster versions.", "tokens": [550, 321, 3847, 552, 365, 34520, 35, 420, 4663, 9606, 13], "temperature": 0.0, "avg_logprob": -0.10755925757862697, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.7774535081116483e-05}, {"id": 1286, "seek": 584668, "start": 5860.4400000000005, "end": 5866.240000000001, "text": " And we learned that convolutions are a particular affine function that work great for autocorrelated", "tokens": [400, 321, 3264, 300, 3754, 15892, 366, 257, 1729, 2096, 533, 2445, 300, 589, 869, 337, 45833, 284, 12004], "temperature": 0.0, "avg_logprob": -0.10755925757862697, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.7774535081116483e-05}, {"id": 1287, "seek": 584668, "start": 5866.240000000001, "end": 5868.6, "text": " data, so things like images and stuff.", "tokens": [1412, 11, 370, 721, 411, 5267, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.10755925757862697, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.7774535081116483e-05}, {"id": 1288, "seek": 584668, "start": 5868.6, "end": 5873.4400000000005, "text": " We learned about batch norm, dropout, data augmentation, and weight decay as ways of", "tokens": [492, 3264, 466, 15245, 2026, 11, 3270, 346, 11, 1412, 14501, 19631, 11, 293, 3364, 21039, 382, 2098, 295], "temperature": 0.0, "avg_logprob": -0.10755925757862697, "compression_ratio": 1.6996197718631179, "no_speech_prob": 1.7774535081116483e-05}, {"id": 1289, "seek": 587344, "start": 5873.44, "end": 5877.679999999999, "text": " regularizing models, and also batch norm helps train models more quickly.", "tokens": [3890, 3319, 5245, 11, 293, 611, 15245, 2026, 3665, 3847, 5245, 544, 2661, 13], "temperature": 0.0, "avg_logprob": -0.14104777043408687, "compression_ratio": 1.628158844765343, "no_speech_prob": 1.202816656586947e-05}, {"id": 1290, "seek": 587344, "start": 5877.679999999999, "end": 5882.759999999999, "text": " And then today we've learned about res slash dense blocks.", "tokens": [400, 550, 965, 321, 600, 3264, 466, 725, 17330, 18011, 8474, 13], "temperature": 0.0, "avg_logprob": -0.14104777043408687, "compression_ratio": 1.628158844765343, "no_speech_prob": 1.202816656586947e-05}, {"id": 1291, "seek": 587344, "start": 5882.759999999999, "end": 5887.36, "text": " We've obviously learned a lot about image classification regression, embeddings, categorical", "tokens": [492, 600, 2745, 3264, 257, 688, 466, 3256, 21538, 24590, 11, 12240, 29432, 11, 19250, 804], "temperature": 0.0, "avg_logprob": -0.14104777043408687, "compression_ratio": 1.628158844765343, "no_speech_prob": 1.202816656586947e-05}, {"id": 1292, "seek": 587344, "start": 5887.36, "end": 5893.4, "text": " and continuous variables, collaborative filtering, language models and NLP classification, and", "tokens": [293, 10957, 9102, 11, 16555, 30822, 11, 2856, 5245, 293, 426, 45196, 21538, 11, 293], "temperature": 0.0, "avg_logprob": -0.14104777043408687, "compression_ratio": 1.628158844765343, "no_speech_prob": 1.202816656586947e-05}, {"id": 1293, "seek": 587344, "start": 5893.4, "end": 5895.839999999999, "text": " then kind of segmentation, neural net and GANs.", "tokens": [550, 733, 295, 9469, 399, 11, 18161, 2533, 293, 460, 1770, 82, 13], "temperature": 0.0, "avg_logprob": -0.14104777043408687, "compression_ratio": 1.628158844765343, "no_speech_prob": 1.202816656586947e-05}, {"id": 1294, "seek": 587344, "start": 5895.839999999999, "end": 5901.919999999999, "text": " So go over these things and make sure that you feel comfortable with each of them.", "tokens": [407, 352, 670, 613, 721, 293, 652, 988, 300, 291, 841, 4619, 365, 1184, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.14104777043408687, "compression_ratio": 1.628158844765343, "no_speech_prob": 1.202816656586947e-05}, {"id": 1295, "seek": 590192, "start": 5901.92, "end": 5906.18, "text": " If you've only watched this series once, you definitely won't.", "tokens": [759, 291, 600, 787, 6337, 341, 2638, 1564, 11, 291, 2138, 1582, 380, 13], "temperature": 0.0, "avg_logprob": -0.09732956014653688, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.5068065951927565e-05}, {"id": 1296, "seek": 590192, "start": 5906.18, "end": 5912.56, "text": " People normally watch it three times or so to really understand the detail.", "tokens": [3432, 5646, 1159, 309, 1045, 1413, 420, 370, 281, 534, 1223, 264, 2607, 13], "temperature": 0.0, "avg_logprob": -0.09732956014653688, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.5068065951927565e-05}, {"id": 1297, "seek": 590192, "start": 5912.56, "end": 5918.58, "text": " So one thing that doesn't get here is RNNs.", "tokens": [407, 472, 551, 300, 1177, 380, 483, 510, 307, 45702, 45, 82, 13], "temperature": 0.0, "avg_logprob": -0.09732956014653688, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.5068065951927565e-05}, {"id": 1298, "seek": 590192, "start": 5918.58, "end": 5922.24, "text": " So that's the last thing we're going to do, RNNs.", "tokens": [407, 300, 311, 264, 1036, 551, 321, 434, 516, 281, 360, 11, 45702, 45, 82, 13], "temperature": 0.0, "avg_logprob": -0.09732956014653688, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.5068065951927565e-05}, {"id": 1299, "seek": 590192, "start": 5922.24, "end": 5928.08, "text": " So RNNs, I'm going to introduce a little kind of diagrammatic method here to explain RNNs.", "tokens": [407, 45702, 45, 82, 11, 286, 478, 516, 281, 5366, 257, 707, 733, 295, 10686, 25915, 3170, 510, 281, 2903, 45702, 45, 82, 13], "temperature": 0.0, "avg_logprob": -0.09732956014653688, "compression_ratio": 1.5911330049261083, "no_speech_prob": 2.5068065951927565e-05}, {"id": 1300, "seek": 592808, "start": 5928.08, "end": 5931.84, "text": " In the diagrammatic method, I'll start by showing you a basic neural net with a single", "tokens": [682, 264, 10686, 25915, 3170, 11, 286, 603, 722, 538, 4099, 291, 257, 3875, 18161, 2533, 365, 257, 2167], "temperature": 0.0, "avg_logprob": -0.19009835207009618, "compression_ratio": 1.5691489361702127, "no_speech_prob": 4.8602314564050175e-06}, {"id": 1301, "seek": 592808, "start": 5931.84, "end": 5933.84, "text": " hidden layer.", "tokens": [7633, 4583, 13], "temperature": 0.0, "avg_logprob": -0.19009835207009618, "compression_ratio": 1.5691489361702127, "no_speech_prob": 4.8602314564050175e-06}, {"id": 1302, "seek": 592808, "start": 5933.84, "end": 5936.98, "text": " Square means an input.", "tokens": [16463, 1355, 364, 4846, 13], "temperature": 0.0, "avg_logprob": -0.19009835207009618, "compression_ratio": 1.5691489361702127, "no_speech_prob": 4.8602314564050175e-06}, {"id": 1303, "seek": 592808, "start": 5936.98, "end": 5941.04, "text": " So that'll be batch size by number of inputs.", "tokens": [407, 300, 603, 312, 15245, 2744, 538, 1230, 295, 15743, 13], "temperature": 0.0, "avg_logprob": -0.19009835207009618, "compression_ratio": 1.5691489361702127, "no_speech_prob": 4.8602314564050175e-06}, {"id": 1304, "seek": 592808, "start": 5941.04, "end": 5950.08, "text": " So kind of batch size by number of inputs.", "tokens": [407, 733, 295, 15245, 2744, 538, 1230, 295, 15743, 13], "temperature": 0.0, "avg_logprob": -0.19009835207009618, "compression_ratio": 1.5691489361702127, "no_speech_prob": 4.8602314564050175e-06}, {"id": 1305, "seek": 592808, "start": 5950.08, "end": 5956.88, "text": " An arrow means a layer, broadly defined, such as matrix product followed by value.", "tokens": [1107, 11610, 1355, 257, 4583, 11, 19511, 7642, 11, 1270, 382, 8141, 1674, 6263, 538, 2158, 13], "temperature": 0.0, "avg_logprob": -0.19009835207009618, "compression_ratio": 1.5691489361702127, "no_speech_prob": 4.8602314564050175e-06}, {"id": 1306, "seek": 595688, "start": 5956.88, "end": 5961.88, "text": " A circle is activations.", "tokens": [316, 6329, 307, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.10174110636991614, "compression_ratio": 1.7527472527472527, "no_speech_prob": 1.0129366273758933e-05}, {"id": 1307, "seek": 595688, "start": 5961.88, "end": 5965.68, "text": " So in this case, we have one set of hidden activations.", "tokens": [407, 294, 341, 1389, 11, 321, 362, 472, 992, 295, 7633, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.10174110636991614, "compression_ratio": 1.7527472527472527, "no_speech_prob": 1.0129366273758933e-05}, {"id": 1308, "seek": 595688, "start": 5965.68, "end": 5972.4400000000005, "text": " And so given that the input was number of inputs, this here is a matrix of number of", "tokens": [400, 370, 2212, 300, 264, 4846, 390, 1230, 295, 15743, 11, 341, 510, 307, 257, 8141, 295, 1230, 295], "temperature": 0.0, "avg_logprob": -0.10174110636991614, "compression_ratio": 1.7527472527472527, "no_speech_prob": 1.0129366273758933e-05}, {"id": 1309, "seek": 595688, "start": 5972.4400000000005, "end": 5974.6, "text": " inputs by number of activations.", "tokens": [15743, 538, 1230, 295, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.10174110636991614, "compression_ratio": 1.7527472527472527, "no_speech_prob": 1.0129366273758933e-05}, {"id": 1310, "seek": 595688, "start": 5974.6, "end": 5979.0, "text": " So the output will be batch size by number of activations.", "tokens": [407, 264, 5598, 486, 312, 15245, 2744, 538, 1230, 295, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.10174110636991614, "compression_ratio": 1.7527472527472527, "no_speech_prob": 1.0129366273758933e-05}, {"id": 1311, "seek": 595688, "start": 5979.0, "end": 5981.52, "text": " It's really important you know how to calculate these shapes.", "tokens": [467, 311, 534, 1021, 291, 458, 577, 281, 8873, 613, 10854, 13], "temperature": 0.0, "avg_logprob": -0.10174110636991614, "compression_ratio": 1.7527472527472527, "no_speech_prob": 1.0129366273758933e-05}, {"id": 1312, "seek": 598152, "start": 5981.52, "end": 5987.200000000001, "text": " So go learn.summary lots to see all the shapes.", "tokens": [407, 352, 1466, 13, 82, 40879, 822, 3195, 281, 536, 439, 264, 10854, 13], "temperature": 0.0, "avg_logprob": -0.14547715603726583, "compression_ratio": 1.7383177570093458, "no_speech_prob": 4.9368813961336855e-06}, {"id": 1313, "seek": 598152, "start": 5987.200000000001, "end": 5988.64, "text": " So then here's another arrow.", "tokens": [407, 550, 510, 311, 1071, 11610, 13], "temperature": 0.0, "avg_logprob": -0.14547715603726583, "compression_ratio": 1.7383177570093458, "no_speech_prob": 4.9368813961336855e-06}, {"id": 1314, "seek": 598152, "start": 5988.64, "end": 5991.96, "text": " So that means it's another layer, matrix product followed by nonlinearity.", "tokens": [407, 300, 1355, 309, 311, 1071, 4583, 11, 8141, 1674, 6263, 538, 2107, 1889, 17409, 13], "temperature": 0.0, "avg_logprob": -0.14547715603726583, "compression_ratio": 1.7383177570093458, "no_speech_prob": 4.9368813961336855e-06}, {"id": 1315, "seek": 598152, "start": 5991.96, "end": 5995.860000000001, "text": " In this case, we go into the output, so we use softmax.", "tokens": [682, 341, 1389, 11, 321, 352, 666, 264, 5598, 11, 370, 321, 764, 2787, 41167, 13], "temperature": 0.0, "avg_logprob": -0.14547715603726583, "compression_ratio": 1.7383177570093458, "no_speech_prob": 4.9368813961336855e-06}, {"id": 1316, "seek": 598152, "start": 5995.860000000001, "end": 5999.68, "text": " And then triangle means an output.", "tokens": [400, 550, 13369, 1355, 364, 5598, 13], "temperature": 0.0, "avg_logprob": -0.14547715603726583, "compression_ratio": 1.7383177570093458, "no_speech_prob": 4.9368813961336855e-06}, {"id": 1317, "seek": 598152, "start": 5999.68, "end": 6003.26, "text": " And so this matrix product will be number of activations by number of classes.", "tokens": [400, 370, 341, 8141, 1674, 486, 312, 1230, 295, 2430, 763, 538, 1230, 295, 5359, 13], "temperature": 0.0, "avg_logprob": -0.14547715603726583, "compression_ratio": 1.7383177570093458, "no_speech_prob": 4.9368813961336855e-06}, {"id": 1318, "seek": 598152, "start": 6003.26, "end": 6006.160000000001, "text": " So our output is batch size by number of classes.", "tokens": [407, 527, 5598, 307, 15245, 2744, 538, 1230, 295, 5359, 13], "temperature": 0.0, "avg_logprob": -0.14547715603726583, "compression_ratio": 1.7383177570093458, "no_speech_prob": 4.9368813961336855e-06}, {"id": 1319, "seek": 600616, "start": 6006.16, "end": 6016.36, "text": " So let's reuse that key, remember, triangle output, circle is activations, hidden state", "tokens": [407, 718, 311, 26225, 300, 2141, 11, 1604, 11, 13369, 5598, 11, 6329, 307, 2430, 763, 11, 7633, 1785], "temperature": 0.0, "avg_logprob": -0.07533128352104863, "compression_ratio": 1.6020942408376964, "no_speech_prob": 1.903300358208071e-06}, {"id": 1320, "seek": 600616, "start": 6016.36, "end": 6020.4, "text": " we also call that, and rectangle is input.", "tokens": [321, 611, 818, 300, 11, 293, 21930, 307, 4846, 13], "temperature": 0.0, "avg_logprob": -0.07533128352104863, "compression_ratio": 1.6020942408376964, "no_speech_prob": 1.903300358208071e-06}, {"id": 1321, "seek": 600616, "start": 6020.4, "end": 6027.8, "text": " So let's now imagine that we wanted to get a big document, split it into sets of three", "tokens": [407, 718, 311, 586, 3811, 300, 321, 1415, 281, 483, 257, 955, 4166, 11, 7472, 309, 666, 6352, 295, 1045], "temperature": 0.0, "avg_logprob": -0.07533128352104863, "compression_ratio": 1.6020942408376964, "no_speech_prob": 1.903300358208071e-06}, {"id": 1322, "seek": 600616, "start": 6027.8, "end": 6034.48, "text": " words at a time, and grab each set of three words and then try to predict the third word", "tokens": [2283, 412, 257, 565, 11, 293, 4444, 1184, 992, 295, 1045, 2283, 293, 550, 853, 281, 6069, 264, 2636, 1349], "temperature": 0.0, "avg_logprob": -0.07533128352104863, "compression_ratio": 1.6020942408376964, "no_speech_prob": 1.903300358208071e-06}, {"id": 1323, "seek": 603448, "start": 6034.48, "end": 6036.5599999999995, "text": " using the first two words.", "tokens": [1228, 264, 700, 732, 2283, 13], "temperature": 0.0, "avg_logprob": -0.11291111840142144, "compression_ratio": 1.7135678391959799, "no_speech_prob": 1.5688676285208203e-05}, {"id": 1324, "seek": 603448, "start": 6036.5599999999995, "end": 6042.12, "text": " So if we had the data set in place, we could grab word one as an input, chuck it through", "tokens": [407, 498, 321, 632, 264, 1412, 992, 294, 1081, 11, 321, 727, 4444, 1349, 472, 382, 364, 4846, 11, 20870, 309, 807], "temperature": 0.0, "avg_logprob": -0.11291111840142144, "compression_ratio": 1.7135678391959799, "no_speech_prob": 1.5688676285208203e-05}, {"id": 1325, "seek": 603448, "start": 6042.12, "end": 6054.0, "text": " an embedding, right, create some activations, pass that through a matrix product and nonlinearity,", "tokens": [364, 12240, 3584, 11, 558, 11, 1884, 512, 2430, 763, 11, 1320, 300, 807, 257, 8141, 1674, 293, 2107, 1889, 17409, 11], "temperature": 0.0, "avg_logprob": -0.11291111840142144, "compression_ratio": 1.7135678391959799, "no_speech_prob": 1.5688676285208203e-05}, {"id": 1326, "seek": 603448, "start": 6054.0, "end": 6060.179999999999, "text": " grab the second word, put it through an embedding, and then we could either add those two things", "tokens": [4444, 264, 1150, 1349, 11, 829, 309, 807, 364, 12240, 3584, 11, 293, 550, 321, 727, 2139, 909, 729, 732, 721], "temperature": 0.0, "avg_logprob": -0.11291111840142144, "compression_ratio": 1.7135678391959799, "no_speech_prob": 1.5688676285208203e-05}, {"id": 1327, "seek": 603448, "start": 6060.179999999999, "end": 6062.4, "text": " together or concatenate them.", "tokens": [1214, 420, 1588, 7186, 473, 552, 13], "temperature": 0.0, "avg_logprob": -0.11291111840142144, "compression_ratio": 1.7135678391959799, "no_speech_prob": 1.5688676285208203e-05}, {"id": 1328, "seek": 606240, "start": 6062.4, "end": 6068.44, "text": " Generally speaking, when you see kind of two sets of activations coming together in a diagram,", "tokens": [21082, 4124, 11, 562, 291, 536, 733, 295, 732, 6352, 295, 2430, 763, 1348, 1214, 294, 257, 10686, 11], "temperature": 0.0, "avg_logprob": -0.11283223172451587, "compression_ratio": 1.683982683982684, "no_speech_prob": 6.240630682441406e-06}, {"id": 1329, "seek": 606240, "start": 6068.44, "end": 6073.24, "text": " you normally have a choice of concatenate or add.", "tokens": [291, 5646, 362, 257, 3922, 295, 1588, 7186, 473, 420, 909, 13], "temperature": 0.0, "avg_logprob": -0.11283223172451587, "compression_ratio": 1.683982683982684, "no_speech_prob": 6.240630682441406e-06}, {"id": 1330, "seek": 606240, "start": 6073.24, "end": 6076.639999999999, "text": " And that's going to create a second bunch of activations, and then you can put it through", "tokens": [400, 300, 311, 516, 281, 1884, 257, 1150, 3840, 295, 2430, 763, 11, 293, 550, 291, 393, 829, 309, 807], "temperature": 0.0, "avg_logprob": -0.11283223172451587, "compression_ratio": 1.683982683982684, "no_speech_prob": 6.240630682441406e-06}, {"id": 1331, "seek": 606240, "start": 6076.639999999999, "end": 6083.2, "text": " one more fully connected layer and softmax to create an output.", "tokens": [472, 544, 4498, 4582, 4583, 293, 2787, 41167, 281, 1884, 364, 5598, 13], "temperature": 0.0, "avg_logprob": -0.11283223172451587, "compression_ratio": 1.683982683982684, "no_speech_prob": 6.240630682441406e-06}, {"id": 1332, "seek": 606240, "start": 6083.2, "end": 6089.5599999999995, "text": " So that would be a totally standard, fully connected neural net with one very minor tweak,", "tokens": [407, 300, 576, 312, 257, 3879, 3832, 11, 4498, 4582, 18161, 2533, 365, 472, 588, 6696, 29879, 11], "temperature": 0.0, "avg_logprob": -0.11283223172451587, "compression_ratio": 1.683982683982684, "no_speech_prob": 6.240630682441406e-06}, {"id": 1333, "seek": 608956, "start": 6089.56, "end": 6094.96, "text": " which is concatenating or adding at this point, which we could use to try to predict the third", "tokens": [597, 307, 1588, 7186, 990, 420, 5127, 412, 341, 935, 11, 597, 321, 727, 764, 281, 853, 281, 6069, 264, 2636], "temperature": 0.0, "avg_logprob": -0.19438169194364, "compression_ratio": 1.5497630331753554, "no_speech_prob": 6.643061169597786e-06}, {"id": 1334, "seek": 608956, "start": 6094.96, "end": 6099.280000000001, "text": " word from pairs of two words.", "tokens": [1349, 490, 15494, 295, 732, 2283, 13], "temperature": 0.0, "avg_logprob": -0.19438169194364, "compression_ratio": 1.5497630331753554, "no_speech_prob": 6.643061169597786e-06}, {"id": 1335, "seek": 608956, "start": 6099.280000000001, "end": 6101.160000000001, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.19438169194364, "compression_ratio": 1.5497630331753554, "no_speech_prob": 6.643061169597786e-06}, {"id": 1336, "seek": 608956, "start": 6101.160000000001, "end": 6108.56, "text": " So remember, arrows represent layer operations, and I removed in this one the specifics of", "tokens": [407, 1604, 11, 19669, 2906, 4583, 7705, 11, 293, 286, 7261, 294, 341, 472, 264, 28454, 295], "temperature": 0.0, "avg_logprob": -0.19438169194364, "compression_ratio": 1.5497630331753554, "no_speech_prob": 6.643061169597786e-06}, {"id": 1337, "seek": 608956, "start": 6108.56, "end": 6113.68, "text": " what they are because they're always an affine function followed by nonlinearity.", "tokens": [437, 436, 366, 570, 436, 434, 1009, 364, 2096, 533, 2445, 6263, 538, 2107, 1889, 17409, 13], "temperature": 0.0, "avg_logprob": -0.19438169194364, "compression_ratio": 1.5497630331753554, "no_speech_prob": 6.643061169597786e-06}, {"id": 1338, "seek": 608956, "start": 6113.68, "end": 6116.76, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.19438169194364, "compression_ratio": 1.5497630331753554, "no_speech_prob": 6.643061169597786e-06}, {"id": 1339, "seek": 608956, "start": 6116.76, "end": 6118.320000000001, "text": " Let's go further.", "tokens": [961, 311, 352, 3052, 13], "temperature": 0.0, "avg_logprob": -0.19438169194364, "compression_ratio": 1.5497630331753554, "no_speech_prob": 6.643061169597786e-06}, {"id": 1340, "seek": 611832, "start": 6118.32, "end": 6123.08, "text": " What if we wanted to predict word four using words one and two and three?", "tokens": [708, 498, 321, 1415, 281, 6069, 1349, 1451, 1228, 2283, 472, 293, 732, 293, 1045, 30], "temperature": 0.0, "avg_logprob": -0.13383014529359108, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.2029191566398367e-05}, {"id": 1341, "seek": 611832, "start": 6123.08, "end": 6126.639999999999, "text": " It's basically the same picture as last time except with one extra input and one extra", "tokens": [467, 311, 1936, 264, 912, 3036, 382, 1036, 565, 3993, 365, 472, 2857, 4846, 293, 472, 2857], "temperature": 0.0, "avg_logprob": -0.13383014529359108, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.2029191566398367e-05}, {"id": 1342, "seek": 611832, "start": 6126.639999999999, "end": 6127.639999999999, "text": " circle.", "tokens": [6329, 13], "temperature": 0.0, "avg_logprob": -0.13383014529359108, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.2029191566398367e-05}, {"id": 1343, "seek": 611832, "start": 6127.639999999999, "end": 6135.759999999999, "text": " But I want to point something out, which is each time we go from rectangle to circle,", "tokens": [583, 286, 528, 281, 935, 746, 484, 11, 597, 307, 1184, 565, 321, 352, 490, 21930, 281, 6329, 11], "temperature": 0.0, "avg_logprob": -0.13383014529359108, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.2029191566398367e-05}, {"id": 1344, "seek": 611832, "start": 6135.759999999999, "end": 6137.04, "text": " we're doing the same thing.", "tokens": [321, 434, 884, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.13383014529359108, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.2029191566398367e-05}, {"id": 1345, "seek": 611832, "start": 6137.04, "end": 6142.4, "text": " We're doing an embedding, which is just a particular kind of matrix multiply where you", "tokens": [492, 434, 884, 364, 12240, 3584, 11, 597, 307, 445, 257, 1729, 733, 295, 8141, 12972, 689, 291], "temperature": 0.0, "avg_logprob": -0.13383014529359108, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.2029191566398367e-05}, {"id": 1346, "seek": 611832, "start": 6142.4, "end": 6144.759999999999, "text": " have one hot encoded input.", "tokens": [362, 472, 2368, 2058, 12340, 4846, 13], "temperature": 0.0, "avg_logprob": -0.13383014529359108, "compression_ratio": 1.6473029045643153, "no_speech_prob": 1.2029191566398367e-05}, {"id": 1347, "seek": 614476, "start": 6144.76, "end": 6150.6, "text": " Each time we go from circle to circle, we're basically taking one piece of hidden state,", "tokens": [6947, 565, 321, 352, 490, 6329, 281, 6329, 11, 321, 434, 1936, 1940, 472, 2522, 295, 7633, 1785, 11], "temperature": 0.0, "avg_logprob": -0.1092510057532269, "compression_ratio": 1.784, "no_speech_prob": 4.860346507484792e-06}, {"id": 1348, "seek": 614476, "start": 6150.6, "end": 6154.92, "text": " one set of activations, and turning it into another set of activations by saying we're", "tokens": [472, 992, 295, 2430, 763, 11, 293, 6246, 309, 666, 1071, 992, 295, 2430, 763, 538, 1566, 321, 434], "temperature": 0.0, "avg_logprob": -0.1092510057532269, "compression_ratio": 1.784, "no_speech_prob": 4.860346507484792e-06}, {"id": 1349, "seek": 614476, "start": 6154.92, "end": 6157.320000000001, "text": " now at the next word.", "tokens": [586, 412, 264, 958, 1349, 13], "temperature": 0.0, "avg_logprob": -0.1092510057532269, "compression_ratio": 1.784, "no_speech_prob": 4.860346507484792e-06}, {"id": 1350, "seek": 614476, "start": 6157.320000000001, "end": 6161.12, "text": " And then when we go from circle to triangle, we're doing something else again, which is", "tokens": [400, 550, 562, 321, 352, 490, 6329, 281, 13369, 11, 321, 434, 884, 746, 1646, 797, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.1092510057532269, "compression_ratio": 1.784, "no_speech_prob": 4.860346507484792e-06}, {"id": 1351, "seek": 614476, "start": 6161.12, "end": 6166.400000000001, "text": " we're saying let's convert the hidden state, these activations, into an output.", "tokens": [321, 434, 1566, 718, 311, 7620, 264, 7633, 1785, 11, 613, 2430, 763, 11, 666, 364, 5598, 13], "temperature": 0.0, "avg_logprob": -0.1092510057532269, "compression_ratio": 1.784, "no_speech_prob": 4.860346507484792e-06}, {"id": 1352, "seek": 614476, "start": 6166.400000000001, "end": 6167.400000000001, "text": " So it makes sense.", "tokens": [407, 309, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.1092510057532269, "compression_ratio": 1.784, "no_speech_prob": 4.860346507484792e-06}, {"id": 1353, "seek": 614476, "start": 6167.400000000001, "end": 6170.72, "text": " So you can see I've colored each of those arrows differently.", "tokens": [407, 291, 393, 536, 286, 600, 14332, 1184, 295, 729, 19669, 7614, 13], "temperature": 0.0, "avg_logprob": -0.1092510057532269, "compression_ratio": 1.784, "no_speech_prob": 4.860346507484792e-06}, {"id": 1354, "seek": 617072, "start": 6170.72, "end": 6176.4400000000005, "text": " So each of those arrows should probably use the same weight matrix because it's doing", "tokens": [407, 1184, 295, 729, 19669, 820, 1391, 764, 264, 912, 3364, 8141, 570, 309, 311, 884], "temperature": 0.0, "avg_logprob": -0.09770930254900898, "compression_ratio": 1.7083333333333333, "no_speech_prob": 4.356821591500193e-06}, {"id": 1355, "seek": 617072, "start": 6176.4400000000005, "end": 6177.84, "text": " the same thing.", "tokens": [264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.09770930254900898, "compression_ratio": 1.7083333333333333, "no_speech_prob": 4.356821591500193e-06}, {"id": 1356, "seek": 617072, "start": 6177.84, "end": 6182.96, "text": " So why would you have a different set of embeddings for each word or a different set of a different", "tokens": [407, 983, 576, 291, 362, 257, 819, 992, 295, 12240, 29432, 337, 1184, 1349, 420, 257, 819, 992, 295, 257, 819], "temperature": 0.0, "avg_logprob": -0.09770930254900898, "compression_ratio": 1.7083333333333333, "no_speech_prob": 4.356821591500193e-06}, {"id": 1357, "seek": 617072, "start": 6182.96, "end": 6188.84, "text": " matrix to multiply by to go from this hidden state to this hidden state versus this one?", "tokens": [8141, 281, 12972, 538, 281, 352, 490, 341, 7633, 1785, 281, 341, 7633, 1785, 5717, 341, 472, 30], "temperature": 0.0, "avg_logprob": -0.09770930254900898, "compression_ratio": 1.7083333333333333, "no_speech_prob": 4.356821591500193e-06}, {"id": 1358, "seek": 617072, "start": 6188.84, "end": 6193.52, "text": " So this is what we're going to build.", "tokens": [407, 341, 307, 437, 321, 434, 516, 281, 1322, 13], "temperature": 0.0, "avg_logprob": -0.09770930254900898, "compression_ratio": 1.7083333333333333, "no_speech_prob": 4.356821591500193e-06}, {"id": 1359, "seek": 619352, "start": 6193.52, "end": 6203.92, "text": " So we're now going to jump into human numbers, which is less than seven human numbers.", "tokens": [407, 321, 434, 586, 516, 281, 3012, 666, 1952, 3547, 11, 597, 307, 1570, 813, 3407, 1952, 3547, 13], "temperature": 0.0, "avg_logprob": -0.14031351529634917, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.5294015156541718e-06}, {"id": 1360, "seek": 619352, "start": 6203.92, "end": 6208.240000000001, "text": " And this is a data set that I created which literally just contains all the numbers from", "tokens": [400, 341, 307, 257, 1412, 992, 300, 286, 2942, 597, 3736, 445, 8306, 439, 264, 3547, 490], "temperature": 0.0, "avg_logprob": -0.14031351529634917, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.5294015156541718e-06}, {"id": 1361, "seek": 619352, "start": 6208.240000000001, "end": 6212.92, "text": " one to 9,999 written out in English.", "tokens": [472, 281, 1722, 11, 49017, 3720, 484, 294, 3669, 13], "temperature": 0.0, "avg_logprob": -0.14031351529634917, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.5294015156541718e-06}, {"id": 1362, "seek": 619352, "start": 6212.92, "end": 6216.4400000000005, "text": " And we're going to try and create a language model that can predict the next word in this", "tokens": [400, 321, 434, 516, 281, 853, 293, 1884, 257, 2856, 2316, 300, 393, 6069, 264, 958, 1349, 294, 341], "temperature": 0.0, "avg_logprob": -0.14031351529634917, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.5294015156541718e-06}, {"id": 1363, "seek": 619352, "start": 6216.4400000000005, "end": 6217.4400000000005, "text": " document.", "tokens": [4166, 13], "temperature": 0.0, "avg_logprob": -0.14031351529634917, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.5294015156541718e-06}, {"id": 1364, "seek": 619352, "start": 6217.4400000000005, "end": 6221.280000000001, "text": " It's just a toy example for this purpose.", "tokens": [467, 311, 445, 257, 12058, 1365, 337, 341, 4334, 13], "temperature": 0.0, "avg_logprob": -0.14031351529634917, "compression_ratio": 1.6090909090909091, "no_speech_prob": 1.5294015156541718e-06}, {"id": 1365, "seek": 622128, "start": 6221.28, "end": 6225.0, "text": " So in this case, we only have one document.", "tokens": [407, 294, 341, 1389, 11, 321, 787, 362, 472, 4166, 13], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1366, "seek": 622128, "start": 6225.0, "end": 6227.36, "text": " That one document is the list of numbers.", "tokens": [663, 472, 4166, 307, 264, 1329, 295, 3547, 13], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1367, "seek": 622128, "start": 6227.36, "end": 6232.24, "text": " So we can use a text list to create an item list with text in for the training and the", "tokens": [407, 321, 393, 764, 257, 2487, 1329, 281, 1884, 364, 3174, 1329, 365, 2487, 294, 337, 264, 3097, 293, 264], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1368, "seek": 622128, "start": 6232.24, "end": 6233.24, "text": " validation.", "tokens": [24071, 13], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1369, "seek": 622128, "start": 6233.24, "end": 6237.599999999999, "text": " In this case, the validation set is the numbers from 8,000 onwards and the training set is", "tokens": [682, 341, 1389, 11, 264, 24071, 992, 307, 264, 3547, 490, 1649, 11, 1360, 34230, 293, 264, 3097, 992, 307], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1370, "seek": 622128, "start": 6237.599999999999, "end": 6239.599999999999, "text": " 1 to 8,000.", "tokens": [502, 281, 1649, 11, 1360, 13], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1371, "seek": 622128, "start": 6239.599999999999, "end": 6244.679999999999, "text": " We can combine them together, turn that into a data bunch.", "tokens": [492, 393, 10432, 552, 1214, 11, 1261, 300, 666, 257, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1372, "seek": 622128, "start": 6244.679999999999, "end": 6245.88, "text": " So we only have one document.", "tokens": [407, 321, 787, 362, 472, 4166, 13], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1373, "seek": 622128, "start": 6245.88, "end": 6247.96, "text": " So train zero is the document.", "tokens": [407, 3847, 4018, 307, 264, 4166, 13], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1374, "seek": 622128, "start": 6247.96, "end": 6249.219999999999, "text": " Grab its dot text.", "tokens": [20357, 1080, 5893, 2487, 13], "temperature": 0.0, "avg_logprob": -0.15312967144074988, "compression_ratio": 1.8849557522123894, "no_speech_prob": 1.9830446035484783e-05}, {"id": 1375, "seek": 624922, "start": 6249.22, "end": 6251.6, "text": " That's how you grab the contents of a text list.", "tokens": [663, 311, 577, 291, 4444, 264, 15768, 295, 257, 2487, 1329, 13], "temperature": 0.0, "avg_logprob": -0.17792490731298397, "compression_ratio": 1.5622641509433963, "no_speech_prob": 1.240909296029713e-05}, {"id": 1376, "seek": 624922, "start": 6251.6, "end": 6255.12, "text": " And here are the first 80 characters.", "tokens": [400, 510, 366, 264, 700, 4688, 4342, 13], "temperature": 0.0, "avg_logprob": -0.17792490731298397, "compression_ratio": 1.5622641509433963, "no_speech_prob": 1.240909296029713e-05}, {"id": 1377, "seek": 624922, "start": 6255.12, "end": 6258.12, "text": " It starts with a special token, XXBOS.", "tokens": [467, 3719, 365, 257, 2121, 14862, 11, 27050, 33, 4367, 13], "temperature": 0.0, "avg_logprob": -0.17792490731298397, "compression_ratio": 1.5622641509433963, "no_speech_prob": 1.240909296029713e-05}, {"id": 1378, "seek": 624922, "start": 6258.12, "end": 6261.16, "text": " Anything starting with XX is a special fast AI token.", "tokens": [11998, 2891, 365, 27050, 307, 257, 2121, 2370, 7318, 14862, 13], "temperature": 0.0, "avg_logprob": -0.17792490731298397, "compression_ratio": 1.5622641509433963, "no_speech_prob": 1.240909296029713e-05}, {"id": 1379, "seek": 624922, "start": 6261.16, "end": 6263.9800000000005, "text": " BOS is the beginning of stream token.", "tokens": [363, 4367, 307, 264, 2863, 295, 4309, 14862, 13], "temperature": 0.0, "avg_logprob": -0.17792490731298397, "compression_ratio": 1.5622641509433963, "no_speech_prob": 1.240909296029713e-05}, {"id": 1380, "seek": 624922, "start": 6263.9800000000005, "end": 6266.4800000000005, "text": " It basically says this is the start of a document.", "tokens": [467, 1936, 1619, 341, 307, 264, 722, 295, 257, 4166, 13], "temperature": 0.0, "avg_logprob": -0.17792490731298397, "compression_ratio": 1.5622641509433963, "no_speech_prob": 1.240909296029713e-05}, {"id": 1381, "seek": 624922, "start": 6266.4800000000005, "end": 6271.96, "text": " It's very helpful in NLP to know when documents start so that your models can learn to recognize", "tokens": [467, 311, 588, 4961, 294, 426, 45196, 281, 458, 562, 8512, 722, 370, 300, 428, 5245, 393, 1466, 281, 5521], "temperature": 0.0, "avg_logprob": -0.17792490731298397, "compression_ratio": 1.5622641509433963, "no_speech_prob": 1.240909296029713e-05}, {"id": 1382, "seek": 624922, "start": 6271.96, "end": 6273.4400000000005, "text": " them.", "tokens": [552, 13], "temperature": 0.0, "avg_logprob": -0.17792490731298397, "compression_ratio": 1.5622641509433963, "no_speech_prob": 1.240909296029713e-05}, {"id": 1383, "seek": 624922, "start": 6273.4400000000005, "end": 6276.240000000001, "text": " The validation set contains 13,000 tokens.", "tokens": [440, 24071, 992, 8306, 3705, 11, 1360, 22667, 13], "temperature": 0.0, "avg_logprob": -0.17792490731298397, "compression_ratio": 1.5622641509433963, "no_speech_prob": 1.240909296029713e-05}, {"id": 1384, "seek": 627624, "start": 6276.24, "end": 6280.24, "text": " So 13,000 words or punctuation marks.", "tokens": [407, 3705, 11, 1360, 2283, 420, 27006, 16073, 10640, 13], "temperature": 0.0, "avg_logprob": -0.1839266690340909, "compression_ratio": 1.3653846153846154, "no_speech_prob": 6.14389318798203e-06}, {"id": 1385, "seek": 627624, "start": 6280.24, "end": 6284.639999999999, "text": " Because everything between spaces is a separate token.", "tokens": [1436, 1203, 1296, 7673, 307, 257, 4994, 14862, 13], "temperature": 0.0, "avg_logprob": -0.1839266690340909, "compression_ratio": 1.3653846153846154, "no_speech_prob": 6.14389318798203e-06}, {"id": 1386, "seek": 627624, "start": 6284.639999999999, "end": 6293.0599999999995, "text": " The batch size that we asked for was 64.", "tokens": [440, 15245, 2744, 300, 321, 2351, 337, 390, 12145, 13], "temperature": 0.0, "avg_logprob": -0.1839266690340909, "compression_ratio": 1.3653846153846154, "no_speech_prob": 6.14389318798203e-06}, {"id": 1387, "seek": 627624, "start": 6293.0599999999995, "end": 6296.44, "text": " And then by default it uses something called BPTT of 70.", "tokens": [400, 550, 538, 7576, 309, 4960, 746, 1219, 40533, 28178, 295, 5285, 13], "temperature": 0.0, "avg_logprob": -0.1839266690340909, "compression_ratio": 1.3653846153846154, "no_speech_prob": 6.14389318798203e-06}, {"id": 1388, "seek": 627624, "start": 6296.44, "end": 6301.42, "text": " BPTT, as we briefly mentioned, stands for back prop through time.", "tokens": [40533, 28178, 11, 382, 321, 10515, 2835, 11, 7382, 337, 646, 2365, 807, 565, 13], "temperature": 0.0, "avg_logprob": -0.1839266690340909, "compression_ratio": 1.3653846153846154, "no_speech_prob": 6.14389318798203e-06}, {"id": 1389, "seek": 627624, "start": 6301.42, "end": 6303.24, "text": " That's the sequence length.", "tokens": [663, 311, 264, 8310, 4641, 13], "temperature": 0.0, "avg_logprob": -0.1839266690340909, "compression_ratio": 1.3653846153846154, "no_speech_prob": 6.14389318798203e-06}, {"id": 1390, "seek": 630324, "start": 6303.24, "end": 6313.88, "text": " So with each of our 64 document segments, we split it up into lists of 70 words that", "tokens": [407, 365, 1184, 295, 527, 12145, 4166, 19904, 11, 321, 7472, 309, 493, 666, 14511, 295, 5285, 2283, 300], "temperature": 0.0, "avg_logprob": -0.13736976402393286, "compression_ratio": 1.4457142857142857, "no_speech_prob": 3.6686901694338303e-06}, {"id": 1391, "seek": 630324, "start": 6313.88, "end": 6315.86, "text": " we look at at one time.", "tokens": [321, 574, 412, 412, 472, 565, 13], "temperature": 0.0, "avg_logprob": -0.13736976402393286, "compression_ratio": 1.4457142857142857, "no_speech_prob": 3.6686901694338303e-06}, {"id": 1392, "seek": 630324, "start": 6315.86, "end": 6324.0199999999995, "text": " So what we do is we grab this for the validation set, entire string of 13,000 tokens.", "tokens": [407, 437, 321, 360, 307, 321, 4444, 341, 337, 264, 24071, 992, 11, 2302, 6798, 295, 3705, 11, 1360, 22667, 13], "temperature": 0.0, "avg_logprob": -0.13736976402393286, "compression_ratio": 1.4457142857142857, "no_speech_prob": 3.6686901694338303e-06}, {"id": 1393, "seek": 630324, "start": 6324.0199999999995, "end": 6330.96, "text": " And then we split it into 64 roughly equal sized sections.", "tokens": [400, 550, 321, 7472, 309, 666, 12145, 9810, 2681, 20004, 10863, 13], "temperature": 0.0, "avg_logprob": -0.13736976402393286, "compression_ratio": 1.4457142857142857, "no_speech_prob": 3.6686901694338303e-06}, {"id": 1394, "seek": 633096, "start": 6330.96, "end": 6333.4800000000005, "text": " People very, very, very often think I'm saying something different.", "tokens": [3432, 588, 11, 588, 11, 588, 2049, 519, 286, 478, 1566, 746, 819, 13], "temperature": 0.0, "avg_logprob": -0.19446087827776917, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.922043156810105e-05}, {"id": 1395, "seek": 633096, "start": 6333.4800000000005, "end": 6335.72, "text": " I did not say they are of length 64.", "tokens": [286, 630, 406, 584, 436, 366, 295, 4641, 12145, 13], "temperature": 0.0, "avg_logprob": -0.19446087827776917, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.922043156810105e-05}, {"id": 1396, "seek": 633096, "start": 6335.72, "end": 6337.2, "text": " They're not.", "tokens": [814, 434, 406, 13], "temperature": 0.0, "avg_logprob": -0.19446087827776917, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.922043156810105e-05}, {"id": 1397, "seek": 633096, "start": 6337.2, "end": 6341.9, "text": " They're 64 equally sized roughly segments.", "tokens": [814, 434, 12145, 12309, 20004, 9810, 19904, 13], "temperature": 0.0, "avg_logprob": -0.19446087827776917, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.922043156810105e-05}, {"id": 1398, "seek": 633096, "start": 6341.9, "end": 6346.2, "text": " So we take the first 1.64th of the document, piece 1.", "tokens": [407, 321, 747, 264, 700, 502, 13, 19395, 392, 295, 264, 4166, 11, 2522, 502, 13], "temperature": 0.0, "avg_logprob": -0.19446087827776917, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.922043156810105e-05}, {"id": 1399, "seek": 633096, "start": 6346.2, "end": 6351.04, "text": " Second 64th, piece 2.", "tokens": [5736, 12145, 392, 11, 2522, 568, 13], "temperature": 0.0, "avg_logprob": -0.19446087827776917, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.922043156810105e-05}, {"id": 1400, "seek": 633096, "start": 6351.04, "end": 6358.08, "text": " And then for each of those 1.64th of the document, we then split those into pieces of length", "tokens": [400, 550, 337, 1184, 295, 729, 502, 13, 19395, 392, 295, 264, 4166, 11, 321, 550, 7472, 729, 666, 3755, 295, 4641], "temperature": 0.0, "avg_logprob": -0.19446087827776917, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.922043156810105e-05}, {"id": 1401, "seek": 633096, "start": 6358.08, "end": 6360.26, "text": " 70.", "tokens": [5285, 13], "temperature": 0.0, "avg_logprob": -0.19446087827776917, "compression_ratio": 1.6485148514851484, "no_speech_prob": 1.922043156810105e-05}, {"id": 1402, "seek": 636026, "start": 6360.26, "end": 6368.08, "text": " So each batch, so let's now say, OK, for those 13,000 tokens, how many batches are there?", "tokens": [407, 1184, 15245, 11, 370, 718, 311, 586, 584, 11, 2264, 11, 337, 729, 3705, 11, 1360, 22667, 11, 577, 867, 15245, 279, 366, 456, 30], "temperature": 0.0, "avg_logprob": -0.1408690969452603, "compression_ratio": 1.6705882352941177, "no_speech_prob": 1.0289030797139276e-05}, {"id": 1403, "seek": 636026, "start": 6368.08, "end": 6371.7, "text": " Well divide by batch size and divide by 70.", "tokens": [1042, 9845, 538, 15245, 2744, 293, 9845, 538, 5285, 13], "temperature": 0.0, "avg_logprob": -0.1408690969452603, "compression_ratio": 1.6705882352941177, "no_speech_prob": 1.0289030797139276e-05}, {"id": 1404, "seek": 636026, "start": 6371.7, "end": 6373.64, "text": " So there's about 2.9 batches.", "tokens": [407, 456, 311, 466, 568, 13, 24, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.1408690969452603, "compression_ratio": 1.6705882352941177, "no_speech_prob": 1.0289030797139276e-05}, {"id": 1405, "seek": 636026, "start": 6373.64, "end": 6375.9400000000005, "text": " So there's going to be three batches.", "tokens": [407, 456, 311, 516, 281, 312, 1045, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.1408690969452603, "compression_ratio": 1.6705882352941177, "no_speech_prob": 1.0289030797139276e-05}, {"id": 1406, "seek": 636026, "start": 6375.9400000000005, "end": 6378.7, "text": " So let's grab an iterator for our data loader.", "tokens": [407, 718, 311, 4444, 364, 17138, 1639, 337, 527, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.1408690969452603, "compression_ratio": 1.6705882352941177, "no_speech_prob": 1.0289030797139276e-05}, {"id": 1407, "seek": 636026, "start": 6378.7, "end": 6383.1, "text": " Grab one, two, three batches, the X and the Y.", "tokens": [20357, 472, 11, 732, 11, 1045, 15245, 279, 11, 264, 1783, 293, 264, 398, 13], "temperature": 0.0, "avg_logprob": -0.1408690969452603, "compression_ratio": 1.6705882352941177, "no_speech_prob": 1.0289030797139276e-05}, {"id": 1408, "seek": 636026, "start": 6383.1, "end": 6385.62, "text": " And let's add up the number of elements.", "tokens": [400, 718, 311, 909, 493, 264, 1230, 295, 4959, 13], "temperature": 0.0, "avg_logprob": -0.1408690969452603, "compression_ratio": 1.6705882352941177, "no_speech_prob": 1.0289030797139276e-05}, {"id": 1409, "seek": 636026, "start": 6385.62, "end": 6390.02, "text": " And we get back slightly less than this because there's a little bit left over at the end", "tokens": [400, 321, 483, 646, 4748, 1570, 813, 341, 570, 456, 311, 257, 707, 857, 1411, 670, 412, 264, 917], "temperature": 0.0, "avg_logprob": -0.1408690969452603, "compression_ratio": 1.6705882352941177, "no_speech_prob": 1.0289030797139276e-05}, {"id": 1410, "seek": 639002, "start": 6390.02, "end": 6394.320000000001, "text": " that doesn't quite make up a full batch.", "tokens": [300, 1177, 380, 1596, 652, 493, 257, 1577, 15245, 13], "temperature": 0.0, "avg_logprob": -0.12570808551929616, "compression_ratio": 1.522633744855967, "no_speech_prob": 2.601565938675776e-06}, {"id": 1411, "seek": 639002, "start": 6394.320000000001, "end": 6397.900000000001, "text": " So this is the kind of stuff you should play around with a lot, lots of shapes and sizes", "tokens": [407, 341, 307, 264, 733, 295, 1507, 291, 820, 862, 926, 365, 257, 688, 11, 3195, 295, 10854, 293, 11602], "temperature": 0.0, "avg_logprob": -0.12570808551929616, "compression_ratio": 1.522633744855967, "no_speech_prob": 2.601565938675776e-06}, {"id": 1412, "seek": 639002, "start": 6397.900000000001, "end": 6400.900000000001, "text": " and stuff and iterators.", "tokens": [293, 1507, 293, 17138, 3391, 13], "temperature": 0.0, "avg_logprob": -0.12570808551929616, "compression_ratio": 1.522633744855967, "no_speech_prob": 2.601565938675776e-06}, {"id": 1413, "seek": 639002, "start": 6400.900000000001, "end": 6403.6, "text": " As you can see, it's 95 by 64.", "tokens": [1018, 291, 393, 536, 11, 309, 311, 13420, 538, 12145, 13], "temperature": 0.0, "avg_logprob": -0.12570808551929616, "compression_ratio": 1.522633744855967, "no_speech_prob": 2.601565938675776e-06}, {"id": 1414, "seek": 639002, "start": 6403.6, "end": 6407.42, "text": " I claimed it was going to be 70 by 64.", "tokens": [286, 12941, 309, 390, 516, 281, 312, 5285, 538, 12145, 13], "temperature": 0.0, "avg_logprob": -0.12570808551929616, "compression_ratio": 1.522633744855967, "no_speech_prob": 2.601565938675776e-06}, {"id": 1415, "seek": 639002, "start": 6407.42, "end": 6413.9400000000005, "text": " That's because our data loader for language models slightly randomizes BPTT, just to give", "tokens": [663, 311, 570, 527, 1412, 3677, 260, 337, 2856, 5245, 4748, 4974, 5660, 40533, 28178, 11, 445, 281, 976], "temperature": 0.0, "avg_logprob": -0.12570808551929616, "compression_ratio": 1.522633744855967, "no_speech_prob": 2.601565938675776e-06}, {"id": 1416, "seek": 639002, "start": 6413.9400000000005, "end": 6417.22, "text": " you a bit more shuffling, get a bit more randomization.", "tokens": [291, 257, 857, 544, 402, 1245, 1688, 11, 483, 257, 857, 544, 4974, 2144, 13], "temperature": 0.0, "avg_logprob": -0.12570808551929616, "compression_ratio": 1.522633744855967, "no_speech_prob": 2.601565938675776e-06}, {"id": 1417, "seek": 641722, "start": 6417.22, "end": 6420.62, "text": " It helps the model.", "tokens": [467, 3665, 264, 2316, 13], "temperature": 0.0, "avg_logprob": -0.10795435774216958, "compression_ratio": 1.5952380952380953, "no_speech_prob": 1.1658771654765587e-05}, {"id": 1418, "seek": 641722, "start": 6420.62, "end": 6430.320000000001, "text": " And so here you can see the first batch of X. Remember we've numericalized all these.", "tokens": [400, 370, 510, 291, 393, 536, 264, 700, 15245, 295, 1783, 13, 5459, 321, 600, 29054, 1602, 439, 613, 13], "temperature": 0.0, "avg_logprob": -0.10795435774216958, "compression_ratio": 1.5952380952380953, "no_speech_prob": 1.1658771654765587e-05}, {"id": 1419, "seek": 641722, "start": 6430.320000000001, "end": 6432.14, "text": " And here's the first batch of Y.", "tokens": [400, 510, 311, 264, 700, 15245, 295, 398, 13], "temperature": 0.0, "avg_logprob": -0.10795435774216958, "compression_ratio": 1.5952380952380953, "no_speech_prob": 1.1658771654765587e-05}, {"id": 1420, "seek": 641722, "start": 6432.14, "end": 6435.62, "text": " And you'll see here this is 2, 18, 10, 11, 8.", "tokens": [400, 291, 603, 536, 510, 341, 307, 568, 11, 2443, 11, 1266, 11, 2975, 11, 1649, 13], "temperature": 0.0, "avg_logprob": -0.10795435774216958, "compression_ratio": 1.5952380952380953, "no_speech_prob": 1.1658771654765587e-05}, {"id": 1421, "seek": 641722, "start": 6435.62, "end": 6437.900000000001, "text": " This is 18, 10, 11, 8.", "tokens": [639, 307, 2443, 11, 1266, 11, 2975, 11, 1649, 13], "temperature": 0.0, "avg_logprob": -0.10795435774216958, "compression_ratio": 1.5952380952380953, "no_speech_prob": 1.1658771654765587e-05}, {"id": 1422, "seek": 641722, "start": 6437.900000000001, "end": 6443.46, "text": " So this one is offset by 1 from here because that's what we want to do with a language", "tokens": [407, 341, 472, 307, 18687, 538, 502, 490, 510, 570, 300, 311, 437, 321, 528, 281, 360, 365, 257, 2856], "temperature": 0.0, "avg_logprob": -0.10795435774216958, "compression_ratio": 1.5952380952380953, "no_speech_prob": 1.1658771654765587e-05}, {"id": 1423, "seek": 641722, "start": 6443.46, "end": 6444.46, "text": " model.", "tokens": [2316, 13], "temperature": 0.0, "avg_logprob": -0.10795435774216958, "compression_ratio": 1.5952380952380953, "no_speech_prob": 1.1658771654765587e-05}, {"id": 1424, "seek": 641722, "start": 6444.46, "end": 6447.06, "text": " We want to predict the next word.", "tokens": [492, 528, 281, 6069, 264, 958, 1349, 13], "temperature": 0.0, "avg_logprob": -0.10795435774216958, "compression_ratio": 1.5952380952380953, "no_speech_prob": 1.1658771654765587e-05}, {"id": 1425, "seek": 644706, "start": 6447.06, "end": 6449.900000000001, "text": " So after 2 should come after 18.", "tokens": [407, 934, 568, 820, 808, 934, 2443, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1426, "seek": 644706, "start": 6449.900000000001, "end": 6454.42, "text": " And after 18 should come 10.", "tokens": [400, 934, 2443, 820, 808, 1266, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1427, "seek": 644706, "start": 6454.42, "end": 6457.26, "text": " You can grab the vocab for this data set.", "tokens": [509, 393, 4444, 264, 2329, 455, 337, 341, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1428, "seek": 644706, "start": 6457.26, "end": 6459.04, "text": " And a vocab has a textify.", "tokens": [400, 257, 2329, 455, 575, 257, 2487, 2505, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1429, "seek": 644706, "start": 6459.04, "end": 6463.740000000001, "text": " So if we look at the same thing but with textify, that'll just look it up in the vocab.", "tokens": [407, 498, 321, 574, 412, 264, 912, 551, 457, 365, 2487, 2505, 11, 300, 603, 445, 574, 309, 493, 294, 264, 2329, 455, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1430, "seek": 644706, "start": 6463.740000000001, "end": 6467.660000000001, "text": " So here you can see XXBOS 8001.", "tokens": [407, 510, 291, 393, 536, 27050, 33, 4367, 13083, 16, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1431, "seek": 644706, "start": 6467.660000000001, "end": 6469.860000000001, "text": " Whereas in the Y, there's no XXBOS.", "tokens": [13813, 294, 264, 398, 11, 456, 311, 572, 27050, 33, 4367, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1432, "seek": 644706, "start": 6469.860000000001, "end": 6470.860000000001, "text": " It's just 8001.", "tokens": [467, 311, 445, 13083, 16, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1433, "seek": 644706, "start": 6470.860000000001, "end": 6473.3, "text": " So after XXBOS is 8.", "tokens": [407, 934, 27050, 33, 4367, 307, 1649, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1434, "seek": 644706, "start": 6473.3, "end": 6474.3, "text": " After 8 is 1000.", "tokens": [2381, 1649, 307, 9714, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1435, "seek": 644706, "start": 6474.3, "end": 6476.3, "text": " After 1000 is 1.", "tokens": [2381, 9714, 307, 502, 13], "temperature": 0.0, "avg_logprob": -0.2376323259793795, "compression_ratio": 1.708133971291866, "no_speech_prob": 2.0779751139343716e-05}, {"id": 1436, "seek": 647630, "start": 6476.3, "end": 6483.06, "text": " And so then after we get 8023 comes X2.", "tokens": [400, 370, 550, 934, 321, 483, 4688, 9356, 1487, 1783, 17, 13], "temperature": 0.0, "avg_logprob": -0.14981050844545718, "compression_ratio": 1.5665024630541873, "no_speech_prob": 9.818244507187046e-06}, {"id": 1437, "seek": 647630, "start": 6483.06, "end": 6484.06, "text": " And look at this.", "tokens": [400, 574, 412, 341, 13], "temperature": 0.0, "avg_logprob": -0.14981050844545718, "compression_ratio": 1.5665024630541873, "no_speech_prob": 9.818244507187046e-06}, {"id": 1438, "seek": 647630, "start": 6484.06, "end": 6485.14, "text": " We're always looking at column 0.", "tokens": [492, 434, 1009, 1237, 412, 7738, 1958, 13], "temperature": 0.0, "avg_logprob": -0.14981050844545718, "compression_ratio": 1.5665024630541873, "no_speech_prob": 9.818244507187046e-06}, {"id": 1439, "seek": 647630, "start": 6485.14, "end": 6488.74, "text": " So this is the first batch, the first mini-batch.", "tokens": [407, 341, 307, 264, 700, 15245, 11, 264, 700, 8382, 12, 65, 852, 13], "temperature": 0.0, "avg_logprob": -0.14981050844545718, "compression_ratio": 1.5665024630541873, "no_speech_prob": 9.818244507187046e-06}, {"id": 1440, "seek": 647630, "start": 6488.74, "end": 6490.74, "text": " Comes 8024.", "tokens": [47290, 4688, 7911, 13], "temperature": 0.0, "avg_logprob": -0.14981050844545718, "compression_ratio": 1.5665024630541873, "no_speech_prob": 9.818244507187046e-06}, {"id": 1441, "seek": 647630, "start": 6490.74, "end": 6495.54, "text": " And then X3 all the way up to 8040.", "tokens": [400, 550, 1783, 18, 439, 264, 636, 493, 281, 4688, 5254, 13], "temperature": 0.0, "avg_logprob": -0.14981050844545718, "compression_ratio": 1.5665024630541873, "no_speech_prob": 9.818244507187046e-06}, {"id": 1442, "seek": 647630, "start": 6495.54, "end": 6501.4800000000005, "text": " And so then we can go right back to the start but look at batch 1.", "tokens": [400, 370, 550, 321, 393, 352, 558, 646, 281, 264, 722, 457, 574, 412, 15245, 502, 13], "temperature": 0.0, "avg_logprob": -0.14981050844545718, "compression_ratio": 1.5665024630541873, "no_speech_prob": 9.818244507187046e-06}, {"id": 1443, "seek": 647630, "start": 6501.4800000000005, "end": 6503.820000000001, "text": " So index 1, which is batch number 2.", "tokens": [407, 8186, 502, 11, 597, 307, 15245, 1230, 568, 13], "temperature": 0.0, "avg_logprob": -0.14981050844545718, "compression_ratio": 1.5665024630541873, "no_speech_prob": 9.818244507187046e-06}, {"id": 1444, "seek": 647630, "start": 6503.820000000001, "end": 6505.54, "text": " And now we can continue.", "tokens": [400, 586, 321, 393, 2354, 13], "temperature": 0.0, "avg_logprob": -0.14981050844545718, "compression_ratio": 1.5665024630541873, "no_speech_prob": 9.818244507187046e-06}, {"id": 1445, "seek": 650554, "start": 6505.54, "end": 6508.9, "text": " A slight skip from 8040 to 8046.", "tokens": [316, 4036, 10023, 490, 4688, 5254, 281, 4688, 16169, 13], "temperature": 0.0, "avg_logprob": -0.16596102281050248, "compression_ratio": 1.4954954954954955, "no_speech_prob": 6.540091362694511e-06}, {"id": 1446, "seek": 650554, "start": 6508.9, "end": 6512.28, "text": " That's because the last mini-batch wasn't quite complete.", "tokens": [663, 311, 570, 264, 1036, 8382, 12, 65, 852, 2067, 380, 1596, 3566, 13], "temperature": 0.0, "avg_logprob": -0.16596102281050248, "compression_ratio": 1.4954954954954955, "no_speech_prob": 6.540091362694511e-06}, {"id": 1447, "seek": 650554, "start": 6512.28, "end": 6521.82, "text": " So what this means is that every mini-batch joins up with the previous mini-batch.", "tokens": [407, 437, 341, 1355, 307, 300, 633, 8382, 12, 65, 852, 24397, 493, 365, 264, 3894, 8382, 12, 65, 852, 13], "temperature": 0.0, "avg_logprob": -0.16596102281050248, "compression_ratio": 1.4954954954954955, "no_speech_prob": 6.540091362694511e-06}, {"id": 1448, "seek": 650554, "start": 6521.82, "end": 6525.46, "text": " So you can go straight from X1, 0 to X2, 0.", "tokens": [407, 291, 393, 352, 2997, 490, 1783, 16, 11, 1958, 281, 1783, 17, 11, 1958, 13], "temperature": 0.0, "avg_logprob": -0.16596102281050248, "compression_ratio": 1.4954954954954955, "no_speech_prob": 6.540091362694511e-06}, {"id": 1449, "seek": 650554, "start": 6525.46, "end": 6526.46, "text": " It continues.", "tokens": [467, 6515, 13], "temperature": 0.0, "avg_logprob": -0.16596102281050248, "compression_ratio": 1.4954954954954955, "no_speech_prob": 6.540091362694511e-06}, {"id": 1450, "seek": 650554, "start": 6526.46, "end": 6527.46, "text": " 8023, 8024.", "tokens": [4688, 9356, 11, 4688, 7911, 13], "temperature": 0.0, "avg_logprob": -0.16596102281050248, "compression_ratio": 1.4954954954954955, "no_speech_prob": 6.540091362694511e-06}, {"id": 1451, "seek": 650554, "start": 6527.46, "end": 6534.94, "text": " And so if you look at the same thing for column, comma, 1, you'll also see they join up.", "tokens": [400, 370, 498, 291, 574, 412, 264, 912, 551, 337, 7738, 11, 22117, 11, 502, 11, 291, 603, 611, 536, 436, 3917, 493, 13], "temperature": 0.0, "avg_logprob": -0.16596102281050248, "compression_ratio": 1.4954954954954955, "no_speech_prob": 6.540091362694511e-06}, {"id": 1452, "seek": 653494, "start": 6534.94, "end": 6538.98, "text": " So all the mini-batches join up.", "tokens": [407, 439, 264, 8382, 12, 65, 852, 279, 3917, 493, 13], "temperature": 0.0, "avg_logprob": -0.14834898915784112, "compression_ratio": 1.3387096774193548, "no_speech_prob": 1.3496198789653135e-06}, {"id": 1453, "seek": 653494, "start": 6538.98, "end": 6540.339999999999, "text": " So that's the data.", "tokens": [407, 300, 311, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.14834898915784112, "compression_ratio": 1.3387096774193548, "no_speech_prob": 1.3496198789653135e-06}, {"id": 1454, "seek": 653494, "start": 6540.339999999999, "end": 6542.94, "text": " We can do show batch to see it.", "tokens": [492, 393, 360, 855, 15245, 281, 536, 309, 13], "temperature": 0.0, "avg_logprob": -0.14834898915784112, "compression_ratio": 1.3387096774193548, "no_speech_prob": 1.3496198789653135e-06}, {"id": 1455, "seek": 653494, "start": 6542.94, "end": 6552.98, "text": " And here is our model, which is doing this.", "tokens": [400, 510, 307, 527, 2316, 11, 597, 307, 884, 341, 13], "temperature": 0.0, "avg_logprob": -0.14834898915784112, "compression_ratio": 1.3387096774193548, "no_speech_prob": 1.3496198789653135e-06}, {"id": 1456, "seek": 653494, "start": 6552.98, "end": 6561.32, "text": " So here is just the code copied over.", "tokens": [407, 510, 307, 445, 264, 3089, 25365, 670, 13], "temperature": 0.0, "avg_logprob": -0.14834898915784112, "compression_ratio": 1.3387096774193548, "no_speech_prob": 1.3496198789653135e-06}, {"id": 1457, "seek": 656132, "start": 6561.32, "end": 6572.259999999999, "text": " So it contains one embedding, i.e. the green arrow, one hidden to hidden brown arrow layer,", "tokens": [407, 309, 8306, 472, 12240, 3584, 11, 741, 13, 68, 13, 264, 3092, 11610, 11, 472, 7633, 281, 7633, 6292, 11610, 4583, 11], "temperature": 0.0, "avg_logprob": -0.13540207585201988, "compression_ratio": 1.652694610778443, "no_speech_prob": 3.611947704484919e-06}, {"id": 1458, "seek": 656132, "start": 6572.259999999999, "end": 6574.179999999999, "text": " and one hidden to output.", "tokens": [293, 472, 7633, 281, 5598, 13], "temperature": 0.0, "avg_logprob": -0.13540207585201988, "compression_ratio": 1.652694610778443, "no_speech_prob": 3.611947704484919e-06}, {"id": 1459, "seek": 656132, "start": 6574.179999999999, "end": 6580.84, "text": " So each coloured arrow has a single matrix.", "tokens": [407, 1184, 42042, 11610, 575, 257, 2167, 8141, 13], "temperature": 0.0, "avg_logprob": -0.13540207585201988, "compression_ratio": 1.652694610778443, "no_speech_prob": 3.611947704484919e-06}, {"id": 1460, "seek": 656132, "start": 6580.84, "end": 6587.0, "text": " And so then in the forward pass, we take our first input, X0, and put it through input", "tokens": [400, 370, 550, 294, 264, 2128, 1320, 11, 321, 747, 527, 700, 4846, 11, 1783, 15, 11, 293, 829, 309, 807, 4846], "temperature": 0.0, "avg_logprob": -0.13540207585201988, "compression_ratio": 1.652694610778443, "no_speech_prob": 3.611947704484919e-06}, {"id": 1461, "seek": 656132, "start": 6587.0, "end": 6589.5, "text": " to hidden, the green arrow.", "tokens": [281, 7633, 11, 264, 3092, 11610, 13], "temperature": 0.0, "avg_logprob": -0.13540207585201988, "compression_ratio": 1.652694610778443, "no_speech_prob": 3.611947704484919e-06}, {"id": 1462, "seek": 658950, "start": 6589.5, "end": 6596.3, "text": " Create our first set of activations, which we call H. Assuming that there is a second", "tokens": [20248, 527, 700, 992, 295, 2430, 763, 11, 597, 321, 818, 389, 13, 6281, 24919, 300, 456, 307, 257, 1150], "temperature": 0.0, "avg_logprob": -0.14501984148140412, "compression_ratio": 1.6284153005464481, "no_speech_prob": 1.0782911886053625e-05}, {"id": 1463, "seek": 658950, "start": 6596.3, "end": 6600.06, "text": " word, because sometimes we might be at the end of a batch where there isn't a second", "tokens": [1349, 11, 570, 2171, 321, 1062, 312, 412, 264, 917, 295, 257, 15245, 689, 456, 1943, 380, 257, 1150], "temperature": 0.0, "avg_logprob": -0.14501984148140412, "compression_ratio": 1.6284153005464481, "no_speech_prob": 1.0782911886053625e-05}, {"id": 1464, "seek": 658950, "start": 6600.06, "end": 6606.7, "text": " word, assuming there is a second word, then we would add to H the result of X1 put through", "tokens": [1349, 11, 11926, 456, 307, 257, 1150, 1349, 11, 550, 321, 576, 909, 281, 389, 264, 1874, 295, 1783, 16, 829, 807], "temperature": 0.0, "avg_logprob": -0.14501984148140412, "compression_ratio": 1.6284153005464481, "no_speech_prob": 1.0782911886053625e-05}, {"id": 1465, "seek": 658950, "start": 6606.7, "end": 6607.7, "text": " the green arrow.", "tokens": [264, 3092, 11610, 13], "temperature": 0.0, "avg_logprob": -0.14501984148140412, "compression_ratio": 1.6284153005464481, "no_speech_prob": 1.0782911886053625e-05}, {"id": 1466, "seek": 658950, "start": 6607.7, "end": 6611.94, "text": " Remember that's iH.", "tokens": [5459, 300, 311, 741, 39, 13], "temperature": 0.0, "avg_logprob": -0.14501984148140412, "compression_ratio": 1.6284153005464481, "no_speech_prob": 1.0782911886053625e-05}, {"id": 1467, "seek": 661194, "start": 6611.94, "end": 6620.9, "text": " And then we would say, OK, our new H is the result of those two added together, put through", "tokens": [400, 550, 321, 576, 584, 11, 2264, 11, 527, 777, 389, 307, 264, 1874, 295, 729, 732, 3869, 1214, 11, 829, 807], "temperature": 0.0, "avg_logprob": -0.14911818990902026, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.084511154658685e-06}, {"id": 1468, "seek": 661194, "start": 6620.9, "end": 6625.0599999999995, "text": " our hidden to hidden, orange arrow, and then ReLU, then batched on.", "tokens": [527, 7633, 281, 7633, 11, 7671, 11610, 11, 293, 550, 1300, 43, 52, 11, 550, 15245, 292, 322, 13], "temperature": 0.0, "avg_logprob": -0.14911818990902026, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.084511154658685e-06}, {"id": 1469, "seek": 661194, "start": 6625.0599999999995, "end": 6628.679999999999, "text": " And then for the second word, do exactly the same thing.", "tokens": [400, 550, 337, 264, 1150, 1349, 11, 360, 2293, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.14911818990902026, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.084511154658685e-06}, {"id": 1470, "seek": 661194, "start": 6628.679999999999, "end": 6632.099999999999, "text": " And then finally, blue arrow, put it through HO.", "tokens": [400, 550, 2721, 11, 3344, 11610, 11, 829, 309, 807, 23097, 13], "temperature": 0.0, "avg_logprob": -0.14911818990902026, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.084511154658685e-06}, {"id": 1471, "seek": 661194, "start": 6632.099999999999, "end": 6636.299999999999, "text": " So that's how we convert our diagram to code.", "tokens": [407, 300, 311, 577, 321, 7620, 527, 10686, 281, 3089, 13], "temperature": 0.0, "avg_logprob": -0.14911818990902026, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.084511154658685e-06}, {"id": 1472, "seek": 661194, "start": 6636.299999999999, "end": 6641.5, "text": " So nothing new here at all.", "tokens": [407, 1825, 777, 510, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.14911818990902026, "compression_ratio": 1.6066350710900474, "no_speech_prob": 1.084511154658685e-06}, {"id": 1473, "seek": 664150, "start": 6641.5, "end": 6649.1, "text": " So now let's do, and just so we can chuck that in the learner and we can train it, 46%.", "tokens": [407, 586, 718, 311, 360, 11, 293, 445, 370, 321, 393, 20870, 300, 294, 264, 33347, 293, 321, 393, 3847, 309, 11, 17835, 6856], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1474, "seek": 664150, "start": 6649.1, "end": 6652.82, "text": " Let's take this code and recognise it's pretty awful.", "tokens": [961, 311, 747, 341, 3089, 293, 23991, 309, 311, 1238, 11232, 13], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1475, "seek": 664150, "start": 6652.82, "end": 6654.34, "text": " There's a lot of duplicate code.", "tokens": [821, 311, 257, 688, 295, 23976, 3089, 13], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1476, "seek": 664150, "start": 6654.34, "end": 6657.1, "text": " And as coders, when we see duplicate code, what do we do?", "tokens": [400, 382, 17656, 433, 11, 562, 321, 536, 23976, 3089, 11, 437, 360, 321, 360, 30], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1477, "seek": 664150, "start": 6657.1, "end": 6658.22, "text": " We refactor.", "tokens": [492, 1895, 15104, 13], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1478, "seek": 664150, "start": 6658.22, "end": 6661.7, "text": " So we should refactor this into a loop.", "tokens": [407, 321, 820, 1895, 15104, 341, 666, 257, 6367, 13], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1479, "seek": 664150, "start": 6661.7, "end": 6662.7, "text": " So here we are.", "tokens": [407, 510, 321, 366, 13], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1480, "seek": 664150, "start": 6662.7, "end": 6664.76, "text": " We've refactored it into a loop.", "tokens": [492, 600, 1895, 578, 2769, 309, 666, 257, 6367, 13], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1481, "seek": 664150, "start": 6664.76, "end": 6668.3, "text": " So now we're going for each X, i, and X, and doing it in the loop.", "tokens": [407, 586, 321, 434, 516, 337, 1184, 1783, 11, 741, 11, 293, 1783, 11, 293, 884, 309, 294, 264, 6367, 13], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1482, "seek": 664150, "start": 6668.3, "end": 6670.22, "text": " Guess what?", "tokens": [17795, 437, 30], "temperature": 0.0, "avg_logprob": -0.15662642584906683, "compression_ratio": 1.7208333333333334, "no_speech_prob": 4.860260105488123e-06}, {"id": 1483, "seek": 667022, "start": 6670.22, "end": 6672.1, "text": " That's an RNN.", "tokens": [663, 311, 364, 45702, 45, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1484, "seek": 667022, "start": 6672.1, "end": 6675.860000000001, "text": " An RNN is just a refactoring.", "tokens": [1107, 45702, 45, 307, 445, 257, 1895, 578, 3662, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1485, "seek": 667022, "start": 6675.860000000001, "end": 6678.92, "text": " It's not anything new.", "tokens": [467, 311, 406, 1340, 777, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1486, "seek": 667022, "start": 6678.92, "end": 6682.06, "text": " This is now an RNN.", "tokens": [639, 307, 586, 364, 45702, 45, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1487, "seek": 667022, "start": 6682.06, "end": 6687.34, "text": " And let's refactor our diagram from this to this.", "tokens": [400, 718, 311, 1895, 15104, 527, 10686, 490, 341, 281, 341, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1488, "seek": 667022, "start": 6687.34, "end": 6688.900000000001, "text": " This is the same diagram.", "tokens": [639, 307, 264, 912, 10686, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1489, "seek": 667022, "start": 6688.900000000001, "end": 6693.18, "text": " But I've just replaced it with my loop.", "tokens": [583, 286, 600, 445, 10772, 309, 365, 452, 6367, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1490, "seek": 667022, "start": 6693.18, "end": 6695.9400000000005, "text": " It does the same thing.", "tokens": [467, 775, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1491, "seek": 667022, "start": 6695.9400000000005, "end": 6696.9400000000005, "text": " So here it is.", "tokens": [407, 510, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1492, "seek": 667022, "start": 6696.9400000000005, "end": 6699.58, "text": " It's got exactly the same in it, literally exactly the same.", "tokens": [467, 311, 658, 2293, 264, 912, 294, 309, 11, 3736, 2293, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.1294044439609234, "compression_ratio": 1.6833333333333333, "no_speech_prob": 5.862530997546855e-06}, {"id": 1493, "seek": 669958, "start": 6699.58, "end": 6701.38, "text": " Just popped a loop here.", "tokens": [1449, 21545, 257, 6367, 510, 13], "temperature": 0.0, "avg_logprob": -0.14235011014071378, "compression_ratio": 1.6605839416058394, "no_speech_prob": 2.1443833247758448e-05}, {"id": 1494, "seek": 669958, "start": 6701.38, "end": 6706.94, "text": " Before I start, I just have to make sure that I've got a bunch of zeros to add to.", "tokens": [4546, 286, 722, 11, 286, 445, 362, 281, 652, 988, 300, 286, 600, 658, 257, 3840, 295, 35193, 281, 909, 281, 13], "temperature": 0.0, "avg_logprob": -0.14235011014071378, "compression_ratio": 1.6605839416058394, "no_speech_prob": 2.1443833247758448e-05}, {"id": 1495, "seek": 669958, "start": 6706.94, "end": 6711.14, "text": " And of course, I get exactly the same result when I train it.", "tokens": [400, 295, 1164, 11, 286, 483, 2293, 264, 912, 1874, 562, 286, 3847, 309, 13], "temperature": 0.0, "avg_logprob": -0.14235011014071378, "compression_ratio": 1.6605839416058394, "no_speech_prob": 2.1443833247758448e-05}, {"id": 1496, "seek": 669958, "start": 6711.14, "end": 6715.78, "text": " So next thing that you might think then, and one nice thing about the loop, though, is", "tokens": [407, 958, 551, 300, 291, 1062, 519, 550, 11, 293, 472, 1481, 551, 466, 264, 6367, 11, 1673, 11, 307], "temperature": 0.0, "avg_logprob": -0.14235011014071378, "compression_ratio": 1.6605839416058394, "no_speech_prob": 2.1443833247758448e-05}, {"id": 1497, "seek": 669958, "start": 6715.78, "end": 6720.18, "text": " now this will work even if I'm not predicting the fourth word from the previous three, but", "tokens": [586, 341, 486, 589, 754, 498, 286, 478, 406, 32884, 264, 6409, 1349, 490, 264, 3894, 1045, 11, 457], "temperature": 0.0, "avg_logprob": -0.14235011014071378, "compression_ratio": 1.6605839416058394, "no_speech_prob": 2.1443833247758448e-05}, {"id": 1498, "seek": 669958, "start": 6720.18, "end": 6721.82, "text": " the ninth word from the previous eight.", "tokens": [264, 28207, 1349, 490, 264, 3894, 3180, 13], "temperature": 0.0, "avg_logprob": -0.14235011014071378, "compression_ratio": 1.6605839416058394, "no_speech_prob": 2.1443833247758448e-05}, {"id": 1499, "seek": 669958, "start": 6721.82, "end": 6726.62, "text": " It'll work for any arbitrarily length long sequence, which is nice.", "tokens": [467, 603, 589, 337, 604, 19071, 3289, 4641, 938, 8310, 11, 597, 307, 1481, 13], "temperature": 0.0, "avg_logprob": -0.14235011014071378, "compression_ratio": 1.6605839416058394, "no_speech_prob": 2.1443833247758448e-05}, {"id": 1500, "seek": 672662, "start": 6726.62, "end": 6731.62, "text": " So let's up the BPTT to 20, since we can now.", "tokens": [407, 718, 311, 493, 264, 40533, 28178, 281, 945, 11, 1670, 321, 393, 586, 13], "temperature": 0.0, "avg_logprob": -0.1337913770354196, "compression_ratio": 1.6737967914438503, "no_speech_prob": 5.014579073758796e-06}, {"id": 1501, "seek": 672662, "start": 6731.62, "end": 6744.3, "text": " And let's now say, OK, instead of just predicting the nth word from the previous n minus 1,", "tokens": [400, 718, 311, 586, 584, 11, 2264, 11, 2602, 295, 445, 32884, 264, 297, 392, 1349, 490, 264, 3894, 297, 3175, 502, 11], "temperature": 0.0, "avg_logprob": -0.1337913770354196, "compression_ratio": 1.6737967914438503, "no_speech_prob": 5.014579073758796e-06}, {"id": 1502, "seek": 672662, "start": 6744.3, "end": 6747.5, "text": " let's try to predict the second word from the first, and the third from the second,", "tokens": [718, 311, 853, 281, 6069, 264, 1150, 1349, 490, 264, 700, 11, 293, 264, 2636, 490, 264, 1150, 11], "temperature": 0.0, "avg_logprob": -0.1337913770354196, "compression_ratio": 1.6737967914438503, "no_speech_prob": 5.014579073758796e-06}, {"id": 1503, "seek": 672662, "start": 6747.5, "end": 6749.78, "text": " and the fourth from the third, and so forth.", "tokens": [293, 264, 6409, 490, 264, 2636, 11, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.1337913770354196, "compression_ratio": 1.6737967914438503, "no_speech_prob": 5.014579073758796e-06}, {"id": 1504, "seek": 672662, "start": 6749.78, "end": 6752.26, "text": " Because previously, look at our loss function.", "tokens": [1436, 8046, 11, 574, 412, 527, 4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1337913770354196, "compression_ratio": 1.6737967914438503, "no_speech_prob": 5.014579073758796e-06}, {"id": 1505, "seek": 675226, "start": 6752.26, "end": 6757.34, "text": " Previously we were comparing the result of our model to just the last word of the sequence.", "tokens": [33606, 321, 645, 15763, 264, 1874, 295, 527, 2316, 281, 445, 264, 1036, 1349, 295, 264, 8310, 13], "temperature": 0.0, "avg_logprob": -0.1228030522664388, "compression_ratio": 1.8777292576419213, "no_speech_prob": 1.221857382915914e-05}, {"id": 1506, "seek": 675226, "start": 6757.34, "end": 6760.66, "text": " It's just very wasteful, because there's a lot of words in the sequence.", "tokens": [467, 311, 445, 588, 5964, 906, 11, 570, 456, 311, 257, 688, 295, 2283, 294, 264, 8310, 13], "temperature": 0.0, "avg_logprob": -0.1228030522664388, "compression_ratio": 1.8777292576419213, "no_speech_prob": 1.221857382915914e-05}, {"id": 1507, "seek": 675226, "start": 6760.66, "end": 6765.780000000001, "text": " So let's compare every word in x to every word in y.", "tokens": [407, 718, 311, 6794, 633, 1349, 294, 2031, 281, 633, 1349, 294, 288, 13], "temperature": 0.0, "avg_logprob": -0.1228030522664388, "compression_ratio": 1.8777292576419213, "no_speech_prob": 1.221857382915914e-05}, {"id": 1508, "seek": 675226, "start": 6765.780000000001, "end": 6771.62, "text": " So to do that, we need to change this so it's not just one triangle at the end of the loop,", "tokens": [407, 281, 360, 300, 11, 321, 643, 281, 1319, 341, 370, 309, 311, 406, 445, 472, 13369, 412, 264, 917, 295, 264, 6367, 11], "temperature": 0.0, "avg_logprob": -0.1228030522664388, "compression_ratio": 1.8777292576419213, "no_speech_prob": 1.221857382915914e-05}, {"id": 1509, "seek": 675226, "start": 6771.62, "end": 6775.4800000000005, "text": " but the triangle is inside this, right?", "tokens": [457, 264, 13369, 307, 1854, 341, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1228030522664388, "compression_ratio": 1.8777292576419213, "no_speech_prob": 1.221857382915914e-05}, {"id": 1510, "seek": 675226, "start": 6775.4800000000005, "end": 6781.66, "text": " So that in other words, after every loop, predict, loop, predict, loop, predict.", "tokens": [407, 300, 294, 661, 2283, 11, 934, 633, 6367, 11, 6069, 11, 6367, 11, 6069, 11, 6367, 11, 6069, 13], "temperature": 0.0, "avg_logprob": -0.1228030522664388, "compression_ratio": 1.8777292576419213, "no_speech_prob": 1.221857382915914e-05}, {"id": 1511, "seek": 678166, "start": 6781.66, "end": 6786.3, "text": " So here's this code.", "tokens": [407, 510, 311, 341, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1340552196707777, "compression_ratio": 1.4742268041237114, "no_speech_prob": 8.013344086066354e-06}, {"id": 1512, "seek": 678166, "start": 6786.3, "end": 6789.84, "text": " It's the same as the previous code, but now I've created an array.", "tokens": [467, 311, 264, 912, 382, 264, 3894, 3089, 11, 457, 586, 286, 600, 2942, 364, 10225, 13], "temperature": 0.0, "avg_logprob": -0.1340552196707777, "compression_ratio": 1.4742268041237114, "no_speech_prob": 8.013344086066354e-06}, {"id": 1513, "seek": 678166, "start": 6789.84, "end": 6795.22, "text": " And every time I go through the loop, I append ho, h to the array.", "tokens": [400, 633, 565, 286, 352, 807, 264, 6367, 11, 286, 34116, 1106, 11, 276, 281, 264, 10225, 13], "temperature": 0.0, "avg_logprob": -0.1340552196707777, "compression_ratio": 1.4742268041237114, "no_speech_prob": 8.013344086066354e-06}, {"id": 1514, "seek": 678166, "start": 6795.22, "end": 6798.74, "text": " So now for n inputs, I create n outputs.", "tokens": [407, 586, 337, 297, 15743, 11, 286, 1884, 297, 23930, 13], "temperature": 0.0, "avg_logprob": -0.1340552196707777, "compression_ratio": 1.4742268041237114, "no_speech_prob": 8.013344086066354e-06}, {"id": 1515, "seek": 678166, "start": 6798.74, "end": 6801.0199999999995, "text": " So I'm predicting after every word.", "tokens": [407, 286, 478, 32884, 934, 633, 1349, 13], "temperature": 0.0, "avg_logprob": -0.1340552196707777, "compression_ratio": 1.4742268041237114, "no_speech_prob": 8.013344086066354e-06}, {"id": 1516, "seek": 678166, "start": 6801.0199999999995, "end": 6803.66, "text": " Previously I had 46%.", "tokens": [33606, 286, 632, 17835, 6856], "temperature": 0.0, "avg_logprob": -0.1340552196707777, "compression_ratio": 1.4742268041237114, "no_speech_prob": 8.013344086066354e-06}, {"id": 1517, "seek": 678166, "start": 6803.66, "end": 6805.86, "text": " Now I have 40%.", "tokens": [823, 286, 362, 3356, 6856], "temperature": 0.0, "avg_logprob": -0.1340552196707777, "compression_ratio": 1.4742268041237114, "no_speech_prob": 8.013344086066354e-06}, {"id": 1518, "seek": 678166, "start": 6805.86, "end": 6806.86, "text": " Why is it worse?", "tokens": [1545, 307, 309, 5324, 30], "temperature": 0.0, "avg_logprob": -0.1340552196707777, "compression_ratio": 1.4742268041237114, "no_speech_prob": 8.013344086066354e-06}, {"id": 1519, "seek": 680686, "start": 6806.86, "end": 6813.0599999999995, "text": " Well, it's worse because now, when I'm trying to predict the second word, I only have one", "tokens": [1042, 11, 309, 311, 5324, 570, 586, 11, 562, 286, 478, 1382, 281, 6069, 264, 1150, 1349, 11, 286, 787, 362, 472], "temperature": 0.0, "avg_logprob": -0.18299378104831862, "compression_ratio": 1.7117903930131004, "no_speech_prob": 5.338039500202285e-06}, {"id": 1520, "seek": 680686, "start": 6813.0599999999995, "end": 6815.98, "text": " word of state to use.", "tokens": [1349, 295, 1785, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.18299378104831862, "compression_ratio": 1.7117903930131004, "no_speech_prob": 5.338039500202285e-06}, {"id": 1521, "seek": 680686, "start": 6815.98, "end": 6820.46, "text": " So when I'm looking at the third word, I only have two words of state to use.", "tokens": [407, 562, 286, 478, 1237, 412, 264, 2636, 1349, 11, 286, 787, 362, 732, 2283, 295, 1785, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.18299378104831862, "compression_ratio": 1.7117903930131004, "no_speech_prob": 5.338039500202285e-06}, {"id": 1522, "seek": 680686, "start": 6820.46, "end": 6823.9, "text": " So it's a much harder problem for it to solve.", "tokens": [407, 309, 311, 257, 709, 6081, 1154, 337, 309, 281, 5039, 13], "temperature": 0.0, "avg_logprob": -0.18299378104831862, "compression_ratio": 1.7117903930131004, "no_speech_prob": 5.338039500202285e-06}, {"id": 1523, "seek": 680686, "start": 6823.9, "end": 6827.98, "text": " So the obvious way to fix this then, the key problem is here.", "tokens": [407, 264, 6322, 636, 281, 3191, 341, 550, 11, 264, 2141, 1154, 307, 510, 13], "temperature": 0.0, "avg_logprob": -0.18299378104831862, "compression_ratio": 1.7117903930131004, "no_speech_prob": 5.338039500202285e-06}, {"id": 1524, "seek": 680686, "start": 6827.98, "end": 6830.099999999999, "text": " I go h equals torch.zeros.", "tokens": [286, 352, 276, 6915, 27822, 13, 4527, 329, 13], "temperature": 0.0, "avg_logprob": -0.18299378104831862, "compression_ratio": 1.7117903930131004, "no_speech_prob": 5.338039500202285e-06}, {"id": 1525, "seek": 680686, "start": 6830.099999999999, "end": 6836.58, "text": " I reset my state to zero every time I start another BPTT sequence.", "tokens": [286, 14322, 452, 1785, 281, 4018, 633, 565, 286, 722, 1071, 40533, 28178, 8310, 13], "temperature": 0.0, "avg_logprob": -0.18299378104831862, "compression_ratio": 1.7117903930131004, "no_speech_prob": 5.338039500202285e-06}, {"id": 1526, "seek": 683658, "start": 6836.58, "end": 6838.18, "text": " Well let's not do that.", "tokens": [1042, 718, 311, 406, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1527, "seek": 683658, "start": 6838.18, "end": 6839.18, "text": " Let's keep h.", "tokens": [961, 311, 1066, 276, 13], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1528, "seek": 683658, "start": 6839.18, "end": 6844.1, "text": " And we can, because remember each batch connects to the previous batch.", "tokens": [400, 321, 393, 11, 570, 1604, 1184, 15245, 16967, 281, 264, 3894, 15245, 13], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1529, "seek": 683658, "start": 6844.1, "end": 6849.0599999999995, "text": " It's not shuffled like happens in image classification.", "tokens": [467, 311, 406, 402, 33974, 411, 2314, 294, 3256, 21538, 13], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1530, "seek": 683658, "start": 6849.0599999999995, "end": 6853.5, "text": " So let's take this exact model and replicate it again, but let's move the creation of h", "tokens": [407, 718, 311, 747, 341, 1900, 2316, 293, 25356, 309, 797, 11, 457, 718, 311, 1286, 264, 8016, 295, 276], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1531, "seek": 683658, "start": 6853.5, "end": 6854.5, "text": " into the constructor.", "tokens": [666, 264, 47479, 13], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1532, "seek": 683658, "start": 6854.5, "end": 6857.0599999999995, "text": " Okay, there it is.", "tokens": [1033, 11, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1533, "seek": 683658, "start": 6857.0599999999995, "end": 6859.34, "text": " So it's now self.h.", "tokens": [407, 309, 311, 586, 2698, 13, 71, 13], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1534, "seek": 683658, "start": 6859.34, "end": 6863.54, "text": " And so this is now exactly the same code, but at the end, let's put the new h back into", "tokens": [400, 370, 341, 307, 586, 2293, 264, 912, 3089, 11, 457, 412, 264, 917, 11, 718, 311, 829, 264, 777, 276, 646, 666], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1535, "seek": 683658, "start": 6863.54, "end": 6864.54, "text": " self.h.", "tokens": [2698, 13, 71, 13], "temperature": 0.0, "avg_logprob": -0.1351162233660298, "compression_ratio": 1.6942148760330578, "no_speech_prob": 2.1781559553346597e-05}, {"id": 1536, "seek": 686454, "start": 6864.54, "end": 6870.42, "text": " So it's now doing the same thing, but it's not throwing away that state.", "tokens": [407, 309, 311, 586, 884, 264, 912, 551, 11, 457, 309, 311, 406, 10238, 1314, 300, 1785, 13], "temperature": 0.0, "avg_logprob": -0.15499022483825683, "compression_ratio": 1.5560344827586208, "no_speech_prob": 3.187549964422942e-06}, {"id": 1537, "seek": 686454, "start": 6870.42, "end": 6874.54, "text": " And so therefore now we actually get above the original.", "tokens": [400, 370, 4412, 586, 321, 767, 483, 3673, 264, 3380, 13], "temperature": 0.0, "avg_logprob": -0.15499022483825683, "compression_ratio": 1.5560344827586208, "no_speech_prob": 3.187549964422942e-06}, {"id": 1538, "seek": 686454, "start": 6874.54, "end": 6877.86, "text": " We get all the way up to 54% accuracy.", "tokens": [492, 483, 439, 264, 636, 493, 281, 20793, 4, 14170, 13], "temperature": 0.0, "avg_logprob": -0.15499022483825683, "compression_ratio": 1.5560344827586208, "no_speech_prob": 3.187549964422942e-06}, {"id": 1539, "seek": 686454, "start": 6877.86, "end": 6883.14, "text": " So this is what a real RNN looks like.", "tokens": [407, 341, 307, 437, 257, 957, 45702, 45, 1542, 411, 13], "temperature": 0.0, "avg_logprob": -0.15499022483825683, "compression_ratio": 1.5560344827586208, "no_speech_prob": 3.187549964422942e-06}, {"id": 1540, "seek": 686454, "start": 6883.14, "end": 6886.34, "text": " You always want to keep that state.", "tokens": [509, 1009, 528, 281, 1066, 300, 1785, 13], "temperature": 0.0, "avg_logprob": -0.15499022483825683, "compression_ratio": 1.5560344827586208, "no_speech_prob": 3.187549964422942e-06}, {"id": 1541, "seek": 686454, "start": 6886.34, "end": 6889.62, "text": " But just keep remembering, there's nothing different about an RNN.", "tokens": [583, 445, 1066, 20719, 11, 456, 311, 1825, 819, 466, 364, 45702, 45, 13], "temperature": 0.0, "avg_logprob": -0.15499022483825683, "compression_ratio": 1.5560344827586208, "no_speech_prob": 3.187549964422942e-06}, {"id": 1542, "seek": 686454, "start": 6889.62, "end": 6892.5, "text": " It's a totally normal, fully connected neural net.", "tokens": [467, 311, 257, 3879, 2710, 11, 4498, 4582, 18161, 2533, 13], "temperature": 0.0, "avg_logprob": -0.15499022483825683, "compression_ratio": 1.5560344827586208, "no_speech_prob": 3.187549964422942e-06}, {"id": 1543, "seek": 689250, "start": 6892.5, "end": 6899.22, "text": " It's just that you've got a loop you refactored.", "tokens": [467, 311, 445, 300, 291, 600, 658, 257, 6367, 291, 1895, 578, 2769, 13], "temperature": 0.0, "avg_logprob": -0.12217968966053651, "compression_ratio": 1.6594827586206897, "no_speech_prob": 7.527655270678224e-06}, {"id": 1544, "seek": 689250, "start": 6899.22, "end": 6904.82, "text": " What you could do though is at the end of your every loop, you could not just spit out", "tokens": [708, 291, 727, 360, 1673, 307, 412, 264, 917, 295, 428, 633, 6367, 11, 291, 727, 406, 445, 22127, 484], "temperature": 0.0, "avg_logprob": -0.12217968966053651, "compression_ratio": 1.6594827586206897, "no_speech_prob": 7.527655270678224e-06}, {"id": 1545, "seek": 689250, "start": 6904.82, "end": 6908.02, "text": " an output, but you could spit it out into another RNN.", "tokens": [364, 5598, 11, 457, 291, 727, 22127, 309, 484, 666, 1071, 45702, 45, 13], "temperature": 0.0, "avg_logprob": -0.12217968966053651, "compression_ratio": 1.6594827586206897, "no_speech_prob": 7.527655270678224e-06}, {"id": 1546, "seek": 689250, "start": 6908.02, "end": 6910.82, "text": " So you'd have an RNN going into an RNN.", "tokens": [407, 291, 1116, 362, 364, 45702, 45, 516, 666, 364, 45702, 45, 13], "temperature": 0.0, "avg_logprob": -0.12217968966053651, "compression_ratio": 1.6594827586206897, "no_speech_prob": 7.527655270678224e-06}, {"id": 1547, "seek": 689250, "start": 6910.82, "end": 6913.8, "text": " And that's nice because we've now got more layers of computation.", "tokens": [400, 300, 311, 1481, 570, 321, 600, 586, 658, 544, 7914, 295, 24903, 13], "temperature": 0.0, "avg_logprob": -0.12217968966053651, "compression_ratio": 1.6594827586206897, "no_speech_prob": 7.527655270678224e-06}, {"id": 1548, "seek": 689250, "start": 6913.8, "end": 6917.86, "text": " You would expect that to work better.", "tokens": [509, 576, 2066, 300, 281, 589, 1101, 13], "temperature": 0.0, "avg_logprob": -0.12217968966053651, "compression_ratio": 1.6594827586206897, "no_speech_prob": 7.527655270678224e-06}, {"id": 1549, "seek": 689250, "start": 6917.86, "end": 6921.26, "text": " Well to get there, let's do some more refactoring.", "tokens": [1042, 281, 483, 456, 11, 718, 311, 360, 512, 544, 1895, 578, 3662, 13], "temperature": 0.0, "avg_logprob": -0.12217968966053651, "compression_ratio": 1.6594827586206897, "no_speech_prob": 7.527655270678224e-06}, {"id": 1550, "seek": 692126, "start": 6921.26, "end": 6927.38, "text": " So let's take this code and replace it with the equivalent built-in PyTorch code, which", "tokens": [407, 718, 311, 747, 341, 3089, 293, 7406, 309, 365, 264, 10344, 3094, 12, 259, 9953, 51, 284, 339, 3089, 11, 597], "temperature": 0.0, "avg_logprob": -0.15004686670979178, "compression_ratio": 1.8162393162393162, "no_speech_prob": 3.5558043691708008e-06}, {"id": 1551, "seek": 692126, "start": 6927.38, "end": 6930.34, "text": " is you just say that.", "tokens": [307, 291, 445, 584, 300, 13], "temperature": 0.0, "avg_logprob": -0.15004686670979178, "compression_ratio": 1.8162393162393162, "no_speech_prob": 3.5558043691708008e-06}, {"id": 1552, "seek": 692126, "start": 6930.34, "end": 6933.780000000001, "text": " So nn.rnn basically says do the loop for me.", "tokens": [407, 297, 77, 13, 81, 26384, 1936, 1619, 360, 264, 6367, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.15004686670979178, "compression_ratio": 1.8162393162393162, "no_speech_prob": 3.5558043691708008e-06}, {"id": 1553, "seek": 692126, "start": 6933.780000000001, "end": 6935.06, "text": " We've still got the same embedding.", "tokens": [492, 600, 920, 658, 264, 912, 12240, 3584, 13], "temperature": 0.0, "avg_logprob": -0.15004686670979178, "compression_ratio": 1.8162393162393162, "no_speech_prob": 3.5558043691708008e-06}, {"id": 1554, "seek": 692126, "start": 6935.06, "end": 6936.54, "text": " We've still got the same output.", "tokens": [492, 600, 920, 658, 264, 912, 5598, 13], "temperature": 0.0, "avg_logprob": -0.15004686670979178, "compression_ratio": 1.8162393162393162, "no_speech_prob": 3.5558043691708008e-06}, {"id": 1555, "seek": 692126, "start": 6936.54, "end": 6938.42, "text": " We've still got the same batch norm.", "tokens": [492, 600, 920, 658, 264, 912, 15245, 2026, 13], "temperature": 0.0, "avg_logprob": -0.15004686670979178, "compression_ratio": 1.8162393162393162, "no_speech_prob": 3.5558043691708008e-06}, {"id": 1556, "seek": 692126, "start": 6938.42, "end": 6943.42, "text": " We've still got the same initialization of h, but we just got rid of the loop.", "tokens": [492, 600, 920, 658, 264, 912, 5883, 2144, 295, 276, 11, 457, 321, 445, 658, 3973, 295, 264, 6367, 13], "temperature": 0.0, "avg_logprob": -0.15004686670979178, "compression_ratio": 1.8162393162393162, "no_speech_prob": 3.5558043691708008e-06}, {"id": 1557, "seek": 692126, "start": 6943.42, "end": 6949.9800000000005, "text": " So one of the nice things about RNN is that you can now say how many layers you want.", "tokens": [407, 472, 295, 264, 1481, 721, 466, 45702, 45, 307, 300, 291, 393, 586, 584, 577, 867, 7914, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.15004686670979178, "compression_ratio": 1.8162393162393162, "no_speech_prob": 3.5558043691708008e-06}, {"id": 1558, "seek": 694998, "start": 6949.98, "end": 6952.94, "text": " So this is the same accuracy of course.", "tokens": [407, 341, 307, 264, 912, 14170, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.15164381849999523, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.338687853713054e-06}, {"id": 1559, "seek": 694998, "start": 6952.94, "end": 6956.219999999999, "text": " So here I'm going to do it with two layers.", "tokens": [407, 510, 286, 478, 516, 281, 360, 309, 365, 732, 7914, 13], "temperature": 0.0, "avg_logprob": -0.15164381849999523, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.338687853713054e-06}, {"id": 1560, "seek": 694998, "start": 6956.219999999999, "end": 6957.66, "text": " But here's the thing.", "tokens": [583, 510, 311, 264, 551, 13], "temperature": 0.0, "avg_logprob": -0.15164381849999523, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.338687853713054e-06}, {"id": 1561, "seek": 694998, "start": 6957.66, "end": 6962.459999999999, "text": " When you think about this, think about it without the loop.", "tokens": [1133, 291, 519, 466, 341, 11, 519, 466, 309, 1553, 264, 6367, 13], "temperature": 0.0, "avg_logprob": -0.15164381849999523, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.338687853713054e-06}, {"id": 1562, "seek": 694998, "start": 6962.459999999999, "end": 6964.54, "text": " It looks like this.", "tokens": [467, 1542, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.15164381849999523, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.338687853713054e-06}, {"id": 1563, "seek": 694998, "start": 6964.54, "end": 6966.339999999999, "text": " It keeps on going.", "tokens": [467, 5965, 322, 516, 13], "temperature": 0.0, "avg_logprob": -0.15164381849999523, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.338687853713054e-06}, {"id": 1564, "seek": 694998, "start": 6966.339999999999, "end": 6971.419999999999, "text": " And we've got a BPTT of 20, so there's 20 layers of this.", "tokens": [400, 321, 600, 658, 257, 40533, 28178, 295, 945, 11, 370, 456, 311, 945, 7914, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.15164381849999523, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.338687853713054e-06}, {"id": 1565, "seek": 694998, "start": 6971.419999999999, "end": 6977.66, "text": " And we know from that visualizing the loss landscapes paper that deep networks have awful", "tokens": [400, 321, 458, 490, 300, 5056, 3319, 264, 4470, 29822, 3035, 300, 2452, 9590, 362, 11232], "temperature": 0.0, "avg_logprob": -0.15164381849999523, "compression_ratio": 1.5714285714285714, "no_speech_prob": 6.338687853713054e-06}, {"id": 1566, "seek": 697766, "start": 6977.66, "end": 6980.54, "text": " bumpy loss surfaces.", "tokens": [49400, 4470, 16130, 13], "temperature": 0.0, "avg_logprob": -0.10346453530447823, "compression_ratio": 1.54, "no_speech_prob": 7.295964678633027e-06}, {"id": 1567, "seek": 697766, "start": 6980.54, "end": 6988.98, "text": " So when you start creating long time scales and multiple layers, these things get impossible", "tokens": [407, 562, 291, 722, 4084, 938, 565, 17408, 293, 3866, 7914, 11, 613, 721, 483, 6243], "temperature": 0.0, "avg_logprob": -0.10346453530447823, "compression_ratio": 1.54, "no_speech_prob": 7.295964678633027e-06}, {"id": 1568, "seek": 697766, "start": 6988.98, "end": 6991.5599999999995, "text": " to train.", "tokens": [281, 3847, 13], "temperature": 0.0, "avg_logprob": -0.10346453530447823, "compression_ratio": 1.54, "no_speech_prob": 7.295964678633027e-06}, {"id": 1569, "seek": 697766, "start": 6991.5599999999995, "end": 6993.139999999999, "text": " So there's a few tricks you can do.", "tokens": [407, 456, 311, 257, 1326, 11733, 291, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.10346453530447823, "compression_ratio": 1.54, "no_speech_prob": 7.295964678633027e-06}, {"id": 1570, "seek": 697766, "start": 6993.139999999999, "end": 6997.66, "text": " One thing is you can add skip connections, of course.", "tokens": [1485, 551, 307, 291, 393, 909, 10023, 9271, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.10346453530447823, "compression_ratio": 1.54, "no_speech_prob": 7.295964678633027e-06}, {"id": 1571, "seek": 697766, "start": 6997.66, "end": 7004.0599999999995, "text": " But what people normally do is instead they put inside, instead of just adding these together,", "tokens": [583, 437, 561, 5646, 360, 307, 2602, 436, 829, 1854, 11, 2602, 295, 445, 5127, 613, 1214, 11], "temperature": 0.0, "avg_logprob": -0.10346453530447823, "compression_ratio": 1.54, "no_speech_prob": 7.295964678633027e-06}, {"id": 1572, "seek": 700406, "start": 7004.06, "end": 7009.46, "text": " they actually use a little mini neural net to decide how much of the green arrow to keep", "tokens": [436, 767, 764, 257, 707, 8382, 18161, 2533, 281, 4536, 577, 709, 295, 264, 3092, 11610, 281, 1066], "temperature": 0.0, "avg_logprob": -0.10997115241156684, "compression_ratio": 1.7346938775510203, "no_speech_prob": 2.947935854535899e-06}, {"id": 1573, "seek": 700406, "start": 7009.46, "end": 7011.9800000000005, "text": " and how much of the orange arrow to keep.", "tokens": [293, 577, 709, 295, 264, 7671, 11610, 281, 1066, 13], "temperature": 0.0, "avg_logprob": -0.10997115241156684, "compression_ratio": 1.7346938775510203, "no_speech_prob": 2.947935854535899e-06}, {"id": 1574, "seek": 700406, "start": 7011.9800000000005, "end": 7017.5, "text": " And when you do that, you get something that's either called a GRU or an LSTM, depending", "tokens": [400, 562, 291, 360, 300, 11, 291, 483, 746, 300, 311, 2139, 1219, 257, 10903, 52, 420, 364, 441, 6840, 44, 11, 5413], "temperature": 0.0, "avg_logprob": -0.10997115241156684, "compression_ratio": 1.7346938775510203, "no_speech_prob": 2.947935854535899e-06}, {"id": 1575, "seek": 700406, "start": 7017.5, "end": 7019.22, "text": " on the details of that little neural net.", "tokens": [322, 264, 4365, 295, 300, 707, 18161, 2533, 13], "temperature": 0.0, "avg_logprob": -0.10997115241156684, "compression_ratio": 1.7346938775510203, "no_speech_prob": 2.947935854535899e-06}, {"id": 1576, "seek": 700406, "start": 7019.22, "end": 7022.22, "text": " And we'll learn about the details of those neural nets in part two.", "tokens": [400, 321, 603, 1466, 466, 264, 4365, 295, 729, 18161, 36170, 294, 644, 732, 13], "temperature": 0.0, "avg_logprob": -0.10997115241156684, "compression_ratio": 1.7346938775510203, "no_speech_prob": 2.947935854535899e-06}, {"id": 1577, "seek": 700406, "start": 7022.22, "end": 7024.92, "text": " They really don't matter though, frankly.", "tokens": [814, 534, 500, 380, 1871, 1673, 11, 11939, 13], "temperature": 0.0, "avg_logprob": -0.10997115241156684, "compression_ratio": 1.7346938775510203, "no_speech_prob": 2.947935854535899e-06}, {"id": 1578, "seek": 700406, "start": 7024.92, "end": 7027.1, "text": " So we can now say let's create a GRU instead.", "tokens": [407, 321, 393, 586, 584, 718, 311, 1884, 257, 10903, 52, 2602, 13], "temperature": 0.0, "avg_logprob": -0.10997115241156684, "compression_ratio": 1.7346938775510203, "no_speech_prob": 2.947935854535899e-06}, {"id": 1579, "seek": 700406, "start": 7027.1, "end": 7033.3, "text": " So it's just like what we had before, but it'll handle longer sequences and deeper networks.", "tokens": [407, 309, 311, 445, 411, 437, 321, 632, 949, 11, 457, 309, 603, 4813, 2854, 22978, 293, 7731, 9590, 13], "temperature": 0.0, "avg_logprob": -0.10997115241156684, "compression_ratio": 1.7346938775510203, "no_speech_prob": 2.947935854535899e-06}, {"id": 1580, "seek": 703330, "start": 7033.3, "end": 7034.3, "text": " Let's use two layers.", "tokens": [961, 311, 764, 732, 7914, 13], "temperature": 0.0, "avg_logprob": -0.14838923107494006, "compression_ratio": 1.4455958549222798, "no_speech_prob": 3.844625553028891e-06}, {"id": 1581, "seek": 703330, "start": 7034.3, "end": 7035.3, "text": " Boom.", "tokens": [15523, 13], "temperature": 0.0, "avg_logprob": -0.14838923107494006, "compression_ratio": 1.4455958549222798, "no_speech_prob": 3.844625553028891e-06}, {"id": 1582, "seek": 703330, "start": 7035.3, "end": 7041.9400000000005, "text": " And we're up to 75%.", "tokens": [400, 321, 434, 493, 281, 9562, 6856], "temperature": 0.0, "avg_logprob": -0.14838923107494006, "compression_ratio": 1.4455958549222798, "no_speech_prob": 3.844625553028891e-06}, {"id": 1583, "seek": 703330, "start": 7041.9400000000005, "end": 7045.7, "text": " So that's RNNs.", "tokens": [407, 300, 311, 45702, 45, 82, 13], "temperature": 0.0, "avg_logprob": -0.14838923107494006, "compression_ratio": 1.4455958549222798, "no_speech_prob": 3.844625553028891e-06}, {"id": 1584, "seek": 703330, "start": 7045.7, "end": 7051.54, "text": " And the main reason I wanted to show it to you was to remove the last remaining piece", "tokens": [400, 264, 2135, 1778, 286, 1415, 281, 855, 309, 281, 291, 390, 281, 4159, 264, 1036, 8877, 2522], "temperature": 0.0, "avg_logprob": -0.14838923107494006, "compression_ratio": 1.4455958549222798, "no_speech_prob": 3.844625553028891e-06}, {"id": 1585, "seek": 703330, "start": 7051.54, "end": 7053.3, "text": " of magic.", "tokens": [295, 5585, 13], "temperature": 0.0, "avg_logprob": -0.14838923107494006, "compression_ratio": 1.4455958549222798, "no_speech_prob": 3.844625553028891e-06}, {"id": 1586, "seek": 703330, "start": 7053.3, "end": 7057.400000000001, "text": " And this is one of the least magical things we have in deep learning.", "tokens": [400, 341, 307, 472, 295, 264, 1935, 12066, 721, 321, 362, 294, 2452, 2539, 13], "temperature": 0.0, "avg_logprob": -0.14838923107494006, "compression_ratio": 1.4455958549222798, "no_speech_prob": 3.844625553028891e-06}, {"id": 1587, "seek": 703330, "start": 7057.400000000001, "end": 7060.820000000001, "text": " It's just a refactored, fully connected network.", "tokens": [467, 311, 445, 257, 1895, 578, 2769, 11, 4498, 4582, 3209, 13], "temperature": 0.0, "avg_logprob": -0.14838923107494006, "compression_ratio": 1.4455958549222798, "no_speech_prob": 3.844625553028891e-06}, {"id": 1588, "seek": 706082, "start": 7060.82, "end": 7065.5, "text": " So don't let RNNs ever put you off.", "tokens": [407, 500, 380, 718, 45702, 45, 82, 1562, 829, 291, 766, 13], "temperature": 0.0, "avg_logprob": -0.13918529857288708, "compression_ratio": 1.6693227091633467, "no_speech_prob": 5.593451078311773e-06}, {"id": 1589, "seek": 706082, "start": 7065.5, "end": 7070.259999999999, "text": " And with this approach, where you basically have a sequence of N inputs and a sequence", "tokens": [400, 365, 341, 3109, 11, 689, 291, 1936, 362, 257, 8310, 295, 426, 15743, 293, 257, 8310], "temperature": 0.0, "avg_logprob": -0.13918529857288708, "compression_ratio": 1.6693227091633467, "no_speech_prob": 5.593451078311773e-06}, {"id": 1590, "seek": 706082, "start": 7070.259999999999, "end": 7075.259999999999, "text": " of N outputs we've been using for language modeling, you can use that for other tasks.", "tokens": [295, 426, 23930, 321, 600, 668, 1228, 337, 2856, 15983, 11, 291, 393, 764, 300, 337, 661, 9608, 13], "temperature": 0.0, "avg_logprob": -0.13918529857288708, "compression_ratio": 1.6693227091633467, "no_speech_prob": 5.593451078311773e-06}, {"id": 1591, "seek": 706082, "start": 7075.259999999999, "end": 7078.86, "text": " For example, the sequence of outputs could be for every word.", "tokens": [1171, 1365, 11, 264, 8310, 295, 23930, 727, 312, 337, 633, 1349, 13], "temperature": 0.0, "avg_logprob": -0.13918529857288708, "compression_ratio": 1.6693227091633467, "no_speech_prob": 5.593451078311773e-06}, {"id": 1592, "seek": 706082, "start": 7078.86, "end": 7082.5, "text": " There could be something saying, is this something that is sensitive and I want to anonymize", "tokens": [821, 727, 312, 746, 1566, 11, 307, 341, 746, 300, 307, 9477, 293, 286, 528, 281, 37293, 1125], "temperature": 0.0, "avg_logprob": -0.13918529857288708, "compression_ratio": 1.6693227091633467, "no_speech_prob": 5.593451078311773e-06}, {"id": 1593, "seek": 706082, "start": 7082.5, "end": 7083.5, "text": " or not?", "tokens": [420, 406, 30], "temperature": 0.0, "avg_logprob": -0.13918529857288708, "compression_ratio": 1.6693227091633467, "no_speech_prob": 5.593451078311773e-06}, {"id": 1594, "seek": 706082, "start": 7083.5, "end": 7087.7, "text": " You know, so like is this private data or not?", "tokens": [509, 458, 11, 370, 411, 307, 341, 4551, 1412, 420, 406, 30], "temperature": 0.0, "avg_logprob": -0.13918529857288708, "compression_ratio": 1.6693227091633467, "no_speech_prob": 5.593451078311773e-06}, {"id": 1595, "seek": 708770, "start": 7087.7, "end": 7092.0199999999995, "text": " Or it could be a part of speech tag for that word.", "tokens": [1610, 309, 727, 312, 257, 644, 295, 6218, 6162, 337, 300, 1349, 13], "temperature": 0.0, "avg_logprob": -0.12540451685587564, "compression_ratio": 1.6757990867579908, "no_speech_prob": 6.4381306401628535e-06}, {"id": 1596, "seek": 708770, "start": 7092.0199999999995, "end": 7098.9, "text": " Or it could be something saying, you know, how should that word be formatted or whatever?", "tokens": [1610, 309, 727, 312, 746, 1566, 11, 291, 458, 11, 577, 820, 300, 1349, 312, 1254, 32509, 420, 2035, 30], "temperature": 0.0, "avg_logprob": -0.12540451685587564, "compression_ratio": 1.6757990867579908, "no_speech_prob": 6.4381306401628535e-06}, {"id": 1597, "seek": 708770, "start": 7098.9, "end": 7101.26, "text": " And so these are called sequence labeling tasks.", "tokens": [400, 370, 613, 366, 1219, 8310, 40244, 9608, 13], "temperature": 0.0, "avg_logprob": -0.12540451685587564, "compression_ratio": 1.6757990867579908, "no_speech_prob": 6.4381306401628535e-06}, {"id": 1598, "seek": 708770, "start": 7101.26, "end": 7105.9, "text": " And so you can use this same approach for pretty much any sequence labeling task.", "tokens": [400, 370, 291, 393, 764, 341, 912, 3109, 337, 1238, 709, 604, 8310, 40244, 5633, 13], "temperature": 0.0, "avg_logprob": -0.12540451685587564, "compression_ratio": 1.6757990867579908, "no_speech_prob": 6.4381306401628535e-06}, {"id": 1599, "seek": 708770, "start": 7105.9, "end": 7110.58, "text": " Or you can do what I did in the earlier lesson, which is once you finish building your language", "tokens": [1610, 291, 393, 360, 437, 286, 630, 294, 264, 3071, 6898, 11, 597, 307, 1564, 291, 2413, 2390, 428, 2856], "temperature": 0.0, "avg_logprob": -0.12540451685587564, "compression_ratio": 1.6757990867579908, "no_speech_prob": 6.4381306401628535e-06}, {"id": 1600, "seek": 711058, "start": 7110.58, "end": 7122.5, "text": " model, you can throw away this HO bit and instead pop there a standard classification", "tokens": [2316, 11, 291, 393, 3507, 1314, 341, 23097, 857, 293, 2602, 1665, 456, 257, 3832, 21538], "temperature": 0.0, "avg_logprob": -0.19930519247954748, "compression_ratio": 1.4701986754966887, "no_speech_prob": 7.527090929215774e-06}, {"id": 1601, "seek": 711058, "start": 7122.5, "end": 7128.9, "text": " head and then you can now do NLP classification, which as you saw earlier will give you state", "tokens": [1378, 293, 550, 291, 393, 586, 360, 426, 45196, 21538, 11, 597, 382, 291, 1866, 3071, 486, 976, 291, 1785], "temperature": 0.0, "avg_logprob": -0.19930519247954748, "compression_ratio": 1.4701986754966887, "no_speech_prob": 7.527090929215774e-06}, {"id": 1602, "seek": 711058, "start": 7128.9, "end": 7134.26, "text": " of the art results even on long documents.", "tokens": [295, 264, 1523, 3542, 754, 322, 938, 8512, 13], "temperature": 0.0, "avg_logprob": -0.19930519247954748, "compression_ratio": 1.4701986754966887, "no_speech_prob": 7.527090929215774e-06}, {"id": 1603, "seek": 713426, "start": 7134.26, "end": 7141.26, "text": " So this is a super valuable technique and not remotely magical.", "tokens": [407, 341, 307, 257, 1687, 8263, 6532, 293, 406, 20824, 12066, 13], "temperature": 0.0, "avg_logprob": -0.1589923835382229, "compression_ratio": 1.5606060606060606, "no_speech_prob": 4.356597855803557e-06}, {"id": 1604, "seek": 713426, "start": 7141.26, "end": 7143.46, "text": " So that's it.", "tokens": [407, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.1589923835382229, "compression_ratio": 1.5606060606060606, "no_speech_prob": 4.356597855803557e-06}, {"id": 1605, "seek": 713426, "start": 7143.46, "end": 7152.22, "text": " That's deep learning or at least the kind of the practical pieces from my point of view.", "tokens": [663, 311, 2452, 2539, 420, 412, 1935, 264, 733, 295, 264, 8496, 3755, 490, 452, 935, 295, 1910, 13], "temperature": 0.0, "avg_logprob": -0.1589923835382229, "compression_ratio": 1.5606060606060606, "no_speech_prob": 4.356597855803557e-06}, {"id": 1606, "seek": 713426, "start": 7152.22, "end": 7158.18, "text": " Having watched this one time, you won't get it all.", "tokens": [10222, 6337, 341, 472, 565, 11, 291, 1582, 380, 483, 309, 439, 13], "temperature": 0.0, "avg_logprob": -0.1589923835382229, "compression_ratio": 1.5606060606060606, "no_speech_prob": 4.356597855803557e-06}, {"id": 1607, "seek": 713426, "start": 7158.18, "end": 7162.22, "text": " And I don't recommend that you do watch this so slowly that you get it all the first time,", "tokens": [400, 286, 500, 380, 2748, 300, 291, 360, 1159, 341, 370, 5692, 300, 291, 483, 309, 439, 264, 700, 565, 11], "temperature": 0.0, "avg_logprob": -0.1589923835382229, "compression_ratio": 1.5606060606060606, "no_speech_prob": 4.356597855803557e-06}, {"id": 1608, "seek": 716222, "start": 7162.22, "end": 7167.62, "text": " but that you go back and look at it again, take your time, and there will be bits that", "tokens": [457, 300, 291, 352, 646, 293, 574, 412, 309, 797, 11, 747, 428, 565, 11, 293, 456, 486, 312, 9239, 300], "temperature": 0.0, "avg_logprob": -0.1624249634919343, "compression_ratio": 1.7773722627737227, "no_speech_prob": 1.8923832612927072e-05}, {"id": 1609, "seek": 716222, "start": 7167.62, "end": 7169.9800000000005, "text": " you go like, oh, now I see what he's saying.", "tokens": [291, 352, 411, 11, 1954, 11, 586, 286, 536, 437, 415, 311, 1566, 13], "temperature": 0.0, "avg_logprob": -0.1624249634919343, "compression_ratio": 1.7773722627737227, "no_speech_prob": 1.8923832612927072e-05}, {"id": 1610, "seek": 716222, "start": 7169.9800000000005, "end": 7172.900000000001, "text": " And then you'll be able to implement things you couldn't implement before and you'll be", "tokens": [400, 550, 291, 603, 312, 1075, 281, 4445, 721, 291, 2809, 380, 4445, 949, 293, 291, 603, 312], "temperature": 0.0, "avg_logprob": -0.1624249634919343, "compression_ratio": 1.7773722627737227, "no_speech_prob": 1.8923832612927072e-05}, {"id": 1611, "seek": 716222, "start": 7172.900000000001, "end": 7174.42, "text": " able to dig in more than you thought.", "tokens": [1075, 281, 2528, 294, 544, 813, 291, 1194, 13], "temperature": 0.0, "avg_logprob": -0.1624249634919343, "compression_ratio": 1.7773722627737227, "no_speech_prob": 1.8923832612927072e-05}, {"id": 1612, "seek": 716222, "start": 7174.42, "end": 7177.22, "text": " So definitely go back and do it again.", "tokens": [407, 2138, 352, 646, 293, 360, 309, 797, 13], "temperature": 0.0, "avg_logprob": -0.1624249634919343, "compression_ratio": 1.7773722627737227, "no_speech_prob": 1.8923832612927072e-05}, {"id": 1613, "seek": 716222, "start": 7177.22, "end": 7182.42, "text": " And as you do, write code, not just for yourself, but put it on GitHub.", "tokens": [400, 382, 291, 360, 11, 2464, 3089, 11, 406, 445, 337, 1803, 11, 457, 829, 309, 322, 23331, 13], "temperature": 0.0, "avg_logprob": -0.1624249634919343, "compression_ratio": 1.7773722627737227, "no_speech_prob": 1.8923832612927072e-05}, {"id": 1614, "seek": 716222, "start": 7182.42, "end": 7185.34, "text": " It doesn't matter if you think it's great code or not.", "tokens": [467, 1177, 380, 1871, 498, 291, 519, 309, 311, 869, 3089, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.1624249634919343, "compression_ratio": 1.7773722627737227, "no_speech_prob": 1.8923832612927072e-05}, {"id": 1615, "seek": 716222, "start": 7185.34, "end": 7190.46, "text": " The fact that you're writing code and sharing it is impressive.", "tokens": [440, 1186, 300, 291, 434, 3579, 3089, 293, 5414, 309, 307, 8992, 13], "temperature": 0.0, "avg_logprob": -0.1624249634919343, "compression_ratio": 1.7773722627737227, "no_speech_prob": 1.8923832612927072e-05}, {"id": 1616, "seek": 719046, "start": 7190.46, "end": 7194.9800000000005, "text": " And the feedback you'll get if you tell people on the forum, hey, I wrote this code.", "tokens": [400, 264, 5824, 291, 603, 483, 498, 291, 980, 561, 322, 264, 17542, 11, 4177, 11, 286, 4114, 341, 3089, 13], "temperature": 0.0, "avg_logprob": -0.14275735753183147, "compression_ratio": 1.6485507246376812, "no_speech_prob": 4.86018643641728e-06}, {"id": 1617, "seek": 719046, "start": 7194.9800000000005, "end": 7198.46, "text": " It's not great, but it's my first effort.", "tokens": [467, 311, 406, 869, 11, 457, 309, 311, 452, 700, 4630, 13], "temperature": 0.0, "avg_logprob": -0.14275735753183147, "compression_ratio": 1.6485507246376812, "no_speech_prob": 4.86018643641728e-06}, {"id": 1618, "seek": 719046, "start": 7198.46, "end": 7200.78, "text": " Anything you see, jump out at you.", "tokens": [11998, 291, 536, 11, 3012, 484, 412, 291, 13], "temperature": 0.0, "avg_logprob": -0.14275735753183147, "compression_ratio": 1.6485507246376812, "no_speech_prob": 4.86018643641728e-06}, {"id": 1619, "seek": 719046, "start": 7200.78, "end": 7202.7, "text": " People will say, oh, that bit was done well.", "tokens": [3432, 486, 584, 11, 1954, 11, 300, 857, 390, 1096, 731, 13], "temperature": 0.0, "avg_logprob": -0.14275735753183147, "compression_ratio": 1.6485507246376812, "no_speech_prob": 4.86018643641728e-06}, {"id": 1620, "seek": 719046, "start": 7202.7, "end": 7205.9, "text": " Hey, but did you know for this bit you could have used this library and saved you some", "tokens": [1911, 11, 457, 630, 291, 458, 337, 341, 857, 291, 727, 362, 1143, 341, 6405, 293, 6624, 291, 512], "temperature": 0.0, "avg_logprob": -0.14275735753183147, "compression_ratio": 1.6485507246376812, "no_speech_prob": 4.86018643641728e-06}, {"id": 1621, "seek": 719046, "start": 7205.9, "end": 7206.9, "text": " time?", "tokens": [565, 30], "temperature": 0.0, "avg_logprob": -0.14275735753183147, "compression_ratio": 1.6485507246376812, "no_speech_prob": 4.86018643641728e-06}, {"id": 1622, "seek": 719046, "start": 7206.9, "end": 7211.58, "text": " You'll learn a lot by interacting with your peers.", "tokens": [509, 603, 1466, 257, 688, 538, 18017, 365, 428, 16739, 13], "temperature": 0.0, "avg_logprob": -0.14275735753183147, "compression_ratio": 1.6485507246376812, "no_speech_prob": 4.86018643641728e-06}, {"id": 1623, "seek": 719046, "start": 7211.58, "end": 7214.1, "text": " As you've noticed, I've started introducing more and more papers.", "tokens": [1018, 291, 600, 5694, 11, 286, 600, 1409, 15424, 544, 293, 544, 10577, 13], "temperature": 0.0, "avg_logprob": -0.14275735753183147, "compression_ratio": 1.6485507246376812, "no_speech_prob": 4.86018643641728e-06}, {"id": 1624, "seek": 719046, "start": 7214.1, "end": 7217.06, "text": " Now, part two will be a lot of papers.", "tokens": [823, 11, 644, 732, 486, 312, 257, 688, 295, 10577, 13], "temperature": 0.0, "avg_logprob": -0.14275735753183147, "compression_ratio": 1.6485507246376812, "no_speech_prob": 4.86018643641728e-06}, {"id": 1625, "seek": 721706, "start": 7217.06, "end": 7222.1, "text": " And so it's a good time to start reading some of the papers that have been introduced in", "tokens": [400, 370, 309, 311, 257, 665, 565, 281, 722, 3760, 512, 295, 264, 10577, 300, 362, 668, 7268, 294], "temperature": 0.0, "avg_logprob": -0.12010454880563837, "compression_ratio": 1.6304347826086956, "no_speech_prob": 7.888096661190502e-06}, {"id": 1626, "seek": 721706, "start": 7222.1, "end": 7224.18, "text": " this section.", "tokens": [341, 3541, 13], "temperature": 0.0, "avg_logprob": -0.12010454880563837, "compression_ratio": 1.6304347826086956, "no_speech_prob": 7.888096661190502e-06}, {"id": 1627, "seek": 721706, "start": 7224.18, "end": 7228.06, "text": " All the bits that say derivation and theorems and lemmas, you can skip them.", "tokens": [1057, 264, 9239, 300, 584, 10151, 399, 293, 10299, 2592, 293, 7495, 3799, 11, 291, 393, 10023, 552, 13], "temperature": 0.0, "avg_logprob": -0.12010454880563837, "compression_ratio": 1.6304347826086956, "no_speech_prob": 7.888096661190502e-06}, {"id": 1628, "seek": 721706, "start": 7228.06, "end": 7229.06, "text": " I do.", "tokens": [286, 360, 13], "temperature": 0.0, "avg_logprob": -0.12010454880563837, "compression_ratio": 1.6304347826086956, "no_speech_prob": 7.888096661190502e-06}, {"id": 1629, "seek": 721706, "start": 7229.06, "end": 7233.22, "text": " They add almost nothing to your understanding of practical deep learning.", "tokens": [814, 909, 1920, 1825, 281, 428, 3701, 295, 8496, 2452, 2539, 13], "temperature": 0.0, "avg_logprob": -0.12010454880563837, "compression_ratio": 1.6304347826086956, "no_speech_prob": 7.888096661190502e-06}, {"id": 1630, "seek": 721706, "start": 7233.22, "end": 7239.900000000001, "text": " But the bits that say why are we solving this problem and what are the results and so forth", "tokens": [583, 264, 9239, 300, 584, 983, 366, 321, 12606, 341, 1154, 293, 437, 366, 264, 3542, 293, 370, 5220], "temperature": 0.0, "avg_logprob": -0.12010454880563837, "compression_ratio": 1.6304347826086956, "no_speech_prob": 7.888096661190502e-06}, {"id": 1631, "seek": 721706, "start": 7239.900000000001, "end": 7242.580000000001, "text": " are really interesting.", "tokens": [366, 534, 1880, 13], "temperature": 0.0, "avg_logprob": -0.12010454880563837, "compression_ratio": 1.6304347826086956, "no_speech_prob": 7.888096661190502e-06}, {"id": 1632, "seek": 724258, "start": 7242.58, "end": 7248.98, "text": " And then try and write English prose.", "tokens": [400, 550, 853, 293, 2464, 3669, 12505, 13], "temperature": 0.0, "avg_logprob": -0.11639851161411831, "compression_ratio": 1.855721393034826, "no_speech_prob": 3.2373213798564393e-06}, {"id": 1633, "seek": 724258, "start": 7248.98, "end": 7252.78, "text": " Not English prose that you want to be read by Geoff Hinton and Jan LeCun, but English", "tokens": [1726, 3669, 12505, 300, 291, 528, 281, 312, 1401, 538, 26119, 389, 12442, 293, 4956, 1456, 34, 409, 11, 457, 3669], "temperature": 0.0, "avg_logprob": -0.11639851161411831, "compression_ratio": 1.855721393034826, "no_speech_prob": 3.2373213798564393e-06}, {"id": 1634, "seek": 724258, "start": 7252.78, "end": 7257.34, "text": " prose that you want to be read by you as of six months ago.", "tokens": [12505, 300, 291, 528, 281, 312, 1401, 538, 291, 382, 295, 2309, 2493, 2057, 13], "temperature": 0.0, "avg_logprob": -0.11639851161411831, "compression_ratio": 1.855721393034826, "no_speech_prob": 3.2373213798564393e-06}, {"id": 1635, "seek": 724258, "start": 7257.34, "end": 7262.38, "text": " Because there's a lot more people in the audience of you as of six months ago than there is", "tokens": [1436, 456, 311, 257, 688, 544, 561, 294, 264, 4034, 295, 291, 382, 295, 2309, 2493, 2057, 813, 456, 307], "temperature": 0.0, "avg_logprob": -0.11639851161411831, "compression_ratio": 1.855721393034826, "no_speech_prob": 3.2373213798564393e-06}, {"id": 1636, "seek": 724258, "start": 7262.38, "end": 7265.3, "text": " of Geoffrey Hinton and Jan LeCun.", "tokens": [295, 26119, 7950, 389, 12442, 293, 4956, 1456, 34, 409, 13], "temperature": 0.0, "avg_logprob": -0.11639851161411831, "compression_ratio": 1.855721393034826, "no_speech_prob": 3.2373213798564393e-06}, {"id": 1637, "seek": 724258, "start": 7265.3, "end": 7267.36, "text": " That's the person you best understand.", "tokens": [663, 311, 264, 954, 291, 1151, 1223, 13], "temperature": 0.0, "avg_logprob": -0.11639851161411831, "compression_ratio": 1.855721393034826, "no_speech_prob": 3.2373213798564393e-06}, {"id": 1638, "seek": 724258, "start": 7267.36, "end": 7271.42, "text": " You know what they need.", "tokens": [509, 458, 437, 436, 643, 13], "temperature": 0.0, "avg_logprob": -0.11639851161411831, "compression_ratio": 1.855721393034826, "no_speech_prob": 3.2373213798564393e-06}, {"id": 1639, "seek": 727142, "start": 7271.42, "end": 7273.08, "text": " Go and get help and help others.", "tokens": [1037, 293, 483, 854, 293, 854, 2357, 13], "temperature": 0.0, "avg_logprob": -0.16601504835971567, "compression_ratio": 1.4844444444444445, "no_speech_prob": 3.424347232794389e-05}, {"id": 1640, "seek": 727142, "start": 7273.08, "end": 7276.06, "text": " Tell us about your success stories.", "tokens": [5115, 505, 466, 428, 2245, 3676, 13], "temperature": 0.0, "avg_logprob": -0.16601504835971567, "compression_ratio": 1.4844444444444445, "no_speech_prob": 3.424347232794389e-05}, {"id": 1641, "seek": 727142, "start": 7276.06, "end": 7279.54, "text": " But perhaps the most important one is get together with others.", "tokens": [583, 4317, 264, 881, 1021, 472, 307, 483, 1214, 365, 2357, 13], "temperature": 0.0, "avg_logprob": -0.16601504835971567, "compression_ratio": 1.4844444444444445, "no_speech_prob": 3.424347232794389e-05}, {"id": 1642, "seek": 727142, "start": 7279.54, "end": 7284.4400000000005, "text": " People's learning works much better if you've got that social experience.", "tokens": [3432, 311, 2539, 1985, 709, 1101, 498, 291, 600, 658, 300, 2093, 1752, 13], "temperature": 0.0, "avg_logprob": -0.16601504835971567, "compression_ratio": 1.4844444444444445, "no_speech_prob": 3.424347232794389e-05}, {"id": 1643, "seek": 727142, "start": 7284.4400000000005, "end": 7291.62, "text": " So start a book club, get involved in meetups, create study groups, and build things.", "tokens": [407, 722, 257, 1446, 6482, 11, 483, 3288, 294, 1677, 7528, 11, 1884, 2979, 3935, 11, 293, 1322, 721, 13], "temperature": 0.0, "avg_logprob": -0.16601504835971567, "compression_ratio": 1.4844444444444445, "no_speech_prob": 3.424347232794389e-05}, {"id": 1644, "seek": 727142, "start": 7291.62, "end": 7296.3, "text": " And again, it doesn't have to be amazing.", "tokens": [400, 797, 11, 309, 1177, 380, 362, 281, 312, 2243, 13], "temperature": 0.0, "avg_logprob": -0.16601504835971567, "compression_ratio": 1.4844444444444445, "no_speech_prob": 3.424347232794389e-05}, {"id": 1645, "seek": 729630, "start": 7296.3, "end": 7301.58, "text": " Just build something that you think the world would be a little bit better if that existed.", "tokens": [1449, 1322, 746, 300, 291, 519, 264, 1002, 576, 312, 257, 707, 857, 1101, 498, 300, 13135, 13], "temperature": 0.0, "avg_logprob": -0.13342736691844706, "compression_ratio": 1.7476190476190476, "no_speech_prob": 3.267729698563926e-05}, {"id": 1646, "seek": 729630, "start": 7301.58, "end": 7306.06, "text": " Or you think it would be slightly delightful to your two-year-old to see that thing.", "tokens": [1610, 291, 519, 309, 576, 312, 4748, 35194, 281, 428, 732, 12, 5294, 12, 2641, 281, 536, 300, 551, 13], "temperature": 0.0, "avg_logprob": -0.13342736691844706, "compression_ratio": 1.7476190476190476, "no_speech_prob": 3.267729698563926e-05}, {"id": 1647, "seek": 729630, "start": 7306.06, "end": 7309.14, "text": " Or you just want to show it to your brother the next time they come around to see what", "tokens": [1610, 291, 445, 528, 281, 855, 309, 281, 428, 3708, 264, 958, 565, 436, 808, 926, 281, 536, 437], "temperature": 0.0, "avg_logprob": -0.13342736691844706, "compression_ratio": 1.7476190476190476, "no_speech_prob": 3.267729698563926e-05}, {"id": 1648, "seek": 729630, "start": 7309.14, "end": 7310.14, "text": " you're doing.", "tokens": [291, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.13342736691844706, "compression_ratio": 1.7476190476190476, "no_speech_prob": 3.267729698563926e-05}, {"id": 1649, "seek": 729630, "start": 7310.14, "end": 7312.58, "text": " Whatever.", "tokens": [8541, 13], "temperature": 0.0, "avg_logprob": -0.13342736691844706, "compression_ratio": 1.7476190476190476, "no_speech_prob": 3.267729698563926e-05}, {"id": 1650, "seek": 729630, "start": 7312.58, "end": 7314.42, "text": " Just finish something.", "tokens": [1449, 2413, 746, 13], "temperature": 0.0, "avg_logprob": -0.13342736691844706, "compression_ratio": 1.7476190476190476, "no_speech_prob": 3.267729698563926e-05}, {"id": 1651, "seek": 729630, "start": 7314.42, "end": 7316.54, "text": " Finish something.", "tokens": [31583, 746, 13], "temperature": 0.0, "avg_logprob": -0.13342736691844706, "compression_ratio": 1.7476190476190476, "no_speech_prob": 3.267729698563926e-05}, {"id": 1652, "seek": 729630, "start": 7316.54, "end": 7318.900000000001, "text": " And then try and make it a bit better.", "tokens": [400, 550, 853, 293, 652, 309, 257, 857, 1101, 13], "temperature": 0.0, "avg_logprob": -0.13342736691844706, "compression_ratio": 1.7476190476190476, "no_speech_prob": 3.267729698563926e-05}, {"id": 1653, "seek": 731890, "start": 7318.9, "end": 7329.339999999999, "text": " So for example, something I just saw this afternoon is the Elon Musk tweet generator.", "tokens": [407, 337, 1365, 11, 746, 286, 445, 1866, 341, 6499, 307, 264, 28498, 26019, 15258, 19265, 13], "temperature": 0.0, "avg_logprob": -0.13145337785993302, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.6693948055035435e-05}, {"id": 1654, "seek": 731890, "start": 7329.339999999999, "end": 7334.54, "text": " So looking at lots of older tweets, creating a language model from Elon Musk, and then", "tokens": [407, 1237, 412, 3195, 295, 4906, 25671, 11, 4084, 257, 2856, 2316, 490, 28498, 26019, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.13145337785993302, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.6693948055035435e-05}, {"id": 1655, "seek": 731890, "start": 7334.54, "end": 7339.66, "text": " creating new tweets such as humanity will also have an option to publish on its own", "tokens": [4084, 777, 25671, 1270, 382, 10243, 486, 611, 362, 364, 3614, 281, 11374, 322, 1080, 1065], "temperature": 0.0, "avg_logprob": -0.13145337785993302, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.6693948055035435e-05}, {"id": 1656, "seek": 731890, "start": 7339.66, "end": 7342.379999999999, "text": " journey as an alien civilization.", "tokens": [4671, 382, 364, 12319, 18036, 13], "temperature": 0.0, "avg_logprob": -0.13145337785993302, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.6693948055035435e-05}, {"id": 1657, "seek": 731890, "start": 7342.379999999999, "end": 7346.98, "text": " It will always, like all human beings, Mars is no longer possible.", "tokens": [467, 486, 1009, 11, 411, 439, 1952, 8958, 11, 9692, 307, 572, 2854, 1944, 13], "temperature": 0.0, "avg_logprob": -0.13145337785993302, "compression_ratio": 1.5726872246696035, "no_speech_prob": 1.6693948055035435e-05}, {"id": 1658, "seek": 734698, "start": 7346.98, "end": 7351.179999999999, "text": " AI will definitely be the central intelligence agency.", "tokens": [7318, 486, 2138, 312, 264, 5777, 7599, 7934, 13], "temperature": 0.0, "avg_logprob": -0.1306751251220703, "compression_ratio": 1.5458715596330275, "no_speech_prob": 9.078392395167612e-06}, {"id": 1659, "seek": 734698, "start": 7351.179999999999, "end": 7352.259999999999, "text": " So this is great.", "tokens": [407, 341, 307, 869, 13], "temperature": 0.0, "avg_logprob": -0.1306751251220703, "compression_ratio": 1.5458715596330275, "no_speech_prob": 9.078392395167612e-06}, {"id": 1660, "seek": 734698, "start": 7352.259999999999, "end": 7353.259999999999, "text": " I love this.", "tokens": [286, 959, 341, 13], "temperature": 0.0, "avg_logprob": -0.1306751251220703, "compression_ratio": 1.5458715596330275, "no_speech_prob": 9.078392395167612e-06}, {"id": 1661, "seek": 734698, "start": 7353.259999999999, "end": 7359.62, "text": " And I love that Dave Smith wrote and said, these are my first ever commits.", "tokens": [400, 286, 959, 300, 11017, 8538, 4114, 293, 848, 11, 613, 366, 452, 700, 1562, 48311, 13], "temperature": 0.0, "avg_logprob": -0.1306751251220703, "compression_ratio": 1.5458715596330275, "no_speech_prob": 9.078392395167612e-06}, {"id": 1662, "seek": 734698, "start": 7359.62, "end": 7363.599999999999, "text": " Thanks for teaching a finance guy how to build an app in eight weeks.", "tokens": [2561, 337, 4571, 257, 10719, 2146, 577, 281, 1322, 364, 724, 294, 3180, 3259, 13], "temperature": 0.0, "avg_logprob": -0.1306751251220703, "compression_ratio": 1.5458715596330275, "no_speech_prob": 9.078392395167612e-06}, {"id": 1663, "seek": 734698, "start": 7363.599999999999, "end": 7366.879999999999, "text": " So I think this is awesome.", "tokens": [407, 286, 519, 341, 307, 3476, 13], "temperature": 0.0, "avg_logprob": -0.1306751251220703, "compression_ratio": 1.5458715596330275, "no_speech_prob": 9.078392395167612e-06}, {"id": 1664, "seek": 734698, "start": 7366.879999999999, "end": 7375.0599999999995, "text": " And I think clearly a lot of care and passion has been put into this project.", "tokens": [400, 286, 519, 4448, 257, 688, 295, 1127, 293, 5418, 575, 668, 829, 666, 341, 1716, 13], "temperature": 0.0, "avg_logprob": -0.1306751251220703, "compression_ratio": 1.5458715596330275, "no_speech_prob": 9.078392395167612e-06}, {"id": 1665, "seek": 737506, "start": 7375.06, "end": 7379.76, "text": " Will it systematically change the future direction of society as a whole?", "tokens": [3099, 309, 39531, 1319, 264, 2027, 3513, 295, 4086, 382, 257, 1379, 30], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1666, "seek": 737506, "start": 7379.76, "end": 7380.900000000001, "text": " Maybe not.", "tokens": [2704, 406, 13], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1667, "seek": 737506, "start": 7380.900000000001, "end": 7386.26, "text": " But maybe Elon will look at this and think, oh, maybe I need to rethink my method of prose.", "tokens": [583, 1310, 28498, 486, 574, 412, 341, 293, 519, 11, 1954, 11, 1310, 286, 643, 281, 34595, 452, 3170, 295, 12505, 13], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1668, "seek": 737506, "start": 7386.26, "end": 7387.26, "text": " I don't know.", "tokens": [286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1669, "seek": 737506, "start": 7387.26, "end": 7389.780000000001, "text": " I think it's great.", "tokens": [286, 519, 309, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1670, "seek": 737506, "start": 7389.780000000001, "end": 7392.26, "text": " And so yeah, create something.", "tokens": [400, 370, 1338, 11, 1884, 746, 13], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1671, "seek": 737506, "start": 7392.26, "end": 7393.9800000000005, "text": " Put it out there.", "tokens": [4935, 309, 484, 456, 13], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1672, "seek": 737506, "start": 7393.9800000000005, "end": 7396.580000000001, "text": " Put a bit of yourself into it.", "tokens": [4935, 257, 857, 295, 1803, 666, 309, 13], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1673, "seek": 737506, "start": 7396.580000000001, "end": 7399.18, "text": " Or get involved in Fast AI.", "tokens": [1610, 483, 3288, 294, 15968, 7318, 13], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1674, "seek": 737506, "start": 7399.18, "end": 7401.54, "text": " The Fast AI project, there's a lot going on.", "tokens": [440, 15968, 7318, 1716, 11, 456, 311, 257, 688, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.13373640233820136, "compression_ratio": 1.5252100840336134, "no_speech_prob": 1.1842473213619087e-05}, {"id": 1675, "seek": 740154, "start": 7401.54, "end": 7405.42, "text": " You can help with documentation and tests, which might sound boring.", "tokens": [509, 393, 854, 365, 14333, 293, 6921, 11, 597, 1062, 1626, 9989, 13], "temperature": 0.0, "avg_logprob": -0.1696758270263672, "compression_ratio": 1.6774193548387097, "no_speech_prob": 3.069616650464013e-05}, {"id": 1676, "seek": 740154, "start": 7405.42, "end": 7409.3, "text": " But you'd be surprised how incredibly not boring it is to take a piece of code that", "tokens": [583, 291, 1116, 312, 6100, 577, 6252, 406, 9989, 309, 307, 281, 747, 257, 2522, 295, 3089, 300], "temperature": 0.0, "avg_logprob": -0.1696758270263672, "compression_ratio": 1.6774193548387097, "no_speech_prob": 3.069616650464013e-05}, {"id": 1677, "seek": 740154, "start": 7409.3, "end": 7414.22, "text": " hasn't been properly documented and research it and understand it and ask Sylvia and I", "tokens": [6132, 380, 668, 6108, 23007, 293, 2132, 309, 293, 1223, 309, 293, 1029, 33349, 11617, 293, 286], "temperature": 0.0, "avg_logprob": -0.1696758270263672, "compression_ratio": 1.6774193548387097, "no_speech_prob": 3.069616650464013e-05}, {"id": 1678, "seek": 740154, "start": 7414.22, "end": 7415.82, "text": " on the forum what's going on.", "tokens": [322, 264, 17542, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.1696758270263672, "compression_ratio": 1.6774193548387097, "no_speech_prob": 3.069616650464013e-05}, {"id": 1679, "seek": 740154, "start": 7415.82, "end": 7417.0199999999995, "text": " Why did you write it this way?", "tokens": [1545, 630, 291, 2464, 309, 341, 636, 30], "temperature": 0.0, "avg_logprob": -0.1696758270263672, "compression_ratio": 1.6774193548387097, "no_speech_prob": 3.069616650464013e-05}, {"id": 1680, "seek": 740154, "start": 7417.0199999999995, "end": 7420.1, "text": " We'll send you off to the papers that we were implementing.", "tokens": [492, 603, 2845, 291, 766, 281, 264, 10577, 300, 321, 645, 18114, 13], "temperature": 0.0, "avg_logprob": -0.1696758270263672, "compression_ratio": 1.6774193548387097, "no_speech_prob": 3.069616650464013e-05}, {"id": 1681, "seek": 740154, "start": 7420.1, "end": 7424.14, "text": " Writing a test requires deeply understanding that part of the machine learning world to", "tokens": [32774, 257, 1500, 7029, 8760, 3701, 300, 644, 295, 264, 3479, 2539, 1002, 281], "temperature": 0.0, "avg_logprob": -0.1696758270263672, "compression_ratio": 1.6774193548387097, "no_speech_prob": 3.069616650464013e-05}, {"id": 1682, "seek": 740154, "start": 7424.14, "end": 7426.66, "text": " really understand how it's meant to work.", "tokens": [534, 1223, 577, 309, 311, 4140, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.1696758270263672, "compression_ratio": 1.6774193548387097, "no_speech_prob": 3.069616650464013e-05}, {"id": 1683, "seek": 740154, "start": 7426.66, "end": 7428.78, "text": " So that's always interesting.", "tokens": [407, 300, 311, 1009, 1880, 13], "temperature": 0.0, "avg_logprob": -0.1696758270263672, "compression_ratio": 1.6774193548387097, "no_speech_prob": 3.069616650464013e-05}, {"id": 1684, "seek": 742878, "start": 7428.78, "end": 7434.74, "text": " Stas Beckman has created this nice dev projects index, which you can go onto the forum in", "tokens": [745, 296, 19184, 1601, 575, 2942, 341, 1481, 1905, 4455, 8186, 11, 597, 291, 393, 352, 3911, 264, 17542, 294], "temperature": 0.0, "avg_logprob": -0.1696545260769504, "compression_ratio": 1.723809523809524, "no_speech_prob": 3.0234441510401666e-05}, {"id": 1685, "seek": 742878, "start": 7434.74, "end": 7440.42, "text": " the Fast AI dev section and find, actually the dev project section, and find here's some", "tokens": [264, 15968, 7318, 1905, 3541, 293, 915, 11, 767, 264, 1905, 1716, 3541, 11, 293, 915, 510, 311, 512], "temperature": 0.0, "avg_logprob": -0.1696545260769504, "compression_ratio": 1.723809523809524, "no_speech_prob": 3.0234441510401666e-05}, {"id": 1686, "seek": 742878, "start": 7440.42, "end": 7442.5, "text": " stuff going on that you might want to get involved in.", "tokens": [1507, 516, 322, 300, 291, 1062, 528, 281, 483, 3288, 294, 13], "temperature": 0.0, "avg_logprob": -0.1696545260769504, "compression_ratio": 1.723809523809524, "no_speech_prob": 3.0234441510401666e-05}, {"id": 1687, "seek": 742878, "start": 7442.5, "end": 7443.78, "text": " Or maybe there's stuff you want to exist.", "tokens": [1610, 1310, 456, 311, 1507, 291, 528, 281, 2514, 13], "temperature": 0.0, "avg_logprob": -0.1696545260769504, "compression_ratio": 1.723809523809524, "no_speech_prob": 3.0234441510401666e-05}, {"id": 1688, "seek": 742878, "start": 7443.78, "end": 7445.98, "text": " You could add your own.", "tokens": [509, 727, 909, 428, 1065, 13], "temperature": 0.0, "avg_logprob": -0.1696545260769504, "compression_ratio": 1.723809523809524, "no_speech_prob": 3.0234441510401666e-05}, {"id": 1689, "seek": 742878, "start": 7445.98, "end": 7446.98, "text": " Create a study group.", "tokens": [20248, 257, 2979, 1594, 13], "temperature": 0.0, "avg_logprob": -0.1696545260769504, "compression_ratio": 1.723809523809524, "no_speech_prob": 3.0234441510401666e-05}, {"id": 1690, "seek": 742878, "start": 7446.98, "end": 7450.5, "text": " You know, Dean has already created a study group for San Francisco starting in January.", "tokens": [509, 458, 11, 13324, 575, 1217, 2942, 257, 2979, 1594, 337, 5271, 12279, 2891, 294, 7061, 13], "temperature": 0.0, "avg_logprob": -0.1696545260769504, "compression_ratio": 1.723809523809524, "no_speech_prob": 3.0234441510401666e-05}, {"id": 1691, "seek": 742878, "start": 7450.5, "end": 7452.86, "text": " This is how easy it is to create a study group.", "tokens": [639, 307, 577, 1858, 309, 307, 281, 1884, 257, 2979, 1594, 13], "temperature": 0.0, "avg_logprob": -0.1696545260769504, "compression_ratio": 1.723809523809524, "no_speech_prob": 3.0234441510401666e-05}, {"id": 1692, "seek": 742878, "start": 7452.86, "end": 7457.38, "text": " Go on the forum, find your little time zone subcategory, and add a post saying, let's", "tokens": [1037, 322, 264, 17542, 11, 915, 428, 707, 565, 6668, 1422, 66, 48701, 11, 293, 909, 257, 2183, 1566, 11, 718, 311], "temperature": 0.0, "avg_logprob": -0.1696545260769504, "compression_ratio": 1.723809523809524, "no_speech_prob": 3.0234441510401666e-05}, {"id": 1693, "seek": 745738, "start": 7457.38, "end": 7458.82, "text": " create a study group.", "tokens": [1884, 257, 2979, 1594, 13], "temperature": 0.0, "avg_logprob": -0.17042856950026292, "compression_ratio": 1.68359375, "no_speech_prob": 1.5445244571310468e-05}, {"id": 1694, "seek": 745738, "start": 7458.82, "end": 7464.5, "text": " But make sure you give people a little Google sheet to sign up, some way to actually do", "tokens": [583, 652, 988, 291, 976, 561, 257, 707, 3329, 8193, 281, 1465, 493, 11, 512, 636, 281, 767, 360], "temperature": 0.0, "avg_logprob": -0.17042856950026292, "compression_ratio": 1.68359375, "no_speech_prob": 1.5445244571310468e-05}, {"id": 1695, "seek": 745738, "start": 7464.5, "end": 7465.5, "text": " something.", "tokens": [746, 13], "temperature": 0.0, "avg_logprob": -0.17042856950026292, "compression_ratio": 1.68359375, "no_speech_prob": 1.5445244571310468e-05}, {"id": 1696, "seek": 745738, "start": 7465.5, "end": 7473.14, "text": " A great example is Pierre, who's been doing a fantastic job in Brazil of running study", "tokens": [316, 869, 1365, 307, 28461, 11, 567, 311, 668, 884, 257, 5456, 1691, 294, 9435, 295, 2614, 2979], "temperature": 0.0, "avg_logprob": -0.17042856950026292, "compression_ratio": 1.68359375, "no_speech_prob": 1.5445244571310468e-05}, {"id": 1697, "seek": 745738, "start": 7473.14, "end": 7475.86, "text": " groups for the last couple of parts of the course.", "tokens": [3935, 337, 264, 1036, 1916, 295, 3166, 295, 264, 1164, 13], "temperature": 0.0, "avg_logprob": -0.17042856950026292, "compression_ratio": 1.68359375, "no_speech_prob": 1.5445244571310468e-05}, {"id": 1698, "seek": 745738, "start": 7475.86, "end": 7480.66, "text": " And he keeps posting these pictures of people having a good time and learning deep learning", "tokens": [400, 415, 5965, 15978, 613, 5242, 295, 561, 1419, 257, 665, 565, 293, 2539, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.17042856950026292, "compression_ratio": 1.68359375, "no_speech_prob": 1.5445244571310468e-05}, {"id": 1699, "seek": 745738, "start": 7480.66, "end": 7485.14, "text": " together, creating wikis together, creating projects together.", "tokens": [1214, 11, 4084, 261, 1035, 271, 1214, 11, 4084, 4455, 1214, 13], "temperature": 0.0, "avg_logprob": -0.17042856950026292, "compression_ratio": 1.68359375, "no_speech_prob": 1.5445244571310468e-05}, {"id": 1700, "seek": 745738, "start": 7485.14, "end": 7487.14, "text": " Great experience.", "tokens": [3769, 1752, 13], "temperature": 0.0, "avg_logprob": -0.17042856950026292, "compression_ratio": 1.68359375, "no_speech_prob": 1.5445244571310468e-05}, {"id": 1701, "seek": 748714, "start": 7487.14, "end": 7493.58, "text": " And then come back for part two, right, where we'll be looking at all of this interesting", "tokens": [400, 550, 808, 646, 337, 644, 732, 11, 558, 11, 689, 321, 603, 312, 1237, 412, 439, 295, 341, 1880], "temperature": 0.0, "avg_logprob": -0.13422893075382009, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.9764609280391596e-05}, {"id": 1702, "seek": 748714, "start": 7493.58, "end": 7494.58, "text": " stuff.", "tokens": [1507, 13], "temperature": 0.0, "avg_logprob": -0.13422893075382009, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.9764609280391596e-05}, {"id": 1703, "seek": 748714, "start": 7494.58, "end": 7498.34, "text": " In particular, going deep into the Fast AI code base to understand how did we build it", "tokens": [682, 1729, 11, 516, 2452, 666, 264, 15968, 7318, 3089, 3096, 281, 1223, 577, 630, 321, 1322, 309], "temperature": 0.0, "avg_logprob": -0.13422893075382009, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.9764609280391596e-05}, {"id": 1704, "seek": 748714, "start": 7498.34, "end": 7499.34, "text": " exactly.", "tokens": [2293, 13], "temperature": 0.0, "avg_logprob": -0.13422893075382009, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.9764609280391596e-05}, {"id": 1705, "seek": 748714, "start": 7499.34, "end": 7504.660000000001, "text": " We'll actually go through, as we were building it, we created notebooks of like here is where", "tokens": [492, 603, 767, 352, 807, 11, 382, 321, 645, 2390, 309, 11, 321, 2942, 43782, 295, 411, 510, 307, 689], "temperature": 0.0, "avg_logprob": -0.13422893075382009, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.9764609280391596e-05}, {"id": 1706, "seek": 748714, "start": 7504.660000000001, "end": 7505.660000000001, "text": " we were at each stage.", "tokens": [321, 645, 412, 1184, 3233, 13], "temperature": 0.0, "avg_logprob": -0.13422893075382009, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.9764609280391596e-05}, {"id": 1707, "seek": 748714, "start": 7505.660000000001, "end": 7508.18, "text": " So we're actually going to see the software development process itself.", "tokens": [407, 321, 434, 767, 516, 281, 536, 264, 4722, 3250, 1399, 2564, 13], "temperature": 0.0, "avg_logprob": -0.13422893075382009, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.9764609280391596e-05}, {"id": 1708, "seek": 748714, "start": 7508.18, "end": 7513.26, "text": " We'll talk about the process of doing research, how to read academic papers, how to turn math", "tokens": [492, 603, 751, 466, 264, 1399, 295, 884, 2132, 11, 577, 281, 1401, 7778, 10577, 11, 577, 281, 1261, 5221], "temperature": 0.0, "avg_logprob": -0.13422893075382009, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.9764609280391596e-05}, {"id": 1709, "seek": 751326, "start": 7513.26, "end": 7519.26, "text": " into code, and then a whole bunch of additional types of models that we haven't seen yet.", "tokens": [666, 3089, 11, 293, 550, 257, 1379, 3840, 295, 4497, 3467, 295, 5245, 300, 321, 2378, 380, 1612, 1939, 13], "temperature": 0.0, "avg_logprob": -0.11942211110541161, "compression_ratio": 1.5481171548117154, "no_speech_prob": 4.826863369089551e-05}, {"id": 1710, "seek": 751326, "start": 7519.26, "end": 7526.08, "text": " So it'll be kind of like going beyond practical deep learning into actually cutting edge research.", "tokens": [407, 309, 603, 312, 733, 295, 411, 516, 4399, 8496, 2452, 2539, 666, 767, 6492, 4691, 2132, 13], "temperature": 0.0, "avg_logprob": -0.11942211110541161, "compression_ratio": 1.5481171548117154, "no_speech_prob": 4.826863369089551e-05}, {"id": 1711, "seek": 751326, "start": 7526.08, "end": 7531.14, "text": " So we've got five minutes to take some questions.", "tokens": [407, 321, 600, 658, 1732, 2077, 281, 747, 512, 1651, 13], "temperature": 0.0, "avg_logprob": -0.11942211110541161, "compression_ratio": 1.5481171548117154, "no_speech_prob": 4.826863369089551e-05}, {"id": 1712, "seek": 751326, "start": 7531.14, "end": 7534.3, "text": " We had an AMA going on online.", "tokens": [492, 632, 364, 6475, 32, 516, 322, 2950, 13], "temperature": 0.0, "avg_logprob": -0.11942211110541161, "compression_ratio": 1.5481171548117154, "no_speech_prob": 4.826863369089551e-05}, {"id": 1713, "seek": 751326, "start": 7534.3, "end": 7538.900000000001, "text": " And so we're going to have time for a couple of the highest ranked AMA questions from the", "tokens": [400, 370, 321, 434, 516, 281, 362, 565, 337, 257, 1916, 295, 264, 6343, 20197, 6475, 32, 1651, 490, 264], "temperature": 0.0, "avg_logprob": -0.11942211110541161, "compression_ratio": 1.5481171548117154, "no_speech_prob": 4.826863369089551e-05}, {"id": 1714, "seek": 751326, "start": 7538.900000000001, "end": 7539.900000000001, "text": " community.", "tokens": [1768, 13], "temperature": 0.0, "avg_logprob": -0.11942211110541161, "compression_ratio": 1.5481171548117154, "no_speech_prob": 4.826863369089551e-05}, {"id": 1715, "seek": 753990, "start": 7539.9, "end": 7544.339999999999, "text": " The first one is by Jeremy's request, although it's not the highest ranked.", "tokens": [440, 700, 472, 307, 538, 17809, 311, 5308, 11, 4878, 309, 311, 406, 264, 6343, 20197, 13], "temperature": 0.0, "avg_logprob": -0.17391390319264263, "compression_ratio": 1.5577689243027888, "no_speech_prob": 2.5432369511690922e-05}, {"id": 1716, "seek": 753990, "start": 7544.339999999999, "end": 7545.94, "text": " What's your typical day like?", "tokens": [708, 311, 428, 7476, 786, 411, 30], "temperature": 0.0, "avg_logprob": -0.17391390319264263, "compression_ratio": 1.5577689243027888, "no_speech_prob": 2.5432369511690922e-05}, {"id": 1717, "seek": 753990, "start": 7545.94, "end": 7549.5, "text": " How do you manage your time across so many things that you do?", "tokens": [1012, 360, 291, 3067, 428, 565, 2108, 370, 867, 721, 300, 291, 360, 30], "temperature": 0.0, "avg_logprob": -0.17391390319264263, "compression_ratio": 1.5577689243027888, "no_speech_prob": 2.5432369511690922e-05}, {"id": 1718, "seek": 753990, "start": 7549.5, "end": 7553.78, "text": " Yeah, I thought that I hear that all the time.", "tokens": [865, 11, 286, 1194, 300, 286, 1568, 300, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.17391390319264263, "compression_ratio": 1.5577689243027888, "no_speech_prob": 2.5432369511690922e-05}, {"id": 1719, "seek": 753990, "start": 7553.78, "end": 7555.339999999999, "text": " So I thought I should answer it.", "tokens": [407, 286, 1194, 286, 820, 1867, 309, 13], "temperature": 0.0, "avg_logprob": -0.17391390319264263, "compression_ratio": 1.5577689243027888, "no_speech_prob": 2.5432369511690922e-05}, {"id": 1720, "seek": 753990, "start": 7555.339999999999, "end": 7559.0199999999995, "text": " And I think I got a few votes.", "tokens": [400, 286, 519, 286, 658, 257, 1326, 12068, 13], "temperature": 0.0, "avg_logprob": -0.17391390319264263, "compression_ratio": 1.5577689243027888, "no_speech_prob": 2.5432369511690922e-05}, {"id": 1721, "seek": 753990, "start": 7559.0199999999995, "end": 7566.78, "text": " Because I think people who come to our study group are always shocked at how disorganized", "tokens": [1436, 286, 519, 561, 567, 808, 281, 527, 2979, 1594, 366, 1009, 12763, 412, 577, 717, 12372, 1602], "temperature": 0.0, "avg_logprob": -0.17391390319264263, "compression_ratio": 1.5577689243027888, "no_speech_prob": 2.5432369511690922e-05}, {"id": 1722, "seek": 753990, "start": 7566.78, "end": 7568.94, "text": " and incompetent I am.", "tokens": [293, 41602, 317, 286, 669, 13], "temperature": 0.0, "avg_logprob": -0.17391390319264263, "compression_ratio": 1.5577689243027888, "no_speech_prob": 2.5432369511690922e-05}, {"id": 1723, "seek": 756894, "start": 7568.94, "end": 7572.74, "text": " And so I often hear people saying, oh, wow, I thought you were like this deep learning", "tokens": [400, 370, 286, 2049, 1568, 561, 1566, 11, 1954, 11, 6076, 11, 286, 1194, 291, 645, 411, 341, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.10011966963459674, "compression_ratio": 1.6996197718631179, "no_speech_prob": 8.939327926782425e-06}, {"id": 1724, "seek": 756894, "start": 7572.74, "end": 7573.74, "text": " role model.", "tokens": [3090, 2316, 13], "temperature": 0.0, "avg_logprob": -0.10011966963459674, "compression_ratio": 1.6996197718631179, "no_speech_prob": 8.939327926782425e-06}, {"id": 1725, "seek": 756894, "start": 7573.74, "end": 7575.219999999999, "text": " And I'd get to see how to be like you.", "tokens": [400, 286, 1116, 483, 281, 536, 577, 281, 312, 411, 291, 13], "temperature": 0.0, "avg_logprob": -0.10011966963459674, "compression_ratio": 1.6996197718631179, "no_speech_prob": 8.939327926782425e-06}, {"id": 1726, "seek": 756894, "start": 7575.219999999999, "end": 7578.62, "text": " And now I'm not sure I want to be like you at all.", "tokens": [400, 586, 286, 478, 406, 988, 286, 528, 281, 312, 411, 291, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.10011966963459674, "compression_ratio": 1.6996197718631179, "no_speech_prob": 8.939327926782425e-06}, {"id": 1727, "seek": 756894, "start": 7578.62, "end": 7585.82, "text": " So yeah, for me, it's all about just having a good time with it.", "tokens": [407, 1338, 11, 337, 385, 11, 309, 311, 439, 466, 445, 1419, 257, 665, 565, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.10011966963459674, "compression_ratio": 1.6996197718631179, "no_speech_prob": 8.939327926782425e-06}, {"id": 1728, "seek": 756894, "start": 7585.82, "end": 7587.9, "text": " I never really have many plans.", "tokens": [286, 1128, 534, 362, 867, 5482, 13], "temperature": 0.0, "avg_logprob": -0.10011966963459674, "compression_ratio": 1.6996197718631179, "no_speech_prob": 8.939327926782425e-06}, {"id": 1729, "seek": 756894, "start": 7587.9, "end": 7591.46, "text": " I just try to finish what I start.", "tokens": [286, 445, 853, 281, 2413, 437, 286, 722, 13], "temperature": 0.0, "avg_logprob": -0.10011966963459674, "compression_ratio": 1.6996197718631179, "no_speech_prob": 8.939327926782425e-06}, {"id": 1730, "seek": 756894, "start": 7591.46, "end": 7594.58, "text": " If you're not having fun with it, it's really, really hard to continue.", "tokens": [759, 291, 434, 406, 1419, 1019, 365, 309, 11, 309, 311, 534, 11, 534, 1152, 281, 2354, 13], "temperature": 0.0, "avg_logprob": -0.10011966963459674, "compression_ratio": 1.6996197718631179, "no_speech_prob": 8.939327926782425e-06}, {"id": 1731, "seek": 756894, "start": 7594.58, "end": 7596.94, "text": " Because there's a lot of frustration in deep learning.", "tokens": [1436, 456, 311, 257, 688, 295, 20491, 294, 2452, 2539, 13], "temperature": 0.0, "avg_logprob": -0.10011966963459674, "compression_ratio": 1.6996197718631179, "no_speech_prob": 8.939327926782425e-06}, {"id": 1732, "seek": 759694, "start": 7596.94, "end": 7603.58, "text": " Because it's not like writing a web app, where it's like, authentication, check.", "tokens": [1436, 309, 311, 406, 411, 3579, 257, 3670, 724, 11, 689, 309, 311, 411, 11, 26643, 11, 1520, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1733, "seek": 759694, "start": 7603.58, "end": 7607.66, "text": " Backend service watchdog, check.", "tokens": [5833, 521, 2643, 1159, 14833, 11, 1520, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1734, "seek": 759694, "start": 7607.66, "end": 7609.219999999999, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1735, "seek": 759694, "start": 7609.219999999999, "end": 7611.219999999999, "text": " User credentials, check.", "tokens": [32127, 27404, 11, 1520, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1736, "seek": 759694, "start": 7611.219999999999, "end": 7612.219999999999, "text": " You're making progress.", "tokens": [509, 434, 1455, 4205, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1737, "seek": 759694, "start": 7612.219999999999, "end": 7613.219999999999, "text": " Where else?", "tokens": [2305, 1646, 30], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1738, "seek": 759694, "start": 7613.219999999999, "end": 7616.74, "text": " For stuff like this, and stuff that we've been doing the last couple of weeks, it's", "tokens": [1171, 1507, 411, 341, 11, 293, 1507, 300, 321, 600, 668, 884, 264, 1036, 1916, 295, 3259, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1739, "seek": 759694, "start": 7616.74, "end": 7619.0599999999995, "text": " just like, it's not working.", "tokens": [445, 411, 11, 309, 311, 406, 1364, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1740, "seek": 759694, "start": 7619.0599999999995, "end": 7620.0599999999995, "text": " It's not working.", "tokens": [467, 311, 406, 1364, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1741, "seek": 759694, "start": 7620.0599999999995, "end": 7621.0599999999995, "text": " It's not working.", "tokens": [467, 311, 406, 1364, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1742, "seek": 759694, "start": 7621.0599999999995, "end": 7622.0599999999995, "text": " No, that also didn't work.", "tokens": [883, 11, 300, 611, 994, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1743, "seek": 759694, "start": 7622.0599999999995, "end": 7625.379999999999, "text": " Oh, that also didn't work until, oh, my god, it's amazing.", "tokens": [876, 11, 300, 611, 994, 380, 589, 1826, 11, 1954, 11, 452, 3044, 11, 309, 311, 2243, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1744, "seek": 759694, "start": 7625.379999999999, "end": 7626.58, "text": " It's a cat.", "tokens": [467, 311, 257, 3857, 13], "temperature": 0.0, "avg_logprob": -0.23674960788205374, "compression_ratio": 1.7708333333333333, "no_speech_prob": 2.8406109777279198e-05}, {"id": 1745, "seek": 762658, "start": 7626.58, "end": 7627.78, "text": " That's kind of what it is.", "tokens": [663, 311, 733, 295, 437, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.12758136930919828, "compression_ratio": 1.7330316742081449, "no_speech_prob": 3.0714152671862394e-05}, {"id": 1746, "seek": 762658, "start": 7627.78, "end": 7630.18, "text": " So you don't get that regular feedback.", "tokens": [407, 291, 500, 380, 483, 300, 3890, 5824, 13], "temperature": 0.0, "avg_logprob": -0.12758136930919828, "compression_ratio": 1.7330316742081449, "no_speech_prob": 3.0714152671862394e-05}, {"id": 1747, "seek": 762658, "start": 7630.18, "end": 7635.22, "text": " So yeah, you've got to have fun with it.", "tokens": [407, 1338, 11, 291, 600, 658, 281, 362, 1019, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.12758136930919828, "compression_ratio": 1.7330316742081449, "no_speech_prob": 3.0714152671862394e-05}, {"id": 1748, "seek": 762658, "start": 7635.22, "end": 7644.1, "text": " And so my day is kind of, you know, I mean, the other thing I'll say, I don't do any meetings.", "tokens": [400, 370, 452, 786, 307, 733, 295, 11, 291, 458, 11, 286, 914, 11, 264, 661, 551, 286, 603, 584, 11, 286, 500, 380, 360, 604, 8410, 13], "temperature": 0.0, "avg_logprob": -0.12758136930919828, "compression_ratio": 1.7330316742081449, "no_speech_prob": 3.0714152671862394e-05}, {"id": 1749, "seek": 762658, "start": 7644.1, "end": 7645.26, "text": " I don't do phone calls.", "tokens": [286, 500, 380, 360, 2593, 5498, 13], "temperature": 0.0, "avg_logprob": -0.12758136930919828, "compression_ratio": 1.7330316742081449, "no_speech_prob": 3.0714152671862394e-05}, {"id": 1750, "seek": 762658, "start": 7645.26, "end": 7646.86, "text": " I don't do coffees.", "tokens": [286, 500, 380, 360, 24768, 4031, 13], "temperature": 0.0, "avg_logprob": -0.12758136930919828, "compression_ratio": 1.7330316742081449, "no_speech_prob": 3.0714152671862394e-05}, {"id": 1751, "seek": 762658, "start": 7646.86, "end": 7647.86, "text": " I don't watch TV.", "tokens": [286, 500, 380, 1159, 3558, 13], "temperature": 0.0, "avg_logprob": -0.12758136930919828, "compression_ratio": 1.7330316742081449, "no_speech_prob": 3.0714152671862394e-05}, {"id": 1752, "seek": 762658, "start": 7647.86, "end": 7649.46, "text": " I don't play computer games.", "tokens": [286, 500, 380, 862, 3820, 2813, 13], "temperature": 0.0, "avg_logprob": -0.12758136930919828, "compression_ratio": 1.7330316742081449, "no_speech_prob": 3.0714152671862394e-05}, {"id": 1753, "seek": 762658, "start": 7649.46, "end": 7655.42, "text": " I spend a lot of time with my family, a lot of time exercising, and a lot of time reading", "tokens": [286, 3496, 257, 688, 295, 565, 365, 452, 1605, 11, 257, 688, 295, 565, 27272, 11, 293, 257, 688, 295, 565, 3760], "temperature": 0.0, "avg_logprob": -0.12758136930919828, "compression_ratio": 1.7330316742081449, "no_speech_prob": 3.0714152671862394e-05}, {"id": 1754, "seek": 765542, "start": 7655.42, "end": 7658.5, "text": " and coding and doing things I like.", "tokens": [293, 17720, 293, 884, 721, 286, 411, 13], "temperature": 0.0, "avg_logprob": -0.18150203704833984, "compression_ratio": 1.6, "no_speech_prob": 3.704261325765401e-05}, {"id": 1755, "seek": 765542, "start": 7658.5, "end": 7665.46, "text": " So I think the main thing is just finish something.", "tokens": [407, 286, 519, 264, 2135, 551, 307, 445, 2413, 746, 13], "temperature": 0.0, "avg_logprob": -0.18150203704833984, "compression_ratio": 1.6, "no_speech_prob": 3.704261325765401e-05}, {"id": 1756, "seek": 765542, "start": 7665.46, "end": 7666.46, "text": " Finish something.", "tokens": [31583, 746, 13], "temperature": 0.0, "avg_logprob": -0.18150203704833984, "compression_ratio": 1.6, "no_speech_prob": 3.704261325765401e-05}, {"id": 1757, "seek": 765542, "start": 7666.46, "end": 7668.62, "text": " Like, properly finish it.", "tokens": [1743, 11, 6108, 2413, 309, 13], "temperature": 0.0, "avg_logprob": -0.18150203704833984, "compression_ratio": 1.6, "no_speech_prob": 3.704261325765401e-05}, {"id": 1758, "seek": 765542, "start": 7668.62, "end": 7671.82, "text": " So when you get to that point where you think you're 80% of the way through, but you haven't", "tokens": [407, 562, 291, 483, 281, 300, 935, 689, 291, 519, 291, 434, 4688, 4, 295, 264, 636, 807, 11, 457, 291, 2378, 380], "temperature": 0.0, "avg_logprob": -0.18150203704833984, "compression_ratio": 1.6, "no_speech_prob": 3.704261325765401e-05}, {"id": 1759, "seek": 765542, "start": 7671.82, "end": 7677.0, "text": " quite created a readme yet, and the install process is still a bit clunky, and you know,", "tokens": [1596, 2942, 257, 1401, 1398, 1939, 11, 293, 264, 3625, 1399, 307, 920, 257, 857, 596, 25837, 11, 293, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.18150203704833984, "compression_ratio": 1.6, "no_speech_prob": 3.704261325765401e-05}, {"id": 1760, "seek": 765542, "start": 7677.0, "end": 7679.34, "text": " this is what 99% of GitHub projects look like.", "tokens": [341, 307, 437, 11803, 4, 295, 23331, 4455, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.18150203704833984, "compression_ratio": 1.6, "no_speech_prob": 3.704261325765401e-05}, {"id": 1761, "seek": 767934, "start": 7679.34, "end": 7686.62, "text": " You'll see the readme says, to do, you know, complete baseline experiments, document, blah,", "tokens": [509, 603, 536, 264, 1401, 1398, 1619, 11, 281, 360, 11, 291, 458, 11, 3566, 20518, 12050, 11, 4166, 11, 12288, 11], "temperature": 0.0, "avg_logprob": -0.18010387053856483, "compression_ratio": 1.6291666666666667, "no_speech_prob": 1.061441707861377e-05}, {"id": 1762, "seek": 767934, "start": 7686.62, "end": 7687.62, "text": " blah, blah.", "tokens": [12288, 11, 12288, 13], "temperature": 0.0, "avg_logprob": -0.18010387053856483, "compression_ratio": 1.6291666666666667, "no_speech_prob": 1.061441707861377e-05}, {"id": 1763, "seek": 767934, "start": 7687.62, "end": 7689.5, "text": " It's like, don't be that person.", "tokens": [467, 311, 411, 11, 500, 380, 312, 300, 954, 13], "temperature": 0.0, "avg_logprob": -0.18010387053856483, "compression_ratio": 1.6291666666666667, "no_speech_prob": 1.061441707861377e-05}, {"id": 1764, "seek": 767934, "start": 7689.5, "end": 7694.58, "text": " Just do something properly and finish it, and maybe get some other people around you", "tokens": [1449, 360, 746, 6108, 293, 2413, 309, 11, 293, 1310, 483, 512, 661, 561, 926, 291], "temperature": 0.0, "avg_logprob": -0.18010387053856483, "compression_ratio": 1.6291666666666667, "no_speech_prob": 1.061441707861377e-05}, {"id": 1765, "seek": 767934, "start": 7694.58, "end": 7702.400000000001, "text": " to work with you so that you're all doing it together and get it done.", "tokens": [281, 589, 365, 291, 370, 300, 291, 434, 439, 884, 309, 1214, 293, 483, 309, 1096, 13], "temperature": 0.0, "avg_logprob": -0.18010387053856483, "compression_ratio": 1.6291666666666667, "no_speech_prob": 1.061441707861377e-05}, {"id": 1766, "seek": 767934, "start": 7702.400000000001, "end": 7705.74, "text": " What are the up and coming deep learning, machine learning things that you are most", "tokens": [708, 366, 264, 493, 293, 1348, 2452, 2539, 11, 3479, 2539, 721, 300, 291, 366, 881], "temperature": 0.0, "avg_logprob": -0.18010387053856483, "compression_ratio": 1.6291666666666667, "no_speech_prob": 1.061441707861377e-05}, {"id": 1767, "seek": 767934, "start": 7705.74, "end": 7706.900000000001, "text": " excited about?", "tokens": [2919, 466, 30], "temperature": 0.0, "avg_logprob": -0.18010387053856483, "compression_ratio": 1.6291666666666667, "no_speech_prob": 1.061441707861377e-05}, {"id": 1768, "seek": 770690, "start": 7706.9, "end": 7711.339999999999, "text": " Also, you've mentioned last year that you are not a believer in reinforcement learning.", "tokens": [2743, 11, 291, 600, 2835, 1036, 1064, 300, 291, 366, 406, 257, 23892, 294, 29280, 2539, 13], "temperature": 0.0, "avg_logprob": -0.11840873119259669, "compression_ratio": 1.7245283018867925, "no_speech_prob": 5.735988088417798e-05}, {"id": 1769, "seek": 770690, "start": 7711.339999999999, "end": 7714.42, "text": " Do you still feel the same way?", "tokens": [1144, 291, 920, 841, 264, 912, 636, 30], "temperature": 0.0, "avg_logprob": -0.11840873119259669, "compression_ratio": 1.7245283018867925, "no_speech_prob": 5.735988088417798e-05}, {"id": 1770, "seek": 770690, "start": 7714.42, "end": 7718.299999999999, "text": " I still feel exactly the same way as I did three years ago when we started this, which", "tokens": [286, 920, 841, 2293, 264, 912, 636, 382, 286, 630, 1045, 924, 2057, 562, 321, 1409, 341, 11, 597], "temperature": 0.0, "avg_logprob": -0.11840873119259669, "compression_ratio": 1.7245283018867925, "no_speech_prob": 5.735988088417798e-05}, {"id": 1771, "seek": 770690, "start": 7718.299999999999, "end": 7721.86, "text": " is it's all about transfer learning.", "tokens": [307, 309, 311, 439, 466, 5003, 2539, 13], "temperature": 0.0, "avg_logprob": -0.11840873119259669, "compression_ratio": 1.7245283018867925, "no_speech_prob": 5.735988088417798e-05}, {"id": 1772, "seek": 770690, "start": 7721.86, "end": 7723.139999999999, "text": " It's underappreciated.", "tokens": [467, 311, 833, 1746, 3326, 770, 13], "temperature": 0.0, "avg_logprob": -0.11840873119259669, "compression_ratio": 1.7245283018867925, "no_speech_prob": 5.735988088417798e-05}, {"id": 1773, "seek": 770690, "start": 7723.139999999999, "end": 7724.259999999999, "text": " It's under-researched.", "tokens": [467, 311, 833, 12, 49838, 1178, 292, 13], "temperature": 0.0, "avg_logprob": -0.11840873119259669, "compression_ratio": 1.7245283018867925, "no_speech_prob": 5.735988088417798e-05}, {"id": 1774, "seek": 770690, "start": 7724.259999999999, "end": 7728.46, "text": " Every time we put transfer learning into anything, we make it much better.", "tokens": [2048, 565, 321, 829, 5003, 2539, 666, 1340, 11, 321, 652, 309, 709, 1101, 13], "temperature": 0.0, "avg_logprob": -0.11840873119259669, "compression_ratio": 1.7245283018867925, "no_speech_prob": 5.735988088417798e-05}, {"id": 1775, "seek": 770690, "start": 7728.46, "end": 7735.0199999999995, "text": " You know, our academic paper on transfer learning for NLP has, you know, helped be one piece", "tokens": [509, 458, 11, 527, 7778, 3035, 322, 5003, 2539, 337, 426, 45196, 575, 11, 291, 458, 11, 4254, 312, 472, 2522], "temperature": 0.0, "avg_logprob": -0.11840873119259669, "compression_ratio": 1.7245283018867925, "no_speech_prob": 5.735988088417798e-05}, {"id": 1776, "seek": 773502, "start": 7735.02, "end": 7737.42, "text": " of kind of changing the direction of NLP this year.", "tokens": [295, 733, 295, 4473, 264, 3513, 295, 426, 45196, 341, 1064, 13], "temperature": 0.0, "avg_logprob": -0.15486486967619476, "compression_ratio": 1.6791044776119404, "no_speech_prob": 8.605207403888926e-05}, {"id": 1777, "seek": 773502, "start": 7737.42, "end": 7740.46, "text": " It made it all the way to the New York Times.", "tokens": [467, 1027, 309, 439, 264, 636, 281, 264, 1873, 3609, 11366, 13], "temperature": 0.0, "avg_logprob": -0.15486486967619476, "compression_ratio": 1.6791044776119404, "no_speech_prob": 8.605207403888926e-05}, {"id": 1778, "seek": 773502, "start": 7740.46, "end": 7744.540000000001, "text": " Just a stupid, obvious little thing that we threw together.", "tokens": [1449, 257, 6631, 11, 6322, 707, 551, 300, 321, 11918, 1214, 13], "temperature": 0.0, "avg_logprob": -0.15486486967619476, "compression_ratio": 1.6791044776119404, "no_speech_prob": 8.605207403888926e-05}, {"id": 1779, "seek": 773502, "start": 7744.540000000001, "end": 7746.18, "text": " So I remain excited about that.", "tokens": [407, 286, 6222, 2919, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.15486486967619476, "compression_ratio": 1.6791044776119404, "no_speech_prob": 8.605207403888926e-05}, {"id": 1780, "seek": 773502, "start": 7746.18, "end": 7750.02, "text": " I remain unexcited about reinforcement learning for most things.", "tokens": [286, 6222, 11572, 66, 1226, 466, 29280, 2539, 337, 881, 721, 13], "temperature": 0.0, "avg_logprob": -0.15486486967619476, "compression_ratio": 1.6791044776119404, "no_speech_prob": 8.605207403888926e-05}, {"id": 1781, "seek": 773502, "start": 7750.02, "end": 7755.900000000001, "text": " I don't see it used by normal people for normal things for nearly anything.", "tokens": [286, 500, 380, 536, 309, 1143, 538, 2710, 561, 337, 2710, 721, 337, 6217, 1340, 13], "temperature": 0.0, "avg_logprob": -0.15486486967619476, "compression_ratio": 1.6791044776119404, "no_speech_prob": 8.605207403888926e-05}, {"id": 1782, "seek": 773502, "start": 7755.900000000001, "end": 7760.46, "text": " It's an incredibly inefficient way to solve problems which are often solved more simply", "tokens": [467, 311, 364, 6252, 43495, 636, 281, 5039, 2740, 597, 366, 2049, 13041, 544, 2935], "temperature": 0.0, "avg_logprob": -0.15486486967619476, "compression_ratio": 1.6791044776119404, "no_speech_prob": 8.605207403888926e-05}, {"id": 1783, "seek": 773502, "start": 7760.46, "end": 7761.9400000000005, "text": " and more quickly in other ways.", "tokens": [293, 544, 2661, 294, 661, 2098, 13], "temperature": 0.0, "avg_logprob": -0.15486486967619476, "compression_ratio": 1.6791044776119404, "no_speech_prob": 8.605207403888926e-05}, {"id": 1784, "seek": 776194, "start": 7761.94, "end": 7770.419999999999, "text": " It probably has maybe a role in the world, but a limited one and not in most people's", "tokens": [467, 1391, 575, 1310, 257, 3090, 294, 264, 1002, 11, 457, 257, 5567, 472, 293, 406, 294, 881, 561, 311], "temperature": 0.0, "avg_logprob": -0.14777979097868266, "compression_ratio": 1.4397905759162304, "no_speech_prob": 5.134231469128281e-05}, {"id": 1785, "seek": 776194, "start": 7770.419999999999, "end": 7779.099999999999, "text": " day-to-day work.", "tokens": [786, 12, 1353, 12, 810, 589, 13], "temperature": 0.0, "avg_logprob": -0.14777979097868266, "compression_ratio": 1.4397905759162304, "no_speech_prob": 5.134231469128281e-05}, {"id": 1786, "seek": 776194, "start": 7779.099999999999, "end": 7783.86, "text": " For someone planning to take part two in 2019, what would you recommend doing learning practicing", "tokens": [1171, 1580, 5038, 281, 747, 644, 732, 294, 6071, 11, 437, 576, 291, 2748, 884, 2539, 11350], "temperature": 0.0, "avg_logprob": -0.14777979097868266, "compression_ratio": 1.4397905759162304, "no_speech_prob": 5.134231469128281e-05}, {"id": 1787, "seek": 776194, "start": 7783.86, "end": 7788.219999999999, "text": " until the part two course starts?", "tokens": [1826, 264, 644, 732, 1164, 3719, 30], "temperature": 0.0, "avg_logprob": -0.14777979097868266, "compression_ratio": 1.4397905759162304, "no_speech_prob": 5.134231469128281e-05}, {"id": 1788, "seek": 776194, "start": 7788.219999999999, "end": 7789.219999999999, "text": " Just code.", "tokens": [1449, 3089, 13], "temperature": 0.0, "avg_logprob": -0.14777979097868266, "compression_ratio": 1.4397905759162304, "no_speech_prob": 5.134231469128281e-05}, {"id": 1789, "seek": 776194, "start": 7789.219999999999, "end": 7791.219999999999, "text": " Yeah, just code all the time.", "tokens": [865, 11, 445, 3089, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.14777979097868266, "compression_ratio": 1.4397905759162304, "no_speech_prob": 5.134231469128281e-05}, {"id": 1790, "seek": 779122, "start": 7791.22, "end": 7792.46, "text": " I know it's perfectly possible.", "tokens": [286, 458, 309, 311, 6239, 1944, 13], "temperature": 0.0, "avg_logprob": -0.1395705023477244, "compression_ratio": 1.7252747252747254, "no_speech_prob": 1.593499655427877e-05}, {"id": 1791, "seek": 779122, "start": 7792.46, "end": 7795.7, "text": " I hear from people who get to this point of the course and they haven't actually written", "tokens": [286, 1568, 490, 561, 567, 483, 281, 341, 935, 295, 264, 1164, 293, 436, 2378, 380, 767, 3720], "temperature": 0.0, "avg_logprob": -0.1395705023477244, "compression_ratio": 1.7252747252747254, "no_speech_prob": 1.593499655427877e-05}, {"id": 1792, "seek": 779122, "start": 7795.7, "end": 7796.7, "text": " any code yet.", "tokens": [604, 3089, 1939, 13], "temperature": 0.0, "avg_logprob": -0.1395705023477244, "compression_ratio": 1.7252747252747254, "no_speech_prob": 1.593499655427877e-05}, {"id": 1793, "seek": 779122, "start": 7796.7, "end": 7799.22, "text": " And if that's you, it's okay.", "tokens": [400, 498, 300, 311, 291, 11, 309, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.1395705023477244, "compression_ratio": 1.7252747252747254, "no_speech_prob": 1.593499655427877e-05}, {"id": 1794, "seek": 779122, "start": 7799.22, "end": 7804.46, "text": " You know, you just go through and do it again and this time do code.", "tokens": [509, 458, 11, 291, 445, 352, 807, 293, 360, 309, 797, 293, 341, 565, 360, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1395705023477244, "compression_ratio": 1.7252747252747254, "no_speech_prob": 1.593499655427877e-05}, {"id": 1795, "seek": 779122, "start": 7804.46, "end": 7808.66, "text": " And look at the input, the shapes of your inputs and look at your outputs and make sure", "tokens": [400, 574, 412, 264, 4846, 11, 264, 10854, 295, 428, 15743, 293, 574, 412, 428, 23930, 293, 652, 988], "temperature": 0.0, "avg_logprob": -0.1395705023477244, "compression_ratio": 1.7252747252747254, "no_speech_prob": 1.593499655427877e-05}, {"id": 1796, "seek": 779122, "start": 7808.66, "end": 7812.820000000001, "text": " you know how to grab a mini-batch and look at its mean and standard deviation and plot", "tokens": [291, 458, 577, 281, 4444, 257, 8382, 12, 65, 852, 293, 574, 412, 1080, 914, 293, 3832, 25163, 293, 7542], "temperature": 0.0, "avg_logprob": -0.1395705023477244, "compression_ratio": 1.7252747252747254, "no_speech_prob": 1.593499655427877e-05}, {"id": 1797, "seek": 779122, "start": 7812.820000000001, "end": 7818.92, "text": " it and, you know, there's so much material that we've covered.", "tokens": [309, 293, 11, 291, 458, 11, 456, 311, 370, 709, 2527, 300, 321, 600, 5343, 13], "temperature": 0.0, "avg_logprob": -0.1395705023477244, "compression_ratio": 1.7252747252747254, "no_speech_prob": 1.593499655427877e-05}, {"id": 1798, "seek": 781892, "start": 7818.92, "end": 7828.34, "text": " If you can get to a point where you can, you know, rebuild those notebooks from scratch", "tokens": [759, 291, 393, 483, 281, 257, 935, 689, 291, 393, 11, 291, 458, 11, 16877, 729, 43782, 490, 8459], "temperature": 0.0, "avg_logprob": -0.18583395628802543, "compression_ratio": 1.714859437751004, "no_speech_prob": 1.0780478078231681e-05}, {"id": 1799, "seek": 781892, "start": 7828.34, "end": 7829.62, "text": " without too much cheating.", "tokens": [1553, 886, 709, 18309, 13], "temperature": 0.0, "avg_logprob": -0.18583395628802543, "compression_ratio": 1.714859437751004, "no_speech_prob": 1.0780478078231681e-05}, {"id": 1800, "seek": 781892, "start": 7829.62, "end": 7835.7, "text": " When I say from scratch, I mean using the Fast AI library, not from scratch from scratch,", "tokens": [1133, 286, 584, 490, 8459, 11, 286, 914, 1228, 264, 15968, 7318, 6405, 11, 406, 490, 8459, 490, 8459, 11], "temperature": 0.0, "avg_logprob": -0.18583395628802543, "compression_ratio": 1.714859437751004, "no_speech_prob": 1.0780478078231681e-05}, {"id": 1801, "seek": 781892, "start": 7835.7, "end": 7840.26, "text": " you know, you'll be in the top echelon of practitioners because you'll be able to do", "tokens": [291, 458, 11, 291, 603, 312, 294, 264, 1192, 36803, 338, 266, 295, 25742, 570, 291, 603, 312, 1075, 281, 360], "temperature": 0.0, "avg_logprob": -0.18583395628802543, "compression_ratio": 1.714859437751004, "no_speech_prob": 1.0780478078231681e-05}, {"id": 1802, "seek": 781892, "start": 7840.26, "end": 7843.76, "text": " all of these things yourself and that's really, really rare.", "tokens": [439, 295, 613, 721, 1803, 293, 300, 311, 534, 11, 534, 5892, 13], "temperature": 0.0, "avg_logprob": -0.18583395628802543, "compression_ratio": 1.714859437751004, "no_speech_prob": 1.0780478078231681e-05}, {"id": 1803, "seek": 781892, "start": 7843.76, "end": 7845.86, "text": " And that'll put you in a great position for part two.", "tokens": [400, 300, 603, 829, 291, 294, 257, 869, 2535, 337, 644, 732, 13], "temperature": 0.0, "avg_logprob": -0.18583395628802543, "compression_ratio": 1.714859437751004, "no_speech_prob": 1.0780478078231681e-05}, {"id": 1804, "seek": 781892, "start": 7845.86, "end": 7847.58, "text": " Should we do one more?", "tokens": [6454, 321, 360, 472, 544, 30], "temperature": 0.0, "avg_logprob": -0.18583395628802543, "compression_ratio": 1.714859437751004, "no_speech_prob": 1.0780478078231681e-05}, {"id": 1805, "seek": 784758, "start": 7847.58, "end": 7850.82, "text": " Nine o'clock, yeah, let's do one more.", "tokens": [18939, 277, 6, 9023, 11, 1338, 11, 718, 311, 360, 472, 544, 13], "temperature": 0.0, "avg_logprob": -0.20012054914309654, "compression_ratio": 1.402116402116402, "no_speech_prob": 6.394858792191371e-05}, {"id": 1806, "seek": 784758, "start": 7850.82, "end": 7856.0199999999995, "text": " Where do you see the Fast AI library going in the future, say in five years?", "tokens": [2305, 360, 291, 536, 264, 15968, 7318, 6405, 516, 294, 264, 2027, 11, 584, 294, 1732, 924, 30], "temperature": 0.0, "avg_logprob": -0.20012054914309654, "compression_ratio": 1.402116402116402, "no_speech_prob": 6.394858792191371e-05}, {"id": 1807, "seek": 784758, "start": 7856.0199999999995, "end": 7859.22, "text": " Well, like I said, I don't make plans.", "tokens": [1042, 11, 411, 286, 848, 11, 286, 500, 380, 652, 5482, 13], "temperature": 0.0, "avg_logprob": -0.20012054914309654, "compression_ratio": 1.402116402116402, "no_speech_prob": 6.394858792191371e-05}, {"id": 1808, "seek": 784758, "start": 7859.22, "end": 7861.7, "text": " I just piss around.", "tokens": [286, 445, 15171, 926, 13], "temperature": 0.0, "avg_logprob": -0.20012054914309654, "compression_ratio": 1.402116402116402, "no_speech_prob": 6.394858792191371e-05}, {"id": 1809, "seek": 784758, "start": 7861.7, "end": 7872.66, "text": " So I mean our only plan for Fast AI, you know, as an organization is to make deep learning", "tokens": [407, 286, 914, 527, 787, 1393, 337, 15968, 7318, 11, 291, 458, 11, 382, 364, 4475, 307, 281, 652, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.20012054914309654, "compression_ratio": 1.402116402116402, "no_speech_prob": 6.394858792191371e-05}, {"id": 1810, "seek": 787266, "start": 7872.66, "end": 7878.04, "text": " accessible as a tool for normal people to use for normal stuff.", "tokens": [9515, 382, 257, 2290, 337, 2710, 561, 281, 764, 337, 2710, 1507, 13], "temperature": 0.0, "avg_logprob": -0.09647860093550249, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.2824360712547787e-05}, {"id": 1811, "seek": 787266, "start": 7878.04, "end": 7881.62, "text": " So as long as we need to code, we failed at that.", "tokens": [407, 382, 938, 382, 321, 643, 281, 3089, 11, 321, 7612, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.09647860093550249, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.2824360712547787e-05}, {"id": 1812, "seek": 787266, "start": 7881.62, "end": 7888.38, "text": " So the big goal, you know, because 99.8% of the world can't code.", "tokens": [407, 264, 955, 3387, 11, 291, 458, 11, 570, 11803, 13, 23, 4, 295, 264, 1002, 393, 380, 3089, 13], "temperature": 0.0, "avg_logprob": -0.09647860093550249, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.2824360712547787e-05}, {"id": 1813, "seek": 787266, "start": 7888.38, "end": 7891.54, "text": " So the main goal would be to get to a point where it's not a library but it's a piece", "tokens": [407, 264, 2135, 3387, 576, 312, 281, 483, 281, 257, 935, 689, 309, 311, 406, 257, 6405, 457, 309, 311, 257, 2522], "temperature": 0.0, "avg_logprob": -0.09647860093550249, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.2824360712547787e-05}, {"id": 1814, "seek": 787266, "start": 7891.54, "end": 7893.3, "text": " of software that doesn't require code.", "tokens": [295, 4722, 300, 1177, 380, 3651, 3089, 13], "temperature": 0.0, "avg_logprob": -0.09647860093550249, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.2824360712547787e-05}, {"id": 1815, "seek": 787266, "start": 7893.3, "end": 7901.139999999999, "text": " It certainly shouldn't require a goddamn lengthy, hardworking course like this one, you know.", "tokens": [467, 3297, 4659, 380, 3651, 257, 32951, 35374, 11, 1152, 22475, 1164, 411, 341, 472, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.09647860093550249, "compression_ratio": 1.6446280991735538, "no_speech_prob": 2.2824360712547787e-05}, {"id": 1816, "seek": 790114, "start": 7901.14, "end": 7904.9800000000005, "text": " So I want to get rid of the course, I want to get rid of the code, I want to make it", "tokens": [407, 286, 528, 281, 483, 3973, 295, 264, 1164, 11, 286, 528, 281, 483, 3973, 295, 264, 3089, 11, 286, 528, 281, 652, 309], "temperature": 0.0, "avg_logprob": -0.14824445748034817, "compression_ratio": 1.5449101796407185, "no_speech_prob": 1.7498075976618566e-05}, {"id": 1817, "seek": 790114, "start": 7904.9800000000005, "end": 7909.12, "text": " so you can just do useful stuff quickly and easily.", "tokens": [370, 291, 393, 445, 360, 4420, 1507, 2661, 293, 3612, 13], "temperature": 0.0, "avg_logprob": -0.14824445748034817, "compression_ratio": 1.5449101796407185, "no_speech_prob": 1.7498075976618566e-05}, {"id": 1818, "seek": 790114, "start": 7909.12, "end": 7912.62, "text": " So that's maybe five years, yeah, maybe longer.", "tokens": [407, 300, 311, 1310, 1732, 924, 11, 1338, 11, 1310, 2854, 13], "temperature": 0.0, "avg_logprob": -0.14824445748034817, "compression_ratio": 1.5449101796407185, "no_speech_prob": 1.7498075976618566e-05}, {"id": 1819, "seek": 790114, "start": 7912.62, "end": 7913.62, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.14824445748034817, "compression_ratio": 1.5449101796407185, "no_speech_prob": 1.7498075976618566e-05}, {"id": 1820, "seek": 790114, "start": 7913.62, "end": 7915.62, "text": " Well, I hope to see you all back here for part two.", "tokens": [1042, 11, 286, 1454, 281, 536, 291, 439, 646, 510, 337, 644, 732, 13], "temperature": 0.0, "avg_logprob": -0.14824445748034817, "compression_ratio": 1.5449101796407185, "no_speech_prob": 1.7498075976618566e-05}, {"id": 1821, "seek": 790114, "start": 7915.62, "end": 7916.62, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.14824445748034817, "compression_ratio": 1.5449101796407185, "no_speech_prob": 1.7498075976618566e-05}, {"id": 1822, "seek": 791662, "start": 7916.62, "end": 7937.54, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 51410], "temperature": 1.0, "avg_logprob": -1.6238555908203125, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.0017553521320223808}], "language": "en"}