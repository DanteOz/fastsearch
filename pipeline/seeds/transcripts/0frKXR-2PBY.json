{"text": " Okay, so today we're going to continue working on object detection Which means that for every object in a photo in one of 20 classes We're going to try and figure out what the object is and what its bounding box is Such that we can apply that model to a new data set of unlabeled data and add those labels to it The general approach we're going to use is to start simple and gradually make it more complicated So we started last week with a simple classifier the three lines of code classifier We then made it slightly more complex to turn it into a bounding box without a classifier Today we're going to put those two pieces together to make a classifier plus a bounding box All of these are just for a single object the largest object and then from there. We'll build up to something Which is closer to our final goal? This is the final goal that we are aiming towards You should go back and make sure that you understand all of these concepts from last week before you move on if you don't Go back and we go through the notebooks carefully I won't read them all to you because you can see in the video easily enough That perhaps this is the most important knowing how to jump around source code in whatever editor You At plot there's lambda functions lambda functions also particularly important they come up everywhere And this idea of a custom head is also going to come up in pretty much every lesson I've also added here a Reminder of what you should know from part one of the course because quite often I see questions on the forum asking Basically, why isn't my model working like why doesn't it start training or? Having trained why doesn't it seem to be any use and Nearly always the answer to the question is Did you print out the inputs to it from a data loader? did you print out the outputs from it after evaluating and Normally the answer is no and I try printing it and turns out all the inputs are zero or all the outputs are negative or it's like It's really obvious. So that's just one of something I wanted to remind you about is that you need to know how to do these two things and if you Hey, if you can't do that, it's gonna be very hard to debug models and They if you can do that, but you're not doing it Then it's going to be very happy to debug models. You can debug models by staring at the source code Hoping your error pops out you debug models by Checking all the intermediate steps looking at the data Printing it out plotting its histogram making sure it makes sense Okay, so We were working through Pascal notebook and we just Quickly zipped through the bounding box of the largest object Without a classifier part and there was one bit that I skipped over and said I've come back to so let's do that now Which is to talk about Augmentations data augmentations Data augmentations of the the y of the dependent variable But for I'll do I just mentioned something Pretty awkward in in all this which is I've got here image classifier data Continuous equals true this makes no sense whatsoever a classifier is anything where the dependent variable is categorical or binomial as opposed to regression which is anything where the Continuous and yet this parameter here continuous equals true says that the dependent variable is continuous So this claims to be creating data for a classifier where the dependent is continuous. This is the kind of awkward rough edge that you see when we're kind of at this like You know that the edge of the past AI code. It's not Quite solidified yet. So probably by the time you watch this in the MOOC This will be sorted out and this will be called image regressor data or something like that But you know, I just wanted to kind of Point out this this issue and also because sometimes people were getting confused between regression versus classification and this is not One bit. Okay, so let's create some data augmentations right now. Normally when we create data augmentations we tend to type in like transform side on or transforms part damn Okay, but if you look inside the fast AI dot transforms module, you'll see that they are simply defined as a list So this is a good transforms basic which is 10 degree rotations plus 0.05 brightness and contrast and then side on adds to that random horizontal flips Or else top down adds to that random dihedral group of 8 symmetry flips which basically means Every possible 90 degree rotation optionally So like these are just little Shortcuts that I added because they seem to be useful a lot of the time, but you can always create your own List of augmentations, right? And if you're not sure what augmentations are there You can obviously check the past source or if you just start typing random They all start with random so you can see them easily enough So let's take a look at what happens if we create some data augmentations create a model data object and let's just go through and rerun the iterator a bunch of times and We'll do two things. We'll print out the bounding boxes And so you can see the bounding box is the same time and we will also draw the pictures So you'll see This lady is as we would expect flipping around and spinning around and getting darker and lighter but the bounding box a Is not moving and B is in the wrong spot. So this is the problem with data augmentation when your dependent variable You know is pixel values or is in some way connected to your independent variable the two need to be augmented together And in fact, you can see that from the printout these numbers are bigger than two to four But these images are of size two to four. That's what we requested in this in this trans once And so it's not even being like scaled or cropped or anything. All right, so you can see that Our dependent variable needs to go through all of the same geometric transformations as our independent variable So to do that Every transformation has an optional transform y parameter It takes a transform type enum The transform type enum has a few options all of which we'll cover in this course The co-ord option says that the y values represent coordinates In this case bounding box coordinates, okay And so therefore if you flip you need to change the coordinate to represent that flip or if you rotate you to change the coordinates You rotate interchange the coordinates represent that rotation so I can add transform type of chord to all of my augmentations. I also have to add the exact same thing to my transforms from model function because that's the thing that does the cropping and or zooming and or padding and or Resizing and all of those things need to happen to the dependent as well All right, so if we add all of those together and rerun this you'll see the bounding box changes each time and You'll see it's in the right spot Now you'll see sometimes It looks a little odd like here. Why is that bounding box there? And the problem is This is just a constraint that the information we have right the bounding box does not tell us That actually her head isn't way over here in the top left corner Right, but actually if you do a 30 degree rotation and her head was over here in the top left corner Then the new bounding box would need would go really high Right. So this is actually the correct bounding box based on the information it has available Which is to say this is this is how high she might have been so basically you've got to be careful of not doing too higher rotations with bounding boxes because there's not enough information for them to stay Totally accurate fundamental limitation with the information we're given if we were doing like polygons or segmentations or whatever we wouldn't have this problem Okay, so I'm going to do maximum of three degree rotations to avoid that problem I'm also going to only rotate half the time My random flip I'm going to have my brightness and contrast changing and so there's my set of transformations So we briefly looked at this custom head idea But basically if you look at dot summary dot summary does something pretty cool which is it basically runs a small batch of data through a model and prints out how big it is at every in every layer and we can see that at the end of the convolutional section before we hit the flatten it's 512 by 7 by 7 Okay, and so 512 by 7 by 7 tensor rank 3 tensor of that size if we flatten it out into a single rank 1 tensor into a vector it's going to be 225,000 and 88 long right so then that's why we had this linear layer For because of the four bounding boxes right so stick that on top of a pre trained ResNet and Train it for a while Okay, so that's where we got to last time so let's now put those two pieces together so that we can get something that classifies and does bounding boxes and there are There are three things that we need to do Basically to train a neural network ever right we need to provide data We need to pick some kind of architecture and We did it loss function Okay, so the loss function says you know something anything that gives a lower number here is a better network Using this data in this architecture So we're going to need to create those three things for our classification plus bounding box regression So That means we need a Model data object which has as the independence the images and as the dependence I want to have a tuple the first element of the tuple should be the bounding box coordinates and the second element The tuple should be the class okay There's lots of different ways you could do this the particularly lazy and convenient way I came up with Was to create two model data objects Representing the two different dependent variables. I want so one with the bounding box coordinates one of the classes Just using the CSP to build them for And now I'm going to merge them together So I create a new data set class and a data set class is anything which has a length and an indexer And so in this case I can have a constructor which takes an existing data set so that's going to have both independent and dependent and the second Dependent that I want The length then is just obviously the length of the data set the first data set and then get item is grab the X and the Y from the data set that passed in and return that X and that Y and The I value of the second dependent variable that passed in right so there's a data set that basically adds In a second dependent variable as I said there's lots of ways you could do this It's kind of convenient because now what I could do is I can create Training data set and validation data set based on that So here's an example. You can see it's got a couple of the bounding box coordinates in the class We can then take the existing training and validation data loaders and actually replace their data sets with these and done done okay, so we can now test it by grabbing a mini batch of data and checking that we Have something that makes sense. Okay, so There's one way to Customize a data set So what we're going to do this time now is we've got the data so now we need an architecture So the architecture is going to be the same as the architectures that we used for the classifier and for the bounding box Aggression, but we're just going to combine them. So in other words if there are C classes Then the number of activations we need in the final layer is 4 plus C for bounding box coordinates and the C probabilities one per class so this is the final layer a linear layer that has four plus when of categories activations The first layer is before as a flatten We could just join those up together, but in general I want my my custom head to like Hopefully be capable of solving the problem That I give it on its own if the pre trained backbone is connected to is You know is appropriate and so in this case, I'm thinking okay I'm trying to do like quite a bit here two different things that classifier and bounding box aggression So just a single linear layer doesn't sound like enough so I put in a second linear layer Okay, and so you can see we basically go value dropout linear Reli you batch norm dropout. Yeah, if you're wondering why there's no batch norm back here I checked the ResNet backbone it already has a batch norm as its final layer Okay, so this is basically a nearly the same Custom head as before it's just it's got two linear layers rather than one and the appropriate nonlinearities, okay, so That's piece two. We've got theta. We've got architecture Now we need a loss function. So the loss function needs to look at these four plus C activations and Decide are they good right are these numbers accurately reflecting the Position and class of the largest object in this image We we know how to do that For the last for the first four we use L1 loss just like we did in the bounding box regression before remember L1 loss is like mean squared error They're out the sum of squares its sum of absolute values sum of absolute values and Then for the rest of the activations we can use cross entropy loss So let's go ahead and do that. So we're going to create something called detection loss And loss functions always take an input and a target. That's what pytorch always calls them. So this is the Activations this is the ground truth so remember that our our date custom data set returns a tuple containing the Bounding box coordinates in the classes so we can destructure that use destructuring assignment to grab the bounding boxes and the classes of the target okay, and then the bounding boxes and the classes of the input are simply the first four elements of the input and the 24 onwards elements of the input and remember we've also got a batch Dimension that we need to grab the whole thing. Okay, so that's it. We've now got the bounding box target bounding box input class target class input For the bounding boxes, we know that they're going to be between 0 and 2 2 4 the coordinates because that's how big our image is right, so Let's grab a sigmoid force it between 0 and 1 multiply it by 2 2 4 and that's just helping our Neural net, you know get close to what we you know be in the range. We know it has to be As a general rule, is it better to put batch norm before or after a value? I Would suggest that you should put it after a value because batch norm is meant to move towards a 0 and 1 random variable And if you put value after it, then you're trying getting it at 0 So there's no way to create negative numbers, but if you put Rally you and then that's normal. It does have that ability Having said that And I think that that way of doing it gives slightly better results having said that it's Not too big a deal either way and you'll see during this part of the course most of the time I go Rally you and then that's norm, but sometimes I go back to norm and then value If I'm trying to like be consistent with a paper or something like that So I think originally the batch normal is put it after the activation. So there's still people to do that Okay, so this is kind of to help our data Or force our data into the right range, which you know if you can do stuff like that It makes it easier to train. Yes, Rachel one more question What's the intuition behind using dropout with P equals 0.5 after a batch norm? Doesn't batch norm already do a good job of regularizing? That's not doesn't okay job of regularizing but if you think back to part one, we kind of had that list of things we do to avoid overfitting and adding batch norm is one of them as is data augmentation, but it's Perfectly possible that you'll still be able to be So one nice thing about dropout is that it has a parameter to say How much to drop out and so that like parameters are great like or specifically parameters that decide how much to regularize? Great because it lets you build a nice big overparameterized model and then decide how much to regularize it so Yeah, I tend to always include dropout and then if it turns out I You know I'll start with P equals 0 and then as I add need to add regularization. I can just change my dropout parameter Without worrying about you know if I saved a model I want to be able to load it back But if I had dropout layers in one and not in another or load me more so this way it stays consistent Okay, so now that I've got my Inputs and targets I can just go hey calculate the L1 loss and add to it the cross entropy All right, so that's our That's our loss function It's surprisingly easy perhaps now of course the cross entropy and the L1 loss may be of wildly different scales In which case in the loss function the larger one is going to dominate and so I just ran this in a debugger in a debugger Checked what you know you could just use print check how big each of the two things were and found if I multiply by 20 That makes them about the same About the same scale As your training it's nice to print out information as you go so I also grabbed the L1 part of this and put it in a in a function and I also created a function for accuracy So that I could then make their metrics and so that printed out Alright, so we've now got something which is printing out our object detection loss detection accuracy and detection L1 And so we train it for a while And it's looking good our detection accuracy is in the low 80s Which is the same as what it was before that doesn't surprise me because like resnet was designed to do classification, so I wouldn't expect us to be able to Improve things in such a simple way But it certainly wasn't designed to do bounding box regression It was explicitly actually designed in such a way as to be as to kind of not care about geometry Right, it takes that last seven by seven grid of activations and averages them all together throws away all of the information about So so you can see that the When we only train the last layer the detection L1 Is is pretty bad 24 and it really improves a lot right where else the accuracy? Doesn't improve this is exactly the same Interestingly the L1 when we do accuracy and bounding box at the same time at 8.5 Seems like it's a little bit better than when we just do bounding box regression and If that's counterintuitive to you then that's would be one of the main things to think about after this lesson So it's a really important idea and the idea is this Figuring out Figuring out What the main object in an image is is kind of the hard part and then figuring out by Exactly where the bounding box is and what class it is is kind of the easy part in a way And so when you've got a single Network is both saying what is the object and where is the object? It's going to share all of the computation about like finding the object Okay, and so all that shared information over that shared computation is very efficient And so when we back propagate the errors in You know the class and in the place That's all information that's going to help the computation around like finding the biggest object. So anytime you've got multiple Tasks which kind of share some some concept of what those tasks would need to do to complete their work It's very likely they should share at least some layers of the network together and We'll look later today at a place where Most of the layers are shared but I've just the last one isn't Okay, so you can see this is doing a good job as before of any time. There's just a single major object Sometimes it's getting a little confused. It thinks the main object here is the dog and it's kind of served with the dog Although it's kind of recognized that actually the main object is a sulfur and so the classifiers doing the right thing with the bounding boxes When there are two birds, it can only pick one so it's just kind of hedging in the middle Did oh and there's lots of cows and so forth doing good job with this car. All right, so that's So that's that right there's there's not much New there, although in that last bit we did learn about, you know, some simple custom data sets and simple custom lots functions Hopefully you can see now how easy that is to do So next stage for me would be to do multi-label classification So this is this idea that I just want to keep building models that are slightly more complex than the last model but Hopefully don't require too much extra concepts so I can kind of keep seeing things working and if something stops working I know exactly where it works. I don't try and build everything at the same time So multi-label classification is so easy. It's there's not much to mention. So we've moved to Pascal multi now. This is what we're going to do the multi object stuff So for the multi object stuff, I've just copied and pasted the functions from the previous Notebook that we used so they're all at the top so we can create now a multi-class A multi-class CSV file using the same basic approach that we did last time and I'll mention by the way One of our students actually who's visiting from India funny Pointed out to me that all this stuff we're doing with Default Dix and stuff like that He actually showed a way of doing it which was much simpler using pandas and he shared that on the forum. So I Totally bowed to his much better approach a much simpler more concise approach And yeah, it's definitely true. Like the more you get to know pandas The more often you realize it's a good way to solve lots of different problems. So definitely check that out When you're building out the smaller models and you're iterating do you reuse those models as pre-trained weights for this like larger one or do you just toss it all away and then Retrain from scratch with when I'm kind of like figuring stuff out as a girl like this I would generally mean towards tossing away because they're kind of reusing the model So I would generally mean tossing away I would generally mean tossing away because they're kind of reusing pre-trained weights introduces complexities that I'm not really think about however, if I'm Trying to get to a point where I can run something on really big images I'll generally start on much smaller ones and often I will reuse those weights Okay, so in this case all we're doing is we're just Joining up all of the classes with a space which gives us a CSV in the normal format Once we've got the CSV in a normal format, it's the usual three lines of code and we train it And We print out the results. So there's literally nothing to show you and as you can see it's done a great job The only mistake I think it made was it called This dog grass should have been dog and sofa Okay, so Modi class classification is is pretty straightforward One minor tweak here is to note that I used a Set here because I don't want to list all of the objects I only want each object type to appear once and so the set class is a way of De-duplicating a list so that's why I don't have person person person person person just appears once so yeah these These object classification pre-trained networks. We have a really pretty good at Recognizing multiple objects as long as you only have to mention each one once so that works pretty well All right, so we've got this idea That we've got an input image That goes through a con Conv net, you know, which we're just kind of treated the black box and it spits out a Tensor a vector that size for passing right where C is the Number of classes and so that's what we've got and that gives us a an object detector for a single object the largest object So let's now create one which doesn't find a single object, but that finds 16 objects Okay so an obvious way to do that would be to take this last this is just a and end on linear right which has got however many inputs and Four plus C outputs we could take that linear layer and rather than having Four plus C outputs we could have 16 times four plus C outputs So it's now spitting out enough things to give us 16 sets of class probabilities and 16 sets of bounding box coordinates and Then we would just need a loss function That would check whether those 16 sets of bounding boxes correctly represented The up to 16 objects that were represented in the image now There's a lot of hand waving about the loss function. We'll go into it later as to what that is, but let's pretend we have one Assuming we had a reasonable loss function that's totally going to work Right that that is an architecture which has the necessary Output activations that with the correct loss function. We should be able to train it to do what we want it to do Okay But that's just one way to do it. There's a second way we could do it rather than having a NN dot linear What if instead we took from our Resnet convolutional background backbone not an in like linear, but instead we added a NN.com 2d with stride To Alright, so the final layer of resnet is Gets you a 7 by 7 by 512 as all right, so this would give us a 4 by 4 by By whatever number of filters result maybe for the number of filters. Let's say we pick 256 Okay, so it would be For for by 256 4 by 4 by 256 has Well actually no, let's change that let's not make it 4 by 4 by 256 better still let's do it all in one step Let's make it 4 by 4 by 4 plus C Because now We've got a tensor where the number of elements is exactly equal to the number of elements we wanted So in other words we could We could we could now if this would work too if we created a loss function That took a 4 by 4 by 4 plus C tensor and mapped it to 16 objects in the image and checked whether each one was correctly represented by Those 4 plus C activations that would work like these are two Exactly equivalent sets of activations because they got the same number of elements. They're just We shake Yeah, so it turns out that both of these approaches are actually used The approach where you basically just spit out one big long vector from a fully connected linear layer is used by a class of models known as Yolo Whereas the approach of the Convolutional activations is used by models which Started with something called SSD or single shot detector What I will say is that since these things came out at very similar times in late 2015 Things are very much moved towards Here to the point where this morning Yolo version 3 came out and is now doing it Yes, SD Okay, so that's what we're going to do. All right, we're going to do this and we're going to learn about Why this makes more sense as well? And so the basic idea is this Let's imagine that on top of underneath this we had another Another conv2d Strive to Then we'd have something which was two by two by again, let's say it's for plus C All right, that's nice and simple. And so basically it's creating a grid That looks something like this one, two, three four Okay, so that would be like how the activations are You know the geometry of the activations of that second extra convolutional stride to layer remember stride to convolution Does the same thing to the geometry of the activations as a stripe one convolution followed by a max pooling? So let's talk about what we might do here because the basic idea is like we want to kind of say all right this Top left grid cell is responsible for identifying any object that's in the top left And this one in the top right is responsible for identifying something in the top right this one bottom left This one the bottom right, okay So in this case you can actually see it started it said okay This one is going to try and find the chair this one It's actually made a mistake should have said table, but there are actually one two three chairs here as well So makes sense right so basically each of these grid cells It's going to be told in the loss function your job is to find the object You know the big object that's in that part of the image So what? So for a multi-label classification I saw you had a threshold on there Which I guess is a hyper parameter is there a way we're getting your well ahead. Let's let's work through this Okay All right, so why do we care about the idea that we would like this convolutional grid cell to be responsible for finding things that were in this part of the image and The reason is because of something called the receptive field of that convolutional grid cell and the basic idea is that throughout your convolutional layers every Every piece of those tensors has a receptive field which means which part of the Input image was responsible for calculating That cell right and like all things in life the easiest way to see this is with Microsoft Excel So do you remember? our convolutional neural net and this was endless and we had the number seven and it went through a a Two channel filter channel one channel two, right which therefore created a two channel output All right, and then the next layer was another convolution. So this tensor is now a 3d tensor right Which then creates a again two channel output and then after that we had our max pooling player So Let's look at this part of this output and the fact that this is common followed by max pool Let's just pretend as a stride to con. It's basically the same So let's see where this number 27 Came from so if you've got Excel You can go formulas trace precedence right and so you can see this came from these Four okay now where did those four come from? Those four came from obviously the convolutional filter kernel the panels and from these four parts of con one All right, because we've got Four things here each one of which has a three by three filter. And so we had three three three three together makes up for that for Where did those four come from? Those four came from Obviously our Filter and This entire part of the input image Okay, and what's more you can see and it also comes through this whole direction as well, right and you can see that These bits in the middle have lots of weights coming out Right where else these bits on the outside only have one weight coming out So we call this here the receptive field of This activation this activation Right, but note that the receptive field is not just saying It's this here box, but also that the center of the box has more dependencies Okay, so this is a critically important concept when it comes to kind of understanding architectures and understanding why Convents work the idea of the receptive field and there are some great articles if you just google for convolution receptive field You can find lots of terrific articles. I'm sure some of you will write much better ones during the week as well So that's the basic idea. All right, is that the receptive field of this convolutional activation is Generally centered around this part of the input image. So it should be responsible for finding objects that are here so That's the architecture The architecture is that we're going to have a resnet backbone followed by one or more 2d convolutions and for now we're just going to do one right which is going to give us a four by four grid And so let's take a look at that so Here it is we start with our value and dropout We then do let's just start at the output Well, I just go through and see what we've got here this one's not being used We start with a stride one Convolution and the reason we start with a stride one convolution is because that doesn't change the geometry at all It just lets us add an extra layer of calculations Right, let's just create, you know, not just a linear layer. But now we have like a little mini Neural network in our custom here All right, so we start with a stride one convolution and standard con is just something I defined up here which does convolution value batch norm drop cut like most research code you see Won't define a class like this instead. They'll write the entire thing again and again and again Convolution batch norm drop cut. It's like don't be like that right like that kind of duplicate code leads to errors and Leads to poor understanding and I mentioned that also because this week I released the first draft of the fast AI style guide and The fast AI style guide is very heavily oriented towards the idea of Expository programming which is the idea that programming code should be something that you can use to explain an idea ideally as readily as mathematical notation to somebody that understands your your coding method and so the idea actually goes back a very long way, but it was Best described in the Turing Award lecture This is like the Nobel computer science the Turing Award lecture of 1979 by probably my greatest computer science hero Ken Iverson He had been working on it since well well before 1964, but 1964 was the first Example of this approach to programming he released on called APL And then 25 years later, he won the Turing Award He then passed on the bat on to his son Eric Iverson and there's been basically 50 or 60 years now of continuous development of this idea of like what does programming look like when it's designed to to be a notation notation as a tool for thought for expository programming and so I've made a very shoddy attempt at taking some of these ideas and thinking about how can they be applied to Python programming with all the limitations by comparison that Python has anyway, so But you know here's a very simple example Is that if you write all of these things again and again and again then it really hides the fact that you've got you know Two convolutional layers one of stride one one of stride two So my default the standard comp is stride two That's right one. This is a stride two and then at the end So this the output of this is going to be four by four, right? I've got a Outcon and an outcome is interesting. You can see it's got two separate convolutional layers each of which is stride one so it's not changing the Geometry of the input. All right, one of them is of length of the number of classes Just ignore K for now K is equal to K is equal to 1 at this point of the code So it's not doing anything. So one is equal to the length of the number of classes One is equal to 4 and so this is this idea of rather than having a single Comp layer that outputs 4 plus C. Let's have two comp layers one of which outputs 4 one of which outputs C and then I will just return them as a list of two items That's nearly the same thing. It's nearly the same thing as having a single comp layer that outputs 4 plus C But it lets it lets these layers specialize just a little bit right, so like we talked about this idea that When you've got kind of multiple tasks, they can share layers, but they don't have to share all the layers So in this case our two tasks, which is fine create a classifier and create down box aggression Share every single layer except the very last one Okay, and so this is going to spit out two separate Tenses of activations one of the classes and one of the bounding box coordinates Why am I adding one? That's because I'm going to have one more class for background right so if there aren't actually 16 objects to detect Or if there isn't an object in this corner represented by this convolutional grid cell then I wanted to predict background So that's the entirety That's the entirety of our architecture. It's incredibly Simple right but the point is now that we You know we have this convolutional layer at the end One thing I do do is that I at the very end I flatten out the convolution Basically because I wrote the loss function to expect a flattened out tensor But I we could totally rewrite it to not do that I might even try doing that during the week and see which one looks easier to understand Okay So we've got our data We've got our architecture So now all we need is a loss function Okay, so the loss function needs to look at each of these 16 sets of activations each of which you're going to have four bounding box coordinates and C plus 1 plus probabilities and decide Are those activations? Close or far away from The object which is kind of closest to this This this grid cell in the image And if nothing's there, then you know are you predicting background? correctly So That turns out to be very hard to do Because let's go back to the two by two example to keep it simple The loss function actually needs to take each of the objects in the image and match them To one of these convolutional grid cells to say like this Grid cell is responsible for this particular object and this grid cell is responsible for this particular object So then it can go ahead and say like okay how close are the four coordinates and how close are the class probabilities? Right. So this is called the matching problem and In order to explain it. I'm going to show it to you But what I'm going to do first is I'm going to take a break Okay, and we're going to come back and understand the maxi map the matching problem So during the break have a think about how would you design a loss function here? How would you design a function which has a lower value if these 16 times 4 plus K activations? You know somehow better reflect the up to 16 objects Which are actually in the ground truth image and we'll come back at 740 So here's our goal our Our Dependent variable basically looks Like that and as I just an extract from our CSV file independent and our Final Convolution or layer is going to be a bunch of numbers which initially is a For by four Five in this case. I think C is equal to 20 plus we've got one for background right so 4 plus 21 equals 26 or 4 right and then we We flatten that out into a vector We flatten that out into a vector and so basically our goal then is to say to some particular Set of activations that ended up coming out of this model for some let's let's pick some particular Dependent variable we need some function that takes in that and that right and where It feeds back a higher number If these activations aren't a good reflection of the ground truth bounding boxes or a lower number It is a good reflection of the ground truth bounding boxes. That's our goal. We need to create that function And so the general approach to creating that function Will be the first of all to simplify it down of two by two version Will be the first of all well actually I'll show you right Here's a model I trained earlier Okay, and let's run through I've taken the loss function, and I've split it line by line So that you can see every line that goes into making it okay, so So let's say So let's grab our validation set data loader grab a batch from it Turn them into variables so we can stick them into a model put the model in evaluation mode Stick that data into we don't actually need Stick that data into our model to grab a batch of activations and remember That the the final output convolution returned two items All right the the classes and the bounding boxes so we can do destructuring assignment to grab the two pieces the batch of classes and Outputs and the batch of bounding box outputs okay And so as expected the batch of class outputs is batch size 64 by 16 grid cells by 21 classes and then 64 by 16 by 4 for the bounding box coordinates Okay, hopefully that all makes sense and after class go back and just make sure if it's not obvious Why these are the shapes make sure you get to the point where you understand why they are Let's now go back and look at the The ground truth so the ground truth is is in this y variable so let's grab the Bounding box part and the class part and put them into These two Python variables and print them out and so there's our Ground truth bounding boxes and there's our ground truth classes. So this this image apparently has three objects in it. So let's Draw a picture of the three objects and there they are Okay, we already have a show ground truth function the torch Ground-truth function simply converts the tensors into numpy and passes them along so that we can print them out So here we've got the bounding box Coordinates you'll notice that they've all been scaled to zero to what between zero and one Okay, so basically we're treating the image as being like one by one. So these are all relative to the size of the image There's our three classes and so here they are chair is zero dining table is one and two is sofa This is not a model. This is the ground truth Great Here is our four by four grid cells from our final convolutional letter So each of these square boxes Different papers call them different things the three terms you'll hear are anchor boxes prior boxes or default boxes, okay and Through this explanation you'll get a sense of what they are. But for now think of them as just these 16 squares I'm going to stick with the term anchor boxes. Okay, these 16 squares are our anchor boxes So what we're going to do for this loss function is we're going to go through a matching problem Where we're going to take every one of these 16 boxes and we're going to see Which one of these three round truth objects has the highest amount of overlap? with this square Okay So to do that, we're going to need to know We're going to have to have some way of measuring We're going to have to have some way of measuring an amount of overlap and there's a standard Function for this which is called the jacquard index And the jacquard index is very simple. I'll do it through example. Let's take this sofa Okay, so if we take this sofa and let's take the jacquard index of this sofa with this grid cell here All right. What we do is we find the area of their intersection so Here is the area of their intersection Okay, and then we find the area of their union. So here is the Area of their you that's not very helpful. Here's the area of their union Okay, and then we say take the intersection divided by the union Okay, and so that's jacquard index Also known as I O you intersection over That's of two things overlapped by more compared to their total sizes together. They have a higher jacquard index all right, so We're going to go through and find the jacquard Overlap for each one of these three objects versus each of these 16 anchor boxes And so that's going to give us a 3 by 16 matrix But for every ground truth object and every anchor box how much overlap is there? So here are the coordinates of all of our anchor boxes In this case, they're printed as center and height and width And So here is the amount of overlap Between and as you can see it's 3 by 16 right so for each of the three Ground truth objects for each of these 16 anchor boxes how much do they overlap right so you can see here zero one two three four five six seven eight? the eighth anchor box overlaps a little bit with the second ground truth object okay, so What we could do now is we could take the max of dimension one All right, so the max of each row and that will tell us for each ground truth object What's the maximum amount that it overlaps with some grid cell and? It also tells us remember pi torch when you say max returns two things it says what is the max and what is the index? of the max so for each of these things the 14th grid cell is the largest It is 14th is the largest overlap for the first ground truth 13 for the second Okay, and 11 for the third Okay, so that tells us You know a pretty good way of assigning each of these ground truth objects to a grid cell what what the match is is which? One is the highest overlap But we're going to do a second thing we're also going to look at max over dimension zero And max over dimension zero is going to tell us What's the maximum amount of overlap for each grid cell so across all of the ground truth objects? Right and so particularly interesting here tells us for every grid cell 16 What's the index of the ground truth object which overlaps with it the most? Zero is a bit overloaded here zero could either mean the amount of overlap was zero or It could mean its largest overlap is with object index zero It's going to turn out not to matter that I just wanted to explain why there's so many zeros here So there's a function called map to ground truth, which I'm not going to worry about for now. It's it's super simple code, but it's slightly awkward to To think about but basically what it does is it combines these two sets of overlaps in a way described in the SSD paper? to assign every anchor box to a ground truth object and basically the way it assigns it is Each of these ones each of these three gets assigned in this way right so this one this object is assigned to bounding object to bound to anchor box 14 this one to 13 and this one to 11 and then of the rest of the anchor boxes They get assigned to anything which they have an overlap of at least 0.5 with if anything that doesn't Which isn't in either of those criteria? ie which either isn't a maximum or doesn't have a greater than 0.5 overlap is considered to be A cell which contains background Okay, so that's all the map to ground truth function does and so after we go through it You can see now a list of all of the assignments and you can also see Anywhere that there's a zero here it means it was assigned background in fact anywhere. It's less than 0.5 here It was assigned a background so you can see those three Which it kind of forced assignments that puts a high number in just to make sure that they're assigned all right so we can now Go ahead and convert those two classes And then we can make sure we just grab those which are at least 0.5 in size and so finally that allows us to spit out the three classes that are being predicted We can then put that back into the bounding boxes and so here are What each of those bounding boxes is sorry what each of those anchor boxes? What each of those anchor boxes is meant to be predicting okay, so You can see sofa dining room table chair which makes perfect sense if we go back to here This is meant to be predicting sofa This is meant to be predicting dining room table This is meant to be predicting chair and everything else is meant to be predicting background So that's the matching stage So once we've done the matching stage we're basically done we can take the The activations Just grab those which which matched that's what this positive indexes are subtract from those the ground truth bounding boxes Just for those which matched positive ones Take the absolute value of the difference take the mean of that and that's about one loss and then for the Classifications we can just do cross entropy and then as before we can add them together Okay, so that's the Basic idea There's a few and so this is this is what's going to happen right we're going to end up with 16 Recommended you know predicted bounding boxes coming out most of them will be background So you all these ones that say BG but from time to time they'll say this is a cow This is part of plant. This is car Okay, if you're wondering like how does it predict in terms of the bounding box of background? The answer is totally ignores it right. That's why we had this Only positive indexes thing here right so if it's background. There's no You know sense of like where's the correct bounding box of background is totally meaningless So the only ones where the bounding box makes sense out of all these are the ones that aren't There are some important little tweaks one is that the How do we interpret the activations and so the way we interpret the activations Is defined here in Activation to bounding box and so basically we grab the activations we stick them through fan and So remember fan is the same as sigmoid That's shape except it's scaled to be between negative 1 and 1 not between 0 So it's a basically a sigmoid function that goes between negative 1 and 1 and so that forces it to be within that range and we then say okay, let's grab the the actual position of the anchor boxes and we will Move them around according to the value of the activations divided by 2 so in other words each each each activate each each predicted bounding box can be moved by up to 50% of a grid size from where its default position is and ditto for its height and width it can be up to Twice as big or half as big as its default size So So that's one thing is we have to convert the activations Into some kind of way of scaling those default anchor box positions Another thing is we don't actually use cross-entropy We actually use binary cross-entropy loss So remember binary cross-entropy loss is what we normally use for multi-label classification like in the Planet Amazon satellite competition Planet Amazon satellite competition each satellite image could have multiple things in it Okay, so if it's got multiple things in it you can't use softmax Because softmax kind of really encourages just one thing to have the high number In our case each anchor box can only have one object associated with it So it's it's not for that reason that we're avoiding softmax. It's something else which is It's possible for an anchor box to have nothing associated with it So there'd be two ways to handle that this idea of background one would be to say you know what backgrounds just a class Right so let's use softmax right and just treat background as one of the classes that the softmax could could predict a Lot of people have done it this way. I don't like that though right because That's a really hard thing to ask a neural network to do is basically to say Can you tell whether this grid cell? Doesn't have any of the 20 objects that I'm interested with a jihad overlap of more than 0.5 Now that's a really hard thing to put into a single computation On the other hand what if we just had for each class? You know is it a motorbike is it a bus is it a person? Dining room table right and then it can check each of those and be no no no no no and it's no to all of them It's like oh background all right, so that's that's the way. I'm doing it is it's not that we could have multiple True labels, but we can have zero True labels, and so that's what's going on here. We take our Target and we do a one-hot embedding with number of classes plus one so at this stage We do have the idea of background for the one-hot embedding, but then we remove The last column so the background columns now gone Right and so now this vectors either of all zeros basically Meaning there's nothing here or it has at most one one And so then we can use binary cross entropy to compare our predictions with that target That is a minor tweak right but like It's the kind of minor tweak that I I want you to think about and understand because it's a really Like it makes a it makes a really big difference In practice to your training and it's the kind of thing that you'll see a lot of papers talk about like often when there's some Increment over some previous paper. It'll be something like this somebody realizes like oh trying to predict a Background category using a softmax is really hard thing to do what if we use the binary cross entropy instead You know and so it's kind of like if you understand What this is doing and more importantly why we're doing it That's a really good test of your understanding of the material and if you don't that's fine, right? This shows you this is something that you need to maybe go back and rewatch this part Video and talk to some of your classmates and if necessary ask for the forum until you understand What are we doing? Okay So that's what this that's what this binary cross entropy loss Lost function is doing so basically in this part of the code. We've got this custom loss function We've got the thing that calculates that a card index We've got the thing that converts activations to bounding box. We've got the thing that does map to ground truth that we looked at Okay, and that's it all that's left is the SSD loss Function so the SSD loss function. This is actually what we set Yeah as our crit as our criterion is SSD loss So what SSD loss class is it it loops through? each image in the mini-batch and It calls SSD one loss so SSD loss for one image So this function is really where it's all happening. This is calculating the SSD loss for one image right, so we destructure our bounding box in class and Basically there's a what this is doing here actually this is worth mentioning a Lot of code you find out there on the internet doesn't work with mini-batches, you know It only does like one thing at a time which we don't want so in this case We you know, all of this stuff is working. It's not exactly a mini-batch at a time. It's on a whole bunch of Ground truth objects at a time and the data loader is being fed a mini-batch at a time to do all the convolutional layers Because We could have different numbers of Ground-truth objects in each image, but a tensor has to be a strict rectangular shape Fast AI automatically pads it with zeros And I think that's not the same way That's a thing. I've barely recently added but it's super handy They're almost no other libraries do that But that does mean that you then have to make sure that you get rid of those zeros, right? So you can see here I'm checking to find all of the all of the non zeros and I'm only Keeping those this is just getting rid of any of the bounding boxes that are actually just padding Yeah, okay, so get rid of the padding turn the activations bounding boxes do the jacquard doing that ground truth This is all the stuff. We just went through it's all line by line underneath, right? Check that there's an overlap greater than something around point four or point five different papers use different values for this Find the things that match Put the class put the background class for those And then finally get the L1 loss for the localization part get the binary cross entropy boss for the classification part We've heard those two pieces and then finally having together So That's a lot going on And it might take a few watches of the video to bring in the code to fully understand it But the basic idea now is that we now have the things we need we have the data We have the architecture and we have the loss function. So now we've got those three things we can train so Do my normal learning rate binder and train for a bit and We get down to 25 and then at the end we can see How we went so obviously this isn't quite what we want I mean in practice We've kind of removed the background ones or some threshold, but it's like it's on the right track There's a dog in the middle. It's got a point three four There's a bird here in the middle of point nine four, you know, something's working. Okay You know, I've got a few concerns. I don't think it's I don't see anything saying motorcycle here. It says bicycle, which isn't great There's nothing for the part of plant that's big enough But that's not surprising because all of our anchor boxes were small They were four by four great so to go from here To something that's going to be more accurate. All we're going to do is to create way more anchor boxes Okay, so there's a couple of ways we can create Quick question. I'm just getting lost in the fact that the anchor boxes in the bounding boxes are How are they not the same? Isn't that how we wrote the last I must be missing something Anchor boxes are the Square the fixed square grid cells These are the anchor boxes there in an exact specific unmoving location the bounding boxes are These are three things about in boxes these 16 things that anchor boxes Okay So we're going to create lots more anchor boxes So there's three ways to do that and I've kind of drawn some of them or printed some of them here One is to create anchor boxes of different sizes and or an aspect ratios So here you can see You know, there's a upright rectangle There's a line down rectangle And there's a square It's a question for the multi-label classification Why aren't we multiplying the categorical loss by a constant like we did before? That's a great question Because later on it'll turn out we don't need to So yeah, so you can see here like there's a square and so I don't know if you can see this But if you look you basically got one two Three squares of different sizes and for each of those three squares You've also got a lying down rectangle and an upright rectangle to go with them Right, so we've got three aspect ratios at three zoom levels. That's one We can do we can do this right and this is for the one by one grid So in other words if we added two more stride two convolutional layers, you're going to get to a one by one grid And this is for the one by one grid Another thing we could do is to use more convolutional layers as sources of anchor boxes so as well as our and I've Randomly jittered these a little bit so it's easy to see right so as well as our 16 by 16 grid cells 22 or these little grid cells We've also got Two by two grid cells and we've also got the one by one grid cell, right? So in other words if we add three stride stride two convolutions to the to the end We have four by four two by two and one by one sets of grid cells all of which have Anchor boxes and then for every one of those we can have all of these different shapes and sizes right, so Obviously those two are combined with each other to create lots of anchor boxes And if I try to print that on the screen, it's just one big blur color So that's all this code is right it says alright, what are all the grid cell sizes? I have for the anchor boxes What are all the zoom levels I have for the anchor boxes and what are all the aspect ratios? I have for the anchor boxes and the rest of this code then just goes away creates the top left and bottom right corners inside Anchor corner and the middle and height width in anchors So that's all this does and you can go through it and print out the anchors and anchor corner So the key the key is to remember this basic idea that we have a Vector of Ground truth stuff right where that stuff is like sets of four Bounding boxes This is what we were given it was in the JSON files All right, it's the ground truth dependent variable sets of four bounding boxes and for each one also a Class right so this is a person in this location. This is a dog in this location That's the ground truth that we're given Yes Yeah, exactly top left XY bottom right XY So that's what we printed here. All right, we printed out. This is what we call the ground truth. There's no model This is what we're told is what when this is what the answer is meant to be and so remember any time we train a neural net we have a dependent variable and then we have a Neural net some black box neural net that takes some input and Spits out some output activations All right, and we take those activations and we compare them To the ground truth We calculate a loss we find the derivative of that and Adjust the weights according to the derivative times the learning rate Okay So the loss is calculated using a loss function Something I wanted to say is just I think one of the challenges with this Problem is part of what's going on here is we're having to come up with an architecture That's letting us predict this ground truth Like it's not because you can have you know, any number of objects in your picture It's not you know, immediately obvious like oh, what's the correct architecture? That's gonna let us predict that sort of ground truth I guess so but I'm gonna kind of make this claim as we saw when we looked at the kind of YOLO versus SSD That like there are only two possible architectures the last layer is fully connected or the last layer is convolutional and Both of them work perfectly well I'm sorry. I meant in terms of By creating this idea of anchor boxes and anchor boxes with different locations Locations and sizes that's giving you a format that kind of lets you get to the activations. You're right like high level It's that you say okay, so that's that's really entirely in the loss function Not in the architecture like and if we use the YOLO architecture where we had a fully connected layer Like literally there would be no concept of geometry in it at all right, so I would suggest like kind of Forgetting the architecture and just like treat it as just a given. It's a thing that is fitting out 16 times 4 plus C activations, right and then I would say our job is to figure out how to take those 16 times 4 plus C activations and compare them to our ground truth, which is like 4 plus It's 4 plus 1 but if it was one hot encoded it would be C and I think that's easier to think about so call it 4 plus C times However many ground truth objects there are for that particular image, right? So let's call that M Right, so we need a loss function That can take these two things and spit out a number that says how good are these activations Okay That's that's what we're trying to do So To do it we need to take each one of these M ground truth objects and decide Which Set of 4 plus C activations is Responsible for that object which one should we could be comparing and saying like yeah It's the right class or not and yeah, it's close or not Okay, and so The way we do that is basically to say okay Let's decide the first for the first 4 plus C activations Got to be responsible for predicting the bounding box of the thing that's closest to the top left And the last 4 plus C will be predicting those the furthest to the bottom right? right and kind of everything in between so this is this matching problem and And then of course, we're not using the yellow approach where we have a single vector. We're using the SSD approach where we spit out a Convolutional output which means that it's it's not arbitrary as to which we match up But actually we want to match up the set of activations whose receptive field Most closely reflects, you know has the maximum density from where this real object is But that's a that's a minor tweak You know I guess like that's the easy way to have taught this would have been to start with the YOLO approach Where it's just like an arbitrary vector and we can decide which activations correspond to which found truth object As long as it's consistent. It's got to be a consistent rule because like if in the first image the top left object Corresponds with the first four plus C activations and then the second image we threw things around and suddenly it's now going with the last four plus C activations The neural net doesn't know what to learn But the neural net needs like a loss function needs to be like some consistent task Right which in this case the consistent task is try to make these activations Reflect the bounding box in this general area That's basically what this loss function is trying to do Is it purely coincident that you know the four by four in the con con 2d is the same thing as you're 16 No, not at all coincidence. It's it's because though That four by four comb is going to give us activations whose receptive field Corresponds to those locations in the image So it's it's it's carefully designed to make that as effective as possible now remember I told you before part two that like the stuff we learn in part two is going to assume that you are extremely comfortable with everything you learn in part one and For a lot of you you might be realizing now Maybe I wasn't quite as familiar with the stuff in part one as I first thought and that's fine right, but just realize you might just have to go back and Really think deeply and experiment more with understanding with life What are the inputs and outputs to each layer in a convolutional network? How big are they? What are their rank exactly? How are they calculated so that you really fully understand the idea of a receptive field? What's the loss function really? How does back propagation work exactly? exactly like these things all need to be like deeply felt intuitions Which you only get through to practice and once they're all deeply felt intuitions, then you can really watch this video And you'll be like oh, I see okay. I see that You know these activations just need Need some way of understanding what task they're being given that is being done by the loss function and the loss function is encoding a task And so the task of the SSD loss function is basically two parts part one is Figure out which ground truth object is closest to which grid cell or which Anchor box right when we when we started doing this the grid cells of the convolution and the anchor boxes were the same right, but now we're starting to introduce the idea that We can have multiple anchor boxes their grid cell okay This is why I start to get a little bit more complicated So every ground truth object we have to figure out which anchor boxes are closest to every anchor box We have to decide which ground truth object is responsible for if any Okay, and once we've done that matching It's trivial now we just basically go through and do Going back to the Single object detection Now it's just this But it's once we've got every ground truth object matched to an anchor box to a set of activations We can basically then say okay. What's the cross entropy loss of the categorical part? What's the L1 loss of the? coordinate part So really it's the matching part which is the cross entropy loss of the categorical part which is kind of the No, kind of slightly surprising bit and then this idea of Picking those in a way that the convolutional network gives it the best opportunity to calculate that part of the space is then the final cherry on top And this I'll tell you something else this class is by is by far. I think going to be the most Conceptually challenging and part of the reason for that is that after this We're going to go and do some different stuff and we're going to come back to it in Lesson 14 and do it again with some tweaks Right and we're going to add in some of the new stuff we learn afterwards So you're going to get like a whole second run through of this material Once we add some some extra stuff at the end, so we're kind of Going to revise it as we normally do remember in part one. We kind of went through computer vision NLP structured data back to NLP back to computer vision, you know So we revised everything from the start at the end. It'll be kind of similar so Yeah, so don't worry if it's a bit challenging interest You'll get there okay, so So for every Grid cell that can be different sizes. We can have different orientations and zooms representing different different anchor boxes, which are just like Conceptual ideas that basically every one of these is associated with one set of four plus C activations In our model, right? So however many of these ground truth boxes we have we need to have that times four plus C activations in the model Now that does not mean that each convolutional Layer needs that many filters Right because remember the four by four convolutional layer already has 16 sets of filters the two by two convolutional layer already has four sets of Activations and then finally the one by one has one set of applications. So we basically get one plus four plus 16 for free just because that's how a convolution works it calculates things at different locations So we actually only need To know K where K is the number of Zooms by the number of aspect ratios where else the grids we're going to get for free Through our architecture, so let's check out that architecture So the model is nearly identical to what we had before All right, but we're going to go We're going to have a number of strive to convolutions Which is going to take us through to four by four two by two One by one, right each drive to convolution halves our grid size in both directions Okay, and then after we do our first convolution to get to four by four We're going to grab a set of outputs from that because we want to save away the four by four grids anchors and then once we get to two by two we grab another set of Now two by two anchors and then finally we get to one by one and we so we get another set of outputs All right, so you can see we've got like a whole bunch of these Outcon This first one we're actually not using So at the end of that we can then concatenate dot-cat Concatenate them all together. So we've got the four by four activations the two by two activations the one by one So that's going to give us the Correct number of activations to give us one activation for every For every Bounding for every anchor box that we have So then we just set criteria as before to SSD loss and we go ahead and train right and Away we go so in this case, I'm just printing out those things with at least probability of point one and You can see we've got Some things look okay. Some things don't Our big objects like bird. We've got a box here with a point nine three probability It's looking to be in about the right spot Our persons looking pretty hopeful But a motorbike has nothing at all The probability of point one Apotid plants looking pretty horrible Our bus is all the wrong size What's going on so though what's going on here will tell us a lot about the kind of history of Object detection and so These five papers the key steps in the history recent modern history of object detection and So they go back to about I think maybe 2013 this paper called scalable object detection using deep neural networks This is what basically set everything up and when people refer to the multi-box method They're talking about this paper and this was the basic one that came up with this idea that you can have a loss function That has this matching process and then you can kind of use that to do object So everything since that time has been trying to figure out basically how to make this better So in parallel As a guy called Ross Gershik who was going down a totally different direction, which was he had These two stage These two stage processes where the first stage used like classical computer vision approaches to like find kind of Edges and changes of gradients and stuff to kind of guess which parts of the image may represent distinct objects and then fit each of those into a convolutional neural network Which was basically designed to figure out is that actually the kind of object I'm interested in and so this was the kind of the R-CNN and then fast R-CNN There was kind of a hybrid of traditional computer vision and deep learning so what Ross and his team then did was they basically took this multi-box idea and replaced the Traditional non deep learning computer vision part of their two-stage process with a component So they now have two components one component that basically spat out something like this Which they call these region proposals, you know all of the things that might be objects And then the second part was the same as this earlier work It was basically something that talked each of those Fed it into a separate component which was designed to classify whether or not that particular thing really isn't interesting object or not At a similar time these two papers came out Yolo and SSD and both of these did something pretty cool Which is they got the same kind of performance as fast R-CNN But with one stage Okay, and so they basically took the multi-box idea and they tried to figure out how to deal with this mess Good stuff and the basic ideas were to use clinical hard negative mining where they would like go through and find all of the Matches it didn't look that good and throw them away Some very Tricky and complex data augmentation methods all kinds of factory basically, but they got it to work pretty pretty well But then something really cool happened late last year, which is this thing called focal loss this paper focal loss for dense object detection The network architecture is called retina net where they actually realized why this messy crap wasn't working and I'll describe why this messy crap wasn't working by trying to describe why it is that we can't find the motivation So here's the thing when We look at this we have three different Granularities of convolutional grid four by four two by two one by one The one by one It's quite likely To have a reasonable overlap with some object because most photos have some kind of main subject Okay on the other hand in the four by four those 16 grid cells Are unlikely most of them are not going to have much of an overlap with anything like in this motorbike case It's gonna be skies skies skies skies skies skies skies skies skies Ground ground ground finally motorbike. Okay, so if somebody was to say to you like You know 20 buck bet What do you reckon? This little click is you know, and you're not sure you're gonna say Background because most of the time it is background Okay and so Here's the thing. Um, I Understand why we have a four by four grid of receptive fields with one anchor box each to coarsely localize objects in the image But I think I'm missing is why we need multiple receptive fields at different sizes The first version already included 16 receptive fields each with a single anchor box associated with the addition There are now many more anchor boxes to consider Is this because you can strain how much a receptive field could move or scale from its original size? Or is there another reason? It's kind of backwards. The reason I did the constraining was because I knew I was going to be adding more boxes later but really the reason is that the jacquard overlap between one of those four by four grid cells and You know a picture a single object that takes up most of the image is never going to be point five because like the Intersections much smaller than the Union because the one object is too big. So for this general idea to work where we're saying like You're responsible for something that you've got a better than 50% overlap with we need anchor boxes which Which will on a regular basis have a 50% or higher overlap Which means we need to have a variety of sizes and shapes and scales Yeah, so this is this this this all happens This all happens in the loss function You know basically the vast majority of the interesting stuff in all of the object detection stuff is the loss function Because there is only three things loss function architecture data So the this is the focal loss paper Focal loss for dense object detection from August 2017 Here's Ross Gershig still doing this stuff timing her you might recognize as being the the resnet guy It's a bit of an all-star cast here and This the key thing is this very first picture the blue line is a picture of binary cross entropy loss The x-axis is what is the probability or what is the activation? What is the probability of the the ground truth class so it's actually a motorbike I Said with point six chance. It's a motorbike or it's actually not a motorbike and I said we pop point six chance So this blue line represents the level of the value of cross entropy loss so you can draw this in Excel or Python or whatever this is just a simple plot of cross entropy loss so the point is if the answer is Because remember we're doing binary cross entropy loss if the answer is not a motorbike and I said yeah, I think it's not a motorbike. I'm point six sure it's not a motorbike This blue line is still at like a loss of about point five I it's it's it's it's there's a lot of it's still pretty bad Right so I actually have to keep getting more and more confident that it's not a motorbike So if I want to get my loss down then for all of these things which are actually background I have to be saying like I am sure that's background You know or I'm sure it's not a motorbike or a bus or a person or a dining room table Because if I don't say I'm sure it's not any of these things then I still get loss so that's why This doesn't work right this doesn't work because even when it gets to here, and it wants to say I Think it's a motorbike There's no payoff for it to say so because if it's wrong Right and it gets killed and the vast majority of the time It's not anything the vast majority of times background and even if it's not background It's not enough just to say it's not background. You've got to say which of the 20 things it is Right so for the really big things It's fine because that's the one by one grid You know so it's it generally is a thing and you just have to figure out which thing it is or else for these small ones And generally it's not anything so generally small ones. We just prefer to be like I Got nothing to say no comment right so that's why this is empty and That's why even when we Do have a bus Right it's using a really big grid cell to say it's a bus because these are the only ones where it's like Confident enough to make a call that something right because the small grid cells It very rarely is something So the trick is to try and find a different loss function instead of binary cross entropy loss It doesn't look like the blue line, but looks more like the green or purple line And they actually end up suggesting the purple line and so it turns out this is cross entropy loss negative log PT Focal loss is simply one minus PT to the gamma where gamma is some Parameter right and they recommend using two times the cross entropy loss That's it's literally just a scaling of it And so that takes you to if you use gamma equals to that takes you to this purple line. So now if we say Now I'm point six sure that it's not a motorbike then the loss function is like good for you No worries, okay So that's what we want to do We want to replace cross entropy loss with focal loss and I mentioned a couple of things about this fantastic paper the first is like The actually come to the actual contribution of this paper is to add one minus P to the gamma to the start of this equation Which sounds like nothing right? But actually people have been trying to figure out this damn problem for years And I'm not even sure that realized it's a problem. There's just this assumption that You know object detection is really hard and you have to do all of these complex data augmentations And have negative mining and blah blah blah to get the damn thing to work. So a it's like this recognition of like But why are we doing all those things and then this realization of like oh if I do that it goes away It's fixed. All right, so When you come across a paper like this, which is like game-changing You shouldn't assume that you're going to have to write a hundred thousand lines of code It very often is one line of code or the change of a single constant or adding log to a single place Okay So let's go down to the bit where it all happens Where they describe the loss and I just wanted to point out a couple of terrific things about this paper the first is here is their definition of Cross entropy and if you're not able to write cross entropy on a piece of paper right now Then you need to go back and study it because we're going to be assuming that you know What it is what it means why it's that what the shape of it looks like cross entropy appears everywhere binary cross entropy and Categorical cross entropy and the softmax that Most people most of the time will see cross entropy written as like an indicator on y times log P plus an indicator on y of 1-y times log 1-p. This is like kind of awkward notation often people use like a direct delta function Stupid stuff like that. Where else this um This paper just says you know what it's just a conditional the cross entropy simply is what negative log P if y is 1 negative log 1 minus P otherwise So this is the y is 1 if it's a motorbike 0 if not in this paper they say 1 if it's a motorbike for negative 1 if not I was right we use zero and Then they do something which mathematicians never do they refactor Right check this out. Hey, what if we replace? What if we define a new term called PT which is equal to the probability? If y is 1 or 1 minus P otherwise if we did that we could now redefine C E as that Which is super cool like it's such a obvious thing to do But as soon as you do it all of the other equations get simpler as well because later on Straighten up at the very next paragraph. They say hey one way to deal with class imbalance ie lots of stuff is background Would just be to have a different weighting factor the background business not so like for class 1 You know we'll have some number alpha and for class Zero, we'll have 1 minus alpha But then they're like hey, let's define out for T the same way and so now our cross entropy Ballot you know with a weighting factor can be written like this and so then they can write their focal loss with the same concept and Then eventually they say hey, let's take focal loss and combine it with class weighting Like so right so often when you see in a paper Huge big equations. It's just because mathematicians don't know how to be factor And you'll see like the same pieces are kind of repeated all over the place Right very very very often and by the time you've turned it into numpy code Suddenly it's super simple so this is a Million times better than nearly any other Paper so it's a great paper to read to understand how papers should be a terrible paper to read to understand what most Okay, so let's try this we're going to use this Yeah, now remember negative log P is the cross-entropy loss So therefore this is just equal to some number times but cross entropy loss and when I defined the binomial cross entropy loss I Don't know if you remember or if you noticed, but I Had a weight which by default was none right and when you call binary cross entropy with log it's the High-forged thing you can optionally pass it away That's just something that's multiplied by everything and if it's none then there's no way so since we're just wanting to multiply Cross entropy by something We can just define Get weight So here's the entirety the focal loss this is the thing that like Suddenly made object detection make sense All right, so this was late last year suddenly it got rid of all of the complex messy Hacker right and so Do our sigmoid is our PT Is a W and here you can see one minus PT to the power of gamma right and so we're going to set gamma of two Alpha is point two five Two five if you're wondering why here's another excellent thing about this paper Because they tried lots of different values of gamma and alpha and they found that two and point two five work well consistent Okay so There's our new loss function it derives from our BC loss adding a weight to it focal loss other than that There's nothing else to do we can just train our model again Okay, and so this time Things are looking quite a bit better You know we now have Motorbike bicycle person motorbike like it's it's actually having a go at finding something. Yeah It's still doing a good job with big ones. In fact. It's looking quite a lot better It's finding quite a few people. It's finding a couple of different birds It's looking pretty good right so our last step Is for now is to basically figure out how to? Pull out just the interesting stuff that it's like let's take this dog in this sofa, right? How do we pick out? Our dog and our sofa and the answer is incredibly simple All we're going to do is we're going to is we're going to go through every pair of these bounding boxes and if they overlap by more than some amount say point five using jacquard and They both are predicting the same class We're going to assume that the same thing and we're just going to pick the one with the higher key value And we just keep doing that Repeat it. That's really boring code. I actually didn't write it myself. I copied it off somebody else somebody else's code non maximum suppression s No reason particularly to go through it, but that's all of us, right? so we can now show the results of the non maximum suppression and Yeah, here's the sofa is the dog Here's the bird Here's the person this person's cigarette looks like it's This one it's like it's okay, but not great like it's found a person that is bicycle of a person Place You know you can also see that like some of these smaller things that lower p-values the hope like a motorbike which is 0.16 This is saying time off us So there's something still to fix here right and the trick will be to use something Called feature periods and that's what we're going to do in lesson 14 Or thereabouts And that'll that'll fix this up Okay What I wanted to do in the last few minutes of class was to talk a Little bit more about the papers and specifically to go back to the SSD paper, so this is Single shot multi-box detect and when this came out. I was very excited because it was kind of You know it and Yolo were like you know the first kind of single pass good quality object detection methods that come along and so I kind of ignored object detection until this time or this to past stuff with RCNN and fast RCNN and faster RCNN because there's been this kind of continuous repetition of history in the last few years repetition of history in the deep learning world, which is things that involve multiple passes of multiple different pieces over time, you know, particularly where they involve some non deep learning pieces like RCNN and fast RCNN did over time They basically always get turned into a single end-to-end deep learning model So I tend to kind of like ignore them until that happens because that's the point where it's like, okay now people have figured out How to show this as a deep learning problem as soon as people do that They generally end up something that's much faster and much more accurate All right, and so SSD and Yolo were really important. So here's the SSD paper Let's go down to the key piece which is where they describe the model and Let's try and understand it So the model is basically one two three Four paragraphs, right so Papers are really concise All right, which means you kind of need to read them pretty carefully Partly though you need to know which bits to read carefully So the bits where they say here we're going to prove the error bounds on this model You can ignore that right because you don't care about proving the error bounds But the bit which says here is what the model is is the bit that you need to read really carefully Okay, so here's the bit called Model and so hopefully you'll find we can now read this together and understand it right so SSD is a feed-forward conclet and It creates a fixed size collection of bounding boxes and scores for the presence of object class instances in those boxes so fixed size that ie the Convolutional grid times K, you know the different aspect ratios and stuff and each one of those has four plus C activations Followed by a non maximum suppression step to take that mass of gum and turn it into you know Just a couple of non overlapping different objects The early layers are based on a standard architecture. So we just use resnet. This is pretty standard as you know, you can kind of see this consistent theme particularly in kind of how the fast AI library tries to do things which is like Grab a pre-trained network that already does something pull off the end bit stick on a new end bit Right. So early network players if we use the standard classifier Truncate the classification layers as we always do that happens automatically when we use common learner And we call this the base network some papers call that the backbone I know we call the backbone And we then add an auxiliary structure. Okay, so the auxiliary structure which we call the custom head Has multi-scale feature mass so we add convolutional layers to the end of this base network and they decrease in size aggressively so a bunch of stride to complex So that allows predictions of detections and multiple scales The grid cells are different size of the edge of these right? The model is different for each feature layer Compared to YOLO that operate on a single feature map So YOLO as we discussed is that is one vector whereas we have different complex each added feature layer Gives you a fixed set of predictions using a bunch of filters, right? for a filter layer where the grid size is n by n 4 by 4 with p channels one fact Let's take the previous one 7 by 7 with 5 12 channels The basic element is going to be a 3 by 3 by p kernel which in our case is a 3 by 3 by 4 for the shape offset bit or 3 by 3 by C for the score for a category D All right, so those are those three those are those two pieces at each of those grid cell locations it's going to produce an output value and the bounding box offsets measured relative to That default box position which we've been calling an anchor box position Relative to the feature map location what we've been calling the grid cell Okay as opposed to YOLO Right which has a fully connected layer And then they go on to describe the default boxes What they are for each feature map cell or what we would say grid cell They tile the feature map in a convolutional manner So the position of each box relative to its grid cell is test So hopefully you can see you know we end up with C plus 4 times K filters if there are K boxes at each location So these are similar to the anchor boxes described in faster rc-net so like if you To jump straight in and read a paper like this without knowing like what problem they're solving and why are they solving it? And what's the kind of no magnitude so forth? Those four paragraphs would probably make almost no sense But now that we've gone through it you read those four paragraphs and hopefully you're thinking oh That's just what Jeremy said only they said it better than Jeremy in less words. Okay So so I have the same problem when I started reading the SSD paper, and I read those four paragraphs And I don't didn't have before this time much of a background in object detection because I had decided to wait until These two parts anymore, and so I read this and I was like What the hell right and so the trick is to? Then start reading back over the citations right so for example And you should go back and read this paper now look here's the matching strategy Right and that whole matching strategy that I somehow spent like an hour talking about that's just a paragraph But it really is right For each ground truth we select from default boxes based on location aspect ratio and scale we match each ground truth to the default box with the best jacquard overlap and And then we match default boxes to anything with jacquard overlap higher than 0.5 That's it. That's the one sentence version And then we've got the loss function which is basically to say Take the average so divided by the number of the Loss based on the classes plus the loss based on localization with some Waiting now with focal loss. I found I didn't really need the weighting factor anymore. They both had about the same scale Just a coincidence perhaps But in this case as I started reading this I didn't really understand Exactly what L and G and all this stuff was but it says well This is derived from the multi box objective, so then I went back to the paper that defined Multi box and I found in their proposed approach. They've also got a section called training objective also known as loss function And Here I can see it's the same notation L G blah blah blah and so this is where I can go back and see the detail and After you read a bunch of papers You'll start to see things very quickly for example when you see these double bars to two You'll realize every time there's mean squared error. That's how you write mean squared error, right? This is actually called the two norm the two norm is just the sum of squared differences, right? And then there's two up here means normally they take the square root. So we just don't do this So this is just a MSE But anytime you see like oh, here's a log C and here's log 1 minus C, you know, that's basically binary cross entropy right, so it's like You you're not actually going to have to read every bit of every equation, but you are kind of a bit at first Right, but after a while Your brain just like immediately knows Basically what's going on and then I say oh, I've got a log C I'm log 1 minus C and as expected I should have my X and here's my 1 minus X Okay, there's all the pieces there that I would expect to see in the binary right So then having done that that then kind of allowed me okay, and then they get combined With the two pieces and all there's the multiplier that I expected and so now I can kind of come back here Understand what's going on? Okay, so We're going to be looking at a lot more papers, right? But maybe this week Go through the code and go through the paper. All right and be like What's what's going on? And remember what I did? to make it easier for you was I took that loss function I copied it into a cell and then I split it up so that each bit Was in a separate cell and then after every cell I either printed or plotted That value Right so if I hadn't have done that for you you should do it yourself But like this is no way you can understand these functions Without trying putting things in and seeing what comes out. Okay, so Hopefully this is kind of a good Good study Right. Well, thanks everybody. Have a great week and see you next Monday", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.68, "text": " Okay, so today we're going to continue working on object detection", "tokens": [1033, 11, 370, 965, 321, 434, 516, 281, 2354, 1364, 322, 2657, 17784], "temperature": 0.0, "avg_logprob": -0.22030743685635654, "compression_ratio": 1.6900826446280992, "no_speech_prob": 0.03960698843002319}, {"id": 1, "seek": 0, "start": 5.08, "end": 9.24, "text": " Which means that for every object in a photo in one of 20 classes", "tokens": [3013, 1355, 300, 337, 633, 2657, 294, 257, 5052, 294, 472, 295, 945, 5359], "temperature": 0.0, "avg_logprob": -0.22030743685635654, "compression_ratio": 1.6900826446280992, "no_speech_prob": 0.03960698843002319}, {"id": 2, "seek": 0, "start": 9.8, "end": 13.88, "text": " We're going to try and figure out what the object is and what its bounding box is", "tokens": [492, 434, 516, 281, 853, 293, 2573, 484, 437, 264, 2657, 307, 293, 437, 1080, 5472, 278, 2424, 307], "temperature": 0.0, "avg_logprob": -0.22030743685635654, "compression_ratio": 1.6900826446280992, "no_speech_prob": 0.03960698843002319}, {"id": 3, "seek": 0, "start": 14.040000000000001, "end": 20.76, "text": " Such that we can apply that model to a new data set of unlabeled data and add those labels to it", "tokens": [9653, 300, 321, 393, 3079, 300, 2316, 281, 257, 777, 1412, 992, 295, 32118, 18657, 292, 1412, 293, 909, 729, 16949, 281, 309], "temperature": 0.0, "avg_logprob": -0.22030743685635654, "compression_ratio": 1.6900826446280992, "no_speech_prob": 0.03960698843002319}, {"id": 4, "seek": 0, "start": 21.44, "end": 27.84, "text": " The general approach we're going to use is to start simple and gradually make it more complicated", "tokens": [440, 2674, 3109, 321, 434, 516, 281, 764, 307, 281, 722, 2199, 293, 13145, 652, 309, 544, 6179], "temperature": 0.0, "avg_logprob": -0.22030743685635654, "compression_ratio": 1.6900826446280992, "no_speech_prob": 0.03960698843002319}, {"id": 5, "seek": 2784, "start": 27.84, "end": 33.16, "text": " So we started last week with a simple classifier the three lines of code classifier", "tokens": [407, 321, 1409, 1036, 1243, 365, 257, 2199, 1508, 9902, 264, 1045, 3876, 295, 3089, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.15074185650758068, "compression_ratio": 1.6872427983539096, "no_speech_prob": 6.502120959339663e-05}, {"id": 6, "seek": 2784, "start": 33.4, "end": 38.4, "text": " We then made it slightly more complex to turn it into a bounding box without a classifier", "tokens": [492, 550, 1027, 309, 4748, 544, 3997, 281, 1261, 309, 666, 257, 5472, 278, 2424, 1553, 257, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.15074185650758068, "compression_ratio": 1.6872427983539096, "no_speech_prob": 6.502120959339663e-05}, {"id": 7, "seek": 2784, "start": 39.16, "end": 43.28, "text": " Today we're going to put those two pieces together to make a classifier plus a bounding box", "tokens": [2692, 321, 434, 516, 281, 829, 729, 732, 3755, 1214, 281, 652, 257, 1508, 9902, 1804, 257, 5472, 278, 2424], "temperature": 0.0, "avg_logprob": -0.15074185650758068, "compression_ratio": 1.6872427983539096, "no_speech_prob": 6.502120959339663e-05}, {"id": 8, "seek": 2784, "start": 43.28, "end": 48.8, "text": " All of these are just for a single object the largest object and then from there. We'll build up to something", "tokens": [1057, 295, 613, 366, 445, 337, 257, 2167, 2657, 264, 6443, 2657, 293, 550, 490, 456, 13, 492, 603, 1322, 493, 281, 746], "temperature": 0.0, "avg_logprob": -0.15074185650758068, "compression_ratio": 1.6872427983539096, "no_speech_prob": 6.502120959339663e-05}, {"id": 9, "seek": 2784, "start": 49.4, "end": 52.08, "text": " Which is closer to our final goal?", "tokens": [3013, 307, 4966, 281, 527, 2572, 3387, 30], "temperature": 0.0, "avg_logprob": -0.15074185650758068, "compression_ratio": 1.6872427983539096, "no_speech_prob": 6.502120959339663e-05}, {"id": 10, "seek": 5208, "start": 52.08, "end": 54.08, "text": " This is the final goal that we are aiming towards", "tokens": [639, 307, 264, 2572, 3387, 300, 321, 366, 20253, 3030], "temperature": 0.0, "avg_logprob": -0.24154563479953342, "compression_ratio": 1.6527196652719665, "no_speech_prob": 2.1781424948130734e-05}, {"id": 11, "seek": 5208, "start": 56.56, "end": 63.44, "text": " You should go back and make sure that you understand all of these concepts from last week before you move on if you don't", "tokens": [509, 820, 352, 646, 293, 652, 988, 300, 291, 1223, 439, 295, 613, 10392, 490, 1036, 1243, 949, 291, 1286, 322, 498, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.24154563479953342, "compression_ratio": 1.6527196652719665, "no_speech_prob": 2.1781424948130734e-05}, {"id": 12, "seek": 5208, "start": 63.519999999999996, "end": 67.16, "text": " Go back and we go through the notebooks carefully", "tokens": [1037, 646, 293, 321, 352, 807, 264, 43782, 7500], "temperature": 0.0, "avg_logprob": -0.24154563479953342, "compression_ratio": 1.6527196652719665, "no_speech_prob": 2.1781424948130734e-05}, {"id": 13, "seek": 5208, "start": 67.16, "end": 71.52, "text": " I won't read them all to you because you can see in the video easily enough", "tokens": [286, 1582, 380, 1401, 552, 439, 281, 291, 570, 291, 393, 536, 294, 264, 960, 3612, 1547], "temperature": 0.0, "avg_logprob": -0.24154563479953342, "compression_ratio": 1.6527196652719665, "no_speech_prob": 2.1781424948130734e-05}, {"id": 14, "seek": 5208, "start": 72.12, "end": 77.4, "text": " That perhaps this is the most important knowing how to jump around source code in whatever editor", "tokens": [663, 4317, 341, 307, 264, 881, 1021, 5276, 577, 281, 3012, 926, 4009, 3089, 294, 2035, 9839], "temperature": 0.0, "avg_logprob": -0.24154563479953342, "compression_ratio": 1.6527196652719665, "no_speech_prob": 2.1781424948130734e-05}, {"id": 15, "seek": 7740, "start": 77.4, "end": 79.4, "text": " You", "tokens": [509], "temperature": 0.0, "avg_logprob": -0.3037117258707682, "compression_ratio": 1.6127450980392157, "no_speech_prob": 1.0451120942889247e-05}, {"id": 16, "seek": 7740, "start": 81.60000000000001, "end": 86.92, "text": " At plot there's lambda functions lambda functions also particularly important they come up everywhere", "tokens": [1711, 7542, 456, 311, 13607, 6828, 13607, 6828, 611, 4098, 1021, 436, 808, 493, 5315], "temperature": 0.0, "avg_logprob": -0.3037117258707682, "compression_ratio": 1.6127450980392157, "no_speech_prob": 1.0451120942889247e-05}, {"id": 17, "seek": 7740, "start": 88.32000000000001, "end": 93.26, "text": " And this idea of a custom head is also going to come up in pretty much every lesson", "tokens": [400, 341, 1558, 295, 257, 2375, 1378, 307, 611, 516, 281, 808, 493, 294, 1238, 709, 633, 6898], "temperature": 0.0, "avg_logprob": -0.3037117258707682, "compression_ratio": 1.6127450980392157, "no_speech_prob": 1.0451120942889247e-05}, {"id": 18, "seek": 7740, "start": 95.68, "end": 97.68, "text": " I've also added here a", "tokens": [286, 600, 611, 3869, 510, 257], "temperature": 0.0, "avg_logprob": -0.3037117258707682, "compression_ratio": 1.6127450980392157, "no_speech_prob": 1.0451120942889247e-05}, {"id": 19, "seek": 7740, "start": 98.04, "end": 104.04, "text": " Reminder of what you should know from part one of the course because quite often I see questions on the forum asking", "tokens": [4080, 5669, 295, 437, 291, 820, 458, 490, 644, 472, 295, 264, 1164, 570, 1596, 2049, 286, 536, 1651, 322, 264, 17542, 3365], "temperature": 0.0, "avg_logprob": -0.3037117258707682, "compression_ratio": 1.6127450980392157, "no_speech_prob": 1.0451120942889247e-05}, {"id": 20, "seek": 10404, "start": 104.04, "end": 110.0, "text": " Basically, why isn't my model working like why doesn't it start training or?", "tokens": [8537, 11, 983, 1943, 380, 452, 2316, 1364, 411, 983, 1177, 380, 309, 722, 3097, 420, 30], "temperature": 0.0, "avg_logprob": -0.28711195914976056, "compression_ratio": 1.7904761904761906, "no_speech_prob": 5.682308255927637e-06}, {"id": 21, "seek": 10404, "start": 111.12, "end": 113.48, "text": " Having trained why doesn't it seem to be any use and", "tokens": [10222, 8895, 983, 1177, 380, 309, 1643, 281, 312, 604, 764, 293], "temperature": 0.0, "avg_logprob": -0.28711195914976056, "compression_ratio": 1.7904761904761906, "no_speech_prob": 5.682308255927637e-06}, {"id": 22, "seek": 10404, "start": 114.80000000000001, "end": 117.24000000000001, "text": " Nearly always the answer to the question is", "tokens": [38000, 1009, 264, 1867, 281, 264, 1168, 307], "temperature": 0.0, "avg_logprob": -0.28711195914976056, "compression_ratio": 1.7904761904761906, "no_speech_prob": 5.682308255927637e-06}, {"id": 23, "seek": 10404, "start": 118.0, "end": 121.76, "text": " Did you print out the inputs to it from a data loader?", "tokens": [2589, 291, 4482, 484, 264, 15743, 281, 309, 490, 257, 1412, 3677, 260, 30], "temperature": 0.0, "avg_logprob": -0.28711195914976056, "compression_ratio": 1.7904761904761906, "no_speech_prob": 5.682308255927637e-06}, {"id": 24, "seek": 10404, "start": 122.52000000000001, "end": 127.72, "text": " did you print out the outputs from it after evaluating and", "tokens": [630, 291, 4482, 484, 264, 23930, 490, 309, 934, 27479, 293], "temperature": 0.0, "avg_logprob": -0.28711195914976056, "compression_ratio": 1.7904761904761906, "no_speech_prob": 5.682308255927637e-06}, {"id": 25, "seek": 12772, "start": 127.72, "end": 134.96, "text": " Normally the answer is no and I try printing it and turns out all the inputs are zero or all the outputs are negative or it's like", "tokens": [17424, 264, 1867, 307, 572, 293, 286, 853, 14699, 309, 293, 4523, 484, 439, 264, 15743, 366, 4018, 420, 439, 264, 23930, 366, 3671, 420, 309, 311, 411], "temperature": 0.0, "avg_logprob": -0.26377091180710566, "compression_ratio": 1.70995670995671, "no_speech_prob": 9.223219421983231e-06}, {"id": 26, "seek": 12772, "start": 134.96, "end": 141.07999999999998, "text": " It's really obvious. So that's just one of something I wanted to remind you about is that you need to know how to do these", "tokens": [467, 311, 534, 6322, 13, 407, 300, 311, 445, 472, 295, 746, 286, 1415, 281, 4160, 291, 466, 307, 300, 291, 643, 281, 458, 577, 281, 360, 613], "temperature": 0.0, "avg_logprob": -0.26377091180710566, "compression_ratio": 1.70995670995671, "no_speech_prob": 9.223219421983231e-06}, {"id": 27, "seek": 12772, "start": 142.0, "end": 144.0, "text": " two things and if you", "tokens": [732, 721, 293, 498, 291], "temperature": 0.0, "avg_logprob": -0.26377091180710566, "compression_ratio": 1.70995670995671, "no_speech_prob": 9.223219421983231e-06}, {"id": 28, "seek": 12772, "start": 144.52, "end": 147.84, "text": " Hey, if you can't do that, it's gonna be very hard to debug models and", "tokens": [1911, 11, 498, 291, 393, 380, 360, 300, 11, 309, 311, 799, 312, 588, 1152, 281, 24083, 5245, 293], "temperature": 0.0, "avg_logprob": -0.26377091180710566, "compression_ratio": 1.70995670995671, "no_speech_prob": 9.223219421983231e-06}, {"id": 29, "seek": 12772, "start": 148.56, "end": 152.34, "text": " They if you can do that, but you're not doing it", "tokens": [814, 498, 291, 393, 360, 300, 11, 457, 291, 434, 406, 884, 309], "temperature": 0.0, "avg_logprob": -0.26377091180710566, "compression_ratio": 1.70995670995671, "no_speech_prob": 9.223219421983231e-06}, {"id": 30, "seek": 15234, "start": 152.34, "end": 157.54, "text": " Then it's going to be very happy to debug models. You can debug models by staring at the source code", "tokens": [1396, 309, 311, 516, 281, 312, 588, 2055, 281, 24083, 5245, 13, 509, 393, 24083, 5245, 538, 18043, 412, 264, 4009, 3089], "temperature": 0.0, "avg_logprob": -0.255537592569987, "compression_ratio": 1.617801047120419, "no_speech_prob": 1.0129628208233044e-05}, {"id": 31, "seek": 15234, "start": 157.74, "end": 161.1, "text": " Hoping your error pops out you debug models by", "tokens": [13438, 278, 428, 6713, 16795, 484, 291, 24083, 5245, 538], "temperature": 0.0, "avg_logprob": -0.255537592569987, "compression_ratio": 1.617801047120419, "no_speech_prob": 1.0129628208233044e-05}, {"id": 32, "seek": 15234, "start": 161.86, "end": 165.14000000000001, "text": " Checking all the intermediate steps looking at the data", "tokens": [6881, 278, 439, 264, 19376, 4439, 1237, 412, 264, 1412], "temperature": 0.0, "avg_logprob": -0.255537592569987, "compression_ratio": 1.617801047120419, "no_speech_prob": 1.0129628208233044e-05}, {"id": 33, "seek": 15234, "start": 166.26, "end": 169.9, "text": " Printing it out plotting its histogram making sure it makes sense", "tokens": [34439, 278, 309, 484, 41178, 1080, 49816, 1455, 988, 309, 1669, 2020], "temperature": 0.0, "avg_logprob": -0.255537592569987, "compression_ratio": 1.617801047120419, "no_speech_prob": 1.0129628208233044e-05}, {"id": 34, "seek": 15234, "start": 173.38, "end": 175.38, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.255537592569987, "compression_ratio": 1.617801047120419, "no_speech_prob": 1.0129628208233044e-05}, {"id": 35, "seek": 17538, "start": 175.38, "end": 182.5, "text": " We were working through Pascal notebook and we just", "tokens": [492, 645, 1364, 807, 41723, 21060, 293, 321, 445], "temperature": 0.0, "avg_logprob": -0.47186408244388206, "compression_ratio": 1.507936507936508, "no_speech_prob": 8.397824785788544e-06}, {"id": 36, "seek": 17538, "start": 183.01999999999998, "end": 187.42, "text": " Quickly zipped through the bounding box of the largest object", "tokens": [31800, 710, 5529, 807, 264, 5472, 278, 2424, 295, 264, 6443, 2657], "temperature": 0.0, "avg_logprob": -0.47186408244388206, "compression_ratio": 1.507936507936508, "no_speech_prob": 8.397824785788544e-06}, {"id": 37, "seek": 17538, "start": 187.98, "end": 193.34, "text": " Without a classifier part and there was one bit that I skipped over and said I've come back to so let's do that now", "tokens": [9129, 257, 1508, 9902, 644, 293, 456, 390, 472, 857, 300, 286, 30193, 670, 293, 848, 286, 600, 808, 646, 281, 370, 718, 311, 360, 300, 586], "temperature": 0.0, "avg_logprob": -0.47186408244388206, "compression_ratio": 1.507936507936508, "no_speech_prob": 8.397824785788544e-06}, {"id": 38, "seek": 17538, "start": 196.78, "end": 198.78, "text": " Which is to talk about", "tokens": [3013, 307, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.47186408244388206, "compression_ratio": 1.507936507936508, "no_speech_prob": 8.397824785788544e-06}, {"id": 39, "seek": 17538, "start": 200.26, "end": 203.06, "text": " Augmentations data augmentations", "tokens": [6088, 518, 763, 1412, 29919, 763], "temperature": 0.0, "avg_logprob": -0.47186408244388206, "compression_ratio": 1.507936507936508, "no_speech_prob": 8.397824785788544e-06}, {"id": 40, "seek": 20306, "start": 203.06, "end": 208.18, "text": " Data augmentations of the the y of the dependent variable", "tokens": [11888, 29919, 763, 295, 264, 264, 288, 295, 264, 12334, 7006], "temperature": 0.0, "avg_logprob": -0.29808974592653037, "compression_ratio": 1.596938775510204, "no_speech_prob": 5.014691851101816e-06}, {"id": 41, "seek": 20306, "start": 208.94, "end": 211.14000000000001, "text": " But for I'll do I just mentioned something", "tokens": [583, 337, 286, 603, 360, 286, 445, 2835, 746], "temperature": 0.0, "avg_logprob": -0.29808974592653037, "compression_ratio": 1.596938775510204, "no_speech_prob": 5.014691851101816e-06}, {"id": 42, "seek": 20306, "start": 213.26, "end": 218.6, "text": " Pretty awkward in in all this which is I've got here image classifier data", "tokens": [10693, 11411, 294, 294, 439, 341, 597, 307, 286, 600, 658, 510, 3256, 1508, 9902, 1412], "temperature": 0.0, "avg_logprob": -0.29808974592653037, "compression_ratio": 1.596938775510204, "no_speech_prob": 5.014691851101816e-06}, {"id": 43, "seek": 20306, "start": 219.58, "end": 224.74, "text": " Continuous equals true this makes no sense whatsoever a classifier is", "tokens": [14674, 12549, 6915, 2074, 341, 1669, 572, 2020, 17076, 257, 1508, 9902, 307], "temperature": 0.0, "avg_logprob": -0.29808974592653037, "compression_ratio": 1.596938775510204, "no_speech_prob": 5.014691851101816e-06}, {"id": 44, "seek": 20306, "start": 225.78, "end": 229.46, "text": " anything where the dependent variable is categorical or binomial as", "tokens": [1340, 689, 264, 12334, 7006, 307, 19250, 804, 420, 5171, 47429, 382], "temperature": 0.0, "avg_logprob": -0.29808974592653037, "compression_ratio": 1.596938775510204, "no_speech_prob": 5.014691851101816e-06}, {"id": 45, "seek": 22946, "start": 229.46, "end": 232.98000000000002, "text": " opposed to regression which is anything where the", "tokens": [8851, 281, 24590, 597, 307, 1340, 689, 264], "temperature": 0.0, "avg_logprob": -0.18356055774907956, "compression_ratio": 1.7363636363636363, "no_speech_prob": 3.966952135669999e-06}, {"id": 46, "seek": 22946, "start": 234.70000000000002, "end": 241.46, "text": " Continuous and yet this parameter here continuous equals true says that the dependent variable is continuous", "tokens": [14674, 12549, 293, 1939, 341, 13075, 510, 10957, 6915, 2074, 1619, 300, 264, 12334, 7006, 307, 10957], "temperature": 0.0, "avg_logprob": -0.18356055774907956, "compression_ratio": 1.7363636363636363, "no_speech_prob": 3.966952135669999e-06}, {"id": 47, "seek": 22946, "start": 241.54000000000002, "end": 248.82, "text": " So this claims to be creating data for a classifier where the dependent is continuous. This is the kind of", "tokens": [407, 341, 9441, 281, 312, 4084, 1412, 337, 257, 1508, 9902, 689, 264, 12334, 307, 10957, 13, 639, 307, 264, 733, 295], "temperature": 0.0, "avg_logprob": -0.18356055774907956, "compression_ratio": 1.7363636363636363, "no_speech_prob": 3.966952135669999e-06}, {"id": 48, "seek": 22946, "start": 250.02, "end": 253.28, "text": " awkward rough edge that you see when we're kind of at this like", "tokens": [11411, 5903, 4691, 300, 291, 536, 562, 321, 434, 733, 295, 412, 341, 411], "temperature": 0.0, "avg_logprob": -0.18356055774907956, "compression_ratio": 1.7363636363636363, "no_speech_prob": 3.966952135669999e-06}, {"id": 49, "seek": 22946, "start": 254.10000000000002, "end": 257.18, "text": " You know that the edge of the past AI code. It's not", "tokens": [509, 458, 300, 264, 4691, 295, 264, 1791, 7318, 3089, 13, 467, 311, 406], "temperature": 0.0, "avg_logprob": -0.18356055774907956, "compression_ratio": 1.7363636363636363, "no_speech_prob": 3.966952135669999e-06}, {"id": 50, "seek": 25718, "start": 257.18, "end": 261.78000000000003, "text": " Quite solidified yet. So probably by the time you watch this in the MOOC", "tokens": [20464, 5100, 2587, 1939, 13, 407, 1391, 538, 264, 565, 291, 1159, 341, 294, 264, 49197, 34], "temperature": 0.0, "avg_logprob": -0.2132662350369483, "compression_ratio": 1.6704545454545454, "no_speech_prob": 1.9525392417563125e-05}, {"id": 51, "seek": 25718, "start": 261.78000000000003, "end": 266.18, "text": " This will be sorted out and this will be called image regressor data or something like that", "tokens": [639, 486, 312, 25462, 484, 293, 341, 486, 312, 1219, 3256, 1121, 735, 284, 1412, 420, 746, 411, 300], "temperature": 0.0, "avg_logprob": -0.2132662350369483, "compression_ratio": 1.6704545454545454, "no_speech_prob": 1.9525392417563125e-05}, {"id": 52, "seek": 25718, "start": 266.18, "end": 268.6, "text": " But you know, I just wanted to kind of", "tokens": [583, 291, 458, 11, 286, 445, 1415, 281, 733, 295], "temperature": 0.0, "avg_logprob": -0.2132662350369483, "compression_ratio": 1.6704545454545454, "no_speech_prob": 1.9525392417563125e-05}, {"id": 53, "seek": 25718, "start": 269.42, "end": 277.02, "text": " Point out this this issue and also because sometimes people were getting confused between regression versus classification and this is not", "tokens": [12387, 484, 341, 341, 2734, 293, 611, 570, 2171, 561, 645, 1242, 9019, 1296, 24590, 5717, 21538, 293, 341, 307, 406], "temperature": 0.0, "avg_logprob": -0.2132662350369483, "compression_ratio": 1.6704545454545454, "no_speech_prob": 1.9525392417563125e-05}, {"id": 54, "seek": 27702, "start": 277.02, "end": 285.58, "text": " One bit. Okay, so let's create some data augmentations right now. Normally when we create data", "tokens": [1485, 857, 13, 1033, 11, 370, 718, 311, 1884, 512, 1412, 29919, 763, 558, 586, 13, 17424, 562, 321, 1884, 1412], "temperature": 0.0, "avg_logprob": -0.3672413936881132, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.4823469882685458e-06}, {"id": 55, "seek": 27702, "start": 286.09999999999997, "end": 288.78, "text": " augmentations we tend to type in like", "tokens": [29919, 763, 321, 3928, 281, 2010, 294, 411], "temperature": 0.0, "avg_logprob": -0.3672413936881132, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.4823469882685458e-06}, {"id": 56, "seek": 27702, "start": 289.29999999999995, "end": 291.78, "text": " transform side on or transforms part damn", "tokens": [4088, 1252, 322, 420, 35592, 644, 8151], "temperature": 0.0, "avg_logprob": -0.3672413936881132, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.4823469882685458e-06}, {"id": 57, "seek": 27702, "start": 291.78, "end": 299.14, "text": " Okay, but if you look inside the fast AI dot transforms module, you'll see that they are simply defined as a list", "tokens": [1033, 11, 457, 498, 291, 574, 1854, 264, 2370, 7318, 5893, 35592, 10088, 11, 291, 603, 536, 300, 436, 366, 2935, 7642, 382, 257, 1329], "temperature": 0.0, "avg_logprob": -0.3672413936881132, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.4823469882685458e-06}, {"id": 58, "seek": 27702, "start": 299.14, "end": 303.53999999999996, "text": " So this is a good transforms basic which is 10 degree rotations plus", "tokens": [407, 341, 307, 257, 665, 35592, 3875, 597, 307, 1266, 4314, 44796, 1804], "temperature": 0.0, "avg_logprob": -0.3672413936881132, "compression_ratio": 1.6451612903225807, "no_speech_prob": 1.4823469882685458e-06}, {"id": 59, "seek": 30354, "start": 303.54, "end": 309.52000000000004, "text": " 0.05 brightness and contrast and then side on adds to that random horizontal flips", "tokens": [1958, 13, 13328, 21367, 293, 8712, 293, 550, 1252, 322, 10860, 281, 300, 4974, 12750, 40249], "temperature": 0.0, "avg_logprob": -0.2837785011114076, "compression_ratio": 1.5541125541125542, "no_speech_prob": 6.962195129744941e-06}, {"id": 60, "seek": 30354, "start": 310.18, "end": 312.78000000000003, "text": " Or else top down adds to that random", "tokens": [1610, 1646, 1192, 760, 10860, 281, 300, 4974], "temperature": 0.0, "avg_logprob": -0.2837785011114076, "compression_ratio": 1.5541125541125542, "no_speech_prob": 6.962195129744941e-06}, {"id": 61, "seek": 30354, "start": 313.74, "end": 316.70000000000005, "text": " dihedral group of 8 symmetry flips which basically means", "tokens": [1026, 71, 24764, 1594, 295, 1649, 25440, 40249, 597, 1936, 1355], "temperature": 0.0, "avg_logprob": -0.2837785011114076, "compression_ratio": 1.5541125541125542, "no_speech_prob": 6.962195129744941e-06}, {"id": 62, "seek": 30354, "start": 317.3, "end": 319.90000000000003, "text": " Every possible 90 degree rotation optionally", "tokens": [2048, 1944, 4289, 4314, 12447, 3614, 379], "temperature": 0.0, "avg_logprob": -0.2837785011114076, "compression_ratio": 1.5541125541125542, "no_speech_prob": 6.962195129744941e-06}, {"id": 63, "seek": 30354, "start": 323.58000000000004, "end": 325.58000000000004, "text": " So like these are just little", "tokens": [407, 411, 613, 366, 445, 707], "temperature": 0.0, "avg_logprob": -0.2837785011114076, "compression_ratio": 1.5541125541125542, "no_speech_prob": 6.962195129744941e-06}, {"id": 64, "seek": 30354, "start": 325.98, "end": 331.70000000000005, "text": " Shortcuts that I added because they seem to be useful a lot of the time, but you can always create your own", "tokens": [16881, 26158, 300, 286, 3869, 570, 436, 1643, 281, 312, 4420, 257, 688, 295, 264, 565, 11, 457, 291, 393, 1009, 1884, 428, 1065], "temperature": 0.0, "avg_logprob": -0.2837785011114076, "compression_ratio": 1.5541125541125542, "no_speech_prob": 6.962195129744941e-06}, {"id": 65, "seek": 33170, "start": 331.7, "end": 336.86, "text": " List of augmentations, right? And if you're not sure what augmentations are there", "tokens": [17668, 295, 29919, 763, 11, 558, 30, 400, 498, 291, 434, 406, 988, 437, 29919, 763, 366, 456], "temperature": 0.0, "avg_logprob": -0.21403332878561582, "compression_ratio": 1.6415094339622642, "no_speech_prob": 4.5659248826268595e-06}, {"id": 66, "seek": 33170, "start": 337.42, "end": 342.38, "text": " You can obviously check the past source or if you just start typing random", "tokens": [509, 393, 2745, 1520, 264, 1791, 4009, 420, 498, 291, 445, 722, 18444, 4974], "temperature": 0.0, "avg_logprob": -0.21403332878561582, "compression_ratio": 1.6415094339622642, "no_speech_prob": 4.5659248826268595e-06}, {"id": 67, "seek": 33170, "start": 343.02, "end": 346.74, "text": " They all start with random so you can see them easily enough", "tokens": [814, 439, 722, 365, 4974, 370, 291, 393, 536, 552, 3612, 1547], "temperature": 0.0, "avg_logprob": -0.21403332878561582, "compression_ratio": 1.6415094339622642, "no_speech_prob": 4.5659248826268595e-06}, {"id": 68, "seek": 33170, "start": 348.7, "end": 353.09999999999997, "text": " So let's take a look at what happens if we create some data augmentations", "tokens": [407, 718, 311, 747, 257, 574, 412, 437, 2314, 498, 321, 1884, 512, 1412, 29919, 763], "temperature": 0.0, "avg_logprob": -0.21403332878561582, "compression_ratio": 1.6415094339622642, "no_speech_prob": 4.5659248826268595e-06}, {"id": 69, "seek": 33170, "start": 354.34, "end": 356.21999999999997, "text": " create a", "tokens": [1884, 257], "temperature": 0.0, "avg_logprob": -0.21403332878561582, "compression_ratio": 1.6415094339622642, "no_speech_prob": 4.5659248826268595e-06}, {"id": 70, "seek": 35622, "start": 356.22, "end": 361.78000000000003, "text": " model data object and let's just go through and", "tokens": [2316, 1412, 2657, 293, 718, 311, 445, 352, 807, 293], "temperature": 0.0, "avg_logprob": -0.21886557675479504, "compression_ratio": 1.6862745098039216, "no_speech_prob": 7.411232672893675e-06}, {"id": 71, "seek": 35622, "start": 363.06, "end": 366.14000000000004, "text": " rerun the iterator a bunch of times and", "tokens": [43819, 409, 264, 17138, 1639, 257, 3840, 295, 1413, 293], "temperature": 0.0, "avg_logprob": -0.21886557675479504, "compression_ratio": 1.6862745098039216, "no_speech_prob": 7.411232672893675e-06}, {"id": 72, "seek": 35622, "start": 366.86, "end": 369.58000000000004, "text": " We'll do two things. We'll print out the bounding boxes", "tokens": [492, 603, 360, 732, 721, 13, 492, 603, 4482, 484, 264, 5472, 278, 9002], "temperature": 0.0, "avg_logprob": -0.21886557675479504, "compression_ratio": 1.6862745098039216, "no_speech_prob": 7.411232672893675e-06}, {"id": 73, "seek": 35622, "start": 370.42, "end": 376.26000000000005, "text": " And so you can see the bounding box is the same time and we will also draw the pictures", "tokens": [400, 370, 291, 393, 536, 264, 5472, 278, 2424, 307, 264, 912, 565, 293, 321, 486, 611, 2642, 264, 5242], "temperature": 0.0, "avg_logprob": -0.21886557675479504, "compression_ratio": 1.6862745098039216, "no_speech_prob": 7.411232672893675e-06}, {"id": 74, "seek": 35622, "start": 376.90000000000003, "end": 378.34000000000003, "text": " So you'll see", "tokens": [407, 291, 603, 536], "temperature": 0.0, "avg_logprob": -0.21886557675479504, "compression_ratio": 1.6862745098039216, "no_speech_prob": 7.411232672893675e-06}, {"id": 75, "seek": 35622, "start": 378.34000000000003, "end": 384.3, "text": " This lady is as we would expect flipping around and spinning around and getting darker and lighter", "tokens": [639, 7262, 307, 382, 321, 576, 2066, 26886, 926, 293, 15640, 926, 293, 1242, 12741, 293, 11546], "temperature": 0.0, "avg_logprob": -0.21886557675479504, "compression_ratio": 1.6862745098039216, "no_speech_prob": 7.411232672893675e-06}, {"id": 76, "seek": 38430, "start": 384.3, "end": 386.3, "text": " but the bounding box a", "tokens": [457, 264, 5472, 278, 2424, 257], "temperature": 0.0, "avg_logprob": -0.24871138163975307, "compression_ratio": 1.6462264150943395, "no_speech_prob": 2.857299705283367e-06}, {"id": 77, "seek": 38430, "start": 387.18, "end": 393.42, "text": " Is not moving and B is in the wrong spot. So this is the problem with data", "tokens": [1119, 406, 2684, 293, 363, 307, 294, 264, 2085, 4008, 13, 407, 341, 307, 264, 1154, 365, 1412], "temperature": 0.0, "avg_logprob": -0.24871138163975307, "compression_ratio": 1.6462264150943395, "no_speech_prob": 2.857299705283367e-06}, {"id": 78, "seek": 38430, "start": 394.34000000000003, "end": 397.3, "text": " augmentation when your dependent variable", "tokens": [14501, 19631, 562, 428, 12334, 7006], "temperature": 0.0, "avg_logprob": -0.24871138163975307, "compression_ratio": 1.6462264150943395, "no_speech_prob": 2.857299705283367e-06}, {"id": 79, "seek": 38430, "start": 398.46000000000004, "end": 405.26, "text": " You know is pixel values or is in some way connected to your independent variable the two need to be augmented together", "tokens": [509, 458, 307, 19261, 4190, 420, 307, 294, 512, 636, 4582, 281, 428, 6695, 7006, 264, 732, 643, 281, 312, 36155, 1214], "temperature": 0.0, "avg_logprob": -0.24871138163975307, "compression_ratio": 1.6462264150943395, "no_speech_prob": 2.857299705283367e-06}, {"id": 80, "seek": 38430, "start": 406.02, "end": 410.90000000000003, "text": " And in fact, you can see that from the printout these numbers are bigger than two to four", "tokens": [400, 294, 1186, 11, 291, 393, 536, 300, 490, 264, 4482, 346, 613, 3547, 366, 3801, 813, 732, 281, 1451], "temperature": 0.0, "avg_logprob": -0.24871138163975307, "compression_ratio": 1.6462264150943395, "no_speech_prob": 2.857299705283367e-06}, {"id": 81, "seek": 41090, "start": 410.9, "end": 415.65999999999997, "text": " But these images are of size two to four. That's what we requested in this in this trans once", "tokens": [583, 613, 5267, 366, 295, 2744, 732, 281, 1451, 13, 663, 311, 437, 321, 16436, 294, 341, 294, 341, 1145, 1564], "temperature": 0.0, "avg_logprob": -0.2865428924560547, "compression_ratio": 1.6359649122807018, "no_speech_prob": 8.013416845642496e-06}, {"id": 82, "seek": 41090, "start": 416.29999999999995, "end": 422.65999999999997, "text": " And so it's not even being like scaled or cropped or anything. All right, so you can see that", "tokens": [400, 370, 309, 311, 406, 754, 885, 411, 36039, 420, 4848, 3320, 420, 1340, 13, 1057, 558, 11, 370, 291, 393, 536, 300], "temperature": 0.0, "avg_logprob": -0.2865428924560547, "compression_ratio": 1.6359649122807018, "no_speech_prob": 8.013416845642496e-06}, {"id": 83, "seek": 41090, "start": 423.34, "end": 429.34, "text": " Our dependent variable needs to go through all of the same geometric transformations as our independent variable", "tokens": [2621, 12334, 7006, 2203, 281, 352, 807, 439, 295, 264, 912, 33246, 34852, 382, 527, 6695, 7006], "temperature": 0.0, "avg_logprob": -0.2865428924560547, "compression_ratio": 1.6359649122807018, "no_speech_prob": 8.013416845642496e-06}, {"id": 84, "seek": 41090, "start": 430.14, "end": 432.14, "text": " So to do that", "tokens": [407, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.2865428924560547, "compression_ratio": 1.6359649122807018, "no_speech_prob": 8.013416845642496e-06}, {"id": 85, "seek": 41090, "start": 433.53999999999996, "end": 438.29999999999995, "text": " Every transformation has an optional transform y parameter", "tokens": [2048, 9887, 575, 364, 17312, 4088, 288, 13075], "temperature": 0.0, "avg_logprob": -0.2865428924560547, "compression_ratio": 1.6359649122807018, "no_speech_prob": 8.013416845642496e-06}, {"id": 86, "seek": 43830, "start": 438.3, "end": 441.22, "text": " It takes a transform type enum", "tokens": [467, 2516, 257, 4088, 2010, 465, 449], "temperature": 0.0, "avg_logprob": -0.4229698181152344, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.1726384627763764e-06}, {"id": 87, "seek": 43830, "start": 442.22, "end": 447.5, "text": " The transform type enum has a few options all of which we'll cover in this course", "tokens": [440, 4088, 2010, 465, 449, 575, 257, 1326, 3956, 439, 295, 597, 321, 603, 2060, 294, 341, 1164], "temperature": 0.0, "avg_logprob": -0.4229698181152344, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.1726384627763764e-06}, {"id": 88, "seek": 43830, "start": 448.42, "end": 452.54, "text": " The co-ord option says that the y values represent", "tokens": [440, 598, 12, 765, 3614, 1619, 300, 264, 288, 4190, 2906], "temperature": 0.0, "avg_logprob": -0.4229698181152344, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.1726384627763764e-06}, {"id": 89, "seek": 43830, "start": 453.46000000000004, "end": 454.46000000000004, "text": " coordinates", "tokens": [21056], "temperature": 0.0, "avg_logprob": -0.4229698181152344, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.1726384627763764e-06}, {"id": 90, "seek": 43830, "start": 454.46000000000004, "end": 457.34000000000003, "text": " In this case bounding box coordinates, okay", "tokens": [682, 341, 1389, 5472, 278, 2424, 21056, 11, 1392], "temperature": 0.0, "avg_logprob": -0.4229698181152344, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.1726384627763764e-06}, {"id": 91, "seek": 43830, "start": 457.34000000000003, "end": 464.02, "text": " And so therefore if you flip you need to change the coordinate to represent that flip or if you rotate you to change the coordinates", "tokens": [400, 370, 4412, 498, 291, 7929, 291, 643, 281, 1319, 264, 15670, 281, 2906, 300, 7929, 420, 498, 291, 13121, 291, 281, 1319, 264, 21056], "temperature": 0.0, "avg_logprob": -0.4229698181152344, "compression_ratio": 1.8333333333333333, "no_speech_prob": 1.1726384627763764e-06}, {"id": 92, "seek": 46402, "start": 464.02, "end": 471.38, "text": " You rotate interchange the coordinates represent that rotation so I can add transform type of chord to all of my augmentations. I", "tokens": [509, 13121, 30358, 264, 21056, 2906, 300, 12447, 370, 286, 393, 909, 4088, 2010, 295, 14137, 281, 439, 295, 452, 29919, 763, 13, 286], "temperature": 0.0, "avg_logprob": -0.2465024084415076, "compression_ratio": 1.802325581395349, "no_speech_prob": 3.4465538192307577e-06}, {"id": 93, "seek": 46402, "start": 472.14, "end": 478.29999999999995, "text": " also have to add the exact same thing to my transforms from model function because that's the thing that does the", "tokens": [611, 362, 281, 909, 264, 1900, 912, 551, 281, 452, 35592, 490, 2316, 2445, 570, 300, 311, 264, 551, 300, 775, 264], "temperature": 0.0, "avg_logprob": -0.2465024084415076, "compression_ratio": 1.802325581395349, "no_speech_prob": 3.4465538192307577e-06}, {"id": 94, "seek": 46402, "start": 478.97999999999996, "end": 482.29999999999995, "text": " cropping and or zooming and or padding and or", "tokens": [4848, 3759, 293, 420, 48226, 293, 420, 39562, 293, 420], "temperature": 0.0, "avg_logprob": -0.2465024084415076, "compression_ratio": 1.802325581395349, "no_speech_prob": 3.4465538192307577e-06}, {"id": 95, "seek": 46402, "start": 483.18, "end": 486.9, "text": " Resizing and all of those things need to happen to the dependent as well", "tokens": [5015, 3319, 293, 439, 295, 729, 721, 643, 281, 1051, 281, 264, 12334, 382, 731], "temperature": 0.0, "avg_logprob": -0.2465024084415076, "compression_ratio": 1.802325581395349, "no_speech_prob": 3.4465538192307577e-06}, {"id": 96, "seek": 48690, "start": 486.9, "end": 493.9, "text": " All right, so if we add all of those together and rerun this you'll see the bounding box changes each time and", "tokens": [1057, 558, 11, 370, 498, 321, 909, 439, 295, 729, 1214, 293, 43819, 409, 341, 291, 603, 536, 264, 5472, 278, 2424, 2962, 1184, 565, 293], "temperature": 0.0, "avg_logprob": -0.18618884933329075, "compression_ratio": 1.6693548387096775, "no_speech_prob": 2.6841910312214168e-06}, {"id": 97, "seek": 48690, "start": 494.53999999999996, "end": 496.53999999999996, "text": " You'll see it's in the right spot", "tokens": [509, 603, 536, 309, 311, 294, 264, 558, 4008], "temperature": 0.0, "avg_logprob": -0.18618884933329075, "compression_ratio": 1.6693548387096775, "no_speech_prob": 2.6841910312214168e-06}, {"id": 98, "seek": 48690, "start": 497.29999999999995, "end": 499.29999999999995, "text": " Now you'll see sometimes", "tokens": [823, 291, 603, 536, 2171], "temperature": 0.0, "avg_logprob": -0.18618884933329075, "compression_ratio": 1.6693548387096775, "no_speech_prob": 2.6841910312214168e-06}, {"id": 99, "seek": 48690, "start": 499.41999999999996, "end": 505.09999999999997, "text": " It looks a little odd like here. Why is that bounding box there? And the problem is", "tokens": [467, 1542, 257, 707, 7401, 411, 510, 13, 1545, 307, 300, 5472, 278, 2424, 456, 30, 400, 264, 1154, 307], "temperature": 0.0, "avg_logprob": -0.18618884933329075, "compression_ratio": 1.6693548387096775, "no_speech_prob": 2.6841910312214168e-06}, {"id": 100, "seek": 48690, "start": 505.58, "end": 511.26, "text": " This is just a constraint that the information we have right the bounding box does not tell us", "tokens": [639, 307, 445, 257, 25534, 300, 264, 1589, 321, 362, 558, 264, 5472, 278, 2424, 775, 406, 980, 505], "temperature": 0.0, "avg_logprob": -0.18618884933329075, "compression_ratio": 1.6693548387096775, "no_speech_prob": 2.6841910312214168e-06}, {"id": 101, "seek": 48690, "start": 511.58, "end": 514.42, "text": " That actually her head isn't way over here in the top left corner", "tokens": [663, 767, 720, 1378, 1943, 380, 636, 670, 510, 294, 264, 1192, 1411, 4538], "temperature": 0.0, "avg_logprob": -0.18618884933329075, "compression_ratio": 1.6693548387096775, "no_speech_prob": 2.6841910312214168e-06}, {"id": 102, "seek": 51442, "start": 514.42, "end": 519.54, "text": " Right, but actually if you do a 30 degree rotation and her head was over here in the top left corner", "tokens": [1779, 11, 457, 767, 498, 291, 360, 257, 2217, 4314, 12447, 293, 720, 1378, 390, 670, 510, 294, 264, 1192, 1411, 4538], "temperature": 0.0, "avg_logprob": -0.17994868080571014, "compression_ratio": 1.77992277992278, "no_speech_prob": 4.785057171829976e-06}, {"id": 103, "seek": 51442, "start": 519.54, "end": 522.36, "text": " Then the new bounding box would need would go really high", "tokens": [1396, 264, 777, 5472, 278, 2424, 576, 643, 576, 352, 534, 1090], "temperature": 0.0, "avg_logprob": -0.17994868080571014, "compression_ratio": 1.77992277992278, "no_speech_prob": 4.785057171829976e-06}, {"id": 104, "seek": 51442, "start": 523.02, "end": 529.66, "text": " Right. So this is actually the correct bounding box based on the information it has available", "tokens": [1779, 13, 407, 341, 307, 767, 264, 3006, 5472, 278, 2424, 2361, 322, 264, 1589, 309, 575, 2435], "temperature": 0.0, "avg_logprob": -0.17994868080571014, "compression_ratio": 1.77992277992278, "no_speech_prob": 4.785057171829976e-06}, {"id": 105, "seek": 51442, "start": 529.66, "end": 536.86, "text": " Which is to say this is this is how high she might have been so basically you've got to be careful of not doing too higher", "tokens": [3013, 307, 281, 584, 341, 307, 341, 307, 577, 1090, 750, 1062, 362, 668, 370, 1936, 291, 600, 658, 281, 312, 5026, 295, 406, 884, 886, 2946], "temperature": 0.0, "avg_logprob": -0.17994868080571014, "compression_ratio": 1.77992277992278, "no_speech_prob": 4.785057171829976e-06}, {"id": 106, "seek": 51442, "start": 537.66, "end": 541.38, "text": " rotations with bounding boxes because there's not enough information for them to stay", "tokens": [44796, 365, 5472, 278, 9002, 570, 456, 311, 406, 1547, 1589, 337, 552, 281, 1754], "temperature": 0.0, "avg_logprob": -0.17994868080571014, "compression_ratio": 1.77992277992278, "no_speech_prob": 4.785057171829976e-06}, {"id": 107, "seek": 54138, "start": 541.38, "end": 547.66, "text": " Totally accurate fundamental limitation with the information we're given if we were doing like", "tokens": [22837, 8559, 8088, 27432, 365, 264, 1589, 321, 434, 2212, 498, 321, 645, 884, 411], "temperature": 0.0, "avg_logprob": -0.28534645192763386, "compression_ratio": 1.5513513513513513, "no_speech_prob": 1.544606675452087e-05}, {"id": 108, "seek": 54138, "start": 548.7, "end": 550.7, "text": " polygons or", "tokens": [6754, 70, 892, 420], "temperature": 0.0, "avg_logprob": -0.28534645192763386, "compression_ratio": 1.5513513513513513, "no_speech_prob": 1.544606675452087e-05}, {"id": 109, "seek": 54138, "start": 550.9399999999999, "end": 553.38, "text": " segmentations or whatever we wouldn't have this problem", "tokens": [9469, 763, 420, 2035, 321, 2759, 380, 362, 341, 1154], "temperature": 0.0, "avg_logprob": -0.28534645192763386, "compression_ratio": 1.5513513513513513, "no_speech_prob": 1.544606675452087e-05}, {"id": 110, "seek": 54138, "start": 554.14, "end": 560.02, "text": " Okay, so I'm going to do maximum of three degree rotations to avoid that problem", "tokens": [1033, 11, 370, 286, 478, 516, 281, 360, 6674, 295, 1045, 4314, 44796, 281, 5042, 300, 1154], "temperature": 0.0, "avg_logprob": -0.28534645192763386, "compression_ratio": 1.5513513513513513, "no_speech_prob": 1.544606675452087e-05}, {"id": 111, "seek": 54138, "start": 562.5, "end": 565.18, "text": " I'm also going to only rotate half the time", "tokens": [286, 478, 611, 516, 281, 787, 13121, 1922, 264, 565], "temperature": 0.0, "avg_logprob": -0.28534645192763386, "compression_ratio": 1.5513513513513513, "no_speech_prob": 1.544606675452087e-05}, {"id": 112, "seek": 56518, "start": 565.18, "end": 572.14, "text": " My random flip I'm going to have my brightness and contrast changing and so there's my set of transformations", "tokens": [1222, 4974, 7929, 286, 478, 516, 281, 362, 452, 21367, 293, 8712, 4473, 293, 370, 456, 311, 452, 992, 295, 34852], "temperature": 0.0, "avg_logprob": -0.2292795181274414, "compression_ratio": 1.608695652173913, "no_speech_prob": 3.2377374736825004e-06}, {"id": 113, "seek": 56518, "start": 575.2199999999999, "end": 577.8199999999999, "text": " So we briefly looked at this custom head idea", "tokens": [407, 321, 10515, 2956, 412, 341, 2375, 1378, 1558], "temperature": 0.0, "avg_logprob": -0.2292795181274414, "compression_ratio": 1.608695652173913, "no_speech_prob": 3.2377374736825004e-06}, {"id": 114, "seek": 56518, "start": 578.5799999999999, "end": 580.5799999999999, "text": " But basically if you look at", "tokens": [583, 1936, 498, 291, 574, 412], "temperature": 0.0, "avg_logprob": -0.2292795181274414, "compression_ratio": 1.608695652173913, "no_speech_prob": 3.2377374736825004e-06}, {"id": 115, "seek": 56518, "start": 581.02, "end": 584.4399999999999, "text": " dot summary dot summary does something pretty cool", "tokens": [5893, 12691, 5893, 12691, 775, 746, 1238, 1627], "temperature": 0.0, "avg_logprob": -0.2292795181274414, "compression_ratio": 1.608695652173913, "no_speech_prob": 3.2377374736825004e-06}, {"id": 116, "seek": 56518, "start": 584.4399999999999, "end": 588.12, "text": " which is it basically runs a small batch of data through a model and", "tokens": [597, 307, 309, 1936, 6676, 257, 1359, 15245, 295, 1412, 807, 257, 2316, 293], "temperature": 0.0, "avg_logprob": -0.2292795181274414, "compression_ratio": 1.608695652173913, "no_speech_prob": 3.2377374736825004e-06}, {"id": 117, "seek": 58812, "start": 588.12, "end": 596.3, "text": " prints out how big it is at every in every layer and we can see that at the end of the", "tokens": [22305, 484, 577, 955, 309, 307, 412, 633, 294, 633, 4583, 293, 321, 393, 536, 300, 412, 264, 917, 295, 264], "temperature": 0.0, "avg_logprob": -0.28719299959849165, "compression_ratio": 1.6704545454545454, "no_speech_prob": 2.947996335933567e-06}, {"id": 118, "seek": 58812, "start": 596.36, "end": 600.6, "text": " convolutional section before we hit the flatten it's 512 by 7 by 7", "tokens": [45216, 304, 3541, 949, 321, 2045, 264, 24183, 309, 311, 1025, 4762, 538, 1614, 538, 1614], "temperature": 0.0, "avg_logprob": -0.28719299959849165, "compression_ratio": 1.6704545454545454, "no_speech_prob": 2.947996335933567e-06}, {"id": 119, "seek": 58812, "start": 601.04, "end": 605.0, "text": " Okay, and so 512 by 7 by 7", "tokens": [1033, 11, 293, 370, 1025, 4762, 538, 1614, 538, 1614], "temperature": 0.0, "avg_logprob": -0.28719299959849165, "compression_ratio": 1.6704545454545454, "no_speech_prob": 2.947996335933567e-06}, {"id": 120, "seek": 58812, "start": 605.92, "end": 613.92, "text": " tensor rank 3 tensor of that size if we flatten it out into a single rank 1 tensor into a vector it's going to be", "tokens": [40863, 6181, 805, 40863, 295, 300, 2744, 498, 321, 24183, 309, 484, 666, 257, 2167, 6181, 502, 40863, 666, 257, 8062, 309, 311, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.28719299959849165, "compression_ratio": 1.6704545454545454, "no_speech_prob": 2.947996335933567e-06}, {"id": 121, "seek": 61392, "start": 613.92, "end": 619.64, "text": " 225,000 and 88 long right so then that's why we had this linear", "tokens": [5853, 20, 11, 1360, 293, 24587, 938, 558, 370, 550, 300, 311, 983, 321, 632, 341, 8213], "temperature": 0.0, "avg_logprob": -0.4591107177734375, "compression_ratio": 1.4228571428571428, "no_speech_prob": 1.0845120641533867e-06}, {"id": 122, "seek": 61392, "start": 620.36, "end": 622.36, "text": " layer", "tokens": [4583], "temperature": 0.0, "avg_logprob": -0.4591107177734375, "compression_ratio": 1.4228571428571428, "no_speech_prob": 1.0845120641533867e-06}, {"id": 123, "seek": 61392, "start": 622.4399999999999, "end": 627.8399999999999, "text": " For because of the four bounding boxes right so stick that on top of a pre trained ResNet", "tokens": [1171, 570, 295, 264, 1451, 5472, 278, 9002, 558, 370, 2897, 300, 322, 1192, 295, 257, 659, 8895, 5015, 31890], "temperature": 0.0, "avg_logprob": -0.4591107177734375, "compression_ratio": 1.4228571428571428, "no_speech_prob": 1.0845120641533867e-06}, {"id": 124, "seek": 61392, "start": 628.56, "end": 629.8399999999999, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.4591107177734375, "compression_ratio": 1.4228571428571428, "no_speech_prob": 1.0845120641533867e-06}, {"id": 125, "seek": 61392, "start": 629.8399999999999, "end": 631.8399999999999, "text": " Train it for a while", "tokens": [28029, 309, 337, 257, 1339], "temperature": 0.0, "avg_logprob": -0.4591107177734375, "compression_ratio": 1.4228571428571428, "no_speech_prob": 1.0845120641533867e-06}, {"id": 126, "seek": 61392, "start": 634.52, "end": 640.78, "text": " Okay, so that's where we got to last time so let's now put those", "tokens": [1033, 11, 370, 300, 311, 689, 321, 658, 281, 1036, 565, 370, 718, 311, 586, 829, 729], "temperature": 0.0, "avg_logprob": -0.4591107177734375, "compression_ratio": 1.4228571428571428, "no_speech_prob": 1.0845120641533867e-06}, {"id": 127, "seek": 64078, "start": 640.78, "end": 642.5799999999999, "text": " two", "tokens": [732], "temperature": 0.0, "avg_logprob": -0.2133088918832632, "compression_ratio": 1.6265822784810127, "no_speech_prob": 1.7330435184703674e-06}, {"id": 128, "seek": 64078, "start": 642.5799999999999, "end": 647.38, "text": " pieces together so that we can get something that classifies and does bounding boxes and", "tokens": [3755, 1214, 370, 300, 321, 393, 483, 746, 300, 1508, 11221, 293, 775, 5472, 278, 9002, 293], "temperature": 0.0, "avg_logprob": -0.2133088918832632, "compression_ratio": 1.6265822784810127, "no_speech_prob": 1.7330435184703674e-06}, {"id": 129, "seek": 64078, "start": 648.86, "end": 650.86, "text": " there are", "tokens": [456, 366], "temperature": 0.0, "avg_logprob": -0.2133088918832632, "compression_ratio": 1.6265822784810127, "no_speech_prob": 1.7330435184703674e-06}, {"id": 130, "seek": 64078, "start": 652.9399999999999, "end": 655.66, "text": " There are three things that we need to do", "tokens": [821, 366, 1045, 721, 300, 321, 643, 281, 360], "temperature": 0.0, "avg_logprob": -0.2133088918832632, "compression_ratio": 1.6265822784810127, "no_speech_prob": 1.7330435184703674e-06}, {"id": 131, "seek": 64078, "start": 656.66, "end": 661.14, "text": " Basically to train a neural network ever right we need to provide", "tokens": [8537, 281, 3847, 257, 18161, 3209, 1562, 558, 321, 643, 281, 2893], "temperature": 0.0, "avg_logprob": -0.2133088918832632, "compression_ratio": 1.6265822784810127, "no_speech_prob": 1.7330435184703674e-06}, {"id": 132, "seek": 64078, "start": 662.1, "end": 664.1, "text": " data", "tokens": [1412], "temperature": 0.0, "avg_logprob": -0.2133088918832632, "compression_ratio": 1.6265822784810127, "no_speech_prob": 1.7330435184703674e-06}, {"id": 133, "seek": 66410, "start": 664.1, "end": 669.1800000000001, "text": " We need to pick some kind of architecture and", "tokens": [492, 643, 281, 1888, 512, 733, 295, 9482, 293], "temperature": 0.0, "avg_logprob": -0.2665528735599002, "compression_ratio": 1.6294416243654823, "no_speech_prob": 2.601588903416996e-06}, {"id": 134, "seek": 66410, "start": 671.1800000000001, "end": 673.1800000000001, "text": " We did it loss function", "tokens": [492, 630, 309, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.2665528735599002, "compression_ratio": 1.6294416243654823, "no_speech_prob": 2.601588903416996e-06}, {"id": 135, "seek": 66410, "start": 673.58, "end": 681.22, "text": " Okay, so the loss function says you know something anything that gives a lower number here is a better network", "tokens": [1033, 11, 370, 264, 4470, 2445, 1619, 291, 458, 746, 1340, 300, 2709, 257, 3126, 1230, 510, 307, 257, 1101, 3209], "temperature": 0.0, "avg_logprob": -0.2665528735599002, "compression_ratio": 1.6294416243654823, "no_speech_prob": 2.601588903416996e-06}, {"id": 136, "seek": 66410, "start": 681.9, "end": 683.9, "text": " Using this data in this architecture", "tokens": [11142, 341, 1412, 294, 341, 9482], "temperature": 0.0, "avg_logprob": -0.2665528735599002, "compression_ratio": 1.6294416243654823, "no_speech_prob": 2.601588903416996e-06}, {"id": 137, "seek": 66410, "start": 684.74, "end": 686.94, "text": " So we're going to need to create those three things", "tokens": [407, 321, 434, 516, 281, 643, 281, 1884, 729, 1045, 721], "temperature": 0.0, "avg_logprob": -0.2665528735599002, "compression_ratio": 1.6294416243654823, "no_speech_prob": 2.601588903416996e-06}, {"id": 138, "seek": 66410, "start": 687.78, "end": 690.58, "text": " for our classification plus bounding box regression", "tokens": [337, 527, 21538, 1804, 5472, 278, 2424, 24590], "temperature": 0.0, "avg_logprob": -0.2665528735599002, "compression_ratio": 1.6294416243654823, "no_speech_prob": 2.601588903416996e-06}, {"id": 139, "seek": 69058, "start": 690.58, "end": 692.58, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.24029062971284118, "compression_ratio": 1.6894736842105262, "no_speech_prob": 3.6119515698374016e-06}, {"id": 140, "seek": 69058, "start": 693.7, "end": 695.7, "text": " That means we need a", "tokens": [663, 1355, 321, 643, 257], "temperature": 0.0, "avg_logprob": -0.24029062971284118, "compression_ratio": 1.6894736842105262, "no_speech_prob": 3.6119515698374016e-06}, {"id": 141, "seek": 69058, "start": 696.86, "end": 703.5, "text": " Model data object which has as the independence the images and as the dependence", "tokens": [17105, 1412, 2657, 597, 575, 382, 264, 14640, 264, 5267, 293, 382, 264, 31704], "temperature": 0.0, "avg_logprob": -0.24029062971284118, "compression_ratio": 1.6894736842105262, "no_speech_prob": 3.6119515698374016e-06}, {"id": 142, "seek": 69058, "start": 703.5, "end": 709.6600000000001, "text": " I want to have a tuple the first element of the tuple should be the bounding box coordinates and the second element", "tokens": [286, 528, 281, 362, 257, 2604, 781, 264, 700, 4478, 295, 264, 2604, 781, 820, 312, 264, 5472, 278, 2424, 21056, 293, 264, 1150, 4478], "temperature": 0.0, "avg_logprob": -0.24029062971284118, "compression_ratio": 1.6894736842105262, "no_speech_prob": 3.6119515698374016e-06}, {"id": 143, "seek": 69058, "start": 709.6600000000001, "end": 712.32, "text": " The tuple should be the class okay", "tokens": [440, 2604, 781, 820, 312, 264, 1508, 1392], "temperature": 0.0, "avg_logprob": -0.24029062971284118, "compression_ratio": 1.6894736842105262, "no_speech_prob": 3.6119515698374016e-06}, {"id": 144, "seek": 69058, "start": 714.82, "end": 718.0200000000001, "text": " There's lots of different ways you could do this the particularly", "tokens": [821, 311, 3195, 295, 819, 2098, 291, 727, 360, 341, 264, 4098], "temperature": 0.0, "avg_logprob": -0.24029062971284118, "compression_ratio": 1.6894736842105262, "no_speech_prob": 3.6119515698374016e-06}, {"id": 145, "seek": 71802, "start": 718.02, "end": 720.86, "text": " lazy and convenient way I came up with", "tokens": [14847, 293, 10851, 636, 286, 1361, 493, 365], "temperature": 0.0, "avg_logprob": -0.271737482355929, "compression_ratio": 1.5981735159817352, "no_speech_prob": 3.187537004123442e-06}, {"id": 146, "seek": 71802, "start": 721.6999999999999, "end": 724.74, "text": " Was to create two model data objects", "tokens": [3027, 281, 1884, 732, 2316, 1412, 6565], "temperature": 0.0, "avg_logprob": -0.271737482355929, "compression_ratio": 1.5981735159817352, "no_speech_prob": 3.187537004123442e-06}, {"id": 147, "seek": 71802, "start": 726.1, "end": 732.66, "text": " Representing the two different dependent variables. I want so one with the bounding box coordinates one of the classes", "tokens": [19945, 278, 264, 732, 819, 12334, 9102, 13, 286, 528, 370, 472, 365, 264, 5472, 278, 2424, 21056, 472, 295, 264, 5359], "temperature": 0.0, "avg_logprob": -0.271737482355929, "compression_ratio": 1.5981735159817352, "no_speech_prob": 3.187537004123442e-06}, {"id": 148, "seek": 71802, "start": 733.22, "end": 735.22, "text": " Just using the CSP to build them for", "tokens": [1449, 1228, 264, 9460, 47, 281, 1322, 552, 337], "temperature": 0.0, "avg_logprob": -0.271737482355929, "compression_ratio": 1.5981735159817352, "no_speech_prob": 3.187537004123442e-06}, {"id": 149, "seek": 71802, "start": 735.98, "end": 739.1, "text": " And now I'm going to merge them together", "tokens": [400, 586, 286, 478, 516, 281, 22183, 552, 1214], "temperature": 0.0, "avg_logprob": -0.271737482355929, "compression_ratio": 1.5981735159817352, "no_speech_prob": 3.187537004123442e-06}, {"id": 150, "seek": 71802, "start": 739.42, "end": 745.18, "text": " So I create a new data set class and a data set class is anything which has a", "tokens": [407, 286, 1884, 257, 777, 1412, 992, 1508, 293, 257, 1412, 992, 1508, 307, 1340, 597, 575, 257], "temperature": 0.0, "avg_logprob": -0.271737482355929, "compression_ratio": 1.5981735159817352, "no_speech_prob": 3.187537004123442e-06}, {"id": 151, "seek": 74518, "start": 745.18, "end": 748.3399999999999, "text": " length and an indexer", "tokens": [4641, 293, 364, 8186, 260], "temperature": 0.0, "avg_logprob": -0.355891031761692, "compression_ratio": 1.676300578034682, "no_speech_prob": 3.0415787932724925e-06}, {"id": 152, "seek": 74518, "start": 749.8599999999999, "end": 757.9799999999999, "text": " And so in this case I can have a constructor which takes an existing data set", "tokens": [400, 370, 294, 341, 1389, 286, 393, 362, 257, 47479, 597, 2516, 364, 6741, 1412, 992], "temperature": 0.0, "avg_logprob": -0.355891031761692, "compression_ratio": 1.676300578034682, "no_speech_prob": 3.0415787932724925e-06}, {"id": 153, "seek": 74518, "start": 757.9799999999999, "end": 761.0999999999999, "text": " so that's going to have both independent and dependent and", "tokens": [370, 300, 311, 516, 281, 362, 1293, 6695, 293, 12334, 293], "temperature": 0.0, "avg_logprob": -0.355891031761692, "compression_ratio": 1.676300578034682, "no_speech_prob": 3.0415787932724925e-06}, {"id": 154, "seek": 74518, "start": 762.62, "end": 764.62, "text": " the second", "tokens": [264, 1150], "temperature": 0.0, "avg_logprob": -0.355891031761692, "compression_ratio": 1.676300578034682, "no_speech_prob": 3.0415787932724925e-06}, {"id": 155, "seek": 74518, "start": 764.6999999999999, "end": 766.6999999999999, "text": " Dependent that I want", "tokens": [4056, 521, 317, 300, 286, 528], "temperature": 0.0, "avg_logprob": -0.355891031761692, "compression_ratio": 1.676300578034682, "no_speech_prob": 3.0415787932724925e-06}, {"id": 156, "seek": 76670, "start": 766.7, "end": 776.5, "text": " The length then is just obviously the length of the data set the first data set and then get item is grab the X and the Y", "tokens": [440, 4641, 550, 307, 445, 2745, 264, 4641, 295, 264, 1412, 992, 264, 700, 1412, 992, 293, 550, 483, 3174, 307, 4444, 264, 1783, 293, 264, 398], "temperature": 0.0, "avg_logprob": -0.32577160130376404, "compression_ratio": 1.953125, "no_speech_prob": 4.356853878562106e-06}, {"id": 157, "seek": 76670, "start": 777.26, "end": 779.6600000000001, "text": " from the data set that passed in and", "tokens": [490, 264, 1412, 992, 300, 4678, 294, 293], "temperature": 0.0, "avg_logprob": -0.32577160130376404, "compression_ratio": 1.953125, "no_speech_prob": 4.356853878562106e-06}, {"id": 158, "seek": 76670, "start": 780.4200000000001, "end": 783.62, "text": " return that X and that Y and", "tokens": [2736, 300, 1783, 293, 300, 398, 293], "temperature": 0.0, "avg_logprob": -0.32577160130376404, "compression_ratio": 1.953125, "no_speech_prob": 4.356853878562106e-06}, {"id": 159, "seek": 76670, "start": 784.5, "end": 791.5, "text": " The I value of the second dependent variable that passed in right so there's a data set that basically adds", "tokens": [440, 286, 2158, 295, 264, 1150, 12334, 7006, 300, 4678, 294, 558, 370, 456, 311, 257, 1412, 992, 300, 1936, 10860], "temperature": 0.0, "avg_logprob": -0.32577160130376404, "compression_ratio": 1.953125, "no_speech_prob": 4.356853878562106e-06}, {"id": 160, "seek": 76670, "start": 791.82, "end": 795.5, "text": " In a second dependent variable as I said there's lots of ways you could do this", "tokens": [682, 257, 1150, 12334, 7006, 382, 286, 848, 456, 311, 3195, 295, 2098, 291, 727, 360, 341], "temperature": 0.0, "avg_logprob": -0.32577160130376404, "compression_ratio": 1.953125, "no_speech_prob": 4.356853878562106e-06}, {"id": 161, "seek": 79550, "start": 795.5, "end": 800.46, "text": " It's kind of convenient because now what I could do is I can create", "tokens": [467, 311, 733, 295, 10851, 570, 586, 437, 286, 727, 360, 307, 286, 393, 1884], "temperature": 0.0, "avg_logprob": -0.21815889531915839, "compression_ratio": 1.7107438016528926, "no_speech_prob": 1.3211767509346828e-05}, {"id": 162, "seek": 79550, "start": 801.18, "end": 803.94, "text": " Training data set and validation data set based on that", "tokens": [20620, 1412, 992, 293, 24071, 1412, 992, 2361, 322, 300], "temperature": 0.0, "avg_logprob": -0.21815889531915839, "compression_ratio": 1.7107438016528926, "no_speech_prob": 1.3211767509346828e-05}, {"id": 163, "seek": 79550, "start": 804.58, "end": 810.42, "text": " So here's an example. You can see it's got a couple of the bounding box coordinates in the class", "tokens": [407, 510, 311, 364, 1365, 13, 509, 393, 536, 309, 311, 658, 257, 1916, 295, 264, 5472, 278, 2424, 21056, 294, 264, 1508], "temperature": 0.0, "avg_logprob": -0.21815889531915839, "compression_ratio": 1.7107438016528926, "no_speech_prob": 1.3211767509346828e-05}, {"id": 164, "seek": 79550, "start": 811.9, "end": 819.02, "text": " We can then take the existing training and validation data loaders and actually replace their data sets with these and done done", "tokens": [492, 393, 550, 747, 264, 6741, 3097, 293, 24071, 1412, 3677, 433, 293, 767, 7406, 641, 1412, 6352, 365, 613, 293, 1096, 1096], "temperature": 0.0, "avg_logprob": -0.21815889531915839, "compression_ratio": 1.7107438016528926, "no_speech_prob": 1.3211767509346828e-05}, {"id": 165, "seek": 79550, "start": 819.26, "end": 823.14, "text": " okay, so we can now test it by grabbing a mini batch of data and", "tokens": [1392, 11, 370, 321, 393, 586, 1500, 309, 538, 23771, 257, 8382, 15245, 295, 1412, 293], "temperature": 0.0, "avg_logprob": -0.21815889531915839, "compression_ratio": 1.7107438016528926, "no_speech_prob": 1.3211767509346828e-05}, {"id": 166, "seek": 82314, "start": 823.14, "end": 825.14, "text": " checking that we", "tokens": [8568, 300, 321], "temperature": 0.0, "avg_logprob": -0.23070414861043295, "compression_ratio": 1.691891891891892, "no_speech_prob": 3.726605655174353e-06}, {"id": 167, "seek": 82314, "start": 825.58, "end": 828.26, "text": " Have something that makes sense. Okay, so", "tokens": [3560, 746, 300, 1669, 2020, 13, 1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.23070414861043295, "compression_ratio": 1.691891891891892, "no_speech_prob": 3.726605655174353e-06}, {"id": 168, "seek": 82314, "start": 828.9, "end": 830.9, "text": " There's one way to", "tokens": [821, 311, 472, 636, 281], "temperature": 0.0, "avg_logprob": -0.23070414861043295, "compression_ratio": 1.691891891891892, "no_speech_prob": 3.726605655174353e-06}, {"id": 169, "seek": 82314, "start": 831.9399999999999, "end": 833.9399999999999, "text": " Customize a data set", "tokens": [16649, 1125, 257, 1412, 992], "temperature": 0.0, "avg_logprob": -0.23070414861043295, "compression_ratio": 1.691891891891892, "no_speech_prob": 3.726605655174353e-06}, {"id": 170, "seek": 82314, "start": 835.14, "end": 841.1, "text": " So what we're going to do this time now is we've got the data so now we need an architecture", "tokens": [407, 437, 321, 434, 516, 281, 360, 341, 565, 586, 307, 321, 600, 658, 264, 1412, 370, 586, 321, 643, 364, 9482], "temperature": 0.0, "avg_logprob": -0.23070414861043295, "compression_ratio": 1.691891891891892, "no_speech_prob": 3.726605655174353e-06}, {"id": 171, "seek": 82314, "start": 841.62, "end": 849.24, "text": " So the architecture is going to be the same as the architectures that we used for the classifier and for the bounding box", "tokens": [407, 264, 9482, 307, 516, 281, 312, 264, 912, 382, 264, 6331, 1303, 300, 321, 1143, 337, 264, 1508, 9902, 293, 337, 264, 5472, 278, 2424], "temperature": 0.0, "avg_logprob": -0.23070414861043295, "compression_ratio": 1.691891891891892, "no_speech_prob": 3.726605655174353e-06}, {"id": 172, "seek": 84924, "start": 849.24, "end": 855.28, "text": " Aggression, but we're just going to combine them. So in other words if there are C classes", "tokens": [41512, 2775, 11, 457, 321, 434, 445, 516, 281, 10432, 552, 13, 407, 294, 661, 2283, 498, 456, 366, 383, 5359], "temperature": 0.0, "avg_logprob": -0.24433286330279183, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.255347332422389e-06}, {"id": 173, "seek": 84924, "start": 857.12, "end": 862.5600000000001, "text": " Then the number of activations we need in the final layer is 4 plus C", "tokens": [1396, 264, 1230, 295, 2430, 763, 321, 643, 294, 264, 2572, 4583, 307, 1017, 1804, 383], "temperature": 0.0, "avg_logprob": -0.24433286330279183, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.255347332422389e-06}, {"id": 174, "seek": 84924, "start": 863.08, "end": 866.24, "text": " for bounding box coordinates and the C", "tokens": [337, 5472, 278, 2424, 21056, 293, 264, 383], "temperature": 0.0, "avg_logprob": -0.24433286330279183, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.255347332422389e-06}, {"id": 175, "seek": 84924, "start": 866.88, "end": 868.88, "text": " probabilities one per class", "tokens": [33783, 472, 680, 1508], "temperature": 0.0, "avg_logprob": -0.24433286330279183, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.255347332422389e-06}, {"id": 176, "seek": 84924, "start": 869.0, "end": 870.84, "text": " so this is the", "tokens": [370, 341, 307, 264], "temperature": 0.0, "avg_logprob": -0.24433286330279183, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.255347332422389e-06}, {"id": 177, "seek": 84924, "start": 870.84, "end": 874.88, "text": " final layer a linear layer that has four plus when of", "tokens": [2572, 4583, 257, 8213, 4583, 300, 575, 1451, 1804, 562, 295], "temperature": 0.0, "avg_logprob": -0.24433286330279183, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.255347332422389e-06}, {"id": 178, "seek": 84924, "start": 875.48, "end": 876.6800000000001, "text": " categories", "tokens": [10479], "temperature": 0.0, "avg_logprob": -0.24433286330279183, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.255347332422389e-06}, {"id": 179, "seek": 84924, "start": 876.6800000000001, "end": 877.92, "text": " activations", "tokens": [2430, 763], "temperature": 0.0, "avg_logprob": -0.24433286330279183, "compression_ratio": 1.5714285714285714, "no_speech_prob": 5.255347332422389e-06}, {"id": 180, "seek": 87792, "start": 877.92, "end": 879.92, "text": " The first layer is before as a flatten", "tokens": [440, 700, 4583, 307, 949, 382, 257, 24183], "temperature": 0.0, "avg_logprob": -0.23255536556243897, "compression_ratio": 1.4829268292682927, "no_speech_prob": 1.8738677454166464e-06}, {"id": 181, "seek": 87792, "start": 881.68, "end": 886.7199999999999, "text": " We could just join those up together, but in general I want my", "tokens": [492, 727, 445, 3917, 729, 493, 1214, 11, 457, 294, 2674, 286, 528, 452], "temperature": 0.0, "avg_logprob": -0.23255536556243897, "compression_ratio": 1.4829268292682927, "no_speech_prob": 1.8738677454166464e-06}, {"id": 182, "seek": 87792, "start": 887.4799999999999, "end": 889.4799999999999, "text": " my custom head", "tokens": [452, 2375, 1378], "temperature": 0.0, "avg_logprob": -0.23255536556243897, "compression_ratio": 1.4829268292682927, "no_speech_prob": 1.8738677454166464e-06}, {"id": 183, "seek": 87792, "start": 889.68, "end": 891.28, "text": " to like", "tokens": [281, 411], "temperature": 0.0, "avg_logprob": -0.23255536556243897, "compression_ratio": 1.4829268292682927, "no_speech_prob": 1.8738677454166464e-06}, {"id": 184, "seek": 87792, "start": 891.28, "end": 893.92, "text": " Hopefully be capable of solving the problem", "tokens": [10429, 312, 8189, 295, 12606, 264, 1154], "temperature": 0.0, "avg_logprob": -0.23255536556243897, "compression_ratio": 1.4829268292682927, "no_speech_prob": 1.8738677454166464e-06}, {"id": 185, "seek": 87792, "start": 894.68, "end": 900.64, "text": " That I give it on its own if the pre trained backbone is connected to is", "tokens": [663, 286, 976, 309, 322, 1080, 1065, 498, 264, 659, 8895, 34889, 307, 4582, 281, 307], "temperature": 0.0, "avg_logprob": -0.23255536556243897, "compression_ratio": 1.4829268292682927, "no_speech_prob": 1.8738677454166464e-06}, {"id": 186, "seek": 87792, "start": 901.36, "end": 905.36, "text": " You know is appropriate and so in this case, I'm thinking okay", "tokens": [509, 458, 307, 6854, 293, 370, 294, 341, 1389, 11, 286, 478, 1953, 1392], "temperature": 0.0, "avg_logprob": -0.23255536556243897, "compression_ratio": 1.4829268292682927, "no_speech_prob": 1.8738677454166464e-06}, {"id": 187, "seek": 90536, "start": 905.36, "end": 910.4, "text": " I'm trying to do like quite a bit here two different things that classifier and bounding box aggression", "tokens": [286, 478, 1382, 281, 360, 411, 1596, 257, 857, 510, 732, 819, 721, 300, 1508, 9902, 293, 5472, 278, 2424, 30268], "temperature": 0.0, "avg_logprob": -0.29949845586504253, "compression_ratio": 1.7045454545454546, "no_speech_prob": 8.139581950672437e-06}, {"id": 188, "seek": 90536, "start": 910.4, "end": 915.32, "text": " So just a single linear layer doesn't sound like enough so I put in a second linear layer", "tokens": [407, 445, 257, 2167, 8213, 4583, 1177, 380, 1626, 411, 1547, 370, 286, 829, 294, 257, 1150, 8213, 4583], "temperature": 0.0, "avg_logprob": -0.29949845586504253, "compression_ratio": 1.7045454545454546, "no_speech_prob": 8.139581950672437e-06}, {"id": 189, "seek": 90536, "start": 915.76, "end": 920.6, "text": " Okay, and so you can see we basically go value dropout linear", "tokens": [1033, 11, 293, 370, 291, 393, 536, 321, 1936, 352, 2158, 3270, 346, 8213], "temperature": 0.0, "avg_logprob": -0.29949845586504253, "compression_ratio": 1.7045454545454546, "no_speech_prob": 8.139581950672437e-06}, {"id": 190, "seek": 90536, "start": 921.24, "end": 926.08, "text": " Reli you batch norm dropout. Yeah, if you're wondering why there's no batch norm back here", "tokens": [8738, 72, 291, 15245, 2026, 3270, 346, 13, 865, 11, 498, 291, 434, 6359, 983, 456, 311, 572, 15245, 2026, 646, 510], "temperature": 0.0, "avg_logprob": -0.29949845586504253, "compression_ratio": 1.7045454545454546, "no_speech_prob": 8.139581950672437e-06}, {"id": 191, "seek": 90536, "start": 926.08, "end": 931.0, "text": " I checked the ResNet backbone it already has a batch norm as its final layer", "tokens": [286, 10033, 264, 5015, 31890, 34889, 309, 1217, 575, 257, 15245, 2026, 382, 1080, 2572, 4583], "temperature": 0.0, "avg_logprob": -0.29949845586504253, "compression_ratio": 1.7045454545454546, "no_speech_prob": 8.139581950672437e-06}, {"id": 192, "seek": 90536, "start": 932.48, "end": 934.48, "text": " Okay, so this is basically", "tokens": [1033, 11, 370, 341, 307, 1936], "temperature": 0.0, "avg_logprob": -0.29949845586504253, "compression_ratio": 1.7045454545454546, "no_speech_prob": 8.139581950672437e-06}, {"id": 193, "seek": 93448, "start": 934.48, "end": 936.48, "text": " a nearly the same", "tokens": [257, 6217, 264, 912], "temperature": 0.0, "avg_logprob": -0.273171684958718, "compression_ratio": 1.5933014354066986, "no_speech_prob": 1.6028062646000762e-06}, {"id": 194, "seek": 93448, "start": 937.0, "end": 943.0, "text": " Custom head as before it's just it's got two linear layers rather than one and the appropriate", "tokens": [16649, 1378, 382, 949, 309, 311, 445, 309, 311, 658, 732, 8213, 7914, 2831, 813, 472, 293, 264, 6854], "temperature": 0.0, "avg_logprob": -0.273171684958718, "compression_ratio": 1.5933014354066986, "no_speech_prob": 1.6028062646000762e-06}, {"id": 195, "seek": 93448, "start": 944.04, "end": 946.04, "text": " nonlinearities, okay, so", "tokens": [2107, 28263, 1088, 11, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.273171684958718, "compression_ratio": 1.5933014354066986, "no_speech_prob": 1.6028062646000762e-06}, {"id": 196, "seek": 93448, "start": 947.28, "end": 950.28, "text": " That's piece two. We've got theta. We've got architecture", "tokens": [663, 311, 2522, 732, 13, 492, 600, 658, 9725, 13, 492, 600, 658, 9482], "temperature": 0.0, "avg_logprob": -0.273171684958718, "compression_ratio": 1.5933014354066986, "no_speech_prob": 1.6028062646000762e-06}, {"id": 197, "seek": 93448, "start": 950.84, "end": 957.88, "text": " Now we need a loss function. So the loss function needs to look at these four plus C activations and", "tokens": [823, 321, 643, 257, 4470, 2445, 13, 407, 264, 4470, 2445, 2203, 281, 574, 412, 613, 1451, 1804, 383, 2430, 763, 293], "temperature": 0.0, "avg_logprob": -0.273171684958718, "compression_ratio": 1.5933014354066986, "no_speech_prob": 1.6028062646000762e-06}, {"id": 198, "seek": 93448, "start": 959.5600000000001, "end": 962.88, "text": " Decide are they good right are these", "tokens": [12427, 482, 366, 436, 665, 558, 366, 613], "temperature": 0.0, "avg_logprob": -0.273171684958718, "compression_ratio": 1.5933014354066986, "no_speech_prob": 1.6028062646000762e-06}, {"id": 199, "seek": 96288, "start": 962.88, "end": 964.36, "text": " numbers", "tokens": [3547], "temperature": 0.0, "avg_logprob": -0.5427871515721451, "compression_ratio": 1.5742574257425743, "no_speech_prob": 7.527926300099352e-06}, {"id": 200, "seek": 96288, "start": 964.36, "end": 966.36, "text": " accurately reflecting the", "tokens": [20095, 23543, 264], "temperature": 0.0, "avg_logprob": -0.5427871515721451, "compression_ratio": 1.5742574257425743, "no_speech_prob": 7.527926300099352e-06}, {"id": 201, "seek": 96288, "start": 967.04, "end": 970.04, "text": " Position and class of the largest object in this image", "tokens": [29780, 293, 1508, 295, 264, 6443, 2657, 294, 341, 3256], "temperature": 0.0, "avg_logprob": -0.5427871515721451, "compression_ratio": 1.5742574257425743, "no_speech_prob": 7.527926300099352e-06}, {"id": 202, "seek": 96288, "start": 972.12, "end": 974.12, "text": " We we know how to do that", "tokens": [492, 321, 458, 577, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.5427871515721451, "compression_ratio": 1.5742574257425743, "no_speech_prob": 7.527926300099352e-06}, {"id": 203, "seek": 96288, "start": 975.32, "end": 979.4399999999999, "text": " For the last for the first four we use", "tokens": [1171, 264, 1036, 337, 264, 700, 1451, 321, 764], "temperature": 0.0, "avg_logprob": -0.5427871515721451, "compression_ratio": 1.5742574257425743, "no_speech_prob": 7.527926300099352e-06}, {"id": 204, "seek": 96288, "start": 980.16, "end": 987.28, "text": " L1 loss just like we did in the bounding box regression before remember L1 loss is like mean squared error", "tokens": [441, 16, 4470, 445, 411, 321, 630, 294, 264, 5472, 278, 2424, 24590, 949, 1604, 441, 16, 4470, 307, 411, 914, 8889, 6713], "temperature": 0.0, "avg_logprob": -0.5427871515721451, "compression_ratio": 1.5742574257425743, "no_speech_prob": 7.527926300099352e-06}, {"id": 205, "seek": 96288, "start": 987.68, "end": 990.56, "text": " They're out the sum of squares its sum of absolute values", "tokens": [814, 434, 484, 264, 2408, 295, 19368, 1080, 2408, 295, 8236, 4190], "temperature": 0.0, "avg_logprob": -0.5427871515721451, "compression_ratio": 1.5742574257425743, "no_speech_prob": 7.527926300099352e-06}, {"id": 206, "seek": 99056, "start": 990.56, "end": 992.56, "text": " sum of absolute values and", "tokens": [2408, 295, 8236, 4190, 293], "temperature": 0.0, "avg_logprob": -0.2057809829711914, "compression_ratio": 1.6523809523809523, "no_speech_prob": 4.637849997379817e-06}, {"id": 207, "seek": 99056, "start": 993.04, "end": 997.54, "text": " Then for the rest of the activations we can use cross entropy loss", "tokens": [1396, 337, 264, 1472, 295, 264, 2430, 763, 321, 393, 764, 3278, 30867, 4470], "temperature": 0.0, "avg_logprob": -0.2057809829711914, "compression_ratio": 1.6523809523809523, "no_speech_prob": 4.637849997379817e-06}, {"id": 208, "seek": 99056, "start": 998.4399999999999, "end": 1002.1199999999999, "text": " So let's go ahead and do that. So we're going to create something called detection loss", "tokens": [407, 718, 311, 352, 2286, 293, 360, 300, 13, 407, 321, 434, 516, 281, 1884, 746, 1219, 17784, 4470], "temperature": 0.0, "avg_logprob": -0.2057809829711914, "compression_ratio": 1.6523809523809523, "no_speech_prob": 4.637849997379817e-06}, {"id": 209, "seek": 99056, "start": 1003.04, "end": 1009.7199999999999, "text": " And loss functions always take an input and a target. That's what pytorch always calls them. So this is the", "tokens": [400, 4470, 6828, 1009, 747, 364, 4846, 293, 257, 3779, 13, 663, 311, 437, 25878, 284, 339, 1009, 5498, 552, 13, 407, 341, 307, 264], "temperature": 0.0, "avg_logprob": -0.2057809829711914, "compression_ratio": 1.6523809523809523, "no_speech_prob": 4.637849997379817e-06}, {"id": 210, "seek": 99056, "start": 1010.4399999999999, "end": 1012.52, "text": " Activations this is the ground truth", "tokens": [28550, 763, 341, 307, 264, 2727, 3494], "temperature": 0.0, "avg_logprob": -0.2057809829711914, "compression_ratio": 1.6523809523809523, "no_speech_prob": 4.637849997379817e-06}, {"id": 211, "seek": 99056, "start": 1013.1199999999999, "end": 1015.1199999999999, "text": " so remember that our", "tokens": [370, 1604, 300, 527], "temperature": 0.0, "avg_logprob": -0.2057809829711914, "compression_ratio": 1.6523809523809523, "no_speech_prob": 4.637849997379817e-06}, {"id": 212, "seek": 101512, "start": 1015.12, "end": 1020.84, "text": " our date custom data set returns a tuple containing the", "tokens": [527, 4002, 2375, 1412, 992, 11247, 257, 2604, 781, 19273, 264], "temperature": 0.0, "avg_logprob": -0.23469171524047852, "compression_ratio": 1.9580838323353293, "no_speech_prob": 5.5943023653526325e-06}, {"id": 213, "seek": 101512, "start": 1022.36, "end": 1029.32, "text": " Bounding box coordinates in the classes so we can destructure that use destructuring assignment to grab the bounding boxes and", "tokens": [363, 24625, 2424, 21056, 294, 264, 5359, 370, 321, 393, 2677, 2885, 300, 764, 2677, 1757, 1345, 15187, 281, 4444, 264, 5472, 278, 9002, 293], "temperature": 0.0, "avg_logprob": -0.23469171524047852, "compression_ratio": 1.9580838323353293, "no_speech_prob": 5.5943023653526325e-06}, {"id": 214, "seek": 101512, "start": 1029.68, "end": 1032.08, "text": " the classes of the target", "tokens": [264, 5359, 295, 264, 3779], "temperature": 0.0, "avg_logprob": -0.23469171524047852, "compression_ratio": 1.9580838323353293, "no_speech_prob": 5.5943023653526325e-06}, {"id": 215, "seek": 101512, "start": 1032.64, "end": 1034.64, "text": " okay, and then the", "tokens": [1392, 11, 293, 550, 264], "temperature": 0.0, "avg_logprob": -0.23469171524047852, "compression_ratio": 1.9580838323353293, "no_speech_prob": 5.5943023653526325e-06}, {"id": 216, "seek": 101512, "start": 1035.36, "end": 1039.2, "text": " bounding boxes and the classes of the input are simply the", "tokens": [5472, 278, 9002, 293, 264, 5359, 295, 264, 4846, 366, 2935, 264], "temperature": 0.0, "avg_logprob": -0.23469171524047852, "compression_ratio": 1.9580838323353293, "no_speech_prob": 5.5943023653526325e-06}, {"id": 217, "seek": 101512, "start": 1039.92, "end": 1043.48, "text": " first four elements of the input and the", "tokens": [700, 1451, 4959, 295, 264, 4846, 293, 264], "temperature": 0.0, "avg_logprob": -0.23469171524047852, "compression_ratio": 1.9580838323353293, "no_speech_prob": 5.5943023653526325e-06}, {"id": 218, "seek": 104348, "start": 1043.48, "end": 1048.32, "text": " 24 onwards elements of the input and remember we've also got a batch", "tokens": [4022, 34230, 4959, 295, 264, 4846, 293, 1604, 321, 600, 611, 658, 257, 15245], "temperature": 0.0, "avg_logprob": -0.2186718158893757, "compression_ratio": 1.6932773109243697, "no_speech_prob": 4.4254620661376975e-06}, {"id": 219, "seek": 104348, "start": 1049.3600000000001, "end": 1053.52, "text": " Dimension that we need to grab the whole thing. Okay, so that's it. We've now got the", "tokens": [20975, 3378, 300, 321, 643, 281, 4444, 264, 1379, 551, 13, 1033, 11, 370, 300, 311, 309, 13, 492, 600, 586, 658, 264], "temperature": 0.0, "avg_logprob": -0.2186718158893757, "compression_ratio": 1.6932773109243697, "no_speech_prob": 4.4254620661376975e-06}, {"id": 220, "seek": 104348, "start": 1054.1200000000001, "end": 1057.96, "text": " bounding box target bounding box input class target class input", "tokens": [5472, 278, 2424, 3779, 5472, 278, 2424, 4846, 1508, 3779, 1508, 4846], "temperature": 0.0, "avg_logprob": -0.2186718158893757, "compression_ratio": 1.6932773109243697, "no_speech_prob": 4.4254620661376975e-06}, {"id": 221, "seek": 104348, "start": 1058.8, "end": 1065.54, "text": " For the bounding boxes, we know that they're going to be between 0 and 2 2 4 the coordinates because that's how big our image is", "tokens": [1171, 264, 5472, 278, 9002, 11, 321, 458, 300, 436, 434, 516, 281, 312, 1296, 1958, 293, 568, 568, 1017, 264, 21056, 570, 300, 311, 577, 955, 527, 3256, 307], "temperature": 0.0, "avg_logprob": -0.2186718158893757, "compression_ratio": 1.6932773109243697, "no_speech_prob": 4.4254620661376975e-06}, {"id": 222, "seek": 104348, "start": 1065.72, "end": 1067.32, "text": " right, so", "tokens": [558, 11, 370], "temperature": 0.0, "avg_logprob": -0.2186718158893757, "compression_ratio": 1.6932773109243697, "no_speech_prob": 4.4254620661376975e-06}, {"id": 223, "seek": 104348, "start": 1067.32, "end": 1069.32, "text": " Let's grab a sigmoid", "tokens": [961, 311, 4444, 257, 4556, 3280, 327], "temperature": 0.0, "avg_logprob": -0.2186718158893757, "compression_ratio": 1.6932773109243697, "no_speech_prob": 4.4254620661376975e-06}, {"id": 224, "seek": 104348, "start": 1069.68, "end": 1071.68, "text": " force it between 0 and 1", "tokens": [3464, 309, 1296, 1958, 293, 502], "temperature": 0.0, "avg_logprob": -0.2186718158893757, "compression_ratio": 1.6932773109243697, "no_speech_prob": 4.4254620661376975e-06}, {"id": 225, "seek": 107168, "start": 1071.68, "end": 1075.16, "text": " multiply it by 2 2 4 and that's just helping our", "tokens": [12972, 309, 538, 568, 568, 1017, 293, 300, 311, 445, 4315, 527], "temperature": 0.0, "avg_logprob": -0.28641266292995876, "compression_ratio": 1.5707070707070707, "no_speech_prob": 5.68236100662034e-06}, {"id": 226, "seek": 107168, "start": 1076.4, "end": 1081.3200000000002, "text": " Neural net, you know get close to what we you know be in the range. We know it has to be", "tokens": [1734, 1807, 2533, 11, 291, 458, 483, 1998, 281, 437, 321, 291, 458, 312, 294, 264, 3613, 13, 492, 458, 309, 575, 281, 312], "temperature": 0.0, "avg_logprob": -0.28641266292995876, "compression_ratio": 1.5707070707070707, "no_speech_prob": 5.68236100662034e-06}, {"id": 227, "seek": 107168, "start": 1082.1200000000001, "end": 1086.64, "text": " As a general rule, is it better to put batch norm before or after a value?", "tokens": [1018, 257, 2674, 4978, 11, 307, 309, 1101, 281, 829, 15245, 2026, 949, 420, 934, 257, 2158, 30], "temperature": 0.0, "avg_logprob": -0.28641266292995876, "compression_ratio": 1.5707070707070707, "no_speech_prob": 5.68236100662034e-06}, {"id": 228, "seek": 107168, "start": 1089.2, "end": 1090.88, "text": " I", "tokens": [286], "temperature": 0.0, "avg_logprob": -0.28641266292995876, "compression_ratio": 1.5707070707070707, "no_speech_prob": 5.68236100662034e-06}, {"id": 229, "seek": 107168, "start": 1090.88, "end": 1093.0800000000002, "text": " Would suggest that you should put it", "tokens": [6068, 3402, 300, 291, 820, 829, 309], "temperature": 0.0, "avg_logprob": -0.28641266292995876, "compression_ratio": 1.5707070707070707, "no_speech_prob": 5.68236100662034e-06}, {"id": 230, "seek": 107168, "start": 1094.4, "end": 1098.16, "text": " after a value because batch norm is meant to", "tokens": [934, 257, 2158, 570, 15245, 2026, 307, 4140, 281], "temperature": 0.0, "avg_logprob": -0.28641266292995876, "compression_ratio": 1.5707070707070707, "no_speech_prob": 5.68236100662034e-06}, {"id": 231, "seek": 107168, "start": 1098.96, "end": 1100.76, "text": " move towards a", "tokens": [1286, 3030, 257], "temperature": 0.0, "avg_logprob": -0.28641266292995876, "compression_ratio": 1.5707070707070707, "no_speech_prob": 5.68236100662034e-06}, {"id": 232, "seek": 110076, "start": 1100.76, "end": 1102.76, "text": " 0 and 1 random variable", "tokens": [1958, 293, 502, 4974, 7006], "temperature": 0.0, "avg_logprob": -0.3134259353449315, "compression_ratio": 1.528497409326425, "no_speech_prob": 9.818198122957256e-06}, {"id": 233, "seek": 110076, "start": 1103.44, "end": 1107.96, "text": " And if you put value after it, then you're trying getting it at 0", "tokens": [400, 498, 291, 829, 2158, 934, 309, 11, 550, 291, 434, 1382, 1242, 309, 412, 1958], "temperature": 0.0, "avg_logprob": -0.3134259353449315, "compression_ratio": 1.528497409326425, "no_speech_prob": 9.818198122957256e-06}, {"id": 234, "seek": 110076, "start": 1110.12, "end": 1113.9, "text": " So there's no way to create negative numbers, but if you put", "tokens": [407, 456, 311, 572, 636, 281, 1884, 3671, 3547, 11, 457, 498, 291, 829], "temperature": 0.0, "avg_logprob": -0.3134259353449315, "compression_ratio": 1.528497409326425, "no_speech_prob": 9.818198122957256e-06}, {"id": 235, "seek": 110076, "start": 1115.8, "end": 1119.8, "text": " Rally you and then that's normal. It does have that ability", "tokens": [497, 379, 291, 293, 550, 300, 311, 2710, 13, 467, 775, 362, 300, 3485], "temperature": 0.0, "avg_logprob": -0.3134259353449315, "compression_ratio": 1.528497409326425, "no_speech_prob": 9.818198122957256e-06}, {"id": 236, "seek": 110076, "start": 1121.12, "end": 1123.12, "text": " Having said that", "tokens": [10222, 848, 300], "temperature": 0.0, "avg_logprob": -0.3134259353449315, "compression_ratio": 1.528497409326425, "no_speech_prob": 9.818198122957256e-06}, {"id": 237, "seek": 110076, "start": 1123.12, "end": 1125.44, "text": " And I think that that way of doing it gives", "tokens": [400, 286, 519, 300, 300, 636, 295, 884, 309, 2709], "temperature": 0.0, "avg_logprob": -0.3134259353449315, "compression_ratio": 1.528497409326425, "no_speech_prob": 9.818198122957256e-06}, {"id": 238, "seek": 110076, "start": 1126.8799999999999, "end": 1128.8799999999999, "text": " slightly better results", "tokens": [4748, 1101, 3542], "temperature": 0.0, "avg_logprob": -0.3134259353449315, "compression_ratio": 1.528497409326425, "no_speech_prob": 9.818198122957256e-06}, {"id": 239, "seek": 112888, "start": 1128.88, "end": 1130.88, "text": " having said that it's", "tokens": [1419, 848, 300, 309, 311], "temperature": 0.0, "avg_logprob": -0.3040294647216797, "compression_ratio": 1.6586345381526104, "no_speech_prob": 1.0952987395285163e-05}, {"id": 240, "seek": 112888, "start": 1131.2, "end": 1137.88, "text": " Not too big a deal either way and you'll see during this part of the course most of the time I go", "tokens": [1726, 886, 955, 257, 2028, 2139, 636, 293, 291, 603, 536, 1830, 341, 644, 295, 264, 1164, 881, 295, 264, 565, 286, 352], "temperature": 0.0, "avg_logprob": -0.3040294647216797, "compression_ratio": 1.6586345381526104, "no_speech_prob": 1.0952987395285163e-05}, {"id": 241, "seek": 112888, "start": 1138.7600000000002, "end": 1143.2, "text": " Rally you and then that's norm, but sometimes I go back to norm and then value", "tokens": [497, 379, 291, 293, 550, 300, 311, 2026, 11, 457, 2171, 286, 352, 646, 281, 2026, 293, 550, 2158], "temperature": 0.0, "avg_logprob": -0.3040294647216797, "compression_ratio": 1.6586345381526104, "no_speech_prob": 1.0952987395285163e-05}, {"id": 242, "seek": 112888, "start": 1143.2, "end": 1146.5200000000002, "text": " If I'm trying to like be consistent with a paper or something like that", "tokens": [759, 286, 478, 1382, 281, 411, 312, 8398, 365, 257, 3035, 420, 746, 411, 300], "temperature": 0.0, "avg_logprob": -0.3040294647216797, "compression_ratio": 1.6586345381526104, "no_speech_prob": 1.0952987395285163e-05}, {"id": 243, "seek": 112888, "start": 1146.5200000000002, "end": 1151.6200000000001, "text": " So I think originally the batch normal is put it after the activation. So there's still people to do that", "tokens": [407, 286, 519, 7993, 264, 15245, 2710, 307, 829, 309, 934, 264, 24433, 13, 407, 456, 311, 920, 561, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.3040294647216797, "compression_ratio": 1.6586345381526104, "no_speech_prob": 1.0952987395285163e-05}, {"id": 244, "seek": 112888, "start": 1152.88, "end": 1156.0, "text": " Okay, so this is kind of to help our", "tokens": [1033, 11, 370, 341, 307, 733, 295, 281, 854, 527], "temperature": 0.0, "avg_logprob": -0.3040294647216797, "compression_ratio": 1.6586345381526104, "no_speech_prob": 1.0952987395285163e-05}, {"id": 245, "seek": 115600, "start": 1156.0, "end": 1158.0, "text": " data", "tokens": [1412], "temperature": 0.0, "avg_logprob": -0.3067301717297784, "compression_ratio": 1.5962962962962963, "no_speech_prob": 1.241119116457412e-05}, {"id": 246, "seek": 115600, "start": 1158.0, "end": 1161.72, "text": " Or force our data into the right range, which you know if you can do stuff like that", "tokens": [1610, 3464, 527, 1412, 666, 264, 558, 3613, 11, 597, 291, 458, 498, 291, 393, 360, 1507, 411, 300], "temperature": 0.0, "avg_logprob": -0.3067301717297784, "compression_ratio": 1.5962962962962963, "no_speech_prob": 1.241119116457412e-05}, {"id": 247, "seek": 115600, "start": 1161.72, "end": 1164.28, "text": " It makes it easier to train. Yes, Rachel one more question", "tokens": [467, 1669, 309, 3571, 281, 3847, 13, 1079, 11, 14246, 472, 544, 1168], "temperature": 0.0, "avg_logprob": -0.3067301717297784, "compression_ratio": 1.5962962962962963, "no_speech_prob": 1.241119116457412e-05}, {"id": 248, "seek": 115600, "start": 1164.32, "end": 1170.12, "text": " What's the intuition behind using dropout with P equals 0.5 after a batch norm?", "tokens": [708, 311, 264, 24002, 2261, 1228, 3270, 346, 365, 430, 6915, 1958, 13, 20, 934, 257, 15245, 2026, 30], "temperature": 0.0, "avg_logprob": -0.3067301717297784, "compression_ratio": 1.5962962962962963, "no_speech_prob": 1.241119116457412e-05}, {"id": 249, "seek": 115600, "start": 1170.4, "end": 1173.6, "text": " Doesn't batch norm already do a good job of regularizing?", "tokens": [12955, 380, 15245, 2026, 1217, 360, 257, 665, 1691, 295, 3890, 3319, 30], "temperature": 0.0, "avg_logprob": -0.3067301717297784, "compression_ratio": 1.5962962962962963, "no_speech_prob": 1.241119116457412e-05}, {"id": 250, "seek": 115600, "start": 1175.76, "end": 1177.76, "text": " That's not doesn't okay job of regularizing", "tokens": [663, 311, 406, 1177, 380, 1392, 1691, 295, 3890, 3319], "temperature": 0.0, "avg_logprob": -0.3067301717297784, "compression_ratio": 1.5962962962962963, "no_speech_prob": 1.241119116457412e-05}, {"id": 251, "seek": 115600, "start": 1178.2, "end": 1183.12, "text": " but if you think back to part one, we kind of had that list of things we do to avoid overfitting and", "tokens": [457, 498, 291, 519, 646, 281, 644, 472, 11, 321, 733, 295, 632, 300, 1329, 295, 721, 321, 360, 281, 5042, 670, 69, 2414, 293], "temperature": 0.0, "avg_logprob": -0.3067301717297784, "compression_ratio": 1.5962962962962963, "no_speech_prob": 1.241119116457412e-05}, {"id": 252, "seek": 118312, "start": 1183.12, "end": 1187.04, "text": " adding batch norm is one of them as is data augmentation, but it's", "tokens": [5127, 15245, 2026, 307, 472, 295, 552, 382, 307, 1412, 14501, 19631, 11, 457, 309, 311], "temperature": 0.0, "avg_logprob": -0.3664975259818283, "compression_ratio": 1.7829787234042553, "no_speech_prob": 1.165932189906016e-05}, {"id": 253, "seek": 118312, "start": 1189.76, "end": 1192.1599999999999, "text": " Perfectly possible that you'll still be able to be", "tokens": [10246, 356, 1944, 300, 291, 603, 920, 312, 1075, 281, 312], "temperature": 0.0, "avg_logprob": -0.3664975259818283, "compression_ratio": 1.7829787234042553, "no_speech_prob": 1.165932189906016e-05}, {"id": 254, "seek": 118312, "start": 1192.9199999999998, "end": 1196.9199999999998, "text": " So one nice thing about dropout is that it has a parameter to say", "tokens": [407, 472, 1481, 551, 466, 3270, 346, 307, 300, 309, 575, 257, 13075, 281, 584], "temperature": 0.0, "avg_logprob": -0.3664975259818283, "compression_ratio": 1.7829787234042553, "no_speech_prob": 1.165932189906016e-05}, {"id": 255, "seek": 118312, "start": 1197.3999999999999, "end": 1204.28, "text": " How much to drop out and so that like parameters are great like or specifically parameters that decide how much to regularize?", "tokens": [1012, 709, 281, 3270, 484, 293, 370, 300, 411, 9834, 366, 869, 411, 420, 4682, 9834, 300, 4536, 577, 709, 281, 3890, 1125, 30], "temperature": 0.0, "avg_logprob": -0.3664975259818283, "compression_ratio": 1.7829787234042553, "no_speech_prob": 1.165932189906016e-05}, {"id": 256, "seek": 118312, "start": 1204.84, "end": 1211.1999999999998, "text": " Great because it lets you build a nice big overparameterized model and then decide how much to regularize it", "tokens": [3769, 570, 309, 6653, 291, 1322, 257, 1481, 955, 670, 2181, 335, 2398, 1602, 2316, 293, 550, 4536, 577, 709, 281, 3890, 1125, 309], "temperature": 0.0, "avg_logprob": -0.3664975259818283, "compression_ratio": 1.7829787234042553, "no_speech_prob": 1.165932189906016e-05}, {"id": 257, "seek": 121120, "start": 1211.2, "end": 1213.2, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.29179065667309806, "compression_ratio": 1.6, "no_speech_prob": 1.406374758516904e-05}, {"id": 258, "seek": 121120, "start": 1213.48, "end": 1217.2, "text": " Yeah, I tend to always include dropout and then if it turns out I", "tokens": [865, 11, 286, 3928, 281, 1009, 4090, 3270, 346, 293, 550, 498, 309, 4523, 484, 286], "temperature": 0.0, "avg_logprob": -0.29179065667309806, "compression_ratio": 1.6, "no_speech_prob": 1.406374758516904e-05}, {"id": 259, "seek": 121120, "start": 1218.16, "end": 1220.16, "text": " You know I'll start with", "tokens": [509, 458, 286, 603, 722, 365], "temperature": 0.0, "avg_logprob": -0.29179065667309806, "compression_ratio": 1.6, "no_speech_prob": 1.406374758516904e-05}, {"id": 260, "seek": 121120, "start": 1220.16, "end": 1225.44, "text": " P equals 0 and then as I add need to add regularization. I can just change my dropout parameter", "tokens": [430, 6915, 1958, 293, 550, 382, 286, 909, 643, 281, 909, 3890, 2144, 13, 286, 393, 445, 1319, 452, 3270, 346, 13075], "temperature": 0.0, "avg_logprob": -0.29179065667309806, "compression_ratio": 1.6, "no_speech_prob": 1.406374758516904e-05}, {"id": 261, "seek": 121120, "start": 1226.8400000000001, "end": 1230.0800000000002, "text": " Without worrying about you know if I saved a model", "tokens": [9129, 18788, 466, 291, 458, 498, 286, 6624, 257, 2316], "temperature": 0.0, "avg_logprob": -0.29179065667309806, "compression_ratio": 1.6, "no_speech_prob": 1.406374758516904e-05}, {"id": 262, "seek": 121120, "start": 1230.0800000000002, "end": 1231.8, "text": " I want to be able to load it back", "tokens": [286, 528, 281, 312, 1075, 281, 3677, 309, 646], "temperature": 0.0, "avg_logprob": -0.29179065667309806, "compression_ratio": 1.6, "no_speech_prob": 1.406374758516904e-05}, {"id": 263, "seek": 121120, "start": 1231.8, "end": 1238.2, "text": " But if I had dropout layers in one and not in another or load me more so this way it stays consistent", "tokens": [583, 498, 286, 632, 3270, 346, 7914, 294, 472, 293, 406, 294, 1071, 420, 3677, 385, 544, 370, 341, 636, 309, 10834, 8398], "temperature": 0.0, "avg_logprob": -0.29179065667309806, "compression_ratio": 1.6, "no_speech_prob": 1.406374758516904e-05}, {"id": 264, "seek": 123820, "start": 1238.2, "end": 1240.2, "text": " Okay, so now that I've got my", "tokens": [1033, 11, 370, 586, 300, 286, 600, 658, 452], "temperature": 0.0, "avg_logprob": -0.36701094988480354, "compression_ratio": 1.6853448275862069, "no_speech_prob": 1.963795057235984e-06}, {"id": 265, "seek": 123820, "start": 1240.64, "end": 1245.96, "text": " Inputs and targets I can just go hey calculate the L1 loss and add to it the cross entropy", "tokens": [682, 2582, 82, 293, 12911, 286, 393, 445, 352, 4177, 8873, 264, 441, 16, 4470, 293, 909, 281, 309, 264, 3278, 30867], "temperature": 0.0, "avg_logprob": -0.36701094988480354, "compression_ratio": 1.6853448275862069, "no_speech_prob": 1.963795057235984e-06}, {"id": 266, "seek": 123820, "start": 1247.04, "end": 1249.04, "text": " All right, so that's our", "tokens": [1057, 558, 11, 370, 300, 311, 527], "temperature": 0.0, "avg_logprob": -0.36701094988480354, "compression_ratio": 1.6853448275862069, "no_speech_prob": 1.963795057235984e-06}, {"id": 267, "seek": 123820, "start": 1249.04, "end": 1251.04, "text": " That's our loss function", "tokens": [663, 311, 527, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.36701094988480354, "compression_ratio": 1.6853448275862069, "no_speech_prob": 1.963795057235984e-06}, {"id": 268, "seek": 123820, "start": 1251.04, "end": 1258.2, "text": " It's surprisingly easy perhaps now of course the cross entropy and the L1 loss may be of wildly different scales", "tokens": [467, 311, 17600, 1858, 4317, 586, 295, 1164, 264, 3278, 30867, 293, 264, 441, 16, 4470, 815, 312, 295, 34731, 819, 17408], "temperature": 0.0, "avg_logprob": -0.36701094988480354, "compression_ratio": 1.6853448275862069, "no_speech_prob": 1.963795057235984e-06}, {"id": 269, "seek": 123820, "start": 1258.44, "end": 1265.88, "text": " In which case in the loss function the larger one is going to dominate and so I just ran this in a debugger", "tokens": [682, 597, 1389, 294, 264, 4470, 2445, 264, 4833, 472, 307, 516, 281, 28246, 293, 370, 286, 445, 5872, 341, 294, 257, 24083, 1321], "temperature": 0.0, "avg_logprob": -0.36701094988480354, "compression_ratio": 1.6853448275862069, "no_speech_prob": 1.963795057235984e-06}, {"id": 270, "seek": 126588, "start": 1265.88, "end": 1267.88, "text": " in a debugger", "tokens": [294, 257, 24083, 1321], "temperature": 0.0, "avg_logprob": -0.2326289126747533, "compression_ratio": 1.600896860986547, "no_speech_prob": 6.643340839218581e-06}, {"id": 271, "seek": 126588, "start": 1267.96, "end": 1274.5400000000002, "text": " Checked what you know you could just use print check how big each of the two things were and found if I multiply by 20", "tokens": [6881, 292, 437, 291, 458, 291, 727, 445, 764, 4482, 1520, 577, 955, 1184, 295, 264, 732, 721, 645, 293, 1352, 498, 286, 12972, 538, 945], "temperature": 0.0, "avg_logprob": -0.2326289126747533, "compression_ratio": 1.600896860986547, "no_speech_prob": 6.643340839218581e-06}, {"id": 272, "seek": 126588, "start": 1274.5400000000002, "end": 1276.5400000000002, "text": " That makes them about the same", "tokens": [663, 1669, 552, 466, 264, 912], "temperature": 0.0, "avg_logprob": -0.2326289126747533, "compression_ratio": 1.600896860986547, "no_speech_prob": 6.643340839218581e-06}, {"id": 273, "seek": 126588, "start": 1276.8000000000002, "end": 1278.8000000000002, "text": " About the same scale", "tokens": [7769, 264, 912, 4373], "temperature": 0.0, "avg_logprob": -0.2326289126747533, "compression_ratio": 1.600896860986547, "no_speech_prob": 6.643340839218581e-06}, {"id": 274, "seek": 126588, "start": 1281.24, "end": 1285.64, "text": " As your training it's nice to print out information as you go", "tokens": [1018, 428, 3097, 309, 311, 1481, 281, 4482, 484, 1589, 382, 291, 352], "temperature": 0.0, "avg_logprob": -0.2326289126747533, "compression_ratio": 1.600896860986547, "no_speech_prob": 6.643340839218581e-06}, {"id": 275, "seek": 126588, "start": 1286.44, "end": 1288.44, "text": " so I also grabbed the", "tokens": [370, 286, 611, 18607, 264], "temperature": 0.0, "avg_logprob": -0.2326289126747533, "compression_ratio": 1.600896860986547, "no_speech_prob": 6.643340839218581e-06}, {"id": 276, "seek": 126588, "start": 1289.2800000000002, "end": 1294.64, "text": " L1 part of this and put it in a in a function and I also created a function for accuracy", "tokens": [441, 16, 644, 295, 341, 293, 829, 309, 294, 257, 294, 257, 2445, 293, 286, 611, 2942, 257, 2445, 337, 14170], "temperature": 0.0, "avg_logprob": -0.2326289126747533, "compression_ratio": 1.600896860986547, "no_speech_prob": 6.643340839218581e-06}, {"id": 277, "seek": 129464, "start": 1294.64, "end": 1298.88, "text": " So that I could then make their metrics and so that printed out", "tokens": [407, 300, 286, 727, 550, 652, 641, 16367, 293, 370, 300, 13567, 484], "temperature": 0.0, "avg_logprob": -0.280610598050631, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.443985522404546e-06}, {"id": 278, "seek": 129464, "start": 1299.76, "end": 1304.0800000000002, "text": " Alright, so we've now got something which is printing out our object detection loss", "tokens": [2798, 11, 370, 321, 600, 586, 658, 746, 597, 307, 14699, 484, 527, 2657, 17784, 4470], "temperature": 0.0, "avg_logprob": -0.280610598050631, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.443985522404546e-06}, {"id": 279, "seek": 129464, "start": 1304.64, "end": 1307.16, "text": " detection accuracy and detection L1", "tokens": [17784, 14170, 293, 17784, 441, 16], "temperature": 0.0, "avg_logprob": -0.280610598050631, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.443985522404546e-06}, {"id": 280, "seek": 129464, "start": 1308.48, "end": 1311.0, "text": " And so we train it for a while", "tokens": [400, 370, 321, 3847, 309, 337, 257, 1339], "temperature": 0.0, "avg_logprob": -0.280610598050631, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.443985522404546e-06}, {"id": 281, "seek": 129464, "start": 1312.0, "end": 1316.68, "text": " And it's looking good our detection accuracy is in the low 80s", "tokens": [400, 309, 311, 1237, 665, 527, 17784, 14170, 307, 294, 264, 2295, 4688, 82], "temperature": 0.0, "avg_logprob": -0.280610598050631, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.443985522404546e-06}, {"id": 282, "seek": 129464, "start": 1317.3200000000002, "end": 1323.3200000000002, "text": " Which is the same as what it was before that doesn't surprise me because like resnet was designed", "tokens": [3013, 307, 264, 912, 382, 437, 309, 390, 949, 300, 1177, 380, 6365, 385, 570, 411, 725, 7129, 390, 4761], "temperature": 0.0, "avg_logprob": -0.280610598050631, "compression_ratio": 1.6666666666666667, "no_speech_prob": 2.443985522404546e-06}, {"id": 283, "seek": 132332, "start": 1323.32, "end": 1328.24, "text": " to do classification, so I wouldn't expect us to be able to", "tokens": [281, 360, 21538, 11, 370, 286, 2759, 380, 2066, 505, 281, 312, 1075, 281], "temperature": 0.0, "avg_logprob": -0.2488973451697308, "compression_ratio": 1.651063829787234, "no_speech_prob": 1.3419707102002576e-05}, {"id": 284, "seek": 132332, "start": 1329.36, "end": 1331.6799999999998, "text": " Improve things in such a simple way", "tokens": [46366, 721, 294, 1270, 257, 2199, 636], "temperature": 0.0, "avg_logprob": -0.2488973451697308, "compression_ratio": 1.651063829787234, "no_speech_prob": 1.3419707102002576e-05}, {"id": 285, "seek": 132332, "start": 1332.28, "end": 1335.24, "text": " But it certainly wasn't designed to do bounding box regression", "tokens": [583, 309, 3297, 2067, 380, 4761, 281, 360, 5472, 278, 2424, 24590], "temperature": 0.0, "avg_logprob": -0.2488973451697308, "compression_ratio": 1.651063829787234, "no_speech_prob": 1.3419707102002576e-05}, {"id": 286, "seek": 132332, "start": 1335.24, "end": 1341.24, "text": " It was explicitly actually designed in such a way as to be as to kind of not care about geometry", "tokens": [467, 390, 20803, 767, 4761, 294, 1270, 257, 636, 382, 281, 312, 382, 281, 733, 295, 406, 1127, 466, 18426], "temperature": 0.0, "avg_logprob": -0.2488973451697308, "compression_ratio": 1.651063829787234, "no_speech_prob": 1.3419707102002576e-05}, {"id": 287, "seek": 132332, "start": 1341.24, "end": 1346.4399999999998, "text": " Right, it takes that last seven by seven grid of activations and averages them all together", "tokens": [1779, 11, 309, 2516, 300, 1036, 3407, 538, 3407, 10748, 295, 2430, 763, 293, 42257, 552, 439, 1214], "temperature": 0.0, "avg_logprob": -0.2488973451697308, "compression_ratio": 1.651063829787234, "no_speech_prob": 1.3419707102002576e-05}, {"id": 288, "seek": 132332, "start": 1347.1599999999999, "end": 1349.1599999999999, "text": " throws away all of the information about", "tokens": [19251, 1314, 439, 295, 264, 1589, 466], "temperature": 0.0, "avg_logprob": -0.2488973451697308, "compression_ratio": 1.651063829787234, "no_speech_prob": 1.3419707102002576e-05}, {"id": 289, "seek": 134916, "start": 1349.16, "end": 1352.96, "text": " So so you can see that the", "tokens": [407, 370, 291, 393, 536, 300, 264], "temperature": 0.0, "avg_logprob": -0.29197493563877064, "compression_ratio": 1.5601851851851851, "no_speech_prob": 4.495139364735223e-06}, {"id": 290, "seek": 134916, "start": 1354.2, "end": 1357.5, "text": " When we only train the last layer the detection L1", "tokens": [1133, 321, 787, 3847, 264, 1036, 4583, 264, 17784, 441, 16], "temperature": 0.0, "avg_logprob": -0.29197493563877064, "compression_ratio": 1.5601851851851851, "no_speech_prob": 4.495139364735223e-06}, {"id": 291, "seek": 134916, "start": 1358.16, "end": 1364.0, "text": " Is is pretty bad 24 and it really improves a lot right where else the accuracy?", "tokens": [1119, 307, 1238, 1578, 4022, 293, 309, 534, 24771, 257, 688, 558, 689, 1646, 264, 14170, 30], "temperature": 0.0, "avg_logprob": -0.29197493563877064, "compression_ratio": 1.5601851851851851, "no_speech_prob": 4.495139364735223e-06}, {"id": 292, "seek": 134916, "start": 1364.72, "end": 1366.72, "text": " Doesn't improve this is exactly the same", "tokens": [12955, 380, 3470, 341, 307, 2293, 264, 912], "temperature": 0.0, "avg_logprob": -0.29197493563877064, "compression_ratio": 1.5601851851851851, "no_speech_prob": 4.495139364735223e-06}, {"id": 293, "seek": 134916, "start": 1367.28, "end": 1373.4, "text": " Interestingly the L1 when we do accuracy and bounding box at the same time at 8.5", "tokens": [30564, 264, 441, 16, 562, 321, 360, 14170, 293, 5472, 278, 2424, 412, 264, 912, 565, 412, 1649, 13, 20], "temperature": 0.0, "avg_logprob": -0.29197493563877064, "compression_ratio": 1.5601851851851851, "no_speech_prob": 4.495139364735223e-06}, {"id": 294, "seek": 137340, "start": 1373.4, "end": 1378.52, "text": " Seems like it's a little bit better than when we just do", "tokens": [22524, 411, 309, 311, 257, 707, 857, 1101, 813, 562, 321, 445, 360], "temperature": 0.0, "avg_logprob": -0.19622570635324502, "compression_ratio": 1.631578947368421, "no_speech_prob": 9.818192665989045e-06}, {"id": 295, "seek": 137340, "start": 1379.0400000000002, "end": 1381.0400000000002, "text": " bounding box regression and", "tokens": [5472, 278, 2424, 24590, 293], "temperature": 0.0, "avg_logprob": -0.19622570635324502, "compression_ratio": 1.631578947368421, "no_speech_prob": 9.818192665989045e-06}, {"id": 296, "seek": 137340, "start": 1381.2, "end": 1386.24, "text": " If that's counterintuitive to you then that's would be one of the main things to think about after this lesson", "tokens": [759, 300, 311, 5682, 686, 48314, 281, 291, 550, 300, 311, 576, 312, 472, 295, 264, 2135, 721, 281, 519, 466, 934, 341, 6898], "temperature": 0.0, "avg_logprob": -0.19622570635324502, "compression_ratio": 1.631578947368421, "no_speech_prob": 9.818192665989045e-06}, {"id": 297, "seek": 137340, "start": 1386.24, "end": 1388.96, "text": " So it's a really important idea and the idea is this", "tokens": [407, 309, 311, 257, 534, 1021, 1558, 293, 264, 1558, 307, 341], "temperature": 0.0, "avg_logprob": -0.19622570635324502, "compression_ratio": 1.631578947368421, "no_speech_prob": 9.818192665989045e-06}, {"id": 298, "seek": 137340, "start": 1392.1200000000001, "end": 1394.1200000000001, "text": " Figuring out", "tokens": [22443, 1345, 484], "temperature": 0.0, "avg_logprob": -0.19622570635324502, "compression_ratio": 1.631578947368421, "no_speech_prob": 9.818192665989045e-06}, {"id": 299, "seek": 137340, "start": 1397.72, "end": 1399.72, "text": " Figuring out", "tokens": [22443, 1345, 484], "temperature": 0.0, "avg_logprob": -0.19622570635324502, "compression_ratio": 1.631578947368421, "no_speech_prob": 9.818192665989045e-06}, {"id": 300, "seek": 139972, "start": 1399.72, "end": 1407.4, "text": " What the main object in an image is is kind of the hard part and then figuring out by", "tokens": [708, 264, 2135, 2657, 294, 364, 3256, 307, 307, 733, 295, 264, 1152, 644, 293, 550, 15213, 484, 538], "temperature": 0.0, "avg_logprob": -0.23263749209317294, "compression_ratio": 1.671497584541063, "no_speech_prob": 1.2029206118313596e-05}, {"id": 301, "seek": 139972, "start": 1408.1200000000001, "end": 1413.76, "text": " Exactly where the bounding box is and what class it is is kind of the easy part in a way", "tokens": [7587, 689, 264, 5472, 278, 2424, 307, 293, 437, 1508, 309, 307, 307, 733, 295, 264, 1858, 644, 294, 257, 636], "temperature": 0.0, "avg_logprob": -0.23263749209317294, "compression_ratio": 1.671497584541063, "no_speech_prob": 1.2029206118313596e-05}, {"id": 302, "seek": 139972, "start": 1413.76, "end": 1416.16, "text": " And so when you've got a single", "tokens": [400, 370, 562, 291, 600, 658, 257, 2167], "temperature": 0.0, "avg_logprob": -0.23263749209317294, "compression_ratio": 1.671497584541063, "no_speech_prob": 1.2029206118313596e-05}, {"id": 303, "seek": 139972, "start": 1417.3600000000001, "end": 1421.3600000000001, "text": " Network is both saying what is the object and where is the object?", "tokens": [12640, 307, 1293, 1566, 437, 307, 264, 2657, 293, 689, 307, 264, 2657, 30], "temperature": 0.0, "avg_logprob": -0.23263749209317294, "compression_ratio": 1.671497584541063, "no_speech_prob": 1.2029206118313596e-05}, {"id": 304, "seek": 139972, "start": 1421.8, "end": 1426.48, "text": " It's going to share all of the computation about like finding the object", "tokens": [467, 311, 516, 281, 2073, 439, 295, 264, 24903, 466, 411, 5006, 264, 2657], "temperature": 0.0, "avg_logprob": -0.23263749209317294, "compression_ratio": 1.671497584541063, "no_speech_prob": 1.2029206118313596e-05}, {"id": 305, "seek": 142648, "start": 1426.48, "end": 1432.8600000000001, "text": " Okay, and so all that shared information over that shared computation is very efficient", "tokens": [1033, 11, 293, 370, 439, 300, 5507, 1589, 670, 300, 5507, 24903, 307, 588, 7148], "temperature": 0.0, "avg_logprob": -0.19169301665231084, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.373648360138759e-05}, {"id": 306, "seek": 142648, "start": 1432.8600000000001, "end": 1435.68, "text": " And so when we back propagate the errors in", "tokens": [400, 370, 562, 321, 646, 48256, 264, 13603, 294], "temperature": 0.0, "avg_logprob": -0.19169301665231084, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.373648360138759e-05}, {"id": 307, "seek": 142648, "start": 1436.64, "end": 1439.52, "text": " You know the class and in the place", "tokens": [509, 458, 264, 1508, 293, 294, 264, 1081], "temperature": 0.0, "avg_logprob": -0.19169301665231084, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.373648360138759e-05}, {"id": 308, "seek": 142648, "start": 1440.04, "end": 1447.16, "text": " That's all information that's going to help the computation around like finding the biggest object. So anytime you've got multiple", "tokens": [663, 311, 439, 1589, 300, 311, 516, 281, 854, 264, 24903, 926, 411, 5006, 264, 3880, 2657, 13, 407, 13038, 291, 600, 658, 3866], "temperature": 0.0, "avg_logprob": -0.19169301665231084, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.373648360138759e-05}, {"id": 309, "seek": 142648, "start": 1448.56, "end": 1455.48, "text": " Tasks which kind of share some some concept of what those tasks would need to do to complete their work", "tokens": [27293, 1694, 597, 733, 295, 2073, 512, 512, 3410, 295, 437, 729, 9608, 576, 643, 281, 360, 281, 3566, 641, 589], "temperature": 0.0, "avg_logprob": -0.19169301665231084, "compression_ratio": 1.6611570247933884, "no_speech_prob": 3.373648360138759e-05}, {"id": 310, "seek": 145548, "start": 1455.48, "end": 1458.28, "text": " It's very likely they should share at least some", "tokens": [467, 311, 588, 3700, 436, 820, 2073, 412, 1935, 512], "temperature": 0.0, "avg_logprob": -0.26841242901690593, "compression_ratio": 1.4871794871794872, "no_speech_prob": 1.6964171663857996e-05}, {"id": 311, "seek": 145548, "start": 1459.08, "end": 1462.2, "text": " layers of the network together and", "tokens": [7914, 295, 264, 3209, 1214, 293], "temperature": 0.0, "avg_logprob": -0.26841242901690593, "compression_ratio": 1.4871794871794872, "no_speech_prob": 1.6964171663857996e-05}, {"id": 312, "seek": 145548, "start": 1463.56, "end": 1467.3600000000001, "text": " We'll look later today at a place where", "tokens": [492, 603, 574, 1780, 965, 412, 257, 1081, 689], "temperature": 0.0, "avg_logprob": -0.26841242901690593, "compression_ratio": 1.4871794871794872, "no_speech_prob": 1.6964171663857996e-05}, {"id": 313, "seek": 145548, "start": 1469.72, "end": 1473.16, "text": " Most of the layers are shared but I've just the last one isn't", "tokens": [4534, 295, 264, 7914, 366, 5507, 457, 286, 600, 445, 264, 1036, 472, 1943, 380], "temperature": 0.0, "avg_logprob": -0.26841242901690593, "compression_ratio": 1.4871794871794872, "no_speech_prob": 1.6964171663857996e-05}, {"id": 314, "seek": 145548, "start": 1474.52, "end": 1482.72, "text": " Okay, so you can see this is doing a good job as before of any time. There's just a single major object", "tokens": [1033, 11, 370, 291, 393, 536, 341, 307, 884, 257, 665, 1691, 382, 949, 295, 604, 565, 13, 821, 311, 445, 257, 2167, 2563, 2657], "temperature": 0.0, "avg_logprob": -0.26841242901690593, "compression_ratio": 1.4871794871794872, "no_speech_prob": 1.6964171663857996e-05}, {"id": 315, "seek": 148272, "start": 1482.72, "end": 1489.4, "text": " Sometimes it's getting a little confused. It thinks the main object here is the dog and it's kind of served with the dog", "tokens": [4803, 309, 311, 1242, 257, 707, 9019, 13, 467, 7309, 264, 2135, 2657, 510, 307, 264, 3000, 293, 309, 311, 733, 295, 7584, 365, 264, 3000], "temperature": 0.0, "avg_logprob": -0.2594729862856061, "compression_ratio": 1.690909090909091, "no_speech_prob": 2.93107168545248e-05}, {"id": 316, "seek": 148272, "start": 1489.4, "end": 1495.8, "text": " Although it's kind of recognized that actually the main object is a sulfur and so the classifiers doing the right thing with the bounding boxes", "tokens": [5780, 309, 311, 733, 295, 9823, 300, 767, 264, 2135, 2657, 307, 257, 33831, 293, 370, 264, 1508, 23463, 884, 264, 558, 551, 365, 264, 5472, 278, 9002], "temperature": 0.0, "avg_logprob": -0.2594729862856061, "compression_ratio": 1.690909090909091, "no_speech_prob": 2.93107168545248e-05}, {"id": 317, "seek": 148272, "start": 1499.72, "end": 1504.1200000000001, "text": " When there are two birds, it can only pick one so it's just kind of hedging in the middle", "tokens": [1133, 456, 366, 732, 9009, 11, 309, 393, 787, 1888, 472, 370, 309, 311, 445, 733, 295, 33653, 3249, 294, 264, 2808], "temperature": 0.0, "avg_logprob": -0.2594729862856061, "compression_ratio": 1.690909090909091, "no_speech_prob": 2.93107168545248e-05}, {"id": 318, "seek": 150412, "start": 1504.12, "end": 1510.4799999999998, "text": " Did oh and there's lots of cows and so forth doing good job with this car. All right, so that's", "tokens": [2589, 1954, 293, 456, 311, 3195, 295, 19148, 293, 370, 5220, 884, 665, 1691, 365, 341, 1032, 13, 1057, 558, 11, 370, 300, 311], "temperature": 0.0, "avg_logprob": -0.2491693599249727, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.3006953849981073e-05}, {"id": 319, "seek": 150412, "start": 1514.2399999999998, "end": 1517.0, "text": " So that's that right there's there's not much", "tokens": [407, 300, 311, 300, 558, 456, 311, 456, 311, 406, 709], "temperature": 0.0, "avg_logprob": -0.2491693599249727, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.3006953849981073e-05}, {"id": 320, "seek": 150412, "start": 1517.76, "end": 1523.84, "text": " New there, although in that last bit we did learn about, you know, some simple custom data sets and simple custom lots functions", "tokens": [1873, 456, 11, 4878, 294, 300, 1036, 857, 321, 630, 1466, 466, 11, 291, 458, 11, 512, 2199, 2375, 1412, 6352, 293, 2199, 2375, 3195, 6828], "temperature": 0.0, "avg_logprob": -0.2491693599249727, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.3006953849981073e-05}, {"id": 321, "seek": 150412, "start": 1524.56, "end": 1526.84, "text": " Hopefully you can see now how easy that is to do", "tokens": [10429, 291, 393, 536, 586, 577, 1858, 300, 307, 281, 360], "temperature": 0.0, "avg_logprob": -0.2491693599249727, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.3006953849981073e-05}, {"id": 322, "seek": 150412, "start": 1529.8799999999999, "end": 1532.8, "text": " So next stage for me would be to do", "tokens": [407, 958, 3233, 337, 385, 576, 312, 281, 360], "temperature": 0.0, "avg_logprob": -0.2491693599249727, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.3006953849981073e-05}, {"id": 323, "seek": 153280, "start": 1532.8, "end": 1534.8, "text": " multi-label classification", "tokens": [4825, 12, 75, 18657, 21538], "temperature": 0.0, "avg_logprob": -0.27440789481189765, "compression_ratio": 1.7132075471698114, "no_speech_prob": 4.6837289119139314e-05}, {"id": 324, "seek": 153280, "start": 1534.8, "end": 1540.68, "text": " So this is this idea that I just want to keep building models that are slightly more complex than the last model", "tokens": [407, 341, 307, 341, 1558, 300, 286, 445, 528, 281, 1066, 2390, 5245, 300, 366, 4748, 544, 3997, 813, 264, 1036, 2316], "temperature": 0.0, "avg_logprob": -0.27440789481189765, "compression_ratio": 1.7132075471698114, "no_speech_prob": 4.6837289119139314e-05}, {"id": 325, "seek": 153280, "start": 1541.24, "end": 1542.48, "text": " but", "tokens": [457], "temperature": 0.0, "avg_logprob": -0.27440789481189765, "compression_ratio": 1.7132075471698114, "no_speech_prob": 4.6837289119139314e-05}, {"id": 326, "seek": 153280, "start": 1542.48, "end": 1549.32, "text": " Hopefully don't require too much extra concepts so I can kind of keep seeing things working and if something stops working", "tokens": [10429, 500, 380, 3651, 886, 709, 2857, 10392, 370, 286, 393, 733, 295, 1066, 2577, 721, 1364, 293, 498, 746, 10094, 1364], "temperature": 0.0, "avg_logprob": -0.27440789481189765, "compression_ratio": 1.7132075471698114, "no_speech_prob": 4.6837289119139314e-05}, {"id": 327, "seek": 153280, "start": 1549.32, "end": 1552.8799999999999, "text": " I know exactly where it works. I don't try and build everything at the same time", "tokens": [286, 458, 2293, 689, 309, 1985, 13, 286, 500, 380, 853, 293, 1322, 1203, 412, 264, 912, 565], "temperature": 0.0, "avg_logprob": -0.27440789481189765, "compression_ratio": 1.7132075471698114, "no_speech_prob": 4.6837289119139314e-05}, {"id": 328, "seek": 155288, "start": 1552.88, "end": 1562.5600000000002, "text": " So multi-label classification is so easy. It's there's not much to mention. So we've moved to Pascal multi now. This is what we're going to do the multi object stuff", "tokens": [407, 4825, 12, 75, 18657, 21538, 307, 370, 1858, 13, 467, 311, 456, 311, 406, 709, 281, 2152, 13, 407, 321, 600, 4259, 281, 41723, 4825, 586, 13, 639, 307, 437, 321, 434, 516, 281, 360, 264, 4825, 2657, 1507], "temperature": 0.0, "avg_logprob": -0.2591551955865354, "compression_ratio": 1.6418604651162791, "no_speech_prob": 1.0952976481348742e-05}, {"id": 329, "seek": 155288, "start": 1563.2800000000002, "end": 1567.5600000000002, "text": " So for the multi object stuff, I've just copied and pasted the functions from the previous", "tokens": [407, 337, 264, 4825, 2657, 1507, 11, 286, 600, 445, 25365, 293, 1791, 292, 264, 6828, 490, 264, 3894], "temperature": 0.0, "avg_logprob": -0.2591551955865354, "compression_ratio": 1.6418604651162791, "no_speech_prob": 1.0952976481348742e-05}, {"id": 330, "seek": 155288, "start": 1568.7600000000002, "end": 1570.92, "text": " Notebook that we used so they're all at the top", "tokens": [11633, 2939, 300, 321, 1143, 370, 436, 434, 439, 412, 264, 1192], "temperature": 0.0, "avg_logprob": -0.2591551955865354, "compression_ratio": 1.6418604651162791, "no_speech_prob": 1.0952976481348742e-05}, {"id": 331, "seek": 155288, "start": 1572.16, "end": 1574.16, "text": " so we can create now a", "tokens": [370, 321, 393, 1884, 586, 257], "temperature": 0.0, "avg_logprob": -0.2591551955865354, "compression_ratio": 1.6418604651162791, "no_speech_prob": 1.0952976481348742e-05}, {"id": 332, "seek": 155288, "start": 1574.96, "end": 1576.96, "text": " multi-class", "tokens": [4825, 12, 11665], "temperature": 0.0, "avg_logprob": -0.2591551955865354, "compression_ratio": 1.6418604651162791, "no_speech_prob": 1.0952976481348742e-05}, {"id": 333, "seek": 155288, "start": 1577.72, "end": 1579.72, "text": " A multi-class", "tokens": [316, 4825, 12, 11665], "temperature": 0.0, "avg_logprob": -0.2591551955865354, "compression_ratio": 1.6418604651162791, "no_speech_prob": 1.0952976481348742e-05}, {"id": 334, "seek": 157972, "start": 1579.72, "end": 1585.9, "text": " CSV file using the same basic approach that we did last time and I'll mention by the way", "tokens": [48814, 3991, 1228, 264, 912, 3875, 3109, 300, 321, 630, 1036, 565, 293, 286, 603, 2152, 538, 264, 636], "temperature": 0.0, "avg_logprob": -0.21802091598510742, "compression_ratio": 1.5491071428571428, "no_speech_prob": 2.9772041671094485e-05}, {"id": 335, "seek": 157972, "start": 1586.56, "end": 1589.68, "text": " One of our students actually who's visiting from India funny", "tokens": [1485, 295, 527, 1731, 767, 567, 311, 11700, 490, 5282, 4074], "temperature": 0.0, "avg_logprob": -0.21802091598510742, "compression_ratio": 1.5491071428571428, "no_speech_prob": 2.9772041671094485e-05}, {"id": 336, "seek": 157972, "start": 1591.44, "end": 1595.04, "text": " Pointed out to me that all this stuff we're doing with", "tokens": [12387, 292, 484, 281, 385, 300, 439, 341, 1507, 321, 434, 884, 365], "temperature": 0.0, "avg_logprob": -0.21802091598510742, "compression_ratio": 1.5491071428571428, "no_speech_prob": 2.9772041671094485e-05}, {"id": 337, "seek": 157972, "start": 1596.32, "end": 1598.48, "text": " Default Dix and stuff like that", "tokens": [9548, 5107, 413, 970, 293, 1507, 411, 300], "temperature": 0.0, "avg_logprob": -0.21802091598510742, "compression_ratio": 1.5491071428571428, "no_speech_prob": 2.9772041671094485e-05}, {"id": 338, "seek": 157972, "start": 1599.24, "end": 1605.48, "text": " He actually showed a way of doing it which was much simpler using pandas and he shared that on the forum. So I", "tokens": [634, 767, 4712, 257, 636, 295, 884, 309, 597, 390, 709, 18587, 1228, 4565, 296, 293, 415, 5507, 300, 322, 264, 17542, 13, 407, 286], "temperature": 0.0, "avg_logprob": -0.21802091598510742, "compression_ratio": 1.5491071428571428, "no_speech_prob": 2.9772041671094485e-05}, {"id": 339, "seek": 160548, "start": 1605.48, "end": 1610.68, "text": " Totally bowed to his much better approach a much simpler more concise approach", "tokens": [22837, 4503, 292, 281, 702, 709, 1101, 3109, 257, 709, 18587, 544, 44882, 3109], "temperature": 0.0, "avg_logprob": -0.19616727359959338, "compression_ratio": 1.4883720930232558, "no_speech_prob": 8.348008850589395e-05}, {"id": 340, "seek": 160548, "start": 1610.68, "end": 1614.08, "text": " And yeah, it's definitely true. Like the more you get to know pandas", "tokens": [400, 1338, 11, 309, 311, 2138, 2074, 13, 1743, 264, 544, 291, 483, 281, 458, 4565, 296], "temperature": 0.0, "avg_logprob": -0.19616727359959338, "compression_ratio": 1.4883720930232558, "no_speech_prob": 8.348008850589395e-05}, {"id": 341, "seek": 160548, "start": 1614.88, "end": 1622.3, "text": " The more often you realize it's a good way to solve lots of different problems. So definitely check that out", "tokens": [440, 544, 2049, 291, 4325, 309, 311, 257, 665, 636, 281, 5039, 3195, 295, 819, 2740, 13, 407, 2138, 1520, 300, 484], "temperature": 0.0, "avg_logprob": -0.19616727359959338, "compression_ratio": 1.4883720930232558, "no_speech_prob": 8.348008850589395e-05}, {"id": 342, "seek": 162230, "start": 1622.3, "end": 1627.86, "text": " When you're building out the smaller models and you're iterating do you reuse those models as", "tokens": [1133, 291, 434, 2390, 484, 264, 4356, 5245, 293, 291, 434, 17138, 990, 360, 291, 26225, 729, 5245, 382], "temperature": 0.0, "avg_logprob": -0.5786498621890419, "compression_ratio": 1.7612612612612613, "no_speech_prob": 1.5935989722493105e-05}, {"id": 343, "seek": 162230, "start": 1628.58, "end": 1633.6, "text": " pre-trained weights for this like larger one or do you just toss it all away and then", "tokens": [659, 12, 17227, 2001, 17443, 337, 341, 411, 4833, 472, 420, 360, 291, 445, 14432, 309, 439, 1314, 293, 550], "temperature": 0.0, "avg_logprob": -0.5786498621890419, "compression_ratio": 1.7612612612612613, "no_speech_prob": 1.5935989722493105e-05}, {"id": 344, "seek": 162230, "start": 1634.3, "end": 1639.18, "text": " Retrain from scratch with when I'm kind of like figuring stuff out as a girl like this", "tokens": [11495, 7146, 490, 8459, 365, 562, 286, 478, 733, 295, 411, 15213, 1507, 484, 382, 257, 2013, 411, 341], "temperature": 0.0, "avg_logprob": -0.5786498621890419, "compression_ratio": 1.7612612612612613, "no_speech_prob": 1.5935989722493105e-05}, {"id": 345, "seek": 162230, "start": 1639.18, "end": 1644.54, "text": " I would generally mean towards tossing away because they're kind of reusing the model", "tokens": [286, 576, 5101, 914, 3030, 14432, 278, 1314, 570, 436, 434, 733, 295, 319, 7981, 264, 2316], "temperature": 0.0, "avg_logprob": -0.5786498621890419, "compression_ratio": 1.7612612612612613, "no_speech_prob": 1.5935989722493105e-05}, {"id": 346, "seek": 162230, "start": 1644.54, "end": 1646.54, "text": " So I would generally mean tossing away", "tokens": [407, 286, 576, 5101, 914, 14432, 278, 1314], "temperature": 0.0, "avg_logprob": -0.5786498621890419, "compression_ratio": 1.7612612612612613, "no_speech_prob": 1.5935989722493105e-05}, {"id": 347, "seek": 164654, "start": 1646.54, "end": 1653.54, "text": " I would generally mean tossing away because they're kind of reusing pre-trained weights", "tokens": [286, 576, 5101, 914, 14432, 278, 1314, 570, 436, 434, 733, 295, 319, 7981, 659, 12, 17227, 2001, 17443], "temperature": 0.0, "avg_logprob": -0.28603977906076533, "compression_ratio": 1.5148514851485149, "no_speech_prob": 3.269634544267319e-05}, {"id": 348, "seek": 164654, "start": 1654.7, "end": 1657.26, "text": " introduces complexities that I'm not really think about", "tokens": [31472, 48705, 300, 286, 478, 406, 534, 519, 466], "temperature": 0.0, "avg_logprob": -0.28603977906076533, "compression_ratio": 1.5148514851485149, "no_speech_prob": 3.269634544267319e-05}, {"id": 349, "seek": 164654, "start": 1658.1, "end": 1659.7, "text": " however, if I'm", "tokens": [4461, 11, 498, 286, 478], "temperature": 0.0, "avg_logprob": -0.28603977906076533, "compression_ratio": 1.5148514851485149, "no_speech_prob": 3.269634544267319e-05}, {"id": 350, "seek": 164654, "start": 1659.7, "end": 1662.94, "text": " Trying to get to a point where I can run something on really big images", "tokens": [20180, 281, 483, 281, 257, 935, 689, 286, 393, 1190, 746, 322, 534, 955, 5267], "temperature": 0.0, "avg_logprob": -0.28603977906076533, "compression_ratio": 1.5148514851485149, "no_speech_prob": 3.269634544267319e-05}, {"id": 351, "seek": 164654, "start": 1662.94, "end": 1667.1, "text": " I'll generally start on much smaller ones and often I will reuse", "tokens": [286, 603, 5101, 722, 322, 709, 4356, 2306, 293, 2049, 286, 486, 26225], "temperature": 0.0, "avg_logprob": -0.28603977906076533, "compression_ratio": 1.5148514851485149, "no_speech_prob": 3.269634544267319e-05}, {"id": 352, "seek": 166710, "start": 1667.1, "end": 1679.1, "text": " those weights", "tokens": [729, 17443], "temperature": 0.0, "avg_logprob": -0.2687965222259066, "compression_ratio": 1.515527950310559, "no_speech_prob": 7.071736945363227e-06}, {"id": 353, "seek": 166710, "start": 1679.1, "end": 1682.4199999999998, "text": " Okay, so in this case all we're doing is we're just", "tokens": [1033, 11, 370, 294, 341, 1389, 439, 321, 434, 884, 307, 321, 434, 445], "temperature": 0.0, "avg_logprob": -0.2687965222259066, "compression_ratio": 1.515527950310559, "no_speech_prob": 7.071736945363227e-06}, {"id": 354, "seek": 166710, "start": 1683.4599999999998, "end": 1687.86, "text": " Joining up all of the classes with a space which gives us a CSV in the normal format", "tokens": [40229, 493, 439, 295, 264, 5359, 365, 257, 1901, 597, 2709, 505, 257, 48814, 294, 264, 2710, 7877], "temperature": 0.0, "avg_logprob": -0.2687965222259066, "compression_ratio": 1.515527950310559, "no_speech_prob": 7.071736945363227e-06}, {"id": 355, "seek": 166710, "start": 1687.86, "end": 1692.34, "text": " Once we've got the CSV in a normal format, it's the usual three lines of code and we train it", "tokens": [3443, 321, 600, 658, 264, 48814, 294, 257, 2710, 7877, 11, 309, 311, 264, 7713, 1045, 3876, 295, 3089, 293, 321, 3847, 309], "temperature": 0.0, "avg_logprob": -0.2687965222259066, "compression_ratio": 1.515527950310559, "no_speech_prob": 7.071736945363227e-06}, {"id": 356, "seek": 169234, "start": 1692.34, "end": 1695.1399999999999, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.3235910024987646, "compression_ratio": 1.4764150943396226, "no_speech_prob": 1.520632577012293e-05}, {"id": 357, "seek": 169234, "start": 1695.1399999999999, "end": 1700.1, "text": " We print out the results. So there's literally nothing to show you and as you can see it's done a great job", "tokens": [492, 4482, 484, 264, 3542, 13, 407, 456, 311, 3736, 1825, 281, 855, 291, 293, 382, 291, 393, 536, 309, 311, 1096, 257, 869, 1691], "temperature": 0.0, "avg_logprob": -0.3235910024987646, "compression_ratio": 1.4764150943396226, "no_speech_prob": 1.520632577012293e-05}, {"id": 358, "seek": 169234, "start": 1700.34, "end": 1702.58, "text": " The only mistake I think it made was it called", "tokens": [440, 787, 6146, 286, 519, 309, 1027, 390, 309, 1219], "temperature": 0.0, "avg_logprob": -0.3235910024987646, "compression_ratio": 1.4764150943396226, "no_speech_prob": 1.520632577012293e-05}, {"id": 359, "seek": 169234, "start": 1703.22, "end": 1706.1799999999998, "text": " This dog grass should have been dog and sofa", "tokens": [639, 3000, 8054, 820, 362, 668, 3000, 293, 28668], "temperature": 0.0, "avg_logprob": -0.3235910024987646, "compression_ratio": 1.4764150943396226, "no_speech_prob": 1.520632577012293e-05}, {"id": 360, "seek": 169234, "start": 1708.3799999999999, "end": 1710.3799999999999, "text": " Okay, so", "tokens": [1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.3235910024987646, "compression_ratio": 1.4764150943396226, "no_speech_prob": 1.520632577012293e-05}, {"id": 361, "seek": 169234, "start": 1710.62, "end": 1713.6599999999999, "text": " Modi class classification is is pretty straightforward", "tokens": [6583, 72, 1508, 21538, 307, 307, 1238, 15325], "temperature": 0.0, "avg_logprob": -0.3235910024987646, "compression_ratio": 1.4764150943396226, "no_speech_prob": 1.520632577012293e-05}, {"id": 362, "seek": 169234, "start": 1715.1399999999999, "end": 1718.1799999999998, "text": " One minor tweak here is to note that I used a", "tokens": [1485, 6696, 29879, 510, 307, 281, 3637, 300, 286, 1143, 257], "temperature": 0.0, "avg_logprob": -0.3235910024987646, "compression_ratio": 1.4764150943396226, "no_speech_prob": 1.520632577012293e-05}, {"id": 363, "seek": 171818, "start": 1718.18, "end": 1723.0600000000002, "text": " Set here because I don't want to list all of the objects", "tokens": [8928, 510, 570, 286, 500, 380, 528, 281, 1329, 439, 295, 264, 6565], "temperature": 0.0, "avg_logprob": -0.22632529185368463, "compression_ratio": 1.8016528925619835, "no_speech_prob": 2.8408190701156855e-05}, {"id": 364, "seek": 171818, "start": 1723.0600000000002, "end": 1728.5, "text": " I only want each object type to appear once and so the set class is a way of", "tokens": [286, 787, 528, 1184, 2657, 2010, 281, 4204, 1564, 293, 370, 264, 992, 1508, 307, 257, 636, 295], "temperature": 0.0, "avg_logprob": -0.22632529185368463, "compression_ratio": 1.8016528925619835, "no_speech_prob": 2.8408190701156855e-05}, {"id": 365, "seek": 171818, "start": 1729.22, "end": 1736.98, "text": " De-duplicating a list so that's why I don't have person person person person person just appears once so yeah these", "tokens": [1346, 12, 769, 4770, 990, 257, 1329, 370, 300, 311, 983, 286, 500, 380, 362, 954, 954, 954, 954, 954, 445, 7038, 1564, 370, 1338, 613], "temperature": 0.0, "avg_logprob": -0.22632529185368463, "compression_ratio": 1.8016528925619835, "no_speech_prob": 2.8408190701156855e-05}, {"id": 366, "seek": 171818, "start": 1738.5, "end": 1742.5800000000002, "text": " These object classification pre-trained networks. We have a really pretty good at", "tokens": [1981, 2657, 21538, 659, 12, 17227, 2001, 9590, 13, 492, 362, 257, 534, 1238, 665, 412], "temperature": 0.0, "avg_logprob": -0.22632529185368463, "compression_ratio": 1.8016528925619835, "no_speech_prob": 2.8408190701156855e-05}, {"id": 367, "seek": 174258, "start": 1742.58, "end": 1747.98, "text": " Recognizing multiple objects as long as you only have to mention each one once so that works pretty well", "tokens": [44682, 3319, 3866, 6565, 382, 938, 382, 291, 787, 362, 281, 2152, 1184, 472, 1564, 370, 300, 1985, 1238, 731], "temperature": 0.0, "avg_logprob": -0.2289135581568668, "compression_ratio": 1.4397905759162304, "no_speech_prob": 8.397913006774615e-06}, {"id": 368, "seek": 174258, "start": 1750.26, "end": 1752.74, "text": " All right, so we've got this idea", "tokens": [1057, 558, 11, 370, 321, 600, 658, 341, 1558], "temperature": 0.0, "avg_logprob": -0.2289135581568668, "compression_ratio": 1.4397905759162304, "no_speech_prob": 8.397913006774615e-06}, {"id": 369, "seek": 174258, "start": 1758.26, "end": 1760.26, "text": " That we've got an", "tokens": [663, 321, 600, 658, 364], "temperature": 0.0, "avg_logprob": -0.2289135581568668, "compression_ratio": 1.4397905759162304, "no_speech_prob": 8.397913006774615e-06}, {"id": 370, "seek": 174258, "start": 1761.34, "end": 1763.34, "text": " input image", "tokens": [4846, 3256], "temperature": 0.0, "avg_logprob": -0.2289135581568668, "compression_ratio": 1.4397905759162304, "no_speech_prob": 8.397913006774615e-06}, {"id": 371, "seek": 174258, "start": 1763.5, "end": 1765.5, "text": " That goes through a con", "tokens": [663, 1709, 807, 257, 416], "temperature": 0.0, "avg_logprob": -0.2289135581568668, "compression_ratio": 1.4397905759162304, "no_speech_prob": 8.397913006774615e-06}, {"id": 372, "seek": 176550, "start": 1765.5, "end": 1772.9, "text": " Conv net, you know, which we're just kind of treated the black box and it spits out a", "tokens": [2656, 85, 2533, 11, 291, 458, 11, 597, 321, 434, 445, 733, 295, 8668, 264, 2211, 2424, 293, 309, 637, 1208, 484, 257], "temperature": 0.0, "avg_logprob": -0.3484368817559604, "compression_ratio": 1.4066666666666667, "no_speech_prob": 5.422190497483825e-06}, {"id": 373, "seek": 176550, "start": 1777.78, "end": 1786.06, "text": " Tensor a vector that size for passing right where C is the", "tokens": [34306, 257, 8062, 300, 2744, 337, 8437, 558, 689, 383, 307, 264], "temperature": 0.0, "avg_logprob": -0.3484368817559604, "compression_ratio": 1.4066666666666667, "no_speech_prob": 5.422190497483825e-06}, {"id": 374, "seek": 178606, "start": 1786.06, "end": 1794.22, "text": " Number of classes and so that's what we've got and that gives us a", "tokens": [5118, 295, 5359, 293, 370, 300, 311, 437, 321, 600, 658, 293, 300, 2709, 505, 257], "temperature": 0.0, "avg_logprob": -0.25431486655925883, "compression_ratio": 1.4930555555555556, "no_speech_prob": 1.6028049003580236e-06}, {"id": 375, "seek": 178606, "start": 1795.22, "end": 1797.7, "text": " an object detector for a single", "tokens": [364, 2657, 25712, 337, 257, 2167], "temperature": 0.0, "avg_logprob": -0.25431486655925883, "compression_ratio": 1.4930555555555556, "no_speech_prob": 1.6028049003580236e-06}, {"id": 376, "seek": 178606, "start": 1798.7, "end": 1800.7, "text": " object the largest object", "tokens": [2657, 264, 6443, 2657], "temperature": 0.0, "avg_logprob": -0.25431486655925883, "compression_ratio": 1.4930555555555556, "no_speech_prob": 1.6028049003580236e-06}, {"id": 377, "seek": 178606, "start": 1801.58, "end": 1809.62, "text": " So let's now create one which doesn't find a single object, but that finds 16 objects", "tokens": [407, 718, 311, 586, 1884, 472, 597, 1177, 380, 915, 257, 2167, 2657, 11, 457, 300, 10704, 3165, 6565], "temperature": 0.0, "avg_logprob": -0.25431486655925883, "compression_ratio": 1.4930555555555556, "no_speech_prob": 1.6028049003580236e-06}, {"id": 378, "seek": 178606, "start": 1810.74, "end": 1811.78, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.25431486655925883, "compression_ratio": 1.4930555555555556, "no_speech_prob": 1.6028049003580236e-06}, {"id": 379, "seek": 181178, "start": 1811.78, "end": 1817.86, "text": " so an obvious way to do that would be to take this last this is just a", "tokens": [370, 364, 6322, 636, 281, 360, 300, 576, 312, 281, 747, 341, 1036, 341, 307, 445, 257], "temperature": 0.0, "avg_logprob": -0.295692631896113, "compression_ratio": 1.6687898089171975, "no_speech_prob": 3.5559580737754004e-06}, {"id": 380, "seek": 181178, "start": 1818.86, "end": 1821.62, "text": " and end on linear right which has got", "tokens": [293, 917, 322, 8213, 558, 597, 575, 658], "temperature": 0.0, "avg_logprob": -0.295692631896113, "compression_ratio": 1.6687898089171975, "no_speech_prob": 3.5559580737754004e-06}, {"id": 381, "seek": 181178, "start": 1822.78, "end": 1824.78, "text": " however many inputs and", "tokens": [4461, 867, 15743, 293], "temperature": 0.0, "avg_logprob": -0.295692631896113, "compression_ratio": 1.6687898089171975, "no_speech_prob": 3.5559580737754004e-06}, {"id": 382, "seek": 181178, "start": 1825.98, "end": 1832.1, "text": " Four plus C outputs we could take that linear layer and rather than having", "tokens": [7451, 1804, 383, 23930, 321, 727, 747, 300, 8213, 4583, 293, 2831, 813, 1419], "temperature": 0.0, "avg_logprob": -0.295692631896113, "compression_ratio": 1.6687898089171975, "no_speech_prob": 3.5559580737754004e-06}, {"id": 383, "seek": 181178, "start": 1832.7, "end": 1835.46, "text": " Four plus C outputs we could have", "tokens": [7451, 1804, 383, 23930, 321, 727, 362], "temperature": 0.0, "avg_logprob": -0.295692631896113, "compression_ratio": 1.6687898089171975, "no_speech_prob": 3.5559580737754004e-06}, {"id": 384, "seek": 181178, "start": 1836.34, "end": 1838.34, "text": " 16 times", "tokens": [3165, 1413], "temperature": 0.0, "avg_logprob": -0.295692631896113, "compression_ratio": 1.6687898089171975, "no_speech_prob": 3.5559580737754004e-06}, {"id": 385, "seek": 181178, "start": 1838.34, "end": 1840.34, "text": " four plus C", "tokens": [1451, 1804, 383], "temperature": 0.0, "avg_logprob": -0.295692631896113, "compression_ratio": 1.6687898089171975, "no_speech_prob": 3.5559580737754004e-06}, {"id": 386, "seek": 184034, "start": 1840.34, "end": 1842.34, "text": " outputs", "tokens": [23930], "temperature": 0.0, "avg_logprob": -0.18939902232243463, "compression_ratio": 1.6631016042780749, "no_speech_prob": 2.355227479711175e-05}, {"id": 387, "seek": 184034, "start": 1842.34, "end": 1845.1, "text": " So it's now spitting out enough things to give us", "tokens": [407, 309, 311, 586, 637, 2414, 484, 1547, 721, 281, 976, 505], "temperature": 0.0, "avg_logprob": -0.18939902232243463, "compression_ratio": 1.6631016042780749, "no_speech_prob": 2.355227479711175e-05}, {"id": 388, "seek": 184034, "start": 1845.9399999999998, "end": 1850.86, "text": " 16 sets of class probabilities and 16 sets of bounding box coordinates and", "tokens": [3165, 6352, 295, 1508, 33783, 293, 3165, 6352, 295, 5472, 278, 2424, 21056, 293], "temperature": 0.0, "avg_logprob": -0.18939902232243463, "compression_ratio": 1.6631016042780749, "no_speech_prob": 2.355227479711175e-05}, {"id": 389, "seek": 184034, "start": 1851.58, "end": 1853.58, "text": " Then we would just need a loss function", "tokens": [1396, 321, 576, 445, 643, 257, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.18939902232243463, "compression_ratio": 1.6631016042780749, "no_speech_prob": 2.355227479711175e-05}, {"id": 390, "seek": 184034, "start": 1853.98, "end": 1855.98, "text": " That would check whether those", "tokens": [663, 576, 1520, 1968, 729], "temperature": 0.0, "avg_logprob": -0.18939902232243463, "compression_ratio": 1.6631016042780749, "no_speech_prob": 2.355227479711175e-05}, {"id": 391, "seek": 184034, "start": 1856.82, "end": 1859.6999999999998, "text": " 16 sets of bounding boxes", "tokens": [3165, 6352, 295, 5472, 278, 9002], "temperature": 0.0, "avg_logprob": -0.18939902232243463, "compression_ratio": 1.6631016042780749, "no_speech_prob": 2.355227479711175e-05}, {"id": 392, "seek": 184034, "start": 1860.62, "end": 1862.4199999999998, "text": " correctly represented", "tokens": [8944, 10379], "temperature": 0.0, "avg_logprob": -0.18939902232243463, "compression_ratio": 1.6631016042780749, "no_speech_prob": 2.355227479711175e-05}, {"id": 393, "seek": 184034, "start": 1862.4199999999998, "end": 1866.78, "text": " The up to 16 objects that were represented in the image now", "tokens": [440, 493, 281, 3165, 6565, 300, 645, 10379, 294, 264, 3256, 586], "temperature": 0.0, "avg_logprob": -0.18939902232243463, "compression_ratio": 1.6631016042780749, "no_speech_prob": 2.355227479711175e-05}, {"id": 394, "seek": 186678, "start": 1866.78, "end": 1872.3, "text": " There's a lot of hand waving about the loss function. We'll go into it later as to what that is, but let's pretend we have one", "tokens": [821, 311, 257, 688, 295, 1011, 35347, 466, 264, 4470, 2445, 13, 492, 603, 352, 666, 309, 1780, 382, 281, 437, 300, 307, 11, 457, 718, 311, 11865, 321, 362, 472], "temperature": 0.0, "avg_logprob": -0.19955373317637343, "compression_ratio": 1.6785714285714286, "no_speech_prob": 5.507569312612759e-06}, {"id": 395, "seek": 186678, "start": 1874.22, "end": 1877.56, "text": " Assuming we had a reasonable loss function that's totally going to work", "tokens": [6281, 24919, 321, 632, 257, 10585, 4470, 2445, 300, 311, 3879, 516, 281, 589], "temperature": 0.0, "avg_logprob": -0.19955373317637343, "compression_ratio": 1.6785714285714286, "no_speech_prob": 5.507569312612759e-06}, {"id": 396, "seek": 186678, "start": 1877.98, "end": 1881.86, "text": " Right that that is an architecture which has the necessary", "tokens": [1779, 300, 300, 307, 364, 9482, 597, 575, 264, 4818], "temperature": 0.0, "avg_logprob": -0.19955373317637343, "compression_ratio": 1.6785714285714286, "no_speech_prob": 5.507569312612759e-06}, {"id": 397, "seek": 186678, "start": 1882.74, "end": 1888.82, "text": " Output activations that with the correct loss function. We should be able to train it to do what we want it to do", "tokens": [5925, 2582, 2430, 763, 300, 365, 264, 3006, 4470, 2445, 13, 492, 820, 312, 1075, 281, 3847, 309, 281, 360, 437, 321, 528, 309, 281, 360], "temperature": 0.0, "avg_logprob": -0.19955373317637343, "compression_ratio": 1.6785714285714286, "no_speech_prob": 5.507569312612759e-06}, {"id": 398, "seek": 186678, "start": 1890.06, "end": 1892.06, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.19955373317637343, "compression_ratio": 1.6785714285714286, "no_speech_prob": 5.507569312612759e-06}, {"id": 399, "seek": 189206, "start": 1892.06, "end": 1899.1599999999999, "text": " But that's just one way to do it. There's a second way we could do it rather than having a", "tokens": [583, 300, 311, 445, 472, 636, 281, 360, 309, 13, 821, 311, 257, 1150, 636, 321, 727, 360, 309, 2831, 813, 1419, 257], "temperature": 0.0, "avg_logprob": -0.3146172107105524, "compression_ratio": 1.4268292682926829, "no_speech_prob": 3.668827957881149e-06}, {"id": 400, "seek": 189206, "start": 1901.06, "end": 1903.06, "text": " NN dot linear", "tokens": [426, 45, 5893, 8213], "temperature": 0.0, "avg_logprob": -0.3146172107105524, "compression_ratio": 1.4268292682926829, "no_speech_prob": 3.668827957881149e-06}, {"id": 401, "seek": 189206, "start": 1904.02, "end": 1906.02, "text": " What if instead", "tokens": [708, 498, 2602], "temperature": 0.0, "avg_logprob": -0.3146172107105524, "compression_ratio": 1.4268292682926829, "no_speech_prob": 3.668827957881149e-06}, {"id": 402, "seek": 189206, "start": 1906.58, "end": 1908.58, "text": " we took from our", "tokens": [321, 1890, 490, 527], "temperature": 0.0, "avg_logprob": -0.3146172107105524, "compression_ratio": 1.4268292682926829, "no_speech_prob": 3.668827957881149e-06}, {"id": 403, "seek": 189206, "start": 1909.8999999999999, "end": 1915.6, "text": " Resnet convolutional background backbone not an in like linear, but instead we added a", "tokens": [5015, 7129, 45216, 304, 3678, 34889, 406, 364, 294, 411, 8213, 11, 457, 2602, 321, 3869, 257], "temperature": 0.0, "avg_logprob": -0.3146172107105524, "compression_ratio": 1.4268292682926829, "no_speech_prob": 3.668827957881149e-06}, {"id": 404, "seek": 189206, "start": 1917.1799999999998, "end": 1919.1799999999998, "text": " NN.com 2d", "tokens": [426, 45, 13, 1112, 568, 67], "temperature": 0.0, "avg_logprob": -0.3146172107105524, "compression_ratio": 1.4268292682926829, "no_speech_prob": 3.668827957881149e-06}, {"id": 405, "seek": 191918, "start": 1919.18, "end": 1921.18, "text": " with", "tokens": [365], "temperature": 0.0, "avg_logprob": -0.3924027262507258, "compression_ratio": 1.4370860927152318, "no_speech_prob": 1.1726378943421878e-06}, {"id": 406, "seek": 191918, "start": 1922.0600000000002, "end": 1924.0600000000002, "text": " stride", "tokens": [1056, 482], "temperature": 0.0, "avg_logprob": -0.3924027262507258, "compression_ratio": 1.4370860927152318, "no_speech_prob": 1.1726378943421878e-06}, {"id": 407, "seek": 191918, "start": 1924.66, "end": 1926.66, "text": " To", "tokens": [1407], "temperature": 0.0, "avg_logprob": -0.3924027262507258, "compression_ratio": 1.4370860927152318, "no_speech_prob": 1.1726378943421878e-06}, {"id": 408, "seek": 191918, "start": 1926.66, "end": 1930.5800000000002, "text": " Alright, so the final layer of resnet is", "tokens": [2798, 11, 370, 264, 2572, 4583, 295, 725, 7129, 307], "temperature": 0.0, "avg_logprob": -0.3924027262507258, "compression_ratio": 1.4370860927152318, "no_speech_prob": 1.1726378943421878e-06}, {"id": 409, "seek": 191918, "start": 1931.3, "end": 1935.7, "text": " Gets you a 7 by 7 by 512", "tokens": [460, 1385, 291, 257, 1614, 538, 1614, 538, 1025, 4762], "temperature": 0.0, "avg_logprob": -0.3924027262507258, "compression_ratio": 1.4370860927152318, "no_speech_prob": 1.1726378943421878e-06}, {"id": 410, "seek": 191918, "start": 1936.46, "end": 1939.54, "text": " as all right, so this would give us a", "tokens": [382, 439, 558, 11, 370, 341, 576, 976, 505, 257], "temperature": 0.0, "avg_logprob": -0.3924027262507258, "compression_ratio": 1.4370860927152318, "no_speech_prob": 1.1726378943421878e-06}, {"id": 411, "seek": 191918, "start": 1940.26, "end": 1942.66, "text": " 4 by 4 by", "tokens": [1017, 538, 1017, 538], "temperature": 0.0, "avg_logprob": -0.3924027262507258, "compression_ratio": 1.4370860927152318, "no_speech_prob": 1.1726378943421878e-06}, {"id": 412, "seek": 194266, "start": 1942.66, "end": 1949.0400000000002, "text": " By whatever number of filters result maybe for the number of filters. Let's say we pick 256", "tokens": [3146, 2035, 1230, 295, 15995, 1874, 1310, 337, 264, 1230, 295, 15995, 13, 961, 311, 584, 321, 1888, 38882], "temperature": 0.0, "avg_logprob": -0.3919659878345246, "compression_ratio": 1.25, "no_speech_prob": 5.0936737352458294e-06}, {"id": 413, "seek": 194266, "start": 1952.14, "end": 1954.8600000000001, "text": " Okay, so it would be", "tokens": [1033, 11, 370, 309, 576, 312], "temperature": 0.0, "avg_logprob": -0.3919659878345246, "compression_ratio": 1.25, "no_speech_prob": 5.0936737352458294e-06}, {"id": 414, "seek": 194266, "start": 1959.14, "end": 1961.3000000000002, "text": " For for by", "tokens": [1171, 337, 538], "temperature": 0.0, "avg_logprob": -0.3919659878345246, "compression_ratio": 1.25, "no_speech_prob": 5.0936737352458294e-06}, {"id": 415, "seek": 194266, "start": 1963.7, "end": 1965.7, "text": " 256", "tokens": [38882], "temperature": 0.0, "avg_logprob": -0.3919659878345246, "compression_ratio": 1.25, "no_speech_prob": 5.0936737352458294e-06}, {"id": 416, "seek": 194266, "start": 1965.74, "end": 1968.66, "text": " 4 by 4 by 256 has", "tokens": [1017, 538, 1017, 538, 38882, 575], "temperature": 0.0, "avg_logprob": -0.3919659878345246, "compression_ratio": 1.25, "no_speech_prob": 5.0936737352458294e-06}, {"id": 417, "seek": 196866, "start": 1968.66, "end": 1975.74, "text": " Well actually no, let's change that let's not make it 4 by 4 by 256 better still let's do it all in one step", "tokens": [1042, 767, 572, 11, 718, 311, 1319, 300, 718, 311, 406, 652, 309, 1017, 538, 1017, 538, 38882, 1101, 920, 718, 311, 360, 309, 439, 294, 472, 1823], "temperature": 0.0, "avg_logprob": -0.38334392029562114, "compression_ratio": 1.6149425287356323, "no_speech_prob": 2.0580398540914757e-06}, {"id": 418, "seek": 196866, "start": 1975.74, "end": 1978.8200000000002, "text": " Let's make it 4 by 4 by", "tokens": [961, 311, 652, 309, 1017, 538, 1017, 538], "temperature": 0.0, "avg_logprob": -0.38334392029562114, "compression_ratio": 1.6149425287356323, "no_speech_prob": 2.0580398540914757e-06}, {"id": 419, "seek": 196866, "start": 1980.18, "end": 1982.18, "text": " 4 plus C", "tokens": [1017, 1804, 383], "temperature": 0.0, "avg_logprob": -0.38334392029562114, "compression_ratio": 1.6149425287356323, "no_speech_prob": 2.0580398540914757e-06}, {"id": 420, "seek": 196866, "start": 1984.5, "end": 1986.5, "text": " Because now", "tokens": [1436, 586], "temperature": 0.0, "avg_logprob": -0.38334392029562114, "compression_ratio": 1.6149425287356323, "no_speech_prob": 2.0580398540914757e-06}, {"id": 421, "seek": 196866, "start": 1986.5, "end": 1992.3000000000002, "text": " We've got a tensor where the number of elements is exactly equal to the number of elements we wanted", "tokens": [492, 600, 658, 257, 40863, 689, 264, 1230, 295, 4959, 307, 2293, 2681, 281, 264, 1230, 295, 4959, 321, 1415], "temperature": 0.0, "avg_logprob": -0.38334392029562114, "compression_ratio": 1.6149425287356323, "no_speech_prob": 2.0580398540914757e-06}, {"id": 422, "seek": 196866, "start": 1993.5800000000002, "end": 1995.5800000000002, "text": " So in other words we could", "tokens": [407, 294, 661, 2283, 321, 727], "temperature": 0.0, "avg_logprob": -0.38334392029562114, "compression_ratio": 1.6149425287356323, "no_speech_prob": 2.0580398540914757e-06}, {"id": 423, "seek": 199558, "start": 1995.58, "end": 2000.28, "text": " We could we could now if this would work too if we created a loss function", "tokens": [492, 727, 321, 727, 586, 498, 341, 576, 589, 886, 498, 321, 2942, 257, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.24364859124888544, "compression_ratio": 1.6200873362445414, "no_speech_prob": 1.8738693370323745e-06}, {"id": 424, "seek": 199558, "start": 2001.06, "end": 2003.98, "text": " That took a 4 by 4 by 4 plus C", "tokens": [663, 1890, 257, 1017, 538, 1017, 538, 1017, 1804, 383], "temperature": 0.0, "avg_logprob": -0.24364859124888544, "compression_ratio": 1.6200873362445414, "no_speech_prob": 1.8738693370323745e-06}, {"id": 425, "seek": 199558, "start": 2005.62, "end": 2007.78, "text": " tensor and mapped it to", "tokens": [40863, 293, 33318, 309, 281], "temperature": 0.0, "avg_logprob": -0.24364859124888544, "compression_ratio": 1.6200873362445414, "no_speech_prob": 1.8738693370323745e-06}, {"id": 426, "seek": 199558, "start": 2008.6999999999998, "end": 2012.98, "text": " 16 objects in the image and checked whether each one was correctly represented by", "tokens": [3165, 6565, 294, 264, 3256, 293, 10033, 1968, 1184, 472, 390, 8944, 10379, 538], "temperature": 0.0, "avg_logprob": -0.24364859124888544, "compression_ratio": 1.6200873362445414, "no_speech_prob": 1.8738693370323745e-06}, {"id": 427, "seek": 199558, "start": 2013.6599999999999, "end": 2015.6599999999999, "text": " Those 4 plus C", "tokens": [3950, 1017, 1804, 383], "temperature": 0.0, "avg_logprob": -0.24364859124888544, "compression_ratio": 1.6200873362445414, "no_speech_prob": 1.8738693370323745e-06}, {"id": 428, "seek": 199558, "start": 2015.78, "end": 2018.34, "text": " activations that would work like these are two", "tokens": [2430, 763, 300, 576, 589, 411, 613, 366, 732], "temperature": 0.0, "avg_logprob": -0.24364859124888544, "compression_ratio": 1.6200873362445414, "no_speech_prob": 1.8738693370323745e-06}, {"id": 429, "seek": 199558, "start": 2019.82, "end": 2024.26, "text": " Exactly equivalent sets of activations because they got the same number of elements. They're just", "tokens": [7587, 10344, 6352, 295, 2430, 763, 570, 436, 658, 264, 912, 1230, 295, 4959, 13, 814, 434, 445], "temperature": 0.0, "avg_logprob": -0.24364859124888544, "compression_ratio": 1.6200873362445414, "no_speech_prob": 1.8738693370323745e-06}, {"id": 430, "seek": 202426, "start": 2024.26, "end": 2026.26, "text": " We shake", "tokens": [492, 10283], "temperature": 0.0, "avg_logprob": -0.2648043632507324, "compression_ratio": 1.5365853658536586, "no_speech_prob": 1.553491074446356e-06}, {"id": 431, "seek": 202426, "start": 2026.78, "end": 2033.1, "text": " Yeah, so it turns out that both of these approaches are actually used", "tokens": [865, 11, 370, 309, 4523, 484, 300, 1293, 295, 613, 11587, 366, 767, 1143], "temperature": 0.0, "avg_logprob": -0.2648043632507324, "compression_ratio": 1.5365853658536586, "no_speech_prob": 1.553491074446356e-06}, {"id": 432, "seek": 202426, "start": 2034.58, "end": 2041.26, "text": " The approach where you basically just spit out one big long vector from a fully connected linear layer", "tokens": [440, 3109, 689, 291, 1936, 445, 22127, 484, 472, 955, 938, 8062, 490, 257, 4498, 4582, 8213, 4583], "temperature": 0.0, "avg_logprob": -0.2648043632507324, "compression_ratio": 1.5365853658536586, "no_speech_prob": 1.553491074446356e-06}, {"id": 433, "seek": 202426, "start": 2041.74, "end": 2045.46, "text": " is used by a class of models known as", "tokens": [307, 1143, 538, 257, 1508, 295, 5245, 2570, 382], "temperature": 0.0, "avg_logprob": -0.2648043632507324, "compression_ratio": 1.5365853658536586, "no_speech_prob": 1.553491074446356e-06}, {"id": 434, "seek": 202426, "start": 2046.22, "end": 2048.22, "text": " Yolo", "tokens": [398, 7902], "temperature": 0.0, "avg_logprob": -0.2648043632507324, "compression_ratio": 1.5365853658536586, "no_speech_prob": 1.553491074446356e-06}, {"id": 435, "seek": 202426, "start": 2048.66, "end": 2050.66, "text": " Whereas the approach of the", "tokens": [13813, 264, 3109, 295, 264], "temperature": 0.0, "avg_logprob": -0.2648043632507324, "compression_ratio": 1.5365853658536586, "no_speech_prob": 1.553491074446356e-06}, {"id": 436, "seek": 205066, "start": 2050.66, "end": 2056.58, "text": " Convolutional activations is used by models which", "tokens": [2656, 85, 3386, 304, 2430, 763, 307, 1143, 538, 5245, 597], "temperature": 0.0, "avg_logprob": -0.29000042102955004, "compression_ratio": 1.4049079754601228, "no_speech_prob": 2.482466925357585e-06}, {"id": 437, "seek": 205066, "start": 2058.5, "end": 2063.8799999999997, "text": " Started with something called SSD or single shot detector", "tokens": [39715, 365, 746, 1219, 30262, 420, 2167, 3347, 25712], "temperature": 0.0, "avg_logprob": -0.29000042102955004, "compression_ratio": 1.4049079754601228, "no_speech_prob": 2.482466925357585e-06}, {"id": 438, "seek": 205066, "start": 2065.5, "end": 2073.2999999999997, "text": " What I will say is that since these things came out at very similar times in late 2015", "tokens": [708, 286, 486, 584, 307, 300, 1670, 613, 721, 1361, 484, 412, 588, 2531, 1413, 294, 3469, 7546], "temperature": 0.0, "avg_logprob": -0.29000042102955004, "compression_ratio": 1.4049079754601228, "no_speech_prob": 2.482466925357585e-06}, {"id": 439, "seek": 205066, "start": 2076.5, "end": 2078.5, "text": " Things are very much moved towards", "tokens": [9514, 366, 588, 709, 4259, 3030], "temperature": 0.0, "avg_logprob": -0.29000042102955004, "compression_ratio": 1.4049079754601228, "no_speech_prob": 2.482466925357585e-06}, {"id": 440, "seek": 207850, "start": 2078.5, "end": 2081.58, "text": " Here to the point where this morning", "tokens": [1692, 281, 264, 935, 689, 341, 2446], "temperature": 0.0, "avg_logprob": -0.2956685775365585, "compression_ratio": 1.5357142857142858, "no_speech_prob": 5.255333690001862e-06}, {"id": 441, "seek": 207850, "start": 2082.94, "end": 2086.58, "text": " Yolo version 3 came out and is now doing it", "tokens": [398, 7902, 3037, 805, 1361, 484, 293, 307, 586, 884, 309], "temperature": 0.0, "avg_logprob": -0.2956685775365585, "compression_ratio": 1.5357142857142858, "no_speech_prob": 5.255333690001862e-06}, {"id": 442, "seek": 207850, "start": 2087.5, "end": 2089.5, "text": " Yes, SD", "tokens": [1079, 11, 14638], "temperature": 0.0, "avg_logprob": -0.2956685775365585, "compression_ratio": 1.5357142857142858, "no_speech_prob": 5.255333690001862e-06}, {"id": 443, "seek": 207850, "start": 2089.5, "end": 2093.94, "text": " Okay, so that's what we're going to do. All right, we're going to do this and we're going to learn about", "tokens": [1033, 11, 370, 300, 311, 437, 321, 434, 516, 281, 360, 13, 1057, 558, 11, 321, 434, 516, 281, 360, 341, 293, 321, 434, 516, 281, 1466, 466], "temperature": 0.0, "avg_logprob": -0.2956685775365585, "compression_ratio": 1.5357142857142858, "no_speech_prob": 5.255333690001862e-06}, {"id": 444, "seek": 207850, "start": 2094.7, "end": 2098.26, "text": " Why this makes more sense as well?", "tokens": [1545, 341, 1669, 544, 2020, 382, 731, 30], "temperature": 0.0, "avg_logprob": -0.2956685775365585, "compression_ratio": 1.5357142857142858, "no_speech_prob": 5.255333690001862e-06}, {"id": 445, "seek": 207850, "start": 2104.1, "end": 2106.1, "text": " And so the basic idea is this", "tokens": [400, 370, 264, 3875, 1558, 307, 341], "temperature": 0.0, "avg_logprob": -0.2956685775365585, "compression_ratio": 1.5357142857142858, "no_speech_prob": 5.255333690001862e-06}, {"id": 446, "seek": 210610, "start": 2106.1, "end": 2111.22, "text": " Let's imagine that on top of underneath this we had another", "tokens": [961, 311, 3811, 300, 322, 1192, 295, 7223, 341, 321, 632, 1071], "temperature": 0.0, "avg_logprob": -0.3855621264531062, "compression_ratio": 1.296875, "no_speech_prob": 4.2892611418210436e-06}, {"id": 447, "seek": 210610, "start": 2114.2599999999998, "end": 2116.2599999999998, "text": " Another conv2d", "tokens": [3996, 3754, 17, 67], "temperature": 0.0, "avg_logprob": -0.3855621264531062, "compression_ratio": 1.296875, "no_speech_prob": 4.2892611418210436e-06}, {"id": 448, "seek": 210610, "start": 2121.38, "end": 2123.38, "text": " Strive to", "tokens": [745, 8003, 281], "temperature": 0.0, "avg_logprob": -0.3855621264531062, "compression_ratio": 1.296875, "no_speech_prob": 4.2892611418210436e-06}, {"id": 449, "seek": 210610, "start": 2126.62, "end": 2131.7, "text": " Then we'd have something which was two by two by again, let's say it's", "tokens": [1396, 321, 1116, 362, 746, 597, 390, 732, 538, 732, 538, 797, 11, 718, 311, 584, 309, 311], "temperature": 0.0, "avg_logprob": -0.3855621264531062, "compression_ratio": 1.296875, "no_speech_prob": 4.2892611418210436e-06}, {"id": 450, "seek": 210610, "start": 2132.98, "end": 2134.98, "text": " for plus C", "tokens": [337, 1804, 383], "temperature": 0.0, "avg_logprob": -0.3855621264531062, "compression_ratio": 1.296875, "no_speech_prob": 4.2892611418210436e-06}, {"id": 451, "seek": 213498, "start": 2134.98, "end": 2140.52, "text": " All right, that's nice and simple. And so basically it's creating a grid", "tokens": [1057, 558, 11, 300, 311, 1481, 293, 2199, 13, 400, 370, 1936, 309, 311, 4084, 257, 10748], "temperature": 0.0, "avg_logprob": -0.23841061909993488, "compression_ratio": 1.6162162162162161, "no_speech_prob": 4.425453425938031e-06}, {"id": 452, "seek": 213498, "start": 2141.34, "end": 2143.86, "text": " That looks something like this one, two, three", "tokens": [663, 1542, 746, 411, 341, 472, 11, 732, 11, 1045], "temperature": 0.0, "avg_logprob": -0.23841061909993488, "compression_ratio": 1.6162162162162161, "no_speech_prob": 4.425453425938031e-06}, {"id": 453, "seek": 213498, "start": 2144.82, "end": 2146.26, "text": " four", "tokens": [1451], "temperature": 0.0, "avg_logprob": -0.23841061909993488, "compression_ratio": 1.6162162162162161, "no_speech_prob": 4.425453425938031e-06}, {"id": 454, "seek": 213498, "start": 2146.26, "end": 2149.62, "text": " Okay, so that would be like how the activations are", "tokens": [1033, 11, 370, 300, 576, 312, 411, 577, 264, 2430, 763, 366], "temperature": 0.0, "avg_logprob": -0.23841061909993488, "compression_ratio": 1.6162162162162161, "no_speech_prob": 4.425453425938031e-06}, {"id": 455, "seek": 213498, "start": 2151.1, "end": 2159.04, "text": " You know the geometry of the activations of that second extra convolutional stride to layer remember stride to convolution", "tokens": [509, 458, 264, 18426, 295, 264, 2430, 763, 295, 300, 1150, 2857, 45216, 304, 1056, 482, 281, 4583, 1604, 1056, 482, 281, 45216], "temperature": 0.0, "avg_logprob": -0.23841061909993488, "compression_ratio": 1.6162162162162161, "no_speech_prob": 4.425453425938031e-06}, {"id": 456, "seek": 215904, "start": 2159.04, "end": 2166.2799999999997, "text": " Does the same thing to the geometry of the activations as a stripe one convolution followed by a max pooling?", "tokens": [4402, 264, 912, 551, 281, 264, 18426, 295, 264, 2430, 763, 382, 257, 42957, 472, 45216, 6263, 538, 257, 11469, 7005, 278, 30], "temperature": 0.0, "avg_logprob": -0.2768390443589952, "compression_ratio": 1.52, "no_speech_prob": 6.339138963085134e-06}, {"id": 457, "seek": 215904, "start": 2169.44, "end": 2176.72, "text": " So let's talk about what we might do here because the basic idea is like we want to kind of say all right this", "tokens": [407, 718, 311, 751, 466, 437, 321, 1062, 360, 510, 570, 264, 3875, 1558, 307, 411, 321, 528, 281, 733, 295, 584, 439, 558, 341], "temperature": 0.0, "avg_logprob": -0.2768390443589952, "compression_ratio": 1.52, "no_speech_prob": 6.339138963085134e-06}, {"id": 458, "seek": 215904, "start": 2177.52, "end": 2184.4, "text": " Top left grid cell is responsible for identifying any object that's in the top left", "tokens": [8840, 1411, 10748, 2815, 307, 6250, 337, 16696, 604, 2657, 300, 311, 294, 264, 1192, 1411], "temperature": 0.0, "avg_logprob": -0.2768390443589952, "compression_ratio": 1.52, "no_speech_prob": 6.339138963085134e-06}, {"id": 459, "seek": 218440, "start": 2184.4, "end": 2189.76, "text": " And this one in the top right is responsible for identifying something in the top right this one bottom left", "tokens": [400, 341, 472, 294, 264, 1192, 558, 307, 6250, 337, 16696, 746, 294, 264, 1192, 558, 341, 472, 2767, 1411], "temperature": 0.0, "avg_logprob": -0.24121943974899032, "compression_ratio": 1.8754716981132076, "no_speech_prob": 9.666013284004293e-06}, {"id": 460, "seek": 218440, "start": 2189.96, "end": 2192.56, "text": " This one the bottom right, okay", "tokens": [639, 472, 264, 2767, 558, 11, 1392], "temperature": 0.0, "avg_logprob": -0.24121943974899032, "compression_ratio": 1.8754716981132076, "no_speech_prob": 9.666013284004293e-06}, {"id": 461, "seek": 218440, "start": 2192.56, "end": 2195.56, "text": " So in this case you can actually see it started it said okay", "tokens": [407, 294, 341, 1389, 291, 393, 767, 536, 309, 1409, 309, 848, 1392], "temperature": 0.0, "avg_logprob": -0.24121943974899032, "compression_ratio": 1.8754716981132076, "no_speech_prob": 9.666013284004293e-06}, {"id": 462, "seek": 218440, "start": 2195.56, "end": 2198.7400000000002, "text": " This one is going to try and find the chair this one", "tokens": [639, 472, 307, 516, 281, 853, 293, 915, 264, 6090, 341, 472], "temperature": 0.0, "avg_logprob": -0.24121943974899032, "compression_ratio": 1.8754716981132076, "no_speech_prob": 9.666013284004293e-06}, {"id": 463, "seek": 218440, "start": 2198.7400000000002, "end": 2203.6600000000003, "text": " It's actually made a mistake should have said table, but there are actually one two three chairs here as well", "tokens": [467, 311, 767, 1027, 257, 6146, 820, 362, 848, 3199, 11, 457, 456, 366, 767, 472, 732, 1045, 18299, 510, 382, 731], "temperature": 0.0, "avg_logprob": -0.24121943974899032, "compression_ratio": 1.8754716981132076, "no_speech_prob": 9.666013284004293e-06}, {"id": 464, "seek": 218440, "start": 2203.6600000000003, "end": 2207.32, "text": " So makes sense right so basically each of these grid cells", "tokens": [407, 1669, 2020, 558, 370, 1936, 1184, 295, 613, 10748, 5438], "temperature": 0.0, "avg_logprob": -0.24121943974899032, "compression_ratio": 1.8754716981132076, "no_speech_prob": 9.666013284004293e-06}, {"id": 465, "seek": 218440, "start": 2208.1600000000003, "end": 2213.48, "text": " It's going to be told in the loss function your job is to find the object", "tokens": [467, 311, 516, 281, 312, 1907, 294, 264, 4470, 2445, 428, 1691, 307, 281, 915, 264, 2657], "temperature": 0.0, "avg_logprob": -0.24121943974899032, "compression_ratio": 1.8754716981132076, "no_speech_prob": 9.666013284004293e-06}, {"id": 466, "seek": 221348, "start": 2213.48, "end": 2215.56, "text": " You know the big object that's in that", "tokens": [509, 458, 264, 955, 2657, 300, 311, 294, 300], "temperature": 0.0, "avg_logprob": -0.2752261161804199, "compression_ratio": 1.4078212290502794, "no_speech_prob": 1.4285321412899066e-05}, {"id": 467, "seek": 221348, "start": 2216.28, "end": 2218.28, "text": " part of the image", "tokens": [644, 295, 264, 3256], "temperature": 0.0, "avg_logprob": -0.2752261161804199, "compression_ratio": 1.4078212290502794, "no_speech_prob": 1.4285321412899066e-05}, {"id": 468, "seek": 221348, "start": 2218.8, "end": 2220.8, "text": " So what?", "tokens": [407, 437, 30], "temperature": 0.0, "avg_logprob": -0.2752261161804199, "compression_ratio": 1.4078212290502794, "no_speech_prob": 1.4285321412899066e-05}, {"id": 469, "seek": 221348, "start": 2222.68, "end": 2227.44, "text": " So for a multi-label classification I saw you had a threshold on there", "tokens": [407, 337, 257, 4825, 12, 75, 18657, 21538, 286, 1866, 291, 632, 257, 14678, 322, 456], "temperature": 0.0, "avg_logprob": -0.2752261161804199, "compression_ratio": 1.4078212290502794, "no_speech_prob": 1.4285321412899066e-05}, {"id": 470, "seek": 221348, "start": 2228.0, "end": 2234.28, "text": " Which I guess is a hyper parameter is there a way we're getting your well ahead. Let's let's work through this", "tokens": [3013, 286, 2041, 307, 257, 9848, 13075, 307, 456, 257, 636, 321, 434, 1242, 428, 731, 2286, 13, 961, 311, 718, 311, 589, 807, 341], "temperature": 0.0, "avg_logprob": -0.2752261161804199, "compression_ratio": 1.4078212290502794, "no_speech_prob": 1.4285321412899066e-05}, {"id": 471, "seek": 221348, "start": 2235.28, "end": 2237.28, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.2752261161804199, "compression_ratio": 1.4078212290502794, "no_speech_prob": 1.4285321412899066e-05}, {"id": 472, "seek": 223728, "start": 2237.28, "end": 2245.28, "text": " All right, so why do we care about the idea that we would like this", "tokens": [1057, 558, 11, 370, 983, 360, 321, 1127, 466, 264, 1558, 300, 321, 576, 411, 341], "temperature": 0.0, "avg_logprob": -0.195870361328125, "compression_ratio": 1.6938775510204083, "no_speech_prob": 4.15732347391895e-06}, {"id": 473, "seek": 223728, "start": 2245.6800000000003, "end": 2250.76, "text": " convolutional grid cell to be responsible for finding things that were in this part of the image and", "tokens": [45216, 304, 10748, 2815, 281, 312, 6250, 337, 5006, 721, 300, 645, 294, 341, 644, 295, 264, 3256, 293], "temperature": 0.0, "avg_logprob": -0.195870361328125, "compression_ratio": 1.6938775510204083, "no_speech_prob": 4.15732347391895e-06}, {"id": 474, "seek": 223728, "start": 2251.1200000000003, "end": 2258.44, "text": " The reason is because of something called the receptive field of that convolutional grid cell and the basic idea is that", "tokens": [440, 1778, 307, 570, 295, 746, 1219, 264, 45838, 2519, 295, 300, 45216, 304, 10748, 2815, 293, 264, 3875, 1558, 307, 300], "temperature": 0.0, "avg_logprob": -0.195870361328125, "compression_ratio": 1.6938775510204083, "no_speech_prob": 4.15732347391895e-06}, {"id": 475, "seek": 223728, "start": 2259.0400000000004, "end": 2261.0400000000004, "text": " throughout your convolutional layers", "tokens": [3710, 428, 45216, 304, 7914], "temperature": 0.0, "avg_logprob": -0.195870361328125, "compression_ratio": 1.6938775510204083, "no_speech_prob": 4.15732347391895e-06}, {"id": 476, "seek": 223728, "start": 2261.6400000000003, "end": 2263.0, "text": " every", "tokens": [633], "temperature": 0.0, "avg_logprob": -0.195870361328125, "compression_ratio": 1.6938775510204083, "no_speech_prob": 4.15732347391895e-06}, {"id": 477, "seek": 226300, "start": 2263.0, "end": 2269.48, "text": " Every piece of those tensors has a receptive field which means which part of the", "tokens": [2048, 2522, 295, 729, 10688, 830, 575, 257, 45838, 2519, 597, 1355, 597, 644, 295, 264], "temperature": 0.0, "avg_logprob": -0.27089662694219335, "compression_ratio": 1.4756756756756757, "no_speech_prob": 3.844910679617897e-06}, {"id": 478, "seek": 226300, "start": 2270.4, "end": 2274.04, "text": " Input image was responsible for calculating", "tokens": [682, 2582, 3256, 390, 6250, 337, 28258], "temperature": 0.0, "avg_logprob": -0.27089662694219335, "compression_ratio": 1.4756756756756757, "no_speech_prob": 3.844910679617897e-06}, {"id": 479, "seek": 226300, "start": 2274.48, "end": 2280.48, "text": " That cell right and like all things in life the easiest way to see this is with Microsoft Excel", "tokens": [663, 2815, 558, 293, 411, 439, 721, 294, 993, 264, 12889, 636, 281, 536, 341, 307, 365, 8116, 19060], "temperature": 0.0, "avg_logprob": -0.27089662694219335, "compression_ratio": 1.4756756756756757, "no_speech_prob": 3.844910679617897e-06}, {"id": 480, "seek": 226300, "start": 2281.64, "end": 2283.64, "text": " So do you remember?", "tokens": [407, 360, 291, 1604, 30], "temperature": 0.0, "avg_logprob": -0.27089662694219335, "compression_ratio": 1.4756756756756757, "no_speech_prob": 3.844910679617897e-06}, {"id": 481, "seek": 226300, "start": 2284.44, "end": 2286.52, "text": " our convolutional neural net", "tokens": [527, 45216, 304, 18161, 2533], "temperature": 0.0, "avg_logprob": -0.27089662694219335, "compression_ratio": 1.4756756756756757, "no_speech_prob": 3.844910679617897e-06}, {"id": 482, "seek": 226300, "start": 2287.32, "end": 2288.56, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.27089662694219335, "compression_ratio": 1.4756756756756757, "no_speech_prob": 3.844910679617897e-06}, {"id": 483, "seek": 228856, "start": 2288.56, "end": 2292.92, "text": " this was endless and we had the number seven and it went through a a", "tokens": [341, 390, 16144, 293, 321, 632, 264, 1230, 3407, 293, 309, 1437, 807, 257, 257], "temperature": 0.0, "avg_logprob": -0.2826490255502554, "compression_ratio": 1.5654761904761905, "no_speech_prob": 5.422175036073895e-06}, {"id": 484, "seek": 228856, "start": 2296.84, "end": 2302.2, "text": " Two channel filter channel one channel two, right which therefore created a", "tokens": [4453, 2269, 6608, 2269, 472, 2269, 732, 11, 558, 597, 4412, 2942, 257], "temperature": 0.0, "avg_logprob": -0.2826490255502554, "compression_ratio": 1.5654761904761905, "no_speech_prob": 5.422175036073895e-06}, {"id": 485, "seek": 228856, "start": 2303.08, "end": 2305.08, "text": " two channel output", "tokens": [732, 2269, 5598], "temperature": 0.0, "avg_logprob": -0.2826490255502554, "compression_ratio": 1.5654761904761905, "no_speech_prob": 5.422175036073895e-06}, {"id": 486, "seek": 228856, "start": 2305.88, "end": 2312.0, "text": " All right, and then the next layer was another convolution. So this tensor is now a 3d tensor", "tokens": [1057, 558, 11, 293, 550, 264, 958, 4583, 390, 1071, 45216, 13, 407, 341, 40863, 307, 586, 257, 805, 67, 40863], "temperature": 0.0, "avg_logprob": -0.2826490255502554, "compression_ratio": 1.5654761904761905, "no_speech_prob": 5.422175036073895e-06}, {"id": 487, "seek": 228856, "start": 2312.56, "end": 2314.44, "text": " right", "tokens": [558], "temperature": 0.0, "avg_logprob": -0.2826490255502554, "compression_ratio": 1.5654761904761905, "no_speech_prob": 5.422175036073895e-06}, {"id": 488, "seek": 231444, "start": 2314.44, "end": 2322.48, "text": " Which then creates a again two channel output and then after that we had our max pooling player", "tokens": [3013, 550, 7829, 257, 797, 732, 2269, 5598, 293, 550, 934, 300, 321, 632, 527, 11469, 7005, 278, 4256], "temperature": 0.0, "avg_logprob": -0.23952093789743822, "compression_ratio": 1.5358851674641147, "no_speech_prob": 1.300689018535195e-05}, {"id": 489, "seek": 231444, "start": 2324.16, "end": 2325.6, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.23952093789743822, "compression_ratio": 1.5358851674641147, "no_speech_prob": 1.300689018535195e-05}, {"id": 490, "seek": 231444, "start": 2325.6, "end": 2331.28, "text": " Let's look at this part of this output and the fact that this is common followed by max pool", "tokens": [961, 311, 574, 412, 341, 644, 295, 341, 5598, 293, 264, 1186, 300, 341, 307, 2689, 6263, 538, 11469, 7005], "temperature": 0.0, "avg_logprob": -0.23952093789743822, "compression_ratio": 1.5358851674641147, "no_speech_prob": 1.300689018535195e-05}, {"id": 491, "seek": 231444, "start": 2331.28, "end": 2334.2000000000003, "text": " Let's just pretend as a stride to con. It's basically the same", "tokens": [961, 311, 445, 11865, 382, 257, 1056, 482, 281, 416, 13, 467, 311, 1936, 264, 912], "temperature": 0.0, "avg_logprob": -0.23952093789743822, "compression_ratio": 1.5358851674641147, "no_speech_prob": 1.300689018535195e-05}, {"id": 492, "seek": 231444, "start": 2336.28, "end": 2339.96, "text": " So let's see where this number 27", "tokens": [407, 718, 311, 536, 689, 341, 1230, 7634], "temperature": 0.0, "avg_logprob": -0.23952093789743822, "compression_ratio": 1.5358851674641147, "no_speech_prob": 1.300689018535195e-05}, {"id": 493, "seek": 231444, "start": 2341.0, "end": 2343.0, "text": " Came from so if you've got Excel", "tokens": [36042, 490, 370, 498, 291, 600, 658, 19060], "temperature": 0.0, "avg_logprob": -0.23952093789743822, "compression_ratio": 1.5358851674641147, "no_speech_prob": 1.300689018535195e-05}, {"id": 494, "seek": 234300, "start": 2343.0, "end": 2347.4, "text": " You can go formulas trace precedence right and so you can see this", "tokens": [509, 393, 352, 30546, 13508, 16969, 655, 558, 293, 370, 291, 393, 536, 341], "temperature": 0.0, "avg_logprob": -0.3631275116451203, "compression_ratio": 1.5723684210526316, "no_speech_prob": 9.368613973492756e-06}, {"id": 495, "seek": 234300, "start": 2348.04, "end": 2349.52, "text": " came from", "tokens": [1361, 490], "temperature": 0.0, "avg_logprob": -0.3631275116451203, "compression_ratio": 1.5723684210526316, "no_speech_prob": 9.368613973492756e-06}, {"id": 496, "seek": 234300, "start": 2349.52, "end": 2350.64, "text": " these", "tokens": [613], "temperature": 0.0, "avg_logprob": -0.3631275116451203, "compression_ratio": 1.5723684210526316, "no_speech_prob": 9.368613973492756e-06}, {"id": 497, "seek": 234300, "start": 2350.64, "end": 2354.8, "text": " Four okay now where did those four come from?", "tokens": [7451, 1392, 586, 689, 630, 729, 1451, 808, 490, 30], "temperature": 0.0, "avg_logprob": -0.3631275116451203, "compression_ratio": 1.5723684210526316, "no_speech_prob": 9.368613973492756e-06}, {"id": 498, "seek": 234300, "start": 2357.16, "end": 2362.8, "text": " Those four came from obviously the convolutional filter", "tokens": [3950, 1451, 1361, 490, 2745, 264, 45216, 304, 6608], "temperature": 0.0, "avg_logprob": -0.3631275116451203, "compression_ratio": 1.5723684210526316, "no_speech_prob": 9.368613973492756e-06}, {"id": 499, "seek": 234300, "start": 2364.28, "end": 2366.28, "text": " kernel the panels and", "tokens": [28256, 264, 13419, 293], "temperature": 0.0, "avg_logprob": -0.3631275116451203, "compression_ratio": 1.5723684210526316, "no_speech_prob": 9.368613973492756e-06}, {"id": 500, "seek": 234300, "start": 2367.12, "end": 2370.34, "text": " from these four parts of con one", "tokens": [490, 613, 1451, 3166, 295, 416, 472], "temperature": 0.0, "avg_logprob": -0.3631275116451203, "compression_ratio": 1.5723684210526316, "no_speech_prob": 9.368613973492756e-06}, {"id": 501, "seek": 237034, "start": 2370.34, "end": 2372.78, "text": " All right, because we've got", "tokens": [1057, 558, 11, 570, 321, 600, 658], "temperature": 0.0, "avg_logprob": -0.38313929239908856, "compression_ratio": 1.5320512820512822, "no_speech_prob": 1.2029482604702935e-05}, {"id": 502, "seek": 237034, "start": 2373.54, "end": 2380.46, "text": " Four things here each one of which has a three by three filter. And so we had three three three three", "tokens": [7451, 721, 510, 1184, 472, 295, 597, 575, 257, 1045, 538, 1045, 6608, 13, 400, 370, 321, 632, 1045, 1045, 1045, 1045], "temperature": 0.0, "avg_logprob": -0.38313929239908856, "compression_ratio": 1.5320512820512822, "no_speech_prob": 1.2029482604702935e-05}, {"id": 503, "seek": 237034, "start": 2381.7000000000003, "end": 2383.7000000000003, "text": " together makes up for that for", "tokens": [1214, 1669, 493, 337, 300, 337], "temperature": 0.0, "avg_logprob": -0.38313929239908856, "compression_ratio": 1.5320512820512822, "no_speech_prob": 1.2029482604702935e-05}, {"id": 504, "seek": 237034, "start": 2384.1400000000003, "end": 2386.1400000000003, "text": " Where did those four come from?", "tokens": [2305, 630, 729, 1451, 808, 490, 30], "temperature": 0.0, "avg_logprob": -0.38313929239908856, "compression_ratio": 1.5320512820512822, "no_speech_prob": 1.2029482604702935e-05}, {"id": 505, "seek": 237034, "start": 2388.94, "end": 2391.1000000000004, "text": " Those four came from", "tokens": [3950, 1451, 1361, 490], "temperature": 0.0, "avg_logprob": -0.38313929239908856, "compression_ratio": 1.5320512820512822, "no_speech_prob": 1.2029482604702935e-05}, {"id": 506, "seek": 237034, "start": 2393.06, "end": 2395.06, "text": " Obviously our", "tokens": [7580, 527], "temperature": 0.0, "avg_logprob": -0.38313929239908856, "compression_ratio": 1.5320512820512822, "no_speech_prob": 1.2029482604702935e-05}, {"id": 507, "seek": 237034, "start": 2395.6200000000003, "end": 2397.6200000000003, "text": " Filter and", "tokens": [39592, 293], "temperature": 0.0, "avg_logprob": -0.38313929239908856, "compression_ratio": 1.5320512820512822, "no_speech_prob": 1.2029482604702935e-05}, {"id": 508, "seek": 239762, "start": 2397.62, "end": 2399.74, "text": " This entire part of the input image", "tokens": [639, 2302, 644, 295, 264, 4846, 3256], "temperature": 0.0, "avg_logprob": -0.406402587890625, "compression_ratio": 1.6780487804878048, "no_speech_prob": 2.9944155812700046e-06}, {"id": 509, "seek": 239762, "start": 2401.74, "end": 2408.8599999999997, "text": " Okay, and what's more you can see and it also comes through this whole direction as well, right and you can see that", "tokens": [1033, 11, 293, 437, 311, 544, 291, 393, 536, 293, 309, 611, 1487, 807, 341, 1379, 3513, 382, 731, 11, 558, 293, 291, 393, 536, 300], "temperature": 0.0, "avg_logprob": -0.406402587890625, "compression_ratio": 1.6780487804878048, "no_speech_prob": 2.9944155812700046e-06}, {"id": 510, "seek": 239762, "start": 2409.8199999999997, "end": 2414.14, "text": " These bits in the middle have lots of weights coming out", "tokens": [1981, 9239, 294, 264, 2808, 362, 3195, 295, 17443, 1348, 484], "temperature": 0.0, "avg_logprob": -0.406402587890625, "compression_ratio": 1.6780487804878048, "no_speech_prob": 2.9944155812700046e-06}, {"id": 511, "seek": 239762, "start": 2414.7, "end": 2418.1, "text": " Right where else these bits on the outside only have one weight coming out", "tokens": [1779, 689, 1646, 613, 9239, 322, 264, 2380, 787, 362, 472, 3364, 1348, 484], "temperature": 0.0, "avg_logprob": -0.406402587890625, "compression_ratio": 1.6780487804878048, "no_speech_prob": 2.9944155812700046e-06}, {"id": 512, "seek": 239762, "start": 2418.1, "end": 2422.06, "text": " So we call this here the receptive field of", "tokens": [407, 321, 818, 341, 510, 264, 45838, 2519, 295], "temperature": 0.0, "avg_logprob": -0.406402587890625, "compression_ratio": 1.6780487804878048, "no_speech_prob": 2.9944155812700046e-06}, {"id": 513, "seek": 239762, "start": 2423.94, "end": 2425.94, "text": " This activation", "tokens": [639, 24433], "temperature": 0.0, "avg_logprob": -0.406402587890625, "compression_ratio": 1.6780487804878048, "no_speech_prob": 2.9944155812700046e-06}, {"id": 514, "seek": 242594, "start": 2425.94, "end": 2427.5, "text": " this activation", "tokens": [341, 24433], "temperature": 0.0, "avg_logprob": -0.260493065329159, "compression_ratio": 1.7161572052401746, "no_speech_prob": 6.747997304046294e-06}, {"id": 515, "seek": 242594, "start": 2427.5, "end": 2430.86, "text": " Right, but note that the receptive field is not just saying", "tokens": [1779, 11, 457, 3637, 300, 264, 45838, 2519, 307, 406, 445, 1566], "temperature": 0.0, "avg_logprob": -0.260493065329159, "compression_ratio": 1.7161572052401746, "no_speech_prob": 6.747997304046294e-06}, {"id": 516, "seek": 242594, "start": 2431.9, "end": 2439.04, "text": " It's this here box, but also that the center of the box has more dependencies", "tokens": [467, 311, 341, 510, 2424, 11, 457, 611, 300, 264, 3056, 295, 264, 2424, 575, 544, 36606], "temperature": 0.0, "avg_logprob": -0.260493065329159, "compression_ratio": 1.7161572052401746, "no_speech_prob": 6.747997304046294e-06}, {"id": 517, "seek": 242594, "start": 2440.7000000000003, "end": 2445.62, "text": " Okay, so this is a critically important concept when it comes to kind of understanding", "tokens": [1033, 11, 370, 341, 307, 257, 22797, 1021, 3410, 562, 309, 1487, 281, 733, 295, 3701], "temperature": 0.0, "avg_logprob": -0.260493065329159, "compression_ratio": 1.7161572052401746, "no_speech_prob": 6.747997304046294e-06}, {"id": 518, "seek": 242594, "start": 2446.3, "end": 2448.3, "text": " architectures and understanding why", "tokens": [6331, 1303, 293, 3701, 983], "temperature": 0.0, "avg_logprob": -0.260493065329159, "compression_ratio": 1.7161572052401746, "no_speech_prob": 6.747997304046294e-06}, {"id": 519, "seek": 244830, "start": 2448.3, "end": 2455.98, "text": " Convents work the idea of the receptive field and there are some great articles if you just google for convolution receptive field", "tokens": [2656, 85, 791, 589, 264, 1558, 295, 264, 45838, 2519, 293, 456, 366, 512, 869, 11290, 498, 291, 445, 20742, 337, 45216, 45838, 2519], "temperature": 0.0, "avg_logprob": -0.1840057758369831, "compression_ratio": 1.7303370786516854, "no_speech_prob": 7.071799245750299e-06}, {"id": 520, "seek": 244830, "start": 2455.98, "end": 2462.46, "text": " You can find lots of terrific articles. I'm sure some of you will write much better ones during the week as well", "tokens": [509, 393, 915, 3195, 295, 20899, 11290, 13, 286, 478, 988, 512, 295, 291, 486, 2464, 709, 1101, 2306, 1830, 264, 1243, 382, 731], "temperature": 0.0, "avg_logprob": -0.1840057758369831, "compression_ratio": 1.7303370786516854, "no_speech_prob": 7.071799245750299e-06}, {"id": 521, "seek": 244830, "start": 2463.5800000000004, "end": 2470.38, "text": " So that's the basic idea. All right, is that the receptive field of this convolutional activation is", "tokens": [407, 300, 311, 264, 3875, 1558, 13, 1057, 558, 11, 307, 300, 264, 45838, 2519, 295, 341, 45216, 304, 24433, 307], "temperature": 0.0, "avg_logprob": -0.1840057758369831, "compression_ratio": 1.7303370786516854, "no_speech_prob": 7.071799245750299e-06}, {"id": 522, "seek": 247038, "start": 2470.38, "end": 2477.46, "text": " Generally centered around this part of the input image. So it should be responsible for finding objects that are here", "tokens": [21082, 18988, 926, 341, 644, 295, 264, 4846, 3256, 13, 407, 309, 820, 312, 6250, 337, 5006, 6565, 300, 366, 510], "temperature": 0.0, "avg_logprob": -0.18780269417711484, "compression_ratio": 1.6311111111111112, "no_speech_prob": 4.785058536072029e-06}, {"id": 523, "seek": 247038, "start": 2478.86, "end": 2480.34, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.18780269417711484, "compression_ratio": 1.6311111111111112, "no_speech_prob": 4.785058536072029e-06}, {"id": 524, "seek": 247038, "start": 2480.34, "end": 2482.34, "text": " That's the architecture", "tokens": [663, 311, 264, 9482], "temperature": 0.0, "avg_logprob": -0.18780269417711484, "compression_ratio": 1.6311111111111112, "no_speech_prob": 4.785058536072029e-06}, {"id": 525, "seek": 247038, "start": 2482.7000000000003, "end": 2488.1400000000003, "text": " The architecture is that we're going to have a resnet backbone followed by one or more", "tokens": [440, 9482, 307, 300, 321, 434, 516, 281, 362, 257, 725, 7129, 34889, 6263, 538, 472, 420, 544], "temperature": 0.0, "avg_logprob": -0.18780269417711484, "compression_ratio": 1.6311111111111112, "no_speech_prob": 4.785058536072029e-06}, {"id": 526, "seek": 247038, "start": 2488.82, "end": 2493.82, "text": " 2d convolutions and for now we're just going to do one right which is going to give us a four by four", "tokens": [568, 67, 3754, 15892, 293, 337, 586, 321, 434, 445, 516, 281, 360, 472, 558, 597, 307, 516, 281, 976, 505, 257, 1451, 538, 1451], "temperature": 0.0, "avg_logprob": -0.18780269417711484, "compression_ratio": 1.6311111111111112, "no_speech_prob": 4.785058536072029e-06}, {"id": 527, "seek": 247038, "start": 2494.78, "end": 2496.78, "text": " grid", "tokens": [10748], "temperature": 0.0, "avg_logprob": -0.18780269417711484, "compression_ratio": 1.6311111111111112, "no_speech_prob": 4.785058536072029e-06}, {"id": 528, "seek": 249678, "start": 2496.78, "end": 2500.3, "text": " And so let's take a look at that so", "tokens": [400, 370, 718, 311, 747, 257, 574, 412, 300, 370], "temperature": 0.0, "avg_logprob": -0.3382606506347656, "compression_ratio": 1.5266666666666666, "no_speech_prob": 1.1842911590065341e-05}, {"id": 529, "seek": 249678, "start": 2505.86, "end": 2509.6600000000003, "text": " Here it is we start with our value and dropout", "tokens": [1692, 309, 307, 321, 722, 365, 527, 2158, 293, 3270, 346], "temperature": 0.0, "avg_logprob": -0.3382606506347656, "compression_ratio": 1.5266666666666666, "no_speech_prob": 1.1842911590065341e-05}, {"id": 530, "seek": 249678, "start": 2511.0600000000004, "end": 2514.42, "text": " We then do let's just start at the output", "tokens": [492, 550, 360, 718, 311, 445, 722, 412, 264, 5598], "temperature": 0.0, "avg_logprob": -0.3382606506347656, "compression_ratio": 1.5266666666666666, "no_speech_prob": 1.1842911590065341e-05}, {"id": 531, "seek": 249678, "start": 2517.02, "end": 2520.5400000000004, "text": " Well, I just go through and see what we've got here this one's not being used", "tokens": [1042, 11, 286, 445, 352, 807, 293, 536, 437, 321, 600, 658, 510, 341, 472, 311, 406, 885, 1143], "temperature": 0.0, "avg_logprob": -0.3382606506347656, "compression_ratio": 1.5266666666666666, "no_speech_prob": 1.1842911590065341e-05}, {"id": 532, "seek": 252054, "start": 2520.54, "end": 2526.2, "text": " We start with a stride one", "tokens": [492, 722, 365, 257, 1056, 482, 472], "temperature": 0.0, "avg_logprob": -0.22945524397350492, "compression_ratio": 1.6119402985074627, "no_speech_prob": 1.0289355486747809e-05}, {"id": 533, "seek": 252054, "start": 2526.98, "end": 2531.94, "text": " Convolution and the reason we start with a stride one convolution is because that doesn't change the geometry at all", "tokens": [2656, 85, 3386, 293, 264, 1778, 321, 722, 365, 257, 1056, 482, 472, 45216, 307, 570, 300, 1177, 380, 1319, 264, 18426, 412, 439], "temperature": 0.0, "avg_logprob": -0.22945524397350492, "compression_ratio": 1.6119402985074627, "no_speech_prob": 1.0289355486747809e-05}, {"id": 534, "seek": 252054, "start": 2531.94, "end": 2536.14, "text": " It just lets us add an extra layer of calculations", "tokens": [467, 445, 6653, 505, 909, 364, 2857, 4583, 295, 20448], "temperature": 0.0, "avg_logprob": -0.22945524397350492, "compression_ratio": 1.6119402985074627, "no_speech_prob": 1.0289355486747809e-05}, {"id": 535, "seek": 252054, "start": 2536.14, "end": 2541.44, "text": " Right, let's just create, you know, not just a linear layer. But now we have like a little mini", "tokens": [1779, 11, 718, 311, 445, 1884, 11, 291, 458, 11, 406, 445, 257, 8213, 4583, 13, 583, 586, 321, 362, 411, 257, 707, 8382], "temperature": 0.0, "avg_logprob": -0.22945524397350492, "compression_ratio": 1.6119402985074627, "no_speech_prob": 1.0289355486747809e-05}, {"id": 536, "seek": 252054, "start": 2542.14, "end": 2544.42, "text": " Neural network in our custom here", "tokens": [1734, 1807, 3209, 294, 527, 2375, 510], "temperature": 0.0, "avg_logprob": -0.22945524397350492, "compression_ratio": 1.6119402985074627, "no_speech_prob": 1.0289355486747809e-05}, {"id": 537, "seek": 254442, "start": 2544.42, "end": 2551.38, "text": " All right, so we start with a stride one convolution and standard con is just something I defined up here which does", "tokens": [1057, 558, 11, 370, 321, 722, 365, 257, 1056, 482, 472, 45216, 293, 3832, 416, 307, 445, 746, 286, 7642, 493, 510, 597, 775], "temperature": 0.0, "avg_logprob": -0.3478246296153349, "compression_ratio": 1.546448087431694, "no_speech_prob": 3.1381271128338994e-06}, {"id": 538, "seek": 254442, "start": 2552.06, "end": 2555.3, "text": " convolution value batch norm drop cut", "tokens": [45216, 2158, 15245, 2026, 3270, 1723], "temperature": 0.0, "avg_logprob": -0.3478246296153349, "compression_ratio": 1.546448087431694, "no_speech_prob": 3.1381271128338994e-06}, {"id": 539, "seek": 254442, "start": 2556.06, "end": 2558.06, "text": " like most", "tokens": [411, 881], "temperature": 0.0, "avg_logprob": -0.3478246296153349, "compression_ratio": 1.546448087431694, "no_speech_prob": 3.1381271128338994e-06}, {"id": 540, "seek": 254442, "start": 2558.1800000000003, "end": 2560.1800000000003, "text": " research code you see", "tokens": [2132, 3089, 291, 536], "temperature": 0.0, "avg_logprob": -0.3478246296153349, "compression_ratio": 1.546448087431694, "no_speech_prob": 3.1381271128338994e-06}, {"id": 541, "seek": 254442, "start": 2560.54, "end": 2567.1, "text": " Won't define a class like this instead. They'll write the entire thing again and again and again", "tokens": [14710, 380, 6964, 257, 1508, 411, 341, 2602, 13, 814, 603, 2464, 264, 2302, 551, 797, 293, 797, 293, 797], "temperature": 0.0, "avg_logprob": -0.3478246296153349, "compression_ratio": 1.546448087431694, "no_speech_prob": 3.1381271128338994e-06}, {"id": 542, "seek": 256710, "start": 2567.1, "end": 2574.58, "text": " Convolution batch norm drop cut. It's like don't be like that right like that kind of duplicate code leads to errors and", "tokens": [2656, 85, 3386, 15245, 2026, 3270, 1723, 13, 467, 311, 411, 500, 380, 312, 411, 300, 558, 411, 300, 733, 295, 23976, 3089, 6689, 281, 13603, 293], "temperature": 0.0, "avg_logprob": -0.26523022969563803, "compression_ratio": 1.619289340101523, "no_speech_prob": 5.422155936685158e-06}, {"id": 543, "seek": 256710, "start": 2575.2999999999997, "end": 2581.1, "text": " Leads to poor understanding and I mentioned that also because this week", "tokens": [1456, 5834, 281, 4716, 3701, 293, 286, 2835, 300, 611, 570, 341, 1243], "temperature": 0.0, "avg_logprob": -0.26523022969563803, "compression_ratio": 1.619289340101523, "no_speech_prob": 5.422155936685158e-06}, {"id": 544, "seek": 256710, "start": 2581.1, "end": 2586.06, "text": " I released the first draft of the fast AI style guide and", "tokens": [286, 4736, 264, 700, 11206, 295, 264, 2370, 7318, 3758, 5934, 293], "temperature": 0.0, "avg_logprob": -0.26523022969563803, "compression_ratio": 1.619289340101523, "no_speech_prob": 5.422155936685158e-06}, {"id": 545, "seek": 256710, "start": 2586.5, "end": 2591.12, "text": " The fast AI style guide is very heavily oriented towards the idea of", "tokens": [440, 2370, 7318, 3758, 5934, 307, 588, 10950, 21841, 3030, 264, 1558, 295], "temperature": 0.0, "avg_logprob": -0.26523022969563803, "compression_ratio": 1.619289340101523, "no_speech_prob": 5.422155936685158e-06}, {"id": 546, "seek": 259112, "start": 2591.12, "end": 2598.48, "text": " Expository programming which is the idea that programming code should be something that you can use to", "tokens": [21391, 9598, 827, 9410, 597, 307, 264, 1558, 300, 9410, 3089, 820, 312, 746, 300, 291, 393, 764, 281], "temperature": 0.0, "avg_logprob": -0.24186382554981806, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.939569852373097e-06}, {"id": 547, "seek": 259112, "start": 2599.7999999999997, "end": 2601.7999999999997, "text": " explain an idea", "tokens": [2903, 364, 1558], "temperature": 0.0, "avg_logprob": -0.24186382554981806, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.939569852373097e-06}, {"id": 548, "seek": 259112, "start": 2602.24, "end": 2604.24, "text": " ideally as readily as", "tokens": [22915, 382, 26336, 382], "temperature": 0.0, "avg_logprob": -0.24186382554981806, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.939569852373097e-06}, {"id": 549, "seek": 259112, "start": 2604.3199999999997, "end": 2606.52, "text": " mathematical notation to somebody that", "tokens": [18894, 24657, 281, 2618, 300], "temperature": 0.0, "avg_logprob": -0.24186382554981806, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.939569852373097e-06}, {"id": 550, "seek": 259112, "start": 2607.24, "end": 2614.44, "text": " understands your your coding method and so the idea actually goes back a very long way, but it was", "tokens": [15146, 428, 428, 17720, 3170, 293, 370, 264, 1558, 767, 1709, 646, 257, 588, 938, 636, 11, 457, 309, 390], "temperature": 0.0, "avg_logprob": -0.24186382554981806, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.939569852373097e-06}, {"id": 551, "seek": 259112, "start": 2615.44, "end": 2618.7599999999998, "text": " Best described in the Turing Award lecture", "tokens": [9752, 7619, 294, 264, 314, 1345, 13894, 7991], "temperature": 0.0, "avg_logprob": -0.24186382554981806, "compression_ratio": 1.6130653266331658, "no_speech_prob": 8.939569852373097e-06}, {"id": 552, "seek": 261876, "start": 2618.76, "end": 2622.2400000000002, "text": " This is like the Nobel computer science the Turing Award lecture of", "tokens": [639, 307, 411, 264, 24611, 3820, 3497, 264, 314, 1345, 13894, 7991, 295], "temperature": 0.0, "avg_logprob": -0.30480824241155313, "compression_ratio": 1.4884792626728112, "no_speech_prob": 1.280511605727952e-05}, {"id": 553, "seek": 261876, "start": 2622.8, "end": 2627.8, "text": " 1979 by probably my greatest computer science hero Ken Iverson", "tokens": [30595, 538, 1391, 452, 6636, 3820, 3497, 5316, 8273, 286, 840, 266], "temperature": 0.0, "avg_logprob": -0.30480824241155313, "compression_ratio": 1.4884792626728112, "no_speech_prob": 1.280511605727952e-05}, {"id": 554, "seek": 261876, "start": 2628.1600000000003, "end": 2633.96, "text": " He had been working on it since well well before 1964, but 1964 was the first", "tokens": [634, 632, 668, 1364, 322, 309, 1670, 731, 731, 949, 34314, 11, 457, 34314, 390, 264, 700], "temperature": 0.0, "avg_logprob": -0.30480824241155313, "compression_ratio": 1.4884792626728112, "no_speech_prob": 1.280511605727952e-05}, {"id": 555, "seek": 261876, "start": 2635.1600000000003, "end": 2638.96, "text": " Example of this approach to programming he released on called APL", "tokens": [24755, 781, 295, 341, 3109, 281, 9410, 415, 4736, 322, 1219, 5372, 43], "temperature": 0.0, "avg_logprob": -0.30480824241155313, "compression_ratio": 1.4884792626728112, "no_speech_prob": 1.280511605727952e-05}, {"id": 556, "seek": 261876, "start": 2639.8, "end": 2643.44, "text": " And then 25 years later, he won the Turing Award", "tokens": [400, 550, 3552, 924, 1780, 11, 415, 1582, 264, 314, 1345, 13894], "temperature": 0.0, "avg_logprob": -0.30480824241155313, "compression_ratio": 1.4884792626728112, "no_speech_prob": 1.280511605727952e-05}, {"id": 557, "seek": 264344, "start": 2643.44, "end": 2649.28, "text": " He then passed on the bat on to his son Eric Iverson and there's been basically", "tokens": [634, 550, 4678, 322, 264, 7362, 322, 281, 702, 1872, 9336, 286, 840, 266, 293, 456, 311, 668, 1936], "temperature": 0.0, "avg_logprob": -0.17905335677297493, "compression_ratio": 1.641350210970464, "no_speech_prob": 7.889144399086945e-06}, {"id": 558, "seek": 264344, "start": 2650.2400000000002, "end": 2656.48, "text": " 50 or 60 years now of continuous development of this idea of like what does programming look like when it's designed to", "tokens": [2625, 420, 4060, 924, 586, 295, 10957, 3250, 295, 341, 1558, 295, 411, 437, 775, 9410, 574, 411, 562, 309, 311, 4761, 281], "temperature": 0.0, "avg_logprob": -0.17905335677297493, "compression_ratio": 1.641350210970464, "no_speech_prob": 7.889144399086945e-06}, {"id": 559, "seek": 264344, "start": 2656.92, "end": 2658.92, "text": " to be a notation", "tokens": [281, 312, 257, 24657], "temperature": 0.0, "avg_logprob": -0.17905335677297493, "compression_ratio": 1.641350210970464, "no_speech_prob": 7.889144399086945e-06}, {"id": 560, "seek": 264344, "start": 2659.6, "end": 2663.44, "text": " notation as a tool for thought for expository programming and so", "tokens": [24657, 382, 257, 2290, 337, 1194, 337, 1278, 9598, 827, 9410, 293, 370], "temperature": 0.0, "avg_logprob": -0.17905335677297493, "compression_ratio": 1.641350210970464, "no_speech_prob": 7.889144399086945e-06}, {"id": 561, "seek": 264344, "start": 2664.4, "end": 2671.52, "text": " I've made a very shoddy attempt at taking some of these ideas and thinking about how can they be applied to", "tokens": [286, 600, 1027, 257, 588, 402, 378, 3173, 5217, 412, 1940, 512, 295, 613, 3487, 293, 1953, 466, 577, 393, 436, 312, 6456, 281], "temperature": 0.0, "avg_logprob": -0.17905335677297493, "compression_ratio": 1.641350210970464, "no_speech_prob": 7.889144399086945e-06}, {"id": 562, "seek": 267152, "start": 2671.52, "end": 2678.84, "text": " Python programming with all the limitations by comparison that Python has anyway, so", "tokens": [15329, 9410, 365, 439, 264, 15705, 538, 9660, 300, 15329, 575, 4033, 11, 370], "temperature": 0.0, "avg_logprob": -0.2499462127685547, "compression_ratio": 1.6824644549763033, "no_speech_prob": 1.7502414266346022e-05}, {"id": 563, "seek": 267152, "start": 2680.48, "end": 2682.64, "text": " But you know here's a very simple example", "tokens": [583, 291, 458, 510, 311, 257, 588, 2199, 1365], "temperature": 0.0, "avg_logprob": -0.2499462127685547, "compression_ratio": 1.6824644549763033, "no_speech_prob": 1.7502414266346022e-05}, {"id": 564, "seek": 267152, "start": 2682.8, "end": 2689.56, "text": " Is that if you write all of these things again and again and again then it really hides the fact that you've got you know", "tokens": [1119, 300, 498, 291, 2464, 439, 295, 613, 721, 797, 293, 797, 293, 797, 550, 309, 534, 35953, 264, 1186, 300, 291, 600, 658, 291, 458], "temperature": 0.0, "avg_logprob": -0.2499462127685547, "compression_ratio": 1.6824644549763033, "no_speech_prob": 1.7502414266346022e-05}, {"id": 565, "seek": 267152, "start": 2689.8, "end": 2694.96, "text": " Two convolutional layers one of stride one one of stride two", "tokens": [4453, 45216, 304, 7914, 472, 295, 1056, 482, 472, 472, 295, 1056, 482, 732], "temperature": 0.0, "avg_logprob": -0.2499462127685547, "compression_ratio": 1.6824644549763033, "no_speech_prob": 1.7502414266346022e-05}, {"id": 566, "seek": 267152, "start": 2696.52, "end": 2699.7599999999998, "text": " So my default the standard comp is stride two", "tokens": [407, 452, 7576, 264, 3832, 715, 307, 1056, 482, 732], "temperature": 0.0, "avg_logprob": -0.2499462127685547, "compression_ratio": 1.6824644549763033, "no_speech_prob": 1.7502414266346022e-05}, {"id": 567, "seek": 269976, "start": 2699.76, "end": 2703.7200000000003, "text": " That's right one. This is a stride two and then at the end", "tokens": [663, 311, 558, 472, 13, 639, 307, 257, 1056, 482, 732, 293, 550, 412, 264, 917], "temperature": 0.0, "avg_logprob": -0.26950599268863074, "compression_ratio": 1.5904761904761904, "no_speech_prob": 4.565943982015597e-06}, {"id": 568, "seek": 269976, "start": 2704.96, "end": 2707.28, "text": " So this the output of this is going to be", "tokens": [407, 341, 264, 5598, 295, 341, 307, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.26950599268863074, "compression_ratio": 1.5904761904761904, "no_speech_prob": 4.565943982015597e-06}, {"id": 569, "seek": 269976, "start": 2708.0800000000004, "end": 2710.0800000000004, "text": " four by four, right?", "tokens": [1451, 538, 1451, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.26950599268863074, "compression_ratio": 1.5904761904761904, "no_speech_prob": 4.565943982015597e-06}, {"id": 570, "seek": 269976, "start": 2710.88, "end": 2712.88, "text": " I've got a", "tokens": [286, 600, 658, 257], "temperature": 0.0, "avg_logprob": -0.26950599268863074, "compression_ratio": 1.5904761904761904, "no_speech_prob": 4.565943982015597e-06}, {"id": 571, "seek": 269976, "start": 2712.92, "end": 2718.32, "text": " Outcon and an outcome is interesting. You can see it's got two separate", "tokens": [5925, 1671, 293, 364, 9700, 307, 1880, 13, 509, 393, 536, 309, 311, 658, 732, 4994], "temperature": 0.0, "avg_logprob": -0.26950599268863074, "compression_ratio": 1.5904761904761904, "no_speech_prob": 4.565943982015597e-06}, {"id": 572, "seek": 269976, "start": 2719.28, "end": 2723.6400000000003, "text": " convolutional layers each of which is stride one so it's not changing the", "tokens": [45216, 304, 7914, 1184, 295, 597, 307, 1056, 482, 472, 370, 309, 311, 406, 4473, 264], "temperature": 0.0, "avg_logprob": -0.26950599268863074, "compression_ratio": 1.5904761904761904, "no_speech_prob": 4.565943982015597e-06}, {"id": 573, "seek": 272364, "start": 2723.64, "end": 2730.52, "text": " Geometry of the input. All right, one of them is of length of the number of classes", "tokens": [2876, 34730, 295, 264, 4846, 13, 1057, 558, 11, 472, 295, 552, 307, 295, 4641, 295, 264, 1230, 295, 5359], "temperature": 0.0, "avg_logprob": -0.22296733684367961, "compression_ratio": 1.9054054054054055, "no_speech_prob": 5.255365522316424e-06}, {"id": 574, "seek": 272364, "start": 2731.7999999999997, "end": 2736.08, "text": " Just ignore K for now K is equal to K is equal to 1 at this point of the code", "tokens": [1449, 11200, 591, 337, 586, 591, 307, 2681, 281, 591, 307, 2681, 281, 502, 412, 341, 935, 295, 264, 3089], "temperature": 0.0, "avg_logprob": -0.22296733684367961, "compression_ratio": 1.9054054054054055, "no_speech_prob": 5.255365522316424e-06}, {"id": 575, "seek": 272364, "start": 2736.08, "end": 2739.16, "text": " So it's not doing anything. So one is equal to the length of the number of classes", "tokens": [407, 309, 311, 406, 884, 1340, 13, 407, 472, 307, 2681, 281, 264, 4641, 295, 264, 1230, 295, 5359], "temperature": 0.0, "avg_logprob": -0.22296733684367961, "compression_ratio": 1.9054054054054055, "no_speech_prob": 5.255365522316424e-06}, {"id": 576, "seek": 272364, "start": 2739.52, "end": 2744.44, "text": " One is equal to 4 and so this is this idea of rather than having a single", "tokens": [1485, 307, 2681, 281, 1017, 293, 370, 341, 307, 341, 1558, 295, 2831, 813, 1419, 257, 2167], "temperature": 0.0, "avg_logprob": -0.22296733684367961, "compression_ratio": 1.9054054054054055, "no_speech_prob": 5.255365522316424e-06}, {"id": 577, "seek": 272364, "start": 2745.3599999999997, "end": 2752.44, "text": " Comp layer that outputs 4 plus C. Let's have two comp layers one of which outputs 4 one of which outputs", "tokens": [6620, 4583, 300, 23930, 1017, 1804, 383, 13, 961, 311, 362, 732, 715, 7914, 472, 295, 597, 23930, 1017, 472, 295, 597, 23930], "temperature": 0.0, "avg_logprob": -0.22296733684367961, "compression_ratio": 1.9054054054054055, "no_speech_prob": 5.255365522316424e-06}, {"id": 578, "seek": 275244, "start": 2752.44, "end": 2757.6, "text": " C and then I will just return them as a list of two items", "tokens": [383, 293, 550, 286, 486, 445, 2736, 552, 382, 257, 1329, 295, 732, 4754], "temperature": 0.0, "avg_logprob": -0.16938320795694986, "compression_ratio": 1.6637554585152838, "no_speech_prob": 2.521564056223724e-06}, {"id": 579, "seek": 275244, "start": 2759.12, "end": 2765.54, "text": " That's nearly the same thing. It's nearly the same thing as having a single comp layer that outputs 4 plus C", "tokens": [663, 311, 6217, 264, 912, 551, 13, 467, 311, 6217, 264, 912, 551, 382, 1419, 257, 2167, 715, 4583, 300, 23930, 1017, 1804, 383], "temperature": 0.0, "avg_logprob": -0.16938320795694986, "compression_ratio": 1.6637554585152838, "no_speech_prob": 2.521564056223724e-06}, {"id": 580, "seek": 275244, "start": 2765.56, "end": 2769.94, "text": " But it lets it lets these layers specialize just a little bit", "tokens": [583, 309, 6653, 309, 6653, 613, 7914, 37938, 445, 257, 707, 857], "temperature": 0.0, "avg_logprob": -0.16938320795694986, "compression_ratio": 1.6637554585152838, "no_speech_prob": 2.521564056223724e-06}, {"id": 581, "seek": 275244, "start": 2770.52, "end": 2773.0, "text": " right, so like we talked about this idea that", "tokens": [558, 11, 370, 411, 321, 2825, 466, 341, 1558, 300], "temperature": 0.0, "avg_logprob": -0.16938320795694986, "compression_ratio": 1.6637554585152838, "no_speech_prob": 2.521564056223724e-06}, {"id": 582, "seek": 275244, "start": 2774.0, "end": 2780.2000000000003, "text": " When you've got kind of multiple tasks, they can share layers, but they don't have to share all the layers", "tokens": [1133, 291, 600, 658, 733, 295, 3866, 9608, 11, 436, 393, 2073, 7914, 11, 457, 436, 500, 380, 362, 281, 2073, 439, 264, 7914], "temperature": 0.0, "avg_logprob": -0.16938320795694986, "compression_ratio": 1.6637554585152838, "no_speech_prob": 2.521564056223724e-06}, {"id": 583, "seek": 278020, "start": 2780.2, "end": 2787.66, "text": " So in this case our two tasks, which is fine create a classifier and create down box aggression", "tokens": [407, 294, 341, 1389, 527, 732, 9608, 11, 597, 307, 2489, 1884, 257, 1508, 9902, 293, 1884, 760, 2424, 30268], "temperature": 0.0, "avg_logprob": -0.23799331564652293, "compression_ratio": 1.5572916666666667, "no_speech_prob": 6.854269940959057e-06}, {"id": 584, "seek": 278020, "start": 2788.3999999999996, "end": 2791.62, "text": " Share every single layer except the very last one", "tokens": [14945, 633, 2167, 4583, 3993, 264, 588, 1036, 472], "temperature": 0.0, "avg_logprob": -0.23799331564652293, "compression_ratio": 1.5572916666666667, "no_speech_prob": 6.854269940959057e-06}, {"id": 585, "seek": 278020, "start": 2792.3199999999997, "end": 2796.04, "text": " Okay, and so this is going to spit out two separate", "tokens": [1033, 11, 293, 370, 341, 307, 516, 281, 22127, 484, 732, 4994], "temperature": 0.0, "avg_logprob": -0.23799331564652293, "compression_ratio": 1.5572916666666667, "no_speech_prob": 6.854269940959057e-06}, {"id": 586, "seek": 278020, "start": 2798.2, "end": 2803.9199999999996, "text": " Tenses of activations one of the classes and one of the bounding box coordinates", "tokens": [314, 9085, 295, 2430, 763, 472, 295, 264, 5359, 293, 472, 295, 264, 5472, 278, 2424, 21056], "temperature": 0.0, "avg_logprob": -0.23799331564652293, "compression_ratio": 1.5572916666666667, "no_speech_prob": 6.854269940959057e-06}, {"id": 587, "seek": 278020, "start": 2805.52, "end": 2807.52, "text": " Why am I adding one?", "tokens": [1545, 669, 286, 5127, 472, 30], "temperature": 0.0, "avg_logprob": -0.23799331564652293, "compression_ratio": 1.5572916666666667, "no_speech_prob": 6.854269940959057e-06}, {"id": 588, "seek": 280752, "start": 2807.52, "end": 2814.44, "text": " That's because I'm going to have one more class for background right so if there aren't actually 16 objects to detect", "tokens": [663, 311, 570, 286, 478, 516, 281, 362, 472, 544, 1508, 337, 3678, 558, 370, 498, 456, 3212, 380, 767, 3165, 6565, 281, 5531], "temperature": 0.0, "avg_logprob": -0.22160760746445768, "compression_ratio": 1.6306306306306306, "no_speech_prob": 4.495149369176943e-06}, {"id": 589, "seek": 280752, "start": 2815.16, "end": 2821.7599999999998, "text": " Or if there isn't an object in this corner represented by this convolutional grid cell then I wanted to predict", "tokens": [1610, 498, 456, 1943, 380, 364, 2657, 294, 341, 4538, 10379, 538, 341, 45216, 304, 10748, 2815, 550, 286, 1415, 281, 6069], "temperature": 0.0, "avg_logprob": -0.22160760746445768, "compression_ratio": 1.6306306306306306, "no_speech_prob": 4.495149369176943e-06}, {"id": 590, "seek": 280752, "start": 2822.96, "end": 2824.96, "text": " background", "tokens": [3678], "temperature": 0.0, "avg_logprob": -0.22160760746445768, "compression_ratio": 1.6306306306306306, "no_speech_prob": 4.495149369176943e-06}, {"id": 591, "seek": 280752, "start": 2825.32, "end": 2827.32, "text": " So that's the entirety", "tokens": [407, 300, 311, 264, 31557], "temperature": 0.0, "avg_logprob": -0.22160760746445768, "compression_ratio": 1.6306306306306306, "no_speech_prob": 4.495149369176943e-06}, {"id": 592, "seek": 280752, "start": 2828.7599999999998, "end": 2831.88, "text": " That's the entirety of our architecture. It's incredibly", "tokens": [663, 311, 264, 31557, 295, 527, 9482, 13, 467, 311, 6252], "temperature": 0.0, "avg_logprob": -0.22160760746445768, "compression_ratio": 1.6306306306306306, "no_speech_prob": 4.495149369176943e-06}, {"id": 593, "seek": 280752, "start": 2833.08, "end": 2836.2599999999998, "text": " Simple right but the point is now that we", "tokens": [21532, 558, 457, 264, 935, 307, 586, 300, 321], "temperature": 0.0, "avg_logprob": -0.22160760746445768, "compression_ratio": 1.6306306306306306, "no_speech_prob": 4.495149369176943e-06}, {"id": 594, "seek": 283626, "start": 2836.26, "end": 2839.42, "text": " You know we have this convolutional layer at the end", "tokens": [509, 458, 321, 362, 341, 45216, 304, 4583, 412, 264, 917], "temperature": 0.0, "avg_logprob": -0.17253643484676587, "compression_ratio": 1.6634615384615385, "no_speech_prob": 9.97281586023746e-06}, {"id": 595, "seek": 283626, "start": 2840.0200000000004, "end": 2846.42, "text": " One thing I do do is that I at the very end I flatten out the convolution", "tokens": [1485, 551, 286, 360, 360, 307, 300, 286, 412, 264, 588, 917, 286, 24183, 484, 264, 45216], "temperature": 0.0, "avg_logprob": -0.17253643484676587, "compression_ratio": 1.6634615384615385, "no_speech_prob": 9.97281586023746e-06}, {"id": 596, "seek": 283626, "start": 2849.7000000000003, "end": 2854.3, "text": " Basically because I wrote the loss function to expect a flattened out tensor", "tokens": [8537, 570, 286, 4114, 264, 4470, 2445, 281, 2066, 257, 24183, 292, 484, 40863], "temperature": 0.0, "avg_logprob": -0.17253643484676587, "compression_ratio": 1.6634615384615385, "no_speech_prob": 9.97281586023746e-06}, {"id": 597, "seek": 283626, "start": 2854.42, "end": 2857.0600000000004, "text": " But I we could totally rewrite it to not do that", "tokens": [583, 286, 321, 727, 3879, 28132, 309, 281, 406, 360, 300], "temperature": 0.0, "avg_logprob": -0.17253643484676587, "compression_ratio": 1.6634615384615385, "no_speech_prob": 9.97281586023746e-06}, {"id": 598, "seek": 283626, "start": 2857.0600000000004, "end": 2862.3, "text": " I might even try doing that during the week and see which one looks easier to understand", "tokens": [286, 1062, 754, 853, 884, 300, 1830, 264, 1243, 293, 536, 597, 472, 1542, 3571, 281, 1223], "temperature": 0.0, "avg_logprob": -0.17253643484676587, "compression_ratio": 1.6634615384615385, "no_speech_prob": 9.97281586023746e-06}, {"id": 599, "seek": 283626, "start": 2863.5, "end": 2864.5400000000004, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.17253643484676587, "compression_ratio": 1.6634615384615385, "no_speech_prob": 9.97281586023746e-06}, {"id": 600, "seek": 286454, "start": 2864.54, "end": 2866.54, "text": " So we've got our data", "tokens": [407, 321, 600, 658, 527, 1412], "temperature": 0.0, "avg_logprob": -0.2111722707748413, "compression_ratio": 1.596774193548387, "no_speech_prob": 8.013427759578917e-06}, {"id": 601, "seek": 286454, "start": 2866.86, "end": 2868.86, "text": " We've got our architecture", "tokens": [492, 600, 658, 527, 9482], "temperature": 0.0, "avg_logprob": -0.2111722707748413, "compression_ratio": 1.596774193548387, "no_speech_prob": 8.013427759578917e-06}, {"id": 602, "seek": 286454, "start": 2869.7, "end": 2872.5, "text": " So now all we need is a loss function", "tokens": [407, 586, 439, 321, 643, 307, 257, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.2111722707748413, "compression_ratio": 1.596774193548387, "no_speech_prob": 8.013427759578917e-06}, {"id": 603, "seek": 286454, "start": 2873.2599999999998, "end": 2877.86, "text": " Okay, so the loss function needs to look at each of these", "tokens": [1033, 11, 370, 264, 4470, 2445, 2203, 281, 574, 412, 1184, 295, 613], "temperature": 0.0, "avg_logprob": -0.2111722707748413, "compression_ratio": 1.596774193548387, "no_speech_prob": 8.013427759578917e-06}, {"id": 604, "seek": 286454, "start": 2878.94, "end": 2884.92, "text": " 16 sets of activations each of which you're going to have four bounding box coordinates and", "tokens": [3165, 6352, 295, 2430, 763, 1184, 295, 597, 291, 434, 516, 281, 362, 1451, 5472, 278, 2424, 21056, 293], "temperature": 0.0, "avg_logprob": -0.2111722707748413, "compression_ratio": 1.596774193548387, "no_speech_prob": 8.013427759578917e-06}, {"id": 605, "seek": 286454, "start": 2886.42, "end": 2889.3, "text": " C plus 1 plus probabilities and", "tokens": [383, 1804, 502, 1804, 33783, 293], "temperature": 0.0, "avg_logprob": -0.2111722707748413, "compression_ratio": 1.596774193548387, "no_speech_prob": 8.013427759578917e-06}, {"id": 606, "seek": 286454, "start": 2890.62, "end": 2892.2599999999998, "text": " decide", "tokens": [4536], "temperature": 0.0, "avg_logprob": -0.2111722707748413, "compression_ratio": 1.596774193548387, "no_speech_prob": 8.013427759578917e-06}, {"id": 607, "seek": 289226, "start": 2892.26, "end": 2894.26, "text": " Are those activations?", "tokens": [2014, 729, 2430, 763, 30], "temperature": 0.0, "avg_logprob": -0.2684235780135445, "compression_ratio": 1.4345238095238095, "no_speech_prob": 4.0928807720774785e-06}, {"id": 608, "seek": 289226, "start": 2897.34, "end": 2899.34, "text": " Close or far away from", "tokens": [16346, 420, 1400, 1314, 490], "temperature": 0.0, "avg_logprob": -0.2684235780135445, "compression_ratio": 1.4345238095238095, "no_speech_prob": 4.0928807720774785e-06}, {"id": 609, "seek": 289226, "start": 2900.46, "end": 2903.7400000000002, "text": " The object which is kind of closest to this", "tokens": [440, 2657, 597, 307, 733, 295, 13699, 281, 341], "temperature": 0.0, "avg_logprob": -0.2684235780135445, "compression_ratio": 1.4345238095238095, "no_speech_prob": 4.0928807720774785e-06}, {"id": 610, "seek": 289226, "start": 2904.5, "end": 2907.78, "text": " This this grid cell in the image", "tokens": [639, 341, 10748, 2815, 294, 264, 3256], "temperature": 0.0, "avg_logprob": -0.2684235780135445, "compression_ratio": 1.4345238095238095, "no_speech_prob": 4.0928807720774785e-06}, {"id": 611, "seek": 289226, "start": 2908.3, "end": 2912.7000000000003, "text": " And if nothing's there, then you know are you predicting background?", "tokens": [400, 498, 1825, 311, 456, 11, 550, 291, 458, 366, 291, 32884, 3678, 30], "temperature": 0.0, "avg_logprob": -0.2684235780135445, "compression_ratio": 1.4345238095238095, "no_speech_prob": 4.0928807720774785e-06}, {"id": 612, "seek": 289226, "start": 2913.26, "end": 2915.26, "text": " correctly", "tokens": [8944], "temperature": 0.0, "avg_logprob": -0.2684235780135445, "compression_ratio": 1.4345238095238095, "no_speech_prob": 4.0928807720774785e-06}, {"id": 613, "seek": 289226, "start": 2915.7400000000002, "end": 2917.7400000000002, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.2684235780135445, "compression_ratio": 1.4345238095238095, "no_speech_prob": 4.0928807720774785e-06}, {"id": 614, "seek": 289226, "start": 2917.86, "end": 2919.86, "text": " That turns out to be very hard to do", "tokens": [663, 4523, 484, 281, 312, 588, 1152, 281, 360], "temperature": 0.0, "avg_logprob": -0.2684235780135445, "compression_ratio": 1.4345238095238095, "no_speech_prob": 4.0928807720774785e-06}, {"id": 615, "seek": 291986, "start": 2919.86, "end": 2926.54, "text": " Because let's go back to the two by two example to keep it simple", "tokens": [1436, 718, 311, 352, 646, 281, 264, 732, 538, 732, 1365, 281, 1066, 309, 2199], "temperature": 0.0, "avg_logprob": -0.21985322075921135, "compression_ratio": 1.8258426966292134, "no_speech_prob": 1.529406745248707e-06}, {"id": 616, "seek": 291986, "start": 2930.26, "end": 2935.58, "text": " The loss function actually needs to take each of the objects in the image and", "tokens": [440, 4470, 2445, 767, 2203, 281, 747, 1184, 295, 264, 6565, 294, 264, 3256, 293], "temperature": 0.0, "avg_logprob": -0.21985322075921135, "compression_ratio": 1.8258426966292134, "no_speech_prob": 1.529406745248707e-06}, {"id": 617, "seek": 291986, "start": 2936.5, "end": 2937.98, "text": " match them", "tokens": [2995, 552], "temperature": 0.0, "avg_logprob": -0.21985322075921135, "compression_ratio": 1.8258426966292134, "no_speech_prob": 1.529406745248707e-06}, {"id": 618, "seek": 291986, "start": 2937.98, "end": 2941.06, "text": " To one of these convolutional grid cells to say like this", "tokens": [1407, 472, 295, 613, 45216, 304, 10748, 5438, 281, 584, 411, 341], "temperature": 0.0, "avg_logprob": -0.21985322075921135, "compression_ratio": 1.8258426966292134, "no_speech_prob": 1.529406745248707e-06}, {"id": 619, "seek": 291986, "start": 2941.46, "end": 2947.02, "text": " Grid cell is responsible for this particular object and this grid cell is responsible for this particular object", "tokens": [42905, 2815, 307, 6250, 337, 341, 1729, 2657, 293, 341, 10748, 2815, 307, 6250, 337, 341, 1729, 2657], "temperature": 0.0, "avg_logprob": -0.21985322075921135, "compression_ratio": 1.8258426966292134, "no_speech_prob": 1.529406745248707e-06}, {"id": 620, "seek": 294702, "start": 2947.02, "end": 2952.74, "text": " So then it can go ahead and say like okay how close are the four coordinates and how close are the class probabilities?", "tokens": [407, 550, 309, 393, 352, 2286, 293, 584, 411, 1392, 577, 1998, 366, 264, 1451, 21056, 293, 577, 1998, 366, 264, 1508, 33783, 30], "temperature": 0.0, "avg_logprob": -0.20513431714928668, "compression_ratio": 1.7598425196850394, "no_speech_prob": 1.1125504897790961e-05}, {"id": 621, "seek": 294702, "start": 2952.74, "end": 2955.2599999999998, "text": " Right. So this is called the matching problem", "tokens": [1779, 13, 407, 341, 307, 1219, 264, 14324, 1154], "temperature": 0.0, "avg_logprob": -0.20513431714928668, "compression_ratio": 1.7598425196850394, "no_speech_prob": 1.1125504897790961e-05}, {"id": 622, "seek": 294702, "start": 2956.3, "end": 2957.7, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.20513431714928668, "compression_ratio": 1.7598425196850394, "no_speech_prob": 1.1125504897790961e-05}, {"id": 623, "seek": 294702, "start": 2957.7, "end": 2961.3, "text": " In order to explain it. I'm going to show it to you", "tokens": [682, 1668, 281, 2903, 309, 13, 286, 478, 516, 281, 855, 309, 281, 291], "temperature": 0.0, "avg_logprob": -0.20513431714928668, "compression_ratio": 1.7598425196850394, "no_speech_prob": 1.1125504897790961e-05}, {"id": 624, "seek": 294702, "start": 2963.42, "end": 2965.5, "text": " But what I'm going to do first is I'm going to take a break", "tokens": [583, 437, 286, 478, 516, 281, 360, 700, 307, 286, 478, 516, 281, 747, 257, 1821], "temperature": 0.0, "avg_logprob": -0.20513431714928668, "compression_ratio": 1.7598425196850394, "no_speech_prob": 1.1125504897790961e-05}, {"id": 625, "seek": 294702, "start": 2965.82, "end": 2969.54, "text": " Okay, and we're going to come back and understand the maxi map the matching problem", "tokens": [1033, 11, 293, 321, 434, 516, 281, 808, 646, 293, 1223, 264, 11469, 72, 4471, 264, 14324, 1154], "temperature": 0.0, "avg_logprob": -0.20513431714928668, "compression_ratio": 1.7598425196850394, "no_speech_prob": 1.1125504897790961e-05}, {"id": 626, "seek": 294702, "start": 2969.54, "end": 2974.42, "text": " So during the break have a think about how would you design a loss function here?", "tokens": [407, 1830, 264, 1821, 362, 257, 519, 466, 577, 576, 291, 1715, 257, 4470, 2445, 510, 30], "temperature": 0.0, "avg_logprob": -0.20513431714928668, "compression_ratio": 1.7598425196850394, "no_speech_prob": 1.1125504897790961e-05}, {"id": 627, "seek": 297442, "start": 2974.42, "end": 2981.7400000000002, "text": " How would you design a function which has a lower value if these 16 times 4 plus K activations?", "tokens": [1012, 576, 291, 1715, 257, 2445, 597, 575, 257, 3126, 2158, 498, 613, 3165, 1413, 1017, 1804, 591, 2430, 763, 30], "temperature": 0.0, "avg_logprob": -0.19372527782733623, "compression_ratio": 1.3651685393258426, "no_speech_prob": 3.288735570095014e-06}, {"id": 628, "seek": 297442, "start": 2982.7000000000003, "end": 2987.94, "text": " You know somehow better reflect the up to 16 objects", "tokens": [509, 458, 6063, 1101, 5031, 264, 493, 281, 3165, 6565], "temperature": 0.0, "avg_logprob": -0.19372527782733623, "compression_ratio": 1.3651685393258426, "no_speech_prob": 3.288735570095014e-06}, {"id": 629, "seek": 297442, "start": 2987.94, "end": 2991.1, "text": " Which are actually in the ground truth image and we'll come back at", "tokens": [3013, 366, 767, 294, 264, 2727, 3494, 3256, 293, 321, 603, 808, 646, 412], "temperature": 0.0, "avg_logprob": -0.19372527782733623, "compression_ratio": 1.3651685393258426, "no_speech_prob": 3.288735570095014e-06}, {"id": 630, "seek": 297442, "start": 2992.02, "end": 2994.02, "text": " 740", "tokens": [1614, 5254], "temperature": 0.0, "avg_logprob": -0.19372527782733623, "compression_ratio": 1.3651685393258426, "no_speech_prob": 3.288735570095014e-06}, {"id": 631, "seek": 297442, "start": 2996.46, "end": 2998.46, "text": " So here's our goal our", "tokens": [407, 510, 311, 527, 3387, 527], "temperature": 0.0, "avg_logprob": -0.19372527782733623, "compression_ratio": 1.3651685393258426, "no_speech_prob": 3.288735570095014e-06}, {"id": 632, "seek": 299846, "start": 2998.46, "end": 3000.46, "text": " Our", "tokens": [2621], "temperature": 0.0, "avg_logprob": -0.39654347153960684, "compression_ratio": 1.3493150684931507, "no_speech_prob": 4.2892852434306405e-06}, {"id": 633, "seek": 299846, "start": 3002.7, "end": 3004.7, "text": " Dependent variable", "tokens": [4056, 521, 317, 7006], "temperature": 0.0, "avg_logprob": -0.39654347153960684, "compression_ratio": 1.3493150684931507, "no_speech_prob": 4.2892852434306405e-06}, {"id": 634, "seek": 299846, "start": 3005.5, "end": 3007.42, "text": " basically looks", "tokens": [1936, 1542], "temperature": 0.0, "avg_logprob": -0.39654347153960684, "compression_ratio": 1.3493150684931507, "no_speech_prob": 4.2892852434306405e-06}, {"id": 635, "seek": 299846, "start": 3007.42, "end": 3011.42, "text": " Like that and as I just an extract from our CSV file", "tokens": [1743, 300, 293, 382, 286, 445, 364, 8947, 490, 527, 48814, 3991], "temperature": 0.0, "avg_logprob": -0.39654347153960684, "compression_ratio": 1.3493150684931507, "no_speech_prob": 4.2892852434306405e-06}, {"id": 636, "seek": 299846, "start": 3012.7400000000002, "end": 3014.7400000000002, "text": " independent and", "tokens": [6695, 293], "temperature": 0.0, "avg_logprob": -0.39654347153960684, "compression_ratio": 1.3493150684931507, "no_speech_prob": 4.2892852434306405e-06}, {"id": 637, "seek": 299846, "start": 3014.94, "end": 3016.94, "text": " our", "tokens": [527], "temperature": 0.0, "avg_logprob": -0.39654347153960684, "compression_ratio": 1.3493150684931507, "no_speech_prob": 4.2892852434306405e-06}, {"id": 638, "seek": 299846, "start": 3017.26, "end": 3019.26, "text": " Final", "tokens": [13443], "temperature": 0.0, "avg_logprob": -0.39654347153960684, "compression_ratio": 1.3493150684931507, "no_speech_prob": 4.2892852434306405e-06}, {"id": 639, "seek": 299846, "start": 3019.54, "end": 3024.1, "text": " Convolution or layer is going to be a bunch of numbers which initially is a", "tokens": [2656, 85, 3386, 420, 4583, 307, 516, 281, 312, 257, 3840, 295, 3547, 597, 9105, 307, 257], "temperature": 0.0, "avg_logprob": -0.39654347153960684, "compression_ratio": 1.3493150684931507, "no_speech_prob": 4.2892852434306405e-06}, {"id": 640, "seek": 299846, "start": 3026.14, "end": 3027.66, "text": " For", "tokens": [1171], "temperature": 0.0, "avg_logprob": -0.39654347153960684, "compression_ratio": 1.3493150684931507, "no_speech_prob": 4.2892852434306405e-06}, {"id": 641, "seek": 302766, "start": 3027.66, "end": 3029.66, "text": " by four", "tokens": [538, 1451], "temperature": 0.0, "avg_logprob": -0.3693880353655134, "compression_ratio": 1.5569620253164558, "no_speech_prob": 8.664513188705314e-06}, {"id": 642, "seek": 302766, "start": 3029.8599999999997, "end": 3037.5, "text": " Five in this case. I think C is equal to 20 plus we've got one for background right so 4 plus", "tokens": [9436, 294, 341, 1389, 13, 286, 519, 383, 307, 2681, 281, 945, 1804, 321, 600, 658, 472, 337, 3678, 558, 370, 1017, 1804], "temperature": 0.0, "avg_logprob": -0.3693880353655134, "compression_ratio": 1.5569620253164558, "no_speech_prob": 8.664513188705314e-06}, {"id": 643, "seek": 302766, "start": 3038.7799999999997, "end": 3040.1, "text": " 21", "tokens": [5080], "temperature": 0.0, "avg_logprob": -0.3693880353655134, "compression_ratio": 1.5569620253164558, "no_speech_prob": 8.664513188705314e-06}, {"id": 644, "seek": 302766, "start": 3040.1, "end": 3042.1, "text": " equals 26", "tokens": [6915, 7551], "temperature": 0.0, "avg_logprob": -0.3693880353655134, "compression_ratio": 1.5569620253164558, "no_speech_prob": 8.664513188705314e-06}, {"id": 645, "seek": 302766, "start": 3042.14, "end": 3043.3399999999997, "text": " or", "tokens": [420], "temperature": 0.0, "avg_logprob": -0.3693880353655134, "compression_ratio": 1.5569620253164558, "no_speech_prob": 8.664513188705314e-06}, {"id": 646, "seek": 302766, "start": 3043.3399999999997, "end": 3045.46, "text": " 4 right and then we", "tokens": [1017, 558, 293, 550, 321], "temperature": 0.0, "avg_logprob": -0.3693880353655134, "compression_ratio": 1.5569620253164558, "no_speech_prob": 8.664513188705314e-06}, {"id": 647, "seek": 302766, "start": 3046.2999999999997, "end": 3048.2999999999997, "text": " We flatten that out", "tokens": [492, 24183, 300, 484], "temperature": 0.0, "avg_logprob": -0.3693880353655134, "compression_ratio": 1.5569620253164558, "no_speech_prob": 8.664513188705314e-06}, {"id": 648, "seek": 302766, "start": 3048.54, "end": 3050.54, "text": " into a vector", "tokens": [666, 257, 8062], "temperature": 0.0, "avg_logprob": -0.3693880353655134, "compression_ratio": 1.5569620253164558, "no_speech_prob": 8.664513188705314e-06}, {"id": 649, "seek": 302766, "start": 3050.8999999999996, "end": 3055.62, "text": " We flatten that out into a vector and so basically our goal then is to say", "tokens": [492, 24183, 300, 484, 666, 257, 8062, 293, 370, 1936, 527, 3387, 550, 307, 281, 584], "temperature": 0.0, "avg_logprob": -0.3693880353655134, "compression_ratio": 1.5569620253164558, "no_speech_prob": 8.664513188705314e-06}, {"id": 650, "seek": 305562, "start": 3055.62, "end": 3058.2599999999998, "text": " to some particular", "tokens": [281, 512, 1729], "temperature": 0.0, "avg_logprob": -0.2906190215564165, "compression_ratio": 1.5850340136054422, "no_speech_prob": 5.3381063480628654e-06}, {"id": 651, "seek": 305562, "start": 3059.42, "end": 3065.7799999999997, "text": " Set of activations that ended up coming out of this model for some let's let's pick some particular", "tokens": [8928, 295, 2430, 763, 300, 4590, 493, 1348, 484, 295, 341, 2316, 337, 512, 718, 311, 718, 311, 1888, 512, 1729], "temperature": 0.0, "avg_logprob": -0.2906190215564165, "compression_ratio": 1.5850340136054422, "no_speech_prob": 5.3381063480628654e-06}, {"id": 652, "seek": 305562, "start": 3067.3399999999997, "end": 3072.18, "text": " Dependent variable we need some function that takes in that and", "tokens": [4056, 521, 317, 7006, 321, 643, 512, 2445, 300, 2516, 294, 300, 293], "temperature": 0.0, "avg_logprob": -0.2906190215564165, "compression_ratio": 1.5850340136054422, "no_speech_prob": 5.3381063480628654e-06}, {"id": 653, "seek": 305562, "start": 3073.2599999999998, "end": 3075.14, "text": " that", "tokens": [300], "temperature": 0.0, "avg_logprob": -0.2906190215564165, "compression_ratio": 1.5850340136054422, "no_speech_prob": 5.3381063480628654e-06}, {"id": 654, "seek": 305562, "start": 3075.14, "end": 3077.14, "text": " right and where", "tokens": [558, 293, 689], "temperature": 0.0, "avg_logprob": -0.2906190215564165, "compression_ratio": 1.5850340136054422, "no_speech_prob": 5.3381063480628654e-06}, {"id": 655, "seek": 305562, "start": 3077.74, "end": 3079.74, "text": " It feeds back a higher number", "tokens": [467, 23712, 646, 257, 2946, 1230], "temperature": 0.0, "avg_logprob": -0.2906190215564165, "compression_ratio": 1.5850340136054422, "no_speech_prob": 5.3381063480628654e-06}, {"id": 656, "seek": 307974, "start": 3079.74, "end": 3085.62, "text": " If these activations aren't a good reflection of the ground truth bounding boxes or a lower number", "tokens": [759, 613, 2430, 763, 3212, 380, 257, 665, 12914, 295, 264, 2727, 3494, 5472, 278, 9002, 420, 257, 3126, 1230], "temperature": 0.0, "avg_logprob": -0.20402246234060703, "compression_ratio": 1.9395604395604396, "no_speech_prob": 2.6841739781957585e-06}, {"id": 657, "seek": 307974, "start": 3085.62, "end": 3090.8599999999997, "text": " It is a good reflection of the ground truth bounding boxes. That's our goal. We need to create", "tokens": [467, 307, 257, 665, 12914, 295, 264, 2727, 3494, 5472, 278, 9002, 13, 663, 311, 527, 3387, 13, 492, 643, 281, 1884], "temperature": 0.0, "avg_logprob": -0.20402246234060703, "compression_ratio": 1.9395604395604396, "no_speech_prob": 2.6841739781957585e-06}, {"id": 658, "seek": 307974, "start": 3091.58, "end": 3093.58, "text": " that function", "tokens": [300, 2445], "temperature": 0.0, "avg_logprob": -0.20402246234060703, "compression_ratio": 1.9395604395604396, "no_speech_prob": 2.6841739781957585e-06}, {"id": 659, "seek": 307974, "start": 3094.14, "end": 3098.2599999999998, "text": " And so the general approach to creating that function", "tokens": [400, 370, 264, 2674, 3109, 281, 4084, 300, 2445], "temperature": 0.0, "avg_logprob": -0.20402246234060703, "compression_ratio": 1.9395604395604396, "no_speech_prob": 2.6841739781957585e-06}, {"id": 660, "seek": 307974, "start": 3100.4199999999996, "end": 3104.06, "text": " Will be the first of all to simplify it down of two by two version", "tokens": [3099, 312, 264, 700, 295, 439, 281, 20460, 309, 760, 295, 732, 538, 732, 3037], "temperature": 0.0, "avg_logprob": -0.20402246234060703, "compression_ratio": 1.9395604395604396, "no_speech_prob": 2.6841739781957585e-06}, {"id": 661, "seek": 310406, "start": 3104.06, "end": 3111.94, "text": " Will be the first of all well actually I'll show you right", "tokens": [3099, 312, 264, 700, 295, 439, 731, 767, 286, 603, 855, 291, 558], "temperature": 0.0, "avg_logprob": -0.45822676567182147, "compression_ratio": 1.5, "no_speech_prob": 4.710856501333183e-06}, {"id": 662, "seek": 310406, "start": 3116.5, "end": 3118.5, "text": " Here's a model I trained earlier", "tokens": [1692, 311, 257, 2316, 286, 8895, 3071], "temperature": 0.0, "avg_logprob": -0.45822676567182147, "compression_ratio": 1.5, "no_speech_prob": 4.710856501333183e-06}, {"id": 663, "seek": 310406, "start": 3119.5, "end": 3124.66, "text": " Okay, and let's run through I've taken the loss function, and I've split it line by line", "tokens": [1033, 11, 293, 718, 311, 1190, 807, 286, 600, 2726, 264, 4470, 2445, 11, 293, 286, 600, 7472, 309, 1622, 538, 1622], "temperature": 0.0, "avg_logprob": -0.45822676567182147, "compression_ratio": 1.5, "no_speech_prob": 4.710856501333183e-06}, {"id": 664, "seek": 310406, "start": 3125.34, "end": 3129.2599999999998, "text": " So that you can see every line that goes into making it okay, so", "tokens": [407, 300, 291, 393, 536, 633, 1622, 300, 1709, 666, 1455, 309, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.45822676567182147, "compression_ratio": 1.5, "no_speech_prob": 4.710856501333183e-06}, {"id": 665, "seek": 310406, "start": 3131.2599999999998, "end": 3133.2599999999998, "text": " So let's say", "tokens": [407, 718, 311, 584], "temperature": 0.0, "avg_logprob": -0.45822676567182147, "compression_ratio": 1.5, "no_speech_prob": 4.710856501333183e-06}, {"id": 666, "seek": 313326, "start": 3133.26, "end": 3137.6600000000003, "text": " So let's grab our validation set data loader grab a batch from it", "tokens": [407, 718, 311, 4444, 527, 24071, 992, 1412, 3677, 260, 4444, 257, 15245, 490, 309], "temperature": 0.0, "avg_logprob": -0.20223330228756636, "compression_ratio": 1.7903225806451613, "no_speech_prob": 7.889185326348525e-06}, {"id": 667, "seek": 313326, "start": 3138.3, "end": 3142.7000000000003, "text": " Turn them into variables so we can stick them into a model put the model in evaluation mode", "tokens": [7956, 552, 666, 9102, 370, 321, 393, 2897, 552, 666, 257, 2316, 829, 264, 2316, 294, 13344, 4391], "temperature": 0.0, "avg_logprob": -0.20223330228756636, "compression_ratio": 1.7903225806451613, "no_speech_prob": 7.889185326348525e-06}, {"id": 668, "seek": 313326, "start": 3143.6200000000003, "end": 3146.38, "text": " Stick that data into we don't actually need", "tokens": [22744, 300, 1412, 666, 321, 500, 380, 767, 643], "temperature": 0.0, "avg_logprob": -0.20223330228756636, "compression_ratio": 1.7903225806451613, "no_speech_prob": 7.889185326348525e-06}, {"id": 669, "seek": 313326, "start": 3148.26, "end": 3153.6200000000003, "text": " Stick that data into our model to grab a batch of activations and remember", "tokens": [22744, 300, 1412, 666, 527, 2316, 281, 4444, 257, 15245, 295, 2430, 763, 293, 1604], "temperature": 0.0, "avg_logprob": -0.20223330228756636, "compression_ratio": 1.7903225806451613, "no_speech_prob": 7.889185326348525e-06}, {"id": 670, "seek": 313326, "start": 3154.1000000000004, "end": 3159.1400000000003, "text": " That the the final output convolution returned two items", "tokens": [663, 264, 264, 2572, 5598, 45216, 8752, 732, 4754], "temperature": 0.0, "avg_logprob": -0.20223330228756636, "compression_ratio": 1.7903225806451613, "no_speech_prob": 7.889185326348525e-06}, {"id": 671, "seek": 315914, "start": 3159.14, "end": 3166.46, "text": " All right the the classes and the bounding boxes so we can do destructuring assignment to grab the two pieces", "tokens": [1057, 558, 264, 264, 5359, 293, 264, 5472, 278, 9002, 370, 321, 393, 360, 2677, 1757, 1345, 15187, 281, 4444, 264, 732, 3755], "temperature": 0.0, "avg_logprob": -0.24379477629790436, "compression_ratio": 1.6962025316455696, "no_speech_prob": 3.844913408102002e-06}, {"id": 672, "seek": 315914, "start": 3166.8199999999997, "end": 3168.9, "text": " the batch of classes and", "tokens": [264, 15245, 295, 5359, 293], "temperature": 0.0, "avg_logprob": -0.24379477629790436, "compression_ratio": 1.6962025316455696, "no_speech_prob": 3.844913408102002e-06}, {"id": 673, "seek": 315914, "start": 3170.2999999999997, "end": 3172.5, "text": " Outputs and the batch of bounding box", "tokens": [5925, 2582, 82, 293, 264, 15245, 295, 5472, 278, 2424], "temperature": 0.0, "avg_logprob": -0.24379477629790436, "compression_ratio": 1.6962025316455696, "no_speech_prob": 3.844913408102002e-06}, {"id": 674, "seek": 315914, "start": 3173.3799999999997, "end": 3175.18, "text": " outputs okay", "tokens": [23930, 1392], "temperature": 0.0, "avg_logprob": -0.24379477629790436, "compression_ratio": 1.6962025316455696, "no_speech_prob": 3.844913408102002e-06}, {"id": 675, "seek": 315914, "start": 3175.18, "end": 3182.04, "text": " And so as expected the batch of class outputs is batch size 64 by", "tokens": [400, 370, 382, 5176, 264, 15245, 295, 1508, 23930, 307, 15245, 2744, 12145, 538], "temperature": 0.0, "avg_logprob": -0.24379477629790436, "compression_ratio": 1.6962025316455696, "no_speech_prob": 3.844913408102002e-06}, {"id": 676, "seek": 315914, "start": 3183.3399999999997, "end": 3184.94, "text": " 16", "tokens": [3165], "temperature": 0.0, "avg_logprob": -0.24379477629790436, "compression_ratio": 1.6962025316455696, "no_speech_prob": 3.844913408102002e-06}, {"id": 677, "seek": 315914, "start": 3184.94, "end": 3186.8599999999997, "text": " grid cells by", "tokens": [10748, 5438, 538], "temperature": 0.0, "avg_logprob": -0.24379477629790436, "compression_ratio": 1.6962025316455696, "no_speech_prob": 3.844913408102002e-06}, {"id": 678, "seek": 318686, "start": 3186.86, "end": 3192.6, "text": " 21 classes and then 64 by 16 by 4 for the bounding box coordinates", "tokens": [5080, 5359, 293, 550, 12145, 538, 3165, 538, 1017, 337, 264, 5472, 278, 2424, 21056], "temperature": 0.0, "avg_logprob": -0.19716479561545633, "compression_ratio": 1.644859813084112, "no_speech_prob": 4.785063083545538e-06}, {"id": 679, "seek": 318686, "start": 3192.9, "end": 3199.1800000000003, "text": " Okay, hopefully that all makes sense and after class go back and just make sure if it's not obvious", "tokens": [1033, 11, 4696, 300, 439, 1669, 2020, 293, 934, 1508, 352, 646, 293, 445, 652, 988, 498, 309, 311, 406, 6322], "temperature": 0.0, "avg_logprob": -0.19716479561545633, "compression_ratio": 1.644859813084112, "no_speech_prob": 4.785063083545538e-06}, {"id": 680, "seek": 318686, "start": 3199.1800000000003, "end": 3203.1400000000003, "text": " Why these are the shapes make sure you get to the point where you understand why they are", "tokens": [1545, 613, 366, 264, 10854, 652, 988, 291, 483, 281, 264, 935, 689, 291, 1223, 983, 436, 366], "temperature": 0.0, "avg_logprob": -0.19716479561545633, "compression_ratio": 1.644859813084112, "no_speech_prob": 4.785063083545538e-06}, {"id": 681, "seek": 318686, "start": 3204.94, "end": 3208.1800000000003, "text": " Let's now go back and look at the", "tokens": [961, 311, 586, 352, 646, 293, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.19716479561545633, "compression_ratio": 1.644859813084112, "no_speech_prob": 4.785063083545538e-06}, {"id": 682, "seek": 318686, "start": 3209.5, "end": 3214.7200000000003, "text": " The ground truth so the ground truth is is in this y variable", "tokens": [440, 2727, 3494, 370, 264, 2727, 3494, 307, 307, 294, 341, 288, 7006], "temperature": 0.0, "avg_logprob": -0.19716479561545633, "compression_ratio": 1.644859813084112, "no_speech_prob": 4.785063083545538e-06}, {"id": 683, "seek": 321472, "start": 3214.72, "end": 3217.8399999999997, "text": " so let's grab the", "tokens": [370, 718, 311, 4444, 264], "temperature": 0.0, "avg_logprob": -0.25057928562164306, "compression_ratio": 1.7595628415300546, "no_speech_prob": 5.862749731022632e-06}, {"id": 684, "seek": 321472, "start": 3220.24, "end": 3223.9599999999996, "text": " Bounding box part and the class part and put them into", "tokens": [363, 24625, 2424, 644, 293, 264, 1508, 644, 293, 829, 552, 666], "temperature": 0.0, "avg_logprob": -0.25057928562164306, "compression_ratio": 1.7595628415300546, "no_speech_prob": 5.862749731022632e-06}, {"id": 685, "seek": 321472, "start": 3225.08, "end": 3228.9599999999996, "text": " These two Python variables and print them out and so there's our", "tokens": [1981, 732, 15329, 9102, 293, 4482, 552, 484, 293, 370, 456, 311, 527], "temperature": 0.0, "avg_logprob": -0.25057928562164306, "compression_ratio": 1.7595628415300546, "no_speech_prob": 5.862749731022632e-06}, {"id": 686, "seek": 321472, "start": 3229.56, "end": 3237.9199999999996, "text": " Ground truth bounding boxes and there's our ground truth classes. So this this image apparently has three objects in it. So let's", "tokens": [28371, 3494, 5472, 278, 9002, 293, 456, 311, 527, 2727, 3494, 5359, 13, 407, 341, 341, 3256, 7970, 575, 1045, 6565, 294, 309, 13, 407, 718, 311], "temperature": 0.0, "avg_logprob": -0.25057928562164306, "compression_ratio": 1.7595628415300546, "no_speech_prob": 5.862749731022632e-06}, {"id": 687, "seek": 321472, "start": 3238.72, "end": 3241.6, "text": " Draw a picture of the three objects and there they are", "tokens": [20386, 257, 3036, 295, 264, 1045, 6565, 293, 456, 436, 366], "temperature": 0.0, "avg_logprob": -0.25057928562164306, "compression_ratio": 1.7595628415300546, "no_speech_prob": 5.862749731022632e-06}, {"id": 688, "seek": 324160, "start": 3241.6, "end": 3247.36, "text": " Okay, we already have a show ground truth function the torch", "tokens": [1033, 11, 321, 1217, 362, 257, 855, 2727, 3494, 2445, 264, 27822], "temperature": 0.0, "avg_logprob": -0.18401560030485453, "compression_ratio": 1.5625, "no_speech_prob": 1.0952978300338145e-05}, {"id": 689, "seek": 324160, "start": 3247.96, "end": 3254.88, "text": " Ground-truth function simply converts the tensors into numpy and passes them along so that we can print them out", "tokens": [28371, 12, 6903, 2910, 2445, 2935, 38874, 264, 10688, 830, 666, 1031, 8200, 293, 11335, 552, 2051, 370, 300, 321, 393, 4482, 552, 484], "temperature": 0.0, "avg_logprob": -0.18401560030485453, "compression_ratio": 1.5625, "no_speech_prob": 1.0952978300338145e-05}, {"id": 690, "seek": 324160, "start": 3254.88, "end": 3256.88, "text": " So here we've got", "tokens": [407, 510, 321, 600, 658], "temperature": 0.0, "avg_logprob": -0.18401560030485453, "compression_ratio": 1.5625, "no_speech_prob": 1.0952978300338145e-05}, {"id": 691, "seek": 324160, "start": 3257.16, "end": 3259.16, "text": " the bounding box", "tokens": [264, 5472, 278, 2424], "temperature": 0.0, "avg_logprob": -0.18401560030485453, "compression_ratio": 1.5625, "no_speech_prob": 1.0952978300338145e-05}, {"id": 692, "seek": 324160, "start": 3260.72, "end": 3265.94, "text": " Coordinates you'll notice that they've all been scaled to zero to what between zero and one", "tokens": [39620, 1024, 291, 603, 3449, 300, 436, 600, 439, 668, 36039, 281, 4018, 281, 437, 1296, 4018, 293, 472], "temperature": 0.0, "avg_logprob": -0.18401560030485453, "compression_ratio": 1.5625, "no_speech_prob": 1.0952978300338145e-05}, {"id": 693, "seek": 326594, "start": 3265.94, "end": 3272.66, "text": " Okay, so basically we're treating the image as being like one by one. So these are all relative to the size of the image", "tokens": [1033, 11, 370, 1936, 321, 434, 15083, 264, 3256, 382, 885, 411, 472, 538, 472, 13, 407, 613, 366, 439, 4972, 281, 264, 2744, 295, 264, 3256], "temperature": 0.0, "avg_logprob": -0.22392075712030585, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.8738686549113481e-06}, {"id": 694, "seek": 326594, "start": 3272.9, "end": 3279.02, "text": " There's our three classes and so here they are chair is zero dining table is one and two is sofa", "tokens": [821, 311, 527, 1045, 5359, 293, 370, 510, 436, 366, 6090, 307, 4018, 17874, 3199, 307, 472, 293, 732, 307, 28668], "temperature": 0.0, "avg_logprob": -0.22392075712030585, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.8738686549113481e-06}, {"id": 695, "seek": 326594, "start": 3279.18, "end": 3281.46, "text": " This is not a model. This is the ground truth", "tokens": [639, 307, 406, 257, 2316, 13, 639, 307, 264, 2727, 3494], "temperature": 0.0, "avg_logprob": -0.22392075712030585, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.8738686549113481e-06}, {"id": 696, "seek": 326594, "start": 3282.9, "end": 3284.9, "text": " Great", "tokens": [3769], "temperature": 0.0, "avg_logprob": -0.22392075712030585, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.8738686549113481e-06}, {"id": 697, "seek": 326594, "start": 3285.46, "end": 3287.7000000000003, "text": " Here is our four by four", "tokens": [1692, 307, 527, 1451, 538, 1451], "temperature": 0.0, "avg_logprob": -0.22392075712030585, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.8738686549113481e-06}, {"id": 698, "seek": 326594, "start": 3289.2200000000003, "end": 3292.46, "text": " grid cells from our final convolutional letter", "tokens": [10748, 5438, 490, 527, 2572, 45216, 304, 5063], "temperature": 0.0, "avg_logprob": -0.22392075712030585, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.8738686549113481e-06}, {"id": 699, "seek": 329246, "start": 3292.46, "end": 3295.34, "text": " So each of these square boxes", "tokens": [407, 1184, 295, 613, 3732, 9002], "temperature": 0.0, "avg_logprob": -0.4351571924546186, "compression_ratio": 1.6790697674418604, "no_speech_prob": 2.4060825580818346e-06}, {"id": 700, "seek": 329246, "start": 3296.18, "end": 3301.98, "text": " Different papers call them different things the three terms you'll hear are anchor boxes", "tokens": [20825, 10577, 818, 552, 819, 721, 264, 1045, 2115, 291, 603, 1568, 366, 18487, 9002], "temperature": 0.0, "avg_logprob": -0.4351571924546186, "compression_ratio": 1.6790697674418604, "no_speech_prob": 2.4060825580818346e-06}, {"id": 701, "seek": 329246, "start": 3302.7, "end": 3306.82, "text": " prior boxes or default boxes, okay and", "tokens": [4059, 9002, 420, 7576, 9002, 11, 1392, 293], "temperature": 0.0, "avg_logprob": -0.4351571924546186, "compression_ratio": 1.6790697674418604, "no_speech_prob": 2.4060825580818346e-06}, {"id": 702, "seek": 329246, "start": 3307.82, "end": 3313.54, "text": " Through this explanation you'll get a sense of what they are. But for now think of them as just these 16 squares", "tokens": [8927, 341, 10835, 291, 603, 483, 257, 2020, 295, 437, 436, 366, 13, 583, 337, 586, 519, 295, 552, 382, 445, 613, 3165, 19368], "temperature": 0.0, "avg_logprob": -0.4351571924546186, "compression_ratio": 1.6790697674418604, "no_speech_prob": 2.4060825580818346e-06}, {"id": 703, "seek": 329246, "start": 3314.06, "end": 3319.18, "text": " I'm going to stick with the term anchor boxes. Okay, these 16 squares are our anchor boxes", "tokens": [286, 478, 516, 281, 2897, 365, 264, 1433, 18487, 9002, 13, 1033, 11, 613, 3165, 19368, 366, 527, 18487, 9002], "temperature": 0.0, "avg_logprob": -0.4351571924546186, "compression_ratio": 1.6790697674418604, "no_speech_prob": 2.4060825580818346e-06}, {"id": 704, "seek": 331918, "start": 3319.18, "end": 3324.18, "text": " So what we're going to do for this loss function is we're going to go through a matching problem", "tokens": [407, 437, 321, 434, 516, 281, 360, 337, 341, 4470, 2445, 307, 321, 434, 516, 281, 352, 807, 257, 14324, 1154], "temperature": 0.0, "avg_logprob": -0.3950262168019088, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.955094820819795e-06}, {"id": 705, "seek": 331918, "start": 3324.74, "end": 3328.74, "text": " Where we're going to take every one of these 16 boxes and we're going to see", "tokens": [2305, 321, 434, 516, 281, 747, 633, 472, 295, 613, 3165, 9002, 293, 321, 434, 516, 281, 536], "temperature": 0.0, "avg_logprob": -0.3950262168019088, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.955094820819795e-06}, {"id": 706, "seek": 331918, "start": 3329.46, "end": 3335.22, "text": " Which one of these three round truth objects has the highest amount of overlap?", "tokens": [3013, 472, 295, 613, 1045, 3098, 3494, 6565, 575, 264, 6343, 2372, 295, 19959, 30], "temperature": 0.0, "avg_logprob": -0.3950262168019088, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.955094820819795e-06}, {"id": 707, "seek": 331918, "start": 3335.94, "end": 3337.94, "text": " with this square", "tokens": [365, 341, 3732], "temperature": 0.0, "avg_logprob": -0.3950262168019088, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.955094820819795e-06}, {"id": 708, "seek": 331918, "start": 3338.5, "end": 3339.8599999999997, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.3950262168019088, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.955094820819795e-06}, {"id": 709, "seek": 331918, "start": 3339.8599999999997, "end": 3343.58, "text": " So to do that, we're going to need to know", "tokens": [407, 281, 360, 300, 11, 321, 434, 516, 281, 643, 281, 458], "temperature": 0.0, "avg_logprob": -0.3950262168019088, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.955094820819795e-06}, {"id": 710, "seek": 331918, "start": 3344.7799999999997, "end": 3346.7799999999997, "text": " We're going to have to have some way of measuring", "tokens": [492, 434, 516, 281, 362, 281, 362, 512, 636, 295, 13389], "temperature": 0.0, "avg_logprob": -0.3950262168019088, "compression_ratio": 1.7777777777777777, "no_speech_prob": 5.955094820819795e-06}, {"id": 711, "seek": 334678, "start": 3346.78, "end": 3351.6200000000003, "text": " We're going to have to have some way of measuring an amount of overlap and there's a standard", "tokens": [492, 434, 516, 281, 362, 281, 362, 512, 636, 295, 13389, 364, 2372, 295, 19959, 293, 456, 311, 257, 3832], "temperature": 0.0, "avg_logprob": -0.173316590329434, "compression_ratio": 1.731958762886598, "no_speech_prob": 3.34052242578764e-06}, {"id": 712, "seek": 334678, "start": 3352.34, "end": 3355.78, "text": " Function for this which is called the jacquard index", "tokens": [11166, 882, 337, 341, 597, 307, 1219, 264, 361, 326, 358, 515, 8186], "temperature": 0.0, "avg_logprob": -0.173316590329434, "compression_ratio": 1.731958762886598, "no_speech_prob": 3.34052242578764e-06}, {"id": 713, "seek": 334678, "start": 3356.5, "end": 3361.4, "text": " And the jacquard index is very simple. I'll do it through example. Let's take", "tokens": [400, 264, 361, 326, 358, 515, 8186, 307, 588, 2199, 13, 286, 603, 360, 309, 807, 1365, 13, 961, 311, 747], "temperature": 0.0, "avg_logprob": -0.173316590329434, "compression_ratio": 1.731958762886598, "no_speech_prob": 3.34052242578764e-06}, {"id": 714, "seek": 334678, "start": 3362.5, "end": 3364.5, "text": " this sofa", "tokens": [341, 28668], "temperature": 0.0, "avg_logprob": -0.173316590329434, "compression_ratio": 1.731958762886598, "no_speech_prob": 3.34052242578764e-06}, {"id": 715, "seek": 334678, "start": 3364.6600000000003, "end": 3372.1000000000004, "text": " Okay, so if we take this sofa and let's take the jacquard index of this sofa with this grid cell here", "tokens": [1033, 11, 370, 498, 321, 747, 341, 28668, 293, 718, 311, 747, 264, 361, 326, 358, 515, 8186, 295, 341, 28668, 365, 341, 10748, 2815, 510], "temperature": 0.0, "avg_logprob": -0.173316590329434, "compression_ratio": 1.731958762886598, "no_speech_prob": 3.34052242578764e-06}, {"id": 716, "seek": 337210, "start": 3372.1, "end": 3376.7, "text": " All right. What we do is we find the area of their intersection so", "tokens": [1057, 558, 13, 708, 321, 360, 307, 321, 915, 264, 1859, 295, 641, 15236, 370], "temperature": 0.0, "avg_logprob": -0.25867673433743993, "compression_ratio": 1.890625, "no_speech_prob": 6.24088943368406e-06}, {"id": 717, "seek": 337210, "start": 3383.06, "end": 3385.46, "text": " Here is the area of their intersection", "tokens": [1692, 307, 264, 1859, 295, 641, 15236], "temperature": 0.0, "avg_logprob": -0.25867673433743993, "compression_ratio": 1.890625, "no_speech_prob": 6.24088943368406e-06}, {"id": 718, "seek": 337210, "start": 3386.98, "end": 3393.86, "text": " Okay, and then we find the area of their union. So here is the", "tokens": [1033, 11, 293, 550, 321, 915, 264, 1859, 295, 641, 11671, 13, 407, 510, 307, 264], "temperature": 0.0, "avg_logprob": -0.25867673433743993, "compression_ratio": 1.890625, "no_speech_prob": 6.24088943368406e-06}, {"id": 719, "seek": 337210, "start": 3396.14, "end": 3400.1, "text": " Area of their you that's not very helpful. Here's the area of their union", "tokens": [19405, 295, 641, 291, 300, 311, 406, 588, 4961, 13, 1692, 311, 264, 1859, 295, 641, 11671], "temperature": 0.0, "avg_logprob": -0.25867673433743993, "compression_ratio": 1.890625, "no_speech_prob": 6.24088943368406e-06}, {"id": 720, "seek": 340010, "start": 3400.1, "end": 3405.22, "text": " Okay, and then we say take the intersection", "tokens": [1033, 11, 293, 550, 321, 584, 747, 264, 15236], "temperature": 0.0, "avg_logprob": -0.3400450547536214, "compression_ratio": 1.5207100591715976, "no_speech_prob": 3.5008297345484607e-06}, {"id": 721, "seek": 340010, "start": 3406.2999999999997, "end": 3408.2999999999997, "text": " divided by the union", "tokens": [6666, 538, 264, 11671], "temperature": 0.0, "avg_logprob": -0.3400450547536214, "compression_ratio": 1.5207100591715976, "no_speech_prob": 3.5008297345484607e-06}, {"id": 722, "seek": 340010, "start": 3408.54, "end": 3411.2599999999998, "text": " Okay, and so that's jacquard index", "tokens": [1033, 11, 293, 370, 300, 311, 361, 326, 358, 515, 8186], "temperature": 0.0, "avg_logprob": -0.3400450547536214, "compression_ratio": 1.5207100591715976, "no_speech_prob": 3.5008297345484607e-06}, {"id": 723, "seek": 340010, "start": 3412.7799999999997, "end": 3416.66, "text": " Also known as I O you intersection over", "tokens": [2743, 2570, 382, 286, 422, 291, 15236, 670], "temperature": 0.0, "avg_logprob": -0.3400450547536214, "compression_ratio": 1.5207100591715976, "no_speech_prob": 3.5008297345484607e-06}, {"id": 724, "seek": 340010, "start": 3417.8199999999997, "end": 3425.2599999999998, "text": " That's of two things overlapped by more compared to their total sizes together. They have a higher jacquard", "tokens": [663, 311, 295, 732, 721, 670, 875, 3320, 538, 544, 5347, 281, 641, 3217, 11602, 1214, 13, 814, 362, 257, 2946, 361, 326, 358, 515], "temperature": 0.0, "avg_logprob": -0.3400450547536214, "compression_ratio": 1.5207100591715976, "no_speech_prob": 3.5008297345484607e-06}, {"id": 725, "seek": 342526, "start": 3425.26, "end": 3428.5200000000004, "text": " index all right, so", "tokens": [8186, 439, 558, 11, 370], "temperature": 0.0, "avg_logprob": -0.24582434863578984, "compression_ratio": 1.5473684210526315, "no_speech_prob": 4.222798452246934e-06}, {"id": 726, "seek": 342526, "start": 3432.1400000000003, "end": 3434.2200000000003, "text": " We're going to go through and find the jacquard", "tokens": [492, 434, 516, 281, 352, 807, 293, 915, 264, 361, 326, 358, 515], "temperature": 0.0, "avg_logprob": -0.24582434863578984, "compression_ratio": 1.5473684210526315, "no_speech_prob": 4.222798452246934e-06}, {"id": 727, "seek": 342526, "start": 3435.0600000000004, "end": 3439.7400000000002, "text": " Overlap for each one of these three objects versus each of these 16 anchor boxes", "tokens": [4886, 75, 569, 337, 1184, 472, 295, 613, 1045, 6565, 5717, 1184, 295, 613, 3165, 18487, 9002], "temperature": 0.0, "avg_logprob": -0.24582434863578984, "compression_ratio": 1.5473684210526315, "no_speech_prob": 4.222798452246934e-06}, {"id": 728, "seek": 342526, "start": 3439.7400000000002, "end": 3443.34, "text": " And so that's going to give us a 3 by 16 matrix", "tokens": [400, 370, 300, 311, 516, 281, 976, 505, 257, 805, 538, 3165, 8141], "temperature": 0.0, "avg_logprob": -0.24582434863578984, "compression_ratio": 1.5473684210526315, "no_speech_prob": 4.222798452246934e-06}, {"id": 729, "seek": 342526, "start": 3443.5, "end": 3448.44, "text": " But for every ground truth object and every anchor box how much overlap is there?", "tokens": [583, 337, 633, 2727, 3494, 2657, 293, 633, 18487, 2424, 577, 709, 19959, 307, 456, 30], "temperature": 0.0, "avg_logprob": -0.24582434863578984, "compression_ratio": 1.5473684210526315, "no_speech_prob": 4.222798452246934e-06}, {"id": 730, "seek": 342526, "start": 3450.1800000000003, "end": 3452.1800000000003, "text": " So here are the", "tokens": [407, 510, 366, 264], "temperature": 0.0, "avg_logprob": -0.24582434863578984, "compression_ratio": 1.5473684210526315, "no_speech_prob": 4.222798452246934e-06}, {"id": 731, "seek": 345218, "start": 3452.18, "end": 3455.62, "text": " coordinates of all of our anchor boxes", "tokens": [21056, 295, 439, 295, 527, 18487, 9002], "temperature": 0.0, "avg_logprob": -0.3158219155300869, "compression_ratio": 1.618811881188119, "no_speech_prob": 3.844912953354651e-06}, {"id": 732, "seek": 345218, "start": 3456.22, "end": 3460.14, "text": " In this case, they're printed as center and height and width", "tokens": [682, 341, 1389, 11, 436, 434, 13567, 382, 3056, 293, 6681, 293, 11402], "temperature": 0.0, "avg_logprob": -0.3158219155300869, "compression_ratio": 1.618811881188119, "no_speech_prob": 3.844912953354651e-06}, {"id": 733, "seek": 345218, "start": 3462.66, "end": 3464.66, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.3158219155300869, "compression_ratio": 1.618811881188119, "no_speech_prob": 3.844912953354651e-06}, {"id": 734, "seek": 345218, "start": 3465.5, "end": 3467.7, "text": " So here is the amount of overlap", "tokens": [407, 510, 307, 264, 2372, 295, 19959], "temperature": 0.0, "avg_logprob": -0.3158219155300869, "compression_ratio": 1.618811881188119, "no_speech_prob": 3.844912953354651e-06}, {"id": 735, "seek": 345218, "start": 3468.5, "end": 3472.8799999999997, "text": " Between and as you can see it's 3 by 16 right so for each of the three", "tokens": [18967, 293, 382, 291, 393, 536, 309, 311, 805, 538, 3165, 558, 370, 337, 1184, 295, 264, 1045], "temperature": 0.0, "avg_logprob": -0.3158219155300869, "compression_ratio": 1.618811881188119, "no_speech_prob": 3.844912953354651e-06}, {"id": 736, "seek": 347288, "start": 3472.88, "end": 3481.88, "text": " Ground truth objects for each of these 16 anchor boxes how much do they overlap right so you can see here zero one two three four five six seven eight?", "tokens": [28371, 3494, 6565, 337, 1184, 295, 613, 3165, 18487, 9002, 577, 709, 360, 436, 19959, 558, 370, 291, 393, 536, 510, 4018, 472, 732, 1045, 1451, 1732, 2309, 3407, 3180, 30], "temperature": 0.0, "avg_logprob": -0.3011414082845052, "compression_ratio": 1.6117021276595744, "no_speech_prob": 7.4112308539042715e-06}, {"id": 737, "seek": 347288, "start": 3482.4, "end": 3484.4, "text": " the eighth", "tokens": [264, 19495], "temperature": 0.0, "avg_logprob": -0.3011414082845052, "compression_ratio": 1.6117021276595744, "no_speech_prob": 7.4112308539042715e-06}, {"id": 738, "seek": 347288, "start": 3485.56, "end": 3487.04, "text": " anchor box", "tokens": [18487, 2424], "temperature": 0.0, "avg_logprob": -0.3011414082845052, "compression_ratio": 1.6117021276595744, "no_speech_prob": 7.4112308539042715e-06}, {"id": 739, "seek": 347288, "start": 3487.04, "end": 3493.04, "text": " overlaps a little bit with the second ground truth object okay, so", "tokens": [15986, 2382, 257, 707, 857, 365, 264, 1150, 2727, 3494, 2657, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.3011414082845052, "compression_ratio": 1.6117021276595744, "no_speech_prob": 7.4112308539042715e-06}, {"id": 740, "seek": 347288, "start": 3494.2400000000002, "end": 3497.96, "text": " What we could do now is we could take the max of dimension one", "tokens": [708, 321, 727, 360, 586, 307, 321, 727, 747, 264, 11469, 295, 10139, 472], "temperature": 0.0, "avg_logprob": -0.3011414082845052, "compression_ratio": 1.6117021276595744, "no_speech_prob": 7.4112308539042715e-06}, {"id": 741, "seek": 349796, "start": 3497.96, "end": 3503.68, "text": " All right, so the max of each row and that will tell us for each ground truth object", "tokens": [1057, 558, 11, 370, 264, 11469, 295, 1184, 5386, 293, 300, 486, 980, 505, 337, 1184, 2727, 3494, 2657], "temperature": 0.0, "avg_logprob": -0.2785058610894707, "compression_ratio": 1.698019801980198, "no_speech_prob": 4.710878329206025e-06}, {"id": 742, "seek": 349796, "start": 3503.88, "end": 3508.36, "text": " What's the maximum amount that it overlaps with some grid cell and?", "tokens": [708, 311, 264, 6674, 2372, 300, 309, 15986, 2382, 365, 512, 10748, 2815, 293, 30], "temperature": 0.0, "avg_logprob": -0.2785058610894707, "compression_ratio": 1.698019801980198, "no_speech_prob": 4.710878329206025e-06}, {"id": 743, "seek": 349796, "start": 3509.44, "end": 3516.68, "text": " It also tells us remember pi torch when you say max returns two things it says what is the max and what is the index?", "tokens": [467, 611, 5112, 505, 1604, 3895, 27822, 562, 291, 584, 11469, 11247, 732, 721, 309, 1619, 437, 307, 264, 11469, 293, 437, 307, 264, 8186, 30], "temperature": 0.0, "avg_logprob": -0.2785058610894707, "compression_ratio": 1.698019801980198, "no_speech_prob": 4.710878329206025e-06}, {"id": 744, "seek": 349796, "start": 3516.92, "end": 3520.0, "text": " of the max so for each of these things the", "tokens": [295, 264, 11469, 370, 337, 1184, 295, 613, 721, 264], "temperature": 0.0, "avg_logprob": -0.2785058610894707, "compression_ratio": 1.698019801980198, "no_speech_prob": 4.710878329206025e-06}, {"id": 745, "seek": 349796, "start": 3520.52, "end": 3523.92, "text": " 14th grid cell is the largest", "tokens": [3499, 392, 10748, 2815, 307, 264, 6443], "temperature": 0.0, "avg_logprob": -0.2785058610894707, "compression_ratio": 1.698019801980198, "no_speech_prob": 4.710878329206025e-06}, {"id": 746, "seek": 352392, "start": 3523.92, "end": 3530.8, "text": " It is 14th is the largest overlap for the first ground truth 13 for the second", "tokens": [467, 307, 3499, 392, 307, 264, 6443, 19959, 337, 264, 700, 2727, 3494, 3705, 337, 264, 1150], "temperature": 0.0, "avg_logprob": -0.2267874466745477, "compression_ratio": 1.6681818181818182, "no_speech_prob": 2.4060957457550103e-06}, {"id": 747, "seek": 352392, "start": 3531.44, "end": 3533.88, "text": " Okay, and 11 for the third", "tokens": [1033, 11, 293, 2975, 337, 264, 2636], "temperature": 0.0, "avg_logprob": -0.2267874466745477, "compression_ratio": 1.6681818181818182, "no_speech_prob": 2.4060957457550103e-06}, {"id": 748, "seek": 352392, "start": 3535.44, "end": 3537.44, "text": " Okay, so that tells us", "tokens": [1033, 11, 370, 300, 5112, 505], "temperature": 0.0, "avg_logprob": -0.2267874466745477, "compression_ratio": 1.6681818181818182, "no_speech_prob": 2.4060957457550103e-06}, {"id": 749, "seek": 352392, "start": 3537.6, "end": 3545.28, "text": " You know a pretty good way of assigning each of these ground truth objects to a grid cell what what the match is is which?", "tokens": [509, 458, 257, 1238, 665, 636, 295, 49602, 1184, 295, 613, 2727, 3494, 6565, 281, 257, 10748, 2815, 437, 437, 264, 2995, 307, 307, 597, 30], "temperature": 0.0, "avg_logprob": -0.2267874466745477, "compression_ratio": 1.6681818181818182, "no_speech_prob": 2.4060957457550103e-06}, {"id": 750, "seek": 352392, "start": 3545.28, "end": 3547.28, "text": " One is the highest overlap", "tokens": [1485, 307, 264, 6343, 19959], "temperature": 0.0, "avg_logprob": -0.2267874466745477, "compression_ratio": 1.6681818181818182, "no_speech_prob": 2.4060957457550103e-06}, {"id": 751, "seek": 352392, "start": 3547.92, "end": 3552.7200000000003, "text": " But we're going to do a second thing we're also going to look at max over dimension zero", "tokens": [583, 321, 434, 516, 281, 360, 257, 1150, 551, 321, 434, 611, 516, 281, 574, 412, 11469, 670, 10139, 4018], "temperature": 0.0, "avg_logprob": -0.2267874466745477, "compression_ratio": 1.6681818181818182, "no_speech_prob": 2.4060957457550103e-06}, {"id": 752, "seek": 355272, "start": 3552.72, "end": 3556.8799999999997, "text": " And max over dimension zero is going to tell us", "tokens": [400, 11469, 670, 10139, 4018, 307, 516, 281, 980, 505], "temperature": 0.0, "avg_logprob": -0.18616473965528535, "compression_ratio": 1.6794258373205742, "no_speech_prob": 5.422190497483825e-06}, {"id": 753, "seek": 355272, "start": 3557.04, "end": 3565.24, "text": " What's the maximum amount of overlap for each grid cell so across all of the ground truth objects?", "tokens": [708, 311, 264, 6674, 2372, 295, 19959, 337, 1184, 10748, 2815, 370, 2108, 439, 295, 264, 2727, 3494, 6565, 30], "temperature": 0.0, "avg_logprob": -0.18616473965528535, "compression_ratio": 1.6794258373205742, "no_speech_prob": 5.422190497483825e-06}, {"id": 754, "seek": 355272, "start": 3565.52, "end": 3571.8199999999997, "text": " Right and so particularly interesting here tells us for every grid cell 16", "tokens": [1779, 293, 370, 4098, 1880, 510, 5112, 505, 337, 633, 10748, 2815, 3165], "temperature": 0.0, "avg_logprob": -0.18616473965528535, "compression_ratio": 1.6794258373205742, "no_speech_prob": 5.422190497483825e-06}, {"id": 755, "seek": 355272, "start": 3572.04, "end": 3577.16, "text": " What's the index of the ground truth object which overlaps with it the most?", "tokens": [708, 311, 264, 8186, 295, 264, 2727, 3494, 2657, 597, 15986, 2382, 365, 309, 264, 881, 30], "temperature": 0.0, "avg_logprob": -0.18616473965528535, "compression_ratio": 1.6794258373205742, "no_speech_prob": 5.422190497483825e-06}, {"id": 756, "seek": 357716, "start": 3577.16, "end": 3582.8799999999997, "text": " Zero is a bit overloaded here zero could either mean the amount of overlap was zero or", "tokens": [17182, 307, 257, 857, 28777, 292, 510, 4018, 727, 2139, 914, 264, 2372, 295, 19959, 390, 4018, 420], "temperature": 0.0, "avg_logprob": -0.4235684871673584, "compression_ratio": 1.6347826086956523, "no_speech_prob": 1.933350631588837e-06}, {"id": 757, "seek": 357716, "start": 3583.7599999999998, "end": 3588.7599999999998, "text": " It could mean its largest overlap is with object index zero", "tokens": [467, 727, 914, 1080, 6443, 19959, 307, 365, 2657, 8186, 4018], "temperature": 0.0, "avg_logprob": -0.4235684871673584, "compression_ratio": 1.6347826086956523, "no_speech_prob": 1.933350631588837e-06}, {"id": 758, "seek": 357716, "start": 3589.48, "end": 3594.12, "text": " It's going to turn out not to matter that I just wanted to explain why there's so many zeros here", "tokens": [467, 311, 516, 281, 1261, 484, 406, 281, 1871, 300, 286, 445, 1415, 281, 2903, 983, 456, 311, 370, 867, 35193, 510], "temperature": 0.0, "avg_logprob": -0.4235684871673584, "compression_ratio": 1.6347826086956523, "no_speech_prob": 1.933350631588837e-06}, {"id": 759, "seek": 357716, "start": 3595.48, "end": 3601.72, "text": " So there's a function called map to ground truth, which I'm not going to worry about for now. It's it's", "tokens": [407, 456, 311, 257, 2445, 1219, 4471, 281, 2727, 3494, 11, 597, 286, 478, 406, 516, 281, 3292, 466, 337, 586, 13, 467, 311, 309, 311], "temperature": 0.0, "avg_logprob": -0.4235684871673584, "compression_ratio": 1.6347826086956523, "no_speech_prob": 1.933350631588837e-06}, {"id": 760, "seek": 357716, "start": 3602.52, "end": 3605.08, "text": " super simple code, but it's", "tokens": [1687, 2199, 3089, 11, 457, 309, 311], "temperature": 0.0, "avg_logprob": -0.4235684871673584, "compression_ratio": 1.6347826086956523, "no_speech_prob": 1.933350631588837e-06}, {"id": 761, "seek": 360508, "start": 3605.08, "end": 3607.08, "text": " slightly awkward to", "tokens": [4748, 11411, 281], "temperature": 0.0, "avg_logprob": -0.38592110099373284, "compression_ratio": 1.733009708737864, "no_speech_prob": 3.1875515560386702e-06}, {"id": 762, "seek": 360508, "start": 3607.08, "end": 3614.12, "text": " To think about but basically what it does is it combines these two sets of overlaps in a way described in the SSD paper?", "tokens": [1407, 519, 466, 457, 1936, 437, 309, 775, 307, 309, 29520, 613, 732, 6352, 295, 15986, 2382, 294, 257, 636, 7619, 294, 264, 30262, 3035, 30], "temperature": 0.0, "avg_logprob": -0.38592110099373284, "compression_ratio": 1.733009708737864, "no_speech_prob": 3.1875515560386702e-06}, {"id": 763, "seek": 360508, "start": 3614.68, "end": 3616.2, "text": " to assign", "tokens": [281, 6269], "temperature": 0.0, "avg_logprob": -0.38592110099373284, "compression_ratio": 1.733009708737864, "no_speech_prob": 3.1875515560386702e-06}, {"id": 764, "seek": 360508, "start": 3616.2, "end": 3618.2, "text": " every", "tokens": [633], "temperature": 0.0, "avg_logprob": -0.38592110099373284, "compression_ratio": 1.733009708737864, "no_speech_prob": 3.1875515560386702e-06}, {"id": 765, "seek": 360508, "start": 3618.2, "end": 3620.2, "text": " anchor box to a", "tokens": [18487, 2424, 281, 257], "temperature": 0.0, "avg_logprob": -0.38592110099373284, "compression_ratio": 1.733009708737864, "no_speech_prob": 3.1875515560386702e-06}, {"id": 766, "seek": 360508, "start": 3620.52, "end": 3624.6, "text": " ground truth object and basically the way it assigns it is", "tokens": [2727, 3494, 2657, 293, 1936, 264, 636, 309, 6269, 82, 309, 307], "temperature": 0.0, "avg_logprob": -0.38592110099373284, "compression_ratio": 1.733009708737864, "no_speech_prob": 3.1875515560386702e-06}, {"id": 767, "seek": 360508, "start": 3625.08, "end": 3631.64, "text": " Each of these ones each of these three gets assigned in this way right so this one this object is assigned to", "tokens": [6947, 295, 613, 2306, 1184, 295, 613, 1045, 2170, 13279, 294, 341, 636, 558, 370, 341, 472, 341, 2657, 307, 13279, 281], "temperature": 0.0, "avg_logprob": -0.38592110099373284, "compression_ratio": 1.733009708737864, "no_speech_prob": 3.1875515560386702e-06}, {"id": 768, "seek": 360508, "start": 3632.2799999999997, "end": 3634.2799999999997, "text": " bounding object", "tokens": [5472, 278, 2657], "temperature": 0.0, "avg_logprob": -0.38592110099373284, "compression_ratio": 1.733009708737864, "no_speech_prob": 3.1875515560386702e-06}, {"id": 769, "seek": 363428, "start": 3634.28, "end": 3641.84, "text": " to bound to anchor box 14 this one to 13 and this one to 11 and then of the rest of the anchor boxes", "tokens": [281, 5472, 281, 18487, 2424, 3499, 341, 472, 281, 3705, 293, 341, 472, 281, 2975, 293, 550, 295, 264, 1472, 295, 264, 18487, 9002], "temperature": 0.0, "avg_logprob": -0.2561079065004985, "compression_ratio": 1.7547169811320755, "no_speech_prob": 2.994428086822154e-06}, {"id": 770, "seek": 363428, "start": 3642.1600000000003, "end": 3647.5, "text": " They get assigned to anything which they have an overlap of at least 0.5 with", "tokens": [814, 483, 13279, 281, 1340, 597, 436, 362, 364, 19959, 295, 412, 1935, 1958, 13, 20, 365], "temperature": 0.0, "avg_logprob": -0.2561079065004985, "compression_ratio": 1.7547169811320755, "no_speech_prob": 2.994428086822154e-06}, {"id": 771, "seek": 363428, "start": 3648.4, "end": 3650.4, "text": " if anything that doesn't", "tokens": [498, 1340, 300, 1177, 380], "temperature": 0.0, "avg_logprob": -0.2561079065004985, "compression_ratio": 1.7547169811320755, "no_speech_prob": 2.994428086822154e-06}, {"id": 772, "seek": 363428, "start": 3650.52, "end": 3652.52, "text": " Which isn't in either of those criteria?", "tokens": [3013, 1943, 380, 294, 2139, 295, 729, 11101, 30], "temperature": 0.0, "avg_logprob": -0.2561079065004985, "compression_ratio": 1.7547169811320755, "no_speech_prob": 2.994428086822154e-06}, {"id": 773, "seek": 363428, "start": 3652.96, "end": 3658.7200000000003, "text": " ie which either isn't a maximum or doesn't have a greater than 0.5 overlap is considered to be", "tokens": [43203, 597, 2139, 1943, 380, 257, 6674, 420, 1177, 380, 362, 257, 5044, 813, 1958, 13, 20, 19959, 307, 4888, 281, 312], "temperature": 0.0, "avg_logprob": -0.2561079065004985, "compression_ratio": 1.7547169811320755, "no_speech_prob": 2.994428086822154e-06}, {"id": 774, "seek": 363428, "start": 3659.0800000000004, "end": 3661.28, "text": " A cell which contains background", "tokens": [316, 2815, 597, 8306, 3678], "temperature": 0.0, "avg_logprob": -0.2561079065004985, "compression_ratio": 1.7547169811320755, "no_speech_prob": 2.994428086822154e-06}, {"id": 775, "seek": 366128, "start": 3661.28, "end": 3666.48, "text": " Okay, so that's all the map to ground truth function does and so after we go through it", "tokens": [1033, 11, 370, 300, 311, 439, 264, 4471, 281, 2727, 3494, 2445, 775, 293, 370, 934, 321, 352, 807, 309], "temperature": 0.0, "avg_logprob": -0.21099131816142314, "compression_ratio": 1.765625, "no_speech_prob": 5.955080268904567e-06}, {"id": 776, "seek": 366128, "start": 3666.6800000000003, "end": 3672.2400000000002, "text": " You can see now a list of all of the assignments and you can also see", "tokens": [509, 393, 536, 586, 257, 1329, 295, 439, 295, 264, 22546, 293, 291, 393, 611, 536], "temperature": 0.0, "avg_logprob": -0.21099131816142314, "compression_ratio": 1.765625, "no_speech_prob": 5.955080268904567e-06}, {"id": 777, "seek": 366128, "start": 3672.76, "end": 3677.92, "text": " Anywhere that there's a zero here it means it was assigned background in fact anywhere. It's less than 0.5 here", "tokens": [2639, 1992, 300, 456, 311, 257, 4018, 510, 309, 1355, 309, 390, 13279, 3678, 294, 1186, 4992, 13, 467, 311, 1570, 813, 1958, 13, 20, 510], "temperature": 0.0, "avg_logprob": -0.21099131816142314, "compression_ratio": 1.765625, "no_speech_prob": 5.955080268904567e-06}, {"id": 778, "seek": 366128, "start": 3678.2000000000003, "end": 3680.98, "text": " It was assigned a background so you can see those three", "tokens": [467, 390, 13279, 257, 3678, 370, 291, 393, 536, 729, 1045], "temperature": 0.0, "avg_logprob": -0.21099131816142314, "compression_ratio": 1.765625, "no_speech_prob": 5.955080268904567e-06}, {"id": 779, "seek": 366128, "start": 3681.88, "end": 3689.1200000000003, "text": " Which it kind of forced assignments that puts a high number in just to make sure that they're assigned all right so we can now", "tokens": [3013, 309, 733, 295, 7579, 22546, 300, 8137, 257, 1090, 1230, 294, 445, 281, 652, 988, 300, 436, 434, 13279, 439, 558, 370, 321, 393, 586], "temperature": 0.0, "avg_logprob": -0.21099131816142314, "compression_ratio": 1.765625, "no_speech_prob": 5.955080268904567e-06}, {"id": 780, "seek": 368912, "start": 3689.12, "end": 3691.72, "text": " Go ahead and convert those two classes", "tokens": [1037, 2286, 293, 7620, 729, 732, 5359], "temperature": 0.0, "avg_logprob": -0.4473971249012465, "compression_ratio": 1.6715686274509804, "no_speech_prob": 3.905446192220552e-06}, {"id": 781, "seek": 368912, "start": 3692.72, "end": 3700.3599999999997, "text": " And then we can make sure we just grab those which are at least 0.5 in size and so finally that allows us to spit out", "tokens": [400, 550, 321, 393, 652, 988, 321, 445, 4444, 729, 597, 366, 412, 1935, 1958, 13, 20, 294, 2744, 293, 370, 2721, 300, 4045, 505, 281, 22127, 484], "temperature": 0.0, "avg_logprob": -0.4473971249012465, "compression_ratio": 1.6715686274509804, "no_speech_prob": 3.905446192220552e-06}, {"id": 782, "seek": 368912, "start": 3701.3599999999997, "end": 3702.8399999999997, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.4473971249012465, "compression_ratio": 1.6715686274509804, "no_speech_prob": 3.905446192220552e-06}, {"id": 783, "seek": 368912, "start": 3702.8399999999997, "end": 3704.16, "text": " three", "tokens": [1045], "temperature": 0.0, "avg_logprob": -0.4473971249012465, "compression_ratio": 1.6715686274509804, "no_speech_prob": 3.905446192220552e-06}, {"id": 784, "seek": 368912, "start": 3704.16, "end": 3706.16, "text": " classes that are being predicted", "tokens": [5359, 300, 366, 885, 19147], "temperature": 0.0, "avg_logprob": -0.4473971249012465, "compression_ratio": 1.6715686274509804, "no_speech_prob": 3.905446192220552e-06}, {"id": 785, "seek": 368912, "start": 3706.92, "end": 3711.88, "text": " We can then put that back into the bounding boxes and so here are", "tokens": [492, 393, 550, 829, 300, 646, 666, 264, 5472, 278, 9002, 293, 370, 510, 366], "temperature": 0.0, "avg_logprob": -0.4473971249012465, "compression_ratio": 1.6715686274509804, "no_speech_prob": 3.905446192220552e-06}, {"id": 786, "seek": 368912, "start": 3712.7599999999998, "end": 3717.3599999999997, "text": " What each of those bounding boxes is sorry what each of those anchor boxes?", "tokens": [708, 1184, 295, 729, 5472, 278, 9002, 307, 2597, 437, 1184, 295, 729, 18487, 9002, 30], "temperature": 0.0, "avg_logprob": -0.4473971249012465, "compression_ratio": 1.6715686274509804, "no_speech_prob": 3.905446192220552e-06}, {"id": 787, "seek": 371736, "start": 3717.36, "end": 3721.88, "text": " What each of those anchor boxes is meant to be predicting okay, so", "tokens": [708, 1184, 295, 729, 18487, 9002, 307, 4140, 281, 312, 32884, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.18554576046495552, "compression_ratio": 2.0742857142857143, "no_speech_prob": 2.9022949092905037e-06}, {"id": 788, "seek": 371736, "start": 3722.52, "end": 3728.92, "text": " You can see sofa dining room table chair which makes perfect sense if we go back to here", "tokens": [509, 393, 536, 28668, 17874, 1808, 3199, 6090, 597, 1669, 2176, 2020, 498, 321, 352, 646, 281, 510], "temperature": 0.0, "avg_logprob": -0.18554576046495552, "compression_ratio": 2.0742857142857143, "no_speech_prob": 2.9022949092905037e-06}, {"id": 789, "seek": 371736, "start": 3730.56, "end": 3732.56, "text": " This is meant to be predicting sofa", "tokens": [639, 307, 4140, 281, 312, 32884, 28668], "temperature": 0.0, "avg_logprob": -0.18554576046495552, "compression_ratio": 2.0742857142857143, "no_speech_prob": 2.9022949092905037e-06}, {"id": 790, "seek": 371736, "start": 3733.44, "end": 3735.92, "text": " This is meant to be predicting dining room table", "tokens": [639, 307, 4140, 281, 312, 32884, 17874, 1808, 3199], "temperature": 0.0, "avg_logprob": -0.18554576046495552, "compression_ratio": 2.0742857142857143, "no_speech_prob": 2.9022949092905037e-06}, {"id": 791, "seek": 371736, "start": 3735.96, "end": 3740.52, "text": " This is meant to be predicting chair and everything else is meant to be predicting background", "tokens": [639, 307, 4140, 281, 312, 32884, 6090, 293, 1203, 1646, 307, 4140, 281, 312, 32884, 3678], "temperature": 0.0, "avg_logprob": -0.18554576046495552, "compression_ratio": 2.0742857142857143, "no_speech_prob": 2.9022949092905037e-06}, {"id": 792, "seek": 374052, "start": 3740.52, "end": 3746.52, "text": " So that's the matching stage", "tokens": [407, 300, 311, 264, 14324, 3233], "temperature": 0.0, "avg_logprob": -0.26187466738516824, "compression_ratio": 1.5753424657534247, "no_speech_prob": 1.7603358628548449e-06}, {"id": 793, "seek": 374052, "start": 3749.96, "end": 3756.12, "text": " So once we've done the matching stage we're basically done we can take the", "tokens": [407, 1564, 321, 600, 1096, 264, 14324, 3233, 321, 434, 1936, 1096, 321, 393, 747, 264], "temperature": 0.0, "avg_logprob": -0.26187466738516824, "compression_ratio": 1.5753424657534247, "no_speech_prob": 1.7603358628548449e-06}, {"id": 794, "seek": 374052, "start": 3757.88, "end": 3759.72, "text": " The activations", "tokens": [440, 2430, 763], "temperature": 0.0, "avg_logprob": -0.26187466738516824, "compression_ratio": 1.5753424657534247, "no_speech_prob": 1.7603358628548449e-06}, {"id": 795, "seek": 374052, "start": 3759.72, "end": 3765.08, "text": " Just grab those which which matched that's what this positive indexes are", "tokens": [1449, 4444, 729, 597, 597, 21447, 300, 311, 437, 341, 3353, 8186, 279, 366], "temperature": 0.0, "avg_logprob": -0.26187466738516824, "compression_ratio": 1.5753424657534247, "no_speech_prob": 1.7603358628548449e-06}, {"id": 796, "seek": 374052, "start": 3766.12, "end": 3768.32, "text": " subtract from those the ground truth", "tokens": [16390, 490, 729, 264, 2727, 3494], "temperature": 0.0, "avg_logprob": -0.26187466738516824, "compression_ratio": 1.5753424657534247, "no_speech_prob": 1.7603358628548449e-06}, {"id": 797, "seek": 376832, "start": 3768.32, "end": 3770.32, "text": " bounding boxes", "tokens": [5472, 278, 9002], "temperature": 0.0, "avg_logprob": -0.2597864591158353, "compression_ratio": 1.5851063829787233, "no_speech_prob": 8.013435035536531e-06}, {"id": 798, "seek": 376832, "start": 3770.32, "end": 3772.7200000000003, "text": " Just for those which matched positive ones", "tokens": [1449, 337, 729, 597, 21447, 3353, 2306], "temperature": 0.0, "avg_logprob": -0.2597864591158353, "compression_ratio": 1.5851063829787233, "no_speech_prob": 8.013435035536531e-06}, {"id": 799, "seek": 376832, "start": 3773.4, "end": 3778.28, "text": " Take the absolute value of the difference take the mean of that and that's about one loss", "tokens": [3664, 264, 8236, 2158, 295, 264, 2649, 747, 264, 914, 295, 300, 293, 300, 311, 466, 472, 4470], "temperature": 0.0, "avg_logprob": -0.2597864591158353, "compression_ratio": 1.5851063829787233, "no_speech_prob": 8.013435035536531e-06}, {"id": 800, "seek": 376832, "start": 3779.56, "end": 3781.56, "text": " and then for the", "tokens": [293, 550, 337, 264], "temperature": 0.0, "avg_logprob": -0.2597864591158353, "compression_ratio": 1.5851063829787233, "no_speech_prob": 8.013435035536531e-06}, {"id": 801, "seek": 376832, "start": 3783.32, "end": 3789.4, "text": " Classifications we can just do cross entropy and then as before we can add them together", "tokens": [9471, 7833, 321, 393, 445, 360, 3278, 30867, 293, 550, 382, 949, 321, 393, 909, 552, 1214], "temperature": 0.0, "avg_logprob": -0.2597864591158353, "compression_ratio": 1.5851063829787233, "no_speech_prob": 8.013435035536531e-06}, {"id": 802, "seek": 376832, "start": 3790.0800000000004, "end": 3792.0800000000004, "text": " Okay, so that's the", "tokens": [1033, 11, 370, 300, 311, 264], "temperature": 0.0, "avg_logprob": -0.2597864591158353, "compression_ratio": 1.5851063829787233, "no_speech_prob": 8.013435035536531e-06}, {"id": 803, "seek": 376832, "start": 3793.1200000000003, "end": 3795.1200000000003, "text": " Basic idea", "tokens": [31598, 1558], "temperature": 0.0, "avg_logprob": -0.2597864591158353, "compression_ratio": 1.5851063829787233, "no_speech_prob": 8.013435035536531e-06}, {"id": 804, "seek": 379512, "start": 3795.12, "end": 3801.44, "text": " There's a few and so this is this is what's going to happen right we're going to end up with", "tokens": [821, 311, 257, 1326, 293, 370, 341, 307, 341, 307, 437, 311, 516, 281, 1051, 558, 321, 434, 516, 281, 917, 493, 365], "temperature": 0.0, "avg_logprob": -0.25808013357767245, "compression_ratio": 1.5435897435897437, "no_speech_prob": 8.939640792959835e-06}, {"id": 805, "seek": 379512, "start": 3802.96, "end": 3804.96, "text": " 16", "tokens": [3165], "temperature": 0.0, "avg_logprob": -0.25808013357767245, "compression_ratio": 1.5435897435897437, "no_speech_prob": 8.939640792959835e-06}, {"id": 806, "seek": 379512, "start": 3806.7999999999997, "end": 3812.08, "text": " Recommended you know predicted bounding boxes coming out most of them will be background", "tokens": [49545, 3502, 291, 458, 19147, 5472, 278, 9002, 1348, 484, 881, 295, 552, 486, 312, 3678], "temperature": 0.0, "avg_logprob": -0.25808013357767245, "compression_ratio": 1.5435897435897437, "no_speech_prob": 8.939640792959835e-06}, {"id": 807, "seek": 379512, "start": 3812.08, "end": 3816.04, "text": " So you all these ones that say BG but from time to time they'll say this is a cow", "tokens": [407, 291, 439, 613, 2306, 300, 584, 363, 38, 457, 490, 565, 281, 565, 436, 603, 584, 341, 307, 257, 8408], "temperature": 0.0, "avg_logprob": -0.25808013357767245, "compression_ratio": 1.5435897435897437, "no_speech_prob": 8.939640792959835e-06}, {"id": 808, "seek": 379512, "start": 3816.44, "end": 3819.38, "text": " This is part of plant. This is car", "tokens": [639, 307, 644, 295, 3709, 13, 639, 307, 1032], "temperature": 0.0, "avg_logprob": -0.25808013357767245, "compression_ratio": 1.5435897435897437, "no_speech_prob": 8.939640792959835e-06}, {"id": 809, "seek": 381938, "start": 3819.38, "end": 3825.6600000000003, "text": " Okay, if you're wondering like how does it predict in terms of the bounding box of background?", "tokens": [1033, 11, 498, 291, 434, 6359, 411, 577, 775, 309, 6069, 294, 2115, 295, 264, 5472, 278, 2424, 295, 3678, 30], "temperature": 0.0, "avg_logprob": -0.23152860005696616, "compression_ratio": 1.7896995708154506, "no_speech_prob": 1.3006925655645318e-05}, {"id": 810, "seek": 381938, "start": 3826.26, "end": 3829.82, "text": " The answer is totally ignores it right. That's why we had this", "tokens": [440, 1867, 307, 3879, 5335, 2706, 309, 558, 13, 663, 311, 983, 321, 632, 341], "temperature": 0.0, "avg_logprob": -0.23152860005696616, "compression_ratio": 1.7896995708154506, "no_speech_prob": 1.3006925655645318e-05}, {"id": 811, "seek": 381938, "start": 3831.54, "end": 3835.4, "text": " Only positive indexes thing here right so if it's background. There's no", "tokens": [5686, 3353, 8186, 279, 551, 510, 558, 370, 498, 309, 311, 3678, 13, 821, 311, 572], "temperature": 0.0, "avg_logprob": -0.23152860005696616, "compression_ratio": 1.7896995708154506, "no_speech_prob": 1.3006925655645318e-05}, {"id": 812, "seek": 381938, "start": 3836.5, "end": 3840.58, "text": " You know sense of like where's the correct bounding box of background is totally meaningless", "tokens": [509, 458, 2020, 295, 411, 689, 311, 264, 3006, 5472, 278, 2424, 295, 3678, 307, 3879, 33232], "temperature": 0.0, "avg_logprob": -0.23152860005696616, "compression_ratio": 1.7896995708154506, "no_speech_prob": 1.3006925655645318e-05}, {"id": 813, "seek": 381938, "start": 3840.82, "end": 3845.46, "text": " So the only ones where the bounding box makes sense out of all these are the ones that aren't", "tokens": [407, 264, 787, 2306, 689, 264, 5472, 278, 2424, 1669, 2020, 484, 295, 439, 613, 366, 264, 2306, 300, 3212, 380], "temperature": 0.0, "avg_logprob": -0.23152860005696616, "compression_ratio": 1.7896995708154506, "no_speech_prob": 1.3006925655645318e-05}, {"id": 814, "seek": 384546, "start": 3845.46, "end": 3849.18, "text": " There are some important little tweaks one is that", "tokens": [821, 366, 512, 1021, 707, 46664, 472, 307, 300], "temperature": 0.0, "avg_logprob": -0.5954760313034058, "compression_ratio": 1.7191780821917808, "no_speech_prob": 6.747997758793645e-06}, {"id": 815, "seek": 384546, "start": 3851.78, "end": 3853.78, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.5954760313034058, "compression_ratio": 1.7191780821917808, "no_speech_prob": 6.747997758793645e-06}, {"id": 816, "seek": 384546, "start": 3854.02, "end": 3859.46, "text": " How do we interpret the activations and so the way we interpret the activations", "tokens": [1012, 360, 321, 7302, 264, 2430, 763, 293, 370, 264, 636, 321, 7302, 264, 2430, 763], "temperature": 0.0, "avg_logprob": -0.5954760313034058, "compression_ratio": 1.7191780821917808, "no_speech_prob": 6.747997758793645e-06}, {"id": 817, "seek": 384546, "start": 3861.46, "end": 3863.46, "text": " Is defined here in", "tokens": [1119, 7642, 510, 294], "temperature": 0.0, "avg_logprob": -0.5954760313034058, "compression_ratio": 1.7191780821917808, "no_speech_prob": 6.747997758793645e-06}, {"id": 818, "seek": 384546, "start": 3864.78, "end": 3869.9, "text": " Activation to bounding box and so basically we grab the activations", "tokens": [28550, 399, 281, 5472, 278, 2424, 293, 370, 1936, 321, 4444, 264, 2430, 763], "temperature": 0.0, "avg_logprob": -0.5954760313034058, "compression_ratio": 1.7191780821917808, "no_speech_prob": 6.747997758793645e-06}, {"id": 819, "seek": 384546, "start": 3870.7400000000002, "end": 3872.7400000000002, "text": " we stick them through fan and", "tokens": [321, 2897, 552, 807, 3429, 293], "temperature": 0.0, "avg_logprob": -0.5954760313034058, "compression_ratio": 1.7191780821917808, "no_speech_prob": 6.747997758793645e-06}, {"id": 820, "seek": 387274, "start": 3872.74, "end": 3875.3399999999997, "text": " So remember fan is the same as sigmoid", "tokens": [407, 1604, 3429, 307, 264, 912, 382, 4556, 3280, 327], "temperature": 0.0, "avg_logprob": -0.4268968370225694, "compression_ratio": 1.740909090909091, "no_speech_prob": 7.071821073623141e-06}, {"id": 821, "seek": 387274, "start": 3875.8599999999997, "end": 3881.22, "text": " That's shape except it's scaled to be between negative 1 and 1 not between 0", "tokens": [663, 311, 3909, 3993, 309, 311, 36039, 281, 312, 1296, 3671, 502, 293, 502, 406, 1296, 1958], "temperature": 0.0, "avg_logprob": -0.4268968370225694, "compression_ratio": 1.740909090909091, "no_speech_prob": 7.071821073623141e-06}, {"id": 822, "seek": 387274, "start": 3882.3399999999997, "end": 3888.06, "text": " So it's a basically a sigmoid function that goes between negative 1 and 1 and so that forces it to be within that range", "tokens": [407, 309, 311, 257, 1936, 257, 4556, 3280, 327, 2445, 300, 1709, 1296, 3671, 502, 293, 502, 293, 370, 300, 5874, 309, 281, 312, 1951, 300, 3613], "temperature": 0.0, "avg_logprob": -0.4268968370225694, "compression_ratio": 1.740909090909091, "no_speech_prob": 7.071821073623141e-06}, {"id": 823, "seek": 387274, "start": 3888.7, "end": 3890.7, "text": " and we then say okay, let's grab the", "tokens": [293, 321, 550, 584, 1392, 11, 718, 311, 4444, 264], "temperature": 0.0, "avg_logprob": -0.4268968370225694, "compression_ratio": 1.740909090909091, "no_speech_prob": 7.071821073623141e-06}, {"id": 824, "seek": 387274, "start": 3891.8599999999997, "end": 3896.1, "text": " the actual position of the anchor boxes and we will", "tokens": [264, 3539, 2535, 295, 264, 18487, 9002, 293, 321, 486], "temperature": 0.0, "avg_logprob": -0.4268968370225694, "compression_ratio": 1.740909090909091, "no_speech_prob": 7.071821073623141e-06}, {"id": 825, "seek": 387274, "start": 3896.8999999999996, "end": 3899.9399999999996, "text": " Move them around according to the value of the activations", "tokens": [10475, 552, 926, 4650, 281, 264, 2158, 295, 264, 2430, 763], "temperature": 0.0, "avg_logprob": -0.4268968370225694, "compression_ratio": 1.740909090909091, "no_speech_prob": 7.071821073623141e-06}, {"id": 826, "seek": 389994, "start": 3899.94, "end": 3902.94, "text": " divided by 2 so in other words each each", "tokens": [6666, 538, 568, 370, 294, 661, 2283, 1184, 1184], "temperature": 0.0, "avg_logprob": -0.4665927244036385, "compression_ratio": 1.6479591836734695, "no_speech_prob": 1.0289370038663037e-05}, {"id": 827, "seek": 389994, "start": 3903.9, "end": 3905.9, "text": " each activate each each", "tokens": [1184, 13615, 1184, 1184], "temperature": 0.0, "avg_logprob": -0.4665927244036385, "compression_ratio": 1.6479591836734695, "no_speech_prob": 1.0289370038663037e-05}, {"id": 828, "seek": 389994, "start": 3906.7000000000003, "end": 3912.02, "text": " predicted bounding box can be moved by up to 50% of a grid size from where its", "tokens": [19147, 5472, 278, 2424, 393, 312, 4259, 538, 493, 281, 2625, 4, 295, 257, 10748, 2744, 490, 689, 1080], "temperature": 0.0, "avg_logprob": -0.4665927244036385, "compression_ratio": 1.6479591836734695, "no_speech_prob": 1.0289370038663037e-05}, {"id": 829, "seek": 389994, "start": 3912.54, "end": 3916.78, "text": " default position is and ditto for its height and width it can be up to", "tokens": [7576, 2535, 307, 293, 274, 34924, 337, 1080, 6681, 293, 11402, 309, 393, 312, 493, 281], "temperature": 0.0, "avg_logprob": -0.4665927244036385, "compression_ratio": 1.6479591836734695, "no_speech_prob": 1.0289370038663037e-05}, {"id": 830, "seek": 389994, "start": 3917.3, "end": 3920.94, "text": " Twice as big or half as big as its default size", "tokens": [46964, 382, 955, 420, 1922, 382, 955, 382, 1080, 7576, 2744], "temperature": 0.0, "avg_logprob": -0.4665927244036385, "compression_ratio": 1.6479591836734695, "no_speech_prob": 1.0289370038663037e-05}, {"id": 831, "seek": 389994, "start": 3922.66, "end": 3924.66, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.4665927244036385, "compression_ratio": 1.6479591836734695, "no_speech_prob": 1.0289370038663037e-05}, {"id": 832, "seek": 389994, "start": 3925.2200000000003, "end": 3928.26, "text": " So that's one thing is we have to convert the activations", "tokens": [407, 300, 311, 472, 551, 307, 321, 362, 281, 7620, 264, 2430, 763], "temperature": 0.0, "avg_logprob": -0.4665927244036385, "compression_ratio": 1.6479591836734695, "no_speech_prob": 1.0289370038663037e-05}, {"id": 833, "seek": 392826, "start": 3928.26, "end": 3933.1000000000004, "text": " Into some kind of way of scaling those default anchor box positions", "tokens": [23373, 512, 733, 295, 636, 295, 21589, 729, 7576, 18487, 2424, 8432], "temperature": 0.0, "avg_logprob": -0.46629720052083334, "compression_ratio": 1.6378378378378378, "no_speech_prob": 5.338131359167164e-06}, {"id": 834, "seek": 392826, "start": 3934.0600000000004, "end": 3938.1800000000003, "text": " Another thing is we don't actually use cross-entropy", "tokens": [3996, 551, 307, 321, 500, 380, 767, 764, 3278, 12, 317, 27514], "temperature": 0.0, "avg_logprob": -0.46629720052083334, "compression_ratio": 1.6378378378378378, "no_speech_prob": 5.338131359167164e-06}, {"id": 835, "seek": 392826, "start": 3939.1800000000003, "end": 3941.1800000000003, "text": " We actually use", "tokens": [492, 767, 764], "temperature": 0.0, "avg_logprob": -0.46629720052083334, "compression_ratio": 1.6378378378378378, "no_speech_prob": 5.338131359167164e-06}, {"id": 836, "seek": 392826, "start": 3941.9, "end": 3943.9, "text": " binary cross-entropy loss", "tokens": [17434, 3278, 12, 317, 27514, 4470], "temperature": 0.0, "avg_logprob": -0.46629720052083334, "compression_ratio": 1.6378378378378378, "no_speech_prob": 5.338131359167164e-06}, {"id": 837, "seek": 392826, "start": 3944.42, "end": 3948.7400000000002, "text": " So remember binary cross-entropy loss is what we normally use for", "tokens": [407, 1604, 17434, 3278, 12, 317, 27514, 4470, 307, 437, 321, 5646, 764, 337], "temperature": 0.0, "avg_logprob": -0.46629720052083334, "compression_ratio": 1.6378378378378378, "no_speech_prob": 5.338131359167164e-06}, {"id": 838, "seek": 392826, "start": 3949.38, "end": 3951.38, "text": " multi-label classification like in the", "tokens": [4825, 12, 75, 18657, 21538, 411, 294, 264], "temperature": 0.0, "avg_logprob": -0.46629720052083334, "compression_ratio": 1.6378378378378378, "no_speech_prob": 5.338131359167164e-06}, {"id": 839, "seek": 392826, "start": 3953.1800000000003, "end": 3955.1800000000003, "text": " Planet Amazon satellite competition", "tokens": [22146, 6795, 16016, 6211], "temperature": 0.0, "avg_logprob": -0.46629720052083334, "compression_ratio": 1.6378378378378378, "no_speech_prob": 5.338131359167164e-06}, {"id": 840, "seek": 395518, "start": 3955.18, "end": 3960.7, "text": " Planet Amazon satellite competition each satellite image could have multiple things in it", "tokens": [22146, 6795, 16016, 6211, 1184, 16016, 3256, 727, 362, 3866, 721, 294, 309], "temperature": 0.0, "avg_logprob": -0.24638559507287067, "compression_ratio": 1.6583333333333334, "no_speech_prob": 5.955088909104234e-06}, {"id": 841, "seek": 395518, "start": 3960.94, "end": 3964.3799999999997, "text": " Okay, so if it's got multiple things in it you can't use softmax", "tokens": [1033, 11, 370, 498, 309, 311, 658, 3866, 721, 294, 309, 291, 393, 380, 764, 2787, 41167], "temperature": 0.0, "avg_logprob": -0.24638559507287067, "compression_ratio": 1.6583333333333334, "no_speech_prob": 5.955088909104234e-06}, {"id": 842, "seek": 395518, "start": 3964.8999999999996, "end": 3969.7, "text": " Because softmax kind of really encourages just one thing to have the high number", "tokens": [1436, 2787, 41167, 733, 295, 534, 28071, 445, 472, 551, 281, 362, 264, 1090, 1230], "temperature": 0.0, "avg_logprob": -0.24638559507287067, "compression_ratio": 1.6583333333333334, "no_speech_prob": 5.955088909104234e-06}, {"id": 843, "seek": 395518, "start": 3971.3399999999997, "end": 3977.94, "text": " In our case each anchor box can only have one object associated with it", "tokens": [682, 527, 1389, 1184, 18487, 2424, 393, 787, 362, 472, 2657, 6615, 365, 309], "temperature": 0.0, "avg_logprob": -0.24638559507287067, "compression_ratio": 1.6583333333333334, "no_speech_prob": 5.955088909104234e-06}, {"id": 844, "seek": 397794, "start": 3977.94, "end": 3984.7400000000002, "text": " So it's it's not for that reason that we're avoiding softmax. It's something else which is", "tokens": [407, 309, 311, 309, 311, 406, 337, 300, 1778, 300, 321, 434, 20220, 2787, 41167, 13, 467, 311, 746, 1646, 597, 307], "temperature": 0.0, "avg_logprob": -0.16590582806131113, "compression_ratio": 1.7207207207207207, "no_speech_prob": 2.3320590116782114e-06}, {"id": 845, "seek": 397794, "start": 3985.26, "end": 3989.78, "text": " It's possible for an anchor box to have nothing associated with it", "tokens": [467, 311, 1944, 337, 364, 18487, 2424, 281, 362, 1825, 6615, 365, 309], "temperature": 0.0, "avg_logprob": -0.16590582806131113, "compression_ratio": 1.7207207207207207, "no_speech_prob": 2.3320590116782114e-06}, {"id": 846, "seek": 397794, "start": 3991.06, "end": 3997.62, "text": " So there'd be two ways to handle that this idea of background one would be to say you know what backgrounds just a class", "tokens": [407, 456, 1116, 312, 732, 2098, 281, 4813, 300, 341, 1558, 295, 3678, 472, 576, 312, 281, 584, 291, 458, 437, 17336, 445, 257, 1508], "temperature": 0.0, "avg_logprob": -0.16590582806131113, "compression_ratio": 1.7207207207207207, "no_speech_prob": 2.3320590116782114e-06}, {"id": 847, "seek": 397794, "start": 3998.34, "end": 4005.64, "text": " Right so let's use softmax right and just treat background as one of the classes that the softmax could", "tokens": [1779, 370, 718, 311, 764, 2787, 41167, 558, 293, 445, 2387, 3678, 382, 472, 295, 264, 5359, 300, 264, 2787, 41167, 727], "temperature": 0.0, "avg_logprob": -0.16590582806131113, "compression_ratio": 1.7207207207207207, "no_speech_prob": 2.3320590116782114e-06}, {"id": 848, "seek": 400564, "start": 4005.64, "end": 4007.64, "text": " could predict a", "tokens": [727, 6069, 257], "temperature": 0.0, "avg_logprob": -0.22343940341595522, "compression_ratio": 1.567099567099567, "no_speech_prob": 3.5008317809115397e-06}, {"id": 849, "seek": 400564, "start": 4008.64, "end": 4012.04, "text": " Lot of people have done it this way. I don't like that though right because", "tokens": [20131, 295, 561, 362, 1096, 309, 341, 636, 13, 286, 500, 380, 411, 300, 1673, 558, 570], "temperature": 0.0, "avg_logprob": -0.22343940341595522, "compression_ratio": 1.567099567099567, "no_speech_prob": 3.5008317809115397e-06}, {"id": 850, "seek": 400564, "start": 4013.08, "end": 4017.6, "text": " That's a really hard thing to ask a neural network to do is basically to say", "tokens": [663, 311, 257, 534, 1152, 551, 281, 1029, 257, 18161, 3209, 281, 360, 307, 1936, 281, 584], "temperature": 0.0, "avg_logprob": -0.22343940341595522, "compression_ratio": 1.567099567099567, "no_speech_prob": 3.5008317809115397e-06}, {"id": 851, "seek": 400564, "start": 4018.3599999999997, "end": 4021.3799999999997, "text": " Can you tell whether this grid cell?", "tokens": [1664, 291, 980, 1968, 341, 10748, 2815, 30], "temperature": 0.0, "avg_logprob": -0.22343940341595522, "compression_ratio": 1.567099567099567, "no_speech_prob": 3.5008317809115397e-06}, {"id": 852, "seek": 400564, "start": 4021.8399999999997, "end": 4028.08, "text": " Doesn't have any of the 20 objects that I'm interested with a jihad overlap of more than 0.5", "tokens": [12955, 380, 362, 604, 295, 264, 945, 6565, 300, 286, 478, 3102, 365, 257, 361, 43837, 19959, 295, 544, 813, 1958, 13, 20], "temperature": 0.0, "avg_logprob": -0.22343940341595522, "compression_ratio": 1.567099567099567, "no_speech_prob": 3.5008317809115397e-06}, {"id": 853, "seek": 400564, "start": 4028.72, "end": 4030.72, "text": " Now that's a really", "tokens": [823, 300, 311, 257, 534], "temperature": 0.0, "avg_logprob": -0.22343940341595522, "compression_ratio": 1.567099567099567, "no_speech_prob": 3.5008317809115397e-06}, {"id": 854, "seek": 400564, "start": 4030.72, "end": 4033.96, "text": " hard thing to put into a single computation", "tokens": [1152, 551, 281, 829, 666, 257, 2167, 24903], "temperature": 0.0, "avg_logprob": -0.22343940341595522, "compression_ratio": 1.567099567099567, "no_speech_prob": 3.5008317809115397e-06}, {"id": 855, "seek": 403396, "start": 4033.96, "end": 4038.36, "text": " On the other hand what if we just had for each class?", "tokens": [1282, 264, 661, 1011, 437, 498, 321, 445, 632, 337, 1184, 1508, 30], "temperature": 0.0, "avg_logprob": -0.3050635355823445, "compression_ratio": 1.6150442477876106, "no_speech_prob": 2.9480038392648567e-06}, {"id": 856, "seek": 403396, "start": 4039.04, "end": 4043.64, "text": " You know is it a motorbike is it a bus is it a person?", "tokens": [509, 458, 307, 309, 257, 5932, 30283, 307, 309, 257, 1255, 307, 309, 257, 954, 30], "temperature": 0.0, "avg_logprob": -0.3050635355823445, "compression_ratio": 1.6150442477876106, "no_speech_prob": 2.9480038392648567e-06}, {"id": 857, "seek": 403396, "start": 4045.64, "end": 4050.66, "text": " Dining room table right and then it can check each of those and be no no no no no and it's no to all of them", "tokens": [413, 1760, 1808, 3199, 558, 293, 550, 309, 393, 1520, 1184, 295, 729, 293, 312, 572, 572, 572, 572, 572, 293, 309, 311, 572, 281, 439, 295, 552], "temperature": 0.0, "avg_logprob": -0.3050635355823445, "compression_ratio": 1.6150442477876106, "no_speech_prob": 2.9480038392648567e-06}, {"id": 858, "seek": 403396, "start": 4050.66, "end": 4058.2200000000003, "text": " It's like oh background all right, so that's that's the way. I'm doing it is it's not that we could have multiple", "tokens": [467, 311, 411, 1954, 3678, 439, 558, 11, 370, 300, 311, 300, 311, 264, 636, 13, 286, 478, 884, 309, 307, 309, 311, 406, 300, 321, 727, 362, 3866], "temperature": 0.0, "avg_logprob": -0.3050635355823445, "compression_ratio": 1.6150442477876106, "no_speech_prob": 2.9480038392648567e-06}, {"id": 859, "seek": 403396, "start": 4058.7400000000002, "end": 4062.04, "text": " True labels, but we can have zero", "tokens": [13587, 16949, 11, 457, 321, 393, 362, 4018], "temperature": 0.0, "avg_logprob": -0.3050635355823445, "compression_ratio": 1.6150442477876106, "no_speech_prob": 2.9480038392648567e-06}, {"id": 860, "seek": 406204, "start": 4062.04, "end": 4066.52, "text": " True labels, and so that's what's going on here. We take our", "tokens": [13587, 16949, 11, 293, 370, 300, 311, 437, 311, 516, 322, 510, 13, 492, 747, 527], "temperature": 0.0, "avg_logprob": -0.2102411862077384, "compression_ratio": 1.6359223300970873, "no_speech_prob": 4.425432052812539e-06}, {"id": 861, "seek": 406204, "start": 4067.48, "end": 4073.72, "text": " Target and we do a one-hot embedding with number of classes plus one so at this stage", "tokens": [24586, 293, 321, 360, 257, 472, 12, 12194, 12240, 3584, 365, 1230, 295, 5359, 1804, 472, 370, 412, 341, 3233], "temperature": 0.0, "avg_logprob": -0.2102411862077384, "compression_ratio": 1.6359223300970873, "no_speech_prob": 4.425432052812539e-06}, {"id": 862, "seek": 406204, "start": 4073.72, "end": 4077.92, "text": " We do have the idea of background for the one-hot embedding, but then we remove", "tokens": [492, 360, 362, 264, 1558, 295, 3678, 337, 264, 472, 12, 12194, 12240, 3584, 11, 457, 550, 321, 4159], "temperature": 0.0, "avg_logprob": -0.2102411862077384, "compression_ratio": 1.6359223300970873, "no_speech_prob": 4.425432052812539e-06}, {"id": 863, "seek": 406204, "start": 4078.48, "end": 4082.22, "text": " The last column so the background columns now gone", "tokens": [440, 1036, 7738, 370, 264, 3678, 13766, 586, 2780], "temperature": 0.0, "avg_logprob": -0.2102411862077384, "compression_ratio": 1.6359223300970873, "no_speech_prob": 4.425432052812539e-06}, {"id": 864, "seek": 406204, "start": 4082.7599999999998, "end": 4088.52, "text": " Right and so now this vectors either of all zeros basically", "tokens": [1779, 293, 370, 586, 341, 18875, 2139, 295, 439, 35193, 1936], "temperature": 0.0, "avg_logprob": -0.2102411862077384, "compression_ratio": 1.6359223300970873, "no_speech_prob": 4.425432052812539e-06}, {"id": 865, "seek": 408852, "start": 4088.52, "end": 4094.48, "text": " Meaning there's nothing here or it has at most one one", "tokens": [19948, 456, 311, 1825, 510, 420, 309, 575, 412, 881, 472, 472], "temperature": 0.0, "avg_logprob": -0.25066395366893096, "compression_ratio": 1.5359116022099448, "no_speech_prob": 5.014690941607114e-06}, {"id": 866, "seek": 408852, "start": 4096.08, "end": 4103.72, "text": " And so then we can use binary cross entropy to compare our predictions with that target", "tokens": [400, 370, 550, 321, 393, 764, 17434, 3278, 30867, 281, 6794, 527, 21264, 365, 300, 3779], "temperature": 0.0, "avg_logprob": -0.25066395366893096, "compression_ratio": 1.5359116022099448, "no_speech_prob": 5.014690941607114e-06}, {"id": 867, "seek": 408852, "start": 4105.68, "end": 4109.16, "text": " That is a minor tweak right but like", "tokens": [663, 307, 257, 6696, 29879, 558, 457, 411], "temperature": 0.0, "avg_logprob": -0.25066395366893096, "compression_ratio": 1.5359116022099448, "no_speech_prob": 5.014690941607114e-06}, {"id": 868, "seek": 408852, "start": 4110.64, "end": 4116.84, "text": " It's the kind of minor tweak that I I want you to think about and understand because it's a really", "tokens": [467, 311, 264, 733, 295, 6696, 29879, 300, 286, 286, 528, 291, 281, 519, 466, 293, 1223, 570, 309, 311, 257, 534], "temperature": 0.0, "avg_logprob": -0.25066395366893096, "compression_ratio": 1.5359116022099448, "no_speech_prob": 5.014690941607114e-06}, {"id": 869, "seek": 411684, "start": 4116.84, "end": 4119.72, "text": " Like it makes a it makes a really big difference", "tokens": [1743, 309, 1669, 257, 309, 1669, 257, 534, 955, 2649], "temperature": 0.0, "avg_logprob": -0.19183907685456453, "compression_ratio": 1.6791044776119404, "no_speech_prob": 4.495139819482574e-06}, {"id": 870, "seek": 411684, "start": 4120.4400000000005, "end": 4126.72, "text": " In practice to your training and it's the kind of thing that you'll see a lot of papers talk about like often when there's some", "tokens": [682, 3124, 281, 428, 3097, 293, 309, 311, 264, 733, 295, 551, 300, 291, 603, 536, 257, 688, 295, 10577, 751, 466, 411, 2049, 562, 456, 311, 512], "temperature": 0.0, "avg_logprob": -0.19183907685456453, "compression_ratio": 1.6791044776119404, "no_speech_prob": 4.495139819482574e-06}, {"id": 871, "seek": 411684, "start": 4127.08, "end": 4132.16, "text": " Increment over some previous paper. It'll be something like this somebody realizes like oh", "tokens": [30367, 518, 670, 512, 3894, 3035, 13, 467, 603, 312, 746, 411, 341, 2618, 29316, 411, 1954], "temperature": 0.0, "avg_logprob": -0.19183907685456453, "compression_ratio": 1.6791044776119404, "no_speech_prob": 4.495139819482574e-06}, {"id": 872, "seek": 411684, "start": 4132.84, "end": 4134.84, "text": " trying to predict a", "tokens": [1382, 281, 6069, 257], "temperature": 0.0, "avg_logprob": -0.19183907685456453, "compression_ratio": 1.6791044776119404, "no_speech_prob": 4.495139819482574e-06}, {"id": 873, "seek": 411684, "start": 4135.400000000001, "end": 4141.12, "text": " Background category using a softmax is really hard thing to do what if we use the binary cross entropy instead", "tokens": [36904, 7719, 1228, 257, 2787, 41167, 307, 534, 1152, 551, 281, 360, 437, 498, 321, 764, 264, 17434, 3278, 30867, 2602], "temperature": 0.0, "avg_logprob": -0.19183907685456453, "compression_ratio": 1.6791044776119404, "no_speech_prob": 4.495139819482574e-06}, {"id": 874, "seek": 411684, "start": 4141.12, "end": 4143.12, "text": " You know and so it's kind of like", "tokens": [509, 458, 293, 370, 309, 311, 733, 295, 411], "temperature": 0.0, "avg_logprob": -0.19183907685456453, "compression_ratio": 1.6791044776119404, "no_speech_prob": 4.495139819482574e-06}, {"id": 875, "seek": 411684, "start": 4143.64, "end": 4145.4800000000005, "text": " if you understand", "tokens": [498, 291, 1223], "temperature": 0.0, "avg_logprob": -0.19183907685456453, "compression_ratio": 1.6791044776119404, "no_speech_prob": 4.495139819482574e-06}, {"id": 876, "seek": 414548, "start": 4145.48, "end": 4149.0, "text": " What this is doing and more importantly why we're doing it", "tokens": [708, 341, 307, 884, 293, 544, 8906, 983, 321, 434, 884, 309], "temperature": 0.0, "avg_logprob": -0.21244415870079628, "compression_ratio": 1.6531531531531531, "no_speech_prob": 8.139569217746612e-06}, {"id": 877, "seek": 414548, "start": 4149.5199999999995, "end": 4155.919999999999, "text": " That's a really good test of your understanding of the material and if you don't that's fine, right?", "tokens": [663, 311, 257, 534, 665, 1500, 295, 428, 3701, 295, 264, 2527, 293, 498, 291, 500, 380, 300, 311, 2489, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21244415870079628, "compression_ratio": 1.6531531531531531, "no_speech_prob": 8.139569217746612e-06}, {"id": 878, "seek": 414548, "start": 4155.919999999999, "end": 4160.799999999999, "text": " This shows you this is something that you need to maybe go back and rewatch this part", "tokens": [639, 3110, 291, 341, 307, 746, 300, 291, 643, 281, 1310, 352, 646, 293, 319, 15219, 341, 644], "temperature": 0.0, "avg_logprob": -0.21244415870079628, "compression_ratio": 1.6531531531531531, "no_speech_prob": 8.139569217746612e-06}, {"id": 879, "seek": 414548, "start": 4161.28, "end": 4167.32, "text": " Video and talk to some of your classmates and if necessary ask for the forum until you understand", "tokens": [9777, 293, 751, 281, 512, 295, 428, 24964, 293, 498, 4818, 1029, 337, 264, 17542, 1826, 291, 1223], "temperature": 0.0, "avg_logprob": -0.21244415870079628, "compression_ratio": 1.6531531531531531, "no_speech_prob": 8.139569217746612e-06}, {"id": 880, "seek": 414548, "start": 4168.32, "end": 4170.32, "text": " What are we doing?", "tokens": [708, 366, 321, 884, 30], "temperature": 0.0, "avg_logprob": -0.21244415870079628, "compression_ratio": 1.6531531531531531, "no_speech_prob": 8.139569217746612e-06}, {"id": 881, "seek": 414548, "start": 4171.16, "end": 4172.32, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.21244415870079628, "compression_ratio": 1.6531531531531531, "no_speech_prob": 8.139569217746612e-06}, {"id": 882, "seek": 417232, "start": 4172.32, "end": 4176.12, "text": " So that's what this that's what this binary cross entropy loss", "tokens": [407, 300, 311, 437, 341, 300, 311, 437, 341, 17434, 3278, 30867, 4470], "temperature": 0.0, "avg_logprob": -0.16690276650821462, "compression_ratio": 1.8726415094339623, "no_speech_prob": 8.397922101721633e-06}, {"id": 883, "seek": 417232, "start": 4176.84, "end": 4182.28, "text": " Lost function is doing so basically in this part of the code. We've got this custom loss function", "tokens": [23422, 2445, 307, 884, 370, 1936, 294, 341, 644, 295, 264, 3089, 13, 492, 600, 658, 341, 2375, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.16690276650821462, "compression_ratio": 1.8726415094339623, "no_speech_prob": 8.397922101721633e-06}, {"id": 884, "seek": 417232, "start": 4182.719999999999, "end": 4185.16, "text": " We've got the thing that calculates that a card index", "tokens": [492, 600, 658, 264, 551, 300, 4322, 1024, 300, 257, 2920, 8186], "temperature": 0.0, "avg_logprob": -0.16690276650821462, "compression_ratio": 1.8726415094339623, "no_speech_prob": 8.397922101721633e-06}, {"id": 885, "seek": 417232, "start": 4186.32, "end": 4193.0, "text": " We've got the thing that converts activations to bounding box. We've got the thing that does map to ground truth that we looked at", "tokens": [492, 600, 658, 264, 551, 300, 38874, 2430, 763, 281, 5472, 278, 2424, 13, 492, 600, 658, 264, 551, 300, 775, 4471, 281, 2727, 3494, 300, 321, 2956, 412], "temperature": 0.0, "avg_logprob": -0.16690276650821462, "compression_ratio": 1.8726415094339623, "no_speech_prob": 8.397922101721633e-06}, {"id": 886, "seek": 417232, "start": 4193.44, "end": 4196.48, "text": " Okay, and that's it all that's left is the", "tokens": [1033, 11, 293, 300, 311, 309, 439, 300, 311, 1411, 307, 264], "temperature": 0.0, "avg_logprob": -0.16690276650821462, "compression_ratio": 1.8726415094339623, "no_speech_prob": 8.397922101721633e-06}, {"id": 887, "seek": 417232, "start": 4197.4, "end": 4199.28, "text": " SSD loss", "tokens": [30262, 4470], "temperature": 0.0, "avg_logprob": -0.16690276650821462, "compression_ratio": 1.8726415094339623, "no_speech_prob": 8.397922101721633e-06}, {"id": 888, "seek": 419928, "start": 4199.28, "end": 4203.44, "text": " Function so the SSD loss function. This is actually what we set", "tokens": [11166, 882, 370, 264, 30262, 4470, 2445, 13, 639, 307, 767, 437, 321, 992], "temperature": 0.0, "avg_logprob": -0.24735772207881626, "compression_ratio": 1.7925531914893618, "no_speech_prob": 7.411224487441359e-06}, {"id": 889, "seek": 419928, "start": 4205.24, "end": 4209.36, "text": " Yeah as our crit as our criterion is SSD loss", "tokens": [865, 382, 527, 3113, 382, 527, 46691, 307, 30262, 4470], "temperature": 0.0, "avg_logprob": -0.24735772207881626, "compression_ratio": 1.7925531914893618, "no_speech_prob": 7.411224487441359e-06}, {"id": 890, "seek": 419928, "start": 4210.08, "end": 4213.5199999999995, "text": " So what SSD loss class is it it loops through?", "tokens": [407, 437, 30262, 4470, 1508, 307, 309, 309, 16121, 807, 30], "temperature": 0.0, "avg_logprob": -0.24735772207881626, "compression_ratio": 1.7925531914893618, "no_speech_prob": 7.411224487441359e-06}, {"id": 891, "seek": 419928, "start": 4214.24, "end": 4216.32, "text": " each image in the mini-batch and", "tokens": [1184, 3256, 294, 264, 8382, 12, 65, 852, 293], "temperature": 0.0, "avg_logprob": -0.24735772207881626, "compression_ratio": 1.7925531914893618, "no_speech_prob": 7.411224487441359e-06}, {"id": 892, "seek": 419928, "start": 4216.92, "end": 4221.5599999999995, "text": " It calls SSD one loss so SSD loss for one image", "tokens": [467, 5498, 30262, 472, 4470, 370, 30262, 4470, 337, 472, 3256], "temperature": 0.0, "avg_logprob": -0.24735772207881626, "compression_ratio": 1.7925531914893618, "no_speech_prob": 7.411224487441359e-06}, {"id": 893, "seek": 419928, "start": 4222.639999999999, "end": 4227.599999999999, "text": " So this function is really where it's all happening. This is calculating the SSD loss for one image", "tokens": [407, 341, 2445, 307, 534, 689, 309, 311, 439, 2737, 13, 639, 307, 28258, 264, 30262, 4470, 337, 472, 3256], "temperature": 0.0, "avg_logprob": -0.24735772207881626, "compression_ratio": 1.7925531914893618, "no_speech_prob": 7.411224487441359e-06}, {"id": 894, "seek": 422760, "start": 4227.6, "end": 4229.6, "text": " right, so we", "tokens": [558, 11, 370, 321], "temperature": 0.0, "avg_logprob": -0.25111708641052244, "compression_ratio": 1.566137566137566, "no_speech_prob": 2.3186834368971176e-05}, {"id": 895, "seek": 422760, "start": 4229.92, "end": 4232.64, "text": " destructure our bounding box in class and", "tokens": [2677, 2885, 527, 5472, 278, 2424, 294, 1508, 293], "temperature": 0.0, "avg_logprob": -0.25111708641052244, "compression_ratio": 1.566137566137566, "no_speech_prob": 2.3186834368971176e-05}, {"id": 896, "seek": 422760, "start": 4237.04, "end": 4241.200000000001, "text": " Basically there's a what this is doing here actually this is worth mentioning a", "tokens": [8537, 456, 311, 257, 437, 341, 307, 884, 510, 767, 341, 307, 3163, 18315, 257], "temperature": 0.0, "avg_logprob": -0.25111708641052244, "compression_ratio": 1.566137566137566, "no_speech_prob": 2.3186834368971176e-05}, {"id": 897, "seek": 422760, "start": 4243.320000000001, "end": 4249.4400000000005, "text": " Lot of code you find out there on the internet doesn't work with mini-batches, you know", "tokens": [20131, 295, 3089, 291, 915, 484, 456, 322, 264, 4705, 1177, 380, 589, 365, 8382, 12, 65, 852, 279, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.25111708641052244, "compression_ratio": 1.566137566137566, "no_speech_prob": 2.3186834368971176e-05}, {"id": 898, "seek": 422760, "start": 4249.4400000000005, "end": 4254.400000000001, "text": " It only does like one thing at a time which we don't want so in this case", "tokens": [467, 787, 775, 411, 472, 551, 412, 257, 565, 597, 321, 500, 380, 528, 370, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.25111708641052244, "compression_ratio": 1.566137566137566, "no_speech_prob": 2.3186834368971176e-05}, {"id": 899, "seek": 425440, "start": 4254.4, "end": 4259.96, "text": " We you know, all of this stuff is working. It's not exactly a mini-batch at a time. It's on a whole bunch of", "tokens": [492, 291, 458, 11, 439, 295, 341, 1507, 307, 1364, 13, 467, 311, 406, 2293, 257, 8382, 12, 65, 852, 412, 257, 565, 13, 467, 311, 322, 257, 1379, 3840, 295], "temperature": 0.0, "avg_logprob": -0.22363434550918151, "compression_ratio": 1.6260162601626016, "no_speech_prob": 2.2473530407296494e-05}, {"id": 900, "seek": 425440, "start": 4260.92, "end": 4267.16, "text": " Ground truth objects at a time and the data loader is being fed a mini-batch at a time to do all the convolutional layers", "tokens": [28371, 3494, 6565, 412, 257, 565, 293, 264, 1412, 3677, 260, 307, 885, 4636, 257, 8382, 12, 65, 852, 412, 257, 565, 281, 360, 439, 264, 45216, 304, 7914], "temperature": 0.0, "avg_logprob": -0.22363434550918151, "compression_ratio": 1.6260162601626016, "no_speech_prob": 2.2473530407296494e-05}, {"id": 901, "seek": 425440, "start": 4269.28, "end": 4271.0, "text": " Because", "tokens": [1436], "temperature": 0.0, "avg_logprob": -0.22363434550918151, "compression_ratio": 1.6260162601626016, "no_speech_prob": 2.2473530407296494e-05}, {"id": 902, "seek": 425440, "start": 4271.0, "end": 4273.0, "text": " We could have different numbers of", "tokens": [492, 727, 362, 819, 3547, 295], "temperature": 0.0, "avg_logprob": -0.22363434550918151, "compression_ratio": 1.6260162601626016, "no_speech_prob": 2.2473530407296494e-05}, {"id": 903, "seek": 425440, "start": 4273.48, "end": 4279.04, "text": " Ground-truth objects in each image, but a tensor has to be a strict rectangular shape", "tokens": [28371, 12, 6903, 2910, 6565, 294, 1184, 3256, 11, 457, 257, 40863, 575, 281, 312, 257, 10910, 31167, 3909], "temperature": 0.0, "avg_logprob": -0.22363434550918151, "compression_ratio": 1.6260162601626016, "no_speech_prob": 2.2473530407296494e-05}, {"id": 904, "seek": 425440, "start": 4279.759999999999, "end": 4282.259999999999, "text": " Fast AI automatically pads it with zeros", "tokens": [15968, 7318, 6772, 19179, 309, 365, 35193], "temperature": 0.0, "avg_logprob": -0.22363434550918151, "compression_ratio": 1.6260162601626016, "no_speech_prob": 2.2473530407296494e-05}, {"id": 905, "seek": 428226, "start": 4282.26, "end": 4284.54, "text": " And I think that's not the same way", "tokens": [400, 286, 519, 300, 311, 406, 264, 912, 636], "temperature": 0.0, "avg_logprob": -0.24093786578312099, "compression_ratio": 1.668, "no_speech_prob": 9.665947800385766e-06}, {"id": 906, "seek": 428226, "start": 4285.18, "end": 4288.74, "text": " That's a thing. I've barely recently added but it's super handy", "tokens": [663, 311, 257, 551, 13, 286, 600, 10268, 3938, 3869, 457, 309, 311, 1687, 13239], "temperature": 0.0, "avg_logprob": -0.24093786578312099, "compression_ratio": 1.668, "no_speech_prob": 9.665947800385766e-06}, {"id": 907, "seek": 428226, "start": 4288.74, "end": 4291.18, "text": " They're almost no other libraries do that", "tokens": [814, 434, 1920, 572, 661, 15148, 360, 300], "temperature": 0.0, "avg_logprob": -0.24093786578312099, "compression_ratio": 1.668, "no_speech_prob": 9.665947800385766e-06}, {"id": 908, "seek": 428226, "start": 4291.26, "end": 4296.74, "text": " But that does mean that you then have to make sure that you get rid of those zeros, right?", "tokens": [583, 300, 775, 914, 300, 291, 550, 362, 281, 652, 988, 300, 291, 483, 3973, 295, 729, 35193, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.24093786578312099, "compression_ratio": 1.668, "no_speech_prob": 9.665947800385766e-06}, {"id": 909, "seek": 428226, "start": 4296.74, "end": 4302.860000000001, "text": " So you can see here I'm checking to find all of the all of the non zeros and I'm only", "tokens": [407, 291, 393, 536, 510, 286, 478, 8568, 281, 915, 439, 295, 264, 439, 295, 264, 2107, 35193, 293, 286, 478, 787], "temperature": 0.0, "avg_logprob": -0.24093786578312099, "compression_ratio": 1.668, "no_speech_prob": 9.665947800385766e-06}, {"id": 910, "seek": 430286, "start": 4302.86, "end": 4312.0599999999995, "text": " Keeping those this is just getting rid of any of the bounding boxes that are actually just padding", "tokens": [30187, 729, 341, 307, 445, 1242, 3973, 295, 604, 295, 264, 5472, 278, 9002, 300, 366, 767, 445, 39562], "temperature": 0.0, "avg_logprob": -0.21675011546341413, "compression_ratio": 1.7228915662650603, "no_speech_prob": 9.665943252912257e-06}, {"id": 911, "seek": 430286, "start": 4312.339999999999, "end": 4318.46, "text": " Yeah, okay, so get rid of the padding turn the activations bounding boxes do the jacquard doing that ground truth", "tokens": [865, 11, 1392, 11, 370, 483, 3973, 295, 264, 39562, 1261, 264, 2430, 763, 5472, 278, 9002, 360, 264, 361, 326, 358, 515, 884, 300, 2727, 3494], "temperature": 0.0, "avg_logprob": -0.21675011546341413, "compression_ratio": 1.7228915662650603, "no_speech_prob": 9.665943252912257e-06}, {"id": 912, "seek": 430286, "start": 4318.46, "end": 4321.66, "text": " This is all the stuff. We just went through it's all line by line underneath, right?", "tokens": [639, 307, 439, 264, 1507, 13, 492, 445, 1437, 807, 309, 311, 439, 1622, 538, 1622, 7223, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21675011546341413, "compression_ratio": 1.7228915662650603, "no_speech_prob": 9.665943252912257e-06}, {"id": 913, "seek": 432166, "start": 4321.66, "end": 4331.9, "text": " Check that there's an overlap greater than something around point four or point five different papers use different values for this", "tokens": [6881, 300, 456, 311, 364, 19959, 5044, 813, 746, 926, 935, 1451, 420, 935, 1732, 819, 10577, 764, 819, 4190, 337, 341], "temperature": 0.0, "avg_logprob": -0.22519363182178442, "compression_ratio": 1.7172774869109948, "no_speech_prob": 1.0451423804624937e-05}, {"id": 914, "seek": 432166, "start": 4332.82, "end": 4334.82, "text": " Find the things that match", "tokens": [11809, 264, 721, 300, 2995], "temperature": 0.0, "avg_logprob": -0.22519363182178442, "compression_ratio": 1.7172774869109948, "no_speech_prob": 1.0451423804624937e-05}, {"id": 915, "seek": 432166, "start": 4337.0199999999995, "end": 4340.18, "text": " Put the class put the background class for those", "tokens": [4935, 264, 1508, 829, 264, 3678, 1508, 337, 729], "temperature": 0.0, "avg_logprob": -0.22519363182178442, "compression_ratio": 1.7172774869109948, "no_speech_prob": 1.0451423804624937e-05}, {"id": 916, "seek": 432166, "start": 4341.139999999999, "end": 4348.82, "text": " And then finally get the L1 loss for the localization part get the binary cross entropy boss for the classification part", "tokens": [400, 550, 2721, 483, 264, 441, 16, 4470, 337, 264, 2654, 2144, 644, 483, 264, 17434, 3278, 30867, 5741, 337, 264, 21538, 644], "temperature": 0.0, "avg_logprob": -0.22519363182178442, "compression_ratio": 1.7172774869109948, "no_speech_prob": 1.0451423804624937e-05}, {"id": 917, "seek": 434882, "start": 4348.82, "end": 4352.299999999999, "text": " We've heard those two pieces and then finally", "tokens": [492, 600, 2198, 729, 732, 3755, 293, 550, 2721], "temperature": 0.0, "avg_logprob": -0.22979276076607083, "compression_ratio": 1.7014218009478672, "no_speech_prob": 6.540387857967289e-06}, {"id": 918, "seek": 434882, "start": 4353.179999999999, "end": 4355.179999999999, "text": " having together", "tokens": [1419, 1214], "temperature": 0.0, "avg_logprob": -0.22979276076607083, "compression_ratio": 1.7014218009478672, "no_speech_prob": 6.540387857967289e-06}, {"id": 919, "seek": 434882, "start": 4355.66, "end": 4357.34, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.22979276076607083, "compression_ratio": 1.7014218009478672, "no_speech_prob": 6.540387857967289e-06}, {"id": 920, "seek": 434882, "start": 4357.34, "end": 4359.34, "text": " That's a lot going on", "tokens": [663, 311, 257, 688, 516, 322], "temperature": 0.0, "avg_logprob": -0.22979276076607083, "compression_ratio": 1.7014218009478672, "no_speech_prob": 6.540387857967289e-06}, {"id": 921, "seek": 434882, "start": 4359.46, "end": 4365.86, "text": " And it might take a few watches of the video to bring in the code to fully understand it", "tokens": [400, 309, 1062, 747, 257, 1326, 17062, 295, 264, 960, 281, 1565, 294, 264, 3089, 281, 4498, 1223, 309], "temperature": 0.0, "avg_logprob": -0.22979276076607083, "compression_ratio": 1.7014218009478672, "no_speech_prob": 6.540387857967289e-06}, {"id": 922, "seek": 434882, "start": 4367.34, "end": 4372.179999999999, "text": " But the basic idea now is that we now have the things we need we have the data", "tokens": [583, 264, 3875, 1558, 586, 307, 300, 321, 586, 362, 264, 721, 321, 643, 321, 362, 264, 1412], "temperature": 0.0, "avg_logprob": -0.22979276076607083, "compression_ratio": 1.7014218009478672, "no_speech_prob": 6.540387857967289e-06}, {"id": 923, "seek": 437218, "start": 4372.18, "end": 4378.1, "text": " We have the architecture and we have the loss function. So now we've got those three things we can train so", "tokens": [492, 362, 264, 9482, 293, 321, 362, 264, 4470, 2445, 13, 407, 586, 321, 600, 658, 729, 1045, 721, 321, 393, 3847, 370], "temperature": 0.0, "avg_logprob": -0.23175046318455747, "compression_ratio": 1.5157894736842106, "no_speech_prob": 9.36860578804044e-06}, {"id": 924, "seek": 437218, "start": 4378.820000000001, "end": 4380.820000000001, "text": " Do my normal learning rate binder", "tokens": [1144, 452, 2710, 2539, 3314, 45630], "temperature": 0.0, "avg_logprob": -0.23175046318455747, "compression_ratio": 1.5157894736842106, "no_speech_prob": 9.36860578804044e-06}, {"id": 925, "seek": 437218, "start": 4382.06, "end": 4384.26, "text": " and train for a bit and", "tokens": [293, 3847, 337, 257, 857, 293], "temperature": 0.0, "avg_logprob": -0.23175046318455747, "compression_ratio": 1.5157894736842106, "no_speech_prob": 9.36860578804044e-06}, {"id": 926, "seek": 437218, "start": 4387.34, "end": 4392.06, "text": " We get down to 25 and then at the end we can see", "tokens": [492, 483, 760, 281, 3552, 293, 550, 412, 264, 917, 321, 393, 536], "temperature": 0.0, "avg_logprob": -0.23175046318455747, "compression_ratio": 1.5157894736842106, "no_speech_prob": 9.36860578804044e-06}, {"id": 927, "seek": 437218, "start": 4394.9800000000005, "end": 4398.9400000000005, "text": " How we went so obviously this isn't quite what we want I mean in practice", "tokens": [1012, 321, 1437, 370, 2745, 341, 1943, 380, 1596, 437, 321, 528, 286, 914, 294, 3124], "temperature": 0.0, "avg_logprob": -0.23175046318455747, "compression_ratio": 1.5157894736842106, "no_speech_prob": 9.36860578804044e-06}, {"id": 928, "seek": 439894, "start": 4398.94, "end": 4403.78, "text": " We've kind of removed the background ones or some threshold, but it's like it's on the right track", "tokens": [492, 600, 733, 295, 7261, 264, 3678, 2306, 420, 512, 14678, 11, 457, 309, 311, 411, 309, 311, 322, 264, 558, 2837], "temperature": 0.0, "avg_logprob": -0.16038614419790415, "compression_ratio": 1.75, "no_speech_prob": 2.7968768335995264e-05}, {"id": 929, "seek": 439894, "start": 4403.78, "end": 4406.0199999999995, "text": " There's a dog in the middle. It's got a point three four", "tokens": [821, 311, 257, 3000, 294, 264, 2808, 13, 467, 311, 658, 257, 935, 1045, 1451], "temperature": 0.0, "avg_logprob": -0.16038614419790415, "compression_ratio": 1.75, "no_speech_prob": 2.7968768335995264e-05}, {"id": 930, "seek": 439894, "start": 4406.54, "end": 4411.839999999999, "text": " There's a bird here in the middle of point nine four, you know, something's working. Okay", "tokens": [821, 311, 257, 5255, 510, 294, 264, 2808, 295, 935, 4949, 1451, 11, 291, 458, 11, 746, 311, 1364, 13, 1033], "temperature": 0.0, "avg_logprob": -0.16038614419790415, "compression_ratio": 1.75, "no_speech_prob": 2.7968768335995264e-05}, {"id": 931, "seek": 439894, "start": 4413.099999999999, "end": 4418.62, "text": " You know, I've got a few concerns. I don't think it's I don't see anything saying motorcycle here. It says bicycle, which isn't great", "tokens": [509, 458, 11, 286, 600, 658, 257, 1326, 7389, 13, 286, 500, 380, 519, 309, 311, 286, 500, 380, 536, 1340, 1566, 20554, 510, 13, 467, 1619, 20888, 11, 597, 1943, 380, 869], "temperature": 0.0, "avg_logprob": -0.16038614419790415, "compression_ratio": 1.75, "no_speech_prob": 2.7968768335995264e-05}, {"id": 932, "seek": 439894, "start": 4420.179999999999, "end": 4422.179999999999, "text": " There's nothing for the part of plant that's big enough", "tokens": [821, 311, 1825, 337, 264, 644, 295, 3709, 300, 311, 955, 1547], "temperature": 0.0, "avg_logprob": -0.16038614419790415, "compression_ratio": 1.75, "no_speech_prob": 2.7968768335995264e-05}, {"id": 933, "seek": 439894, "start": 4423.0599999999995, "end": 4427.339999999999, "text": " But that's not surprising because all of our anchor boxes were small", "tokens": [583, 300, 311, 406, 8830, 570, 439, 295, 527, 18487, 9002, 645, 1359], "temperature": 0.0, "avg_logprob": -0.16038614419790415, "compression_ratio": 1.75, "no_speech_prob": 2.7968768335995264e-05}, {"id": 934, "seek": 442734, "start": 4427.34, "end": 4429.9400000000005, "text": " They were four by four great", "tokens": [814, 645, 1451, 538, 1451, 869], "temperature": 0.0, "avg_logprob": -0.2126314324068736, "compression_ratio": 1.6141304347826086, "no_speech_prob": 2.726447746681515e-06}, {"id": 935, "seek": 442734, "start": 4430.7, "end": 4432.06, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.2126314324068736, "compression_ratio": 1.6141304347826086, "no_speech_prob": 2.726447746681515e-06}, {"id": 936, "seek": 442734, "start": 4432.06, "end": 4433.9800000000005, "text": " to go from here", "tokens": [281, 352, 490, 510], "temperature": 0.0, "avg_logprob": -0.2126314324068736, "compression_ratio": 1.6141304347826086, "no_speech_prob": 2.726447746681515e-06}, {"id": 937, "seek": 442734, "start": 4433.9800000000005, "end": 4439.82, "text": " To something that's going to be more accurate. All we're going to do is to create way more", "tokens": [1407, 746, 300, 311, 516, 281, 312, 544, 8559, 13, 1057, 321, 434, 516, 281, 360, 307, 281, 1884, 636, 544], "temperature": 0.0, "avg_logprob": -0.2126314324068736, "compression_ratio": 1.6141304347826086, "no_speech_prob": 2.726447746681515e-06}, {"id": 938, "seek": 442734, "start": 4440.34, "end": 4442.34, "text": " anchor boxes", "tokens": [18487, 9002], "temperature": 0.0, "avg_logprob": -0.2126314324068736, "compression_ratio": 1.6141304347826086, "no_speech_prob": 2.726447746681515e-06}, {"id": 939, "seek": 442734, "start": 4442.58, "end": 4445.54, "text": " Okay, so there's a couple of ways we can create", "tokens": [1033, 11, 370, 456, 311, 257, 1916, 295, 2098, 321, 393, 1884], "temperature": 0.0, "avg_logprob": -0.2126314324068736, "compression_ratio": 1.6141304347826086, "no_speech_prob": 2.726447746681515e-06}, {"id": 940, "seek": 442734, "start": 4448.54, "end": 4454.42, "text": " Quick question. I'm just getting lost in the fact that the anchor boxes in the bounding boxes are", "tokens": [12101, 1168, 13, 286, 478, 445, 1242, 2731, 294, 264, 1186, 300, 264, 18487, 9002, 294, 264, 5472, 278, 9002, 366], "temperature": 0.0, "avg_logprob": -0.2126314324068736, "compression_ratio": 1.6141304347826086, "no_speech_prob": 2.726447746681515e-06}, {"id": 941, "seek": 445442, "start": 4454.42, "end": 4459.76, "text": " How are they not the same? Isn't that how we wrote the last I must be missing something", "tokens": [1012, 366, 436, 406, 264, 912, 30, 6998, 380, 300, 577, 321, 4114, 264, 1036, 286, 1633, 312, 5361, 746], "temperature": 0.0, "avg_logprob": -0.2748837599883208, "compression_ratio": 1.697142857142857, "no_speech_prob": 3.373172876308672e-05}, {"id": 942, "seek": 445442, "start": 4461.9400000000005, "end": 4463.9400000000005, "text": " Anchor boxes are the", "tokens": [39547, 284, 9002, 366, 264], "temperature": 0.0, "avg_logprob": -0.2748837599883208, "compression_ratio": 1.697142857142857, "no_speech_prob": 3.373172876308672e-05}, {"id": 943, "seek": 445442, "start": 4465.38, "end": 4467.9400000000005, "text": " Square the fixed square grid cells", "tokens": [16463, 264, 6806, 3732, 10748, 5438], "temperature": 0.0, "avg_logprob": -0.2748837599883208, "compression_ratio": 1.697142857142857, "no_speech_prob": 3.373172876308672e-05}, {"id": 944, "seek": 445442, "start": 4468.9400000000005, "end": 4472.56, "text": " These are the anchor boxes there in an exact", "tokens": [1981, 366, 264, 18487, 9002, 456, 294, 364, 1900], "temperature": 0.0, "avg_logprob": -0.2748837599883208, "compression_ratio": 1.697142857142857, "no_speech_prob": 3.373172876308672e-05}, {"id": 945, "seek": 445442, "start": 4473.5, "end": 4477.14, "text": " specific unmoving location the bounding boxes are", "tokens": [2685, 517, 3280, 798, 4914, 264, 5472, 278, 9002, 366], "temperature": 0.0, "avg_logprob": -0.2748837599883208, "compression_ratio": 1.697142857142857, "no_speech_prob": 3.373172876308672e-05}, {"id": 946, "seek": 447714, "start": 4477.14, "end": 4484.06, "text": " These are three things about in boxes these 16 things that anchor boxes", "tokens": [1981, 366, 1045, 721, 466, 294, 9002, 613, 3165, 721, 300, 18487, 9002], "temperature": 0.0, "avg_logprob": -0.2734103006859348, "compression_ratio": 1.7052023121387283, "no_speech_prob": 4.2892856981779914e-06}, {"id": 947, "seek": 447714, "start": 4485.660000000001, "end": 4487.660000000001, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.2734103006859348, "compression_ratio": 1.7052023121387283, "no_speech_prob": 4.2892856981779914e-06}, {"id": 948, "seek": 447714, "start": 4487.900000000001, "end": 4491.3, "text": " So we're going to create lots more anchor boxes", "tokens": [407, 321, 434, 516, 281, 1884, 3195, 544, 18487, 9002], "temperature": 0.0, "avg_logprob": -0.2734103006859348, "compression_ratio": 1.7052023121387283, "no_speech_prob": 4.2892856981779914e-06}, {"id": 949, "seek": 447714, "start": 4492.18, "end": 4497.740000000001, "text": " So there's three ways to do that and I've kind of drawn some of them or printed some of them here", "tokens": [407, 456, 311, 1045, 2098, 281, 360, 300, 293, 286, 600, 733, 295, 10117, 512, 295, 552, 420, 13567, 512, 295, 552, 510], "temperature": 0.0, "avg_logprob": -0.2734103006859348, "compression_ratio": 1.7052023121387283, "no_speech_prob": 4.2892856981779914e-06}, {"id": 950, "seek": 447714, "start": 4499.54, "end": 4506.38, "text": " One is to create anchor boxes of different sizes and or an aspect ratios", "tokens": [1485, 307, 281, 1884, 18487, 9002, 295, 819, 11602, 293, 420, 364, 4171, 32435], "temperature": 0.0, "avg_logprob": -0.2734103006859348, "compression_ratio": 1.7052023121387283, "no_speech_prob": 4.2892856981779914e-06}, {"id": 951, "seek": 450638, "start": 4506.38, "end": 4508.900000000001, "text": " So here you can see", "tokens": [407, 510, 291, 393, 536], "temperature": 0.0, "avg_logprob": -0.24340261112559924, "compression_ratio": 1.5728643216080402, "no_speech_prob": 8.13958376966184e-06}, {"id": 952, "seek": 450638, "start": 4510.74, "end": 4512.62, "text": " You know, there's a", "tokens": [509, 458, 11, 456, 311, 257], "temperature": 0.0, "avg_logprob": -0.24340261112559924, "compression_ratio": 1.5728643216080402, "no_speech_prob": 8.13958376966184e-06}, {"id": 953, "seek": 450638, "start": 4512.62, "end": 4514.54, "text": " upright rectangle", "tokens": [27405, 21930], "temperature": 0.0, "avg_logprob": -0.24340261112559924, "compression_ratio": 1.5728643216080402, "no_speech_prob": 8.13958376966184e-06}, {"id": 954, "seek": 450638, "start": 4514.54, "end": 4516.54, "text": " There's a line down rectangle", "tokens": [821, 311, 257, 1622, 760, 21930], "temperature": 0.0, "avg_logprob": -0.24340261112559924, "compression_ratio": 1.5728643216080402, "no_speech_prob": 8.13958376966184e-06}, {"id": 955, "seek": 450638, "start": 4517.58, "end": 4519.58, "text": " And there's a square", "tokens": [400, 456, 311, 257, 3732], "temperature": 0.0, "avg_logprob": -0.24340261112559924, "compression_ratio": 1.5728643216080402, "no_speech_prob": 8.13958376966184e-06}, {"id": 956, "seek": 450638, "start": 4521.9400000000005, "end": 4525.58, "text": " It's a question for the multi-label classification", "tokens": [467, 311, 257, 1168, 337, 264, 4825, 12, 75, 18657, 21538], "temperature": 0.0, "avg_logprob": -0.24340261112559924, "compression_ratio": 1.5728643216080402, "no_speech_prob": 8.13958376966184e-06}, {"id": 957, "seek": 450638, "start": 4525.66, "end": 4529.86, "text": " Why aren't we multiplying the categorical loss by a constant like we did before?", "tokens": [1545, 3212, 380, 321, 30955, 264, 19250, 804, 4470, 538, 257, 5754, 411, 321, 630, 949, 30], "temperature": 0.0, "avg_logprob": -0.24340261112559924, "compression_ratio": 1.5728643216080402, "no_speech_prob": 8.13958376966184e-06}, {"id": 958, "seek": 450638, "start": 4531.06, "end": 4533.06, "text": " That's a great question", "tokens": [663, 311, 257, 869, 1168], "temperature": 0.0, "avg_logprob": -0.24340261112559924, "compression_ratio": 1.5728643216080402, "no_speech_prob": 8.13958376966184e-06}, {"id": 959, "seek": 453306, "start": 4533.06, "end": 4535.660000000001, "text": " Because later on it'll turn out we don't need to", "tokens": [1436, 1780, 322, 309, 603, 1261, 484, 321, 500, 380, 643, 281], "temperature": 0.0, "avg_logprob": -0.17798976705531883, "compression_ratio": 1.6781115879828326, "no_speech_prob": 9.51609035837464e-06}, {"id": 960, "seek": 453306, "start": 4541.34, "end": 4546.1, "text": " So yeah, so you can see here like there's a square and so I don't know if you can see this", "tokens": [407, 1338, 11, 370, 291, 393, 536, 510, 411, 456, 311, 257, 3732, 293, 370, 286, 500, 380, 458, 498, 291, 393, 536, 341], "temperature": 0.0, "avg_logprob": -0.17798976705531883, "compression_ratio": 1.6781115879828326, "no_speech_prob": 9.51609035837464e-06}, {"id": 961, "seek": 453306, "start": 4546.1, "end": 4548.34, "text": " But if you look you basically got one two", "tokens": [583, 498, 291, 574, 291, 1936, 658, 472, 732], "temperature": 0.0, "avg_logprob": -0.17798976705531883, "compression_ratio": 1.6781115879828326, "no_speech_prob": 9.51609035837464e-06}, {"id": 962, "seek": 453306, "start": 4549.22, "end": 4552.72, "text": " Three squares of different sizes and for each of those three squares", "tokens": [6244, 19368, 295, 819, 11602, 293, 337, 1184, 295, 729, 1045, 19368], "temperature": 0.0, "avg_logprob": -0.17798976705531883, "compression_ratio": 1.6781115879828326, "no_speech_prob": 9.51609035837464e-06}, {"id": 963, "seek": 453306, "start": 4552.72, "end": 4558.160000000001, "text": " You've also got a lying down rectangle and an upright rectangle to go with them", "tokens": [509, 600, 611, 658, 257, 8493, 760, 21930, 293, 364, 27405, 21930, 281, 352, 365, 552], "temperature": 0.0, "avg_logprob": -0.17798976705531883, "compression_ratio": 1.6781115879828326, "no_speech_prob": 9.51609035837464e-06}, {"id": 964, "seek": 455816, "start": 4558.16, "end": 4563.66, "text": " Right, so we've got three aspect ratios at three zoom levels. That's one", "tokens": [1779, 11, 370, 321, 600, 658, 1045, 4171, 32435, 412, 1045, 8863, 4358, 13, 663, 311, 472], "temperature": 0.0, "avg_logprob": -0.22626546223958333, "compression_ratio": 1.7234042553191489, "no_speech_prob": 4.6378481783904135e-06}, {"id": 965, "seek": 455816, "start": 4563.66, "end": 4568.46, "text": " We can do we can do this right and this is for the one by one grid", "tokens": [492, 393, 360, 321, 393, 360, 341, 558, 293, 341, 307, 337, 264, 472, 538, 472, 10748], "temperature": 0.0, "avg_logprob": -0.22626546223958333, "compression_ratio": 1.7234042553191489, "no_speech_prob": 4.6378481783904135e-06}, {"id": 966, "seek": 455816, "start": 4568.46, "end": 4574.22, "text": " So in other words if we added two more stride two convolutional layers, you're going to get to a one by one grid", "tokens": [407, 294, 661, 2283, 498, 321, 3869, 732, 544, 1056, 482, 732, 45216, 304, 7914, 11, 291, 434, 516, 281, 483, 281, 257, 472, 538, 472, 10748], "temperature": 0.0, "avg_logprob": -0.22626546223958333, "compression_ratio": 1.7234042553191489, "no_speech_prob": 4.6378481783904135e-06}, {"id": 967, "seek": 455816, "start": 4574.22, "end": 4576.22, "text": " And this is for the one by one grid", "tokens": [400, 341, 307, 337, 264, 472, 538, 472, 10748], "temperature": 0.0, "avg_logprob": -0.22626546223958333, "compression_ratio": 1.7234042553191489, "no_speech_prob": 4.6378481783904135e-06}, {"id": 968, "seek": 455816, "start": 4577.22, "end": 4581.0599999999995, "text": " Another thing we could do is to use", "tokens": [3996, 551, 321, 727, 360, 307, 281, 764], "temperature": 0.0, "avg_logprob": -0.22626546223958333, "compression_ratio": 1.7234042553191489, "no_speech_prob": 4.6378481783904135e-06}, {"id": 969, "seek": 458106, "start": 4581.06, "end": 4588.660000000001, "text": " more convolutional layers as sources of anchor boxes so as well as our and I've", "tokens": [544, 45216, 304, 7914, 382, 7139, 295, 18487, 9002, 370, 382, 731, 382, 527, 293, 286, 600], "temperature": 0.0, "avg_logprob": -0.2512032872154599, "compression_ratio": 1.7085714285714286, "no_speech_prob": 6.339154879242415e-06}, {"id": 970, "seek": 458106, "start": 4589.54, "end": 4595.46, "text": " Randomly jittered these a little bit so it's easy to see right so as well as our 16 by 16 grid cells", "tokens": [37603, 356, 361, 3904, 292, 613, 257, 707, 857, 370, 309, 311, 1858, 281, 536, 558, 370, 382, 731, 382, 527, 3165, 538, 3165, 10748, 5438], "temperature": 0.0, "avg_logprob": -0.2512032872154599, "compression_ratio": 1.7085714285714286, "no_speech_prob": 6.339154879242415e-06}, {"id": 971, "seek": 458106, "start": 4597.580000000001, "end": 4599.580000000001, "text": " 22 or these little grid cells", "tokens": [5853, 420, 613, 707, 10748, 5438], "temperature": 0.0, "avg_logprob": -0.2512032872154599, "compression_ratio": 1.7085714285714286, "no_speech_prob": 6.339154879242415e-06}, {"id": 972, "seek": 458106, "start": 4599.780000000001, "end": 4601.780000000001, "text": " We've also got", "tokens": [492, 600, 611, 658], "temperature": 0.0, "avg_logprob": -0.2512032872154599, "compression_ratio": 1.7085714285714286, "no_speech_prob": 6.339154879242415e-06}, {"id": 973, "seek": 458106, "start": 4601.820000000001, "end": 4607.3, "text": " Two by two grid cells and we've also got the one by one grid cell, right?", "tokens": [4453, 538, 732, 10748, 5438, 293, 321, 600, 611, 658, 264, 472, 538, 472, 10748, 2815, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2512032872154599, "compression_ratio": 1.7085714285714286, "no_speech_prob": 6.339154879242415e-06}, {"id": 974, "seek": 460730, "start": 4607.3, "end": 4614.18, "text": " So in other words if we add three stride stride two convolutions to the to the end", "tokens": [407, 294, 661, 2283, 498, 321, 909, 1045, 1056, 482, 1056, 482, 732, 3754, 15892, 281, 264, 281, 264, 917], "temperature": 0.0, "avg_logprob": -0.1743014926002139, "compression_ratio": 1.7148760330578512, "no_speech_prob": 3.5008358736376977e-06}, {"id": 975, "seek": 460730, "start": 4614.18, "end": 4619.74, "text": " We have four by four two by two and one by one sets of grid cells all of which have", "tokens": [492, 362, 1451, 538, 1451, 732, 538, 732, 293, 472, 538, 472, 6352, 295, 10748, 5438, 439, 295, 597, 362], "temperature": 0.0, "avg_logprob": -0.1743014926002139, "compression_ratio": 1.7148760330578512, "no_speech_prob": 3.5008358736376977e-06}, {"id": 976, "seek": 460730, "start": 4620.18, "end": 4625.9400000000005, "text": " Anchor boxes and then for every one of those we can have all of these different shapes and sizes", "tokens": [39547, 284, 9002, 293, 550, 337, 633, 472, 295, 729, 321, 393, 362, 439, 295, 613, 819, 10854, 293, 11602], "temperature": 0.0, "avg_logprob": -0.1743014926002139, "compression_ratio": 1.7148760330578512, "no_speech_prob": 3.5008358736376977e-06}, {"id": 977, "seek": 460730, "start": 4626.66, "end": 4628.66, "text": " right, so", "tokens": [558, 11, 370], "temperature": 0.0, "avg_logprob": -0.1743014926002139, "compression_ratio": 1.7148760330578512, "no_speech_prob": 3.5008358736376977e-06}, {"id": 978, "seek": 460730, "start": 4628.7, "end": 4632.66, "text": " Obviously those two are combined with each other to create lots of anchor boxes", "tokens": [7580, 729, 732, 366, 9354, 365, 1184, 661, 281, 1884, 3195, 295, 18487, 9002], "temperature": 0.0, "avg_logprob": -0.1743014926002139, "compression_ratio": 1.7148760330578512, "no_speech_prob": 3.5008358736376977e-06}, {"id": 979, "seek": 463266, "start": 4632.66, "end": 4637.46, "text": " And if I try to print that on the screen, it's just one big blur color", "tokens": [400, 498, 286, 853, 281, 4482, 300, 322, 264, 2568, 11, 309, 311, 445, 472, 955, 14257, 2017], "temperature": 0.0, "avg_logprob": -0.20814913795107887, "compression_ratio": 1.9082125603864735, "no_speech_prob": 1.6701216736692004e-05}, {"id": 980, "seek": 463266, "start": 4640.26, "end": 4645.099999999999, "text": " So that's all this code is right it says alright, what are all the grid cell sizes?", "tokens": [407, 300, 311, 439, 341, 3089, 307, 558, 309, 1619, 5845, 11, 437, 366, 439, 264, 10748, 2815, 11602, 30], "temperature": 0.0, "avg_logprob": -0.20814913795107887, "compression_ratio": 1.9082125603864735, "no_speech_prob": 1.6701216736692004e-05}, {"id": 981, "seek": 463266, "start": 4645.099999999999, "end": 4646.58, "text": " I have for the anchor boxes", "tokens": [286, 362, 337, 264, 18487, 9002], "temperature": 0.0, "avg_logprob": -0.20814913795107887, "compression_ratio": 1.9082125603864735, "no_speech_prob": 1.6701216736692004e-05}, {"id": 982, "seek": 463266, "start": 4646.58, "end": 4651.0199999999995, "text": " What are all the zoom levels I have for the anchor boxes and what are all the aspect ratios?", "tokens": [708, 366, 439, 264, 8863, 4358, 286, 362, 337, 264, 18487, 9002, 293, 437, 366, 439, 264, 4171, 32435, 30], "temperature": 0.0, "avg_logprob": -0.20814913795107887, "compression_ratio": 1.9082125603864735, "no_speech_prob": 1.6701216736692004e-05}, {"id": 983, "seek": 463266, "start": 4651.0199999999995, "end": 4655.86, "text": " I have for the anchor boxes and the rest of this code then just goes away", "tokens": [286, 362, 337, 264, 18487, 9002, 293, 264, 1472, 295, 341, 3089, 550, 445, 1709, 1314], "temperature": 0.0, "avg_logprob": -0.20814913795107887, "compression_ratio": 1.9082125603864735, "no_speech_prob": 1.6701216736692004e-05}, {"id": 984, "seek": 463266, "start": 4656.62, "end": 4657.82, "text": " creates", "tokens": [7829], "temperature": 0.0, "avg_logprob": -0.20814913795107887, "compression_ratio": 1.9082125603864735, "no_speech_prob": 1.6701216736692004e-05}, {"id": 985, "seek": 463266, "start": 4657.82, "end": 4659.0599999999995, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.20814913795107887, "compression_ratio": 1.9082125603864735, "no_speech_prob": 1.6701216736692004e-05}, {"id": 986, "seek": 465906, "start": 4659.06, "end": 4662.860000000001, "text": " top left and bottom right corners inside", "tokens": [1192, 1411, 293, 2767, 558, 12413, 1854], "temperature": 0.0, "avg_logprob": -0.18887130797855436, "compression_ratio": 1.6282051282051282, "no_speech_prob": 9.66599145613145e-06}, {"id": 987, "seek": 465906, "start": 4663.5, "end": 4668.240000000001, "text": " Anchor corner and the middle and height width in anchors", "tokens": [39547, 284, 4538, 293, 264, 2808, 293, 6681, 11402, 294, 12723, 830], "temperature": 0.0, "avg_logprob": -0.18887130797855436, "compression_ratio": 1.6282051282051282, "no_speech_prob": 9.66599145613145e-06}, {"id": 988, "seek": 465906, "start": 4669.14, "end": 4673.88, "text": " So that's all this does and you can go through it and print out the anchors and anchor corner", "tokens": [407, 300, 311, 439, 341, 775, 293, 291, 393, 352, 807, 309, 293, 4482, 484, 264, 12723, 830, 293, 18487, 4538], "temperature": 0.0, "avg_logprob": -0.18887130797855436, "compression_ratio": 1.6282051282051282, "no_speech_prob": 9.66599145613145e-06}, {"id": 989, "seek": 467388, "start": 4673.88, "end": 4685.76, "text": " So the key the key is to remember this basic idea that we have a", "tokens": [407, 264, 2141, 264, 2141, 307, 281, 1604, 341, 3875, 1558, 300, 321, 362, 257], "temperature": 0.0, "avg_logprob": -0.27812621467991877, "compression_ratio": 1.3300970873786409, "no_speech_prob": 1.1544580047484487e-06}, {"id": 990, "seek": 467388, "start": 4691.84, "end": 4693.84, "text": " Vector of", "tokens": [691, 20814, 295], "temperature": 0.0, "avg_logprob": -0.27812621467991877, "compression_ratio": 1.3300970873786409, "no_speech_prob": 1.1544580047484487e-06}, {"id": 991, "seek": 467388, "start": 4694.6, "end": 4700.72, "text": " Ground truth stuff right where that stuff is like sets of four", "tokens": [28371, 3494, 1507, 558, 689, 300, 1507, 307, 411, 6352, 295, 1451], "temperature": 0.0, "avg_logprob": -0.27812621467991877, "compression_ratio": 1.3300970873786409, "no_speech_prob": 1.1544580047484487e-06}, {"id": 992, "seek": 470072, "start": 4700.72, "end": 4702.72, "text": " Bounding boxes", "tokens": [363, 24625, 9002], "temperature": 0.0, "avg_logprob": -0.2850289093820672, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.2125030227471143e-05}, {"id": 993, "seek": 470072, "start": 4702.72, "end": 4707.04, "text": " This is what we were given it was in the JSON files", "tokens": [639, 307, 437, 321, 645, 2212, 309, 390, 294, 264, 31828, 7098], "temperature": 0.0, "avg_logprob": -0.2850289093820672, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.2125030227471143e-05}, {"id": 994, "seek": 470072, "start": 4707.04, "end": 4714.16, "text": " All right, it's the ground truth dependent variable sets of four bounding boxes and for each one also a", "tokens": [1057, 558, 11, 309, 311, 264, 2727, 3494, 12334, 7006, 6352, 295, 1451, 5472, 278, 9002, 293, 337, 1184, 472, 611, 257], "temperature": 0.0, "avg_logprob": -0.2850289093820672, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.2125030227471143e-05}, {"id": 995, "seek": 470072, "start": 4715.280000000001, "end": 4722.360000000001, "text": " Class right so this is a person in this location. This is a dog in this location", "tokens": [9471, 558, 370, 341, 307, 257, 954, 294, 341, 4914, 13, 639, 307, 257, 3000, 294, 341, 4914], "temperature": 0.0, "avg_logprob": -0.2850289093820672, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.2125030227471143e-05}, {"id": 996, "seek": 470072, "start": 4723.76, "end": 4725.76, "text": " That's the ground truth that we're given", "tokens": [663, 311, 264, 2727, 3494, 300, 321, 434, 2212], "temperature": 0.0, "avg_logprob": -0.2850289093820672, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.2125030227471143e-05}, {"id": 997, "seek": 472576, "start": 4725.76, "end": 4727.76, "text": " Yes", "tokens": [1079], "temperature": 0.0, "avg_logprob": -0.22047250535753038, "compression_ratio": 1.6887755102040816, "no_speech_prob": 3.0415837954933522e-06}, {"id": 998, "seek": 472576, "start": 4729.72, "end": 4734.04, "text": " Yeah, exactly top left XY bottom right XY", "tokens": [865, 11, 2293, 1192, 1411, 48826, 2767, 558, 48826], "temperature": 0.0, "avg_logprob": -0.22047250535753038, "compression_ratio": 1.6887755102040816, "no_speech_prob": 3.0415837954933522e-06}, {"id": 999, "seek": 472576, "start": 4735.320000000001, "end": 4741.320000000001, "text": " So that's what we printed here. All right, we printed out. This is what we call the ground truth. There's no model", "tokens": [407, 300, 311, 437, 321, 13567, 510, 13, 1057, 558, 11, 321, 13567, 484, 13, 639, 307, 437, 321, 818, 264, 2727, 3494, 13, 821, 311, 572, 2316], "temperature": 0.0, "avg_logprob": -0.22047250535753038, "compression_ratio": 1.6887755102040816, "no_speech_prob": 3.0415837954933522e-06}, {"id": 1000, "seek": 472576, "start": 4741.8, "end": 4748.76, "text": " This is what we're told is what when this is what the answer is meant to be and so remember any time we train a neural net", "tokens": [639, 307, 437, 321, 434, 1907, 307, 437, 562, 341, 307, 437, 264, 1867, 307, 4140, 281, 312, 293, 370, 1604, 604, 565, 321, 3847, 257, 18161, 2533], "temperature": 0.0, "avg_logprob": -0.22047250535753038, "compression_ratio": 1.6887755102040816, "no_speech_prob": 3.0415837954933522e-06}, {"id": 1001, "seek": 472576, "start": 4749.2, "end": 4751.2, "text": " we have a dependent variable and", "tokens": [321, 362, 257, 12334, 7006, 293], "temperature": 0.0, "avg_logprob": -0.22047250535753038, "compression_ratio": 1.6887755102040816, "no_speech_prob": 3.0415837954933522e-06}, {"id": 1002, "seek": 472576, "start": 4752.08, "end": 4754.08, "text": " then we have a", "tokens": [550, 321, 362, 257], "temperature": 0.0, "avg_logprob": -0.22047250535753038, "compression_ratio": 1.6887755102040816, "no_speech_prob": 3.0415837954933522e-06}, {"id": 1003, "seek": 475408, "start": 4754.08, "end": 4758.88, "text": " Neural net some black box neural net that takes some input and", "tokens": [1734, 1807, 2533, 512, 2211, 2424, 18161, 2533, 300, 2516, 512, 4846, 293], "temperature": 0.0, "avg_logprob": -0.24179919354327314, "compression_ratio": 1.664864864864865, "no_speech_prob": 4.860421086050337e-06}, {"id": 1004, "seek": 475408, "start": 4759.96, "end": 4762.44, "text": " Spits out some output activations", "tokens": [1738, 1208, 484, 512, 5598, 2430, 763], "temperature": 0.0, "avg_logprob": -0.24179919354327314, "compression_ratio": 1.664864864864865, "no_speech_prob": 4.860421086050337e-06}, {"id": 1005, "seek": 475408, "start": 4763.5199999999995, "end": 4768.0199999999995, "text": " All right, and we take those activations and we compare them", "tokens": [1057, 558, 11, 293, 321, 747, 729, 2430, 763, 293, 321, 6794, 552], "temperature": 0.0, "avg_logprob": -0.24179919354327314, "compression_ratio": 1.664864864864865, "no_speech_prob": 4.860421086050337e-06}, {"id": 1006, "seek": 475408, "start": 4769.64, "end": 4771.64, "text": " To the ground truth", "tokens": [1407, 264, 2727, 3494], "temperature": 0.0, "avg_logprob": -0.24179919354327314, "compression_ratio": 1.664864864864865, "no_speech_prob": 4.860421086050337e-06}, {"id": 1007, "seek": 475408, "start": 4771.8, "end": 4773.8, "text": " We calculate a loss", "tokens": [492, 8873, 257, 4470], "temperature": 0.0, "avg_logprob": -0.24179919354327314, "compression_ratio": 1.664864864864865, "no_speech_prob": 4.860421086050337e-06}, {"id": 1008, "seek": 475408, "start": 4774.5199999999995, "end": 4776.72, "text": " we find the derivative of that and", "tokens": [321, 915, 264, 13760, 295, 300, 293], "temperature": 0.0, "avg_logprob": -0.24179919354327314, "compression_ratio": 1.664864864864865, "no_speech_prob": 4.860421086050337e-06}, {"id": 1009, "seek": 475408, "start": 4777.5599999999995, "end": 4781.32, "text": " Adjust the weights according to the derivative times the learning rate", "tokens": [34049, 264, 17443, 4650, 281, 264, 13760, 1413, 264, 2539, 3314], "temperature": 0.0, "avg_logprob": -0.24179919354327314, "compression_ratio": 1.664864864864865, "no_speech_prob": 4.860421086050337e-06}, {"id": 1010, "seek": 478132, "start": 4781.32, "end": 4783.32, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.21507288160778226, "compression_ratio": 1.5787037037037037, "no_speech_prob": 4.469064515433274e-05}, {"id": 1011, "seek": 478132, "start": 4786.16, "end": 4788.5599999999995, "text": " So the loss is calculated using a loss function", "tokens": [407, 264, 4470, 307, 15598, 1228, 257, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.21507288160778226, "compression_ratio": 1.5787037037037037, "no_speech_prob": 4.469064515433274e-05}, {"id": 1012, "seek": 478132, "start": 4790.88, "end": 4794.28, "text": " Something I wanted to say is just I think one of the challenges with this", "tokens": [6595, 286, 1415, 281, 584, 307, 445, 286, 519, 472, 295, 264, 4759, 365, 341], "temperature": 0.0, "avg_logprob": -0.21507288160778226, "compression_ratio": 1.5787037037037037, "no_speech_prob": 4.469064515433274e-05}, {"id": 1013, "seek": 478132, "start": 4794.639999999999, "end": 4798.599999999999, "text": " Problem is part of what's going on here is we're having to come up with an architecture", "tokens": [11676, 307, 644, 295, 437, 311, 516, 322, 510, 307, 321, 434, 1419, 281, 808, 493, 365, 364, 9482], "temperature": 0.0, "avg_logprob": -0.21507288160778226, "compression_ratio": 1.5787037037037037, "no_speech_prob": 4.469064515433274e-05}, {"id": 1014, "seek": 478132, "start": 4798.599999999999, "end": 4800.84, "text": " That's letting us predict this ground truth", "tokens": [663, 311, 8295, 505, 6069, 341, 2727, 3494], "temperature": 0.0, "avg_logprob": -0.21507288160778226, "compression_ratio": 1.5787037037037037, "no_speech_prob": 4.469064515433274e-05}, {"id": 1015, "seek": 478132, "start": 4801.24, "end": 4806.679999999999, "text": " Like it's not because you can have you know, any number of objects in your picture", "tokens": [1743, 309, 311, 406, 570, 291, 393, 362, 291, 458, 11, 604, 1230, 295, 6565, 294, 428, 3036], "temperature": 0.0, "avg_logprob": -0.21507288160778226, "compression_ratio": 1.5787037037037037, "no_speech_prob": 4.469064515433274e-05}, {"id": 1016, "seek": 480668, "start": 4806.68, "end": 4812.04, "text": " It's not you know, immediately obvious like oh, what's the correct architecture?", "tokens": [467, 311, 406, 291, 458, 11, 4258, 6322, 411, 1954, 11, 437, 311, 264, 3006, 9482, 30], "temperature": 0.0, "avg_logprob": -0.24823229028544294, "compression_ratio": 1.6150943396226416, "no_speech_prob": 3.4465558655938366e-06}, {"id": 1017, "seek": 480668, "start": 4812.04, "end": 4814.400000000001, "text": " That's gonna let us predict that sort of ground truth", "tokens": [663, 311, 799, 718, 505, 6069, 300, 1333, 295, 2727, 3494], "temperature": 0.0, "avg_logprob": -0.24823229028544294, "compression_ratio": 1.6150943396226416, "no_speech_prob": 3.4465558655938366e-06}, {"id": 1018, "seek": 480668, "start": 4814.400000000001, "end": 4821.96, "text": " I guess so but I'm gonna kind of make this claim as we saw when we looked at the kind of YOLO versus SSD", "tokens": [286, 2041, 370, 457, 286, 478, 799, 733, 295, 652, 341, 3932, 382, 321, 1866, 562, 321, 2956, 412, 264, 733, 295, 398, 5046, 46, 5717, 30262], "temperature": 0.0, "avg_logprob": -0.24823229028544294, "compression_ratio": 1.6150943396226416, "no_speech_prob": 3.4465558655938366e-06}, {"id": 1019, "seek": 480668, "start": 4822.320000000001, "end": 4825.4400000000005, "text": " That like there are only two possible architectures", "tokens": [663, 411, 456, 366, 787, 732, 1944, 6331, 1303], "temperature": 0.0, "avg_logprob": -0.24823229028544294, "compression_ratio": 1.6150943396226416, "no_speech_prob": 3.4465558655938366e-06}, {"id": 1020, "seek": 480668, "start": 4825.68, "end": 4830.360000000001, "text": " the last layer is fully connected or the last layer is convolutional and", "tokens": [264, 1036, 4583, 307, 4498, 4582, 420, 264, 1036, 4583, 307, 45216, 304, 293], "temperature": 0.0, "avg_logprob": -0.24823229028544294, "compression_ratio": 1.6150943396226416, "no_speech_prob": 3.4465558655938366e-06}, {"id": 1021, "seek": 480668, "start": 4830.68, "end": 4833.04, "text": " Both of them work perfectly well", "tokens": [6767, 295, 552, 589, 6239, 731], "temperature": 0.0, "avg_logprob": -0.24823229028544294, "compression_ratio": 1.6150943396226416, "no_speech_prob": 3.4465558655938366e-06}, {"id": 1022, "seek": 480668, "start": 4833.6, "end": 4835.6, "text": " I'm sorry. I meant in terms of", "tokens": [286, 478, 2597, 13, 286, 4140, 294, 2115, 295], "temperature": 0.0, "avg_logprob": -0.24823229028544294, "compression_ratio": 1.6150943396226416, "no_speech_prob": 3.4465558655938366e-06}, {"id": 1023, "seek": 483560, "start": 4835.6, "end": 4840.04, "text": " By creating this idea of anchor boxes and anchor boxes with different locations", "tokens": [3146, 4084, 341, 1558, 295, 18487, 9002, 293, 18487, 9002, 365, 819, 9253], "temperature": 0.0, "avg_logprob": -0.19434585999906734, "compression_ratio": 1.6784140969162995, "no_speech_prob": 7.071826530591352e-06}, {"id": 1024, "seek": 483560, "start": 4840.400000000001, "end": 4847.38, "text": " Locations and sizes that's giving you a format that kind of lets you get to the activations. You're right like high level", "tokens": [12859, 763, 293, 11602, 300, 311, 2902, 291, 257, 7877, 300, 733, 295, 6653, 291, 483, 281, 264, 2430, 763, 13, 509, 434, 558, 411, 1090, 1496], "temperature": 0.0, "avg_logprob": -0.19434585999906734, "compression_ratio": 1.6784140969162995, "no_speech_prob": 7.071826530591352e-06}, {"id": 1025, "seek": 483560, "start": 4847.38, "end": 4852.8, "text": " It's that you say okay, so that's that's really entirely in the loss function", "tokens": [467, 311, 300, 291, 584, 1392, 11, 370, 300, 311, 300, 311, 534, 7696, 294, 264, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.19434585999906734, "compression_ratio": 1.6784140969162995, "no_speech_prob": 7.071826530591352e-06}, {"id": 1026, "seek": 483560, "start": 4853.4800000000005, "end": 4860.46, "text": " Not in the architecture like and if we use the YOLO architecture where we had a fully connected layer", "tokens": [1726, 294, 264, 9482, 411, 293, 498, 321, 764, 264, 398, 5046, 46, 9482, 689, 321, 632, 257, 4498, 4582, 4583], "temperature": 0.0, "avg_logprob": -0.19434585999906734, "compression_ratio": 1.6784140969162995, "no_speech_prob": 7.071826530591352e-06}, {"id": 1027, "seek": 486046, "start": 4860.46, "end": 4865.62, "text": " Like literally there would be no concept of geometry in it at all", "tokens": [1743, 3736, 456, 576, 312, 572, 3410, 295, 18426, 294, 309, 412, 439], "temperature": 0.0, "avg_logprob": -0.20624778487465598, "compression_ratio": 1.6633663366336633, "no_speech_prob": 6.339155788737116e-06}, {"id": 1028, "seek": 486046, "start": 4865.9800000000005, "end": 4869.12, "text": " right, so I would suggest like kind of", "tokens": [558, 11, 370, 286, 576, 3402, 411, 733, 295], "temperature": 0.0, "avg_logprob": -0.20624778487465598, "compression_ratio": 1.6633663366336633, "no_speech_prob": 6.339155788737116e-06}, {"id": 1029, "seek": 486046, "start": 4870.34, "end": 4876.14, "text": " Forgetting the architecture and just like treat it as just a given. It's a thing that is fitting out", "tokens": [18675, 783, 264, 9482, 293, 445, 411, 2387, 309, 382, 445, 257, 2212, 13, 467, 311, 257, 551, 300, 307, 15669, 484], "temperature": 0.0, "avg_logprob": -0.20624778487465598, "compression_ratio": 1.6633663366336633, "no_speech_prob": 6.339155788737116e-06}, {"id": 1030, "seek": 486046, "start": 4876.94, "end": 4878.58, "text": " 16 times", "tokens": [3165, 1413], "temperature": 0.0, "avg_logprob": -0.20624778487465598, "compression_ratio": 1.6633663366336633, "no_speech_prob": 6.339155788737116e-06}, {"id": 1031, "seek": 486046, "start": 4878.58, "end": 4885.62, "text": " 4 plus C activations, right and then I would say our job is to figure out how to take those", "tokens": [1017, 1804, 383, 2430, 763, 11, 558, 293, 550, 286, 576, 584, 527, 1691, 307, 281, 2573, 484, 577, 281, 747, 729], "temperature": 0.0, "avg_logprob": -0.20624778487465598, "compression_ratio": 1.6633663366336633, "no_speech_prob": 6.339155788737116e-06}, {"id": 1032, "seek": 488562, "start": 4885.62, "end": 4890.14, "text": " 16 times 4 plus C activations and", "tokens": [3165, 1413, 1017, 1804, 383, 2430, 763, 293], "temperature": 0.0, "avg_logprob": -0.23656171162923176, "compression_ratio": 1.5656565656565657, "no_speech_prob": 2.2603173874813365e-06}, {"id": 1033, "seek": 488562, "start": 4890.9, "end": 4895.18, "text": " compare them to our ground truth, which is like", "tokens": [6794, 552, 281, 527, 2727, 3494, 11, 597, 307, 411], "temperature": 0.0, "avg_logprob": -0.23656171162923176, "compression_ratio": 1.5656565656565657, "no_speech_prob": 2.2603173874813365e-06}, {"id": 1034, "seek": 488562, "start": 4896.9, "end": 4898.5, "text": " 4", "tokens": [1017], "temperature": 0.0, "avg_logprob": -0.23656171162923176, "compression_ratio": 1.5656565656565657, "no_speech_prob": 2.2603173874813365e-06}, {"id": 1035, "seek": 488562, "start": 4898.5, "end": 4899.78, "text": " plus", "tokens": [1804], "temperature": 0.0, "avg_logprob": -0.23656171162923176, "compression_ratio": 1.5656565656565657, "no_speech_prob": 2.2603173874813365e-06}, {"id": 1036, "seek": 488562, "start": 4899.78, "end": 4905.98, "text": " It's 4 plus 1 but if it was one hot encoded it would be C and I think that's easier to think about so call it 4 plus", "tokens": [467, 311, 1017, 1804, 502, 457, 498, 309, 390, 472, 2368, 2058, 12340, 309, 576, 312, 383, 293, 286, 519, 300, 311, 3571, 281, 519, 466, 370, 818, 309, 1017, 1804], "temperature": 0.0, "avg_logprob": -0.23656171162923176, "compression_ratio": 1.5656565656565657, "no_speech_prob": 2.2603173874813365e-06}, {"id": 1037, "seek": 488562, "start": 4905.98, "end": 4907.22, "text": " C", "tokens": [383], "temperature": 0.0, "avg_logprob": -0.23656171162923176, "compression_ratio": 1.5656565656565657, "no_speech_prob": 2.2603173874813365e-06}, {"id": 1038, "seek": 488562, "start": 4907.22, "end": 4908.58, "text": " times", "tokens": [1413], "temperature": 0.0, "avg_logprob": -0.23656171162923176, "compression_ratio": 1.5656565656565657, "no_speech_prob": 2.2603173874813365e-06}, {"id": 1039, "seek": 488562, "start": 4908.58, "end": 4914.26, "text": " However many ground truth objects there are for that particular image, right? So let's call that", "tokens": [2908, 867, 2727, 3494, 6565, 456, 366, 337, 300, 1729, 3256, 11, 558, 30, 407, 718, 311, 818, 300], "temperature": 0.0, "avg_logprob": -0.23656171162923176, "compression_ratio": 1.5656565656565657, "no_speech_prob": 2.2603173874813365e-06}, {"id": 1040, "seek": 491426, "start": 4914.26, "end": 4916.26, "text": " M", "tokens": [376], "temperature": 0.0, "avg_logprob": -0.28514168713543864, "compression_ratio": 1.5123456790123457, "no_speech_prob": 2.9944217203592416e-06}, {"id": 1041, "seek": 491426, "start": 4916.780000000001, "end": 4919.9400000000005, "text": " Right, so we need a loss function", "tokens": [1779, 11, 370, 321, 643, 257, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.28514168713543864, "compression_ratio": 1.5123456790123457, "no_speech_prob": 2.9944217203592416e-06}, {"id": 1042, "seek": 491426, "start": 4923.22, "end": 4928.02, "text": " That can take these two things and spit out a number that says how good are these activations", "tokens": [663, 393, 747, 613, 732, 721, 293, 22127, 484, 257, 1230, 300, 1619, 577, 665, 366, 613, 2430, 763], "temperature": 0.0, "avg_logprob": -0.28514168713543864, "compression_ratio": 1.5123456790123457, "no_speech_prob": 2.9944217203592416e-06}, {"id": 1043, "seek": 491426, "start": 4928.62, "end": 4930.14, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.28514168713543864, "compression_ratio": 1.5123456790123457, "no_speech_prob": 2.9944217203592416e-06}, {"id": 1044, "seek": 491426, "start": 4930.14, "end": 4932.72, "text": " That's that's what we're trying to do", "tokens": [663, 311, 300, 311, 437, 321, 434, 1382, 281, 360], "temperature": 0.0, "avg_logprob": -0.28514168713543864, "compression_ratio": 1.5123456790123457, "no_speech_prob": 2.9944217203592416e-06}, {"id": 1045, "seek": 491426, "start": 4934.3, "end": 4936.3, "text": " So", "tokens": [407], "temperature": 0.0, "avg_logprob": -0.28514168713543864, "compression_ratio": 1.5123456790123457, "no_speech_prob": 2.9944217203592416e-06}, {"id": 1046, "seek": 491426, "start": 4936.58, "end": 4938.34, "text": " To do it", "tokens": [1407, 360, 309], "temperature": 0.0, "avg_logprob": -0.28514168713543864, "compression_ratio": 1.5123456790123457, "no_speech_prob": 2.9944217203592416e-06}, {"id": 1047, "seek": 491426, "start": 4938.34, "end": 4942.3, "text": " we need to take each one of these M ground truth objects and", "tokens": [321, 643, 281, 747, 1184, 472, 295, 613, 376, 2727, 3494, 6565, 293], "temperature": 0.0, "avg_logprob": -0.28514168713543864, "compression_ratio": 1.5123456790123457, "no_speech_prob": 2.9944217203592416e-06}, {"id": 1048, "seek": 494230, "start": 4942.3, "end": 4944.3, "text": " decide", "tokens": [4536], "temperature": 0.0, "avg_logprob": -0.26853733331384794, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.7264529762760503e-06}, {"id": 1049, "seek": 494230, "start": 4945.820000000001, "end": 4947.22, "text": " Which", "tokens": [3013], "temperature": 0.0, "avg_logprob": -0.26853733331384794, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.7264529762760503e-06}, {"id": 1050, "seek": 494230, "start": 4947.22, "end": 4950.42, "text": " Set of 4 plus C activations is", "tokens": [8928, 295, 1017, 1804, 383, 2430, 763, 307], "temperature": 0.0, "avg_logprob": -0.26853733331384794, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.7264529762760503e-06}, {"id": 1051, "seek": 494230, "start": 4951.78, "end": 4958.1, "text": " Responsible for that object which one should we could be comparing and saying like yeah", "tokens": [46003, 964, 337, 300, 2657, 597, 472, 820, 321, 727, 312, 15763, 293, 1566, 411, 1338], "temperature": 0.0, "avg_logprob": -0.26853733331384794, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.7264529762760503e-06}, {"id": 1052, "seek": 494230, "start": 4958.1, "end": 4961.46, "text": " It's the right class or not and yeah, it's close or not", "tokens": [467, 311, 264, 558, 1508, 420, 406, 293, 1338, 11, 309, 311, 1998, 420, 406], "temperature": 0.0, "avg_logprob": -0.26853733331384794, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.7264529762760503e-06}, {"id": 1053, "seek": 494230, "start": 4962.7, "end": 4964.7, "text": " Okay, and so", "tokens": [1033, 11, 293, 370], "temperature": 0.0, "avg_logprob": -0.26853733331384794, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.7264529762760503e-06}, {"id": 1054, "seek": 494230, "start": 4965.22, "end": 4968.42, "text": " The way we do that is basically to say okay", "tokens": [440, 636, 321, 360, 300, 307, 1936, 281, 584, 1392], "temperature": 0.0, "avg_logprob": -0.26853733331384794, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.7264529762760503e-06}, {"id": 1055, "seek": 496842, "start": 4968.42, "end": 4973.38, "text": " Let's decide the first for the first 4 plus C", "tokens": [961, 311, 4536, 264, 700, 337, 264, 700, 1017, 1804, 383], "temperature": 0.0, "avg_logprob": -0.26877567893580384, "compression_ratio": 1.6952789699570816, "no_speech_prob": 7.183198249549605e-06}, {"id": 1056, "seek": 496842, "start": 4974.3, "end": 4975.9400000000005, "text": " activations", "tokens": [2430, 763], "temperature": 0.0, "avg_logprob": -0.26877567893580384, "compression_ratio": 1.6952789699570816, "no_speech_prob": 7.183198249549605e-06}, {"id": 1057, "seek": 496842, "start": 4975.9400000000005, "end": 4982.82, "text": " Got to be responsible for predicting the bounding box of the thing that's closest to the top left", "tokens": [5803, 281, 312, 6250, 337, 32884, 264, 5472, 278, 2424, 295, 264, 551, 300, 311, 13699, 281, 264, 1192, 1411], "temperature": 0.0, "avg_logprob": -0.26877567893580384, "compression_ratio": 1.6952789699570816, "no_speech_prob": 7.183198249549605e-06}, {"id": 1058, "seek": 496842, "start": 4982.82, "end": 4988.26, "text": " And the last 4 plus C will be predicting those the furthest to the bottom right?", "tokens": [400, 264, 1036, 1017, 1804, 383, 486, 312, 32884, 729, 264, 2687, 36356, 281, 264, 2767, 558, 30], "temperature": 0.0, "avg_logprob": -0.26877567893580384, "compression_ratio": 1.6952789699570816, "no_speech_prob": 7.183198249549605e-06}, {"id": 1059, "seek": 496842, "start": 4988.9, "end": 4993.58, "text": " right and kind of everything in between so this is this matching problem and", "tokens": [558, 293, 733, 295, 1203, 294, 1296, 370, 341, 307, 341, 14324, 1154, 293], "temperature": 0.0, "avg_logprob": -0.26877567893580384, "compression_ratio": 1.6952789699570816, "no_speech_prob": 7.183198249549605e-06}, {"id": 1060, "seek": 499358, "start": 4993.58, "end": 5001.14, "text": " And then of course, we're not using the yellow approach where we have a single vector. We're using the SSD approach where we spit out a", "tokens": [400, 550, 295, 1164, 11, 321, 434, 406, 1228, 264, 5566, 3109, 689, 321, 362, 257, 2167, 8062, 13, 492, 434, 1228, 264, 30262, 3109, 689, 321, 22127, 484, 257], "temperature": 0.0, "avg_logprob": -0.187689208984375, "compression_ratio": 1.6063348416289593, "no_speech_prob": 3.6688252293970436e-06}, {"id": 1061, "seek": 499358, "start": 5004.94, "end": 5010.14, "text": " Convolutional output which means that it's it's not arbitrary as to which we match up", "tokens": [2656, 85, 3386, 304, 5598, 597, 1355, 300, 309, 311, 309, 311, 406, 23211, 382, 281, 597, 321, 2995, 493], "temperature": 0.0, "avg_logprob": -0.187689208984375, "compression_ratio": 1.6063348416289593, "no_speech_prob": 3.6688252293970436e-06}, {"id": 1062, "seek": 499358, "start": 5010.14, "end": 5015.68, "text": " But actually we want to match up the set of activations whose receptive field", "tokens": [583, 767, 321, 528, 281, 2995, 493, 264, 992, 295, 2430, 763, 6104, 45838, 2519], "temperature": 0.0, "avg_logprob": -0.187689208984375, "compression_ratio": 1.6063348416289593, "no_speech_prob": 3.6688252293970436e-06}, {"id": 1063, "seek": 499358, "start": 5016.3, "end": 5020.66, "text": " Most closely reflects, you know has the maximum density", "tokens": [4534, 8185, 18926, 11, 291, 458, 575, 264, 6674, 10305], "temperature": 0.0, "avg_logprob": -0.187689208984375, "compression_ratio": 1.6063348416289593, "no_speech_prob": 3.6688252293970436e-06}, {"id": 1064, "seek": 502066, "start": 5020.66, "end": 5024.74, "text": " from where this real object is", "tokens": [490, 689, 341, 957, 2657, 307], "temperature": 0.0, "avg_logprob": -0.2036309728817064, "compression_ratio": 1.6352459016393444, "no_speech_prob": 8.26780524221249e-06}, {"id": 1065, "seek": 502066, "start": 5025.38, "end": 5028.0199999999995, "text": " But that's a that's a minor tweak", "tokens": [583, 300, 311, 257, 300, 311, 257, 6696, 29879], "temperature": 0.0, "avg_logprob": -0.2036309728817064, "compression_ratio": 1.6352459016393444, "no_speech_prob": 8.26780524221249e-06}, {"id": 1066, "seek": 502066, "start": 5028.38, "end": 5034.5, "text": " You know I guess like that's the easy way to have taught this would have been to start with the YOLO approach", "tokens": [509, 458, 286, 2041, 411, 300, 311, 264, 1858, 636, 281, 362, 5928, 341, 576, 362, 668, 281, 722, 365, 264, 398, 5046, 46, 3109], "temperature": 0.0, "avg_logprob": -0.2036309728817064, "compression_ratio": 1.6352459016393444, "no_speech_prob": 8.26780524221249e-06}, {"id": 1067, "seek": 502066, "start": 5035.0199999999995, "end": 5041.44, "text": " Where it's just like an arbitrary vector and we can decide which activations correspond to which found truth object", "tokens": [2305, 309, 311, 445, 411, 364, 23211, 8062, 293, 321, 393, 4536, 597, 2430, 763, 6805, 281, 597, 1352, 3494, 2657], "temperature": 0.0, "avg_logprob": -0.2036309728817064, "compression_ratio": 1.6352459016393444, "no_speech_prob": 8.26780524221249e-06}, {"id": 1068, "seek": 502066, "start": 5041.86, "end": 5048.86, "text": " As long as it's consistent. It's got to be a consistent rule because like if in the first image the top left", "tokens": [1018, 938, 382, 309, 311, 8398, 13, 467, 311, 658, 281, 312, 257, 8398, 4978, 570, 411, 498, 294, 264, 700, 3256, 264, 1192, 1411], "temperature": 0.0, "avg_logprob": -0.2036309728817064, "compression_ratio": 1.6352459016393444, "no_speech_prob": 8.26780524221249e-06}, {"id": 1069, "seek": 504886, "start": 5048.86, "end": 5050.86, "text": " object", "tokens": [2657], "temperature": 0.0, "avg_logprob": -0.24546051025390625, "compression_ratio": 1.7904761904761906, "no_speech_prob": 1.3211646546551492e-05}, {"id": 1070, "seek": 504886, "start": 5051.259999999999, "end": 5058.82, "text": " Corresponds with the first four plus C activations and then the second image we threw things around and suddenly it's now going with the last", "tokens": [3925, 6663, 82, 365, 264, 700, 1451, 1804, 383, 2430, 763, 293, 550, 264, 1150, 3256, 321, 11918, 721, 926, 293, 5800, 309, 311, 586, 516, 365, 264, 1036], "temperature": 0.0, "avg_logprob": -0.24546051025390625, "compression_ratio": 1.7904761904761906, "no_speech_prob": 1.3211646546551492e-05}, {"id": 1071, "seek": 504886, "start": 5058.82, "end": 5060.82, "text": " four plus C activations", "tokens": [1451, 1804, 383, 2430, 763], "temperature": 0.0, "avg_logprob": -0.24546051025390625, "compression_ratio": 1.7904761904761906, "no_speech_prob": 1.3211646546551492e-05}, {"id": 1072, "seek": 504886, "start": 5061.74, "end": 5063.82, "text": " The neural net doesn't know what to learn", "tokens": [440, 18161, 2533, 1177, 380, 458, 437, 281, 1466], "temperature": 0.0, "avg_logprob": -0.24546051025390625, "compression_ratio": 1.7904761904761906, "no_speech_prob": 1.3211646546551492e-05}, {"id": 1073, "seek": 504886, "start": 5064.58, "end": 5069.74, "text": " But the neural net needs like a loss function needs to be like some consistent task", "tokens": [583, 264, 18161, 2533, 2203, 411, 257, 4470, 2445, 2203, 281, 312, 411, 512, 8398, 5633], "temperature": 0.0, "avg_logprob": -0.24546051025390625, "compression_ratio": 1.7904761904761906, "no_speech_prob": 1.3211646546551492e-05}, {"id": 1074, "seek": 504886, "start": 5070.38, "end": 5075.88, "text": " Right which in this case the consistent task is try to make these activations", "tokens": [1779, 597, 294, 341, 1389, 264, 8398, 5633, 307, 853, 281, 652, 613, 2430, 763], "temperature": 0.0, "avg_logprob": -0.24546051025390625, "compression_ratio": 1.7904761904761906, "no_speech_prob": 1.3211646546551492e-05}, {"id": 1075, "seek": 507588, "start": 5075.88, "end": 5079.08, "text": " Reflect the bounding box in this general area", "tokens": [16957, 1809, 264, 5472, 278, 2424, 294, 341, 2674, 1859], "temperature": 0.0, "avg_logprob": -0.26808087418719034, "compression_ratio": 1.5408163265306123, "no_speech_prob": 5.682337359758094e-06}, {"id": 1076, "seek": 507588, "start": 5080.76, "end": 5083.08, "text": " That's basically what this loss function is trying to do", "tokens": [663, 311, 1936, 437, 341, 4470, 2445, 307, 1382, 281, 360], "temperature": 0.0, "avg_logprob": -0.26808087418719034, "compression_ratio": 1.5408163265306123, "no_speech_prob": 5.682337359758094e-06}, {"id": 1077, "seek": 507588, "start": 5087.68, "end": 5094.84, "text": " Is it purely coincident that you know the four by four in the con con 2d is the same thing as you're 16", "tokens": [1119, 309, 17491, 13001, 1078, 300, 291, 458, 264, 1451, 538, 1451, 294, 264, 416, 416, 568, 67, 307, 264, 912, 551, 382, 291, 434, 3165], "temperature": 0.0, "avg_logprob": -0.26808087418719034, "compression_ratio": 1.5408163265306123, "no_speech_prob": 5.682337359758094e-06}, {"id": 1078, "seek": 507588, "start": 5094.84, "end": 5098.56, "text": " No, not at all coincidence. It's it's because though", "tokens": [883, 11, 406, 412, 439, 22137, 13, 467, 311, 309, 311, 570, 1673], "temperature": 0.0, "avg_logprob": -0.26808087418719034, "compression_ratio": 1.5408163265306123, "no_speech_prob": 5.682337359758094e-06}, {"id": 1079, "seek": 507588, "start": 5100.52, "end": 5103.08, "text": " That four by four comb is going to give us", "tokens": [663, 1451, 538, 1451, 2512, 307, 516, 281, 976, 505], "temperature": 0.0, "avg_logprob": -0.26808087418719034, "compression_ratio": 1.5408163265306123, "no_speech_prob": 5.682337359758094e-06}, {"id": 1080, "seek": 510308, "start": 5103.08, "end": 5106.0, "text": " activations whose receptive field", "tokens": [2430, 763, 6104, 45838, 2519], "temperature": 0.0, "avg_logprob": -0.2692140882665461, "compression_ratio": 1.6504424778761062, "no_speech_prob": 6.438972377509344e-06}, {"id": 1081, "seek": 510308, "start": 5107.04, "end": 5109.76, "text": " Corresponds to those locations in the image", "tokens": [3925, 6663, 82, 281, 729, 9253, 294, 264, 3256], "temperature": 0.0, "avg_logprob": -0.2692140882665461, "compression_ratio": 1.6504424778761062, "no_speech_prob": 6.438972377509344e-06}, {"id": 1082, "seek": 510308, "start": 5110.76, "end": 5116.64, "text": " So it's it's it's carefully designed to make that as effective as possible now", "tokens": [407, 309, 311, 309, 311, 309, 311, 7500, 4761, 281, 652, 300, 382, 4942, 382, 1944, 586], "temperature": 0.0, "avg_logprob": -0.2692140882665461, "compression_ratio": 1.6504424778761062, "no_speech_prob": 6.438972377509344e-06}, {"id": 1083, "seek": 510308, "start": 5118.04, "end": 5125.28, "text": " remember I told you before part two that like the stuff we learn in part two is going to assume that you are", "tokens": [1604, 286, 1907, 291, 949, 644, 732, 300, 411, 264, 1507, 321, 1466, 294, 644, 732, 307, 516, 281, 6552, 300, 291, 366], "temperature": 0.0, "avg_logprob": -0.2692140882665461, "compression_ratio": 1.6504424778761062, "no_speech_prob": 6.438972377509344e-06}, {"id": 1084, "seek": 510308, "start": 5126.04, "end": 5128.88, "text": " extremely comfortable with everything you learn in part one and", "tokens": [4664, 4619, 365, 1203, 291, 1466, 294, 644, 472, 293], "temperature": 0.0, "avg_logprob": -0.2692140882665461, "compression_ratio": 1.6504424778761062, "no_speech_prob": 6.438972377509344e-06}, {"id": 1085, "seek": 510308, "start": 5129.72, "end": 5132.2, "text": " For a lot of you you might be realizing now", "tokens": [1171, 257, 688, 295, 291, 291, 1062, 312, 16734, 586], "temperature": 0.0, "avg_logprob": -0.2692140882665461, "compression_ratio": 1.6504424778761062, "no_speech_prob": 6.438972377509344e-06}, {"id": 1086, "seek": 513220, "start": 5132.2, "end": 5137.74, "text": " Maybe I wasn't quite as familiar with the stuff in part one as I first thought and that's fine", "tokens": [2704, 286, 2067, 380, 1596, 382, 4963, 365, 264, 1507, 294, 644, 472, 382, 286, 700, 1194, 293, 300, 311, 2489], "temperature": 0.0, "avg_logprob": -0.24707833994989808, "compression_ratio": 1.7363013698630136, "no_speech_prob": 4.356848421593895e-06}, {"id": 1087, "seek": 513220, "start": 5138.0, "end": 5141.0, "text": " right, but just realize you might just have to go back and", "tokens": [558, 11, 457, 445, 4325, 291, 1062, 445, 362, 281, 352, 646, 293], "temperature": 0.0, "avg_logprob": -0.24707833994989808, "compression_ratio": 1.7363013698630136, "no_speech_prob": 4.356848421593895e-06}, {"id": 1088, "seek": 513220, "start": 5142.0, "end": 5146.28, "text": " Really think deeply and experiment more with understanding with life", "tokens": [4083, 519, 8760, 293, 5120, 544, 365, 3701, 365, 993], "temperature": 0.0, "avg_logprob": -0.24707833994989808, "compression_ratio": 1.7363013698630136, "no_speech_prob": 4.356848421593895e-06}, {"id": 1089, "seek": 513220, "start": 5146.639999999999, "end": 5152.74, "text": " What are the inputs and outputs to each layer in a convolutional network? How big are they? What are their rank exactly?", "tokens": [708, 366, 264, 15743, 293, 23930, 281, 1184, 4583, 294, 257, 45216, 304, 3209, 30, 1012, 955, 366, 436, 30, 708, 366, 641, 6181, 2293, 30], "temperature": 0.0, "avg_logprob": -0.24707833994989808, "compression_ratio": 1.7363013698630136, "no_speech_prob": 4.356848421593895e-06}, {"id": 1090, "seek": 513220, "start": 5152.74, "end": 5156.96, "text": " How are they calculated so that you really fully understand the idea of a receptive field?", "tokens": [1012, 366, 436, 15598, 370, 300, 291, 534, 4498, 1223, 264, 1558, 295, 257, 45838, 2519, 30], "temperature": 0.0, "avg_logprob": -0.24707833994989808, "compression_ratio": 1.7363013698630136, "no_speech_prob": 4.356848421593895e-06}, {"id": 1091, "seek": 513220, "start": 5157.28, "end": 5161.16, "text": " What's the loss function really? How does back propagation work exactly?", "tokens": [708, 311, 264, 4470, 2445, 534, 30, 1012, 775, 646, 38377, 589, 2293, 30], "temperature": 0.0, "avg_logprob": -0.24707833994989808, "compression_ratio": 1.7363013698630136, "no_speech_prob": 4.356848421593895e-06}, {"id": 1092, "seek": 516116, "start": 5161.16, "end": 5164.24, "text": " exactly like these things all need to be like", "tokens": [2293, 411, 613, 721, 439, 643, 281, 312, 411], "temperature": 0.0, "avg_logprob": -0.2927385330200195, "compression_ratio": 1.590643274853801, "no_speech_prob": 6.854241291875951e-06}, {"id": 1093, "seek": 516116, "start": 5165.72, "end": 5167.72, "text": " deeply felt intuitions", "tokens": [8760, 2762, 16224, 626], "temperature": 0.0, "avg_logprob": -0.2927385330200195, "compression_ratio": 1.590643274853801, "no_speech_prob": 6.854241291875951e-06}, {"id": 1094, "seek": 516116, "start": 5168.599999999999, "end": 5176.24, "text": " Which you only get through to practice and once they're all deeply felt intuitions, then you can really watch this video", "tokens": [3013, 291, 787, 483, 807, 281, 3124, 293, 1564, 436, 434, 439, 8760, 2762, 16224, 626, 11, 550, 291, 393, 534, 1159, 341, 960], "temperature": 0.0, "avg_logprob": -0.2927385330200195, "compression_ratio": 1.590643274853801, "no_speech_prob": 6.854241291875951e-06}, {"id": 1095, "seek": 516116, "start": 5176.96, "end": 5181.8, "text": " And you'll be like oh, I see okay. I see that", "tokens": [400, 291, 603, 312, 411, 1954, 11, 286, 536, 1392, 13, 286, 536, 300], "temperature": 0.0, "avg_logprob": -0.2927385330200195, "compression_ratio": 1.590643274853801, "no_speech_prob": 6.854241291875951e-06}, {"id": 1096, "seek": 516116, "start": 5182.8, "end": 5185.8, "text": " You know these activations just need", "tokens": [509, 458, 613, 2430, 763, 445, 643], "temperature": 0.0, "avg_logprob": -0.2927385330200195, "compression_ratio": 1.590643274853801, "no_speech_prob": 6.854241291875951e-06}, {"id": 1097, "seek": 518580, "start": 5185.8, "end": 5194.12, "text": " Need some way of understanding what task they're being given that is being done by the loss function and the loss function is encoding", "tokens": [16984, 512, 636, 295, 3701, 437, 5633, 436, 434, 885, 2212, 300, 307, 885, 1096, 538, 264, 4470, 2445, 293, 264, 4470, 2445, 307, 43430], "temperature": 0.0, "avg_logprob": -0.27909967173700745, "compression_ratio": 1.6742857142857144, "no_speech_prob": 7.88912620919291e-06}, {"id": 1098, "seek": 518580, "start": 5194.4400000000005, "end": 5196.04, "text": " a task", "tokens": [257, 5633], "temperature": 0.0, "avg_logprob": -0.27909967173700745, "compression_ratio": 1.6742857142857144, "no_speech_prob": 7.88912620919291e-06}, {"id": 1099, "seek": 518580, "start": 5196.04, "end": 5203.24, "text": " And so the task of the SSD loss function is basically two parts part one is", "tokens": [400, 370, 264, 5633, 295, 264, 30262, 4470, 2445, 307, 1936, 732, 3166, 644, 472, 307], "temperature": 0.0, "avg_logprob": -0.27909967173700745, "compression_ratio": 1.6742857142857144, "no_speech_prob": 7.88912620919291e-06}, {"id": 1100, "seek": 518580, "start": 5204.360000000001, "end": 5207.96, "text": " Figure out which ground truth object is closest to which", "tokens": [43225, 484, 597, 2727, 3494, 2657, 307, 13699, 281, 597], "temperature": 0.0, "avg_logprob": -0.27909967173700745, "compression_ratio": 1.6742857142857144, "no_speech_prob": 7.88912620919291e-06}, {"id": 1101, "seek": 518580, "start": 5208.88, "end": 5210.68, "text": " grid cell or which", "tokens": [10748, 2815, 420, 597], "temperature": 0.0, "avg_logprob": -0.27909967173700745, "compression_ratio": 1.6742857142857144, "no_speech_prob": 7.88912620919291e-06}, {"id": 1102, "seek": 521068, "start": 5210.68, "end": 5217.92, "text": " Anchor box right when we when we started doing this the grid cells of the convolution and the anchor boxes were the same", "tokens": [39547, 284, 2424, 558, 562, 321, 562, 321, 1409, 884, 341, 264, 10748, 5438, 295, 264, 45216, 293, 264, 18487, 9002, 645, 264, 912], "temperature": 0.0, "avg_logprob": -0.3466692515781948, "compression_ratio": 1.6055555555555556, "no_speech_prob": 6.14411874266807e-06}, {"id": 1103, "seek": 521068, "start": 5218.400000000001, "end": 5220.400000000001, "text": " right, but now", "tokens": [558, 11, 457, 586], "temperature": 0.0, "avg_logprob": -0.3466692515781948, "compression_ratio": 1.6055555555555556, "no_speech_prob": 6.14411874266807e-06}, {"id": 1104, "seek": 521068, "start": 5220.400000000001, "end": 5223.16, "text": " we're starting to introduce the idea that", "tokens": [321, 434, 2891, 281, 5366, 264, 1558, 300], "temperature": 0.0, "avg_logprob": -0.3466692515781948, "compression_ratio": 1.6055555555555556, "no_speech_prob": 6.14411874266807e-06}, {"id": 1105, "seek": 521068, "start": 5225.400000000001, "end": 5229.84, "text": " We can have multiple anchor boxes their grid cell okay", "tokens": [492, 393, 362, 3866, 18487, 9002, 641, 10748, 2815, 1392], "temperature": 0.0, "avg_logprob": -0.3466692515781948, "compression_ratio": 1.6055555555555556, "no_speech_prob": 6.14411874266807e-06}, {"id": 1106, "seek": 521068, "start": 5230.96, "end": 5233.72, "text": " This is why I start to get a little bit more complicated", "tokens": [639, 307, 983, 286, 722, 281, 483, 257, 707, 857, 544, 6179], "temperature": 0.0, "avg_logprob": -0.3466692515781948, "compression_ratio": 1.6055555555555556, "no_speech_prob": 6.14411874266807e-06}, {"id": 1107, "seek": 523372, "start": 5233.72, "end": 5241.12, "text": " So every ground truth object we have to figure out which anchor boxes are closest to every anchor box", "tokens": [407, 633, 2727, 3494, 2657, 321, 362, 281, 2573, 484, 597, 18487, 9002, 366, 13699, 281, 633, 18487, 2424], "temperature": 0.0, "avg_logprob": -0.2117254998948839, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.3405074191250606e-06}, {"id": 1108, "seek": 523372, "start": 5241.12, "end": 5244.240000000001, "text": " We have to decide which ground truth object is responsible for", "tokens": [492, 362, 281, 4536, 597, 2727, 3494, 2657, 307, 6250, 337], "temperature": 0.0, "avg_logprob": -0.2117254998948839, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.3405074191250606e-06}, {"id": 1109, "seek": 523372, "start": 5245.0, "end": 5246.280000000001, "text": " if any", "tokens": [498, 604], "temperature": 0.0, "avg_logprob": -0.2117254998948839, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.3405074191250606e-06}, {"id": 1110, "seek": 523372, "start": 5246.280000000001, "end": 5248.4800000000005, "text": " Okay, and once we've done that matching", "tokens": [1033, 11, 293, 1564, 321, 600, 1096, 300, 14324], "temperature": 0.0, "avg_logprob": -0.2117254998948839, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.3405074191250606e-06}, {"id": 1111, "seek": 523372, "start": 5249.240000000001, "end": 5251.08, "text": " It's trivial", "tokens": [467, 311, 26703], "temperature": 0.0, "avg_logprob": -0.2117254998948839, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.3405074191250606e-06}, {"id": 1112, "seek": 523372, "start": 5251.08, "end": 5253.88, "text": " now we just basically go through and do", "tokens": [586, 321, 445, 1936, 352, 807, 293, 360], "temperature": 0.0, "avg_logprob": -0.2117254998948839, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.3405074191250606e-06}, {"id": 1113, "seek": 523372, "start": 5257.240000000001, "end": 5259.240000000001, "text": " Going back to the", "tokens": [10963, 646, 281, 264], "temperature": 0.0, "avg_logprob": -0.2117254998948839, "compression_ratio": 1.5494505494505495, "no_speech_prob": 3.3405074191250606e-06}, {"id": 1114, "seek": 525924, "start": 5259.24, "end": 5261.24, "text": " Single object detection", "tokens": [31248, 2657, 17784], "temperature": 0.0, "avg_logprob": -0.4924213575280231, "compression_ratio": 1.7733990147783252, "no_speech_prob": 1.3630890862259548e-05}, {"id": 1115, "seek": 525924, "start": 5263.5599999999995, "end": 5265.5599999999995, "text": " Now it's just this", "tokens": [823, 309, 311, 445, 341], "temperature": 0.0, "avg_logprob": -0.4924213575280231, "compression_ratio": 1.7733990147783252, "no_speech_prob": 1.3630890862259548e-05}, {"id": 1116, "seek": 525924, "start": 5266.599999999999, "end": 5272.5199999999995, "text": " But it's once we've got every ground truth object matched to an anchor box to a set of activations", "tokens": [583, 309, 311, 1564, 321, 600, 658, 633, 2727, 3494, 2657, 21447, 281, 364, 18487, 2424, 281, 257, 992, 295, 2430, 763], "temperature": 0.0, "avg_logprob": -0.4924213575280231, "compression_ratio": 1.7733990147783252, "no_speech_prob": 1.3630890862259548e-05}, {"id": 1117, "seek": 525924, "start": 5273.08, "end": 5280.36, "text": " We can basically then say okay. What's the cross entropy loss of the categorical part? What's the L1 loss of the?", "tokens": [492, 393, 1936, 550, 584, 1392, 13, 708, 311, 264, 3278, 30867, 4470, 295, 264, 19250, 804, 644, 30, 708, 311, 264, 441, 16, 4470, 295, 264, 30], "temperature": 0.0, "avg_logprob": -0.4924213575280231, "compression_ratio": 1.7733990147783252, "no_speech_prob": 1.3630890862259548e-05}, {"id": 1118, "seek": 525924, "start": 5281.4, "end": 5283.4, "text": " coordinate part", "tokens": [15670, 644], "temperature": 0.0, "avg_logprob": -0.4924213575280231, "compression_ratio": 1.7733990147783252, "no_speech_prob": 1.3630890862259548e-05}, {"id": 1119, "seek": 525924, "start": 5283.4, "end": 5288.599999999999, "text": " So really it's the matching part which is the cross entropy loss of the categorical part", "tokens": [407, 534, 309, 311, 264, 14324, 644, 597, 307, 264, 3278, 30867, 4470, 295, 264, 19250, 804, 644], "temperature": 0.0, "avg_logprob": -0.4924213575280231, "compression_ratio": 1.7733990147783252, "no_speech_prob": 1.3630890862259548e-05}, {"id": 1120, "seek": 528860, "start": 5288.6, "end": 5290.6, "text": " which is kind of the", "tokens": [597, 307, 733, 295, 264], "temperature": 0.0, "avg_logprob": -0.3346184902503842, "compression_ratio": 1.5031446540880504, "no_speech_prob": 2.1112195099703968e-05}, {"id": 1121, "seek": 528860, "start": 5291.68, "end": 5297.120000000001, "text": " No, kind of slightly surprising bit and then this idea of", "tokens": [883, 11, 733, 295, 4748, 8830, 857, 293, 550, 341, 1558, 295], "temperature": 0.0, "avg_logprob": -0.3346184902503842, "compression_ratio": 1.5031446540880504, "no_speech_prob": 2.1112195099703968e-05}, {"id": 1122, "seek": 528860, "start": 5298.92, "end": 5307.120000000001, "text": " Picking those in a way that the convolutional network gives it the best opportunity to calculate that part of the space is then the final", "tokens": [430, 10401, 729, 294, 257, 636, 300, 264, 45216, 304, 3209, 2709, 309, 264, 1151, 2650, 281, 8873, 300, 644, 295, 264, 1901, 307, 550, 264, 2572], "temperature": 0.0, "avg_logprob": -0.3346184902503842, "compression_ratio": 1.5031446540880504, "no_speech_prob": 2.1112195099703968e-05}, {"id": 1123, "seek": 528860, "start": 5308.120000000001, "end": 5310.120000000001, "text": " cherry on top", "tokens": [20164, 322, 1192], "temperature": 0.0, "avg_logprob": -0.3346184902503842, "compression_ratio": 1.5031446540880504, "no_speech_prob": 2.1112195099703968e-05}, {"id": 1124, "seek": 528860, "start": 5311.64, "end": 5313.64, "text": " And this", "tokens": [400, 341], "temperature": 0.0, "avg_logprob": -0.3346184902503842, "compression_ratio": 1.5031446540880504, "no_speech_prob": 2.1112195099703968e-05}, {"id": 1125, "seek": 531364, "start": 5313.64, "end": 5321.160000000001, "text": " I'll tell you something else this class is by is by far. I think going to be the most", "tokens": [286, 603, 980, 291, 746, 1646, 341, 1508, 307, 538, 307, 538, 1400, 13, 286, 519, 516, 281, 312, 264, 881], "temperature": 0.0, "avg_logprob": -0.2232345457999937, "compression_ratio": 1.723809523809524, "no_speech_prob": 4.785038981935941e-06}, {"id": 1126, "seek": 531364, "start": 5321.96, "end": 5326.4800000000005, "text": " Conceptually challenging and part of the reason for that is that after this", "tokens": [47482, 671, 7595, 293, 644, 295, 264, 1778, 337, 300, 307, 300, 934, 341], "temperature": 0.0, "avg_logprob": -0.2232345457999937, "compression_ratio": 1.723809523809524, "no_speech_prob": 4.785038981935941e-06}, {"id": 1127, "seek": 531364, "start": 5327.200000000001, "end": 5331.4800000000005, "text": " We're going to go and do some different stuff and we're going to come back to it in", "tokens": [492, 434, 516, 281, 352, 293, 360, 512, 819, 1507, 293, 321, 434, 516, 281, 808, 646, 281, 309, 294], "temperature": 0.0, "avg_logprob": -0.2232345457999937, "compression_ratio": 1.723809523809524, "no_speech_prob": 4.785038981935941e-06}, {"id": 1128, "seek": 531364, "start": 5332.360000000001, "end": 5336.96, "text": " Lesson 14 and do it again with some tweaks", "tokens": [18649, 266, 3499, 293, 360, 309, 797, 365, 512, 46664], "temperature": 0.0, "avg_logprob": -0.2232345457999937, "compression_ratio": 1.723809523809524, "no_speech_prob": 4.785038981935941e-06}, {"id": 1129, "seek": 531364, "start": 5337.4800000000005, "end": 5340.4800000000005, "text": " Right and we're going to add in some of the new stuff we learn afterwards", "tokens": [1779, 293, 321, 434, 516, 281, 909, 294, 512, 295, 264, 777, 1507, 321, 1466, 10543], "temperature": 0.0, "avg_logprob": -0.2232345457999937, "compression_ratio": 1.723809523809524, "no_speech_prob": 4.785038981935941e-06}, {"id": 1130, "seek": 534048, "start": 5340.48, "end": 5344.639999999999, "text": " So you're going to get like a whole second run through of this material", "tokens": [407, 291, 434, 516, 281, 483, 411, 257, 1379, 1150, 1190, 807, 295, 341, 2527], "temperature": 0.0, "avg_logprob": -0.2206382404674183, "compression_ratio": 1.6385542168674698, "no_speech_prob": 1.5445699318661354e-05}, {"id": 1131, "seek": 534048, "start": 5345.959999999999, "end": 5349.32, "text": " Once we add some some extra stuff at the end, so we're kind of", "tokens": [3443, 321, 909, 512, 512, 2857, 1507, 412, 264, 917, 11, 370, 321, 434, 733, 295], "temperature": 0.0, "avg_logprob": -0.2206382404674183, "compression_ratio": 1.6385542168674698, "no_speech_prob": 1.5445699318661354e-05}, {"id": 1132, "seek": 534048, "start": 5350.12, "end": 5354.5199999999995, "text": " Going to revise it as we normally do remember in part one. We kind of went through", "tokens": [10963, 281, 44252, 309, 382, 321, 5646, 360, 1604, 294, 644, 472, 13, 492, 733, 295, 1437, 807], "temperature": 0.0, "avg_logprob": -0.2206382404674183, "compression_ratio": 1.6385542168674698, "no_speech_prob": 1.5445699318661354e-05}, {"id": 1133, "seek": 534048, "start": 5355.24, "end": 5356.48, "text": " computer vision", "tokens": [3820, 5201], "temperature": 0.0, "avg_logprob": -0.2206382404674183, "compression_ratio": 1.6385542168674698, "no_speech_prob": 1.5445699318661354e-05}, {"id": 1134, "seek": 534048, "start": 5356.48, "end": 5360.759999999999, "text": " NLP structured data back to NLP back to computer vision, you know", "tokens": [426, 45196, 18519, 1412, 646, 281, 426, 45196, 646, 281, 3820, 5201, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.2206382404674183, "compression_ratio": 1.6385542168674698, "no_speech_prob": 1.5445699318661354e-05}, {"id": 1135, "seek": 534048, "start": 5360.759999999999, "end": 5365.08, "text": " So we revised everything from the start at the end. It'll be kind of similar", "tokens": [407, 321, 35228, 1203, 490, 264, 722, 412, 264, 917, 13, 467, 603, 312, 733, 295, 2531], "temperature": 0.0, "avg_logprob": -0.2206382404674183, "compression_ratio": 1.6385542168674698, "no_speech_prob": 1.5445699318661354e-05}, {"id": 1136, "seek": 534048, "start": 5366.28, "end": 5367.599999999999, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.2206382404674183, "compression_ratio": 1.6385542168674698, "no_speech_prob": 1.5445699318661354e-05}, {"id": 1137, "seek": 536760, "start": 5367.6, "end": 5373.0, "text": " Yeah, so don't worry if it's a bit challenging interest", "tokens": [865, 11, 370, 500, 380, 3292, 498, 309, 311, 257, 857, 7595, 1179], "temperature": 0.0, "avg_logprob": -0.2030972050082299, "compression_ratio": 1.4759036144578312, "no_speech_prob": 1.2606344171217643e-05}, {"id": 1138, "seek": 536760, "start": 5374.92, "end": 5377.76, "text": " You'll get there okay, so", "tokens": [509, 603, 483, 456, 1392, 11, 370], "temperature": 0.0, "avg_logprob": -0.2030972050082299, "compression_ratio": 1.4759036144578312, "no_speech_prob": 1.2606344171217643e-05}, {"id": 1139, "seek": 536760, "start": 5380.200000000001, "end": 5382.200000000001, "text": " So for every", "tokens": [407, 337, 633], "temperature": 0.0, "avg_logprob": -0.2030972050082299, "compression_ratio": 1.4759036144578312, "no_speech_prob": 1.2606344171217643e-05}, {"id": 1140, "seek": 536760, "start": 5382.84, "end": 5387.76, "text": " Grid cell that can be different sizes. We can have different orientations and zooms", "tokens": [42905, 2815, 300, 393, 312, 819, 11602, 13, 492, 393, 362, 819, 8579, 763, 293, 5721, 4785], "temperature": 0.0, "avg_logprob": -0.2030972050082299, "compression_ratio": 1.4759036144578312, "no_speech_prob": 1.2606344171217643e-05}, {"id": 1141, "seek": 536760, "start": 5389.08, "end": 5392.400000000001, "text": " representing different different anchor boxes, which are just like", "tokens": [13460, 819, 819, 18487, 9002, 11, 597, 366, 445, 411], "temperature": 0.0, "avg_logprob": -0.2030972050082299, "compression_ratio": 1.4759036144578312, "no_speech_prob": 1.2606344171217643e-05}, {"id": 1142, "seek": 539240, "start": 5392.4, "end": 5400.16, "text": " Conceptual ideas that basically every one of these is associated with one set of four plus C", "tokens": [47482, 901, 3487, 300, 1936, 633, 472, 295, 613, 307, 6615, 365, 472, 992, 295, 1451, 1804, 383], "temperature": 0.0, "avg_logprob": -0.330430425008138, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.521547003198066e-06}, {"id": 1143, "seek": 539240, "start": 5400.92, "end": 5402.92, "text": " activations", "tokens": [2430, 763], "temperature": 0.0, "avg_logprob": -0.330430425008138, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.521547003198066e-06}, {"id": 1144, "seek": 539240, "start": 5404.2, "end": 5411.2, "text": " In our model, right? So however many of these ground truth boxes we have we need to have that times", "tokens": [682, 527, 2316, 11, 558, 30, 407, 4461, 867, 295, 613, 2727, 3494, 9002, 321, 362, 321, 643, 281, 362, 300, 1413], "temperature": 0.0, "avg_logprob": -0.330430425008138, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.521547003198066e-06}, {"id": 1145, "seek": 539240, "start": 5412.48, "end": 5414.48, "text": " four plus C", "tokens": [1451, 1804, 383], "temperature": 0.0, "avg_logprob": -0.330430425008138, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.521547003198066e-06}, {"id": 1146, "seek": 539240, "start": 5414.96, "end": 5416.599999999999, "text": " activations in the model", "tokens": [2430, 763, 294, 264, 2316], "temperature": 0.0, "avg_logprob": -0.330430425008138, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.521547003198066e-06}, {"id": 1147, "seek": 539240, "start": 5416.599999999999, "end": 5418.599999999999, "text": " Now that does not mean that each", "tokens": [823, 300, 775, 406, 914, 300, 1184], "temperature": 0.0, "avg_logprob": -0.330430425008138, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.521547003198066e-06}, {"id": 1148, "seek": 539240, "start": 5419.44, "end": 5420.719999999999, "text": " convolutional", "tokens": [45216, 304], "temperature": 0.0, "avg_logprob": -0.330430425008138, "compression_ratio": 1.6179775280898876, "no_speech_prob": 2.521547003198066e-06}, {"id": 1149, "seek": 542072, "start": 5420.72, "end": 5422.88, "text": " Layer needs that many filters", "tokens": [35166, 2203, 300, 867, 15995], "temperature": 0.0, "avg_logprob": -0.24596917451317632, "compression_ratio": 1.755952380952381, "no_speech_prob": 9.97280494630104e-06}, {"id": 1150, "seek": 542072, "start": 5423.240000000001, "end": 5429.92, "text": " Right because remember the four by four convolutional layer already has 16 sets of filters", "tokens": [1779, 570, 1604, 264, 1451, 538, 1451, 45216, 304, 4583, 1217, 575, 3165, 6352, 295, 15995], "temperature": 0.0, "avg_logprob": -0.24596917451317632, "compression_ratio": 1.755952380952381, "no_speech_prob": 9.97280494630104e-06}, {"id": 1151, "seek": 542072, "start": 5430.360000000001, "end": 5434.6, "text": " the two by two convolutional layer already has four sets of", "tokens": [264, 732, 538, 732, 45216, 304, 4583, 1217, 575, 1451, 6352, 295], "temperature": 0.0, "avg_logprob": -0.24596917451317632, "compression_ratio": 1.755952380952381, "no_speech_prob": 9.97280494630104e-06}, {"id": 1152, "seek": 542072, "start": 5436.68, "end": 5444.88, "text": " Activations and then finally the one by one has one set of applications. So we basically get one plus four plus 16", "tokens": [28550, 763, 293, 550, 2721, 264, 472, 538, 472, 575, 472, 992, 295, 5821, 13, 407, 321, 1936, 483, 472, 1804, 1451, 1804, 3165], "temperature": 0.0, "avg_logprob": -0.24596917451317632, "compression_ratio": 1.755952380952381, "no_speech_prob": 9.97280494630104e-06}, {"id": 1153, "seek": 544488, "start": 5444.88, "end": 5452.28, "text": " for free just because that's how a convolution works it calculates things at different locations", "tokens": [337, 1737, 445, 570, 300, 311, 577, 257, 45216, 1985, 309, 4322, 1024, 721, 412, 819, 9253], "temperature": 0.0, "avg_logprob": -0.2711437328441723, "compression_ratio": 1.5803108808290156, "no_speech_prob": 5.50755430595018e-06}, {"id": 1154, "seek": 544488, "start": 5453.36, "end": 5455.36, "text": " So we actually only need", "tokens": [407, 321, 767, 787, 643], "temperature": 0.0, "avg_logprob": -0.2711437328441723, "compression_ratio": 1.5803108808290156, "no_speech_prob": 5.50755430595018e-06}, {"id": 1155, "seek": 544488, "start": 5457.28, "end": 5460.76, "text": " To know K where K is the number of", "tokens": [1407, 458, 591, 689, 591, 307, 264, 1230, 295], "temperature": 0.0, "avg_logprob": -0.2711437328441723, "compression_ratio": 1.5803108808290156, "no_speech_prob": 5.50755430595018e-06}, {"id": 1156, "seek": 544488, "start": 5462.08, "end": 5467.68, "text": " Zooms by the number of aspect ratios where else the grids we're going to get for free", "tokens": [10337, 4785, 538, 264, 1230, 295, 4171, 32435, 689, 1646, 264, 677, 3742, 321, 434, 516, 281, 483, 337, 1737], "temperature": 0.0, "avg_logprob": -0.2711437328441723, "compression_ratio": 1.5803108808290156, "no_speech_prob": 5.50755430595018e-06}, {"id": 1157, "seek": 544488, "start": 5468.56, "end": 5471.92, "text": " Through our architecture, so let's check out that architecture", "tokens": [8927, 527, 9482, 11, 370, 718, 311, 1520, 484, 300, 9482], "temperature": 0.0, "avg_logprob": -0.2711437328441723, "compression_ratio": 1.5803108808290156, "no_speech_prob": 5.50755430595018e-06}, {"id": 1158, "seek": 547192, "start": 5471.92, "end": 5476.12, "text": " So the model is nearly identical to what we had before", "tokens": [407, 264, 2316, 307, 6217, 14800, 281, 437, 321, 632, 949], "temperature": 0.0, "avg_logprob": -0.2939464208242056, "compression_ratio": 1.6123595505617978, "no_speech_prob": 3.6119549804425333e-06}, {"id": 1159, "seek": 547192, "start": 5477.0, "end": 5479.0, "text": " All right, but we're going to go", "tokens": [1057, 558, 11, 457, 321, 434, 516, 281, 352], "temperature": 0.0, "avg_logprob": -0.2939464208242056, "compression_ratio": 1.6123595505617978, "no_speech_prob": 3.6119549804425333e-06}, {"id": 1160, "seek": 547192, "start": 5479.88, "end": 5482.74, "text": " We're going to have a number of strive to convolutions", "tokens": [492, 434, 516, 281, 362, 257, 1230, 295, 23829, 281, 3754, 15892], "temperature": 0.0, "avg_logprob": -0.2939464208242056, "compression_ratio": 1.6123595505617978, "no_speech_prob": 3.6119549804425333e-06}, {"id": 1161, "seek": 547192, "start": 5484.76, "end": 5491.16, "text": " Which is going to take us through to four by four two by two", "tokens": [3013, 307, 516, 281, 747, 505, 807, 281, 1451, 538, 1451, 732, 538, 732], "temperature": 0.0, "avg_logprob": -0.2939464208242056, "compression_ratio": 1.6123595505617978, "no_speech_prob": 3.6119549804425333e-06}, {"id": 1162, "seek": 547192, "start": 5492.4400000000005, "end": 5499.12, "text": " One by one, right each drive to convolution halves our grid size in both directions", "tokens": [1485, 538, 472, 11, 558, 1184, 3332, 281, 45216, 38490, 527, 10748, 2744, 294, 1293, 11095], "temperature": 0.0, "avg_logprob": -0.2939464208242056, "compression_ratio": 1.6123595505617978, "no_speech_prob": 3.6119549804425333e-06}, {"id": 1163, "seek": 549912, "start": 5499.12, "end": 5505.74, "text": " Okay, and then after we do our first convolution to get to four by four", "tokens": [1033, 11, 293, 550, 934, 321, 360, 527, 700, 45216, 281, 483, 281, 1451, 538, 1451], "temperature": 0.0, "avg_logprob": -0.20131423447158311, "compression_ratio": 1.9147727272727273, "no_speech_prob": 3.5008351915166713e-06}, {"id": 1164, "seek": 549912, "start": 5506.88, "end": 5511.08, "text": " We're going to grab a set of outputs from that because we want to save away", "tokens": [492, 434, 516, 281, 4444, 257, 992, 295, 23930, 490, 300, 570, 321, 528, 281, 3155, 1314], "temperature": 0.0, "avg_logprob": -0.20131423447158311, "compression_ratio": 1.9147727272727273, "no_speech_prob": 3.5008351915166713e-06}, {"id": 1165, "seek": 549912, "start": 5511.84, "end": 5513.84, "text": " the four by four", "tokens": [264, 1451, 538, 1451], "temperature": 0.0, "avg_logprob": -0.20131423447158311, "compression_ratio": 1.9147727272727273, "no_speech_prob": 3.5008351915166713e-06}, {"id": 1166, "seek": 549912, "start": 5513.92, "end": 5519.72, "text": " grids anchors and then once we get to two by two we grab another set of", "tokens": [677, 3742, 12723, 830, 293, 550, 1564, 321, 483, 281, 732, 538, 732, 321, 4444, 1071, 992, 295], "temperature": 0.0, "avg_logprob": -0.20131423447158311, "compression_ratio": 1.9147727272727273, "no_speech_prob": 3.5008351915166713e-06}, {"id": 1167, "seek": 549912, "start": 5520.5599999999995, "end": 5527.2, "text": " Now two by two anchors and then finally we get to one by one and we so we get another set of outputs", "tokens": [823, 732, 538, 732, 12723, 830, 293, 550, 2721, 321, 483, 281, 472, 538, 472, 293, 321, 370, 321, 483, 1071, 992, 295, 23930], "temperature": 0.0, "avg_logprob": -0.20131423447158311, "compression_ratio": 1.9147727272727273, "no_speech_prob": 3.5008351915166713e-06}, {"id": 1168, "seek": 552720, "start": 5527.2, "end": 5531.48, "text": " All right, so you can see we've got like a whole bunch of these", "tokens": [1057, 558, 11, 370, 291, 393, 536, 321, 600, 658, 411, 257, 1379, 3840, 295, 613], "temperature": 0.0, "avg_logprob": -0.2579395587627704, "compression_ratio": 1.627659574468085, "no_speech_prob": 6.643367669312283e-06}, {"id": 1169, "seek": 552720, "start": 5533.48, "end": 5535.48, "text": " Outcon", "tokens": [5925, 1671], "temperature": 0.0, "avg_logprob": -0.2579395587627704, "compression_ratio": 1.627659574468085, "no_speech_prob": 6.643367669312283e-06}, {"id": 1170, "seek": 552720, "start": 5536.0, "end": 5538.0, "text": " This first one we're actually not using", "tokens": [639, 700, 472, 321, 434, 767, 406, 1228], "temperature": 0.0, "avg_logprob": -0.2579395587627704, "compression_ratio": 1.627659574468085, "no_speech_prob": 6.643367669312283e-06}, {"id": 1171, "seek": 552720, "start": 5539.4, "end": 5542.0, "text": " So at the end of that we can then concatenate", "tokens": [407, 412, 264, 917, 295, 300, 321, 393, 550, 1588, 7186, 473], "temperature": 0.0, "avg_logprob": -0.2579395587627704, "compression_ratio": 1.627659574468085, "no_speech_prob": 6.643367669312283e-06}, {"id": 1172, "seek": 552720, "start": 5542.8, "end": 5543.88, "text": " dot-cat", "tokens": [5893, 12, 18035], "temperature": 0.0, "avg_logprob": -0.2579395587627704, "compression_ratio": 1.627659574468085, "no_speech_prob": 6.643367669312283e-06}, {"id": 1173, "seek": 552720, "start": 5543.88, "end": 5550.76, "text": " Concatenate them all together. So we've got the four by four activations the two by two activations the one by one", "tokens": [18200, 7186, 473, 552, 439, 1214, 13, 407, 321, 600, 658, 264, 1451, 538, 1451, 2430, 763, 264, 732, 538, 732, 2430, 763, 264, 472, 538, 472], "temperature": 0.0, "avg_logprob": -0.2579395587627704, "compression_ratio": 1.627659574468085, "no_speech_prob": 6.643367669312283e-06}, {"id": 1174, "seek": 552720, "start": 5554.48, "end": 5556.48, "text": " So that's going to give us", "tokens": [407, 300, 311, 516, 281, 976, 505], "temperature": 0.0, "avg_logprob": -0.2579395587627704, "compression_ratio": 1.627659574468085, "no_speech_prob": 6.643367669312283e-06}, {"id": 1175, "seek": 555648, "start": 5556.48, "end": 5557.679999999999, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.35599420987642727, "compression_ratio": 1.5379310344827586, "no_speech_prob": 1.6797212083474733e-06}, {"id": 1176, "seek": 555648, "start": 5557.679999999999, "end": 5560.719999999999, "text": " Correct number of activations to give us one", "tokens": [12753, 1230, 295, 2430, 763, 281, 976, 505, 472], "temperature": 0.0, "avg_logprob": -0.35599420987642727, "compression_ratio": 1.5379310344827586, "no_speech_prob": 1.6797212083474733e-06}, {"id": 1177, "seek": 555648, "start": 5561.639999999999, "end": 5563.639999999999, "text": " activation for every", "tokens": [24433, 337, 633], "temperature": 0.0, "avg_logprob": -0.35599420987642727, "compression_ratio": 1.5379310344827586, "no_speech_prob": 1.6797212083474733e-06}, {"id": 1178, "seek": 555648, "start": 5565.2, "end": 5566.799999999999, "text": " For every", "tokens": [1171, 633], "temperature": 0.0, "avg_logprob": -0.35599420987642727, "compression_ratio": 1.5379310344827586, "no_speech_prob": 1.6797212083474733e-06}, {"id": 1179, "seek": 555648, "start": 5566.799999999999, "end": 5569.639999999999, "text": " Bounding for every anchor box that we have", "tokens": [363, 24625, 337, 633, 18487, 2424, 300, 321, 362], "temperature": 0.0, "avg_logprob": -0.35599420987642727, "compression_ratio": 1.5379310344827586, "no_speech_prob": 1.6797212083474733e-06}, {"id": 1180, "seek": 555648, "start": 5570.759999999999, "end": 5574.2, "text": " So then we just set criteria as before to SSD loss", "tokens": [407, 550, 321, 445, 992, 11101, 382, 949, 281, 30262, 4470], "temperature": 0.0, "avg_logprob": -0.35599420987642727, "compression_ratio": 1.5379310344827586, "no_speech_prob": 1.6797212083474733e-06}, {"id": 1181, "seek": 555648, "start": 5575.44, "end": 5579.44, "text": " and we go ahead and train right and", "tokens": [293, 321, 352, 2286, 293, 3847, 558, 293], "temperature": 0.0, "avg_logprob": -0.35599420987642727, "compression_ratio": 1.5379310344827586, "no_speech_prob": 1.6797212083474733e-06}, {"id": 1182, "seek": 555648, "start": 5582.799999999999, "end": 5584.799999999999, "text": " Away we go so", "tokens": [36957, 321, 352, 370], "temperature": 0.0, "avg_logprob": -0.35599420987642727, "compression_ratio": 1.5379310344827586, "no_speech_prob": 1.6797212083474733e-06}, {"id": 1183, "seek": 558480, "start": 5584.8, "end": 5591.24, "text": " in this case, I'm just printing out those things with at least probability of point one and", "tokens": [294, 341, 1389, 11, 286, 478, 445, 14699, 484, 729, 721, 365, 412, 1935, 8482, 295, 935, 472, 293], "temperature": 0.0, "avg_logprob": -0.2211708026927906, "compression_ratio": 1.647887323943662, "no_speech_prob": 6.339158517221222e-06}, {"id": 1184, "seek": 558480, "start": 5591.92, "end": 5593.92, "text": " You can see we've got", "tokens": [509, 393, 536, 321, 600, 658], "temperature": 0.0, "avg_logprob": -0.2211708026927906, "compression_ratio": 1.647887323943662, "no_speech_prob": 6.339158517221222e-06}, {"id": 1185, "seek": 558480, "start": 5593.96, "end": 5596.2, "text": " Some things look okay. Some things don't", "tokens": [2188, 721, 574, 1392, 13, 2188, 721, 500, 380], "temperature": 0.0, "avg_logprob": -0.2211708026927906, "compression_ratio": 1.647887323943662, "no_speech_prob": 6.339158517221222e-06}, {"id": 1186, "seek": 558480, "start": 5596.84, "end": 5601.4400000000005, "text": " Our big objects like bird. We've got a box here with a point nine three probability", "tokens": [2621, 955, 6565, 411, 5255, 13, 492, 600, 658, 257, 2424, 510, 365, 257, 935, 4949, 1045, 8482], "temperature": 0.0, "avg_logprob": -0.2211708026927906, "compression_ratio": 1.647887323943662, "no_speech_prob": 6.339158517221222e-06}, {"id": 1187, "seek": 558480, "start": 5601.4400000000005, "end": 5603.4400000000005, "text": " It's looking to be in about the right spot", "tokens": [467, 311, 1237, 281, 312, 294, 466, 264, 558, 4008], "temperature": 0.0, "avg_logprob": -0.2211708026927906, "compression_ratio": 1.647887323943662, "no_speech_prob": 6.339158517221222e-06}, {"id": 1188, "seek": 558480, "start": 5603.4400000000005, "end": 5605.4400000000005, "text": " Our persons looking pretty hopeful", "tokens": [2621, 14453, 1237, 1238, 20531], "temperature": 0.0, "avg_logprob": -0.2211708026927906, "compression_ratio": 1.647887323943662, "no_speech_prob": 6.339158517221222e-06}, {"id": 1189, "seek": 558480, "start": 5606.64, "end": 5609.16, "text": " But a motorbike has nothing at all", "tokens": [583, 257, 5932, 30283, 575, 1825, 412, 439], "temperature": 0.0, "avg_logprob": -0.2211708026927906, "compression_ratio": 1.647887323943662, "no_speech_prob": 6.339158517221222e-06}, {"id": 1190, "seek": 560916, "start": 5609.16, "end": 5611.16, "text": " The probability of point one", "tokens": [440, 8482, 295, 935, 472], "temperature": 0.0, "avg_logprob": -0.4515295190326238, "compression_ratio": 1.4527027027027026, "no_speech_prob": 3.187543825333705e-06}, {"id": 1191, "seek": 560916, "start": 5613.16, "end": 5615.36, "text": " Apotid plants looking pretty horrible", "tokens": [8723, 310, 327, 5972, 1237, 1238, 9263], "temperature": 0.0, "avg_logprob": -0.4515295190326238, "compression_ratio": 1.4527027027027026, "no_speech_prob": 3.187543825333705e-06}, {"id": 1192, "seek": 560916, "start": 5617.16, "end": 5619.16, "text": " Our bus is all the wrong size", "tokens": [2621, 1255, 307, 439, 264, 2085, 2744], "temperature": 0.0, "avg_logprob": -0.4515295190326238, "compression_ratio": 1.4527027027027026, "no_speech_prob": 3.187543825333705e-06}, {"id": 1193, "seek": 560916, "start": 5621.599999999999, "end": 5623.96, "text": " What's going on so", "tokens": [708, 311, 516, 322, 370], "temperature": 0.0, "avg_logprob": -0.4515295190326238, "compression_ratio": 1.4527027027027026, "no_speech_prob": 3.187543825333705e-06}, {"id": 1194, "seek": 560916, "start": 5625.24, "end": 5629.599999999999, "text": " though what's going on here will tell us a lot about the kind of history of", "tokens": [1673, 437, 311, 516, 322, 510, 486, 980, 505, 257, 688, 466, 264, 733, 295, 2503, 295], "temperature": 0.0, "avg_logprob": -0.4515295190326238, "compression_ratio": 1.4527027027027026, "no_speech_prob": 3.187543825333705e-06}, {"id": 1195, "seek": 560916, "start": 5631.84, "end": 5634.36, "text": " Object detection and so", "tokens": [24753, 17784, 293, 370], "temperature": 0.0, "avg_logprob": -0.4515295190326238, "compression_ratio": 1.4527027027027026, "no_speech_prob": 3.187543825333705e-06}, {"id": 1196, "seek": 563436, "start": 5634.36, "end": 5638.58, "text": " These five papers the key", "tokens": [1981, 1732, 10577, 264, 2141], "temperature": 0.0, "avg_logprob": -0.43759163750542535, "compression_ratio": 1.6706827309236947, "no_speech_prob": 3.2377092793467455e-06}, {"id": 1197, "seek": 563436, "start": 5639.08, "end": 5643.4, "text": " steps in the history recent modern history of object detection and", "tokens": [4439, 294, 264, 2503, 5162, 4363, 2503, 295, 2657, 17784, 293], "temperature": 0.0, "avg_logprob": -0.43759163750542535, "compression_ratio": 1.6706827309236947, "no_speech_prob": 3.2377092793467455e-06}, {"id": 1198, "seek": 563436, "start": 5643.96, "end": 5650.599999999999, "text": " So they go back to about I think maybe 2013 this paper called scalable object detection using deep neural networks", "tokens": [407, 436, 352, 646, 281, 466, 286, 519, 1310, 9012, 341, 3035, 1219, 38481, 2657, 17784, 1228, 2452, 18161, 9590], "temperature": 0.0, "avg_logprob": -0.43759163750542535, "compression_ratio": 1.6706827309236947, "no_speech_prob": 3.2377092793467455e-06}, {"id": 1199, "seek": 563436, "start": 5650.88, "end": 5656.0, "text": " This is what basically set everything up and when people refer to the multi-box method", "tokens": [639, 307, 437, 1936, 992, 1203, 493, 293, 562, 561, 2864, 281, 264, 4825, 12, 4995, 3170], "temperature": 0.0, "avg_logprob": -0.43759163750542535, "compression_ratio": 1.6706827309236947, "no_speech_prob": 3.2377092793467455e-06}, {"id": 1200, "seek": 563436, "start": 5656.5199999999995, "end": 5662.28, "text": " They're talking about this paper and this was the basic one that came up with this idea that you can have a loss function", "tokens": [814, 434, 1417, 466, 341, 3035, 293, 341, 390, 264, 3875, 472, 300, 1361, 493, 365, 341, 1558, 300, 291, 393, 362, 257, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.43759163750542535, "compression_ratio": 1.6706827309236947, "no_speech_prob": 3.2377092793467455e-06}, {"id": 1201, "seek": 566228, "start": 5662.28, "end": 5667.34, "text": " That has this matching process and then you can kind of use that to do object", "tokens": [663, 575, 341, 14324, 1399, 293, 550, 291, 393, 733, 295, 764, 300, 281, 360, 2657], "temperature": 0.0, "avg_logprob": -0.41731570518180117, "compression_ratio": 1.5204081632653061, "no_speech_prob": 1.1300555343041196e-05}, {"id": 1202, "seek": 566228, "start": 5668.16, "end": 5675.08, "text": " So everything since that time has been trying to figure out basically how to make this better", "tokens": [407, 1203, 1670, 300, 565, 575, 668, 1382, 281, 2573, 484, 1936, 577, 281, 652, 341, 1101], "temperature": 0.0, "avg_logprob": -0.41731570518180117, "compression_ratio": 1.5204081632653061, "no_speech_prob": 1.1300555343041196e-05}, {"id": 1203, "seek": 566228, "start": 5676.92, "end": 5678.92, "text": " So in parallel", "tokens": [407, 294, 8952], "temperature": 0.0, "avg_logprob": -0.41731570518180117, "compression_ratio": 1.5204081632653061, "no_speech_prob": 1.1300555343041196e-05}, {"id": 1204, "seek": 566228, "start": 5679.4, "end": 5685.28, "text": " As a guy called Ross Gershik who was going down a totally different direction, which was he had", "tokens": [1018, 257, 2146, 1219, 16140, 460, 433, 71, 1035, 567, 390, 516, 760, 257, 3879, 819, 3513, 11, 597, 390, 415, 632], "temperature": 0.0, "avg_logprob": -0.41731570518180117, "compression_ratio": 1.5204081632653061, "no_speech_prob": 1.1300555343041196e-05}, {"id": 1205, "seek": 566228, "start": 5686.12, "end": 5688.12, "text": " These two stage", "tokens": [1981, 732, 3233], "temperature": 0.0, "avg_logprob": -0.41731570518180117, "compression_ratio": 1.5204081632653061, "no_speech_prob": 1.1300555343041196e-05}, {"id": 1206, "seek": 568812, "start": 5688.12, "end": 5695.44, "text": " These two stage processes where the first stage used like classical computer vision approaches to like find kind of", "tokens": [1981, 732, 3233, 7555, 689, 264, 700, 3233, 1143, 411, 13735, 3820, 5201, 11587, 281, 411, 915, 733, 295], "temperature": 0.0, "avg_logprob": -0.21397527058919272, "compression_ratio": 1.688259109311741, "no_speech_prob": 1.8631095372256823e-05}, {"id": 1207, "seek": 568812, "start": 5695.88, "end": 5703.44, "text": " Edges and changes of gradients and stuff to kind of guess which parts of the image may represent distinct", "tokens": [3977, 2880, 293, 2962, 295, 2771, 2448, 293, 1507, 281, 733, 295, 2041, 597, 3166, 295, 264, 3256, 815, 2906, 10644], "temperature": 0.0, "avg_logprob": -0.21397527058919272, "compression_ratio": 1.688259109311741, "no_speech_prob": 1.8631095372256823e-05}, {"id": 1208, "seek": 568812, "start": 5704.04, "end": 5707.0, "text": " objects and then fit each of those into a", "tokens": [6565, 293, 550, 3318, 1184, 295, 729, 666, 257], "temperature": 0.0, "avg_logprob": -0.21397527058919272, "compression_ratio": 1.688259109311741, "no_speech_prob": 1.8631095372256823e-05}, {"id": 1209, "seek": 568812, "start": 5708.16, "end": 5709.5199999999995, "text": " convolutional neural network", "tokens": [45216, 304, 18161, 3209], "temperature": 0.0, "avg_logprob": -0.21397527058919272, "compression_ratio": 1.688259109311741, "no_speech_prob": 1.8631095372256823e-05}, {"id": 1210, "seek": 568812, "start": 5709.5199999999995, "end": 5716.8, "text": " Which was basically designed to figure out is that actually the kind of object I'm interested in and so this was the kind of", "tokens": [3013, 390, 1936, 4761, 281, 2573, 484, 307, 300, 767, 264, 733, 295, 2657, 286, 478, 3102, 294, 293, 370, 341, 390, 264, 733, 295], "temperature": 0.0, "avg_logprob": -0.21397527058919272, "compression_ratio": 1.688259109311741, "no_speech_prob": 1.8631095372256823e-05}, {"id": 1211, "seek": 571680, "start": 5716.8, "end": 5718.0, "text": " the", "tokens": [264], "temperature": 0.0, "avg_logprob": -0.3679033750063413, "compression_ratio": 1.6174863387978142, "no_speech_prob": 5.955047072347952e-06}, {"id": 1212, "seek": 571680, "start": 5718.0, "end": 5720.2, "text": " R-CNN and then fast R-CNN", "tokens": [497, 12, 34, 45, 45, 293, 550, 2370, 497, 12, 34, 45, 45], "temperature": 0.0, "avg_logprob": -0.3679033750063413, "compression_ratio": 1.6174863387978142, "no_speech_prob": 5.955047072347952e-06}, {"id": 1213, "seek": 571680, "start": 5720.88, "end": 5725.72, "text": " There was kind of a hybrid of traditional computer vision and deep learning", "tokens": [821, 390, 733, 295, 257, 13051, 295, 5164, 3820, 5201, 293, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.3679033750063413, "compression_ratio": 1.6174863387978142, "no_speech_prob": 5.955047072347952e-06}, {"id": 1214, "seek": 571680, "start": 5726.56, "end": 5728.28, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.3679033750063413, "compression_ratio": 1.6174863387978142, "no_speech_prob": 5.955047072347952e-06}, {"id": 1215, "seek": 571680, "start": 5728.28, "end": 5734.76, "text": " what Ross and his team then did was they basically took this multi-box idea and replaced the", "tokens": [437, 16140, 293, 702, 1469, 550, 630, 390, 436, 1936, 1890, 341, 4825, 12, 4995, 1558, 293, 10772, 264], "temperature": 0.0, "avg_logprob": -0.3679033750063413, "compression_ratio": 1.6174863387978142, "no_speech_prob": 5.955047072347952e-06}, {"id": 1216, "seek": 571680, "start": 5736.320000000001, "end": 5741.6, "text": " Traditional non deep learning computer vision part of their two-stage process with a component", "tokens": [46738, 2107, 2452, 2539, 3820, 5201, 644, 295, 641, 732, 12, 17882, 1399, 365, 257, 6542], "temperature": 0.0, "avg_logprob": -0.3679033750063413, "compression_ratio": 1.6174863387978142, "no_speech_prob": 5.955047072347952e-06}, {"id": 1217, "seek": 574160, "start": 5741.6, "end": 5746.88, "text": " So they now have two components one component that basically spat out something like this", "tokens": [407, 436, 586, 362, 732, 6677, 472, 6542, 300, 1936, 15000, 484, 746, 411, 341], "temperature": 0.0, "avg_logprob": -0.2886718114217122, "compression_ratio": 1.7707509881422925, "no_speech_prob": 3.2886739518289687e-06}, {"id": 1218, "seek": 574160, "start": 5747.360000000001, "end": 5752.6, "text": " Which they call these region proposals, you know all of the things that might be objects", "tokens": [3013, 436, 818, 613, 4458, 20198, 11, 291, 458, 439, 295, 264, 721, 300, 1062, 312, 6565], "temperature": 0.0, "avg_logprob": -0.2886718114217122, "compression_ratio": 1.7707509881422925, "no_speech_prob": 3.2886739518289687e-06}, {"id": 1219, "seek": 574160, "start": 5752.6, "end": 5756.240000000001, "text": " And then the second part was the same as this earlier work", "tokens": [400, 550, 264, 1150, 644, 390, 264, 912, 382, 341, 3071, 589], "temperature": 0.0, "avg_logprob": -0.2886718114217122, "compression_ratio": 1.7707509881422925, "no_speech_prob": 3.2886739518289687e-06}, {"id": 1220, "seek": 574160, "start": 5756.240000000001, "end": 5758.400000000001, "text": " It was basically something that talked each of those", "tokens": [467, 390, 1936, 746, 300, 2825, 1184, 295, 729], "temperature": 0.0, "avg_logprob": -0.2886718114217122, "compression_ratio": 1.7707509881422925, "no_speech_prob": 3.2886739518289687e-06}, {"id": 1221, "seek": 574160, "start": 5758.76, "end": 5765.88, "text": " Fed it into a separate component which was designed to classify whether or not that particular thing really isn't", "tokens": [7772, 309, 666, 257, 4994, 6542, 597, 390, 4761, 281, 33872, 1968, 420, 406, 300, 1729, 551, 534, 1943, 380], "temperature": 0.0, "avg_logprob": -0.2886718114217122, "compression_ratio": 1.7707509881422925, "no_speech_prob": 3.2886739518289687e-06}, {"id": 1222, "seek": 574160, "start": 5766.120000000001, "end": 5768.120000000001, "text": " interesting object or not", "tokens": [1880, 2657, 420, 406], "temperature": 0.0, "avg_logprob": -0.2886718114217122, "compression_ratio": 1.7707509881422925, "no_speech_prob": 3.2886739518289687e-06}, {"id": 1223, "seek": 576812, "start": 5768.12, "end": 5773.18, "text": " At a similar time these two papers came out", "tokens": [1711, 257, 2531, 565, 613, 732, 10577, 1361, 484], "temperature": 0.0, "avg_logprob": -0.18114171709333146, "compression_ratio": 1.476923076923077, "no_speech_prob": 5.682350092683919e-06}, {"id": 1224, "seek": 576812, "start": 5774.0, "end": 5778.98, "text": " Yolo and SSD and both of these did something pretty cool", "tokens": [398, 7902, 293, 30262, 293, 1293, 295, 613, 630, 746, 1238, 1627], "temperature": 0.0, "avg_logprob": -0.18114171709333146, "compression_ratio": 1.476923076923077, "no_speech_prob": 5.682350092683919e-06}, {"id": 1225, "seek": 576812, "start": 5779.36, "end": 5783.5599999999995, "text": " Which is they got the same kind of performance as fast R-CNN", "tokens": [3013, 307, 436, 658, 264, 912, 733, 295, 3389, 382, 2370, 497, 12, 34, 45, 45], "temperature": 0.0, "avg_logprob": -0.18114171709333146, "compression_ratio": 1.476923076923077, "no_speech_prob": 5.682350092683919e-06}, {"id": 1226, "seek": 576812, "start": 5784.24, "end": 5786.24, "text": " But with one stage", "tokens": [583, 365, 472, 3233], "temperature": 0.0, "avg_logprob": -0.18114171709333146, "compression_ratio": 1.476923076923077, "no_speech_prob": 5.682350092683919e-06}, {"id": 1227, "seek": 576812, "start": 5786.96, "end": 5794.12, "text": " Okay, and so they basically took the multi-box idea and they tried to figure out how to deal with this mess", "tokens": [1033, 11, 293, 370, 436, 1936, 1890, 264, 4825, 12, 4995, 1558, 293, 436, 3031, 281, 2573, 484, 577, 281, 2028, 365, 341, 2082], "temperature": 0.0, "avg_logprob": -0.18114171709333146, "compression_ratio": 1.476923076923077, "no_speech_prob": 5.682350092683919e-06}, {"id": 1228, "seek": 579412, "start": 5794.12, "end": 5798.36, "text": " Good stuff and the basic ideas were to use", "tokens": [2205, 1507, 293, 264, 3875, 3487, 645, 281, 764], "temperature": 0.0, "avg_logprob": -0.351590887292639, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.260293967992766e-06}, {"id": 1229, "seek": 579412, "start": 5799.16, "end": 5803.36, "text": " clinical hard negative mining where they would like go through and find", "tokens": [9115, 1152, 3671, 15512, 689, 436, 576, 411, 352, 807, 293, 915], "temperature": 0.0, "avg_logprob": -0.351590887292639, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.260293967992766e-06}, {"id": 1230, "seek": 579412, "start": 5804.16, "end": 5806.16, "text": " all of the", "tokens": [439, 295, 264], "temperature": 0.0, "avg_logprob": -0.351590887292639, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.260293967992766e-06}, {"id": 1231, "seek": 579412, "start": 5806.5599999999995, "end": 5809.08, "text": " Matches it didn't look that good and throw them away", "tokens": [26178, 279, 309, 994, 380, 574, 300, 665, 293, 3507, 552, 1314], "temperature": 0.0, "avg_logprob": -0.351590887292639, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.260293967992766e-06}, {"id": 1232, "seek": 579412, "start": 5811.599999999999, "end": 5813.599999999999, "text": " Some very", "tokens": [2188, 588], "temperature": 0.0, "avg_logprob": -0.351590887292639, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.260293967992766e-06}, {"id": 1233, "seek": 579412, "start": 5813.599999999999, "end": 5819.92, "text": " Tricky and complex data augmentation methods all kinds of factory basically, but they got it to work", "tokens": [1765, 20539, 293, 3997, 1412, 14501, 19631, 7150, 439, 3685, 295, 9265, 1936, 11, 457, 436, 658, 309, 281, 589], "temperature": 0.0, "avg_logprob": -0.351590887292639, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.260293967992766e-06}, {"id": 1234, "seek": 579412, "start": 5820.84, "end": 5822.84, "text": " pretty pretty well", "tokens": [1238, 1238, 731], "temperature": 0.0, "avg_logprob": -0.351590887292639, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.260293967992766e-06}, {"id": 1235, "seek": 582284, "start": 5822.84, "end": 5831.96, "text": " But then something really cool happened late last year, which is this thing called focal loss this paper focal loss for dense object detection", "tokens": [583, 550, 746, 534, 1627, 2011, 3469, 1036, 1064, 11, 597, 307, 341, 551, 1219, 26592, 4470, 341, 3035, 26592, 4470, 337, 18011, 2657, 17784], "temperature": 0.0, "avg_logprob": -0.3132668460708067, "compression_ratio": 1.7935779816513762, "no_speech_prob": 3.7265651826601243e-06}, {"id": 1236, "seek": 582284, "start": 5833.28, "end": 5840.88, "text": " The network architecture is called retina net where they actually realized why this messy crap wasn't working and", "tokens": [440, 3209, 9482, 307, 1219, 1533, 1426, 2533, 689, 436, 767, 5334, 983, 341, 16191, 12426, 2067, 380, 1364, 293], "temperature": 0.0, "avg_logprob": -0.3132668460708067, "compression_ratio": 1.7935779816513762, "no_speech_prob": 3.7265651826601243e-06}, {"id": 1237, "seek": 582284, "start": 5841.4800000000005, "end": 5847.52, "text": " I'll describe why this messy crap wasn't working by trying to describe why it is that we can't find the motivation", "tokens": [286, 603, 6786, 983, 341, 16191, 12426, 2067, 380, 1364, 538, 1382, 281, 6786, 983, 309, 307, 300, 321, 393, 380, 915, 264, 12335], "temperature": 0.0, "avg_logprob": -0.3132668460708067, "compression_ratio": 1.7935779816513762, "no_speech_prob": 3.7265651826601243e-06}, {"id": 1238, "seek": 584752, "start": 5847.52, "end": 5851.52, "text": " So here's the thing when", "tokens": [407, 510, 311, 264, 551, 562], "temperature": 0.0, "avg_logprob": -0.3209572982788086, "compression_ratio": 1.3548387096774193, "no_speech_prob": 1.7603307469471474e-06}, {"id": 1239, "seek": 584752, "start": 5854.72, "end": 5858.56, "text": " We look at this we have three different", "tokens": [492, 574, 412, 341, 321, 362, 1045, 819], "temperature": 0.0, "avg_logprob": -0.3209572982788086, "compression_ratio": 1.3548387096774193, "no_speech_prob": 1.7603307469471474e-06}, {"id": 1240, "seek": 584752, "start": 5861.88, "end": 5865.52, "text": " Granularities of convolutional grid four by four two by two one by one", "tokens": [23554, 1040, 1088, 295, 45216, 304, 10748, 1451, 538, 1451, 732, 538, 732, 472, 538, 472], "temperature": 0.0, "avg_logprob": -0.3209572982788086, "compression_ratio": 1.3548387096774193, "no_speech_prob": 1.7603307469471474e-06}, {"id": 1241, "seek": 584752, "start": 5868.0, "end": 5870.0, "text": " The one by one", "tokens": [440, 472, 538, 472], "temperature": 0.0, "avg_logprob": -0.3209572982788086, "compression_ratio": 1.3548387096774193, "no_speech_prob": 1.7603307469471474e-06}, {"id": 1242, "seek": 584752, "start": 5870.320000000001, "end": 5872.320000000001, "text": " It's quite likely", "tokens": [467, 311, 1596, 3700], "temperature": 0.0, "avg_logprob": -0.3209572982788086, "compression_ratio": 1.3548387096774193, "no_speech_prob": 1.7603307469471474e-06}, {"id": 1243, "seek": 587232, "start": 5872.32, "end": 5878.58, "text": " To have a reasonable overlap with some object because most photos have some kind of main subject", "tokens": [1407, 362, 257, 10585, 19959, 365, 512, 2657, 570, 881, 5787, 362, 512, 733, 295, 2135, 3983], "temperature": 0.0, "avg_logprob": -0.2864102073337721, "compression_ratio": 1.789237668161435, "no_speech_prob": 6.339100309560308e-06}, {"id": 1244, "seek": 587232, "start": 5879.24, "end": 5885.0, "text": " Okay on the other hand in the four by four those 16 grid cells", "tokens": [1033, 322, 264, 661, 1011, 294, 264, 1451, 538, 1451, 729, 3165, 10748, 5438], "temperature": 0.0, "avg_logprob": -0.2864102073337721, "compression_ratio": 1.789237668161435, "no_speech_prob": 6.339100309560308e-06}, {"id": 1245, "seek": 587232, "start": 5885.5199999999995, "end": 5891.16, "text": " Are unlikely most of them are not going to have much of an overlap with anything like in this motorbike case", "tokens": [2014, 17518, 881, 295, 552, 366, 406, 516, 281, 362, 709, 295, 364, 19959, 365, 1340, 411, 294, 341, 5932, 30283, 1389], "temperature": 0.0, "avg_logprob": -0.2864102073337721, "compression_ratio": 1.789237668161435, "no_speech_prob": 6.339100309560308e-06}, {"id": 1246, "seek": 587232, "start": 5891.16, "end": 5894.599999999999, "text": " It's gonna be skies skies skies skies skies skies skies skies skies", "tokens": [467, 311, 799, 312, 25861, 25861, 25861, 25861, 25861, 25861, 25861, 25861, 25861], "temperature": 0.0, "avg_logprob": -0.2864102073337721, "compression_ratio": 1.789237668161435, "no_speech_prob": 6.339100309560308e-06}, {"id": 1247, "seek": 589460, "start": 5894.6, "end": 5901.0, "text": " Ground ground ground finally motorbike. Okay, so if somebody was to say to you like", "tokens": [28371, 2727, 2727, 2721, 5932, 30283, 13, 1033, 11, 370, 498, 2618, 390, 281, 584, 281, 291, 411], "temperature": 0.0, "avg_logprob": -0.24936149693742582, "compression_ratio": 1.4972677595628416, "no_speech_prob": 1.5534850490439567e-06}, {"id": 1248, "seek": 589460, "start": 5904.08, "end": 5905.4400000000005, "text": " You know", "tokens": [509, 458], "temperature": 0.0, "avg_logprob": -0.24936149693742582, "compression_ratio": 1.4972677595628416, "no_speech_prob": 1.5534850490439567e-06}, {"id": 1249, "seek": 589460, "start": 5905.4400000000005, "end": 5907.4400000000005, "text": " 20 buck bet", "tokens": [945, 14894, 778], "temperature": 0.0, "avg_logprob": -0.24936149693742582, "compression_ratio": 1.4972677595628416, "no_speech_prob": 1.5534850490439567e-06}, {"id": 1250, "seek": 589460, "start": 5907.92, "end": 5909.64, "text": " What do you reckon?", "tokens": [708, 360, 291, 29548, 30], "temperature": 0.0, "avg_logprob": -0.24936149693742582, "compression_ratio": 1.4972677595628416, "no_speech_prob": 1.5534850490439567e-06}, {"id": 1251, "seek": 589460, "start": 5909.64, "end": 5915.0, "text": " This little click is you know, and you're not sure you're gonna say", "tokens": [639, 707, 2052, 307, 291, 458, 11, 293, 291, 434, 406, 988, 291, 434, 799, 584], "temperature": 0.0, "avg_logprob": -0.24936149693742582, "compression_ratio": 1.4972677595628416, "no_speech_prob": 1.5534850490439567e-06}, {"id": 1252, "seek": 589460, "start": 5915.92, "end": 5918.56, "text": " Background because most of the time it is background", "tokens": [36904, 570, 881, 295, 264, 565, 309, 307, 3678], "temperature": 0.0, "avg_logprob": -0.24936149693742582, "compression_ratio": 1.4972677595628416, "no_speech_prob": 1.5534850490439567e-06}, {"id": 1253, "seek": 589460, "start": 5919.200000000001, "end": 5920.76, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.24936149693742582, "compression_ratio": 1.4972677595628416, "no_speech_prob": 1.5534850490439567e-06}, {"id": 1254, "seek": 589460, "start": 5920.76, "end": 5922.4400000000005, "text": " and so", "tokens": [293, 370], "temperature": 0.0, "avg_logprob": -0.24936149693742582, "compression_ratio": 1.4972677595628416, "no_speech_prob": 1.5534850490439567e-06}, {"id": 1255, "seek": 592244, "start": 5922.44, "end": 5924.799999999999, "text": " Here's the thing. Um, I", "tokens": [1692, 311, 264, 551, 13, 3301, 11, 286], "temperature": 0.0, "avg_logprob": -0.19290614657931857, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.3996093154419214e-05}, {"id": 1256, "seek": 592244, "start": 5928.839999999999, "end": 5935.919999999999, "text": " Understand why we have a four by four grid of receptive fields with one anchor box each to coarsely localize objects in the image", "tokens": [26093, 983, 321, 362, 257, 1451, 538, 1451, 10748, 295, 45838, 7909, 365, 472, 18487, 2424, 1184, 281, 598, 685, 736, 2654, 1125, 6565, 294, 264, 3256], "temperature": 0.0, "avg_logprob": -0.19290614657931857, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.3996093154419214e-05}, {"id": 1257, "seek": 592244, "start": 5936.48, "end": 5940.28, "text": " But I think I'm missing is why we need multiple receptive fields at different sizes", "tokens": [583, 286, 519, 286, 478, 5361, 307, 983, 321, 643, 3866, 45838, 7909, 412, 819, 11602], "temperature": 0.0, "avg_logprob": -0.19290614657931857, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.3996093154419214e-05}, {"id": 1258, "seek": 592244, "start": 5940.879999999999, "end": 5947.78, "text": " The first version already included 16 receptive fields each with a single anchor box associated with the addition", "tokens": [440, 700, 3037, 1217, 5556, 3165, 45838, 7909, 1184, 365, 257, 2167, 18487, 2424, 6615, 365, 264, 4500], "temperature": 0.0, "avg_logprob": -0.19290614657931857, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.3996093154419214e-05}, {"id": 1259, "seek": 592244, "start": 5947.78, "end": 5949.919999999999, "text": " There are now many more anchor boxes to consider", "tokens": [821, 366, 586, 867, 544, 18487, 9002, 281, 1949], "temperature": 0.0, "avg_logprob": -0.19290614657931857, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.3996093154419214e-05}, {"id": 1260, "seek": 594992, "start": 5949.92, "end": 5956.68, "text": " Is this because you can strain how much a receptive field could move or scale from its original size?", "tokens": [1119, 341, 570, 291, 393, 14249, 577, 709, 257, 45838, 2519, 727, 1286, 420, 4373, 490, 1080, 3380, 2744, 30], "temperature": 0.0, "avg_logprob": -0.1854145880972985, "compression_ratio": 1.5961538461538463, "no_speech_prob": 5.422150024969596e-06}, {"id": 1261, "seek": 594992, "start": 5956.92, "end": 5958.92, "text": " Or is there another reason?", "tokens": [1610, 307, 456, 1071, 1778, 30], "temperature": 0.0, "avg_logprob": -0.1854145880972985, "compression_ratio": 1.5961538461538463, "no_speech_prob": 5.422150024969596e-06}, {"id": 1262, "seek": 594992, "start": 5959.04, "end": 5964.16, "text": " It's kind of backwards. The reason I did the constraining was because I knew I was going to be adding more boxes later", "tokens": [467, 311, 733, 295, 12204, 13, 440, 1778, 286, 630, 264, 11525, 1760, 390, 570, 286, 2586, 286, 390, 516, 281, 312, 5127, 544, 9002, 1780], "temperature": 0.0, "avg_logprob": -0.1854145880972985, "compression_ratio": 1.5961538461538463, "no_speech_prob": 5.422150024969596e-06}, {"id": 1263, "seek": 594992, "start": 5965.4800000000005, "end": 5967.84, "text": " but really the reason is that", "tokens": [457, 534, 264, 1778, 307, 300], "temperature": 0.0, "avg_logprob": -0.1854145880972985, "compression_ratio": 1.5961538461538463, "no_speech_prob": 5.422150024969596e-06}, {"id": 1264, "seek": 594992, "start": 5968.52, "end": 5973.56, "text": " the jacquard overlap between one of those four by four grid cells and", "tokens": [264, 361, 326, 358, 515, 19959, 1296, 472, 295, 729, 1451, 538, 1451, 10748, 5438, 293], "temperature": 0.0, "avg_logprob": -0.1854145880972985, "compression_ratio": 1.5961538461538463, "no_speech_prob": 5.422150024969596e-06}, {"id": 1265, "seek": 597356, "start": 5973.56, "end": 5979.64, "text": " You know a picture a single object that takes up most of the image", "tokens": [509, 458, 257, 3036, 257, 2167, 2657, 300, 2516, 493, 881, 295, 264, 3256], "temperature": 0.0, "avg_logprob": -0.19963681420614554, "compression_ratio": 1.5478260869565217, "no_speech_prob": 8.800980140222237e-06}, {"id": 1266, "seek": 597356, "start": 5980.160000000001, "end": 5983.4800000000005, "text": " is never going to be point five because like the", "tokens": [307, 1128, 516, 281, 312, 935, 1732, 570, 411, 264], "temperature": 0.0, "avg_logprob": -0.19963681420614554, "compression_ratio": 1.5478260869565217, "no_speech_prob": 8.800980140222237e-06}, {"id": 1267, "seek": 597356, "start": 5984.200000000001, "end": 5991.26, "text": " Intersections much smaller than the Union because the one object is too big. So for this general idea to work where we're saying like", "tokens": [5751, 40329, 709, 4356, 813, 264, 8133, 570, 264, 472, 2657, 307, 886, 955, 13, 407, 337, 341, 2674, 1558, 281, 589, 689, 321, 434, 1566, 411], "temperature": 0.0, "avg_logprob": -0.19963681420614554, "compression_ratio": 1.5478260869565217, "no_speech_prob": 8.800980140222237e-06}, {"id": 1268, "seek": 597356, "start": 5991.96, "end": 5997.64, "text": " You're responsible for something that you've got a better than 50% overlap with we need", "tokens": [509, 434, 6250, 337, 746, 300, 291, 600, 658, 257, 1101, 813, 2625, 4, 19959, 365, 321, 643], "temperature": 0.0, "avg_logprob": -0.19963681420614554, "compression_ratio": 1.5478260869565217, "no_speech_prob": 8.800980140222237e-06}, {"id": 1269, "seek": 597356, "start": 5998.4800000000005, "end": 6000.400000000001, "text": " anchor boxes", "tokens": [18487, 9002], "temperature": 0.0, "avg_logprob": -0.19963681420614554, "compression_ratio": 1.5478260869565217, "no_speech_prob": 8.800980140222237e-06}, {"id": 1270, "seek": 597356, "start": 6000.400000000001, "end": 6002.080000000001, "text": " which", "tokens": [597], "temperature": 0.0, "avg_logprob": -0.19963681420614554, "compression_ratio": 1.5478260869565217, "no_speech_prob": 8.800980140222237e-06}, {"id": 1271, "seek": 600208, "start": 6002.08, "end": 6005.92, "text": " Which will on a regular basis have a 50% or higher overlap", "tokens": [3013, 486, 322, 257, 3890, 5143, 362, 257, 2625, 4, 420, 2946, 19959], "temperature": 0.0, "avg_logprob": -0.1763261597732018, "compression_ratio": 1.7300884955752212, "no_speech_prob": 5.954939297225792e-06}, {"id": 1272, "seek": 600208, "start": 6005.92, "end": 6010.2, "text": " Which means we need to have a variety of sizes and shapes and scales", "tokens": [3013, 1355, 321, 643, 281, 362, 257, 5673, 295, 11602, 293, 10854, 293, 17408], "temperature": 0.0, "avg_logprob": -0.1763261597732018, "compression_ratio": 1.7300884955752212, "no_speech_prob": 5.954939297225792e-06}, {"id": 1273, "seek": 600208, "start": 6014.2, "end": 6016.68, "text": " Yeah, so this is this this this all happens", "tokens": [865, 11, 370, 341, 307, 341, 341, 341, 439, 2314], "temperature": 0.0, "avg_logprob": -0.1763261597732018, "compression_ratio": 1.7300884955752212, "no_speech_prob": 5.954939297225792e-06}, {"id": 1274, "seek": 600208, "start": 6017.44, "end": 6019.44, "text": " This all happens in the loss function", "tokens": [639, 439, 2314, 294, 264, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.1763261597732018, "compression_ratio": 1.7300884955752212, "no_speech_prob": 5.954939297225792e-06}, {"id": 1275, "seek": 600208, "start": 6019.44, "end": 6026.42, "text": " You know basically the vast majority of the interesting stuff in all of the object detection stuff is the loss function", "tokens": [509, 458, 1936, 264, 8369, 6286, 295, 264, 1880, 1507, 294, 439, 295, 264, 2657, 17784, 1507, 307, 264, 4470, 2445], "temperature": 0.0, "avg_logprob": -0.1763261597732018, "compression_ratio": 1.7300884955752212, "no_speech_prob": 5.954939297225792e-06}, {"id": 1276, "seek": 602642, "start": 6026.42, "end": 6031.9, "text": " Because there is only three things loss function architecture data", "tokens": [1436, 456, 307, 787, 1045, 721, 4470, 2445, 9482, 1412], "temperature": 0.0, "avg_logprob": -0.3170308663811482, "compression_ratio": 1.4871794871794872, "no_speech_prob": 9.817873433348723e-06}, {"id": 1277, "seek": 602642, "start": 6037.22, "end": 6040.82, "text": " So the this is the focal loss paper", "tokens": [407, 264, 341, 307, 264, 26592, 4470, 3035], "temperature": 0.0, "avg_logprob": -0.3170308663811482, "compression_ratio": 1.4871794871794872, "no_speech_prob": 9.817873433348723e-06}, {"id": 1278, "seek": 602642, "start": 6043.38, "end": 6046.84, "text": " Focal loss for dense object detection from August 2017", "tokens": [479, 36483, 4470, 337, 18011, 2657, 17784, 490, 6897, 6591], "temperature": 0.0, "avg_logprob": -0.3170308663811482, "compression_ratio": 1.4871794871794872, "no_speech_prob": 9.817873433348723e-06}, {"id": 1279, "seek": 602642, "start": 6047.22, "end": 6052.96, "text": " Here's Ross Gershig still doing this stuff timing her you might recognize as being the the resnet guy", "tokens": [1692, 311, 16140, 460, 433, 71, 328, 920, 884, 341, 1507, 10822, 720, 291, 1062, 5521, 382, 885, 264, 264, 725, 7129, 2146], "temperature": 0.0, "avg_logprob": -0.3170308663811482, "compression_ratio": 1.4871794871794872, "no_speech_prob": 9.817873433348723e-06}, {"id": 1280, "seek": 605296, "start": 6052.96, "end": 6056.24, "text": " It's a bit of an all-star cast here and", "tokens": [467, 311, 257, 857, 295, 364, 439, 12, 9710, 4193, 510, 293], "temperature": 0.0, "avg_logprob": -0.27985007853447635, "compression_ratio": 1.6145251396648044, "no_speech_prob": 3.6688199998025084e-06}, {"id": 1281, "seek": 605296, "start": 6057.04, "end": 6059.4800000000005, "text": " This the key thing is this very first picture", "tokens": [639, 264, 2141, 551, 307, 341, 588, 700, 3036], "temperature": 0.0, "avg_logprob": -0.27985007853447635, "compression_ratio": 1.6145251396648044, "no_speech_prob": 3.6688199998025084e-06}, {"id": 1282, "seek": 605296, "start": 6060.2, "end": 6062.2, "text": " the blue line is a", "tokens": [264, 3344, 1622, 307, 257], "temperature": 0.0, "avg_logprob": -0.27985007853447635, "compression_ratio": 1.6145251396648044, "no_speech_prob": 3.6688199998025084e-06}, {"id": 1283, "seek": 605296, "start": 6063.12, "end": 6065.12, "text": " picture of", "tokens": [3036, 295], "temperature": 0.0, "avg_logprob": -0.27985007853447635, "compression_ratio": 1.6145251396648044, "no_speech_prob": 3.6688199998025084e-06}, {"id": 1284, "seek": 605296, "start": 6065.72, "end": 6067.92, "text": " binary cross entropy loss", "tokens": [17434, 3278, 30867, 4470], "temperature": 0.0, "avg_logprob": -0.27985007853447635, "compression_ratio": 1.6145251396648044, "no_speech_prob": 3.6688199998025084e-06}, {"id": 1285, "seek": 605296, "start": 6068.96, "end": 6074.28, "text": " The x-axis is what is the probability or what is the activation?", "tokens": [440, 2031, 12, 24633, 307, 437, 307, 264, 8482, 420, 437, 307, 264, 24433, 30], "temperature": 0.0, "avg_logprob": -0.27985007853447635, "compression_ratio": 1.6145251396648044, "no_speech_prob": 3.6688199998025084e-06}, {"id": 1286, "seek": 607428, "start": 6074.28, "end": 6082.44, "text": " What is the probability of the the ground truth class so it's actually a motorbike I", "tokens": [708, 307, 264, 8482, 295, 264, 264, 2727, 3494, 1508, 370, 309, 311, 767, 257, 5932, 30283, 286], "temperature": 0.0, "avg_logprob": -0.19484127044677735, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.1300553524051793e-05}, {"id": 1287, "seek": 607428, "start": 6083.36, "end": 6090.8, "text": " Said with point six chance. It's a motorbike or it's actually not a motorbike and I said we pop point six chance", "tokens": [26490, 365, 935, 2309, 2931, 13, 467, 311, 257, 5932, 30283, 420, 309, 311, 767, 406, 257, 5932, 30283, 293, 286, 848, 321, 1665, 935, 2309, 2931], "temperature": 0.0, "avg_logprob": -0.19484127044677735, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.1300553524051793e-05}, {"id": 1288, "seek": 607428, "start": 6092.16, "end": 6099.8, "text": " So this blue line represents the level of the value of cross entropy loss so you can draw this in Excel or", "tokens": [407, 341, 3344, 1622, 8855, 264, 1496, 295, 264, 2158, 295, 3278, 30867, 4470, 370, 291, 393, 2642, 341, 294, 19060, 420], "temperature": 0.0, "avg_logprob": -0.19484127044677735, "compression_ratio": 1.6703296703296704, "no_speech_prob": 1.1300553524051793e-05}, {"id": 1289, "seek": 609980, "start": 6099.8, "end": 6105.16, "text": " Python or whatever this is just a simple plot of cross entropy loss", "tokens": [15329, 420, 2035, 341, 307, 445, 257, 2199, 7542, 295, 3278, 30867, 4470], "temperature": 0.0, "avg_logprob": -0.2025328106350369, "compression_ratio": 1.7578947368421052, "no_speech_prob": 4.785054898093222e-06}, {"id": 1290, "seek": 609980, "start": 6106.16, "end": 6108.16, "text": " so the point is if", "tokens": [370, 264, 935, 307, 498], "temperature": 0.0, "avg_logprob": -0.2025328106350369, "compression_ratio": 1.7578947368421052, "no_speech_prob": 4.785054898093222e-06}, {"id": 1291, "seek": 609980, "start": 6108.76, "end": 6110.76, "text": " the answer is", "tokens": [264, 1867, 307], "temperature": 0.0, "avg_logprob": -0.2025328106350369, "compression_ratio": 1.7578947368421052, "no_speech_prob": 4.785054898093222e-06}, {"id": 1292, "seek": 609980, "start": 6110.88, "end": 6114.76, "text": " Because remember we're doing binary cross entropy loss if the answer is not a motorbike and", "tokens": [1436, 1604, 321, 434, 884, 17434, 3278, 30867, 4470, 498, 264, 1867, 307, 406, 257, 5932, 30283, 293], "temperature": 0.0, "avg_logprob": -0.2025328106350369, "compression_ratio": 1.7578947368421052, "no_speech_prob": 4.785054898093222e-06}, {"id": 1293, "seek": 609980, "start": 6115.400000000001, "end": 6121.04, "text": " I said yeah, I think it's not a motorbike. I'm point six sure it's not a motorbike", "tokens": [286, 848, 1338, 11, 286, 519, 309, 311, 406, 257, 5932, 30283, 13, 286, 478, 935, 2309, 988, 309, 311, 406, 257, 5932, 30283], "temperature": 0.0, "avg_logprob": -0.2025328106350369, "compression_ratio": 1.7578947368421052, "no_speech_prob": 4.785054898093222e-06}, {"id": 1294, "seek": 609980, "start": 6122.2, "end": 6126.400000000001, "text": " This blue line is still at like a loss of about point five", "tokens": [639, 3344, 1622, 307, 920, 412, 411, 257, 4470, 295, 466, 935, 1732], "temperature": 0.0, "avg_logprob": -0.2025328106350369, "compression_ratio": 1.7578947368421052, "no_speech_prob": 4.785054898093222e-06}, {"id": 1295, "seek": 612640, "start": 6126.4, "end": 6130.92, "text": " I it's it's it's it's there's a lot of it's still pretty bad", "tokens": [286, 309, 311, 309, 311, 309, 311, 309, 311, 456, 311, 257, 688, 295, 309, 311, 920, 1238, 1578], "temperature": 0.0, "avg_logprob": -0.17951433475200945, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.1125497621833347e-05}, {"id": 1296, "seek": 612640, "start": 6131.48, "end": 6136.879999999999, "text": " Right so I actually have to keep getting more and more confident that it's not a motorbike", "tokens": [1779, 370, 286, 767, 362, 281, 1066, 1242, 544, 293, 544, 6679, 300, 309, 311, 406, 257, 5932, 30283], "temperature": 0.0, "avg_logprob": -0.17951433475200945, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.1125497621833347e-05}, {"id": 1297, "seek": 612640, "start": 6137.08, "end": 6143.4, "text": " So if I want to get my loss down then for all of these things which are actually background", "tokens": [407, 498, 286, 528, 281, 483, 452, 4470, 760, 550, 337, 439, 295, 613, 721, 597, 366, 767, 3678], "temperature": 0.0, "avg_logprob": -0.17951433475200945, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.1125497621833347e-05}, {"id": 1298, "seek": 612640, "start": 6143.4, "end": 6146.879999999999, "text": " I have to be saying like I am sure that's background", "tokens": [286, 362, 281, 312, 1566, 411, 286, 669, 988, 300, 311, 3678], "temperature": 0.0, "avg_logprob": -0.17951433475200945, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.1125497621833347e-05}, {"id": 1299, "seek": 612640, "start": 6146.92, "end": 6151.879999999999, "text": " You know or I'm sure it's not a motorbike or a bus or a person or a dining room table", "tokens": [509, 458, 420, 286, 478, 988, 309, 311, 406, 257, 5932, 30283, 420, 257, 1255, 420, 257, 954, 420, 257, 17874, 1808, 3199], "temperature": 0.0, "avg_logprob": -0.17951433475200945, "compression_ratio": 1.7767441860465116, "no_speech_prob": 1.1125497621833347e-05}, {"id": 1300, "seek": 615188, "start": 6151.88, "end": 6157.4800000000005, "text": " Because if I don't say I'm sure it's not any of these things then I still get", "tokens": [1436, 498, 286, 500, 380, 584, 286, 478, 988, 309, 311, 406, 604, 295, 613, 721, 550, 286, 920, 483], "temperature": 0.0, "avg_logprob": -0.15165958171937524, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.495165740081575e-06}, {"id": 1301, "seek": 615188, "start": 6158.2, "end": 6159.84, "text": " loss", "tokens": [4470], "temperature": 0.0, "avg_logprob": -0.15165958171937524, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.495165740081575e-06}, {"id": 1302, "seek": 615188, "start": 6159.84, "end": 6161.84, "text": " so that's why", "tokens": [370, 300, 311, 983], "temperature": 0.0, "avg_logprob": -0.15165958171937524, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.495165740081575e-06}, {"id": 1303, "seek": 615188, "start": 6163.96, "end": 6170.64, "text": " This doesn't work right this doesn't work because even when it gets to here, and it wants to say I", "tokens": [639, 1177, 380, 589, 558, 341, 1177, 380, 589, 570, 754, 562, 309, 2170, 281, 510, 11, 293, 309, 2738, 281, 584, 286], "temperature": 0.0, "avg_logprob": -0.15165958171937524, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.495165740081575e-06}, {"id": 1304, "seek": 615188, "start": 6171.76, "end": 6173.76, "text": " Think it's a motorbike", "tokens": [6557, 309, 311, 257, 5932, 30283], "temperature": 0.0, "avg_logprob": -0.15165958171937524, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.495165740081575e-06}, {"id": 1305, "seek": 615188, "start": 6173.76, "end": 6177.64, "text": " There's no payoff for it to say so because if it's wrong", "tokens": [821, 311, 572, 46547, 337, 309, 281, 584, 370, 570, 498, 309, 311, 2085], "temperature": 0.0, "avg_logprob": -0.15165958171937524, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.495165740081575e-06}, {"id": 1306, "seek": 617764, "start": 6177.64, "end": 6182.280000000001, "text": " Right and it gets killed and the vast majority of the time", "tokens": [1779, 293, 309, 2170, 4652, 293, 264, 8369, 6286, 295, 264, 565], "temperature": 0.0, "avg_logprob": -0.18828920957421055, "compression_ratio": 1.9586776859504131, "no_speech_prob": 2.1112122340127826e-05}, {"id": 1307, "seek": 617764, "start": 6182.88, "end": 6188.200000000001, "text": " It's not anything the vast majority of times background and even if it's not background", "tokens": [467, 311, 406, 1340, 264, 8369, 6286, 295, 1413, 3678, 293, 754, 498, 309, 311, 406, 3678], "temperature": 0.0, "avg_logprob": -0.18828920957421055, "compression_ratio": 1.9586776859504131, "no_speech_prob": 2.1112122340127826e-05}, {"id": 1308, "seek": 617764, "start": 6188.200000000001, "end": 6191.76, "text": " It's not enough just to say it's not background. You've got to say which of the 20 things it is", "tokens": [467, 311, 406, 1547, 445, 281, 584, 309, 311, 406, 3678, 13, 509, 600, 658, 281, 584, 597, 295, 264, 945, 721, 309, 307], "temperature": 0.0, "avg_logprob": -0.18828920957421055, "compression_ratio": 1.9586776859504131, "no_speech_prob": 2.1112122340127826e-05}, {"id": 1309, "seek": 617764, "start": 6192.240000000001, "end": 6194.240000000001, "text": " Right so for the really big things", "tokens": [1779, 370, 337, 264, 534, 955, 721], "temperature": 0.0, "avg_logprob": -0.18828920957421055, "compression_ratio": 1.9586776859504131, "no_speech_prob": 2.1112122340127826e-05}, {"id": 1310, "seek": 617764, "start": 6194.72, "end": 6197.12, "text": " It's fine because that's the one by one grid", "tokens": [467, 311, 2489, 570, 300, 311, 264, 472, 538, 472, 10748], "temperature": 0.0, "avg_logprob": -0.18828920957421055, "compression_ratio": 1.9586776859504131, "no_speech_prob": 2.1112122340127826e-05}, {"id": 1311, "seek": 617764, "start": 6197.4400000000005, "end": 6204.6, "text": " You know so it's it generally is a thing and you just have to figure out which thing it is or else for these small ones", "tokens": [509, 458, 370, 309, 311, 309, 5101, 307, 257, 551, 293, 291, 445, 362, 281, 2573, 484, 597, 551, 309, 307, 420, 1646, 337, 613, 1359, 2306], "temperature": 0.0, "avg_logprob": -0.18828920957421055, "compression_ratio": 1.9586776859504131, "no_speech_prob": 2.1112122340127826e-05}, {"id": 1312, "seek": 620460, "start": 6204.6, "end": 6210.360000000001, "text": " And generally it's not anything so generally small ones. We just prefer to be like I", "tokens": [400, 5101, 309, 311, 406, 1340, 370, 5101, 1359, 2306, 13, 492, 445, 4382, 281, 312, 411, 286], "temperature": 0.0, "avg_logprob": -0.2357898756515148, "compression_ratio": 1.574468085106383, "no_speech_prob": 5.255355517874705e-06}, {"id": 1313, "seek": 620460, "start": 6211.360000000001, "end": 6213.6, "text": " Got nothing to say no comment", "tokens": [5803, 1825, 281, 584, 572, 2871], "temperature": 0.0, "avg_logprob": -0.2357898756515148, "compression_ratio": 1.574468085106383, "no_speech_prob": 5.255355517874705e-06}, {"id": 1314, "seek": 620460, "start": 6214.56, "end": 6216.120000000001, "text": " right", "tokens": [558], "temperature": 0.0, "avg_logprob": -0.2357898756515148, "compression_ratio": 1.574468085106383, "no_speech_prob": 5.255355517874705e-06}, {"id": 1315, "seek": 620460, "start": 6216.120000000001, "end": 6219.04, "text": " so that's why this is empty and", "tokens": [370, 300, 311, 983, 341, 307, 6707, 293], "temperature": 0.0, "avg_logprob": -0.2357898756515148, "compression_ratio": 1.574468085106383, "no_speech_prob": 5.255355517874705e-06}, {"id": 1316, "seek": 620460, "start": 6219.6, "end": 6221.8, "text": " That's why even when we", "tokens": [663, 311, 983, 754, 562, 321], "temperature": 0.0, "avg_logprob": -0.2357898756515148, "compression_ratio": 1.574468085106383, "no_speech_prob": 5.255355517874705e-06}, {"id": 1317, "seek": 620460, "start": 6222.8, "end": 6224.8, "text": " Do have a bus", "tokens": [1144, 362, 257, 1255], "temperature": 0.0, "avg_logprob": -0.2357898756515148, "compression_ratio": 1.574468085106383, "no_speech_prob": 5.255355517874705e-06}, {"id": 1318, "seek": 620460, "start": 6224.88, "end": 6227.280000000001, "text": " Right it's using a really big grid cell", "tokens": [1779, 309, 311, 1228, 257, 534, 955, 10748, 2815], "temperature": 0.0, "avg_logprob": -0.2357898756515148, "compression_ratio": 1.574468085106383, "no_speech_prob": 5.255355517874705e-06}, {"id": 1319, "seek": 620460, "start": 6227.84, "end": 6231.52, "text": " to say it's a bus because these are the only ones where it's like", "tokens": [281, 584, 309, 311, 257, 1255, 570, 613, 366, 264, 787, 2306, 689, 309, 311, 411], "temperature": 0.0, "avg_logprob": -0.2357898756515148, "compression_ratio": 1.574468085106383, "no_speech_prob": 5.255355517874705e-06}, {"id": 1320, "seek": 623152, "start": 6231.52, "end": 6236.52, "text": " Confident enough to make a call that something right because the small grid cells", "tokens": [11701, 1078, 1547, 281, 652, 257, 818, 300, 746, 558, 570, 264, 1359, 10748, 5438], "temperature": 0.0, "avg_logprob": -0.16445618090422257, "compression_ratio": 1.702127659574468, "no_speech_prob": 1.7880565792438574e-06}, {"id": 1321, "seek": 623152, "start": 6237.120000000001, "end": 6239.120000000001, "text": " It very rarely is something", "tokens": [467, 588, 13752, 307, 746], "temperature": 0.0, "avg_logprob": -0.16445618090422257, "compression_ratio": 1.702127659574468, "no_speech_prob": 1.7880565792438574e-06}, {"id": 1322, "seek": 623152, "start": 6239.8, "end": 6245.400000000001, "text": " So the trick is to try and find a different loss function instead of binary cross entropy loss", "tokens": [407, 264, 4282, 307, 281, 853, 293, 915, 257, 819, 4470, 2445, 2602, 295, 17434, 3278, 30867, 4470], "temperature": 0.0, "avg_logprob": -0.16445618090422257, "compression_ratio": 1.702127659574468, "no_speech_prob": 1.7880565792438574e-06}, {"id": 1323, "seek": 623152, "start": 6245.400000000001, "end": 6249.280000000001, "text": " It doesn't look like the blue line, but looks more like the green or purple line", "tokens": [467, 1177, 380, 574, 411, 264, 3344, 1622, 11, 457, 1542, 544, 411, 264, 3092, 420, 9656, 1622], "temperature": 0.0, "avg_logprob": -0.16445618090422257, "compression_ratio": 1.702127659574468, "no_speech_prob": 1.7880565792438574e-06}, {"id": 1324, "seek": 623152, "start": 6250.120000000001, "end": 6255.92, "text": " And they actually end up suggesting the purple line and so it turns out this is cross entropy loss", "tokens": [400, 436, 767, 917, 493, 18094, 264, 9656, 1622, 293, 370, 309, 4523, 484, 341, 307, 3278, 30867, 4470], "temperature": 0.0, "avg_logprob": -0.16445618090422257, "compression_ratio": 1.702127659574468, "no_speech_prob": 1.7880565792438574e-06}, {"id": 1325, "seek": 623152, "start": 6256.88, "end": 6258.88, "text": " negative log PT", "tokens": [3671, 3565, 35460], "temperature": 0.0, "avg_logprob": -0.16445618090422257, "compression_ratio": 1.702127659574468, "no_speech_prob": 1.7880565792438574e-06}, {"id": 1326, "seek": 625888, "start": 6258.88, "end": 6266.2, "text": " Focal loss is simply one minus PT to the gamma where gamma is some", "tokens": [479, 36483, 4470, 307, 2935, 472, 3175, 35460, 281, 264, 15546, 689, 15546, 307, 512], "temperature": 0.0, "avg_logprob": -0.2727698771158854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 2.2959111447562464e-06}, {"id": 1327, "seek": 625888, "start": 6267.76, "end": 6271.04, "text": " Parameter right and they recommend using two times", "tokens": [34882, 2398, 558, 293, 436, 2748, 1228, 732, 1413], "temperature": 0.0, "avg_logprob": -0.2727698771158854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 2.2959111447562464e-06}, {"id": 1328, "seek": 625888, "start": 6272.12, "end": 6274.12, "text": " the cross entropy loss", "tokens": [264, 3278, 30867, 4470], "temperature": 0.0, "avg_logprob": -0.2727698771158854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 2.2959111447562464e-06}, {"id": 1329, "seek": 625888, "start": 6274.4800000000005, "end": 6278.08, "text": " That's it's literally just a scaling of it", "tokens": [663, 311, 309, 311, 3736, 445, 257, 21589, 295, 309], "temperature": 0.0, "avg_logprob": -0.2727698771158854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 2.2959111447562464e-06}, {"id": 1330, "seek": 625888, "start": 6278.08, "end": 6284.12, "text": " And so that takes you to if you use gamma equals to that takes you to this purple line. So now if we say", "tokens": [400, 370, 300, 2516, 291, 281, 498, 291, 764, 15546, 6915, 281, 300, 2516, 291, 281, 341, 9656, 1622, 13, 407, 586, 498, 321, 584], "temperature": 0.0, "avg_logprob": -0.2727698771158854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 2.2959111447562464e-06}, {"id": 1331, "seek": 628412, "start": 6284.12, "end": 6290.599999999999, "text": " Now I'm point six sure that it's not a motorbike then the loss function is like good for you", "tokens": [823, 286, 478, 935, 2309, 988, 300, 309, 311, 406, 257, 5932, 30283, 550, 264, 4470, 2445, 307, 411, 665, 337, 291], "temperature": 0.0, "avg_logprob": -0.2601231555549466, "compression_ratio": 1.6779661016949152, "no_speech_prob": 3.966969870816683e-06}, {"id": 1332, "seek": 628412, "start": 6291.92, "end": 6293.92, "text": " No worries, okay", "tokens": [883, 16340, 11, 1392], "temperature": 0.0, "avg_logprob": -0.2601231555549466, "compression_ratio": 1.6779661016949152, "no_speech_prob": 3.966969870816683e-06}, {"id": 1333, "seek": 628412, "start": 6294.48, "end": 6295.84, "text": " So that's what we want to do", "tokens": [407, 300, 311, 437, 321, 528, 281, 360], "temperature": 0.0, "avg_logprob": -0.2601231555549466, "compression_ratio": 1.6779661016949152, "no_speech_prob": 3.966969870816683e-06}, {"id": 1334, "seek": 628412, "start": 6295.84, "end": 6303.0, "text": " We want to replace cross entropy loss with focal loss and I mentioned a couple of things about this fantastic paper", "tokens": [492, 528, 281, 7406, 3278, 30867, 4470, 365, 26592, 4470, 293, 286, 2835, 257, 1916, 295, 721, 466, 341, 5456, 3035], "temperature": 0.0, "avg_logprob": -0.2601231555549466, "compression_ratio": 1.6779661016949152, "no_speech_prob": 3.966969870816683e-06}, {"id": 1335, "seek": 628412, "start": 6303.4, "end": 6305.4, "text": " the first is like", "tokens": [264, 700, 307, 411], "temperature": 0.0, "avg_logprob": -0.2601231555549466, "compression_ratio": 1.6779661016949152, "no_speech_prob": 3.966969870816683e-06}, {"id": 1336, "seek": 628412, "start": 6305.64, "end": 6312.76, "text": " The actually come to the actual contribution of this paper is to add one minus P to the gamma to the start of this equation", "tokens": [440, 767, 808, 281, 264, 3539, 13150, 295, 341, 3035, 307, 281, 909, 472, 3175, 430, 281, 264, 15546, 281, 264, 722, 295, 341, 5367], "temperature": 0.0, "avg_logprob": -0.2601231555549466, "compression_ratio": 1.6779661016949152, "no_speech_prob": 3.966969870816683e-06}, {"id": 1337, "seek": 631276, "start": 6312.76, "end": 6319.72, "text": " Which sounds like nothing right? But actually people have been trying to figure out this damn problem for years", "tokens": [3013, 3263, 411, 1825, 558, 30, 583, 767, 561, 362, 668, 1382, 281, 2573, 484, 341, 8151, 1154, 337, 924], "temperature": 0.0, "avg_logprob": -0.2222646282565209, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5008351915166713e-06}, {"id": 1338, "seek": 631276, "start": 6319.72, "end": 6323.84, "text": " And I'm not even sure that realized it's a problem. There's just this assumption that", "tokens": [400, 286, 478, 406, 754, 988, 300, 5334, 309, 311, 257, 1154, 13, 821, 311, 445, 341, 15302, 300], "temperature": 0.0, "avg_logprob": -0.2222646282565209, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5008351915166713e-06}, {"id": 1339, "seek": 631276, "start": 6325.320000000001, "end": 6330.8, "text": " You know object detection is really hard and you have to do all of these complex data augmentations", "tokens": [509, 458, 2657, 17784, 307, 534, 1152, 293, 291, 362, 281, 360, 439, 295, 613, 3997, 1412, 29919, 763], "temperature": 0.0, "avg_logprob": -0.2222646282565209, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5008351915166713e-06}, {"id": 1340, "seek": 631276, "start": 6331.88, "end": 6338.8, "text": " And have negative mining and blah blah blah to get the damn thing to work. So a it's like this recognition of like", "tokens": [400, 362, 3671, 15512, 293, 12288, 12288, 12288, 281, 483, 264, 8151, 551, 281, 589, 13, 407, 257, 309, 311, 411, 341, 11150, 295, 411], "temperature": 0.0, "avg_logprob": -0.2222646282565209, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5008351915166713e-06}, {"id": 1341, "seek": 633880, "start": 6338.8, "end": 6346.320000000001, "text": " But why are we doing all those things and then this realization of like oh if I do that it goes away", "tokens": [583, 983, 366, 321, 884, 439, 729, 721, 293, 550, 341, 25138, 295, 411, 1954, 498, 286, 360, 300, 309, 1709, 1314], "temperature": 0.0, "avg_logprob": -0.23103354149258015, "compression_ratio": 1.6, "no_speech_prob": 1.406391220371006e-05}, {"id": 1342, "seek": 633880, "start": 6347.4800000000005, "end": 6349.4800000000005, "text": " It's fixed. All right, so", "tokens": [467, 311, 6806, 13, 1057, 558, 11, 370], "temperature": 0.0, "avg_logprob": -0.23103354149258015, "compression_ratio": 1.6, "no_speech_prob": 1.406391220371006e-05}, {"id": 1343, "seek": 633880, "start": 6350.6, "end": 6353.92, "text": " When you come across a paper like this, which is like game-changing", "tokens": [1133, 291, 808, 2108, 257, 3035, 411, 341, 11, 597, 307, 411, 1216, 12, 27123], "temperature": 0.0, "avg_logprob": -0.23103354149258015, "compression_ratio": 1.6, "no_speech_prob": 1.406391220371006e-05}, {"id": 1344, "seek": 633880, "start": 6354.8, "end": 6358.8, "text": " You shouldn't assume that you're going to have to write a hundred thousand lines of code", "tokens": [509, 4659, 380, 6552, 300, 291, 434, 516, 281, 362, 281, 2464, 257, 3262, 4714, 3876, 295, 3089], "temperature": 0.0, "avg_logprob": -0.23103354149258015, "compression_ratio": 1.6, "no_speech_prob": 1.406391220371006e-05}, {"id": 1345, "seek": 633880, "start": 6358.96, "end": 6365.6, "text": " It very often is one line of code or the change of a single constant or adding log to a single place", "tokens": [467, 588, 2049, 307, 472, 1622, 295, 3089, 420, 264, 1319, 295, 257, 2167, 5754, 420, 5127, 3565, 281, 257, 2167, 1081], "temperature": 0.0, "avg_logprob": -0.23103354149258015, "compression_ratio": 1.6, "no_speech_prob": 1.406391220371006e-05}, {"id": 1346, "seek": 636560, "start": 6365.6, "end": 6367.4400000000005, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.19494440222299228, "compression_ratio": 1.6277056277056277, "no_speech_prob": 1.0953014680126216e-05}, {"id": 1347, "seek": 636560, "start": 6367.4400000000005, "end": 6372.18, "text": " So let's go down to the bit where it all happens", "tokens": [407, 718, 311, 352, 760, 281, 264, 857, 689, 309, 439, 2314], "temperature": 0.0, "avg_logprob": -0.19494440222299228, "compression_ratio": 1.6277056277056277, "no_speech_prob": 1.0953014680126216e-05}, {"id": 1348, "seek": 636560, "start": 6372.68, "end": 6378.04, "text": " Where they describe the loss and I just wanted to point out a couple of terrific things about this paper", "tokens": [2305, 436, 6786, 264, 4470, 293, 286, 445, 1415, 281, 935, 484, 257, 1916, 295, 20899, 721, 466, 341, 3035], "temperature": 0.0, "avg_logprob": -0.19494440222299228, "compression_ratio": 1.6277056277056277, "no_speech_prob": 1.0953014680126216e-05}, {"id": 1349, "seek": 636560, "start": 6378.4400000000005, "end": 6381.04, "text": " the first is here is their definition of", "tokens": [264, 700, 307, 510, 307, 641, 7123, 295], "temperature": 0.0, "avg_logprob": -0.19494440222299228, "compression_ratio": 1.6277056277056277, "no_speech_prob": 1.0953014680126216e-05}, {"id": 1350, "seek": 636560, "start": 6381.56, "end": 6386.4400000000005, "text": " Cross entropy and if you're not able to write cross entropy on a piece of paper right now", "tokens": [11623, 30867, 293, 498, 291, 434, 406, 1075, 281, 2464, 3278, 30867, 322, 257, 2522, 295, 3035, 558, 586], "temperature": 0.0, "avg_logprob": -0.19494440222299228, "compression_ratio": 1.6277056277056277, "no_speech_prob": 1.0953014680126216e-05}, {"id": 1351, "seek": 636560, "start": 6386.96, "end": 6391.360000000001, "text": " Then you need to go back and study it because we're going to be assuming that you know", "tokens": [1396, 291, 643, 281, 352, 646, 293, 2979, 309, 570, 321, 434, 516, 281, 312, 11926, 300, 291, 458], "temperature": 0.0, "avg_logprob": -0.19494440222299228, "compression_ratio": 1.6277056277056277, "no_speech_prob": 1.0953014680126216e-05}, {"id": 1352, "seek": 639136, "start": 6391.36, "end": 6399.36, "text": " What it is what it means why it's that what the shape of it looks like cross entropy appears everywhere binary cross entropy and", "tokens": [708, 309, 307, 437, 309, 1355, 983, 309, 311, 300, 437, 264, 3909, 295, 309, 1542, 411, 3278, 30867, 7038, 5315, 17434, 3278, 30867, 293], "temperature": 0.0, "avg_logprob": -0.2916278076171875, "compression_ratio": 1.8048780487804879, "no_speech_prob": 6.048863724572584e-06}, {"id": 1353, "seek": 639136, "start": 6399.88, "end": 6402.799999999999, "text": " Categorical cross entropy and the softmax that", "tokens": [383, 2968, 284, 804, 3278, 30867, 293, 264, 2787, 41167, 300], "temperature": 0.0, "avg_logprob": -0.2916278076171875, "compression_ratio": 1.8048780487804879, "no_speech_prob": 6.048863724572584e-06}, {"id": 1354, "seek": 639136, "start": 6406.44, "end": 6410.24, "text": " Most people most of the time will see cross entropy written as", "tokens": [4534, 561, 881, 295, 264, 565, 486, 536, 3278, 30867, 3720, 382], "temperature": 0.0, "avg_logprob": -0.2916278076171875, "compression_ratio": 1.8048780487804879, "no_speech_prob": 6.048863724572584e-06}, {"id": 1355, "seek": 639136, "start": 6411.16, "end": 6414.0, "text": " like an indicator on y times", "tokens": [411, 364, 16961, 322, 288, 1413], "temperature": 0.0, "avg_logprob": -0.2916278076171875, "compression_ratio": 1.8048780487804879, "no_speech_prob": 6.048863724572584e-06}, {"id": 1356, "seek": 639136, "start": 6414.719999999999, "end": 6416.24, "text": " log P", "tokens": [3565, 430], "temperature": 0.0, "avg_logprob": -0.2916278076171875, "compression_ratio": 1.8048780487804879, "no_speech_prob": 6.048863724572584e-06}, {"id": 1357, "seek": 639136, "start": 6416.24, "end": 6418.5599999999995, "text": " plus an indicator on y", "tokens": [1804, 364, 16961, 322, 288], "temperature": 0.0, "avg_logprob": -0.2916278076171875, "compression_ratio": 1.8048780487804879, "no_speech_prob": 6.048863724572584e-06}, {"id": 1358, "seek": 641856, "start": 6418.56, "end": 6420.240000000001, "text": " of", "tokens": [295], "temperature": 0.0, "avg_logprob": -0.41228314568014707, "compression_ratio": 1.5742574257425743, "no_speech_prob": 5.9550975493039005e-06}, {"id": 1359, "seek": 641856, "start": 6420.240000000001, "end": 6428.240000000001, "text": " 1-y times log 1-p. This is like kind of awkward notation often people use like a direct delta function", "tokens": [502, 12, 88, 1413, 3565, 502, 12, 79, 13, 639, 307, 411, 733, 295, 11411, 24657, 2049, 561, 764, 411, 257, 2047, 8289, 2445], "temperature": 0.0, "avg_logprob": -0.41228314568014707, "compression_ratio": 1.5742574257425743, "no_speech_prob": 5.9550975493039005e-06}, {"id": 1360, "seek": 641856, "start": 6428.240000000001, "end": 6430.76, "text": " Stupid stuff like that. Where else this um", "tokens": [37659, 1507, 411, 300, 13, 2305, 1646, 341, 1105], "temperature": 0.0, "avg_logprob": -0.41228314568014707, "compression_ratio": 1.5742574257425743, "no_speech_prob": 5.9550975493039005e-06}, {"id": 1361, "seek": 641856, "start": 6431.280000000001, "end": 6437.76, "text": " This paper just says you know what it's just a conditional the cross entropy simply is what negative log P if y is 1", "tokens": [639, 3035, 445, 1619, 291, 458, 437, 309, 311, 445, 257, 27708, 264, 3278, 30867, 2935, 307, 437, 3671, 3565, 430, 498, 288, 307, 502], "temperature": 0.0, "avg_logprob": -0.41228314568014707, "compression_ratio": 1.5742574257425743, "no_speech_prob": 5.9550975493039005e-06}, {"id": 1362, "seek": 641856, "start": 6438.56, "end": 6440.56, "text": " negative log 1 minus P otherwise", "tokens": [3671, 3565, 502, 3175, 430, 5911], "temperature": 0.0, "avg_logprob": -0.41228314568014707, "compression_ratio": 1.5742574257425743, "no_speech_prob": 5.9550975493039005e-06}, {"id": 1363, "seek": 641856, "start": 6441.080000000001, "end": 6443.080000000001, "text": " So this is the y is", "tokens": [407, 341, 307, 264, 288, 307], "temperature": 0.0, "avg_logprob": -0.41228314568014707, "compression_ratio": 1.5742574257425743, "no_speech_prob": 5.9550975493039005e-06}, {"id": 1364, "seek": 644308, "start": 6443.08, "end": 6449.72, "text": " 1 if it's a motorbike 0 if not in this paper they say 1 if it's a motorbike for negative 1 if not", "tokens": [502, 498, 309, 311, 257, 5932, 30283, 1958, 498, 406, 294, 341, 3035, 436, 584, 502, 498, 309, 311, 257, 5932, 30283, 337, 3671, 502, 498, 406], "temperature": 0.0, "avg_logprob": -0.37703101579533066, "compression_ratio": 1.526829268292683, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1365, "seek": 644308, "start": 6450.44, "end": 6452.68, "text": " I was right we use zero and", "tokens": [286, 390, 558, 321, 764, 4018, 293], "temperature": 0.0, "avg_logprob": -0.37703101579533066, "compression_ratio": 1.526829268292683, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1366, "seek": 644308, "start": 6453.48, "end": 6457.54, "text": " Then they do something which mathematicians never do they refactor", "tokens": [1396, 436, 360, 746, 597, 32811, 2567, 1128, 360, 436, 1895, 15104], "temperature": 0.0, "avg_logprob": -0.37703101579533066, "compression_ratio": 1.526829268292683, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1367, "seek": 644308, "start": 6458.2, "end": 6461.6, "text": " Right check this out. Hey, what if we replace?", "tokens": [1779, 1520, 341, 484, 13, 1911, 11, 437, 498, 321, 7406, 30], "temperature": 0.0, "avg_logprob": -0.37703101579533066, "compression_ratio": 1.526829268292683, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1368, "seek": 644308, "start": 6462.2, "end": 6466.92, "text": " What if we define a new term called PT which is equal to the probability?", "tokens": [708, 498, 321, 6964, 257, 777, 1433, 1219, 35460, 597, 307, 2681, 281, 264, 8482, 30], "temperature": 0.0, "avg_logprob": -0.37703101579533066, "compression_ratio": 1.526829268292683, "no_speech_prob": 1.7603376818442484e-06}, {"id": 1369, "seek": 646692, "start": 6466.92, "end": 6473.6, "text": " If y is 1 or 1 minus P otherwise if we did that we could now redefine C E as", "tokens": [759, 288, 307, 502, 420, 502, 3175, 430, 5911, 498, 321, 630, 300, 321, 727, 586, 38818, 533, 383, 462, 382], "temperature": 0.0, "avg_logprob": -0.256892337593981, "compression_ratio": 1.5086206896551724, "no_speech_prob": 5.594297817879124e-06}, {"id": 1370, "seek": 646692, "start": 6474.76, "end": 6476.68, "text": " that", "tokens": [300], "temperature": 0.0, "avg_logprob": -0.256892337593981, "compression_ratio": 1.5086206896551724, "no_speech_prob": 5.594297817879124e-06}, {"id": 1371, "seek": 646692, "start": 6476.68, "end": 6480.72, "text": " Which is super cool like it's such a obvious thing to do", "tokens": [3013, 307, 1687, 1627, 411, 309, 311, 1270, 257, 6322, 551, 281, 360], "temperature": 0.0, "avg_logprob": -0.256892337593981, "compression_ratio": 1.5086206896551724, "no_speech_prob": 5.594297817879124e-06}, {"id": 1372, "seek": 646692, "start": 6480.72, "end": 6484.68, "text": " But as soon as you do it all of the other equations get simpler as well", "tokens": [583, 382, 2321, 382, 291, 360, 309, 439, 295, 264, 661, 11787, 483, 18587, 382, 731], "temperature": 0.0, "avg_logprob": -0.256892337593981, "compression_ratio": 1.5086206896551724, "no_speech_prob": 5.594297817879124e-06}, {"id": 1373, "seek": 646692, "start": 6485.88, "end": 6487.88, "text": " because later on", "tokens": [570, 1780, 322], "temperature": 0.0, "avg_logprob": -0.256892337593981, "compression_ratio": 1.5086206896551724, "no_speech_prob": 5.594297817879124e-06}, {"id": 1374, "seek": 646692, "start": 6487.92, "end": 6494.4, "text": " Straighten up at the very next paragraph. They say hey one way to deal with class imbalance ie lots of stuff is background", "tokens": [26908, 268, 493, 412, 264, 588, 958, 18865, 13, 814, 584, 4177, 472, 636, 281, 2028, 365, 1508, 43007, 43203, 3195, 295, 1507, 307, 3678], "temperature": 0.0, "avg_logprob": -0.256892337593981, "compression_ratio": 1.5086206896551724, "no_speech_prob": 5.594297817879124e-06}, {"id": 1375, "seek": 649440, "start": 6494.4, "end": 6500.32, "text": " Would just be to have a different weighting factor the background business not so like", "tokens": [6068, 445, 312, 281, 362, 257, 819, 3364, 278, 5952, 264, 3678, 1606, 406, 370, 411], "temperature": 0.0, "avg_logprob": -0.27546372076477665, "compression_ratio": 1.6608695652173913, "no_speech_prob": 5.507557943928987e-06}, {"id": 1376, "seek": 649440, "start": 6501.12, "end": 6503.12, "text": " for class 1", "tokens": [337, 1508, 502], "temperature": 0.0, "avg_logprob": -0.27546372076477665, "compression_ratio": 1.6608695652173913, "no_speech_prob": 5.507557943928987e-06}, {"id": 1377, "seek": 649440, "start": 6503.32, "end": 6506.799999999999, "text": " You know we'll have some number alpha and for class", "tokens": [509, 458, 321, 603, 362, 512, 1230, 8961, 293, 337, 1508], "temperature": 0.0, "avg_logprob": -0.27546372076477665, "compression_ratio": 1.6608695652173913, "no_speech_prob": 5.507557943928987e-06}, {"id": 1378, "seek": 649440, "start": 6507.599999999999, "end": 6509.599999999999, "text": " Zero, we'll have 1 minus alpha", "tokens": [17182, 11, 321, 603, 362, 502, 3175, 8961], "temperature": 0.0, "avg_logprob": -0.27546372076477665, "compression_ratio": 1.6608695652173913, "no_speech_prob": 5.507557943928987e-06}, {"id": 1379, "seek": 649440, "start": 6510.44, "end": 6514.679999999999, "text": " But then they're like hey, let's define out for T the same way and so now our", "tokens": [583, 550, 436, 434, 411, 4177, 11, 718, 311, 6964, 484, 337, 314, 264, 912, 636, 293, 370, 586, 527], "temperature": 0.0, "avg_logprob": -0.27546372076477665, "compression_ratio": 1.6608695652173913, "no_speech_prob": 5.507557943928987e-06}, {"id": 1380, "seek": 649440, "start": 6515.4, "end": 6517.04, "text": " cross entropy", "tokens": [3278, 30867], "temperature": 0.0, "avg_logprob": -0.27546372076477665, "compression_ratio": 1.6608695652173913, "no_speech_prob": 5.507557943928987e-06}, {"id": 1381, "seek": 649440, "start": 6517.04, "end": 6521.759999999999, "text": " Ballot you know with a weighting factor can be written like this and so then they can write their focal loss", "tokens": [10744, 310, 291, 458, 365, 257, 3364, 278, 5952, 393, 312, 3720, 411, 341, 293, 370, 550, 436, 393, 2464, 641, 26592, 4470], "temperature": 0.0, "avg_logprob": -0.27546372076477665, "compression_ratio": 1.6608695652173913, "no_speech_prob": 5.507557943928987e-06}, {"id": 1382, "seek": 652176, "start": 6521.76, "end": 6524.0, "text": " with the same concept and", "tokens": [365, 264, 912, 3410, 293], "temperature": 0.0, "avg_logprob": -0.22399771554129463, "compression_ratio": 1.5849056603773586, "no_speech_prob": 2.561268502176972e-06}, {"id": 1383, "seek": 652176, "start": 6524.92, "end": 6530.16, "text": " Then eventually they say hey, let's take focal loss and combine it with class weighting", "tokens": [1396, 4728, 436, 584, 4177, 11, 718, 311, 747, 26592, 4470, 293, 10432, 309, 365, 1508, 3364, 278], "temperature": 0.0, "avg_logprob": -0.22399771554129463, "compression_ratio": 1.5849056603773586, "no_speech_prob": 2.561268502176972e-06}, {"id": 1384, "seek": 652176, "start": 6531.400000000001, "end": 6534.3, "text": " Like so right so often when you see in a paper", "tokens": [1743, 370, 558, 370, 2049, 562, 291, 536, 294, 257, 3035], "temperature": 0.0, "avg_logprob": -0.22399771554129463, "compression_ratio": 1.5849056603773586, "no_speech_prob": 2.561268502176972e-06}, {"id": 1385, "seek": 652176, "start": 6534.96, "end": 6539.2, "text": " Huge big equations. It's just because mathematicians don't know how to be factor", "tokens": [37043, 955, 11787, 13, 467, 311, 445, 570, 32811, 2567, 500, 380, 458, 577, 281, 312, 5952], "temperature": 0.0, "avg_logprob": -0.22399771554129463, "compression_ratio": 1.5849056603773586, "no_speech_prob": 2.561268502176972e-06}, {"id": 1386, "seek": 652176, "start": 6539.2, "end": 6542.56, "text": " And you'll see like the same pieces are kind of repeated all over the place", "tokens": [400, 291, 603, 536, 411, 264, 912, 3755, 366, 733, 295, 10477, 439, 670, 264, 1081], "temperature": 0.0, "avg_logprob": -0.22399771554129463, "compression_ratio": 1.5849056603773586, "no_speech_prob": 2.561268502176972e-06}, {"id": 1387, "seek": 652176, "start": 6542.88, "end": 6547.16, "text": " Right very very very often and by the time you've turned it into numpy code", "tokens": [1779, 588, 588, 588, 2049, 293, 538, 264, 565, 291, 600, 3574, 309, 666, 1031, 8200, 3089], "temperature": 0.0, "avg_logprob": -0.22399771554129463, "compression_ratio": 1.5849056603773586, "no_speech_prob": 2.561268502176972e-06}, {"id": 1388, "seek": 652176, "start": 6547.88, "end": 6549.88, "text": " Suddenly it's super simple", "tokens": [21194, 309, 311, 1687, 2199], "temperature": 0.0, "avg_logprob": -0.22399771554129463, "compression_ratio": 1.5849056603773586, "no_speech_prob": 2.561268502176972e-06}, {"id": 1389, "seek": 654988, "start": 6549.88, "end": 6551.88, "text": " so this is a", "tokens": [370, 341, 307, 257], "temperature": 0.0, "avg_logprob": -0.2814685460683462, "compression_ratio": 1.6079545454545454, "no_speech_prob": 3.340513330840622e-06}, {"id": 1390, "seek": 654988, "start": 6552.88, "end": 6555.68, "text": " Million times better than nearly any other", "tokens": [33959, 1413, 1101, 813, 6217, 604, 661], "temperature": 0.0, "avg_logprob": -0.2814685460683462, "compression_ratio": 1.6079545454545454, "no_speech_prob": 3.340513330840622e-06}, {"id": 1391, "seek": 654988, "start": 6556.28, "end": 6563.52, "text": " Paper so it's a great paper to read to understand how papers should be a terrible paper to read to understand what most", "tokens": [24990, 370, 309, 311, 257, 869, 3035, 281, 1401, 281, 1223, 577, 10577, 820, 312, 257, 6237, 3035, 281, 1401, 281, 1223, 437, 881], "temperature": 0.0, "avg_logprob": -0.2814685460683462, "compression_ratio": 1.6079545454545454, "no_speech_prob": 3.340513330840622e-06}, {"id": 1392, "seek": 654988, "start": 6567.16, "end": 6570.08, "text": " Okay, so let's try this we're going to use this", "tokens": [1033, 11, 370, 718, 311, 853, 341, 321, 434, 516, 281, 764, 341], "temperature": 0.0, "avg_logprob": -0.2814685460683462, "compression_ratio": 1.6079545454545454, "no_speech_prob": 3.340513330840622e-06}, {"id": 1393, "seek": 654988, "start": 6570.76, "end": 6575.28, "text": " Yeah, now remember negative log P is the cross-entropy loss", "tokens": [865, 11, 586, 1604, 3671, 3565, 430, 307, 264, 3278, 12, 317, 27514, 4470], "temperature": 0.0, "avg_logprob": -0.2814685460683462, "compression_ratio": 1.6079545454545454, "no_speech_prob": 3.340513330840622e-06}, {"id": 1394, "seek": 657528, "start": 6575.28, "end": 6580.16, "text": " So therefore this is just equal to some number times", "tokens": [407, 4412, 341, 307, 445, 2681, 281, 512, 1230, 1413], "temperature": 0.0, "avg_logprob": -0.2906288464864095, "compression_ratio": 1.4697986577181208, "no_speech_prob": 1.8448150740368874e-06}, {"id": 1395, "seek": 657528, "start": 6580.679999999999, "end": 6582.679999999999, "text": " but cross entropy loss and", "tokens": [457, 3278, 30867, 4470, 293], "temperature": 0.0, "avg_logprob": -0.2906288464864095, "compression_ratio": 1.4697986577181208, "no_speech_prob": 1.8448150740368874e-06}, {"id": 1396, "seek": 657528, "start": 6583.16, "end": 6585.16, "text": " when I defined the", "tokens": [562, 286, 7642, 264], "temperature": 0.0, "avg_logprob": -0.2906288464864095, "compression_ratio": 1.4697986577181208, "no_speech_prob": 1.8448150740368874e-06}, {"id": 1397, "seek": 657528, "start": 6586.28, "end": 6588.28, "text": " binomial cross entropy loss I", "tokens": [5171, 47429, 3278, 30867, 4470, 286], "temperature": 0.0, "avg_logprob": -0.2906288464864095, "compression_ratio": 1.4697986577181208, "no_speech_prob": 1.8448150740368874e-06}, {"id": 1398, "seek": 657528, "start": 6589.92, "end": 6593.32, "text": " Don't know if you remember or if you noticed, but I", "tokens": [1468, 380, 458, 498, 291, 1604, 420, 498, 291, 5694, 11, 457, 286], "temperature": 0.0, "avg_logprob": -0.2906288464864095, "compression_ratio": 1.4697986577181208, "no_speech_prob": 1.8448150740368874e-06}, {"id": 1399, "seek": 657528, "start": 6597.24, "end": 6602.96, "text": " Had a weight which by default was none", "tokens": [12298, 257, 3364, 597, 538, 7576, 390, 6022], "temperature": 0.0, "avg_logprob": -0.2906288464864095, "compression_ratio": 1.4697986577181208, "no_speech_prob": 1.8448150740368874e-06}, {"id": 1400, "seek": 660296, "start": 6602.96, "end": 6607.28, "text": " right and when you call binary cross entropy with log it's the", "tokens": [558, 293, 562, 291, 818, 17434, 3278, 30867, 365, 3565, 309, 311, 264], "temperature": 0.0, "avg_logprob": -0.3906308843734417, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.5612564513721736e-06}, {"id": 1401, "seek": 660296, "start": 6608.0, "end": 6610.42, "text": " High-forged thing you can optionally pass it away", "tokens": [5229, 12, 2994, 3004, 551, 291, 393, 3614, 379, 1320, 309, 1314], "temperature": 0.0, "avg_logprob": -0.3906308843734417, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.5612564513721736e-06}, {"id": 1402, "seek": 660296, "start": 6610.52, "end": 6617.08, "text": " That's just something that's multiplied by everything and if it's none then there's no way so since we're just wanting to multiply", "tokens": [663, 311, 445, 746, 300, 311, 17207, 538, 1203, 293, 498, 309, 311, 6022, 550, 456, 311, 572, 636, 370, 1670, 321, 434, 445, 7935, 281, 12972], "temperature": 0.0, "avg_logprob": -0.3906308843734417, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.5612564513721736e-06}, {"id": 1403, "seek": 660296, "start": 6617.68, "end": 6619.68, "text": " Cross entropy by something", "tokens": [11623, 30867, 538, 746], "temperature": 0.0, "avg_logprob": -0.3906308843734417, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.5612564513721736e-06}, {"id": 1404, "seek": 660296, "start": 6619.68, "end": 6621.68, "text": " We can just define", "tokens": [492, 393, 445, 6964], "temperature": 0.0, "avg_logprob": -0.3906308843734417, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.5612564513721736e-06}, {"id": 1405, "seek": 660296, "start": 6621.72, "end": 6623.72, "text": " Get weight", "tokens": [3240, 3364], "temperature": 0.0, "avg_logprob": -0.3906308843734417, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.5612564513721736e-06}, {"id": 1406, "seek": 660296, "start": 6624.2, "end": 6626.92, "text": " So here's the entirety", "tokens": [407, 510, 311, 264, 31557], "temperature": 0.0, "avg_logprob": -0.3906308843734417, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.5612564513721736e-06}, {"id": 1407, "seek": 660296, "start": 6628.16, "end": 6631.16, "text": " the focal loss this is the thing that like", "tokens": [264, 26592, 4470, 341, 307, 264, 551, 300, 411], "temperature": 0.0, "avg_logprob": -0.3906308843734417, "compression_ratio": 1.7023255813953488, "no_speech_prob": 2.5612564513721736e-06}, {"id": 1408, "seek": 663116, "start": 6631.16, "end": 6634.16, "text": " Suddenly made object detection make sense", "tokens": [21194, 1027, 2657, 17784, 652, 2020], "temperature": 0.0, "avg_logprob": -0.6442722407254305, "compression_ratio": 1.5276381909547738, "no_speech_prob": 9.972821317205671e-06}, {"id": 1409, "seek": 663116, "start": 6634.88, "end": 6639.08, "text": " All right, so this was late last year suddenly it got rid of all of the", "tokens": [1057, 558, 11, 370, 341, 390, 3469, 1036, 1064, 5800, 309, 658, 3973, 295, 439, 295, 264], "temperature": 0.0, "avg_logprob": -0.6442722407254305, "compression_ratio": 1.5276381909547738, "no_speech_prob": 9.972821317205671e-06}, {"id": 1410, "seek": 663116, "start": 6639.84, "end": 6641.84, "text": " complex messy", "tokens": [3997, 16191], "temperature": 0.0, "avg_logprob": -0.6442722407254305, "compression_ratio": 1.5276381909547738, "no_speech_prob": 9.972821317205671e-06}, {"id": 1411, "seek": 663116, "start": 6641.84, "end": 6644.32, "text": " Hacker right and so", "tokens": [389, 23599, 558, 293, 370], "temperature": 0.0, "avg_logprob": -0.6442722407254305, "compression_ratio": 1.5276381909547738, "no_speech_prob": 9.972821317205671e-06}, {"id": 1412, "seek": 663116, "start": 6645.36, "end": 6648.36, "text": " Do our sigmoid is our", "tokens": [1144, 527, 4556, 3280, 327, 307, 527], "temperature": 0.0, "avg_logprob": -0.6442722407254305, "compression_ratio": 1.5276381909547738, "no_speech_prob": 9.972821317205671e-06}, {"id": 1413, "seek": 663116, "start": 6648.88, "end": 6650.88, "text": " PT", "tokens": [35460], "temperature": 0.0, "avg_logprob": -0.6442722407254305, "compression_ratio": 1.5276381909547738, "no_speech_prob": 9.972821317205671e-06}, {"id": 1414, "seek": 663116, "start": 6650.88, "end": 6657.5199999999995, "text": " Is a W and here you can see one minus PT to the power of gamma right and so we're going to set gamma of two", "tokens": [1119, 257, 343, 293, 510, 291, 393, 536, 472, 3175, 35460, 281, 264, 1347, 295, 15546, 558, 293, 370, 321, 434, 516, 281, 992, 15546, 295, 732], "temperature": 0.0, "avg_logprob": -0.6442722407254305, "compression_ratio": 1.5276381909547738, "no_speech_prob": 9.972821317205671e-06}, {"id": 1415, "seek": 663116, "start": 6657.96, "end": 6659.96, "text": " Alpha is point two five", "tokens": [20588, 307, 935, 732, 1732], "temperature": 0.0, "avg_logprob": -0.6442722407254305, "compression_ratio": 1.5276381909547738, "no_speech_prob": 9.972821317205671e-06}, {"id": 1416, "seek": 665996, "start": 6659.96, "end": 6664.52, "text": " Two five if you're wondering why here's another excellent thing about this paper", "tokens": [4453, 1732, 498, 291, 434, 6359, 983, 510, 311, 1071, 7103, 551, 466, 341, 3035], "temperature": 0.0, "avg_logprob": -0.307861281029972, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.5294070863092202e-06}, {"id": 1417, "seek": 665996, "start": 6665.96, "end": 6673.08, "text": " Because they tried lots of different values of gamma and alpha and they found that two and point two five work well", "tokens": [1436, 436, 3031, 3195, 295, 819, 4190, 295, 15546, 293, 8961, 293, 436, 1352, 300, 732, 293, 935, 732, 1732, 589, 731], "temperature": 0.0, "avg_logprob": -0.307861281029972, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.5294070863092202e-06}, {"id": 1418, "seek": 665996, "start": 6673.92, "end": 6675.24, "text": " consistent", "tokens": [8398], "temperature": 0.0, "avg_logprob": -0.307861281029972, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.5294070863092202e-06}, {"id": 1419, "seek": 665996, "start": 6675.24, "end": 6676.52, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.307861281029972, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.5294070863092202e-06}, {"id": 1420, "seek": 665996, "start": 6676.52, "end": 6677.8, "text": " so", "tokens": [370], "temperature": 0.0, "avg_logprob": -0.307861281029972, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.5294070863092202e-06}, {"id": 1421, "seek": 665996, "start": 6677.8, "end": 6683.76, "text": " There's our new loss function it derives from our BC loss adding a weight to it", "tokens": [821, 311, 527, 777, 4470, 2445, 309, 1163, 1539, 490, 527, 14359, 4470, 5127, 257, 3364, 281, 309], "temperature": 0.0, "avg_logprob": -0.307861281029972, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.5294070863092202e-06}, {"id": 1422, "seek": 665996, "start": 6684.52, "end": 6685.84, "text": " focal loss", "tokens": [26592, 4470], "temperature": 0.0, "avg_logprob": -0.307861281029972, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.5294070863092202e-06}, {"id": 1423, "seek": 665996, "start": 6685.84, "end": 6687.8, "text": " other than that", "tokens": [661, 813, 300], "temperature": 0.0, "avg_logprob": -0.307861281029972, "compression_ratio": 1.6019900497512438, "no_speech_prob": 1.5294070863092202e-06}, {"id": 1424, "seek": 668780, "start": 6687.8, "end": 6691.0, "text": " There's nothing else to do we can just train our model again", "tokens": [821, 311, 1825, 1646, 281, 360, 321, 393, 445, 3847, 527, 2316, 797], "temperature": 0.0, "avg_logprob": -0.1670033908584743, "compression_ratio": 1.6936170212765957, "no_speech_prob": 1.028933547786437e-05}, {"id": 1425, "seek": 668780, "start": 6691.64, "end": 6693.8, "text": " Okay, and so this time", "tokens": [1033, 11, 293, 370, 341, 565], "temperature": 0.0, "avg_logprob": -0.1670033908584743, "compression_ratio": 1.6936170212765957, "no_speech_prob": 1.028933547786437e-05}, {"id": 1426, "seek": 668780, "start": 6694.76, "end": 6696.76, "text": " Things are looking quite a bit better", "tokens": [9514, 366, 1237, 1596, 257, 857, 1101], "temperature": 0.0, "avg_logprob": -0.1670033908584743, "compression_ratio": 1.6936170212765957, "no_speech_prob": 1.028933547786437e-05}, {"id": 1427, "seek": 668780, "start": 6697.400000000001, "end": 6699.400000000001, "text": " You know we now have", "tokens": [509, 458, 321, 586, 362], "temperature": 0.0, "avg_logprob": -0.1670033908584743, "compression_ratio": 1.6936170212765957, "no_speech_prob": 1.028933547786437e-05}, {"id": 1428, "seek": 668780, "start": 6701.08, "end": 6707.24, "text": " Motorbike bicycle person motorbike like it's it's actually having a go at finding something. Yeah", "tokens": [18495, 30283, 20888, 954, 5932, 30283, 411, 309, 311, 309, 311, 767, 1419, 257, 352, 412, 5006, 746, 13, 865], "temperature": 0.0, "avg_logprob": -0.1670033908584743, "compression_ratio": 1.6936170212765957, "no_speech_prob": 1.028933547786437e-05}, {"id": 1429, "seek": 668780, "start": 6708.320000000001, "end": 6711.72, "text": " It's still doing a good job with big ones. In fact. It's looking quite a lot better", "tokens": [467, 311, 920, 884, 257, 665, 1691, 365, 955, 2306, 13, 682, 1186, 13, 467, 311, 1237, 1596, 257, 688, 1101], "temperature": 0.0, "avg_logprob": -0.1670033908584743, "compression_ratio": 1.6936170212765957, "no_speech_prob": 1.028933547786437e-05}, {"id": 1430, "seek": 671172, "start": 6711.72, "end": 6716.84, "text": " It's finding quite a few people. It's finding a couple of different birds", "tokens": [467, 311, 5006, 1596, 257, 1326, 561, 13, 467, 311, 5006, 257, 1916, 295, 819, 9009], "temperature": 0.0, "avg_logprob": -0.29706562524554375, "compression_ratio": 1.5627906976744186, "no_speech_prob": 1.5206461284833495e-05}, {"id": 1431, "seek": 671172, "start": 6717.68, "end": 6721.68, "text": " It's looking pretty good right so our last step", "tokens": [467, 311, 1237, 1238, 665, 558, 370, 527, 1036, 1823], "temperature": 0.0, "avg_logprob": -0.29706562524554375, "compression_ratio": 1.5627906976744186, "no_speech_prob": 1.5206461284833495e-05}, {"id": 1432, "seek": 671172, "start": 6722.4400000000005, "end": 6725.88, "text": " Is for now is to basically figure out how to?", "tokens": [1119, 337, 586, 307, 281, 1936, 2573, 484, 577, 281, 30], "temperature": 0.0, "avg_logprob": -0.29706562524554375, "compression_ratio": 1.5627906976744186, "no_speech_prob": 1.5206461284833495e-05}, {"id": 1433, "seek": 671172, "start": 6727.2, "end": 6732.12, "text": " Pull out just the interesting stuff that it's like let's take this dog in this sofa, right? How do we pick out?", "tokens": [15074, 484, 445, 264, 1880, 1507, 300, 309, 311, 411, 718, 311, 747, 341, 3000, 294, 341, 28668, 11, 558, 30, 1012, 360, 321, 1888, 484, 30], "temperature": 0.0, "avg_logprob": -0.29706562524554375, "compression_ratio": 1.5627906976744186, "no_speech_prob": 1.5206461284833495e-05}, {"id": 1434, "seek": 671172, "start": 6732.64, "end": 6737.320000000001, "text": " Our dog and our sofa and the answer is incredibly simple", "tokens": [2621, 3000, 293, 527, 28668, 293, 264, 1867, 307, 6252, 2199], "temperature": 0.0, "avg_logprob": -0.29706562524554375, "compression_ratio": 1.5627906976744186, "no_speech_prob": 1.5206461284833495e-05}, {"id": 1435, "seek": 673732, "start": 6737.32, "end": 6742.799999999999, "text": " All we're going to do is we're going to is we're going to go through every pair of these", "tokens": [1057, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 307, 321, 434, 516, 281, 352, 807, 633, 6119, 295, 613], "temperature": 0.0, "avg_logprob": -0.277433937474301, "compression_ratio": 1.775, "no_speech_prob": 3.321269832667895e-05}, {"id": 1436, "seek": 673732, "start": 6743.5599999999995, "end": 6745.44, "text": " bounding boxes and", "tokens": [5472, 278, 9002, 293], "temperature": 0.0, "avg_logprob": -0.277433937474301, "compression_ratio": 1.775, "no_speech_prob": 3.321269832667895e-05}, {"id": 1437, "seek": 673732, "start": 6745.44, "end": 6746.84, "text": " if they", "tokens": [498, 436], "temperature": 0.0, "avg_logprob": -0.277433937474301, "compression_ratio": 1.775, "no_speech_prob": 3.321269832667895e-05}, {"id": 1438, "seek": 673732, "start": 6746.84, "end": 6751.84, "text": " overlap by more than some amount say point five using jacquard and", "tokens": [19959, 538, 544, 813, 512, 2372, 584, 935, 1732, 1228, 361, 326, 358, 515, 293], "temperature": 0.0, "avg_logprob": -0.277433937474301, "compression_ratio": 1.775, "no_speech_prob": 3.321269832667895e-05}, {"id": 1439, "seek": 673732, "start": 6752.759999999999, "end": 6754.88, "text": " They both are predicting the same class", "tokens": [814, 1293, 366, 32884, 264, 912, 1508], "temperature": 0.0, "avg_logprob": -0.277433937474301, "compression_ratio": 1.775, "no_speech_prob": 3.321269832667895e-05}, {"id": 1440, "seek": 673732, "start": 6755.32, "end": 6759.96, "text": " We're going to assume that the same thing and we're just going to pick the one with the higher key value", "tokens": [492, 434, 516, 281, 6552, 300, 264, 912, 551, 293, 321, 434, 445, 516, 281, 1888, 264, 472, 365, 264, 2946, 2141, 2158], "temperature": 0.0, "avg_logprob": -0.277433937474301, "compression_ratio": 1.775, "no_speech_prob": 3.321269832667895e-05}, {"id": 1441, "seek": 673732, "start": 6760.679999999999, "end": 6762.679999999999, "text": " And we just keep doing that", "tokens": [400, 321, 445, 1066, 884, 300], "temperature": 0.0, "avg_logprob": -0.277433937474301, "compression_ratio": 1.775, "no_speech_prob": 3.321269832667895e-05}, {"id": 1442, "seek": 676268, "start": 6762.68, "end": 6769.0, "text": " Repeat it. That's really boring code. I actually didn't write it myself. I copied it off somebody else somebody else's code", "tokens": [28523, 309, 13, 663, 311, 534, 9989, 3089, 13, 286, 767, 994, 380, 2464, 309, 2059, 13, 286, 25365, 309, 766, 2618, 1646, 2618, 1646, 311, 3089], "temperature": 0.0, "avg_logprob": -0.2746345561037781, "compression_ratio": 1.6157407407407407, "no_speech_prob": 1.6797007447166834e-06}, {"id": 1443, "seek": 676268, "start": 6770.12, "end": 6772.4800000000005, "text": " non maximum suppression s", "tokens": [2107, 6674, 36807, 262], "temperature": 0.0, "avg_logprob": -0.2746345561037781, "compression_ratio": 1.6157407407407407, "no_speech_prob": 1.6797007447166834e-06}, {"id": 1444, "seek": 676268, "start": 6773.360000000001, "end": 6776.6, "text": " No reason particularly to go through it, but that's all of us, right?", "tokens": [883, 1778, 4098, 281, 352, 807, 309, 11, 457, 300, 311, 439, 295, 505, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2746345561037781, "compression_ratio": 1.6157407407407407, "no_speech_prob": 1.6797007447166834e-06}, {"id": 1445, "seek": 676268, "start": 6777.360000000001, "end": 6781.64, "text": " so we can now show the results of the non maximum suppression and", "tokens": [370, 321, 393, 586, 855, 264, 3542, 295, 264, 2107, 6674, 36807, 293], "temperature": 0.0, "avg_logprob": -0.2746345561037781, "compression_ratio": 1.6157407407407407, "no_speech_prob": 1.6797007447166834e-06}, {"id": 1446, "seek": 676268, "start": 6783.84, "end": 6786.22, "text": " Yeah, here's the sofa is the dog", "tokens": [865, 11, 510, 311, 264, 28668, 307, 264, 3000], "temperature": 0.0, "avg_logprob": -0.2746345561037781, "compression_ratio": 1.6157407407407407, "no_speech_prob": 1.6797007447166834e-06}, {"id": 1447, "seek": 676268, "start": 6788.4800000000005, "end": 6790.4800000000005, "text": " Here's the bird", "tokens": [1692, 311, 264, 5255], "temperature": 0.0, "avg_logprob": -0.2746345561037781, "compression_ratio": 1.6157407407407407, "no_speech_prob": 1.6797007447166834e-06}, {"id": 1448, "seek": 679048, "start": 6790.48, "end": 6795.759999999999, "text": " Here's the person this person's cigarette looks like it's", "tokens": [1692, 311, 264, 954, 341, 954, 311, 26184, 1542, 411, 309, 311], "temperature": 0.0, "avg_logprob": -0.3143921902305202, "compression_ratio": 1.6123595505617978, "no_speech_prob": 1.2218869414937217e-05}, {"id": 1449, "seek": 679048, "start": 6800.5599999999995, "end": 6806.839999999999, "text": " This one it's like it's okay, but not great like it's found a person that is bicycle of a person", "tokens": [639, 472, 309, 311, 411, 309, 311, 1392, 11, 457, 406, 869, 411, 309, 311, 1352, 257, 954, 300, 307, 20888, 295, 257, 954], "temperature": 0.0, "avg_logprob": -0.3143921902305202, "compression_ratio": 1.6123595505617978, "no_speech_prob": 1.2218869414937217e-05}, {"id": 1450, "seek": 679048, "start": 6810.5199999999995, "end": 6812.5199999999995, "text": " Place", "tokens": [13637], "temperature": 0.0, "avg_logprob": -0.3143921902305202, "compression_ratio": 1.6123595505617978, "no_speech_prob": 1.2218869414937217e-05}, {"id": 1451, "seek": 681252, "start": 6812.52, "end": 6820.080000000001, "text": " You know you can also see that like some of these smaller things that lower p-values the hope like a motorbike which is 0.16", "tokens": [509, 458, 291, 393, 611, 536, 300, 411, 512, 295, 613, 4356, 721, 300, 3126, 280, 12, 46033, 264, 1454, 411, 257, 5932, 30283, 597, 307, 1958, 13, 6866], "temperature": 0.0, "avg_logprob": -0.4043345658675484, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.473856082156999e-05}, {"id": 1452, "seek": 681252, "start": 6820.56, "end": 6822.860000000001, "text": " This is saying time off us", "tokens": [639, 307, 1566, 565, 766, 505], "temperature": 0.0, "avg_logprob": -0.4043345658675484, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.473856082156999e-05}, {"id": 1453, "seek": 681252, "start": 6823.400000000001, "end": 6827.96, "text": " So there's something still to fix here right and the trick will be to use something", "tokens": [407, 456, 311, 746, 920, 281, 3191, 510, 558, 293, 264, 4282, 486, 312, 281, 764, 746], "temperature": 0.0, "avg_logprob": -0.4043345658675484, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.473856082156999e-05}, {"id": 1454, "seek": 681252, "start": 6828.64, "end": 6833.84, "text": " Called feature periods and that's what we're going to do in lesson 14", "tokens": [45001, 4111, 13804, 293, 300, 311, 437, 321, 434, 516, 281, 360, 294, 6898, 3499], "temperature": 0.0, "avg_logprob": -0.4043345658675484, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.473856082156999e-05}, {"id": 1455, "seek": 681252, "start": 6836.52, "end": 6838.52, "text": " Or thereabouts", "tokens": [1610, 456, 41620], "temperature": 0.0, "avg_logprob": -0.4043345658675484, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.473856082156999e-05}, {"id": 1456, "seek": 681252, "start": 6838.72, "end": 6841.160000000001, "text": " And that'll that'll fix this up", "tokens": [400, 300, 603, 300, 603, 3191, 341, 493], "temperature": 0.0, "avg_logprob": -0.4043345658675484, "compression_ratio": 1.592760180995475, "no_speech_prob": 1.473856082156999e-05}, {"id": 1457, "seek": 684116, "start": 6841.16, "end": 6843.16, "text": " Okay", "tokens": [1033], "temperature": 0.0, "avg_logprob": -0.2819522636524145, "compression_ratio": 1.4301675977653632, "no_speech_prob": 6.6433231040718965e-06}, {"id": 1458, "seek": 684116, "start": 6843.88, "end": 6848.08, "text": " What I wanted to do in the last few minutes of class was to talk a", "tokens": [708, 286, 1415, 281, 360, 294, 264, 1036, 1326, 2077, 295, 1508, 390, 281, 751, 257], "temperature": 0.0, "avg_logprob": -0.2819522636524145, "compression_ratio": 1.4301675977653632, "no_speech_prob": 6.6433231040718965e-06}, {"id": 1459, "seek": 684116, "start": 6851.84, "end": 6856.04, "text": " Little bit more about the papers and", "tokens": [8022, 857, 544, 466, 264, 10577, 293], "temperature": 0.0, "avg_logprob": -0.2819522636524145, "compression_ratio": 1.4301675977653632, "no_speech_prob": 6.6433231040718965e-06}, {"id": 1460, "seek": 684116, "start": 6857.24, "end": 6861.8, "text": " specifically to go back to the SSD paper, so this is", "tokens": [4682, 281, 352, 646, 281, 264, 30262, 3035, 11, 370, 341, 307], "temperature": 0.0, "avg_logprob": -0.2819522636524145, "compression_ratio": 1.4301675977653632, "no_speech_prob": 6.6433231040718965e-06}, {"id": 1461, "seek": 684116, "start": 6863.36, "end": 6868.4, "text": " Single shot multi-box detect and when this came out. I was very excited because it was kind of", "tokens": [31248, 3347, 4825, 12, 4995, 5531, 293, 562, 341, 1361, 484, 13, 286, 390, 588, 2919, 570, 309, 390, 733, 295], "temperature": 0.0, "avg_logprob": -0.2819522636524145, "compression_ratio": 1.4301675977653632, "no_speech_prob": 6.6433231040718965e-06}, {"id": 1462, "seek": 686840, "start": 6868.4, "end": 6873.28, "text": " You know it and Yolo were like you know the first kind of", "tokens": [509, 458, 309, 293, 398, 7902, 645, 411, 291, 458, 264, 700, 733, 295], "temperature": 0.0, "avg_logprob": -0.6011246272495815, "compression_ratio": 1.6767676767676767, "no_speech_prob": 2.8408114303601906e-05}, {"id": 1463, "seek": 686840, "start": 6874.12, "end": 6876.12, "text": " single pass", "tokens": [2167, 1320], "temperature": 0.0, "avg_logprob": -0.6011246272495815, "compression_ratio": 1.6767676767676767, "no_speech_prob": 2.8408114303601906e-05}, {"id": 1464, "seek": 686840, "start": 6876.12, "end": 6878.12, "text": " good quality", "tokens": [665, 3125], "temperature": 0.0, "avg_logprob": -0.6011246272495815, "compression_ratio": 1.6767676767676767, "no_speech_prob": 2.8408114303601906e-05}, {"id": 1465, "seek": 686840, "start": 6878.36, "end": 6887.0, "text": " object detection methods that come along and so I kind of ignored object detection until this time or this to past stuff with", "tokens": [2657, 17784, 7150, 300, 808, 2051, 293, 370, 286, 733, 295, 19735, 2657, 17784, 1826, 341, 565, 420, 341, 281, 1791, 1507, 365], "temperature": 0.0, "avg_logprob": -0.6011246272495815, "compression_ratio": 1.6767676767676767, "no_speech_prob": 2.8408114303601906e-05}, {"id": 1466, "seek": 686840, "start": 6887.5199999999995, "end": 6893.599999999999, "text": " RCNN and fast RCNN and faster RCNN because there's been this kind of continuous", "tokens": [28987, 45, 45, 293, 2370, 28987, 45, 45, 293, 4663, 28987, 45, 45, 570, 456, 311, 668, 341, 733, 295, 10957], "temperature": 0.0, "avg_logprob": -0.6011246272495815, "compression_ratio": 1.6767676767676767, "no_speech_prob": 2.8408114303601906e-05}, {"id": 1467, "seek": 686840, "start": 6894.92, "end": 6897.24, "text": " repetition of history in the last few years", "tokens": [30432, 295, 2503, 294, 264, 1036, 1326, 924], "temperature": 0.0, "avg_logprob": -0.6011246272495815, "compression_ratio": 1.6767676767676767, "no_speech_prob": 2.8408114303601906e-05}, {"id": 1468, "seek": 689724, "start": 6897.24, "end": 6900.24, "text": " repetition of history in the deep learning world, which is", "tokens": [30432, 295, 2503, 294, 264, 2452, 2539, 1002, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.20980746203129835, "compression_ratio": 1.704, "no_speech_prob": 1.497058565291809e-05}, {"id": 1469, "seek": 689724, "start": 6901.04, "end": 6902.719999999999, "text": " things that involve", "tokens": [721, 300, 9494], "temperature": 0.0, "avg_logprob": -0.20980746203129835, "compression_ratio": 1.704, "no_speech_prob": 1.497058565291809e-05}, {"id": 1470, "seek": 689724, "start": 6902.719999999999, "end": 6905.719999999999, "text": " multiple passes of multiple different pieces", "tokens": [3866, 11335, 295, 3866, 819, 3755], "temperature": 0.0, "avg_logprob": -0.20980746203129835, "compression_ratio": 1.704, "no_speech_prob": 1.497058565291809e-05}, {"id": 1471, "seek": 689724, "start": 6906.48, "end": 6911.32, "text": " over time, you know, particularly where they involve some non deep learning pieces like", "tokens": [670, 565, 11, 291, 458, 11, 4098, 689, 436, 9494, 512, 2107, 2452, 2539, 3755, 411], "temperature": 0.0, "avg_logprob": -0.20980746203129835, "compression_ratio": 1.704, "no_speech_prob": 1.497058565291809e-05}, {"id": 1472, "seek": 689724, "start": 6912.36, "end": 6915.2, "text": " RCNN and fast RCNN did over time", "tokens": [28987, 45, 45, 293, 2370, 28987, 45, 45, 630, 670, 565], "temperature": 0.0, "avg_logprob": -0.20980746203129835, "compression_ratio": 1.704, "no_speech_prob": 1.497058565291809e-05}, {"id": 1473, "seek": 689724, "start": 6915.48, "end": 6921.12, "text": " They basically always get turned into a single end-to-end deep learning model", "tokens": [814, 1936, 1009, 483, 3574, 666, 257, 2167, 917, 12, 1353, 12, 521, 2452, 2539, 2316], "temperature": 0.0, "avg_logprob": -0.20980746203129835, "compression_ratio": 1.704, "no_speech_prob": 1.497058565291809e-05}, {"id": 1474, "seek": 692112, "start": 6921.12, "end": 6928.64, "text": " So I tend to kind of like ignore them until that happens because that's the point where it's like, okay now people have figured out", "tokens": [407, 286, 3928, 281, 733, 295, 411, 11200, 552, 1826, 300, 2314, 570, 300, 311, 264, 935, 689, 309, 311, 411, 11, 1392, 586, 561, 362, 8932, 484], "temperature": 0.0, "avg_logprob": -0.18503038315545944, "compression_ratio": 1.6174242424242424, "no_speech_prob": 4.8603797040414065e-06}, {"id": 1475, "seek": 692112, "start": 6928.8, "end": 6931.96, "text": " How to show this as a deep learning problem as soon as people do that", "tokens": [1012, 281, 855, 341, 382, 257, 2452, 2539, 1154, 382, 2321, 382, 561, 360, 300], "temperature": 0.0, "avg_logprob": -0.18503038315545944, "compression_ratio": 1.6174242424242424, "no_speech_prob": 4.8603797040414065e-06}, {"id": 1476, "seek": 692112, "start": 6932.0, "end": 6936.08, "text": " They generally end up something that's much faster and much more accurate", "tokens": [814, 5101, 917, 493, 746, 300, 311, 709, 4663, 293, 709, 544, 8559], "temperature": 0.0, "avg_logprob": -0.18503038315545944, "compression_ratio": 1.6174242424242424, "no_speech_prob": 4.8603797040414065e-06}, {"id": 1477, "seek": 692112, "start": 6936.48, "end": 6942.16, "text": " All right, and so SSD and Yolo were really important. So here's the SSD paper", "tokens": [1057, 558, 11, 293, 370, 30262, 293, 398, 7902, 645, 534, 1021, 13, 407, 510, 311, 264, 30262, 3035], "temperature": 0.0, "avg_logprob": -0.18503038315545944, "compression_ratio": 1.6174242424242424, "no_speech_prob": 4.8603797040414065e-06}, {"id": 1478, "seek": 692112, "start": 6944.599999999999, "end": 6946.599999999999, "text": " Let's go down to the key piece", "tokens": [961, 311, 352, 760, 281, 264, 2141, 2522], "temperature": 0.0, "avg_logprob": -0.18503038315545944, "compression_ratio": 1.6174242424242424, "no_speech_prob": 4.8603797040414065e-06}, {"id": 1479, "seek": 692112, "start": 6947.32, "end": 6949.32, "text": " which is where they describe the model and", "tokens": [597, 307, 689, 436, 6786, 264, 2316, 293], "temperature": 0.0, "avg_logprob": -0.18503038315545944, "compression_ratio": 1.6174242424242424, "no_speech_prob": 4.8603797040414065e-06}, {"id": 1480, "seek": 694932, "start": 6949.32, "end": 6951.32, "text": " Let's try and", "tokens": [961, 311, 853, 293], "temperature": 0.0, "avg_logprob": -0.312661091486613, "compression_ratio": 1.3185185185185184, "no_speech_prob": 1.9637952846096596e-06}, {"id": 1481, "seek": 694932, "start": 6952.0, "end": 6954.0, "text": " understand it", "tokens": [1223, 309], "temperature": 0.0, "avg_logprob": -0.312661091486613, "compression_ratio": 1.3185185185185184, "no_speech_prob": 1.9637952846096596e-06}, {"id": 1482, "seek": 694932, "start": 6956.84, "end": 6963.84, "text": " So the model is basically one two three", "tokens": [407, 264, 2316, 307, 1936, 472, 732, 1045], "temperature": 0.0, "avg_logprob": -0.312661091486613, "compression_ratio": 1.3185185185185184, "no_speech_prob": 1.9637952846096596e-06}, {"id": 1483, "seek": 694932, "start": 6968.599999999999, "end": 6971.12, "text": " Four paragraphs, right so", "tokens": [7451, 48910, 11, 558, 370], "temperature": 0.0, "avg_logprob": -0.312661091486613, "compression_ratio": 1.3185185185185184, "no_speech_prob": 1.9637952846096596e-06}, {"id": 1484, "seek": 694932, "start": 6972.599999999999, "end": 6974.599999999999, "text": " Papers are really concise", "tokens": [430, 14441, 366, 534, 44882], "temperature": 0.0, "avg_logprob": -0.312661091486613, "compression_ratio": 1.3185185185185184, "no_speech_prob": 1.9637952846096596e-06}, {"id": 1485, "seek": 697460, "start": 6974.6, "end": 6979.04, "text": " All right, which means you kind of need to read them pretty carefully", "tokens": [1057, 558, 11, 597, 1355, 291, 733, 295, 643, 281, 1401, 552, 1238, 7500], "temperature": 0.0, "avg_logprob": -0.22263700821820429, "compression_ratio": 1.8634361233480177, "no_speech_prob": 6.048824616300408e-06}, {"id": 1486, "seek": 697460, "start": 6979.92, "end": 6982.4400000000005, "text": " Partly though you need to know which bits to read carefully", "tokens": [4100, 356, 1673, 291, 643, 281, 458, 597, 9239, 281, 1401, 7500], "temperature": 0.0, "avg_logprob": -0.22263700821820429, "compression_ratio": 1.8634361233480177, "no_speech_prob": 6.048824616300408e-06}, {"id": 1487, "seek": 697460, "start": 6982.8, "end": 6988.8, "text": " So the bits where they say here we're going to prove the error bounds on this model", "tokens": [407, 264, 9239, 689, 436, 584, 510, 321, 434, 516, 281, 7081, 264, 6713, 29905, 322, 341, 2316], "temperature": 0.0, "avg_logprob": -0.22263700821820429, "compression_ratio": 1.8634361233480177, "no_speech_prob": 6.048824616300408e-06}, {"id": 1488, "seek": 697460, "start": 6988.92, "end": 6992.240000000001, "text": " You can ignore that right because you don't care about proving the error bounds", "tokens": [509, 393, 11200, 300, 558, 570, 291, 500, 380, 1127, 466, 27221, 264, 6713, 29905], "temperature": 0.0, "avg_logprob": -0.22263700821820429, "compression_ratio": 1.8634361233480177, "no_speech_prob": 6.048824616300408e-06}, {"id": 1489, "seek": 697460, "start": 6992.240000000001, "end": 6997.8, "text": " But the bit which says here is what the model is is the bit that you need to read really carefully", "tokens": [583, 264, 857, 597, 1619, 510, 307, 437, 264, 2316, 307, 307, 264, 857, 300, 291, 643, 281, 1401, 534, 7500], "temperature": 0.0, "avg_logprob": -0.22263700821820429, "compression_ratio": 1.8634361233480177, "no_speech_prob": 6.048824616300408e-06}, {"id": 1490, "seek": 697460, "start": 6997.8, "end": 6999.8, "text": " Okay, so here's the bit called", "tokens": [1033, 11, 370, 510, 311, 264, 857, 1219], "temperature": 0.0, "avg_logprob": -0.22263700821820429, "compression_ratio": 1.8634361233480177, "no_speech_prob": 6.048824616300408e-06}, {"id": 1491, "seek": 699980, "start": 6999.8, "end": 7004.96, "text": " Model and so hopefully you'll find we can now read this together and understand it", "tokens": [17105, 293, 370, 4696, 291, 603, 915, 321, 393, 586, 1401, 341, 1214, 293, 1223, 309], "temperature": 0.0, "avg_logprob": -0.26761866139841606, "compression_ratio": 1.6051502145922747, "no_speech_prob": 8.267781595350243e-06}, {"id": 1492, "seek": 699980, "start": 7004.96, "end": 7008.08, "text": " right so SSD is a feed-forward conclet and", "tokens": [558, 370, 30262, 307, 257, 3154, 12, 13305, 1588, 2631, 293], "temperature": 0.0, "avg_logprob": -0.26761866139841606, "compression_ratio": 1.6051502145922747, "no_speech_prob": 8.267781595350243e-06}, {"id": 1493, "seek": 699980, "start": 7008.360000000001, "end": 7016.360000000001, "text": " It creates a fixed size collection of bounding boxes and scores for the presence of object class instances in those boxes", "tokens": [467, 7829, 257, 6806, 2744, 5765, 295, 5472, 278, 9002, 293, 13444, 337, 264, 6814, 295, 2657, 1508, 14519, 294, 729, 9002], "temperature": 0.0, "avg_logprob": -0.26761866139841606, "compression_ratio": 1.6051502145922747, "no_speech_prob": 8.267781595350243e-06}, {"id": 1494, "seek": 699980, "start": 7016.52, "end": 7018.52, "text": " so fixed size", "tokens": [370, 6806, 2744], "temperature": 0.0, "avg_logprob": -0.26761866139841606, "compression_ratio": 1.6051502145922747, "no_speech_prob": 8.267781595350243e-06}, {"id": 1495, "seek": 699980, "start": 7018.72, "end": 7020.72, "text": " that ie the", "tokens": [300, 43203, 264], "temperature": 0.0, "avg_logprob": -0.26761866139841606, "compression_ratio": 1.6051502145922747, "no_speech_prob": 8.267781595350243e-06}, {"id": 1496, "seek": 699980, "start": 7021.68, "end": 7028.06, "text": " Convolutional grid times K, you know the different aspect ratios and stuff and each one of those has", "tokens": [2656, 85, 3386, 304, 10748, 1413, 591, 11, 291, 458, 264, 819, 4171, 32435, 293, 1507, 293, 1184, 472, 295, 729, 575], "temperature": 0.0, "avg_logprob": -0.26761866139841606, "compression_ratio": 1.6051502145922747, "no_speech_prob": 8.267781595350243e-06}, {"id": 1497, "seek": 702806, "start": 7028.06, "end": 7030.06, "text": " four plus C activations", "tokens": [1451, 1804, 383, 2430, 763], "temperature": 0.0, "avg_logprob": -0.31242056150694153, "compression_ratio": 1.4879227053140096, "no_speech_prob": 1.3845730791217647e-05}, {"id": 1498, "seek": 702806, "start": 7033.900000000001, "end": 7040.660000000001, "text": " Followed by a non maximum suppression step to take that mass of gum and turn it into you know", "tokens": [9876, 292, 538, 257, 2107, 6674, 36807, 1823, 281, 747, 300, 2758, 295, 19973, 293, 1261, 309, 666, 291, 458], "temperature": 0.0, "avg_logprob": -0.31242056150694153, "compression_ratio": 1.4879227053140096, "no_speech_prob": 1.3845730791217647e-05}, {"id": 1499, "seek": 702806, "start": 7040.820000000001, "end": 7043.860000000001, "text": " Just a couple of non overlapping different objects", "tokens": [1449, 257, 1916, 295, 2107, 33535, 819, 6565], "temperature": 0.0, "avg_logprob": -0.31242056150694153, "compression_ratio": 1.4879227053140096, "no_speech_prob": 1.3845730791217647e-05}, {"id": 1500, "seek": 702806, "start": 7045.22, "end": 7052.8, "text": " The early layers are based on a standard architecture. So we just use resnet. This is pretty standard as you know, you can kind of see this", "tokens": [440, 2440, 7914, 366, 2361, 322, 257, 3832, 9482, 13, 407, 321, 445, 764, 725, 7129, 13, 639, 307, 1238, 3832, 382, 291, 458, 11, 291, 393, 733, 295, 536, 341], "temperature": 0.0, "avg_logprob": -0.31242056150694153, "compression_ratio": 1.4879227053140096, "no_speech_prob": 1.3845730791217647e-05}, {"id": 1501, "seek": 705280, "start": 7052.8, "end": 7058.64, "text": " consistent theme particularly in kind of how the fast AI library tries to do things which is like", "tokens": [8398, 6314, 4098, 294, 733, 295, 577, 264, 2370, 7318, 6405, 9898, 281, 360, 721, 597, 307, 411], "temperature": 0.0, "avg_logprob": -0.26826176498875476, "compression_ratio": 1.6964980544747081, "no_speech_prob": 1.2218903066241182e-05}, {"id": 1502, "seek": 705280, "start": 7058.92, "end": 7063.56, "text": " Grab a pre-trained network that already does something pull off the end bit stick on a new end bit", "tokens": [20357, 257, 659, 12, 17227, 2001, 3209, 300, 1217, 775, 746, 2235, 766, 264, 917, 857, 2897, 322, 257, 777, 917, 857], "temperature": 0.0, "avg_logprob": -0.26826176498875476, "compression_ratio": 1.6964980544747081, "no_speech_prob": 1.2218903066241182e-05}, {"id": 1503, "seek": 705280, "start": 7063.72, "end": 7067.28, "text": " Right. So early network players if we use the standard", "tokens": [1779, 13, 407, 2440, 3209, 4150, 498, 321, 764, 264, 3832], "temperature": 0.0, "avg_logprob": -0.26826176498875476, "compression_ratio": 1.6964980544747081, "no_speech_prob": 1.2218903066241182e-05}, {"id": 1504, "seek": 705280, "start": 7067.84, "end": 7069.2, "text": " classifier", "tokens": [1508, 9902], "temperature": 0.0, "avg_logprob": -0.26826176498875476, "compression_ratio": 1.6964980544747081, "no_speech_prob": 1.2218903066241182e-05}, {"id": 1505, "seek": 705280, "start": 7069.2, "end": 7074.56, "text": " Truncate the classification layers as we always do that happens automatically when we use common learner", "tokens": [1765, 409, 66, 473, 264, 21538, 7914, 382, 321, 1009, 360, 300, 2314, 6772, 562, 321, 764, 2689, 33347], "temperature": 0.0, "avg_logprob": -0.26826176498875476, "compression_ratio": 1.6964980544747081, "no_speech_prob": 1.2218903066241182e-05}, {"id": 1506, "seek": 705280, "start": 7075.4400000000005, "end": 7079.320000000001, "text": " And we call this the base network some papers call that the backbone", "tokens": [400, 321, 818, 341, 264, 3096, 3209, 512, 10577, 818, 300, 264, 34889], "temperature": 0.0, "avg_logprob": -0.26826176498875476, "compression_ratio": 1.6964980544747081, "no_speech_prob": 1.2218903066241182e-05}, {"id": 1507, "seek": 707932, "start": 7079.32, "end": 7081.32, "text": " I know we call the backbone", "tokens": [286, 458, 321, 818, 264, 34889], "temperature": 0.0, "avg_logprob": -0.3309036011391498, "compression_ratio": 1.6598360655737705, "no_speech_prob": 1.0129880138265435e-05}, {"id": 1508, "seek": 707932, "start": 7082.2, "end": 7088.12, "text": " And we then add an auxiliary structure. Okay, so the auxiliary structure which we call the custom head", "tokens": [400, 321, 550, 909, 364, 43741, 3877, 13, 1033, 11, 370, 264, 43741, 3877, 597, 321, 818, 264, 2375, 1378], "temperature": 0.0, "avg_logprob": -0.3309036011391498, "compression_ratio": 1.6598360655737705, "no_speech_prob": 1.0129880138265435e-05}, {"id": 1509, "seek": 707932, "start": 7089.08, "end": 7092.12, "text": " Has multi-scale feature mass so we add", "tokens": [8646, 4825, 12, 20033, 4111, 2758, 370, 321, 909], "temperature": 0.0, "avg_logprob": -0.3309036011391498, "compression_ratio": 1.6598360655737705, "no_speech_prob": 1.0129880138265435e-05}, {"id": 1510, "seek": 707932, "start": 7092.759999999999, "end": 7100.12, "text": " convolutional layers to the end of this base network and they decrease in size aggressively so a bunch of stride to", "tokens": [45216, 304, 7914, 281, 264, 917, 295, 341, 3096, 3209, 293, 436, 11514, 294, 2744, 32024, 370, 257, 3840, 295, 1056, 482, 281], "temperature": 0.0, "avg_logprob": -0.3309036011391498, "compression_ratio": 1.6598360655737705, "no_speech_prob": 1.0129880138265435e-05}, {"id": 1511, "seek": 707932, "start": 7100.88, "end": 7102.48, "text": " complex", "tokens": [3997], "temperature": 0.0, "avg_logprob": -0.3309036011391498, "compression_ratio": 1.6598360655737705, "no_speech_prob": 1.0129880138265435e-05}, {"id": 1512, "seek": 707932, "start": 7102.48, "end": 7105.44, "text": " So that allows predictions of detections and multiple scales", "tokens": [407, 300, 4045, 21264, 295, 5531, 626, 293, 3866, 17408], "temperature": 0.0, "avg_logprob": -0.3309036011391498, "compression_ratio": 1.6598360655737705, "no_speech_prob": 1.0129880138265435e-05}, {"id": 1513, "seek": 710544, "start": 7105.44, "end": 7109.48, "text": " The grid cells are different size of the edge of these right?", "tokens": [440, 10748, 5438, 366, 819, 2744, 295, 264, 4691, 295, 613, 558, 30], "temperature": 0.0, "avg_logprob": -0.43354007809661155, "compression_ratio": 1.6076555023923444, "no_speech_prob": 5.862739271833561e-06}, {"id": 1514, "seek": 710544, "start": 7110.639999999999, "end": 7115.28, "text": " The model is different for each feature layer", "tokens": [440, 2316, 307, 819, 337, 1184, 4111, 4583], "temperature": 0.0, "avg_logprob": -0.43354007809661155, "compression_ratio": 1.6076555023923444, "no_speech_prob": 5.862739271833561e-06}, {"id": 1515, "seek": 710544, "start": 7115.679999999999, "end": 7119.639999999999, "text": " Compared to YOLO that operate on a single feature map", "tokens": [30539, 281, 398, 5046, 46, 300, 9651, 322, 257, 2167, 4111, 4471], "temperature": 0.0, "avg_logprob": -0.43354007809661155, "compression_ratio": 1.6076555023923444, "no_speech_prob": 5.862739271833561e-06}, {"id": 1516, "seek": 710544, "start": 7119.639999999999, "end": 7124.4, "text": " So YOLO as we discussed is that is one vector whereas we have different", "tokens": [407, 398, 5046, 46, 382, 321, 7152, 307, 300, 307, 472, 8062, 9735, 321, 362, 819], "temperature": 0.0, "avg_logprob": -0.43354007809661155, "compression_ratio": 1.6076555023923444, "no_speech_prob": 5.862739271833561e-06}, {"id": 1517, "seek": 710544, "start": 7125.08, "end": 7127.0, "text": " complex", "tokens": [3997], "temperature": 0.0, "avg_logprob": -0.43354007809661155, "compression_ratio": 1.6076555023923444, "no_speech_prob": 5.862739271833561e-06}, {"id": 1518, "seek": 710544, "start": 7127.0, "end": 7129.0, "text": " each added feature layer", "tokens": [1184, 3869, 4111, 4583], "temperature": 0.0, "avg_logprob": -0.43354007809661155, "compression_ratio": 1.6076555023923444, "no_speech_prob": 5.862739271833561e-06}, {"id": 1519, "seek": 710544, "start": 7129.639999999999, "end": 7134.04, "text": " Gives you a fixed set of predictions using a bunch of filters, right?", "tokens": [460, 1539, 291, 257, 6806, 992, 295, 21264, 1228, 257, 3840, 295, 15995, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.43354007809661155, "compression_ratio": 1.6076555023923444, "no_speech_prob": 5.862739271833561e-06}, {"id": 1520, "seek": 713404, "start": 7134.04, "end": 7135.12, "text": " for", "tokens": [337], "temperature": 0.0, "avg_logprob": -0.29015933635622954, "compression_ratio": 1.544378698224852, "no_speech_prob": 6.854266757727601e-06}, {"id": 1521, "seek": 713404, "start": 7135.12, "end": 7138.8, "text": " a filter layer where the grid size is n by n", "tokens": [257, 6608, 4583, 689, 264, 10748, 2744, 307, 297, 538, 297], "temperature": 0.0, "avg_logprob": -0.29015933635622954, "compression_ratio": 1.544378698224852, "no_speech_prob": 6.854266757727601e-06}, {"id": 1522, "seek": 713404, "start": 7139.44, "end": 7142.72, "text": " 4 by 4 with p channels one fact", "tokens": [1017, 538, 1017, 365, 280, 9235, 472, 1186], "temperature": 0.0, "avg_logprob": -0.29015933635622954, "compression_ratio": 1.544378698224852, "no_speech_prob": 6.854266757727601e-06}, {"id": 1523, "seek": 713404, "start": 7142.72, "end": 7146.94, "text": " Let's take the previous one 7 by 7 with 5 12 channels", "tokens": [961, 311, 747, 264, 3894, 472, 1614, 538, 1614, 365, 1025, 2272, 9235], "temperature": 0.0, "avg_logprob": -0.29015933635622954, "compression_ratio": 1.544378698224852, "no_speech_prob": 6.854266757727601e-06}, {"id": 1524, "seek": 713404, "start": 7147.32, "end": 7152.2, "text": " The basic element is going to be a 3 by 3 by p kernel", "tokens": [440, 3875, 4478, 307, 516, 281, 312, 257, 805, 538, 805, 538, 280, 28256], "temperature": 0.0, "avg_logprob": -0.29015933635622954, "compression_ratio": 1.544378698224852, "no_speech_prob": 6.854266757727601e-06}, {"id": 1525, "seek": 713404, "start": 7153.12, "end": 7155.12, "text": " which in our case is a", "tokens": [597, 294, 527, 1389, 307, 257], "temperature": 0.0, "avg_logprob": -0.29015933635622954, "compression_ratio": 1.544378698224852, "no_speech_prob": 6.854266757727601e-06}, {"id": 1526, "seek": 713404, "start": 7156.04, "end": 7158.04, "text": " 3 by 3 by", "tokens": [805, 538, 805, 538], "temperature": 0.0, "avg_logprob": -0.29015933635622954, "compression_ratio": 1.544378698224852, "no_speech_prob": 6.854266757727601e-06}, {"id": 1527, "seek": 713404, "start": 7158.08, "end": 7163.0, "text": " 4 for the shape offset bit or 3 by 3 by", "tokens": [1017, 337, 264, 3909, 18687, 857, 420, 805, 538, 805, 538], "temperature": 0.0, "avg_logprob": -0.29015933635622954, "compression_ratio": 1.544378698224852, "no_speech_prob": 6.854266757727601e-06}, {"id": 1528, "seek": 716300, "start": 7163.0, "end": 7165.84, "text": " C for the score for a category D", "tokens": [383, 337, 264, 6175, 337, 257, 7719, 413], "temperature": 0.0, "avg_logprob": -0.2796498630823714, "compression_ratio": 1.7488151658767772, "no_speech_prob": 5.255345513432985e-06}, {"id": 1529, "seek": 716300, "start": 7165.84, "end": 7172.24, "text": " All right, so those are those three those are those two pieces at each of those grid cell locations", "tokens": [1057, 558, 11, 370, 729, 366, 729, 1045, 729, 366, 729, 732, 3755, 412, 1184, 295, 729, 10748, 2815, 9253], "temperature": 0.0, "avg_logprob": -0.2796498630823714, "compression_ratio": 1.7488151658767772, "no_speech_prob": 5.255345513432985e-06}, {"id": 1530, "seek": 716300, "start": 7172.48, "end": 7175.04, "text": " it's going to produce an output value and", "tokens": [309, 311, 516, 281, 5258, 364, 5598, 2158, 293], "temperature": 0.0, "avg_logprob": -0.2796498630823714, "compression_ratio": 1.7488151658767772, "no_speech_prob": 5.255345513432985e-06}, {"id": 1531, "seek": 716300, "start": 7176.2, "end": 7178.2, "text": " the bounding box offsets", "tokens": [264, 5472, 278, 2424, 39457, 1385], "temperature": 0.0, "avg_logprob": -0.2796498630823714, "compression_ratio": 1.7488151658767772, "no_speech_prob": 5.255345513432985e-06}, {"id": 1532, "seek": 716300, "start": 7179.2, "end": 7181.2, "text": " measured relative to", "tokens": [12690, 4972, 281], "temperature": 0.0, "avg_logprob": -0.2796498630823714, "compression_ratio": 1.7488151658767772, "no_speech_prob": 5.255345513432985e-06}, {"id": 1533, "seek": 716300, "start": 7181.48, "end": 7186.64, "text": " That default box position which we've been calling an anchor box position", "tokens": [663, 7576, 2424, 2535, 597, 321, 600, 668, 5141, 364, 18487, 2424, 2535], "temperature": 0.0, "avg_logprob": -0.2796498630823714, "compression_ratio": 1.7488151658767772, "no_speech_prob": 5.255345513432985e-06}, {"id": 1534, "seek": 718664, "start": 7186.64, "end": 7192.4400000000005, "text": " Relative to the feature map location what we've been calling the grid cell", "tokens": [8738, 1166, 281, 264, 4111, 4471, 4914, 437, 321, 600, 668, 5141, 264, 10748, 2815], "temperature": 0.0, "avg_logprob": -0.2475575422629332, "compression_ratio": 1.5707070707070707, "no_speech_prob": 2.769394086499233e-06}, {"id": 1535, "seek": 718664, "start": 7194.0, "end": 7196.0, "text": " Okay as opposed to YOLO", "tokens": [1033, 382, 8851, 281, 398, 5046, 46], "temperature": 0.0, "avg_logprob": -0.2475575422629332, "compression_ratio": 1.5707070707070707, "no_speech_prob": 2.769394086499233e-06}, {"id": 1536, "seek": 718664, "start": 7197.08, "end": 7199.240000000001, "text": " Right which has a fully connected layer", "tokens": [1779, 597, 575, 257, 4498, 4582, 4583], "temperature": 0.0, "avg_logprob": -0.2475575422629332, "compression_ratio": 1.5707070707070707, "no_speech_prob": 2.769394086499233e-06}, {"id": 1537, "seek": 718664, "start": 7200.52, "end": 7204.68, "text": " And then they go on to describe the default boxes", "tokens": [400, 550, 436, 352, 322, 281, 6786, 264, 7576, 9002], "temperature": 0.0, "avg_logprob": -0.2475575422629332, "compression_ratio": 1.5707070707070707, "no_speech_prob": 2.769394086499233e-06}, {"id": 1538, "seek": 718664, "start": 7205.280000000001, "end": 7208.88, "text": " What they are for each feature map cell or what we would say grid cell", "tokens": [708, 436, 366, 337, 1184, 4111, 4471, 2815, 420, 437, 321, 576, 584, 10748, 2815], "temperature": 0.0, "avg_logprob": -0.2475575422629332, "compression_ratio": 1.5707070707070707, "no_speech_prob": 2.769394086499233e-06}, {"id": 1539, "seek": 718664, "start": 7209.56, "end": 7212.4400000000005, "text": " They tile the feature map in a convolutional manner", "tokens": [814, 20590, 264, 4111, 4471, 294, 257, 45216, 304, 9060], "temperature": 0.0, "avg_logprob": -0.2475575422629332, "compression_ratio": 1.5707070707070707, "no_speech_prob": 2.769394086499233e-06}, {"id": 1540, "seek": 721244, "start": 7212.44, "end": 7216.48, "text": " So the position of each box relative to its grid cell is test", "tokens": [407, 264, 2535, 295, 1184, 2424, 4972, 281, 1080, 10748, 2815, 307, 1500], "temperature": 0.0, "avg_logprob": -0.3133208509804546, "compression_ratio": 1.471264367816092, "no_speech_prob": 5.014687758375658e-06}, {"id": 1541, "seek": 721244, "start": 7217.839999999999, "end": 7223.5199999999995, "text": " So hopefully you can see you know we end up with C plus 4 times K", "tokens": [407, 4696, 291, 393, 536, 291, 458, 321, 917, 493, 365, 383, 1804, 1017, 1413, 591], "temperature": 0.0, "avg_logprob": -0.3133208509804546, "compression_ratio": 1.471264367816092, "no_speech_prob": 5.014687758375658e-06}, {"id": 1542, "seek": 721244, "start": 7224.4, "end": 7226.4, "text": " filters if there are", "tokens": [15995, 498, 456, 366], "temperature": 0.0, "avg_logprob": -0.3133208509804546, "compression_ratio": 1.471264367816092, "no_speech_prob": 5.014687758375658e-06}, {"id": 1543, "seek": 721244, "start": 7226.599999999999, "end": 7228.599999999999, "text": " K boxes at each location", "tokens": [591, 9002, 412, 1184, 4914], "temperature": 0.0, "avg_logprob": -0.3133208509804546, "compression_ratio": 1.471264367816092, "no_speech_prob": 5.014687758375658e-06}, {"id": 1544, "seek": 721244, "start": 7232.0, "end": 7237.799999999999, "text": " So these are similar to the anchor boxes described in faster rc-net so like if you", "tokens": [407, 613, 366, 2531, 281, 264, 18487, 9002, 7619, 294, 4663, 367, 66, 12, 7129, 370, 411, 498, 291], "temperature": 0.0, "avg_logprob": -0.3133208509804546, "compression_ratio": 1.471264367816092, "no_speech_prob": 5.014687758375658e-06}, {"id": 1545, "seek": 723780, "start": 7237.8, "end": 7245.88, "text": " To jump straight in and read a paper like this without knowing like what problem they're solving and why are they solving it?", "tokens": [1407, 3012, 2997, 294, 293, 1401, 257, 3035, 411, 341, 1553, 5276, 411, 437, 1154, 436, 434, 12606, 293, 983, 366, 436, 12606, 309, 30], "temperature": 0.0, "avg_logprob": -0.24892956018447876, "compression_ratio": 1.6482213438735178, "no_speech_prob": 2.3320494619838428e-06}, {"id": 1546, "seek": 723780, "start": 7245.88, "end": 7247.88, "text": " And what's the kind of no magnitude so forth?", "tokens": [400, 437, 311, 264, 733, 295, 572, 15668, 370, 5220, 30], "temperature": 0.0, "avg_logprob": -0.24892956018447876, "compression_ratio": 1.6482213438735178, "no_speech_prob": 2.3320494619838428e-06}, {"id": 1547, "seek": 723780, "start": 7248.4400000000005, "end": 7251.320000000001, "text": " Those four paragraphs would probably make almost no sense", "tokens": [3950, 1451, 48910, 576, 1391, 652, 1920, 572, 2020], "temperature": 0.0, "avg_logprob": -0.24892956018447876, "compression_ratio": 1.6482213438735178, "no_speech_prob": 2.3320494619838428e-06}, {"id": 1548, "seek": 723780, "start": 7251.92, "end": 7256.52, "text": " But now that we've gone through it you read those four paragraphs and hopefully you're thinking oh", "tokens": [583, 586, 300, 321, 600, 2780, 807, 309, 291, 1401, 729, 1451, 48910, 293, 4696, 291, 434, 1953, 1954], "temperature": 0.0, "avg_logprob": -0.24892956018447876, "compression_ratio": 1.6482213438735178, "no_speech_prob": 2.3320494619838428e-06}, {"id": 1549, "seek": 723780, "start": 7257.320000000001, "end": 7262.320000000001, "text": " That's just what Jeremy said only they said it better than Jeremy in less words. Okay", "tokens": [663, 311, 445, 437, 17809, 848, 787, 436, 848, 309, 1101, 813, 17809, 294, 1570, 2283, 13, 1033], "temperature": 0.0, "avg_logprob": -0.24892956018447876, "compression_ratio": 1.6482213438735178, "no_speech_prob": 2.3320494619838428e-06}, {"id": 1550, "seek": 726232, "start": 7262.32, "end": 7266.32, "text": " So so", "tokens": [407, 370], "temperature": 0.0, "avg_logprob": -0.34744926293691, "compression_ratio": 1.6176470588235294, "no_speech_prob": 6.240869424800621e-06}, {"id": 1551, "seek": 726232, "start": 7267.719999999999, "end": 7272.48, "text": " I have the same problem when I started reading the SSD paper, and I read those four paragraphs", "tokens": [286, 362, 264, 912, 1154, 562, 286, 1409, 3760, 264, 30262, 3035, 11, 293, 286, 1401, 729, 1451, 48910], "temperature": 0.0, "avg_logprob": -0.34744926293691, "compression_ratio": 1.6176470588235294, "no_speech_prob": 6.240869424800621e-06}, {"id": 1552, "seek": 726232, "start": 7272.48, "end": 7278.44, "text": " And I don't didn't have before this time much of a background in object detection because I had decided to wait until", "tokens": [400, 286, 500, 380, 994, 380, 362, 949, 341, 565, 709, 295, 257, 3678, 294, 2657, 17784, 570, 286, 632, 3047, 281, 1699, 1826], "temperature": 0.0, "avg_logprob": -0.34744926293691, "compression_ratio": 1.6176470588235294, "no_speech_prob": 6.240869424800621e-06}, {"id": 1553, "seek": 726232, "start": 7278.759999999999, "end": 7281.4, "text": " These two parts anymore, and so I read this and I was like", "tokens": [1981, 732, 3166, 3602, 11, 293, 370, 286, 1401, 341, 293, 286, 390, 411], "temperature": 0.0, "avg_logprob": -0.34744926293691, "compression_ratio": 1.6176470588235294, "no_speech_prob": 6.240869424800621e-06}, {"id": 1554, "seek": 726232, "start": 7282.24, "end": 7285.12, "text": " What the hell right and so the trick is to?", "tokens": [708, 264, 4921, 558, 293, 370, 264, 4282, 307, 281, 30], "temperature": 0.0, "avg_logprob": -0.34744926293691, "compression_ratio": 1.6176470588235294, "no_speech_prob": 6.240869424800621e-06}, {"id": 1555, "seek": 726232, "start": 7286.679999999999, "end": 7290.5199999999995, "text": " Then start reading back over the citations right so for example", "tokens": [1396, 722, 3760, 646, 670, 264, 4814, 763, 558, 370, 337, 1365], "temperature": 0.0, "avg_logprob": -0.34744926293691, "compression_ratio": 1.6176470588235294, "no_speech_prob": 6.240869424800621e-06}, {"id": 1556, "seek": 729052, "start": 7290.52, "end": 7295.64, "text": " And you should go back and read this paper now look here's the matching strategy", "tokens": [400, 291, 820, 352, 646, 293, 1401, 341, 3035, 586, 574, 510, 311, 264, 14324, 5206], "temperature": 0.0, "avg_logprob": -0.20370525053177757, "compression_ratio": 1.6899563318777293, "no_speech_prob": 6.048868726793444e-06}, {"id": 1557, "seek": 729052, "start": 7296.320000000001, "end": 7301.76, "text": " Right and that whole matching strategy that I somehow spent like an hour talking about that's just a paragraph", "tokens": [1779, 293, 300, 1379, 14324, 5206, 300, 286, 6063, 4418, 411, 364, 1773, 1417, 466, 300, 311, 445, 257, 18865], "temperature": 0.0, "avg_logprob": -0.20370525053177757, "compression_ratio": 1.6899563318777293, "no_speech_prob": 6.048868726793444e-06}, {"id": 1558, "seek": 729052, "start": 7302.52, "end": 7304.52, "text": " But it really is right", "tokens": [583, 309, 534, 307, 558], "temperature": 0.0, "avg_logprob": -0.20370525053177757, "compression_ratio": 1.6899563318777293, "no_speech_prob": 6.048868726793444e-06}, {"id": 1559, "seek": 729052, "start": 7304.76, "end": 7311.160000000001, "text": " For each ground truth we select from default boxes based on location aspect ratio and scale", "tokens": [1171, 1184, 2727, 3494, 321, 3048, 490, 7576, 9002, 2361, 322, 4914, 4171, 8509, 293, 4373], "temperature": 0.0, "avg_logprob": -0.20370525053177757, "compression_ratio": 1.6899563318777293, "no_speech_prob": 6.048868726793444e-06}, {"id": 1560, "seek": 729052, "start": 7311.8, "end": 7316.080000000001, "text": " we match each ground truth to the default box with the best jacquard overlap and", "tokens": [321, 2995, 1184, 2727, 3494, 281, 264, 7576, 2424, 365, 264, 1151, 361, 326, 358, 515, 19959, 293], "temperature": 0.0, "avg_logprob": -0.20370525053177757, "compression_ratio": 1.6899563318777293, "no_speech_prob": 6.048868726793444e-06}, {"id": 1561, "seek": 731608, "start": 7316.08, "end": 7321.16, "text": " And then we match default boxes to anything with jacquard overlap higher than 0.5", "tokens": [400, 550, 321, 2995, 7576, 9002, 281, 1340, 365, 361, 326, 358, 515, 19959, 2946, 813, 1958, 13, 20], "temperature": 0.0, "avg_logprob": -0.25243252883722755, "compression_ratio": 1.54, "no_speech_prob": 4.860393801209284e-06}, {"id": 1562, "seek": 731608, "start": 7321.88, "end": 7324.96, "text": " That's it. That's the one sentence version", "tokens": [663, 311, 309, 13, 663, 311, 264, 472, 8174, 3037], "temperature": 0.0, "avg_logprob": -0.25243252883722755, "compression_ratio": 1.54, "no_speech_prob": 4.860393801209284e-06}, {"id": 1563, "seek": 731608, "start": 7326.32, "end": 7330.08, "text": " And then we've got the loss function which is basically to say", "tokens": [400, 550, 321, 600, 658, 264, 4470, 2445, 597, 307, 1936, 281, 584], "temperature": 0.0, "avg_logprob": -0.25243252883722755, "compression_ratio": 1.54, "no_speech_prob": 4.860393801209284e-06}, {"id": 1564, "seek": 731608, "start": 7331.44, "end": 7335.0, "text": " Take the average so divided by the number of the", "tokens": [3664, 264, 4274, 370, 6666, 538, 264, 1230, 295, 264], "temperature": 0.0, "avg_logprob": -0.25243252883722755, "compression_ratio": 1.54, "no_speech_prob": 4.860393801209284e-06}, {"id": 1565, "seek": 731608, "start": 7336.92, "end": 7341.96, "text": " Loss based on the classes plus the loss based on localization", "tokens": [441, 772, 2361, 322, 264, 5359, 1804, 264, 4470, 2361, 322, 2654, 2144], "temperature": 0.0, "avg_logprob": -0.25243252883722755, "compression_ratio": 1.54, "no_speech_prob": 4.860393801209284e-06}, {"id": 1566, "seek": 731608, "start": 7343.28, "end": 7344.84, "text": " with some", "tokens": [365, 512], "temperature": 0.0, "avg_logprob": -0.25243252883722755, "compression_ratio": 1.54, "no_speech_prob": 4.860393801209284e-06}, {"id": 1567, "seek": 734484, "start": 7344.84, "end": 7350.96, "text": " Waiting now with focal loss. I found I didn't really need the weighting factor anymore. They both had about the same scale", "tokens": [37291, 586, 365, 26592, 4470, 13, 286, 1352, 286, 994, 380, 534, 643, 264, 3364, 278, 5952, 3602, 13, 814, 1293, 632, 466, 264, 912, 4373], "temperature": 0.0, "avg_logprob": -0.2404318820224719, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.012986740533961e-05}, {"id": 1568, "seek": 734484, "start": 7351.92, "end": 7353.92, "text": " Just a coincidence perhaps", "tokens": [1449, 257, 22137, 4317], "temperature": 0.0, "avg_logprob": -0.2404318820224719, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.012986740533961e-05}, {"id": 1569, "seek": 734484, "start": 7355.16, "end": 7358.6, "text": " But in this case as I started reading this I didn't really understand", "tokens": [583, 294, 341, 1389, 382, 286, 1409, 3760, 341, 286, 994, 380, 534, 1223], "temperature": 0.0, "avg_logprob": -0.2404318820224719, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.012986740533961e-05}, {"id": 1570, "seek": 734484, "start": 7359.4800000000005, "end": 7363.2, "text": " Exactly what L and G and all this stuff was but it says well", "tokens": [7587, 437, 441, 293, 460, 293, 439, 341, 1507, 390, 457, 309, 1619, 731], "temperature": 0.0, "avg_logprob": -0.2404318820224719, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.012986740533961e-05}, {"id": 1571, "seek": 734484, "start": 7363.2, "end": 7368.6, "text": " This is derived from the multi box objective, so then I went back to the paper that defined", "tokens": [639, 307, 18949, 490, 264, 4825, 2424, 10024, 11, 370, 550, 286, 1437, 646, 281, 264, 3035, 300, 7642], "temperature": 0.0, "avg_logprob": -0.2404318820224719, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.012986740533961e-05}, {"id": 1572, "seek": 736860, "start": 7368.6, "end": 7377.200000000001, "text": " Multi box and I found in their proposed approach. They've also got a section called training objective also known as", "tokens": [29238, 2424, 293, 286, 1352, 294, 641, 10348, 3109, 13, 814, 600, 611, 658, 257, 3541, 1219, 3097, 10024, 611, 2570, 382], "temperature": 0.0, "avg_logprob": -0.235955083692396, "compression_ratio": 1.5, "no_speech_prob": 1.2606787095137406e-05}, {"id": 1573, "seek": 736860, "start": 7378.0, "end": 7380.0, "text": " loss function", "tokens": [4470, 2445], "temperature": 0.0, "avg_logprob": -0.235955083692396, "compression_ratio": 1.5, "no_speech_prob": 1.2606787095137406e-05}, {"id": 1574, "seek": 736860, "start": 7381.8, "end": 7383.6, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.235955083692396, "compression_ratio": 1.5, "no_speech_prob": 1.2606787095137406e-05}, {"id": 1575, "seek": 736860, "start": 7383.6, "end": 7386.08, "text": " Here I can see it's the same notation L", "tokens": [1692, 286, 393, 536, 309, 311, 264, 912, 24657, 441], "temperature": 0.0, "avg_logprob": -0.235955083692396, "compression_ratio": 1.5, "no_speech_prob": 1.2606787095137406e-05}, {"id": 1576, "seek": 736860, "start": 7386.6, "end": 7392.280000000001, "text": " G blah blah blah and so this is where I can go back and see the detail and", "tokens": [460, 12288, 12288, 12288, 293, 370, 341, 307, 689, 286, 393, 352, 646, 293, 536, 264, 2607, 293], "temperature": 0.0, "avg_logprob": -0.235955083692396, "compression_ratio": 1.5, "no_speech_prob": 1.2606787095137406e-05}, {"id": 1577, "seek": 736860, "start": 7393.360000000001, "end": 7395.08, "text": " After you read a bunch of papers", "tokens": [2381, 291, 1401, 257, 3840, 295, 10577], "temperature": 0.0, "avg_logprob": -0.235955083692396, "compression_ratio": 1.5, "no_speech_prob": 1.2606787095137406e-05}, {"id": 1578, "seek": 739508, "start": 7395.08, "end": 7399.68, "text": " You'll start to see things very quickly for example when you see these double bars to two", "tokens": [509, 603, 722, 281, 536, 721, 588, 2661, 337, 1365, 562, 291, 536, 613, 3834, 10228, 281, 732], "temperature": 0.0, "avg_logprob": -0.2090350047196492, "compression_ratio": 1.735042735042735, "no_speech_prob": 1.723125751595944e-05}, {"id": 1579, "seek": 739508, "start": 7400.32, "end": 7405.5599999999995, "text": " You'll realize every time there's mean squared error. That's how you write mean squared error, right?", "tokens": [509, 603, 4325, 633, 565, 456, 311, 914, 8889, 6713, 13, 663, 311, 577, 291, 2464, 914, 8889, 6713, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2090350047196492, "compression_ratio": 1.735042735042735, "no_speech_prob": 1.723125751595944e-05}, {"id": 1580, "seek": 739508, "start": 7405.5599999999995, "end": 7411.24, "text": " This is actually called the two norm the two norm is just the sum of squared differences, right?", "tokens": [639, 307, 767, 1219, 264, 732, 2026, 264, 732, 2026, 307, 445, 264, 2408, 295, 8889, 7300, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2090350047196492, "compression_ratio": 1.735042735042735, "no_speech_prob": 1.723125751595944e-05}, {"id": 1581, "seek": 739508, "start": 7411.24, "end": 7415.88, "text": " And then there's two up here means normally they take the square root. So we just don't do this", "tokens": [400, 550, 456, 311, 732, 493, 510, 1355, 5646, 436, 747, 264, 3732, 5593, 13, 407, 321, 445, 500, 380, 360, 341], "temperature": 0.0, "avg_logprob": -0.2090350047196492, "compression_ratio": 1.735042735042735, "no_speech_prob": 1.723125751595944e-05}, {"id": 1582, "seek": 739508, "start": 7416.88, "end": 7418.92, "text": " So this is just a MSE", "tokens": [407, 341, 307, 445, 257, 376, 5879], "temperature": 0.0, "avg_logprob": -0.2090350047196492, "compression_ratio": 1.735042735042735, "no_speech_prob": 1.723125751595944e-05}, {"id": 1583, "seek": 741892, "start": 7418.92, "end": 7425.6, "text": " But anytime you see like oh, here's a log C and here's log 1 minus C, you know, that's basically binary cross entropy", "tokens": [583, 13038, 291, 536, 411, 1954, 11, 510, 311, 257, 3565, 383, 293, 510, 311, 3565, 502, 3175, 383, 11, 291, 458, 11, 300, 311, 1936, 17434, 3278, 30867], "temperature": 0.0, "avg_logprob": -0.2806856470200622, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.045145108946599e-05}, {"id": 1584, "seek": 741892, "start": 7426.12, "end": 7428.12, "text": " right, so it's like", "tokens": [558, 11, 370, 309, 311, 411], "temperature": 0.0, "avg_logprob": -0.2806856470200622, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.045145108946599e-05}, {"id": 1585, "seek": 741892, "start": 7429.04, "end": 7435.52, "text": " You you're not actually going to have to read every bit of every equation, but you are kind of a bit at first", "tokens": [509, 291, 434, 406, 767, 516, 281, 362, 281, 1401, 633, 857, 295, 633, 5367, 11, 457, 291, 366, 733, 295, 257, 857, 412, 700], "temperature": 0.0, "avg_logprob": -0.2806856470200622, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.045145108946599e-05}, {"id": 1586, "seek": 741892, "start": 7436.04, "end": 7438.04, "text": " Right, but after a while", "tokens": [1779, 11, 457, 934, 257, 1339], "temperature": 0.0, "avg_logprob": -0.2806856470200622, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.045145108946599e-05}, {"id": 1587, "seek": 741892, "start": 7438.2, "end": 7441.36, "text": " Your brain just like immediately knows", "tokens": [2260, 3567, 445, 411, 4258, 3255], "temperature": 0.0, "avg_logprob": -0.2806856470200622, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.045145108946599e-05}, {"id": 1588, "seek": 741892, "start": 7442.4400000000005, "end": 7445.34, "text": " Basically what's going on and then I say oh, I've got a log C", "tokens": [8537, 437, 311, 516, 322, 293, 550, 286, 584, 1954, 11, 286, 600, 658, 257, 3565, 383], "temperature": 0.0, "avg_logprob": -0.2806856470200622, "compression_ratio": 1.6147186147186148, "no_speech_prob": 1.045145108946599e-05}, {"id": 1589, "seek": 744534, "start": 7445.34, "end": 7449.96, "text": " I'm log 1 minus C and as expected I should have my X and here's my 1 minus X", "tokens": [286, 478, 3565, 502, 3175, 383, 293, 382, 5176, 286, 820, 362, 452, 1783, 293, 510, 311, 452, 502, 3175, 1783], "temperature": 0.0, "avg_logprob": -0.20383386704528217, "compression_ratio": 1.706140350877193, "no_speech_prob": 5.014706857764395e-06}, {"id": 1590, "seek": 744534, "start": 7449.96, "end": 7453.76, "text": " Okay, there's all the pieces there that I would expect to see in the binary", "tokens": [1033, 11, 456, 311, 439, 264, 3755, 456, 300, 286, 576, 2066, 281, 536, 294, 264, 17434], "temperature": 0.0, "avg_logprob": -0.20383386704528217, "compression_ratio": 1.706140350877193, "no_speech_prob": 5.014706857764395e-06}, {"id": 1591, "seek": 744534, "start": 7454.76, "end": 7456.76, "text": " right", "tokens": [558], "temperature": 0.0, "avg_logprob": -0.20383386704528217, "compression_ratio": 1.706140350877193, "no_speech_prob": 5.014706857764395e-06}, {"id": 1592, "seek": 744534, "start": 7457.22, "end": 7461.400000000001, "text": " So then having done that that then kind of allowed me okay, and then they get combined", "tokens": [407, 550, 1419, 1096, 300, 300, 550, 733, 295, 4350, 385, 1392, 11, 293, 550, 436, 483, 9354], "temperature": 0.0, "avg_logprob": -0.20383386704528217, "compression_ratio": 1.706140350877193, "no_speech_prob": 5.014706857764395e-06}, {"id": 1593, "seek": 744534, "start": 7462.400000000001, "end": 7469.08, "text": " With the two pieces and all there's the multiplier that I expected and so now I can kind of come back here", "tokens": [2022, 264, 732, 3755, 293, 439, 456, 311, 264, 44106, 300, 286, 5176, 293, 370, 586, 286, 393, 733, 295, 808, 646, 510], "temperature": 0.0, "avg_logprob": -0.20383386704528217, "compression_ratio": 1.706140350877193, "no_speech_prob": 5.014706857764395e-06}, {"id": 1594, "seek": 744534, "start": 7470.360000000001, "end": 7473.12, "text": " Understand what's going on? Okay, so", "tokens": [26093, 437, 311, 516, 322, 30, 1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.20383386704528217, "compression_ratio": 1.706140350877193, "no_speech_prob": 5.014706857764395e-06}, {"id": 1595, "seek": 747312, "start": 7473.12, "end": 7478.72, "text": " We're going to be looking at a lot more papers, right? But maybe this week", "tokens": [492, 434, 516, 281, 312, 1237, 412, 257, 688, 544, 10577, 11, 558, 30, 583, 1310, 341, 1243], "temperature": 0.0, "avg_logprob": -0.24047618688539016, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.23774747812422e-06}, {"id": 1596, "seek": 747312, "start": 7480.0, "end": 7484.46, "text": " Go through the code and go through the paper. All right and be like", "tokens": [1037, 807, 264, 3089, 293, 352, 807, 264, 3035, 13, 1057, 558, 293, 312, 411], "temperature": 0.0, "avg_logprob": -0.24047618688539016, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.23774747812422e-06}, {"id": 1597, "seek": 747312, "start": 7485.48, "end": 7489.099999999999, "text": " What's what's going on? And remember what I did?", "tokens": [708, 311, 437, 311, 516, 322, 30, 400, 1604, 437, 286, 630, 30], "temperature": 0.0, "avg_logprob": -0.24047618688539016, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.23774747812422e-06}, {"id": 1598, "seek": 747312, "start": 7489.68, "end": 7493.5599999999995, "text": " to make it easier for you was I took that loss function I", "tokens": [281, 652, 309, 3571, 337, 291, 390, 286, 1890, 300, 4470, 2445, 286], "temperature": 0.0, "avg_logprob": -0.24047618688539016, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.23774747812422e-06}, {"id": 1599, "seek": 747312, "start": 7494.5199999999995, "end": 7499.24, "text": " copied it into a cell and then I split it up so that each bit", "tokens": [25365, 309, 666, 257, 2815, 293, 550, 286, 7472, 309, 493, 370, 300, 1184, 857], "temperature": 0.0, "avg_logprob": -0.24047618688539016, "compression_ratio": 1.5628140703517588, "no_speech_prob": 3.23774747812422e-06}, {"id": 1600, "seek": 749924, "start": 7499.24, "end": 7505.12, "text": " Was in a separate cell and then after every cell I either printed or plotted", "tokens": [3027, 294, 257, 4994, 2815, 293, 550, 934, 633, 2815, 286, 2139, 13567, 420, 43288], "temperature": 0.0, "avg_logprob": -0.29835117294127683, "compression_ratio": 1.5161290322580645, "no_speech_prob": 4.157353032496758e-06}, {"id": 1601, "seek": 749924, "start": 7506.5599999999995, "end": 7508.0, "text": " That value", "tokens": [663, 2158], "temperature": 0.0, "avg_logprob": -0.29835117294127683, "compression_ratio": 1.5161290322580645, "no_speech_prob": 4.157353032496758e-06}, {"id": 1602, "seek": 749924, "start": 7508.0, "end": 7512.04, "text": " Right so if I hadn't have done that for you you should do it yourself", "tokens": [1779, 370, 498, 286, 8782, 380, 362, 1096, 300, 337, 291, 291, 820, 360, 309, 1803], "temperature": 0.0, "avg_logprob": -0.29835117294127683, "compression_ratio": 1.5161290322580645, "no_speech_prob": 4.157353032496758e-06}, {"id": 1603, "seek": 749924, "start": 7512.32, "end": 7515.28, "text": " But like this is no way you can understand these functions", "tokens": [583, 411, 341, 307, 572, 636, 291, 393, 1223, 613, 6828], "temperature": 0.0, "avg_logprob": -0.29835117294127683, "compression_ratio": 1.5161290322580645, "no_speech_prob": 4.157353032496758e-06}, {"id": 1604, "seek": 749924, "start": 7515.92, "end": 7520.44, "text": " Without trying putting things in and seeing what comes out. Okay, so", "tokens": [9129, 1382, 3372, 721, 294, 293, 2577, 437, 1487, 484, 13, 1033, 11, 370], "temperature": 0.0, "avg_logprob": -0.29835117294127683, "compression_ratio": 1.5161290322580645, "no_speech_prob": 4.157353032496758e-06}, {"id": 1605, "seek": 749924, "start": 7521.639999999999, "end": 7523.639999999999, "text": " Hopefully this is kind of a good", "tokens": [10429, 341, 307, 733, 295, 257, 665], "temperature": 0.0, "avg_logprob": -0.29835117294127683, "compression_ratio": 1.5161290322580645, "no_speech_prob": 4.157353032496758e-06}, {"id": 1606, "seek": 749924, "start": 7525.04, "end": 7526.8, "text": " Good study", "tokens": [2205, 2979], "temperature": 0.0, "avg_logprob": -0.29835117294127683, "compression_ratio": 1.5161290322580645, "no_speech_prob": 4.157353032496758e-06}, {"id": 1607, "seek": 752680, "start": 7526.8, "end": 7530.24, "text": " Right. Well, thanks everybody. Have a great week and see you next Monday", "tokens": [50364, 1779, 13, 1042, 11, 3231, 2201, 13, 3560, 257, 869, 1243, 293, 536, 291, 958, 8138, 50536], "temperature": 0.0, "avg_logprob": -0.18883503110785232, "compression_ratio": 0.96, "no_speech_prob": 1.567671642987989e-05}], "language": "en"}