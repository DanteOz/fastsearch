{"text": " Okay, hi there everybody. Can you see in here okay? Great. Okay, let me know if anybody has any requests. This will be the last walkthrough, at least for a while, because we've covered most of the main stuff, other than what's in Lerner and Optimizer and stuff, which is largely the same as what was in the course in version, part two, version three of the course. We might do another, we'll probably do another walkthrough in a couple of weeks or so to cover the little differences, I suspect. But we can have a quick look at the image net tutorial today as well. But mainly I was going to look at the data augmentation and finish off a little bit more of the stuff that's in core. But yeah, just ask any questions if this stuff either we haven't covered or you didn't quite follow or you don't quite know how it fits together. Excuse me. In the meantime, we'll get back to core. And so you can see in core, other than meta classes, which we're probably going to be largely getting rid of, so we'll ignore that. There was, there's the kind of decorators and stuff we talked about. There's Gadatra, there's L, and then there's a bunch of stuff. And the bunch of stuff is, broadly speaking, stuff for collections, types, functions about functions, file and network. So in terms of stuff that's interesting, one thing that's kind of interesting is make class. Make class is a replacement for typing class. So basically, I'll just make sure I've done a pull here. There we go. So basically this one here, make class t equals one super equals get extra. Is the same as typing this class and the score T get extra. Colon a equals one. So those are basically two ways of doing the same thing, except that this version has a bit of extra functionality. Oh, let me think. What does it do? It's been a while since I've looked at this one. Yes. Okay. So the class that we get back works kind of a bit more like a data class from the Python data classes standard library thing. So you can kind of see and behind the scenes it calls this thing called get class, which is actually kind of what does the work. So you can see that we can pass in, for instance, a says that we will get something called as you see here to a. Let's try that. So we could go t equals underscore t. There we go. Okay. T.A. And so you can see that if we just pass in something saying this is a field, so we see we first pass in a list of fields and we get that as an empty field, you can pass in a value for it. And so that will mean that field, the first field listed a will get that value. As you can see, you can pass in keyword argument fields. So in this case, be here. You can initialize like this. There it is. You can also pass in functions that you want to be included. So, for example, define F self. Grant. And so then we could say. Bunks equals. F. And so now we'll have an underscore F. What did I do wrong there? Functions. No funds. And. What did I do wrong? Let's have a look. So maybe I should get rid of the other score that might be confusing for it because that's normally hidden. T. Oh, sorry, I'm being silly. We need to recreate it. So we need to go. I'm going crazy. So we have to create the class. Bunks. Is there. We had a. And we had B equals two. Right. And so now. There we go. It's our function. Let's see. We get a rep for free. Let's try that one. Yep, there we go. So you can see I can just type T. You'll see that the rep for isn't added if you put in a superclass because the superclass might have its own rep. So basically by using this make class, we can quickly create a little it's kind of good for tests and stuff. We can create a quick class which has, you know, some key values that we want and fields that we want. You can initialize it. It's got a representation. So that's pretty handy little handy little thing that we use quite often in the tests. Let's have a look actually see if it's also used in the actual main code base. So let's look for make class. OK, it's used occasionally. So here's an example. One of usages inside layers. So let's take a look at that. OK, so here's the example of in layers. It's creating a class called pool type. And it has a bunch of. Fields in it. So this is actually a really good example of something that we do occasionally. So let's use that to see how it works. So let's see what does pool type now look like. So we're going through average, Max, cat and creating a dictionary. So if we go to let's just go pool. Type. Dot tab and you can see average cat and Max. This is actually a really nice way of creating kind of in on the strings or kind of strings that have, you know, nice tab completion. So that's a good use of make class. Here you go. Doing exactly the same here for pad mode. It's actually the same here for resize method. So other than that. Oh, here's one again that's using getting all the events for callbacks. And then in the note. No space. In the note. Yeah, you can see we use it sometimes to create little quick and dirty things for testing. So we kind of tend to use it instead of data classes because we find it a bit more convenient sometimes. So Kevin asked about multiple inheritance. So. Yeah. So multiple inheritance is pretty widely covered in. Python tutorials. So I won't go into detail, but if you go to Python multiple inheritance. You will find lots of examples, but the answer is, yeah, basically you have multiple base classes. So what will happen is that when you look in super for something, it will first look in here. If it doesn't find it, then it will look in here. That's basically what multiple inheritance does. So in this case, we wanted this to contain all of the basic collection stuff. And we also wanted it to have the get atra. So this means we now have both. Right. What else have we got here? In functions. Wrap class is something that just takes a function and wraps it into a class by calling make class. So sometimes that's handy for tests where you want to quickly create something that you can test methods on. No worries, Kevin. The collection functions worth knowing about, but they're pretty simple. So like couple of fire to turn something into a couple. Unique a fire to get the unique values of something set a fire to turn something into a set. Group by is super handy. It. Takes a list like this and groups it by some function. So this case, a a b b b being grouped by item get a zero is going to group by the first letter. So a is a b a b and b is b b. That's a very handy function. There's something called it a tools group by in Python standard library. I find this one more convenient and less complicated to understand. Merging dictionaries is often handy. So it just does what it suggests. Merge the dictionaries together. OK, yes, so here are me 30. Is the text stuff we probably will do a walkthrough with the text stuff. But we haven't really gone back over it to see whether the ideas from tabular could be used there because we wrote the 30 stuff first before we did tabular. But we might be able to refactor text using in place transform. I'm not sure. So if we do end up with two different approaches, we'll explain why. Hopefully we won't because it's nice not to have to have two different approaches. Oh, this is fun. I don't use this very much, but I possibly could use it more as more of an exploration of some functional programming ideas. So this is basically something where I'm creating all of these things as functions less than greater than less than equal greater than equal, et cetera. They are all functions that exist within the operator module in the Python standard library. And these functions work the same way. Best than three comma five is true, greater than three comma five is false. But they also allow you to do what's called carrying, as you can see here. And specifically, this is helpful. Where you can kind of go F equals the LTE three. And then I could and then I could do F five. So just putting that into two lines. And the reason that's interesting. Is so I could do stuff like L dot range. Eight. So let's pick those ones. Let's say we had some list. We wanted to grab those, which are less than three. I could go filtered LTE three. Like so. And so that's just a lot more convenient than writing the normal way, which would be. Lambda X colon X is less than three. So this kind of thing is pretty common, like pretty much all functional languages allow you to do carrying like this. Unfortunately, Python doesn't, but you can kind of create versions that do work that way. And as you can see, the way I'm doing it is I've got this little opera thing, which if you pass in only one thing, then B is none. Then it returns a lambda. Otherwise, it does the actual operation. And so that is handy with some of this extra stuff that I'm going to show here, for example. I've created a infinite lists class so that you can do things like an infinite count is is arranged from zero to infinity. So I could do, for instance, list filter in dot count comma less than 10. Oops, run those. Wrong way around filter in Python first takes a function. Less than 10 comma count. Now, that's interesting. Why isn't that working? Never mind. We can do it this way. Zip range. Five comma fifteen. Comma in dot count. And then list that. OK, there we go. So you can see that the numbers coming from in that count are just the numbers counting up. So we could do things like. Rest it to tools dot I slice in dot count comma 10. Or we could map. And X colon X times two. So and so forth. You could replace in stock count with in zeros. As you can see, or in ones. So it's often really handy to be able to have quick infinite lists available to you. We use that, for example, in the data loader. So that's basically why this is here. It's actually very challenging. In I mean, not challenging, it's kind of it's just it's awkward in Python to be able to create a property like this that behaves this way. The only way I could do it was to make it into a meta class and put the properties in the meta class and then make that meta class. Meta class. The thing I actually want. So it's not too bad, but it's a little more awkward than would be ideal. It's often useful to be able to do a an expression that returns that raises an exception. So something like a equals three. A is greater than five or stop. And so you can raise an exception in this way. So I do that quite often. So when you see stop, I particularly use that by default. It raises a stop iteration, which is what Python uses when you finish iterating through a list. But you can do anything like if you can see. Oh, this is this is a good example of how to use that. So I've created a generator function that is a lot like a map, but it allows us to do this handle stop iteration nicely. So we can generate from some function over some sequence. So it's basically like a map as long as some condition is true. So, for example, do no up over count while less than five. And that's going to be returned the same as range five or operator negative over an infinite count. Well, it's greater than negative five. We'll return this. Well, here's an example which does not have a condition, but instead the actual mapping function has a stop in it. So look over an infinite list, return itself if always less than five, otherwise stop. So this is actually a super nice way of doing kind of functional stuff in Python. Chunked we briefly saw because it was in data loader and the behavior you can kind of see you start with a range example and chunk into groups of three. And this is how we do batching in the data loader. Retained type we've seen. Most of these types we've seen show title. So that's fine. Trace is super handy. If I have a let me give you an example. So let's say I'm creating, I don't know, some list.Matched lambda. O, O colon O times two. So I've got something like this, right? And so I've got a passing a function or lambda into something and I want to debug something like something like this. Actually, so like a good example would be what if I was doing this? Whoops, I should say negative. OK, and maybe it's not working the way I expected. So I want to debug it. You can use trace to turn any function into a traced version of that function. Like so. And so now I can step into if I step, I will be stepping into operator dot negative. Which it looks like I can't step into because I guess that's written not in Python. That's annoying. Let's create our own version then. Def neg. Just for this example. Return neg X. There we go. Step. OK, and there you go. Here we are. We've stepped into neg. So this is a really handy for debugging stuff, particularly where you're doing map or something like that, passing in some function that might be from fast AI or the Python standard library or PyTorch, whatever. And as you can see, it's very simple. We just stick a set trace and then return the same function. Composed as function composition. Map does the same as map, but you can pass in multiple functions. Yeah, they're all pretty self explanatory and then these are the ones we're not really using at the moment. So don't worry about that. If you look at any of those other things and decide you're interested, feel free to ask on the forums. LS we've looked at. This is interesting. Something like B unzip. It's interesting to note that the Python standard library has a Bzip standard library function, but it doesn't do simple things like unzip something in a path. So here's a little function that just does that. It just takes a path and unzips it with Bzip using the standard library. So you don't have to call out to a, you know, external process. So this kind of thing is very useful to create cross platform compatible code. Okay. So as you can see, it's kind of a bit of a mishmash of stuff that we've kind of thrown in there as we've needed it. Main thing I wanted to show you then was. Augmentation functionality. And the data augmentation functionality is basically grouped into two phases. You can either do data augmentation on individual items like an individual image, or you can do data augmentation on a whole batch. And so obviously we would rather do data augmentation on a whole batch so we can do it on the GPU. But that it's pretty difficult to create data augmentation functions that operate on a batch where the things in a batch are different sizes because you can't really create a proper tensor of it unless you're too padding and stuff. So to deal with that, we suggest you first of all do a data augmentation that resizes things to a consistent size and then do the rest of your data augmentation on the GPU as a batch. Either way, as most of you probably know, you need to make sure that if you're doing something like segmentation or object detection, that your independent variables and your dependent variables get augmentation using the same random state. The same, you know, they need to be rotate your mask and your image both need to be rotated by the same amount, for example. So to let that happen, we have a subclass of transform called ran transform. And ran transform. Overrides done to call from transform to just add a extra call back. Call before call. So remember how in our transforms, they will by default operate. They will like get called on each part of your top or independently. So we need to make sure that we do any randomization before that happens. So this is our opportunity. To do that. And so by default, ran transform has a P, a probability that the transform is applied. And by default, our before call will set something called do. So do you want to do it or not, which is is some random number. Less than that P or not. So that's how we do data augmentation. So, for example, we can create a ran transform where the encoder is at one. Excuse me. And so P equals point five means that will be applied half the time. So let's. We don't really. Need to create it there. We can actually create it there. Oh. So these got renamed somehow. Okay. Oh, I see. It doesn't need to be inside. Yes, I see. Okay. So. You can see that the do attribute will be set to true about half the time. So if it's set to true, we'll set this thing to say, yep, it was set to true at least once. Otherwise, we'll set this thing saying it was false at least once. We'll make sure that both of them got called. That way we know it is actually randomizing properly. Yeah, that's the basic idea. Now, most of the time, you're not going to create a ran transform by passing an encoder in like this. Most of the time you will create a ran transform by example. By inheriting from ran transform and defining before call and end codes. So the end code is just the usual fast AI transform encodes. And this is the bit where you get to set things up. So let's look at some examples. Okay. So let's do a flip left right. So before we do, it would be nice if we have a flip left right method, which we can call on pretty much anything. Which, you know, isn't a random transform, just something where we can just say like this, show image, image dot flip left right. So if I'm going to be able to say image dot flip left right, then the easiest way to do that is with our patch. And there's no reason for that just to be a PIO image. It could actually be a image dot image. May as well make it as convenient as possible. There we go. So now we have something called flip allow, which is a method of image tensor image tensor point tensor B box. And so we can test that by creating a tensor from a pillar image. We can test flip LR. We can create a tensor point, we can create a tensor B box, as you can see, we're just checking that our flip LR works correctly. So for the example for the high torch case, it already has a dot flip and you just say which axis to flip on. So that made that one super easy. Pillow has something else called transpose. So when you want to now turn that into a random data augmentation, then you inherit from RAND transform. And actually in the case where everything you want to use it on is going to just be exactly the same line of code, it's going to have the same name. So there's a couple of ways we could do this, right? One would be to say def encodes self comma x colon tensor image. Return X dot flip LR. That'd be one way to do it. And then we could like do it for each different type. But they're all going to have the same code. So another thing we could do would be to actually use a tuple as our dispatch type. And in fast AI if you use a tuple, it means any of these. Well, we actually have an even easier way with RAND transform is that the default encodes actually is something which will basically just call a function called self dot name. And so in this case, if I set self dot name to flip LR, then it's just going to call that function, which is the function I want to call. But we wouldn't want to like you might have some types that just so happens to have this function name and we don't want to do data augmentation on. So the other thing you do is you would add your type to this supports list to say this is something which supports flipping. So if you later on have something else that has a flip LR method and you want it to be added to things that get flipped in data augmentation. So maybe your class is a I don't know, a 3D image, something called image 3D, then you could say you could say flip item supports dot append image 3D. And that's it. Now that's going to get random data augmentation as well. Or you can do it in the usual way, which is. Def encodes. So comma. X colon. And then you can do it there. So that's the usual way of adding stuff to transform. All right. Another interesting point about brand transforms is that felt. Is set to zero. And to remind you in transforms, we use this to decide whether or not to call a transform based on what subset it's in. So this says because felt is zero for this transform, this will be by default only called on your training set and will not be called on your validation or test sets. You can obviously change that by setting felt to something else, but that's the default. And so when we then create our flip item transform to test it out, when we call it, we have to say felt equals zero because we're not using a data source or anything here to say, hey, we're in the training set. So dihedral, for those of you that remember, is basically the same thing, except it flips also vertically or with transposes. So the eight possible dihedral symmetries. And as you can see, it's doing the same thing. So now we've patched dihedral into all these types. So we can just say name equals dihedral. And this time we don't only have a P, but we also need to set our random number between not and seven. Saying which of these types of flip will you be doing? Presumably random.rand int is inclusive, is it? And int. Including both endpoints. OK. That's not what I expected. Yeah, so by doing this with before call, we make sure that that K is available. Although how is that going to work? It's not. That's a bug. So we're testing it only with this image.dihedral approach. But we're not testing it with the function. That was a mistake. Because this K is going to be passed in here. All right, so let's we have to call that ourselves, which is no problem. Right. So I think we're going to have to go def end codes. Self, comma, x, colon, and then we list all the types we support. Just all of those. There we go. And so now there's no point passing this name along because we're not doing the automatic version. And so now we will return x.dihedral self.k. So now we need to make sure we have a test of that. So what we could do was we could create a transform here called a dihedral item transform. And let's do it with a p equals one. OK. So we're going to go and then we will go show, we will go f image. And we would say field equals zero. There's no need to use the i because this is random this time. So hopefully we'll see a nice mix of random transforms. Let's see if that works. And that needs a field. And super needs a field. OK. There we go. So we've got lots of different random versions. So let's get rid of this one. We don't need it twice. OK. And this one, we can probably hide because it's just testing it on tensor point as well. OK. So those are transforms that work on a single item at a time. So here is something called crop pad, which will either crop or pad, depending on whatever is necessary to create the size that you ask for, which we've seen in other versions of Fast AI. So we've done the same idea. There's a crop pad, which calls something called do crop pad. And then do crop pad is defined. Let's move everything around so it's easier to see what's going on. There we go. For tensor B box, for tensor point, and for any kind of image. So since we now have that working, we can in our crop pad transform simply call, as you see, do crop pad. Still some room to refactor this a little bit, but it's on the right track. All right. And yeah, as you can see, you can choose what padding mode you want, reflection or border, zeros. So then we can use something you can then inherit from that to create random crop just by changing before call. So do a random crop, as you can see. So here's some random crops of this doggy. And one of the nice things here is it'll automatically take the oh, we should check this is actually working. We want it to take the center crop automatically on the validation set, although I don't know if we actually have that set up. OK, we can do resizing. Similar idea again, just inheriting from crop pad. The famous random resize crop used in pretty much all ImageNet solutions is just another kind of crop pad. So we don't need to go through all that. And then we start the random transforms that will work on the GPU. And there's nothing particularly different about them. These don't need to be refactored a little bit. But yeah, same basic idea. There's a before call. There's encodes for the different types you want. And they're just written so that the the matrix math works out with the extra batch dimension automatically. So, for example, dihedral is done on the GPU by using an F1 transform. Great. And most of this stuff, the F1 transforms and warps and stuff we did touch on in the last part too. So go check that out. And the lighting transforms also were done there. If you've forgotten. Great. So then finally, you can check out 21. So this is ImageNet. And looks pretty familiar. Untar data, get image files. So I'm not going to use data blocks here. Obviously you could use data blocks as well, but this is doing it fairly manually. Hector of the rows. These tags are mentioned in the previous code walkthroughs. So check them out. Otherwise, just look in the scripts, starting with the number nine to see how they're defined. All right. So transforms for the independent variable will just be create an image for the dependent. It will be for the parent label function and then categorize. And then for the tuples, we go tensor optionally flip. Random resize crop. Create a data source. And then on the GPU, turn it into code, or on the batch, I should say, put it on the GPU, turn it into a float tensor, normalize it. And so then we can create a data bunch. There it is. And here's the data block version of the same thing. So you can compare. And again, data bunch. So then these are some of these should need to be exported, but we can create a CNN learner to wrap our learner a bit more conveniently like we did in version one. Label smoothing and fit. And we can see if we have any augmentation. Oh, that's it listed. Not sure we might be need to add that in. Actually, we tend not to add much augmentation because we tend to use mix up nowadays if we want to use or epochs. So, so we tested this on more epochs and he was getting slightly better results than we were version one. So I thought that was a good sign. All right. I think one more question torch vision models be used. Yeah, anything should be usable. They're just models. So if you look at X ResNet, it's just a normal and sequential. So, yeah, there shouldn't be any special requirements. If you try using a model and it doesn't work, let us know. I guess the stuff like transfer learning. Maybe that's something we can do in a future walkthrough. Yeah, we should probably do that in a future walkthrough. Talk about how that stuff works. All right. Thanks for joining everybody. See you on the forums and I'll let you know if we're going to do more of these in the future. Thanks for coming along. Bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.200000000000001, "text": " Okay, hi there everybody.", "tokens": [1033, 11, 4879, 456, 2201, 13], "temperature": 0.0, "avg_logprob": -0.7725646279074929, "compression_ratio": 0.9354838709677419, "no_speech_prob": 0.31213822960853577}, {"id": 1, "seek": 0, "start": 9.200000000000001, "end": 18.2, "text": " Can you see in here okay?", "tokens": [1664, 291, 536, 294, 510, 1392, 30], "temperature": 0.0, "avg_logprob": -0.7725646279074929, "compression_ratio": 0.9354838709677419, "no_speech_prob": 0.31213822960853577}, {"id": 2, "seek": 1820, "start": 18.2, "end": 37.2, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.29969293192813273, "compression_ratio": 0.9137931034482759, "no_speech_prob": 0.0003294079506304115}, {"id": 3, "seek": 1820, "start": 37.2, "end": 43.2, "text": " Okay, let me know if anybody has any requests.", "tokens": [1033, 11, 718, 385, 458, 498, 4472, 575, 604, 12475, 13], "temperature": 0.0, "avg_logprob": -0.29969293192813273, "compression_ratio": 0.9137931034482759, "no_speech_prob": 0.0003294079506304115}, {"id": 4, "seek": 4320, "start": 43.2, "end": 50.2, "text": " This will be the last walkthrough, at least for a while, because we've covered most of the main stuff,", "tokens": [639, 486, 312, 264, 1036, 1792, 11529, 11, 412, 1935, 337, 257, 1339, 11, 570, 321, 600, 5343, 881, 295, 264, 2135, 1507, 11], "temperature": 0.0, "avg_logprob": -0.19912479234778363, "compression_ratio": 1.6303317535545023, "no_speech_prob": 0.00021962722530588508}, {"id": 5, "seek": 4320, "start": 50.2, "end": 56.2, "text": " other than what's in Lerner and Optimizer and stuff,", "tokens": [661, 813, 437, 311, 294, 441, 260, 1193, 293, 35013, 6545, 293, 1507, 11], "temperature": 0.0, "avg_logprob": -0.19912479234778363, "compression_ratio": 1.6303317535545023, "no_speech_prob": 0.00021962722530588508}, {"id": 6, "seek": 4320, "start": 56.2, "end": 61.2, "text": " which is largely the same as what was in the course in version,", "tokens": [597, 307, 11611, 264, 912, 382, 437, 390, 294, 264, 1164, 294, 3037, 11], "temperature": 0.0, "avg_logprob": -0.19912479234778363, "compression_ratio": 1.6303317535545023, "no_speech_prob": 0.00021962722530588508}, {"id": 7, "seek": 4320, "start": 61.2, "end": 63.2, "text": " part two, version three of the course.", "tokens": [644, 732, 11, 3037, 1045, 295, 264, 1164, 13], "temperature": 0.0, "avg_logprob": -0.19912479234778363, "compression_ratio": 1.6303317535545023, "no_speech_prob": 0.00021962722530588508}, {"id": 8, "seek": 4320, "start": 63.2, "end": 68.2, "text": " We might do another, we'll probably do another walkthrough in a couple of weeks or so", "tokens": [492, 1062, 360, 1071, 11, 321, 603, 1391, 360, 1071, 1792, 11529, 294, 257, 1916, 295, 3259, 420, 370], "temperature": 0.0, "avg_logprob": -0.19912479234778363, "compression_ratio": 1.6303317535545023, "no_speech_prob": 0.00021962722530588508}, {"id": 9, "seek": 6820, "start": 68.2, "end": 73.2, "text": " to cover the little differences, I suspect.", "tokens": [281, 2060, 264, 707, 7300, 11, 286, 9091, 13], "temperature": 0.0, "avg_logprob": -0.12104841154448841, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00014194214600138366}, {"id": 10, "seek": 6820, "start": 73.2, "end": 78.2, "text": " But we can have a quick look at the image net tutorial today as well.", "tokens": [583, 321, 393, 362, 257, 1702, 574, 412, 264, 3256, 2533, 7073, 965, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.12104841154448841, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00014194214600138366}, {"id": 11, "seek": 6820, "start": 78.2, "end": 82.2, "text": " But mainly I was going to look at the data augmentation", "tokens": [583, 8704, 286, 390, 516, 281, 574, 412, 264, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.12104841154448841, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00014194214600138366}, {"id": 12, "seek": 6820, "start": 82.2, "end": 86.2, "text": " and finish off a little bit more of the stuff that's in core.", "tokens": [293, 2413, 766, 257, 707, 857, 544, 295, 264, 1507, 300, 311, 294, 4965, 13], "temperature": 0.0, "avg_logprob": -0.12104841154448841, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00014194214600138366}, {"id": 13, "seek": 6820, "start": 86.2, "end": 91.2, "text": " But yeah, just ask any questions if this stuff either we haven't covered", "tokens": [583, 1338, 11, 445, 1029, 604, 1651, 498, 341, 1507, 2139, 321, 2378, 380, 5343], "temperature": 0.0, "avg_logprob": -0.12104841154448841, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00014194214600138366}, {"id": 14, "seek": 6820, "start": 91.2, "end": 96.2, "text": " or you didn't quite follow or you don't quite know how it fits together.", "tokens": [420, 291, 994, 380, 1596, 1524, 420, 291, 500, 380, 1596, 458, 577, 309, 9001, 1214, 13], "temperature": 0.0, "avg_logprob": -0.12104841154448841, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.00014194214600138366}, {"id": 15, "seek": 9620, "start": 96.2, "end": 99.2, "text": " Excuse me.", "tokens": [11359, 385, 13], "temperature": 0.0, "avg_logprob": -0.14963816570979294, "compression_ratio": 1.5594059405940595, "no_speech_prob": 8.348371193278581e-05}, {"id": 16, "seek": 9620, "start": 99.2, "end": 104.2, "text": " In the meantime, we'll get back to core.", "tokens": [682, 264, 14991, 11, 321, 603, 483, 646, 281, 4965, 13], "temperature": 0.0, "avg_logprob": -0.14963816570979294, "compression_ratio": 1.5594059405940595, "no_speech_prob": 8.348371193278581e-05}, {"id": 17, "seek": 9620, "start": 104.2, "end": 108.2, "text": " And so you can see in core,", "tokens": [400, 370, 291, 393, 536, 294, 4965, 11], "temperature": 0.0, "avg_logprob": -0.14963816570979294, "compression_ratio": 1.5594059405940595, "no_speech_prob": 8.348371193278581e-05}, {"id": 18, "seek": 9620, "start": 108.2, "end": 113.2, "text": " other than meta classes, which we're probably going to be largely getting rid of, so we'll ignore that.", "tokens": [661, 813, 19616, 5359, 11, 597, 321, 434, 1391, 516, 281, 312, 11611, 1242, 3973, 295, 11, 370, 321, 603, 11200, 300, 13], "temperature": 0.0, "avg_logprob": -0.14963816570979294, "compression_ratio": 1.5594059405940595, "no_speech_prob": 8.348371193278581e-05}, {"id": 19, "seek": 9620, "start": 113.2, "end": 117.2, "text": " There was, there's the kind of decorators and stuff we talked about.", "tokens": [821, 390, 11, 456, 311, 264, 733, 295, 7919, 3391, 293, 1507, 321, 2825, 466, 13], "temperature": 0.0, "avg_logprob": -0.14963816570979294, "compression_ratio": 1.5594059405940595, "no_speech_prob": 8.348371193278581e-05}, {"id": 20, "seek": 9620, "start": 117.2, "end": 122.2, "text": " There's Gadatra, there's L, and then there's a bunch of stuff.", "tokens": [821, 311, 37171, 33593, 11, 456, 311, 441, 11, 293, 550, 456, 311, 257, 3840, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.14963816570979294, "compression_ratio": 1.5594059405940595, "no_speech_prob": 8.348371193278581e-05}, {"id": 21, "seek": 12220, "start": 122.2, "end": 128.2, "text": " And the bunch of stuff is, broadly speaking,", "tokens": [400, 264, 3840, 295, 1507, 307, 11, 19511, 4124, 11], "temperature": 0.0, "avg_logprob": -0.1295032854433413, "compression_ratio": 1.5142857142857142, "no_speech_prob": 9.817865247896407e-06}, {"id": 22, "seek": 12220, "start": 128.2, "end": 137.2, "text": " stuff for collections, types, functions about functions, file and network.", "tokens": [1507, 337, 16641, 11, 3467, 11, 6828, 466, 6828, 11, 3991, 293, 3209, 13], "temperature": 0.0, "avg_logprob": -0.1295032854433413, "compression_ratio": 1.5142857142857142, "no_speech_prob": 9.817865247896407e-06}, {"id": 23, "seek": 12220, "start": 137.2, "end": 146.2, "text": " So in terms of stuff that's interesting,", "tokens": [407, 294, 2115, 295, 1507, 300, 311, 1880, 11], "temperature": 0.0, "avg_logprob": -0.1295032854433413, "compression_ratio": 1.5142857142857142, "no_speech_prob": 9.817865247896407e-06}, {"id": 24, "seek": 12220, "start": 146.2, "end": 150.2, "text": " one thing that's kind of interesting is make class.", "tokens": [472, 551, 300, 311, 733, 295, 1880, 307, 652, 1508, 13], "temperature": 0.0, "avg_logprob": -0.1295032854433413, "compression_ratio": 1.5142857142857142, "no_speech_prob": 9.817865247896407e-06}, {"id": 25, "seek": 15020, "start": 150.2, "end": 155.2, "text": " Make class is a replacement for typing class.", "tokens": [4387, 1508, 307, 257, 14419, 337, 18444, 1508, 13], "temperature": 0.0, "avg_logprob": -0.21996931234995523, "compression_ratio": 1.116504854368932, "no_speech_prob": 4.6832570660626516e-05}, {"id": 26, "seek": 15020, "start": 155.2, "end": 167.2, "text": " So basically, I'll just make sure I've done a pull here.", "tokens": [407, 1936, 11, 286, 603, 445, 652, 988, 286, 600, 1096, 257, 2235, 510, 13], "temperature": 0.0, "avg_logprob": -0.21996931234995523, "compression_ratio": 1.116504854368932, "no_speech_prob": 4.6832570660626516e-05}, {"id": 27, "seek": 15020, "start": 167.2, "end": 178.2, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.21996931234995523, "compression_ratio": 1.116504854368932, "no_speech_prob": 4.6832570660626516e-05}, {"id": 28, "seek": 17820, "start": 178.2, "end": 186.2, "text": " So basically this one here, make class t equals one super equals get extra.", "tokens": [407, 1936, 341, 472, 510, 11, 652, 1508, 256, 6915, 472, 1687, 6915, 483, 2857, 13], "temperature": 0.0, "avg_logprob": -0.4256208472781711, "compression_ratio": 1.35, "no_speech_prob": 1.8922648450825363e-05}, {"id": 29, "seek": 17820, "start": 186.2, "end": 196.2, "text": " Is the same as typing this class and the score T get extra.", "tokens": [1119, 264, 912, 382, 18444, 341, 1508, 293, 264, 6175, 314, 483, 2857, 13], "temperature": 0.0, "avg_logprob": -0.4256208472781711, "compression_ratio": 1.35, "no_speech_prob": 1.8922648450825363e-05}, {"id": 30, "seek": 19620, "start": 196.2, "end": 212.2, "text": " Colon a equals one. So those are basically two ways of doing the same thing, except that this version", "tokens": [4004, 266, 257, 6915, 472, 13, 407, 729, 366, 1936, 732, 2098, 295, 884, 264, 912, 551, 11, 3993, 300, 341, 3037], "temperature": 0.0, "avg_logprob": -0.22238685062953403, "compression_ratio": 1.238532110091743, "no_speech_prob": 3.668588988148258e-06}, {"id": 31, "seek": 19620, "start": 212.2, "end": 217.2, "text": " has a bit of extra functionality.", "tokens": [575, 257, 857, 295, 2857, 14980, 13], "temperature": 0.0, "avg_logprob": -0.22238685062953403, "compression_ratio": 1.238532110091743, "no_speech_prob": 3.668588988148258e-06}, {"id": 32, "seek": 21720, "start": 217.2, "end": 231.2, "text": " Oh, let me think. What does it do?", "tokens": [876, 11, 718, 385, 519, 13, 708, 775, 309, 360, 30], "temperature": 0.0, "avg_logprob": -0.30901947021484377, "compression_ratio": 0.8717948717948718, "no_speech_prob": 1.8315469787921757e-05}, {"id": 33, "seek": 23120, "start": 231.2, "end": 248.2, "text": " It's been a while since I've looked at this one. Yes. Okay.", "tokens": [467, 311, 668, 257, 1339, 1670, 286, 600, 2956, 412, 341, 472, 13, 1079, 13, 1033, 13], "temperature": 0.0, "avg_logprob": -0.2010739871433803, "compression_ratio": 0.8939393939393939, "no_speech_prob": 4.565474228002131e-06}, {"id": 34, "seek": 24820, "start": 248.2, "end": 263.2, "text": " So the class that we get back works kind of a bit more like a data class from the Python data classes standard library thing.", "tokens": [407, 264, 1508, 300, 321, 483, 646, 1985, 733, 295, 257, 857, 544, 411, 257, 1412, 1508, 490, 264, 15329, 1412, 5359, 3832, 6405, 551, 13], "temperature": 0.0, "avg_logprob": -0.11304959943217616, "compression_ratio": 1.5875, "no_speech_prob": 7.295692284969846e-06}, {"id": 35, "seek": 24820, "start": 263.2, "end": 270.2, "text": " So you can kind of see and behind the scenes it calls this thing called get class,", "tokens": [407, 291, 393, 733, 295, 536, 293, 2261, 264, 8026, 309, 5498, 341, 551, 1219, 483, 1508, 11], "temperature": 0.0, "avg_logprob": -0.11304959943217616, "compression_ratio": 1.5875, "no_speech_prob": 7.295692284969846e-06}, {"id": 36, "seek": 24820, "start": 270.2, "end": 275.2, "text": " which is actually kind of what does the work.", "tokens": [597, 307, 767, 733, 295, 437, 775, 264, 589, 13], "temperature": 0.0, "avg_logprob": -0.11304959943217616, "compression_ratio": 1.5875, "no_speech_prob": 7.295692284969846e-06}, {"id": 37, "seek": 27520, "start": 275.2, "end": 295.2, "text": " So you can see that we can pass in, for instance, a says that we will get something called as you see here to a.", "tokens": [407, 291, 393, 536, 300, 321, 393, 1320, 294, 11, 337, 5197, 11, 257, 1619, 300, 321, 486, 483, 746, 1219, 382, 291, 536, 510, 281, 257, 13], "temperature": 0.0, "avg_logprob": -0.2115715742111206, "compression_ratio": 1.360655737704918, "no_speech_prob": 1.1842217645607889e-05}, {"id": 38, "seek": 27520, "start": 295.2, "end": 303.2, "text": " Let's try that. So we could go t equals underscore t.", "tokens": [961, 311, 853, 300, 13, 407, 321, 727, 352, 256, 6915, 37556, 256, 13], "temperature": 0.0, "avg_logprob": -0.2115715742111206, "compression_ratio": 1.360655737704918, "no_speech_prob": 1.1842217645607889e-05}, {"id": 39, "seek": 30320, "start": 303.2, "end": 306.2, "text": " There we go. Okay. T.A.", "tokens": [821, 321, 352, 13, 1033, 13, 314, 13, 32, 13], "temperature": 0.0, "avg_logprob": -0.15001948861514822, "compression_ratio": 1.7530120481927711, "no_speech_prob": 6.604640657315031e-05}, {"id": 40, "seek": 30320, "start": 306.2, "end": 312.2, "text": " And so you can see that if we just pass in something saying this is a field, so we see we first pass in a list of fields", "tokens": [400, 370, 291, 393, 536, 300, 498, 321, 445, 1320, 294, 746, 1566, 341, 307, 257, 2519, 11, 370, 321, 536, 321, 700, 1320, 294, 257, 1329, 295, 7909], "temperature": 0.0, "avg_logprob": -0.15001948861514822, "compression_ratio": 1.7530120481927711, "no_speech_prob": 6.604640657315031e-05}, {"id": 41, "seek": 30320, "start": 312.2, "end": 321.2, "text": " and we get that as an empty field, you can pass in a value for it.", "tokens": [293, 321, 483, 300, 382, 364, 6707, 2519, 11, 291, 393, 1320, 294, 257, 2158, 337, 309, 13], "temperature": 0.0, "avg_logprob": -0.15001948861514822, "compression_ratio": 1.7530120481927711, "no_speech_prob": 6.604640657315031e-05}, {"id": 42, "seek": 30320, "start": 321.2, "end": 327.2, "text": " And so that will mean that field, the first field listed a will get that value.", "tokens": [400, 370, 300, 486, 914, 300, 2519, 11, 264, 700, 2519, 10052, 257, 486, 483, 300, 2158, 13], "temperature": 0.0, "avg_logprob": -0.15001948861514822, "compression_ratio": 1.7530120481927711, "no_speech_prob": 6.604640657315031e-05}, {"id": 43, "seek": 32720, "start": 327.2, "end": 336.2, "text": " As you can see, you can pass in keyword argument fields.", "tokens": [1018, 291, 393, 536, 11, 291, 393, 1320, 294, 20428, 6770, 7909, 13], "temperature": 0.0, "avg_logprob": -0.10036597335547731, "compression_ratio": 1.4307692307692308, "no_speech_prob": 1.9033683429370285e-06}, {"id": 44, "seek": 32720, "start": 336.2, "end": 340.2, "text": " So in this case, be here.", "tokens": [407, 294, 341, 1389, 11, 312, 510, 13], "temperature": 0.0, "avg_logprob": -0.10036597335547731, "compression_ratio": 1.4307692307692308, "no_speech_prob": 1.9033683429370285e-06}, {"id": 45, "seek": 32720, "start": 340.2, "end": 345.2, "text": " You can initialize like this.", "tokens": [509, 393, 5883, 1125, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.10036597335547731, "compression_ratio": 1.4307692307692308, "no_speech_prob": 1.9033683429370285e-06}, {"id": 46, "seek": 32720, "start": 345.2, "end": 349.2, "text": " There it is.", "tokens": [821, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.10036597335547731, "compression_ratio": 1.4307692307692308, "no_speech_prob": 1.9033683429370285e-06}, {"id": 47, "seek": 32720, "start": 349.2, "end": 355.2, "text": " You can also pass in functions that you want to be included.", "tokens": [509, 393, 611, 1320, 294, 6828, 300, 291, 528, 281, 312, 5556, 13], "temperature": 0.0, "avg_logprob": -0.10036597335547731, "compression_ratio": 1.4307692307692308, "no_speech_prob": 1.9033683429370285e-06}, {"id": 48, "seek": 35520, "start": 355.2, "end": 364.2, "text": " So, for example, define F self.", "tokens": [407, 11, 337, 1365, 11, 6964, 479, 2698, 13], "temperature": 0.0, "avg_logprob": -0.3137509822845459, "compression_ratio": 1.1428571428571428, "no_speech_prob": 1.9525237803463824e-05}, {"id": 49, "seek": 35520, "start": 364.2, "end": 369.2, "text": " Grant.", "tokens": [17529, 13], "temperature": 0.0, "avg_logprob": -0.3137509822845459, "compression_ratio": 1.1428571428571428, "no_speech_prob": 1.9525237803463824e-05}, {"id": 50, "seek": 35520, "start": 369.2, "end": 372.2, "text": " And so then we could say.", "tokens": [400, 370, 550, 321, 727, 584, 13], "temperature": 0.0, "avg_logprob": -0.3137509822845459, "compression_ratio": 1.1428571428571428, "no_speech_prob": 1.9525237803463824e-05}, {"id": 51, "seek": 35520, "start": 372.2, "end": 376.2, "text": " Bunks equals.", "tokens": [363, 17627, 6915, 13], "temperature": 0.0, "avg_logprob": -0.3137509822845459, "compression_ratio": 1.1428571428571428, "no_speech_prob": 1.9525237803463824e-05}, {"id": 52, "seek": 35520, "start": 376.2, "end": 378.2, "text": " F.", "tokens": [479, 13], "temperature": 0.0, "avg_logprob": -0.3137509822845459, "compression_ratio": 1.1428571428571428, "no_speech_prob": 1.9525237803463824e-05}, {"id": 53, "seek": 35520, "start": 378.2, "end": 383.2, "text": " And so now we'll have an underscore F.", "tokens": [400, 370, 586, 321, 603, 362, 364, 37556, 479, 13], "temperature": 0.0, "avg_logprob": -0.3137509822845459, "compression_ratio": 1.1428571428571428, "no_speech_prob": 1.9525237803463824e-05}, {"id": 54, "seek": 38320, "start": 383.2, "end": 387.2, "text": " What did I do wrong there?", "tokens": [708, 630, 286, 360, 2085, 456, 30], "temperature": 0.0, "avg_logprob": -0.23531212439903845, "compression_ratio": 1.3605442176870748, "no_speech_prob": 4.133406400796957e-05}, {"id": 55, "seek": 38320, "start": 387.2, "end": 391.2, "text": " Functions.", "tokens": [11166, 3916, 13], "temperature": 0.0, "avg_logprob": -0.23531212439903845, "compression_ratio": 1.3605442176870748, "no_speech_prob": 4.133406400796957e-05}, {"id": 56, "seek": 38320, "start": 391.2, "end": 394.2, "text": " No funds.", "tokens": [883, 8271, 13], "temperature": 0.0, "avg_logprob": -0.23531212439903845, "compression_ratio": 1.3605442176870748, "no_speech_prob": 4.133406400796957e-05}, {"id": 57, "seek": 38320, "start": 394.2, "end": 397.2, "text": " And.", "tokens": [400, 13], "temperature": 0.0, "avg_logprob": -0.23531212439903845, "compression_ratio": 1.3605442176870748, "no_speech_prob": 4.133406400796957e-05}, {"id": 58, "seek": 38320, "start": 397.2, "end": 399.2, "text": " What did I do wrong?", "tokens": [708, 630, 286, 360, 2085, 30], "temperature": 0.0, "avg_logprob": -0.23531212439903845, "compression_ratio": 1.3605442176870748, "no_speech_prob": 4.133406400796957e-05}, {"id": 59, "seek": 38320, "start": 399.2, "end": 405.2, "text": " Let's have a look.", "tokens": [961, 311, 362, 257, 574, 13], "temperature": 0.0, "avg_logprob": -0.23531212439903845, "compression_ratio": 1.3605442176870748, "no_speech_prob": 4.133406400796957e-05}, {"id": 60, "seek": 38320, "start": 405.2, "end": 412.2, "text": " So maybe I should get rid of the other score that might be confusing for it because that's normally hidden.", "tokens": [407, 1310, 286, 820, 483, 3973, 295, 264, 661, 6175, 300, 1062, 312, 13181, 337, 309, 570, 300, 311, 5646, 7633, 13], "temperature": 0.0, "avg_logprob": -0.23531212439903845, "compression_ratio": 1.3605442176870748, "no_speech_prob": 4.133406400796957e-05}, {"id": 61, "seek": 41220, "start": 412.2, "end": 428.2, "text": " T.", "tokens": [314, 13], "temperature": 0.0, "avg_logprob": -0.1425955891609192, "compression_ratio": 1.072289156626506, "no_speech_prob": 8.612075907876715e-05}, {"id": 62, "seek": 41220, "start": 428.2, "end": 431.2, "text": " Oh, sorry, I'm being silly.", "tokens": [876, 11, 2597, 11, 286, 478, 885, 11774, 13], "temperature": 0.0, "avg_logprob": -0.1425955891609192, "compression_ratio": 1.072289156626506, "no_speech_prob": 8.612075907876715e-05}, {"id": 63, "seek": 41220, "start": 431.2, "end": 433.2, "text": " We need to recreate it.", "tokens": [492, 643, 281, 25833, 309, 13], "temperature": 0.0, "avg_logprob": -0.1425955891609192, "compression_ratio": 1.072289156626506, "no_speech_prob": 8.612075907876715e-05}, {"id": 64, "seek": 41220, "start": 433.2, "end": 438.2, "text": " So we need to go.", "tokens": [407, 321, 643, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.1425955891609192, "compression_ratio": 1.072289156626506, "no_speech_prob": 8.612075907876715e-05}, {"id": 65, "seek": 41220, "start": 438.2, "end": 440.2, "text": " I'm going crazy.", "tokens": [286, 478, 516, 3219, 13], "temperature": 0.0, "avg_logprob": -0.1425955891609192, "compression_ratio": 1.072289156626506, "no_speech_prob": 8.612075907876715e-05}, {"id": 66, "seek": 44020, "start": 440.2, "end": 445.2, "text": " So we have to create the class.", "tokens": [407, 321, 362, 281, 1884, 264, 1508, 13], "temperature": 0.0, "avg_logprob": -0.2584015663633955, "compression_ratio": 1.146067415730337, "no_speech_prob": 6.643106189585524e-06}, {"id": 67, "seek": 44020, "start": 445.2, "end": 454.2, "text": " Bunks.", "tokens": [363, 17627, 13], "temperature": 0.0, "avg_logprob": -0.2584015663633955, "compression_ratio": 1.146067415730337, "no_speech_prob": 6.643106189585524e-06}, {"id": 68, "seek": 44020, "start": 454.2, "end": 456.2, "text": " Is there.", "tokens": [1119, 456, 13], "temperature": 0.0, "avg_logprob": -0.2584015663633955, "compression_ratio": 1.146067415730337, "no_speech_prob": 6.643106189585524e-06}, {"id": 69, "seek": 44020, "start": 456.2, "end": 458.2, "text": " We had a.", "tokens": [492, 632, 257, 13], "temperature": 0.0, "avg_logprob": -0.2584015663633955, "compression_ratio": 1.146067415730337, "no_speech_prob": 6.643106189585524e-06}, {"id": 70, "seek": 44020, "start": 458.2, "end": 462.2, "text": " And we had B equals two.", "tokens": [400, 321, 632, 363, 6915, 732, 13], "temperature": 0.0, "avg_logprob": -0.2584015663633955, "compression_ratio": 1.146067415730337, "no_speech_prob": 6.643106189585524e-06}, {"id": 71, "seek": 44020, "start": 462.2, "end": 464.2, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.2584015663633955, "compression_ratio": 1.146067415730337, "no_speech_prob": 6.643106189585524e-06}, {"id": 72, "seek": 44020, "start": 464.2, "end": 467.2, "text": " And so now.", "tokens": [400, 370, 586, 13], "temperature": 0.0, "avg_logprob": -0.2584015663633955, "compression_ratio": 1.146067415730337, "no_speech_prob": 6.643106189585524e-06}, {"id": 73, "seek": 46720, "start": 467.2, "end": 476.2, "text": " There we go. It's our function.", "tokens": [821, 321, 352, 13, 467, 311, 527, 2445, 13], "temperature": 0.0, "avg_logprob": -0.16913617098772968, "compression_ratio": 1.2924528301886793, "no_speech_prob": 3.237668579458841e-06}, {"id": 74, "seek": 46720, "start": 476.2, "end": 483.2, "text": " Let's see.", "tokens": [961, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.16913617098772968, "compression_ratio": 1.2924528301886793, "no_speech_prob": 3.237668579458841e-06}, {"id": 75, "seek": 46720, "start": 483.2, "end": 486.2, "text": " We get a rep for free.", "tokens": [492, 483, 257, 1085, 337, 1737, 13], "temperature": 0.0, "avg_logprob": -0.16913617098772968, "compression_ratio": 1.2924528301886793, "no_speech_prob": 3.237668579458841e-06}, {"id": 76, "seek": 46720, "start": 486.2, "end": 490.2, "text": " Let's try that one.", "tokens": [961, 311, 853, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.16913617098772968, "compression_ratio": 1.2924528301886793, "no_speech_prob": 3.237668579458841e-06}, {"id": 77, "seek": 46720, "start": 490.2, "end": 494.2, "text": " Yep, there we go. So you can see I can just type T.", "tokens": [7010, 11, 456, 321, 352, 13, 407, 291, 393, 536, 286, 393, 445, 2010, 314, 13], "temperature": 0.0, "avg_logprob": -0.16913617098772968, "compression_ratio": 1.2924528301886793, "no_speech_prob": 3.237668579458841e-06}, {"id": 78, "seek": 49420, "start": 494.2, "end": 502.2, "text": " You'll see that the rep for isn't added if you put in a superclass because the superclass might have its own rep.", "tokens": [509, 603, 536, 300, 264, 1085, 337, 1943, 380, 3869, 498, 291, 829, 294, 257, 1687, 11665, 570, 264, 1687, 11665, 1062, 362, 1080, 1065, 1085, 13], "temperature": 0.0, "avg_logprob": -0.13273329686636876, "compression_ratio": 1.609442060085837, "no_speech_prob": 2.392103306192439e-05}, {"id": 79, "seek": 49420, "start": 502.2, "end": 509.2, "text": " So basically by using this make class, we can quickly create a little it's kind of good for tests and stuff.", "tokens": [407, 1936, 538, 1228, 341, 652, 1508, 11, 321, 393, 2661, 1884, 257, 707, 309, 311, 733, 295, 665, 337, 6921, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.13273329686636876, "compression_ratio": 1.609442060085837, "no_speech_prob": 2.392103306192439e-05}, {"id": 80, "seek": 49420, "start": 509.2, "end": 514.2, "text": " We can create a quick class which has, you know, some key values that we want and fields that we want.", "tokens": [492, 393, 1884, 257, 1702, 1508, 597, 575, 11, 291, 458, 11, 512, 2141, 4190, 300, 321, 528, 293, 7909, 300, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.13273329686636876, "compression_ratio": 1.609442060085837, "no_speech_prob": 2.392103306192439e-05}, {"id": 81, "seek": 49420, "start": 514.2, "end": 516.2, "text": " You can initialize it.", "tokens": [509, 393, 5883, 1125, 309, 13], "temperature": 0.0, "avg_logprob": -0.13273329686636876, "compression_ratio": 1.609442060085837, "no_speech_prob": 2.392103306192439e-05}, {"id": 82, "seek": 49420, "start": 516.2, "end": 518.2, "text": " It's got a representation.", "tokens": [467, 311, 658, 257, 10290, 13], "temperature": 0.0, "avg_logprob": -0.13273329686636876, "compression_ratio": 1.609442060085837, "no_speech_prob": 2.392103306192439e-05}, {"id": 83, "seek": 51820, "start": 518.2, "end": 527.2, "text": " So that's pretty handy little handy little thing that we use quite often in the tests.", "tokens": [407, 300, 311, 1238, 13239, 707, 13239, 707, 551, 300, 321, 764, 1596, 2049, 294, 264, 6921, 13], "temperature": 0.0, "avg_logprob": -0.10699597891274985, "compression_ratio": 1.5568181818181819, "no_speech_prob": 7.002132633715519e-07}, {"id": 84, "seek": 51820, "start": 527.2, "end": 531.2, "text": " Let's have a look actually see if it's also used in the actual main code base.", "tokens": [961, 311, 362, 257, 574, 767, 536, 498, 309, 311, 611, 1143, 294, 264, 3539, 2135, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.10699597891274985, "compression_ratio": 1.5568181818181819, "no_speech_prob": 7.002132633715519e-07}, {"id": 85, "seek": 51820, "start": 531.2, "end": 537.2, "text": " So let's look for make class.", "tokens": [407, 718, 311, 574, 337, 652, 1508, 13], "temperature": 0.0, "avg_logprob": -0.10699597891274985, "compression_ratio": 1.5568181818181819, "no_speech_prob": 7.002132633715519e-07}, {"id": 86, "seek": 51820, "start": 537.2, "end": 540.2, "text": " OK, it's used occasionally.", "tokens": [2264, 11, 309, 311, 1143, 16895, 13], "temperature": 0.0, "avg_logprob": -0.10699597891274985, "compression_ratio": 1.5568181818181819, "no_speech_prob": 7.002132633715519e-07}, {"id": 87, "seek": 51820, "start": 540.2, "end": 544.2, "text": " So here's an example. One of usages inside layers.", "tokens": [407, 510, 311, 364, 1365, 13, 1485, 295, 505, 1660, 1854, 7914, 13], "temperature": 0.0, "avg_logprob": -0.10699597891274985, "compression_ratio": 1.5568181818181819, "no_speech_prob": 7.002132633715519e-07}, {"id": 88, "seek": 54420, "start": 544.2, "end": 555.2, "text": " So let's take a look at that.", "tokens": [407, 718, 311, 747, 257, 574, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.12431482646776282, "compression_ratio": 1.168141592920354, "no_speech_prob": 5.014691396354465e-06}, {"id": 89, "seek": 54420, "start": 555.2, "end": 559.2, "text": " OK, so here's the example of in layers.", "tokens": [2264, 11, 370, 510, 311, 264, 1365, 295, 294, 7914, 13], "temperature": 0.0, "avg_logprob": -0.12431482646776282, "compression_ratio": 1.168141592920354, "no_speech_prob": 5.014691396354465e-06}, {"id": 90, "seek": 54420, "start": 559.2, "end": 564.2, "text": " It's creating a class called pool type.", "tokens": [467, 311, 4084, 257, 1508, 1219, 7005, 2010, 13], "temperature": 0.0, "avg_logprob": -0.12431482646776282, "compression_ratio": 1.168141592920354, "no_speech_prob": 5.014691396354465e-06}, {"id": 91, "seek": 54420, "start": 564.2, "end": 571.2, "text": " And it has a bunch of.", "tokens": [400, 309, 575, 257, 3840, 295, 13], "temperature": 0.0, "avg_logprob": -0.12431482646776282, "compression_ratio": 1.168141592920354, "no_speech_prob": 5.014691396354465e-06}, {"id": 92, "seek": 57120, "start": 571.2, "end": 576.2, "text": " Fields in it. So this is actually a really good example of something that we do occasionally.", "tokens": [48190, 294, 309, 13, 407, 341, 307, 767, 257, 534, 665, 1365, 295, 746, 300, 321, 360, 16895, 13], "temperature": 0.0, "avg_logprob": -0.16188753218877883, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.2606766176759265e-05}, {"id": 93, "seek": 57120, "start": 576.2, "end": 580.2, "text": " So let's use that to see how it works.", "tokens": [407, 718, 311, 764, 300, 281, 536, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.16188753218877883, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.2606766176759265e-05}, {"id": 94, "seek": 57120, "start": 580.2, "end": 585.2, "text": " So let's see what does pool type now look like.", "tokens": [407, 718, 311, 536, 437, 775, 7005, 2010, 586, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.16188753218877883, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.2606766176759265e-05}, {"id": 95, "seek": 57120, "start": 585.2, "end": 590.2, "text": " So we're going through average, Max, cat and creating a dictionary.", "tokens": [407, 321, 434, 516, 807, 4274, 11, 7402, 11, 3857, 293, 4084, 257, 25890, 13], "temperature": 0.0, "avg_logprob": -0.16188753218877883, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.2606766176759265e-05}, {"id": 96, "seek": 57120, "start": 590.2, "end": 595.2, "text": " So if we go to let's just go pool.", "tokens": [407, 498, 321, 352, 281, 718, 311, 445, 352, 7005, 13], "temperature": 0.0, "avg_logprob": -0.16188753218877883, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.2606766176759265e-05}, {"id": 97, "seek": 57120, "start": 595.2, "end": 597.2, "text": " Type.", "tokens": [15576, 13], "temperature": 0.0, "avg_logprob": -0.16188753218877883, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.2606766176759265e-05}, {"id": 98, "seek": 59720, "start": 597.2, "end": 603.2, "text": " Dot tab and you can see average cat and Max.", "tokens": [38753, 4421, 293, 291, 393, 536, 4274, 3857, 293, 7402, 13], "temperature": 0.0, "avg_logprob": -0.2002787132785745, "compression_ratio": 1.4944444444444445, "no_speech_prob": 1.8738489870884223e-06}, {"id": 99, "seek": 59720, "start": 603.2, "end": 611.2, "text": " This is actually a really nice way of creating kind of in on the strings or kind of strings that have, you know, nice tab completion.", "tokens": [639, 307, 767, 257, 534, 1481, 636, 295, 4084, 733, 295, 294, 322, 264, 13985, 420, 733, 295, 13985, 300, 362, 11, 291, 458, 11, 1481, 4421, 19372, 13], "temperature": 0.0, "avg_logprob": -0.2002787132785745, "compression_ratio": 1.4944444444444445, "no_speech_prob": 1.8738489870884223e-06}, {"id": 100, "seek": 59720, "start": 611.2, "end": 618.2, "text": " So that's a good use of make class.", "tokens": [407, 300, 311, 257, 665, 764, 295, 652, 1508, 13], "temperature": 0.0, "avg_logprob": -0.2002787132785745, "compression_ratio": 1.4944444444444445, "no_speech_prob": 1.8738489870884223e-06}, {"id": 101, "seek": 59720, "start": 618.2, "end": 623.2, "text": " Here you go. Doing exactly the same here for pad mode.", "tokens": [1692, 291, 352, 13, 18496, 2293, 264, 912, 510, 337, 6887, 4391, 13], "temperature": 0.0, "avg_logprob": -0.2002787132785745, "compression_ratio": 1.4944444444444445, "no_speech_prob": 1.8738489870884223e-06}, {"id": 102, "seek": 62320, "start": 623.2, "end": 628.2, "text": " It's actually the same here for resize method.", "tokens": [467, 311, 767, 264, 912, 510, 337, 50069, 3170, 13], "temperature": 0.0, "avg_logprob": -0.12343084812164307, "compression_ratio": 1.2432432432432432, "no_speech_prob": 1.4509878383250907e-05}, {"id": 103, "seek": 62320, "start": 628.2, "end": 636.2, "text": " So other than that.", "tokens": [407, 661, 813, 300, 13], "temperature": 0.0, "avg_logprob": -0.12343084812164307, "compression_ratio": 1.2432432432432432, "no_speech_prob": 1.4509878383250907e-05}, {"id": 104, "seek": 62320, "start": 636.2, "end": 652.2, "text": " Oh, here's one again that's using getting all the events for callbacks.", "tokens": [876, 11, 510, 311, 472, 797, 300, 311, 1228, 1242, 439, 264, 3931, 337, 818, 17758, 13], "temperature": 0.0, "avg_logprob": -0.12343084812164307, "compression_ratio": 1.2432432432432432, "no_speech_prob": 1.4509878383250907e-05}, {"id": 105, "seek": 65220, "start": 652.2, "end": 658.2, "text": " And then in the note.", "tokens": [400, 550, 294, 264, 3637, 13], "temperature": 0.0, "avg_logprob": -0.24633017040434338, "compression_ratio": 1.25, "no_speech_prob": 9.22302388062235e-06}, {"id": 106, "seek": 65220, "start": 658.2, "end": 666.2, "text": " No space.", "tokens": [883, 1901, 13], "temperature": 0.0, "avg_logprob": -0.24633017040434338, "compression_ratio": 1.25, "no_speech_prob": 9.22302388062235e-06}, {"id": 107, "seek": 65220, "start": 666.2, "end": 671.2, "text": " In the note.", "tokens": [682, 264, 3637, 13], "temperature": 0.0, "avg_logprob": -0.24633017040434338, "compression_ratio": 1.25, "no_speech_prob": 9.22302388062235e-06}, {"id": 108, "seek": 65220, "start": 671.2, "end": 679.2, "text": " Yeah, you can see we use it sometimes to create little quick and dirty things for testing.", "tokens": [865, 11, 291, 393, 536, 321, 764, 309, 2171, 281, 1884, 707, 1702, 293, 9360, 721, 337, 4997, 13], "temperature": 0.0, "avg_logprob": -0.24633017040434338, "compression_ratio": 1.25, "no_speech_prob": 9.22302388062235e-06}, {"id": 109, "seek": 67920, "start": 679.2, "end": 689.2, "text": " So we kind of tend to use it instead of data classes because we find it a bit more convenient sometimes.", "tokens": [407, 321, 733, 295, 3928, 281, 764, 309, 2602, 295, 1412, 5359, 570, 321, 915, 309, 257, 857, 544, 10851, 2171, 13], "temperature": 0.0, "avg_logprob": -0.17519098061781663, "compression_ratio": 1.5, "no_speech_prob": 5.955034339422127e-06}, {"id": 110, "seek": 67920, "start": 689.2, "end": 699.2, "text": " So Kevin asked about multiple inheritance.", "tokens": [407, 9954, 2351, 466, 3866, 32122, 13], "temperature": 0.0, "avg_logprob": -0.17519098061781663, "compression_ratio": 1.5, "no_speech_prob": 5.955034339422127e-06}, {"id": 111, "seek": 67920, "start": 699.2, "end": 701.2, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.17519098061781663, "compression_ratio": 1.5, "no_speech_prob": 5.955034339422127e-06}, {"id": 112, "seek": 67920, "start": 701.2, "end": 706.2, "text": " Yeah. So multiple inheritance is pretty widely covered in.", "tokens": [865, 13, 407, 3866, 32122, 307, 1238, 13371, 5343, 294, 13], "temperature": 0.0, "avg_logprob": -0.17519098061781663, "compression_ratio": 1.5, "no_speech_prob": 5.955034339422127e-06}, {"id": 113, "seek": 70620, "start": 706.2, "end": 714.2, "text": " Python tutorials. So I won't go into detail, but if you go to Python multiple inheritance.", "tokens": [15329, 17616, 13, 407, 286, 1582, 380, 352, 666, 2607, 11, 457, 498, 291, 352, 281, 15329, 3866, 32122, 13], "temperature": 0.0, "avg_logprob": -0.1309708867754255, "compression_ratio": 1.5380434782608696, "no_speech_prob": 1.6963900634436868e-05}, {"id": 114, "seek": 70620, "start": 714.2, "end": 722.2, "text": " You will find lots of examples, but the answer is, yeah, basically you have multiple base classes.", "tokens": [509, 486, 915, 3195, 295, 5110, 11, 457, 264, 1867, 307, 11, 1338, 11, 1936, 291, 362, 3866, 3096, 5359, 13], "temperature": 0.0, "avg_logprob": -0.1309708867754255, "compression_ratio": 1.5380434782608696, "no_speech_prob": 1.6963900634436868e-05}, {"id": 115, "seek": 70620, "start": 722.2, "end": 731.2, "text": " So what will happen is that when you look in super for something, it will first look in here.", "tokens": [407, 437, 486, 1051, 307, 300, 562, 291, 574, 294, 1687, 337, 746, 11, 309, 486, 700, 574, 294, 510, 13], "temperature": 0.0, "avg_logprob": -0.1309708867754255, "compression_ratio": 1.5380434782608696, "no_speech_prob": 1.6963900634436868e-05}, {"id": 116, "seek": 73120, "start": 731.2, "end": 739.2, "text": " If it doesn't find it, then it will look in here. That's basically what multiple inheritance does.", "tokens": [759, 309, 1177, 380, 915, 309, 11, 550, 309, 486, 574, 294, 510, 13, 663, 311, 1936, 437, 3866, 32122, 775, 13], "temperature": 0.0, "avg_logprob": -0.16348702160280143, "compression_ratio": 1.5089820359281436, "no_speech_prob": 3.0894295832695207e-06}, {"id": 117, "seek": 73120, "start": 739.2, "end": 748.2, "text": " So in this case, we wanted this to contain all of the basic collection stuff.", "tokens": [407, 294, 341, 1389, 11, 321, 1415, 341, 281, 5304, 439, 295, 264, 3875, 5765, 1507, 13], "temperature": 0.0, "avg_logprob": -0.16348702160280143, "compression_ratio": 1.5089820359281436, "no_speech_prob": 3.0894295832695207e-06}, {"id": 118, "seek": 73120, "start": 748.2, "end": 760.2, "text": " And we also wanted it to have the get atra. So this means we now have both.", "tokens": [400, 321, 611, 1415, 309, 281, 362, 264, 483, 412, 424, 13, 407, 341, 1355, 321, 586, 362, 1293, 13], "temperature": 0.0, "avg_logprob": -0.16348702160280143, "compression_ratio": 1.5089820359281436, "no_speech_prob": 3.0894295832695207e-06}, {"id": 119, "seek": 76020, "start": 760.2, "end": 766.2, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.10390211286998931, "compression_ratio": 1.3097345132743363, "no_speech_prob": 9.223201232089195e-06}, {"id": 120, "seek": 76020, "start": 766.2, "end": 769.2, "text": " What else have we got here?", "tokens": [708, 1646, 362, 321, 658, 510, 30], "temperature": 0.0, "avg_logprob": -0.10390211286998931, "compression_ratio": 1.3097345132743363, "no_speech_prob": 9.223201232089195e-06}, {"id": 121, "seek": 76020, "start": 769.2, "end": 779.2, "text": " In functions.", "tokens": [682, 6828, 13], "temperature": 0.0, "avg_logprob": -0.10390211286998931, "compression_ratio": 1.3097345132743363, "no_speech_prob": 9.223201232089195e-06}, {"id": 122, "seek": 76020, "start": 779.2, "end": 786.2, "text": " Wrap class is something that just takes a function and wraps it into a class by calling make class.", "tokens": [41291, 1508, 307, 746, 300, 445, 2516, 257, 2445, 293, 25831, 309, 666, 257, 1508, 538, 5141, 652, 1508, 13], "temperature": 0.0, "avg_logprob": -0.10390211286998931, "compression_ratio": 1.3097345132743363, "no_speech_prob": 9.223201232089195e-06}, {"id": 123, "seek": 78620, "start": 786.2, "end": 796.2, "text": " So sometimes that's handy for tests where you want to quickly create something that you can test methods on.", "tokens": [407, 2171, 300, 311, 13239, 337, 6921, 689, 291, 528, 281, 2661, 1884, 746, 300, 291, 393, 1500, 7150, 322, 13], "temperature": 0.0, "avg_logprob": -0.19371465909278998, "compression_ratio": 1.4797687861271676, "no_speech_prob": 2.642533218022436e-06}, {"id": 124, "seek": 78620, "start": 796.2, "end": 802.2, "text": " No worries, Kevin.", "tokens": [883, 16340, 11, 9954, 13], "temperature": 0.0, "avg_logprob": -0.19371465909278998, "compression_ratio": 1.4797687861271676, "no_speech_prob": 2.642533218022436e-06}, {"id": 125, "seek": 78620, "start": 802.2, "end": 809.2, "text": " The collection functions worth knowing about, but they're pretty simple. So like couple of fire to turn something into a couple.", "tokens": [440, 5765, 6828, 3163, 5276, 466, 11, 457, 436, 434, 1238, 2199, 13, 407, 411, 1916, 295, 2610, 281, 1261, 746, 666, 257, 1916, 13], "temperature": 0.0, "avg_logprob": -0.19371465909278998, "compression_ratio": 1.4797687861271676, "no_speech_prob": 2.642533218022436e-06}, {"id": 126, "seek": 80920, "start": 809.2, "end": 822.2, "text": " Unique a fire to get the unique values of something set a fire to turn something into a set.", "tokens": [1156, 1925, 257, 2610, 281, 483, 264, 3845, 4190, 295, 746, 992, 257, 2610, 281, 1261, 746, 666, 257, 992, 13], "temperature": 0.0, "avg_logprob": -0.2598175593784877, "compression_ratio": 1.315217391304348, "no_speech_prob": 5.7718457355804276e-06}, {"id": 127, "seek": 80920, "start": 822.2, "end": 829.2, "text": " Group by is super handy. It.", "tokens": [10500, 538, 307, 1687, 13239, 13, 467, 13], "temperature": 0.0, "avg_logprob": -0.2598175593784877, "compression_ratio": 1.315217391304348, "no_speech_prob": 5.7718457355804276e-06}, {"id": 128, "seek": 82920, "start": 829.2, "end": 843.2, "text": " Takes a list like this and groups it by some function. So this case, a a b b b being grouped by item get a zero is going to group by the first letter.", "tokens": [44347, 257, 1329, 411, 341, 293, 3935, 309, 538, 512, 2445, 13, 407, 341, 1389, 11, 257, 257, 272, 272, 272, 885, 41877, 538, 3174, 483, 257, 4018, 307, 516, 281, 1594, 538, 264, 700, 5063, 13], "temperature": 0.0, "avg_logprob": -0.24437758210417512, "compression_ratio": 1.5898876404494382, "no_speech_prob": 2.368781224504346e-06}, {"id": 129, "seek": 82920, "start": 843.2, "end": 855.2, "text": " So a is a b a b and b is b b. That's a very handy function. There's something called it a tools group by in Python standard library.", "tokens": [407, 257, 307, 257, 272, 257, 272, 293, 272, 307, 272, 272, 13, 663, 311, 257, 588, 13239, 2445, 13, 821, 311, 746, 1219, 309, 257, 3873, 1594, 538, 294, 15329, 3832, 6405, 13], "temperature": 0.0, "avg_logprob": -0.24437758210417512, "compression_ratio": 1.5898876404494382, "no_speech_prob": 2.368781224504346e-06}, {"id": 130, "seek": 85520, "start": 855.2, "end": 862.2, "text": " I find this one more convenient and less complicated to understand.", "tokens": [286, 915, 341, 472, 544, 10851, 293, 1570, 6179, 281, 1223, 13], "temperature": 0.0, "avg_logprob": -0.18618276642590034, "compression_ratio": 1.3902439024390243, "no_speech_prob": 4.6107310481602326e-05}, {"id": 131, "seek": 85520, "start": 862.2, "end": 880.2, "text": " Merging dictionaries is often handy. So it just does what it suggests. Merge the dictionaries together.", "tokens": [6124, 3249, 22352, 4889, 307, 2049, 13239, 13, 407, 309, 445, 775, 437, 309, 13409, 13, 6124, 432, 264, 22352, 4889, 1214, 13], "temperature": 0.0, "avg_logprob": -0.18618276642590034, "compression_ratio": 1.3902439024390243, "no_speech_prob": 4.6107310481602326e-05}, {"id": 132, "seek": 88020, "start": 880.2, "end": 894.2, "text": " OK, yes, so here are me 30.", "tokens": [2264, 11, 2086, 11, 370, 510, 366, 385, 2217, 13], "temperature": 0.0, "avg_logprob": -0.48773915427071707, "compression_ratio": 0.8181818181818182, "no_speech_prob": 5.507212790689664e-06}, {"id": 133, "seek": 89420, "start": 894.2, "end": 915.2, "text": " Is the text stuff we probably will do a walkthrough with the text stuff. But we haven't really gone back over it to see whether the ideas from tabular could be used there because we wrote the 30 stuff first before we did tabular.", "tokens": [1119, 264, 2487, 1507, 321, 1391, 486, 360, 257, 1792, 11529, 365, 264, 2487, 1507, 13, 583, 321, 2378, 380, 534, 2780, 646, 670, 309, 281, 536, 1968, 264, 3487, 490, 4421, 1040, 727, 312, 1143, 456, 570, 321, 4114, 264, 2217, 1507, 700, 949, 321, 630, 4421, 1040, 13], "temperature": 0.0, "avg_logprob": -0.17306545045640734, "compression_ratio": 1.4870129870129871, "no_speech_prob": 1.3845088687958196e-05}, {"id": 134, "seek": 91520, "start": 915.2, "end": 924.2, "text": " But we might be able to refactor text using in place transform. I'm not sure. So if we do end up with two different approaches, we'll explain why.", "tokens": [583, 321, 1062, 312, 1075, 281, 1895, 15104, 2487, 1228, 294, 1081, 4088, 13, 286, 478, 406, 988, 13, 407, 498, 321, 360, 917, 493, 365, 732, 819, 11587, 11, 321, 603, 2903, 983, 13], "temperature": 0.0, "avg_logprob": -0.06586875604546588, "compression_ratio": 1.5854700854700854, "no_speech_prob": 3.3403559882572154e-06}, {"id": 135, "seek": 91520, "start": 924.2, "end": 932.2, "text": " Hopefully we won't because it's nice not to have to have two different approaches.", "tokens": [10429, 321, 1582, 380, 570, 309, 311, 1481, 406, 281, 362, 281, 362, 732, 819, 11587, 13], "temperature": 0.0, "avg_logprob": -0.06586875604546588, "compression_ratio": 1.5854700854700854, "no_speech_prob": 3.3403559882572154e-06}, {"id": 136, "seek": 91520, "start": 932.2, "end": 941.2, "text": " Oh, this is fun. I don't use this very much, but I possibly could use it more as more of an exploration of some functional programming ideas.", "tokens": [876, 11, 341, 307, 1019, 13, 286, 500, 380, 764, 341, 588, 709, 11, 457, 286, 6264, 727, 764, 309, 544, 382, 544, 295, 364, 16197, 295, 512, 11745, 9410, 3487, 13], "temperature": 0.0, "avg_logprob": -0.06586875604546588, "compression_ratio": 1.5854700854700854, "no_speech_prob": 3.3403559882572154e-06}, {"id": 137, "seek": 94120, "start": 941.2, "end": 952.2, "text": " So this is basically something where I'm creating all of these things as functions less than greater than less than equal greater than equal, et cetera.", "tokens": [407, 341, 307, 1936, 746, 689, 286, 478, 4084, 439, 295, 613, 721, 382, 6828, 1570, 813, 5044, 813, 1570, 813, 2681, 5044, 813, 2681, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.14442208128155404, "compression_ratio": 1.5705128205128205, "no_speech_prob": 4.222759798722109e-06}, {"id": 138, "seek": 94120, "start": 952.2, "end": 959.2, "text": " They are all functions that exist within the operator", "tokens": [814, 366, 439, 6828, 300, 2514, 1951, 264, 12973], "temperature": 0.0, "avg_logprob": -0.14442208128155404, "compression_ratio": 1.5705128205128205, "no_speech_prob": 4.222759798722109e-06}, {"id": 139, "seek": 94120, "start": 959.2, "end": 964.2, "text": " module in the Python standard library.", "tokens": [10088, 294, 264, 15329, 3832, 6405, 13], "temperature": 0.0, "avg_logprob": -0.14442208128155404, "compression_ratio": 1.5705128205128205, "no_speech_prob": 4.222759798722109e-06}, {"id": 140, "seek": 96420, "start": 964.2, "end": 972.2, "text": " And these functions work the same way. Best than three comma five is true, greater than three comma five is false.", "tokens": [400, 613, 6828, 589, 264, 912, 636, 13, 9752, 813, 1045, 22117, 1732, 307, 2074, 11, 5044, 813, 1045, 22117, 1732, 307, 7908, 13], "temperature": 0.0, "avg_logprob": -0.22116245163811576, "compression_ratio": 1.5251396648044693, "no_speech_prob": 2.8129741167504108e-06}, {"id": 141, "seek": 96420, "start": 972.2, "end": 979.2, "text": " But they also allow you to do what's called carrying, as you can see here.", "tokens": [583, 436, 611, 2089, 291, 281, 360, 437, 311, 1219, 9792, 11, 382, 291, 393, 536, 510, 13], "temperature": 0.0, "avg_logprob": -0.22116245163811576, "compression_ratio": 1.5251396648044693, "no_speech_prob": 2.8129741167504108e-06}, {"id": 142, "seek": 96420, "start": 979.2, "end": 982.2, "text": " And specifically, this is helpful.", "tokens": [400, 4682, 11, 341, 307, 4961, 13], "temperature": 0.0, "avg_logprob": -0.22116245163811576, "compression_ratio": 1.5251396648044693, "no_speech_prob": 2.8129741167504108e-06}, {"id": 143, "seek": 96420, "start": 982.2, "end": 989.2, "text": " Where you can kind of go F equals the LTE three.", "tokens": [2305, 291, 393, 733, 295, 352, 479, 6915, 264, 441, 13639, 1045, 13], "temperature": 0.0, "avg_logprob": -0.22116245163811576, "compression_ratio": 1.5251396648044693, "no_speech_prob": 2.8129741167504108e-06}, {"id": 144, "seek": 98920, "start": 989.2, "end": 995.2, "text": " And then I could and then I could do F five.", "tokens": [400, 550, 286, 727, 293, 550, 286, 727, 360, 479, 1732, 13], "temperature": 0.0, "avg_logprob": -0.12971054753170738, "compression_ratio": 1.542857142857143, "no_speech_prob": 6.854115781607106e-06}, {"id": 145, "seek": 98920, "start": 995.2, "end": 1001.2, "text": " So just putting that into two lines. And the reason that's interesting.", "tokens": [407, 445, 3372, 300, 666, 732, 3876, 13, 400, 264, 1778, 300, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.12971054753170738, "compression_ratio": 1.542857142857143, "no_speech_prob": 6.854115781607106e-06}, {"id": 146, "seek": 98920, "start": 1001.2, "end": 1007.2, "text": " Is so I could do stuff like L dot range.", "tokens": [1119, 370, 286, 727, 360, 1507, 411, 441, 5893, 3613, 13], "temperature": 0.0, "avg_logprob": -0.12971054753170738, "compression_ratio": 1.542857142857143, "no_speech_prob": 6.854115781607106e-06}, {"id": 147, "seek": 98920, "start": 1007.2, "end": 1011.2, "text": " Eight. So let's pick those ones.", "tokens": [17708, 13, 407, 718, 311, 1888, 729, 2306, 13], "temperature": 0.0, "avg_logprob": -0.12971054753170738, "compression_ratio": 1.542857142857143, "no_speech_prob": 6.854115781607106e-06}, {"id": 148, "seek": 98920, "start": 1011.2, "end": 1016.2, "text": " Let's say we had some list. We wanted to grab those, which are less than three.", "tokens": [961, 311, 584, 321, 632, 512, 1329, 13, 492, 1415, 281, 4444, 729, 11, 597, 366, 1570, 813, 1045, 13], "temperature": 0.0, "avg_logprob": -0.12971054753170738, "compression_ratio": 1.542857142857143, "no_speech_prob": 6.854115781607106e-06}, {"id": 149, "seek": 101620, "start": 1016.2, "end": 1021.2, "text": " I could go filtered LTE three.", "tokens": [286, 727, 352, 37111, 441, 13639, 1045, 13], "temperature": 0.0, "avg_logprob": -0.12266055742899577, "compression_ratio": 1.4583333333333333, "no_speech_prob": 4.052516544561513e-07}, {"id": 150, "seek": 101620, "start": 1021.2, "end": 1030.2, "text": " Like so. And so that's just a lot more convenient than writing the normal way, which would be.", "tokens": [1743, 370, 13, 400, 370, 300, 311, 445, 257, 688, 544, 10851, 813, 3579, 264, 2710, 636, 11, 597, 576, 312, 13], "temperature": 0.0, "avg_logprob": -0.12266055742899577, "compression_ratio": 1.4583333333333333, "no_speech_prob": 4.052516544561513e-07}, {"id": 151, "seek": 101620, "start": 1030.2, "end": 1037.2, "text": " Lambda X colon X is less than three.", "tokens": [45691, 1783, 8255, 1783, 307, 1570, 813, 1045, 13], "temperature": 0.0, "avg_logprob": -0.12266055742899577, "compression_ratio": 1.4583333333333333, "no_speech_prob": 4.052516544561513e-07}, {"id": 152, "seek": 101620, "start": 1037.2, "end": 1045.2, "text": " So this kind of thing is pretty common, like pretty much all functional languages allow you to do carrying like this.", "tokens": [407, 341, 733, 295, 551, 307, 1238, 2689, 11, 411, 1238, 709, 439, 11745, 8650, 2089, 291, 281, 360, 9792, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.12266055742899577, "compression_ratio": 1.4583333333333333, "no_speech_prob": 4.052516544561513e-07}, {"id": 153, "seek": 104520, "start": 1045.2, "end": 1055.2, "text": " Unfortunately, Python doesn't, but you can kind of create versions that do work that way.", "tokens": [8590, 11, 15329, 1177, 380, 11, 457, 291, 393, 733, 295, 1884, 9606, 300, 360, 589, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.12404597432989824, "compression_ratio": 1.4947916666666667, "no_speech_prob": 7.889078915468417e-06}, {"id": 154, "seek": 104520, "start": 1055.2, "end": 1062.2, "text": " And as you can see, the way I'm doing it is I've got this little opera thing, which if you pass in only one thing, then B is none.", "tokens": [400, 382, 291, 393, 536, 11, 264, 636, 286, 478, 884, 309, 307, 286, 600, 658, 341, 707, 22202, 551, 11, 597, 498, 291, 1320, 294, 787, 472, 551, 11, 550, 363, 307, 6022, 13], "temperature": 0.0, "avg_logprob": -0.12404597432989824, "compression_ratio": 1.4947916666666667, "no_speech_prob": 7.889078915468417e-06}, {"id": 155, "seek": 104520, "start": 1062.2, "end": 1068.2, "text": " Then it returns a lambda. Otherwise, it does the actual operation.", "tokens": [1396, 309, 11247, 257, 13607, 13, 10328, 11, 309, 775, 264, 3539, 6916, 13], "temperature": 0.0, "avg_logprob": -0.12404597432989824, "compression_ratio": 1.4947916666666667, "no_speech_prob": 7.889078915468417e-06}, {"id": 156, "seek": 106820, "start": 1068.2, "end": 1079.2, "text": " And so that is handy with some of this extra stuff that I'm going to show here, for example.", "tokens": [400, 370, 300, 307, 13239, 365, 512, 295, 341, 2857, 1507, 300, 286, 478, 516, 281, 855, 510, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.08703141842248305, "compression_ratio": 1.4527027027027026, "no_speech_prob": 2.4824564661685145e-06}, {"id": 157, "seek": 106820, "start": 1079.2, "end": 1090.2, "text": " I've created a infinite lists class so that you can do things like an infinite count is is arranged from zero to infinity.", "tokens": [286, 600, 2942, 257, 13785, 14511, 1508, 370, 300, 291, 393, 360, 721, 411, 364, 13785, 1207, 307, 307, 18721, 490, 4018, 281, 13202, 13], "temperature": 0.0, "avg_logprob": -0.08703141842248305, "compression_ratio": 1.4527027027027026, "no_speech_prob": 2.4824564661685145e-06}, {"id": 158, "seek": 109020, "start": 1090.2, "end": 1107.2, "text": " So I could do, for instance, list filter in dot count comma less than 10.", "tokens": [407, 286, 727, 360, 11, 337, 5197, 11, 1329, 6608, 294, 5893, 1207, 22117, 1570, 813, 1266, 13], "temperature": 0.0, "avg_logprob": -0.37971095381111936, "compression_ratio": 1.0714285714285714, "no_speech_prob": 3.8448552004410885e-06}, {"id": 159, "seek": 109020, "start": 1107.2, "end": 1114.2, "text": " Oops, run those.", "tokens": [21726, 11, 1190, 729, 13], "temperature": 0.0, "avg_logprob": -0.37971095381111936, "compression_ratio": 1.0714285714285714, "no_speech_prob": 3.8448552004410885e-06}, {"id": 160, "seek": 111420, "start": 1114.2, "end": 1120.2, "text": " Wrong way around filter in Python first takes a function.", "tokens": [28150, 636, 926, 6608, 294, 15329, 700, 2516, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.22452792143210387, "compression_ratio": 1.1578947368421053, "no_speech_prob": 3.7852846617170144e-06}, {"id": 161, "seek": 111420, "start": 1120.2, "end": 1130.2, "text": " Less than 10 comma count.", "tokens": [18649, 813, 1266, 22117, 1207, 13], "temperature": 0.0, "avg_logprob": -0.22452792143210387, "compression_ratio": 1.1578947368421053, "no_speech_prob": 3.7852846617170144e-06}, {"id": 162, "seek": 111420, "start": 1130.2, "end": 1133.2, "text": " Now, that's interesting.", "tokens": [823, 11, 300, 311, 1880, 13], "temperature": 0.0, "avg_logprob": -0.22452792143210387, "compression_ratio": 1.1578947368421053, "no_speech_prob": 3.7852846617170144e-06}, {"id": 163, "seek": 111420, "start": 1133.2, "end": 1137.2, "text": " Why isn't that working?", "tokens": [1545, 1943, 380, 300, 1364, 30], "temperature": 0.0, "avg_logprob": -0.22452792143210387, "compression_ratio": 1.1578947368421053, "no_speech_prob": 3.7852846617170144e-06}, {"id": 164, "seek": 113720, "start": 1137.2, "end": 1147.2, "text": " Never mind. We can do it this way. Zip range.", "tokens": [7344, 1575, 13, 492, 393, 360, 309, 341, 636, 13, 1176, 647, 3613, 13], "temperature": 0.0, "avg_logprob": -0.26244711264585835, "compression_ratio": 1.1170212765957446, "no_speech_prob": 2.2252595499594463e-06}, {"id": 165, "seek": 113720, "start": 1147.2, "end": 1151.2, "text": " Five comma fifteen.", "tokens": [9436, 22117, 18126, 13], "temperature": 0.0, "avg_logprob": -0.26244711264585835, "compression_ratio": 1.1170212765957446, "no_speech_prob": 2.2252595499594463e-06}, {"id": 166, "seek": 113720, "start": 1151.2, "end": 1155.2, "text": " Comma in dot count.", "tokens": [3046, 64, 294, 5893, 1207, 13], "temperature": 0.0, "avg_logprob": -0.26244711264585835, "compression_ratio": 1.1170212765957446, "no_speech_prob": 2.2252595499594463e-06}, {"id": 167, "seek": 113720, "start": 1155.2, "end": 1159.2, "text": " And then list that.", "tokens": [400, 550, 1329, 300, 13], "temperature": 0.0, "avg_logprob": -0.26244711264585835, "compression_ratio": 1.1170212765957446, "no_speech_prob": 2.2252595499594463e-06}, {"id": 168, "seek": 115920, "start": 1159.2, "end": 1170.2, "text": " OK, there we go. So you can see that the numbers coming from in that count are just the numbers counting up.", "tokens": [2264, 11, 456, 321, 352, 13, 407, 291, 393, 536, 300, 264, 3547, 1348, 490, 294, 300, 1207, 366, 445, 264, 3547, 13251, 493, 13], "temperature": 0.0, "avg_logprob": -0.2113604796560187, "compression_ratio": 1.3333333333333333, "no_speech_prob": 3.3404935493308585e-06}, {"id": 169, "seek": 115920, "start": 1170.2, "end": 1176.2, "text": " So we could do things like.", "tokens": [407, 321, 727, 360, 721, 411, 13], "temperature": 0.0, "avg_logprob": -0.2113604796560187, "compression_ratio": 1.3333333333333333, "no_speech_prob": 3.3404935493308585e-06}, {"id": 170, "seek": 117620, "start": 1176.2, "end": 1190.2, "text": " Rest it to tools dot I slice in dot count comma 10.", "tokens": [13094, 309, 281, 3873, 5893, 286, 13153, 294, 5893, 1207, 22117, 1266, 13], "temperature": 0.0, "avg_logprob": -0.36246947086218634, "compression_ratio": 1.0941176470588236, "no_speech_prob": 5.954956122877775e-06}, {"id": 171, "seek": 117620, "start": 1190.2, "end": 1193.2, "text": " Or we could map.", "tokens": [1610, 321, 727, 4471, 13], "temperature": 0.0, "avg_logprob": -0.36246947086218634, "compression_ratio": 1.0941176470588236, "no_speech_prob": 5.954956122877775e-06}, {"id": 172, "seek": 117620, "start": 1193.2, "end": 1201.2, "text": " And X colon X times two.", "tokens": [400, 1783, 8255, 1783, 1413, 732, 13], "temperature": 0.0, "avg_logprob": -0.36246947086218634, "compression_ratio": 1.0941176470588236, "no_speech_prob": 5.954956122877775e-06}, {"id": 173, "seek": 120120, "start": 1201.2, "end": 1206.2, "text": " So and so forth.", "tokens": [407, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.2157286885958999, "compression_ratio": 1.39375, "no_speech_prob": 9.422354878552142e-07}, {"id": 174, "seek": 120120, "start": 1206.2, "end": 1212.2, "text": " You could replace in stock count with in zeros.", "tokens": [509, 727, 7406, 294, 4127, 1207, 365, 294, 35193, 13], "temperature": 0.0, "avg_logprob": -0.2157286885958999, "compression_ratio": 1.39375, "no_speech_prob": 9.422354878552142e-07}, {"id": 175, "seek": 120120, "start": 1212.2, "end": 1216.2, "text": " As you can see, or in ones.", "tokens": [1018, 291, 393, 536, 11, 420, 294, 2306, 13], "temperature": 0.0, "avg_logprob": -0.2157286885958999, "compression_ratio": 1.39375, "no_speech_prob": 9.422354878552142e-07}, {"id": 176, "seek": 120120, "start": 1216.2, "end": 1220.2, "text": " So it's often really handy to be able to have quick infinite lists available to you.", "tokens": [407, 309, 311, 2049, 534, 13239, 281, 312, 1075, 281, 362, 1702, 13785, 14511, 2435, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.2157286885958999, "compression_ratio": 1.39375, "no_speech_prob": 9.422354878552142e-07}, {"id": 177, "seek": 120120, "start": 1220.2, "end": 1225.2, "text": " We use that, for example, in the data loader.", "tokens": [492, 764, 300, 11, 337, 1365, 11, 294, 264, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.2157286885958999, "compression_ratio": 1.39375, "no_speech_prob": 9.422354878552142e-07}, {"id": 178, "seek": 122520, "start": 1225.2, "end": 1231.2, "text": " So that's basically why this is here. It's actually very challenging.", "tokens": [407, 300, 311, 1936, 983, 341, 307, 510, 13, 467, 311, 767, 588, 7595, 13], "temperature": 0.0, "avg_logprob": -0.0992511340550014, "compression_ratio": 1.7149321266968325, "no_speech_prob": 4.092801191291073e-06}, {"id": 179, "seek": 122520, "start": 1231.2, "end": 1239.2, "text": " In I mean, not challenging, it's kind of it's just it's awkward in Python to be able to create a property like this that behaves this way.", "tokens": [682, 286, 914, 11, 406, 7595, 11, 309, 311, 733, 295, 309, 311, 445, 309, 311, 11411, 294, 15329, 281, 312, 1075, 281, 1884, 257, 4707, 411, 341, 300, 36896, 341, 636, 13], "temperature": 0.0, "avg_logprob": -0.0992511340550014, "compression_ratio": 1.7149321266968325, "no_speech_prob": 4.092801191291073e-06}, {"id": 180, "seek": 122520, "start": 1239.2, "end": 1249.2, "text": " The only way I could do it was to make it into a meta class and put the properties in the meta class and then make that meta class.", "tokens": [440, 787, 636, 286, 727, 360, 309, 390, 281, 652, 309, 666, 257, 19616, 1508, 293, 829, 264, 7221, 294, 264, 19616, 1508, 293, 550, 652, 300, 19616, 1508, 13], "temperature": 0.0, "avg_logprob": -0.0992511340550014, "compression_ratio": 1.7149321266968325, "no_speech_prob": 4.092801191291073e-06}, {"id": 181, "seek": 122520, "start": 1249.2, "end": 1254.2, "text": " Meta class. The thing I actually want.", "tokens": [6377, 64, 1508, 13, 440, 551, 286, 767, 528, 13], "temperature": 0.0, "avg_logprob": -0.0992511340550014, "compression_ratio": 1.7149321266968325, "no_speech_prob": 4.092801191291073e-06}, {"id": 182, "seek": 125420, "start": 1254.2, "end": 1263.2, "text": " So it's not too bad, but it's a little more awkward than would be ideal.", "tokens": [407, 309, 311, 406, 886, 1578, 11, 457, 309, 311, 257, 707, 544, 11411, 813, 576, 312, 7157, 13], "temperature": 0.0, "avg_logprob": -0.1324131263876861, "compression_ratio": 1.4, "no_speech_prob": 6.144059170765104e-06}, {"id": 183, "seek": 125420, "start": 1263.2, "end": 1273.2, "text": " It's often useful to be able to do a an expression that returns that raises an exception.", "tokens": [467, 311, 2049, 4420, 281, 312, 1075, 281, 360, 257, 364, 6114, 300, 11247, 300, 19658, 364, 11183, 13], "temperature": 0.0, "avg_logprob": -0.1324131263876861, "compression_ratio": 1.4, "no_speech_prob": 6.144059170765104e-06}, {"id": 184, "seek": 125420, "start": 1273.2, "end": 1278.2, "text": " So something like a equals three.", "tokens": [407, 746, 411, 257, 6915, 1045, 13], "temperature": 0.0, "avg_logprob": -0.1324131263876861, "compression_ratio": 1.4, "no_speech_prob": 6.144059170765104e-06}, {"id": 185, "seek": 127820, "start": 1278.2, "end": 1286.2, "text": " A is greater than five or stop.", "tokens": [316, 307, 5044, 813, 1732, 420, 1590, 13], "temperature": 0.0, "avg_logprob": -0.10123733852220618, "compression_ratio": 1.5, "no_speech_prob": 6.276632120716386e-07}, {"id": 186, "seek": 127820, "start": 1286.2, "end": 1292.2, "text": " And so you can raise an exception in this way.", "tokens": [400, 370, 291, 393, 5300, 364, 11183, 294, 341, 636, 13], "temperature": 0.0, "avg_logprob": -0.10123733852220618, "compression_ratio": 1.5, "no_speech_prob": 6.276632120716386e-07}, {"id": 187, "seek": 127820, "start": 1292.2, "end": 1299.2, "text": " So I do that quite often. So when you see stop, I particularly use that by default.", "tokens": [407, 286, 360, 300, 1596, 2049, 13, 407, 562, 291, 536, 1590, 11, 286, 4098, 764, 300, 538, 7576, 13], "temperature": 0.0, "avg_logprob": -0.10123733852220618, "compression_ratio": 1.5, "no_speech_prob": 6.276632120716386e-07}, {"id": 188, "seek": 127820, "start": 1299.2, "end": 1305.2, "text": " It raises a stop iteration, which is what Python uses when you finish iterating through a list.", "tokens": [467, 19658, 257, 1590, 24784, 11, 597, 307, 437, 15329, 4960, 562, 291, 2413, 17138, 990, 807, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.10123733852220618, "compression_ratio": 1.5, "no_speech_prob": 6.276632120716386e-07}, {"id": 189, "seek": 130520, "start": 1305.2, "end": 1318.2, "text": " But you can do anything like if you can see.", "tokens": [583, 291, 393, 360, 1340, 411, 498, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.08385625432749264, "compression_ratio": 1.4285714285714286, "no_speech_prob": 1.679711544966267e-06}, {"id": 190, "seek": 130520, "start": 1318.2, "end": 1321.2, "text": " Oh, this is this is a good example of how to use that.", "tokens": [876, 11, 341, 307, 341, 307, 257, 665, 1365, 295, 577, 281, 764, 300, 13], "temperature": 0.0, "avg_logprob": -0.08385625432749264, "compression_ratio": 1.4285714285714286, "no_speech_prob": 1.679711544966267e-06}, {"id": 191, "seek": 130520, "start": 1321.2, "end": 1334.2, "text": " So I've created a generator function that is a lot like a map, but it allows us to do this handle stop iteration nicely.", "tokens": [407, 286, 600, 2942, 257, 19265, 2445, 300, 307, 257, 688, 411, 257, 4471, 11, 457, 309, 4045, 505, 281, 360, 341, 4813, 1590, 24784, 9594, 13], "temperature": 0.0, "avg_logprob": -0.08385625432749264, "compression_ratio": 1.4285714285714286, "no_speech_prob": 1.679711544966267e-06}, {"id": 192, "seek": 133420, "start": 1334.2, "end": 1341.2, "text": " So we can generate from some function over some sequence.", "tokens": [407, 321, 393, 8460, 490, 512, 2445, 670, 512, 8310, 13], "temperature": 0.0, "avg_logprob": -0.13617902406504456, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.553486526972847e-06}, {"id": 193, "seek": 133420, "start": 1341.2, "end": 1346.2, "text": " So it's basically like a map as long as some condition is true.", "tokens": [407, 309, 311, 1936, 411, 257, 4471, 382, 938, 382, 512, 4188, 307, 2074, 13], "temperature": 0.0, "avg_logprob": -0.13617902406504456, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.553486526972847e-06}, {"id": 194, "seek": 133420, "start": 1346.2, "end": 1353.2, "text": " So, for example, do no up over count while less than five.", "tokens": [407, 11, 337, 1365, 11, 360, 572, 493, 670, 1207, 1339, 1570, 813, 1732, 13], "temperature": 0.0, "avg_logprob": -0.13617902406504456, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.553486526972847e-06}, {"id": 195, "seek": 133420, "start": 1353.2, "end": 1361.2, "text": " And that's going to be returned the same as range five or operator negative over an infinite count.", "tokens": [400, 300, 311, 516, 281, 312, 8752, 264, 912, 382, 3613, 1732, 420, 12973, 3671, 670, 364, 13785, 1207, 13], "temperature": 0.0, "avg_logprob": -0.13617902406504456, "compression_ratio": 1.5384615384615385, "no_speech_prob": 1.553486526972847e-06}, {"id": 196, "seek": 136120, "start": 1361.2, "end": 1366.2, "text": " Well, it's greater than negative five. We'll return this.", "tokens": [1042, 11, 309, 311, 5044, 813, 3671, 1732, 13, 492, 603, 2736, 341, 13], "temperature": 0.0, "avg_logprob": -0.1114949385325114, "compression_ratio": 1.55, "no_speech_prob": 3.555959892764804e-06}, {"id": 197, "seek": 136120, "start": 1366.2, "end": 1375.2, "text": " Well, here's an example which does not have a condition, but instead the actual mapping function has a stop in it.", "tokens": [1042, 11, 510, 311, 364, 1365, 597, 775, 406, 362, 257, 4188, 11, 457, 2602, 264, 3539, 18350, 2445, 575, 257, 1590, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.1114949385325114, "compression_ratio": 1.55, "no_speech_prob": 3.555959892764804e-06}, {"id": 198, "seek": 136120, "start": 1375.2, "end": 1382.2, "text": " So look over an infinite list, return itself if always less than five, otherwise stop.", "tokens": [407, 574, 670, 364, 13785, 1329, 11, 2736, 2564, 498, 1009, 1570, 813, 1732, 11, 5911, 1590, 13], "temperature": 0.0, "avg_logprob": -0.1114949385325114, "compression_ratio": 1.55, "no_speech_prob": 3.555959892764804e-06}, {"id": 199, "seek": 136120, "start": 1382.2, "end": 1390.2, "text": " So this is actually a super nice way of doing kind of functional stuff in Python.", "tokens": [407, 341, 307, 767, 257, 1687, 1481, 636, 295, 884, 733, 295, 11745, 1507, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.1114949385325114, "compression_ratio": 1.55, "no_speech_prob": 3.555959892764804e-06}, {"id": 200, "seek": 139020, "start": 1390.2, "end": 1399.2, "text": " Chunked we briefly saw because it was in data loader and the behavior you can kind of see you start with a range example and chunk into groups of three.", "tokens": [761, 3197, 292, 321, 10515, 1866, 570, 309, 390, 294, 1412, 3677, 260, 293, 264, 5223, 291, 393, 733, 295, 536, 291, 722, 365, 257, 3613, 1365, 293, 16635, 666, 3935, 295, 1045, 13], "temperature": 0.0, "avg_logprob": -0.16517975216820127, "compression_ratio": 1.440251572327044, "no_speech_prob": 5.507529749593232e-06}, {"id": 201, "seek": 139020, "start": 1399.2, "end": 1403.2, "text": " And this is how we do batching in the data loader.", "tokens": [400, 341, 307, 577, 321, 360, 15245, 278, 294, 264, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.16517975216820127, "compression_ratio": 1.440251572327044, "no_speech_prob": 5.507529749593232e-06}, {"id": 202, "seek": 139020, "start": 1403.2, "end": 1410.2, "text": " Retained type we've seen.", "tokens": [11495, 3563, 2010, 321, 600, 1612, 13], "temperature": 0.0, "avg_logprob": -0.16517975216820127, "compression_ratio": 1.440251572327044, "no_speech_prob": 5.507529749593232e-06}, {"id": 203, "seek": 141020, "start": 1410.2, "end": 1420.2, "text": " Most of these types we've seen show title. So that's fine.", "tokens": [4534, 295, 613, 3467, 321, 600, 1612, 855, 4876, 13, 407, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.1632062883088083, "compression_ratio": 1.069767441860465, "no_speech_prob": 2.2603076104132924e-06}, {"id": 204, "seek": 141020, "start": 1420.2, "end": 1425.2, "text": " Trace is super handy.", "tokens": [1765, 617, 307, 1687, 13239, 13], "temperature": 0.0, "avg_logprob": -0.1632062883088083, "compression_ratio": 1.069767441860465, "no_speech_prob": 2.2603076104132924e-06}, {"id": 205, "seek": 141020, "start": 1425.2, "end": 1428.2, "text": " If I have a", "tokens": [759, 286, 362, 257], "temperature": 0.0, "avg_logprob": -0.1632062883088083, "compression_ratio": 1.069767441860465, "no_speech_prob": 2.2603076104132924e-06}, {"id": 206, "seek": 142820, "start": 1428.2, "end": 1442.2, "text": " let me give you an example. So let's say I'm creating, I don't know, some list.Matched lambda.", "tokens": [718, 385, 976, 291, 364, 1365, 13, 407, 718, 311, 584, 286, 478, 4084, 11, 286, 500, 380, 458, 11, 512, 1329, 13, 44, 24102, 13607, 13], "temperature": 0.2, "avg_logprob": -0.32418876970318, "compression_ratio": 1.4201183431952662, "no_speech_prob": 1.544583028589841e-05}, {"id": 207, "seek": 142820, "start": 1442.2, "end": 1450.2, "text": " O, O colon O times two.", "tokens": [422, 11, 422, 8255, 422, 1413, 732, 13], "temperature": 0.2, "avg_logprob": -0.32418876970318, "compression_ratio": 1.4201183431952662, "no_speech_prob": 1.544583028589841e-05}, {"id": 208, "seek": 142820, "start": 1450.2, "end": 1457.2, "text": " So I've got something like this, right? And so I've got a passing a function or lambda into something and I want to debug", "tokens": [407, 286, 600, 658, 746, 411, 341, 11, 558, 30, 400, 370, 286, 600, 658, 257, 8437, 257, 2445, 420, 13607, 666, 746, 293, 286, 528, 281, 24083], "temperature": 0.2, "avg_logprob": -0.32418876970318, "compression_ratio": 1.4201183431952662, "no_speech_prob": 1.544583028589841e-05}, {"id": 209, "seek": 145720, "start": 1457.2, "end": 1462.2, "text": " something like something like this. Actually, so like a good example would be what if I was doing this?", "tokens": [746, 411, 746, 411, 341, 13, 5135, 11, 370, 411, 257, 665, 1365, 576, 312, 437, 498, 286, 390, 884, 341, 30], "temperature": 0.0, "avg_logprob": -0.1888009480067662, "compression_ratio": 1.276190476190476, "no_speech_prob": 7.527651632699417e-06}, {"id": 210, "seek": 145720, "start": 1462.2, "end": 1474.2, "text": " Whoops, I should say negative.", "tokens": [45263, 11, 286, 820, 584, 3671, 13], "temperature": 0.0, "avg_logprob": -0.1888009480067662, "compression_ratio": 1.276190476190476, "no_speech_prob": 7.527651632699417e-06}, {"id": 211, "seek": 147420, "start": 1474.2, "end": 1489.2, "text": " OK, and maybe it's not working the way I expected. So I want to debug it. You can use trace to turn any function into a traced version of that function.", "tokens": [2264, 11, 293, 1310, 309, 311, 406, 1364, 264, 636, 286, 5176, 13, 407, 286, 528, 281, 24083, 309, 13, 509, 393, 764, 13508, 281, 1261, 604, 2445, 666, 257, 38141, 3037, 295, 300, 2445, 13], "temperature": 0.0, "avg_logprob": -0.09534303225003755, "compression_ratio": 1.4385964912280702, "no_speech_prob": 2.4439448225166416e-06}, {"id": 212, "seek": 147420, "start": 1489.2, "end": 1501.2, "text": " Like so. And so now I can step into if I step, I will be stepping into operator dot negative.", "tokens": [1743, 370, 13, 400, 370, 586, 286, 393, 1823, 666, 498, 286, 1823, 11, 286, 486, 312, 16821, 666, 12973, 5893, 3671, 13], "temperature": 0.0, "avg_logprob": -0.09534303225003755, "compression_ratio": 1.4385964912280702, "no_speech_prob": 2.4439448225166416e-06}, {"id": 213, "seek": 150120, "start": 1501.2, "end": 1509.2, "text": " Which it looks like I can't step into because I guess that's written not in Python. That's annoying.", "tokens": [3013, 309, 1542, 411, 286, 393, 380, 1823, 666, 570, 286, 2041, 300, 311, 3720, 406, 294, 15329, 13, 663, 311, 11304, 13], "temperature": 0.0, "avg_logprob": -0.17641710767558977, "compression_ratio": 1.292857142857143, "no_speech_prob": 4.42540704170824e-06}, {"id": 214, "seek": 150120, "start": 1509.2, "end": 1518.2, "text": " Let's create our own version then. Def neg. Just for this example.", "tokens": [961, 311, 1884, 527, 1065, 3037, 550, 13, 9548, 2485, 13, 1449, 337, 341, 1365, 13], "temperature": 0.0, "avg_logprob": -0.17641710767558977, "compression_ratio": 1.292857142857143, "no_speech_prob": 4.42540704170824e-06}, {"id": 215, "seek": 150120, "start": 1518.2, "end": 1527.2, "text": " Return neg X.", "tokens": [24350, 2485, 1783, 13], "temperature": 0.0, "avg_logprob": -0.17641710767558977, "compression_ratio": 1.292857142857143, "no_speech_prob": 4.42540704170824e-06}, {"id": 216, "seek": 152720, "start": 1527.2, "end": 1534.2, "text": " There we go. Step. OK, and there you go. Here we are. We've stepped into neg.", "tokens": [821, 321, 352, 13, 5470, 13, 2264, 11, 293, 456, 291, 352, 13, 1692, 321, 366, 13, 492, 600, 15251, 666, 2485, 13], "temperature": 0.0, "avg_logprob": -0.1496538104433002, "compression_ratio": 1.5582329317269077, "no_speech_prob": 5.338061328075128e-06}, {"id": 217, "seek": 152720, "start": 1534.2, "end": 1547.2, "text": " So this is a really handy for debugging stuff, particularly where you're doing map or something like that, passing in some function that might be from fast AI or the Python standard library or PyTorch, whatever.", "tokens": [407, 341, 307, 257, 534, 13239, 337, 45592, 1507, 11, 4098, 689, 291, 434, 884, 4471, 420, 746, 411, 300, 11, 8437, 294, 512, 2445, 300, 1062, 312, 490, 2370, 7318, 420, 264, 15329, 3832, 6405, 420, 9953, 51, 284, 339, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1496538104433002, "compression_ratio": 1.5582329317269077, "no_speech_prob": 5.338061328075128e-06}, {"id": 218, "seek": 152720, "start": 1547.2, "end": 1556.2, "text": " And as you can see, it's very simple. We just stick a set trace and then return the same function.", "tokens": [400, 382, 291, 393, 536, 11, 309, 311, 588, 2199, 13, 492, 445, 2897, 257, 992, 13508, 293, 550, 2736, 264, 912, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1496538104433002, "compression_ratio": 1.5582329317269077, "no_speech_prob": 5.338061328075128e-06}, {"id": 219, "seek": 155620, "start": 1556.2, "end": 1561.2, "text": " Composed as function composition.", "tokens": [6620, 1744, 382, 2445, 12686, 13], "temperature": 0.0, "avg_logprob": -0.10462431907653809, "compression_ratio": 1.453416149068323, "no_speech_prob": 5.955032065685373e-06}, {"id": 220, "seek": 155620, "start": 1561.2, "end": 1573.2, "text": " Map does the same as map, but you can pass in multiple functions.", "tokens": [22053, 775, 264, 912, 382, 4471, 11, 457, 291, 393, 1320, 294, 3866, 6828, 13], "temperature": 0.0, "avg_logprob": -0.10462431907653809, "compression_ratio": 1.453416149068323, "no_speech_prob": 5.955032065685373e-06}, {"id": 221, "seek": 155620, "start": 1573.2, "end": 1581.2, "text": " Yeah, they're all pretty self explanatory and then these are the ones we're not really using at the moment. So don't worry about that.", "tokens": [865, 11, 436, 434, 439, 1238, 2698, 9045, 4745, 293, 550, 613, 366, 264, 2306, 321, 434, 406, 534, 1228, 412, 264, 1623, 13, 407, 500, 380, 3292, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.10462431907653809, "compression_ratio": 1.453416149068323, "no_speech_prob": 5.955032065685373e-06}, {"id": 222, "seek": 158120, "start": 1581.2, "end": 1587.2, "text": " If you look at any of those other things and decide you're interested, feel free to ask on the forums.", "tokens": [759, 291, 574, 412, 604, 295, 729, 661, 721, 293, 4536, 291, 434, 3102, 11, 841, 1737, 281, 1029, 322, 264, 26998, 13], "temperature": 0.0, "avg_logprob": -0.10779443979263306, "compression_ratio": 1.587378640776699, "no_speech_prob": 4.637751317204675e-06}, {"id": 223, "seek": 158120, "start": 1587.2, "end": 1594.2, "text": " LS we've looked at.", "tokens": [36657, 321, 600, 2956, 412, 13], "temperature": 0.0, "avg_logprob": -0.10779443979263306, "compression_ratio": 1.587378640776699, "no_speech_prob": 4.637751317204675e-06}, {"id": 224, "seek": 158120, "start": 1594.2, "end": 1610.2, "text": " This is interesting. Something like B unzip. It's interesting to note that the Python standard library has a Bzip standard library function, but it doesn't do simple things like unzip something in a path.", "tokens": [639, 307, 1880, 13, 6595, 411, 363, 517, 27268, 13, 467, 311, 1880, 281, 3637, 300, 264, 15329, 3832, 6405, 575, 257, 363, 27268, 3832, 6405, 2445, 11, 457, 309, 1177, 380, 360, 2199, 721, 411, 517, 27268, 746, 294, 257, 3100, 13], "temperature": 0.0, "avg_logprob": -0.10779443979263306, "compression_ratio": 1.587378640776699, "no_speech_prob": 4.637751317204675e-06}, {"id": 225, "seek": 161020, "start": 1610.2, "end": 1619.2, "text": " So here's a little function that just does that. It just takes a path and unzips it with Bzip using the standard library.", "tokens": [407, 510, 311, 257, 707, 2445, 300, 445, 775, 300, 13, 467, 445, 2516, 257, 3100, 293, 517, 89, 2600, 309, 365, 363, 27268, 1228, 264, 3832, 6405, 13], "temperature": 0.0, "avg_logprob": -0.08013973374297653, "compression_ratio": 1.4505494505494505, "no_speech_prob": 5.954939751973143e-06}, {"id": 226, "seek": 161020, "start": 1619.2, "end": 1624.2, "text": " So you don't have to call out to a, you know, external process.", "tokens": [407, 291, 500, 380, 362, 281, 818, 484, 281, 257, 11, 291, 458, 11, 8320, 1399, 13], "temperature": 0.0, "avg_logprob": -0.08013973374297653, "compression_ratio": 1.4505494505494505, "no_speech_prob": 5.954939751973143e-06}, {"id": 227, "seek": 161020, "start": 1624.2, "end": 1636.2, "text": " So this kind of thing is very useful to create cross platform compatible code.", "tokens": [407, 341, 733, 295, 551, 307, 588, 4420, 281, 1884, 3278, 3663, 18218, 3089, 13], "temperature": 0.0, "avg_logprob": -0.08013973374297653, "compression_ratio": 1.4505494505494505, "no_speech_prob": 5.954939751973143e-06}, {"id": 228, "seek": 163620, "start": 1636.2, "end": 1644.2, "text": " Okay. So as you can see, it's kind of a bit of a mishmash of stuff that we've kind of thrown in there as we've needed it.", "tokens": [1033, 13, 407, 382, 291, 393, 536, 11, 309, 311, 733, 295, 257, 857, 295, 257, 275, 742, 76, 1299, 295, 1507, 300, 321, 600, 733, 295, 11732, 294, 456, 382, 321, 600, 2978, 309, 13], "temperature": 0.0, "avg_logprob": -0.07930196474676263, "compression_ratio": 1.563953488372093, "no_speech_prob": 3.0894211704435293e-06}, {"id": 229, "seek": 163620, "start": 1644.2, "end": 1648.2, "text": " Main thing I wanted to show you then was.", "tokens": [12383, 551, 286, 1415, 281, 855, 291, 550, 390, 13], "temperature": 0.0, "avg_logprob": -0.07930196474676263, "compression_ratio": 1.563953488372093, "no_speech_prob": 3.0894211704435293e-06}, {"id": 230, "seek": 163620, "start": 1648.2, "end": 1652.2, "text": " Augmentation functionality.", "tokens": [6088, 19631, 14980, 13], "temperature": 0.0, "avg_logprob": -0.07930196474676263, "compression_ratio": 1.563953488372093, "no_speech_prob": 3.0894211704435293e-06}, {"id": 231, "seek": 163620, "start": 1652.2, "end": 1658.2, "text": " And the data augmentation functionality is basically grouped into two phases.", "tokens": [400, 264, 1412, 14501, 19631, 14980, 307, 1936, 41877, 666, 732, 18764, 13], "temperature": 0.0, "avg_logprob": -0.07930196474676263, "compression_ratio": 1.563953488372093, "no_speech_prob": 3.0894211704435293e-06}, {"id": 232, "seek": 165820, "start": 1658.2, "end": 1668.2, "text": " You can either do data augmentation on individual items like an individual image, or you can do data augmentation on a whole batch.", "tokens": [509, 393, 2139, 360, 1412, 14501, 19631, 322, 2609, 4754, 411, 364, 2609, 3256, 11, 420, 291, 393, 360, 1412, 14501, 19631, 322, 257, 1379, 15245, 13], "temperature": 0.0, "avg_logprob": -0.08234543476289916, "compression_ratio": 1.8704453441295548, "no_speech_prob": 1.2289067399251508e-06}, {"id": 233, "seek": 165820, "start": 1668.2, "end": 1674.2, "text": " And so obviously we would rather do data augmentation on a whole batch so we can do it on the GPU.", "tokens": [400, 370, 2745, 321, 576, 2831, 360, 1412, 14501, 19631, 322, 257, 1379, 15245, 370, 321, 393, 360, 309, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.08234543476289916, "compression_ratio": 1.8704453441295548, "no_speech_prob": 1.2289067399251508e-06}, {"id": 234, "seek": 165820, "start": 1674.2, "end": 1687.2, "text": " But that it's pretty difficult to create data augmentation functions that operate on a batch where the things in a batch are different sizes because you can't really create a proper tensor of it unless you're too padding and stuff.", "tokens": [583, 300, 309, 311, 1238, 2252, 281, 1884, 1412, 14501, 19631, 6828, 300, 9651, 322, 257, 15245, 689, 264, 721, 294, 257, 15245, 366, 819, 11602, 570, 291, 393, 380, 534, 1884, 257, 2296, 40863, 295, 309, 5969, 291, 434, 886, 39562, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.08234543476289916, "compression_ratio": 1.8704453441295548, "no_speech_prob": 1.2289067399251508e-06}, {"id": 235, "seek": 168720, "start": 1687.2, "end": 1701.2, "text": " So to deal with that, we suggest you first of all do a data augmentation that resizes things to a consistent size and then do the rest of your data augmentation on the GPU as a batch.", "tokens": [407, 281, 2028, 365, 300, 11, 321, 3402, 291, 700, 295, 439, 360, 257, 1412, 14501, 19631, 300, 725, 5660, 721, 281, 257, 8398, 2744, 293, 550, 360, 264, 1472, 295, 428, 1412, 14501, 19631, 322, 264, 18407, 382, 257, 15245, 13], "temperature": 0.0, "avg_logprob": -0.06611581470655359, "compression_ratio": 1.4523809523809523, "no_speech_prob": 2.5215308596671093e-06}, {"id": 236, "seek": 170120, "start": 1701.2, "end": 1720.2, "text": " Either way, as most of you probably know, you need to make sure that if you're doing something like segmentation or object detection, that your independent variables and your dependent variables get augmentation using the same random state.", "tokens": [13746, 636, 11, 382, 881, 295, 291, 1391, 458, 11, 291, 643, 281, 652, 988, 300, 498, 291, 434, 884, 746, 411, 9469, 399, 420, 2657, 17784, 11, 300, 428, 6695, 9102, 293, 428, 12334, 9102, 483, 14501, 19631, 1228, 264, 912, 4974, 1785, 13], "temperature": 0.0, "avg_logprob": -0.09158194661140442, "compression_ratio": 1.7980295566502462, "no_speech_prob": 9.276260470869602e-07}, {"id": 237, "seek": 170120, "start": 1720.2, "end": 1727.2, "text": " The same, you know, they need to be rotate your mask and your image both need to be rotated by the same amount, for example.", "tokens": [440, 912, 11, 291, 458, 11, 436, 643, 281, 312, 13121, 428, 6094, 293, 428, 3256, 1293, 643, 281, 312, 42146, 538, 264, 912, 2372, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.09158194661140442, "compression_ratio": 1.7980295566502462, "no_speech_prob": 9.276260470869602e-07}, {"id": 238, "seek": 172720, "start": 1727.2, "end": 1733.2, "text": " So to let that happen, we have a subclass of transform called ran transform.", "tokens": [407, 281, 718, 300, 1051, 11, 321, 362, 257, 1422, 11665, 295, 4088, 1219, 5872, 4088, 13], "temperature": 0.0, "avg_logprob": -0.21735613081190322, "compression_ratio": 1.4260869565217391, "no_speech_prob": 2.994383521581767e-06}, {"id": 239, "seek": 172720, "start": 1733.2, "end": 1739.2, "text": " And ran transform.", "tokens": [400, 5872, 4088, 13], "temperature": 0.0, "avg_logprob": -0.21735613081190322, "compression_ratio": 1.4260869565217391, "no_speech_prob": 2.994383521581767e-06}, {"id": 240, "seek": 172720, "start": 1739.2, "end": 1745.2, "text": " Overrides done to call from transform to just add a extra call back.", "tokens": [4886, 81, 1875, 1096, 281, 818, 490, 4088, 281, 445, 909, 257, 2857, 818, 646, 13], "temperature": 0.0, "avg_logprob": -0.21735613081190322, "compression_ratio": 1.4260869565217391, "no_speech_prob": 2.994383521581767e-06}, {"id": 241, "seek": 174520, "start": 1745.2, "end": 1758.2, "text": " Call before call. So remember how in our transforms, they will by default operate. They will like get called on each part of your top or independently.", "tokens": [7807, 949, 818, 13, 407, 1604, 577, 294, 527, 35592, 11, 436, 486, 538, 7576, 9651, 13, 814, 486, 411, 483, 1219, 322, 1184, 644, 295, 428, 1192, 420, 21761, 13], "temperature": 0.0, "avg_logprob": -0.16841343267640072, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.1811560436144646e-07}, {"id": 242, "seek": 174520, "start": 1758.2, "end": 1764.2, "text": " So we need to make sure that we do any randomization before that happens.", "tokens": [407, 321, 643, 281, 652, 988, 300, 321, 360, 604, 4974, 2144, 949, 300, 2314, 13], "temperature": 0.0, "avg_logprob": -0.16841343267640072, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.1811560436144646e-07}, {"id": 243, "seek": 174520, "start": 1764.2, "end": 1766.2, "text": " So this is our opportunity.", "tokens": [407, 341, 307, 527, 2650, 13], "temperature": 0.0, "avg_logprob": -0.16841343267640072, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.1811560436144646e-07}, {"id": 244, "seek": 174520, "start": 1766.2, "end": 1767.2, "text": " To do that.", "tokens": [1407, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.16841343267640072, "compression_ratio": 1.5229885057471264, "no_speech_prob": 4.1811560436144646e-07}, {"id": 245, "seek": 176720, "start": 1767.2, "end": 1775.2, "text": " And so by default, ran transform has a P, a probability that the transform is applied.", "tokens": [400, 370, 538, 7576, 11, 5872, 4088, 575, 257, 430, 11, 257, 8482, 300, 264, 4088, 307, 6456, 13], "temperature": 0.0, "avg_logprob": -0.14142365204660515, "compression_ratio": 1.5333333333333334, "no_speech_prob": 1.0511422487979871e-06}, {"id": 246, "seek": 176720, "start": 1775.2, "end": 1786.2, "text": " And by default, our before call will set something called do. So do you want to do it or not, which is is some random number.", "tokens": [400, 538, 7576, 11, 527, 949, 818, 486, 992, 746, 1219, 360, 13, 407, 360, 291, 528, 281, 360, 309, 420, 406, 11, 597, 307, 307, 512, 4974, 1230, 13], "temperature": 0.0, "avg_logprob": -0.14142365204660515, "compression_ratio": 1.5333333333333334, "no_speech_prob": 1.0511422487979871e-06}, {"id": 247, "seek": 176720, "start": 1786.2, "end": 1789.2, "text": " Less than that P or not.", "tokens": [18649, 813, 300, 430, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.14142365204660515, "compression_ratio": 1.5333333333333334, "no_speech_prob": 1.0511422487979871e-06}, {"id": 248, "seek": 176720, "start": 1789.2, "end": 1795.2, "text": " So that's how we do data augmentation.", "tokens": [407, 300, 311, 577, 321, 360, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.14142365204660515, "compression_ratio": 1.5333333333333334, "no_speech_prob": 1.0511422487979871e-06}, {"id": 249, "seek": 179520, "start": 1795.2, "end": 1801.2, "text": " So, for example, we can create a ran transform where the encoder is at one.", "tokens": [407, 11, 337, 1365, 11, 321, 393, 1884, 257, 5872, 4088, 689, 264, 2058, 19866, 307, 412, 472, 13], "temperature": 0.0, "avg_logprob": -0.14617043528063545, "compression_ratio": 1.2816901408450705, "no_speech_prob": 2.5215010737156263e-06}, {"id": 250, "seek": 179520, "start": 1801.2, "end": 1803.2, "text": " Excuse me.", "tokens": [11359, 385, 13], "temperature": 0.0, "avg_logprob": -0.14617043528063545, "compression_ratio": 1.2816901408450705, "no_speech_prob": 2.5215010737156263e-06}, {"id": 251, "seek": 179520, "start": 1803.2, "end": 1809.2, "text": " And so P equals point five means that will be applied half the time.", "tokens": [400, 370, 430, 6915, 935, 1732, 1355, 300, 486, 312, 6456, 1922, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.14617043528063545, "compression_ratio": 1.2816901408450705, "no_speech_prob": 2.5215010737156263e-06}, {"id": 252, "seek": 179520, "start": 1809.2, "end": 1814.2, "text": " So let's.", "tokens": [407, 718, 311, 13], "temperature": 0.0, "avg_logprob": -0.14617043528063545, "compression_ratio": 1.2816901408450705, "no_speech_prob": 2.5215010737156263e-06}, {"id": 253, "seek": 179520, "start": 1814.2, "end": 1816.2, "text": " We don't really.", "tokens": [492, 500, 380, 534, 13], "temperature": 0.0, "avg_logprob": -0.14617043528063545, "compression_ratio": 1.2816901408450705, "no_speech_prob": 2.5215010737156263e-06}, {"id": 254, "seek": 181620, "start": 1816.2, "end": 1840.2, "text": " Need to create it there. We can actually create it there.", "tokens": [16984, 281, 1884, 309, 456, 13, 492, 393, 767, 1884, 309, 456, 13], "temperature": 0.0, "avg_logprob": -0.20088329769316174, "compression_ratio": 1.150943396226415, "no_speech_prob": 0.00018229377747047693}, {"id": 255, "seek": 181620, "start": 1840.2, "end": 1843.2, "text": " Oh.", "tokens": [876, 13], "temperature": 0.0, "avg_logprob": -0.20088329769316174, "compression_ratio": 1.150943396226415, "no_speech_prob": 0.00018229377747047693}, {"id": 256, "seek": 184320, "start": 1843.2, "end": 1858.2, "text": " So these got renamed somehow.", "tokens": [407, 613, 658, 40949, 6063, 13], "temperature": 0.0, "avg_logprob": -0.2247182747413372, "compression_ratio": 1.0, "no_speech_prob": 1.4283331438491587e-05}, {"id": 257, "seek": 184320, "start": 1858.2, "end": 1861.2, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.2247182747413372, "compression_ratio": 1.0, "no_speech_prob": 1.4283331438491587e-05}, {"id": 258, "seek": 184320, "start": 1861.2, "end": 1870.2, "text": " Oh, I see. It doesn't need to be inside.", "tokens": [876, 11, 286, 536, 13, 467, 1177, 380, 643, 281, 312, 1854, 13], "temperature": 0.0, "avg_logprob": -0.2247182747413372, "compression_ratio": 1.0, "no_speech_prob": 1.4283331438491587e-05}, {"id": 259, "seek": 187020, "start": 1870.2, "end": 1874.2, "text": " Yes, I see. Okay. So.", "tokens": [1079, 11, 286, 536, 13, 1033, 13, 407, 13], "temperature": 0.0, "avg_logprob": -0.12481360686452765, "compression_ratio": 1.7219730941704037, "no_speech_prob": 1.0782923709484749e-05}, {"id": 260, "seek": 187020, "start": 1874.2, "end": 1880.2, "text": " You can see that the do attribute will be set to true about half the time.", "tokens": [509, 393, 536, 300, 264, 360, 19667, 486, 312, 992, 281, 2074, 466, 1922, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.12481360686452765, "compression_ratio": 1.7219730941704037, "no_speech_prob": 1.0782923709484749e-05}, {"id": 261, "seek": 187020, "start": 1880.2, "end": 1886.2, "text": " So if it's set to true, we'll set this thing to say, yep, it was set to true at least once.", "tokens": [407, 498, 309, 311, 992, 281, 2074, 11, 321, 603, 992, 341, 551, 281, 584, 11, 18633, 11, 309, 390, 992, 281, 2074, 412, 1935, 1564, 13], "temperature": 0.0, "avg_logprob": -0.12481360686452765, "compression_ratio": 1.7219730941704037, "no_speech_prob": 1.0782923709484749e-05}, {"id": 262, "seek": 187020, "start": 1886.2, "end": 1889.2, "text": " Otherwise, we'll set this thing saying it was false at least once.", "tokens": [10328, 11, 321, 603, 992, 341, 551, 1566, 309, 390, 7908, 412, 1935, 1564, 13], "temperature": 0.0, "avg_logprob": -0.12481360686452765, "compression_ratio": 1.7219730941704037, "no_speech_prob": 1.0782923709484749e-05}, {"id": 263, "seek": 187020, "start": 1889.2, "end": 1891.2, "text": " We'll make sure that both of them got called.", "tokens": [492, 603, 652, 988, 300, 1293, 295, 552, 658, 1219, 13], "temperature": 0.0, "avg_logprob": -0.12481360686452765, "compression_ratio": 1.7219730941704037, "no_speech_prob": 1.0782923709484749e-05}, {"id": 264, "seek": 187020, "start": 1891.2, "end": 1894.2, "text": " That way we know it is actually randomizing properly.", "tokens": [663, 636, 321, 458, 309, 307, 767, 4974, 3319, 6108, 13], "temperature": 0.0, "avg_logprob": -0.12481360686452765, "compression_ratio": 1.7219730941704037, "no_speech_prob": 1.0782923709484749e-05}, {"id": 265, "seek": 187020, "start": 1894.2, "end": 1896.2, "text": " Yeah, that's the basic idea.", "tokens": [865, 11, 300, 311, 264, 3875, 1558, 13], "temperature": 0.0, "avg_logprob": -0.12481360686452765, "compression_ratio": 1.7219730941704037, "no_speech_prob": 1.0782923709484749e-05}, {"id": 266, "seek": 189620, "start": 1896.2, "end": 1900.2, "text": " Now, most of the time, you're not going to create a ran transform by passing an encoder in like this.", "tokens": [823, 11, 881, 295, 264, 565, 11, 291, 434, 406, 516, 281, 1884, 257, 5872, 4088, 538, 8437, 364, 2058, 19866, 294, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1913139820098877, "compression_ratio": 1.6433566433566433, "no_speech_prob": 1.873865016932541e-06}, {"id": 267, "seek": 189620, "start": 1900.2, "end": 1912.2, "text": " Most of the time you will create a ran transform by example.", "tokens": [4534, 295, 264, 565, 291, 486, 1884, 257, 5872, 4088, 538, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1913139820098877, "compression_ratio": 1.6433566433566433, "no_speech_prob": 1.873865016932541e-06}, {"id": 268, "seek": 189620, "start": 1912.2, "end": 1922.2, "text": " By inheriting from ran transform and defining before call and end codes.", "tokens": [3146, 9484, 1748, 490, 5872, 4088, 293, 17827, 949, 818, 293, 917, 14211, 13], "temperature": 0.0, "avg_logprob": -0.1913139820098877, "compression_ratio": 1.6433566433566433, "no_speech_prob": 1.873865016932541e-06}, {"id": 269, "seek": 192220, "start": 1922.2, "end": 1928.2, "text": " So the end code is just the usual fast AI transform encodes.", "tokens": [407, 264, 917, 3089, 307, 445, 264, 7713, 2370, 7318, 4088, 2058, 4789, 13], "temperature": 0.0, "avg_logprob": -0.09865964692214439, "compression_ratio": 1.3308823529411764, "no_speech_prob": 5.338069058780093e-06}, {"id": 270, "seek": 192220, "start": 1928.2, "end": 1932.2, "text": " And this is the bit where you get to set things up.", "tokens": [400, 341, 307, 264, 857, 689, 291, 483, 281, 992, 721, 493, 13], "temperature": 0.0, "avg_logprob": -0.09865964692214439, "compression_ratio": 1.3308823529411764, "no_speech_prob": 5.338069058780093e-06}, {"id": 271, "seek": 192220, "start": 1932.2, "end": 1938.2, "text": " So let's look at some examples.", "tokens": [407, 718, 311, 574, 412, 512, 5110, 13], "temperature": 0.0, "avg_logprob": -0.09865964692214439, "compression_ratio": 1.3308823529411764, "no_speech_prob": 5.338069058780093e-06}, {"id": 272, "seek": 192220, "start": 1938.2, "end": 1941.2, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.09865964692214439, "compression_ratio": 1.3308823529411764, "no_speech_prob": 5.338069058780093e-06}, {"id": 273, "seek": 192220, "start": 1941.2, "end": 1945.2, "text": " So let's do a flip left right.", "tokens": [407, 718, 311, 360, 257, 7929, 1411, 558, 13], "temperature": 0.0, "avg_logprob": -0.09865964692214439, "compression_ratio": 1.3308823529411764, "no_speech_prob": 5.338069058780093e-06}, {"id": 274, "seek": 194520, "start": 1945.2, "end": 1954.2, "text": " So before we do, it would be nice if we have a flip left right method, which we can call on pretty much anything.", "tokens": [407, 949, 321, 360, 11, 309, 576, 312, 1481, 498, 321, 362, 257, 7929, 1411, 558, 3170, 11, 597, 321, 393, 818, 322, 1238, 709, 1340, 13], "temperature": 0.0, "avg_logprob": -0.11328653109970913, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.862680609425297e-06}, {"id": 275, "seek": 194520, "start": 1954.2, "end": 1963.2, "text": " Which, you know, isn't a random transform, just something where we can just say like this, show image, image dot flip left right.", "tokens": [3013, 11, 291, 458, 11, 1943, 380, 257, 4974, 4088, 11, 445, 746, 689, 321, 393, 445, 584, 411, 341, 11, 855, 3256, 11, 3256, 5893, 7929, 1411, 558, 13], "temperature": 0.0, "avg_logprob": -0.11328653109970913, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.862680609425297e-06}, {"id": 276, "seek": 194520, "start": 1963.2, "end": 1973.2, "text": " So if I'm going to be able to say image dot flip left right, then the easiest way to do that is with our patch.", "tokens": [407, 498, 286, 478, 516, 281, 312, 1075, 281, 584, 3256, 5893, 7929, 1411, 558, 11, 550, 264, 12889, 636, 281, 360, 300, 307, 365, 527, 9972, 13], "temperature": 0.0, "avg_logprob": -0.11328653109970913, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.862680609425297e-06}, {"id": 277, "seek": 197320, "start": 1973.2, "end": 1976.2, "text": " And there's no reason for that just to be a PIO image.", "tokens": [400, 456, 311, 572, 1778, 337, 300, 445, 281, 312, 257, 430, 15167, 3256, 13], "temperature": 0.0, "avg_logprob": -0.17730351016946036, "compression_ratio": 1.4722222222222223, "no_speech_prob": 3.041534910153132e-06}, {"id": 278, "seek": 197320, "start": 1976.2, "end": 1981.2, "text": " It could actually be a image dot image.", "tokens": [467, 727, 767, 312, 257, 3256, 5893, 3256, 13], "temperature": 0.0, "avg_logprob": -0.17730351016946036, "compression_ratio": 1.4722222222222223, "no_speech_prob": 3.041534910153132e-06}, {"id": 279, "seek": 197320, "start": 1981.2, "end": 1985.2, "text": " May as well make it as convenient as possible.", "tokens": [1891, 382, 731, 652, 309, 382, 10851, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.17730351016946036, "compression_ratio": 1.4722222222222223, "no_speech_prob": 3.041534910153132e-06}, {"id": 280, "seek": 197320, "start": 1985.2, "end": 1987.2, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.17730351016946036, "compression_ratio": 1.4722222222222223, "no_speech_prob": 3.041534910153132e-06}, {"id": 281, "seek": 197320, "start": 1987.2, "end": 1995.2, "text": " So now we have something called flip allow, which is a method of image tensor image tensor point tensor B box.", "tokens": [407, 586, 321, 362, 746, 1219, 7929, 2089, 11, 597, 307, 257, 3170, 295, 3256, 40863, 3256, 40863, 935, 40863, 363, 2424, 13], "temperature": 0.0, "avg_logprob": -0.17730351016946036, "compression_ratio": 1.4722222222222223, "no_speech_prob": 3.041534910153132e-06}, {"id": 282, "seek": 199520, "start": 1995.2, "end": 2010.2, "text": " And so we can test that by creating a tensor from a pillar image.", "tokens": [400, 370, 321, 393, 1500, 300, 538, 4084, 257, 40863, 490, 257, 27592, 3256, 13], "temperature": 0.0, "avg_logprob": -0.23682616438184464, "compression_ratio": 1.0617283950617284, "no_speech_prob": 3.4464972031855723e-06}, {"id": 283, "seek": 199520, "start": 2010.2, "end": 2017.2, "text": " We can test flip LR.", "tokens": [492, 393, 1500, 7929, 441, 49, 13], "temperature": 0.0, "avg_logprob": -0.23682616438184464, "compression_ratio": 1.0617283950617284, "no_speech_prob": 3.4464972031855723e-06}, {"id": 284, "seek": 201720, "start": 2017.2, "end": 2027.2, "text": " We can create a tensor point, we can create a tensor B box, as you can see, we're just checking that our flip LR works correctly.", "tokens": [492, 393, 1884, 257, 40863, 935, 11, 321, 393, 1884, 257, 40863, 363, 2424, 11, 382, 291, 393, 536, 11, 321, 434, 445, 8568, 300, 527, 7929, 441, 49, 1985, 8944, 13], "temperature": 0.0, "avg_logprob": -0.12004803475879487, "compression_ratio": 1.5771144278606966, "no_speech_prob": 4.784992142958799e-06}, {"id": 285, "seek": 201720, "start": 2027.2, "end": 2035.2, "text": " So for the example for the high torch case, it already has a dot flip and you just say which axis to flip on.", "tokens": [407, 337, 264, 1365, 337, 264, 1090, 27822, 1389, 11, 309, 1217, 575, 257, 5893, 7929, 293, 291, 445, 584, 597, 10298, 281, 7929, 322, 13], "temperature": 0.0, "avg_logprob": -0.12004803475879487, "compression_ratio": 1.5771144278606966, "no_speech_prob": 4.784992142958799e-06}, {"id": 286, "seek": 201720, "start": 2035.2, "end": 2038.2, "text": " So that made that one super easy.", "tokens": [407, 300, 1027, 300, 472, 1687, 1858, 13], "temperature": 0.0, "avg_logprob": -0.12004803475879487, "compression_ratio": 1.5771144278606966, "no_speech_prob": 4.784992142958799e-06}, {"id": 287, "seek": 201720, "start": 2038.2, "end": 2044.2, "text": " Pillow has something else called transpose.", "tokens": [44656, 305, 575, 746, 1646, 1219, 25167, 13], "temperature": 0.0, "avg_logprob": -0.12004803475879487, "compression_ratio": 1.5771144278606966, "no_speech_prob": 4.784992142958799e-06}, {"id": 288, "seek": 204420, "start": 2044.2, "end": 2053.2, "text": " So when you want to now turn that into a random data augmentation, then you inherit from RAND transform.", "tokens": [407, 562, 291, 528, 281, 586, 1261, 300, 666, 257, 4974, 1412, 14501, 19631, 11, 550, 291, 21389, 490, 497, 8070, 4088, 13], "temperature": 0.0, "avg_logprob": -0.11546504346630242, "compression_ratio": 1.5612244897959184, "no_speech_prob": 1.1911030242117704e-06}, {"id": 289, "seek": 204420, "start": 2053.2, "end": 2063.2, "text": " And actually in the case where everything you want to use it on is going to just be exactly the same line of code, it's going to have the same name.", "tokens": [400, 767, 294, 264, 1389, 689, 1203, 291, 528, 281, 764, 309, 322, 307, 516, 281, 445, 312, 2293, 264, 912, 1622, 295, 3089, 11, 309, 311, 516, 281, 362, 264, 912, 1315, 13], "temperature": 0.0, "avg_logprob": -0.11546504346630242, "compression_ratio": 1.5612244897959184, "no_speech_prob": 1.1911030242117704e-06}, {"id": 290, "seek": 204420, "start": 2063.2, "end": 2065.2, "text": " So there's a couple of ways we could do this, right?", "tokens": [407, 456, 311, 257, 1916, 295, 2098, 321, 727, 360, 341, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.11546504346630242, "compression_ratio": 1.5612244897959184, "no_speech_prob": 1.1911030242117704e-06}, {"id": 291, "seek": 206520, "start": 2065.2, "end": 2078.2, "text": " One would be to say def encodes self comma x colon tensor image.", "tokens": [1485, 576, 312, 281, 584, 1060, 2058, 4789, 2698, 22117, 2031, 8255, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.30226959500994, "compression_ratio": 1.048780487804878, "no_speech_prob": 4.784969405591255e-06}, {"id": 292, "seek": 206520, "start": 2078.2, "end": 2087.2, "text": " Return X dot flip LR.", "tokens": [24350, 1783, 5893, 7929, 441, 49, 13], "temperature": 0.0, "avg_logprob": -0.30226959500994, "compression_ratio": 1.048780487804878, "no_speech_prob": 4.784969405591255e-06}, {"id": 293, "seek": 208720, "start": 2087.2, "end": 2096.2, "text": " That'd be one way to do it. And then we could like do it for each different type.", "tokens": [663, 1116, 312, 472, 636, 281, 360, 309, 13, 400, 550, 321, 727, 411, 360, 309, 337, 1184, 819, 2010, 13], "temperature": 0.0, "avg_logprob": -0.10479852480766101, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.994684225792298e-06}, {"id": 294, "seek": 208720, "start": 2096.2, "end": 2098.2, "text": " But they're all going to have the same code.", "tokens": [583, 436, 434, 439, 516, 281, 362, 264, 912, 3089, 13], "temperature": 0.0, "avg_logprob": -0.10479852480766101, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.994684225792298e-06}, {"id": 295, "seek": 208720, "start": 2098.2, "end": 2109.2, "text": " So another thing we could do would be to actually use a tuple as our dispatch type.", "tokens": [407, 1071, 551, 321, 727, 360, 576, 312, 281, 767, 764, 257, 2604, 781, 382, 527, 36729, 2010, 13], "temperature": 0.0, "avg_logprob": -0.10479852480766101, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.994684225792298e-06}, {"id": 296, "seek": 208720, "start": 2109.2, "end": 2115.2, "text": " And in fast AI if you use a tuple, it means any of these.", "tokens": [400, 294, 2370, 7318, 498, 291, 764, 257, 2604, 781, 11, 309, 1355, 604, 295, 613, 13], "temperature": 0.0, "avg_logprob": -0.10479852480766101, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.994684225792298e-06}, {"id": 297, "seek": 211520, "start": 2115.2, "end": 2132.2, "text": " Well, we actually have an even easier way with RAND transform is that the default encodes actually is something which will basically just call a function called self dot name.", "tokens": [1042, 11, 321, 767, 362, 364, 754, 3571, 636, 365, 497, 8070, 4088, 307, 300, 264, 7576, 2058, 4789, 767, 307, 746, 597, 486, 1936, 445, 818, 257, 2445, 1219, 2698, 5893, 1315, 13], "temperature": 0.0, "avg_logprob": -0.09889602033715499, "compression_ratio": 1.5808080808080809, "no_speech_prob": 1.5056906477184384e-06}, {"id": 298, "seek": 211520, "start": 2132.2, "end": 2143.2, "text": " And so in this case, if I set self dot name to flip LR, then it's just going to call that function, which is the function I want to call.", "tokens": [400, 370, 294, 341, 1389, 11, 498, 286, 992, 2698, 5893, 1315, 281, 7929, 441, 49, 11, 550, 309, 311, 445, 516, 281, 818, 300, 2445, 11, 597, 307, 264, 2445, 286, 528, 281, 818, 13], "temperature": 0.0, "avg_logprob": -0.09889602033715499, "compression_ratio": 1.5808080808080809, "no_speech_prob": 1.5056906477184384e-06}, {"id": 299, "seek": 214320, "start": 2143.2, "end": 2151.2, "text": " But we wouldn't want to like you might have some types that just so happens to have this function name and we don't want to do data augmentation on.", "tokens": [583, 321, 2759, 380, 528, 281, 411, 291, 1062, 362, 512, 3467, 300, 445, 370, 2314, 281, 362, 341, 2445, 1315, 293, 321, 500, 380, 528, 281, 360, 1412, 14501, 19631, 322, 13], "temperature": 0.0, "avg_logprob": -0.05261743798547862, "compression_ratio": 1.836283185840708, "no_speech_prob": 8.139396413753275e-06}, {"id": 300, "seek": 214320, "start": 2151.2, "end": 2159.2, "text": " So the other thing you do is you would add your type to this supports list to say this is something which supports flipping.", "tokens": [407, 264, 661, 551, 291, 360, 307, 291, 576, 909, 428, 2010, 281, 341, 9346, 1329, 281, 584, 341, 307, 746, 597, 9346, 26886, 13], "temperature": 0.0, "avg_logprob": -0.05261743798547862, "compression_ratio": 1.836283185840708, "no_speech_prob": 8.139396413753275e-06}, {"id": 301, "seek": 214320, "start": 2159.2, "end": 2169.2, "text": " So if you later on have something else that has a flip LR method and you want it to be added to things that get flipped in data augmentation.", "tokens": [407, 498, 291, 1780, 322, 362, 746, 1646, 300, 575, 257, 7929, 441, 49, 3170, 293, 291, 528, 309, 281, 312, 3869, 281, 721, 300, 483, 26273, 294, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.05261743798547862, "compression_ratio": 1.836283185840708, "no_speech_prob": 8.139396413753275e-06}, {"id": 302, "seek": 216920, "start": 2169.2, "end": 2184.2, "text": " So maybe your class is a I don't know, a 3D image, something called image 3D, then you could say you could say flip item supports dot append image 3D.", "tokens": [407, 1310, 428, 1508, 307, 257, 286, 500, 380, 458, 11, 257, 805, 35, 3256, 11, 746, 1219, 3256, 805, 35, 11, 550, 291, 727, 584, 291, 727, 584, 7929, 3174, 9346, 5893, 34116, 3256, 805, 35, 13], "temperature": 0.0, "avg_logprob": -0.19590257829235447, "compression_ratio": 1.4294871794871795, "no_speech_prob": 8.990858191282314e-07}, {"id": 303, "seek": 216920, "start": 2184.2, "end": 2190.2, "text": " And that's it. Now that's going to get random data augmentation as well.", "tokens": [400, 300, 311, 309, 13, 823, 300, 311, 516, 281, 483, 4974, 1412, 14501, 19631, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19590257829235447, "compression_ratio": 1.4294871794871795, "no_speech_prob": 8.990858191282314e-07}, {"id": 304, "seek": 219020, "start": 2190.2, "end": 2200.2, "text": " Or you can do it in the usual way, which is.", "tokens": [1610, 291, 393, 360, 309, 294, 264, 7713, 636, 11, 597, 307, 13], "temperature": 0.0, "avg_logprob": -0.16280722184614702, "compression_ratio": 1.3559322033898304, "no_speech_prob": 7.69033249525819e-07}, {"id": 305, "seek": 219020, "start": 2200.2, "end": 2203.2, "text": " Def encodes.", "tokens": [9548, 2058, 4789, 13], "temperature": 0.0, "avg_logprob": -0.16280722184614702, "compression_ratio": 1.3559322033898304, "no_speech_prob": 7.69033249525819e-07}, {"id": 306, "seek": 219020, "start": 2203.2, "end": 2206.2, "text": " So comma.", "tokens": [407, 22117, 13], "temperature": 0.0, "avg_logprob": -0.16280722184614702, "compression_ratio": 1.3559322033898304, "no_speech_prob": 7.69033249525819e-07}, {"id": 307, "seek": 219020, "start": 2206.2, "end": 2209.2, "text": " X colon.", "tokens": [1783, 8255, 13], "temperature": 0.0, "avg_logprob": -0.16280722184614702, "compression_ratio": 1.3559322033898304, "no_speech_prob": 7.69033249525819e-07}, {"id": 308, "seek": 219020, "start": 2209.2, "end": 2219.2, "text": " And then you can do it there. So that's the usual way of adding stuff to transform.", "tokens": [400, 550, 291, 393, 360, 309, 456, 13, 407, 300, 311, 264, 7713, 636, 295, 5127, 1507, 281, 4088, 13], "temperature": 0.0, "avg_logprob": -0.16280722184614702, "compression_ratio": 1.3559322033898304, "no_speech_prob": 7.69033249525819e-07}, {"id": 309, "seek": 221920, "start": 2219.2, "end": 2221.2, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.12883966619318182, "compression_ratio": 1.4513888888888888, "no_speech_prob": 4.785035343957134e-06}, {"id": 310, "seek": 221920, "start": 2221.2, "end": 2227.2, "text": " Another interesting point about brand transforms is that felt.", "tokens": [3996, 1880, 935, 466, 3360, 35592, 307, 300, 2762, 13], "temperature": 0.0, "avg_logprob": -0.12883966619318182, "compression_ratio": 1.4513888888888888, "no_speech_prob": 4.785035343957134e-06}, {"id": 311, "seek": 221920, "start": 2227.2, "end": 2230.2, "text": " Is set to zero.", "tokens": [1119, 992, 281, 4018, 13], "temperature": 0.0, "avg_logprob": -0.12883966619318182, "compression_ratio": 1.4513888888888888, "no_speech_prob": 4.785035343957134e-06}, {"id": 312, "seek": 221920, "start": 2230.2, "end": 2242.2, "text": " And to remind you in transforms, we use this to decide whether or not to call a transform based on what subset it's in.", "tokens": [400, 281, 4160, 291, 294, 35592, 11, 321, 764, 341, 281, 4536, 1968, 420, 406, 281, 818, 257, 4088, 2361, 322, 437, 25993, 309, 311, 294, 13], "temperature": 0.0, "avg_logprob": -0.12883966619318182, "compression_ratio": 1.4513888888888888, "no_speech_prob": 4.785035343957134e-06}, {"id": 313, "seek": 224220, "start": 2242.2, "end": 2256.2, "text": " So this says because felt is zero for this transform, this will be by default only called on your training set and will not be called on your validation or test sets.", "tokens": [407, 341, 1619, 570, 2762, 307, 4018, 337, 341, 4088, 11, 341, 486, 312, 538, 7576, 787, 1219, 322, 428, 3097, 992, 293, 486, 406, 312, 1219, 322, 428, 24071, 420, 1500, 6352, 13], "temperature": 0.0, "avg_logprob": -0.08544982712844322, "compression_ratio": 1.5740740740740742, "no_speech_prob": 3.7852887544431724e-06}, {"id": 314, "seek": 224220, "start": 2256.2, "end": 2261.2, "text": " You can obviously change that by setting felt to something else, but that's the default.", "tokens": [509, 393, 2745, 1319, 300, 538, 3287, 2762, 281, 746, 1646, 11, 457, 300, 311, 264, 7576, 13], "temperature": 0.0, "avg_logprob": -0.08544982712844322, "compression_ratio": 1.5740740740740742, "no_speech_prob": 3.7852887544431724e-06}, {"id": 315, "seek": 226120, "start": 2261.2, "end": 2279.2, "text": " And so when we then create our flip item transform to test it out, when we call it, we have to say felt equals zero because we're not using a data source or anything here to say, hey, we're in the training set.", "tokens": [400, 370, 562, 321, 550, 1884, 527, 7929, 3174, 4088, 281, 1500, 309, 484, 11, 562, 321, 818, 309, 11, 321, 362, 281, 584, 2762, 6915, 4018, 570, 321, 434, 406, 1228, 257, 1412, 4009, 420, 1340, 510, 281, 584, 11, 4177, 11, 321, 434, 294, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.06291279527876112, "compression_ratio": 1.4788732394366197, "no_speech_prob": 2.5612523586460156e-06}, {"id": 316, "seek": 227920, "start": 2279.2, "end": 2294.2, "text": " So dihedral, for those of you that remember, is basically the same thing, except it flips also vertically or with transposes. So the eight possible dihedral symmetries.", "tokens": [407, 1026, 71, 24764, 11, 337, 729, 295, 291, 300, 1604, 11, 307, 1936, 264, 912, 551, 11, 3993, 309, 40249, 611, 28450, 420, 365, 7132, 4201, 13, 407, 264, 3180, 1944, 1026, 71, 24764, 14232, 302, 2244, 13], "temperature": 0.0, "avg_logprob": -0.11310227711995442, "compression_ratio": 1.5344827586206897, "no_speech_prob": 5.422135927801719e-06}, {"id": 317, "seek": 227920, "start": 2294.2, "end": 2301.2, "text": " And as you can see, it's doing the same thing. So now we've patched dihedral into all these types.", "tokens": [400, 382, 291, 393, 536, 11, 309, 311, 884, 264, 912, 551, 13, 407, 586, 321, 600, 9972, 292, 1026, 71, 24764, 666, 439, 613, 3467, 13], "temperature": 0.0, "avg_logprob": -0.11310227711995442, "compression_ratio": 1.5344827586206897, "no_speech_prob": 5.422135927801719e-06}, {"id": 318, "seek": 230120, "start": 2301.2, "end": 2321.2, "text": " So we can just say name equals dihedral. And this time we don't only have a P, but we also need to set our random number between not and seven.", "tokens": [407, 321, 393, 445, 584, 1315, 6915, 1026, 71, 24764, 13, 400, 341, 565, 321, 500, 380, 787, 362, 257, 430, 11, 457, 321, 611, 643, 281, 992, 527, 4974, 1230, 1296, 406, 293, 3407, 13], "temperature": 0.0, "avg_logprob": -0.1294400215148926, "compression_ratio": 1.2543859649122806, "no_speech_prob": 2.05802916752873e-06}, {"id": 319, "seek": 232120, "start": 2321.2, "end": 2331.2, "text": " Saying which of these types of flip will you be doing? Presumably random.rand int is inclusive, is it?", "tokens": [34087, 597, 295, 613, 3467, 295, 7929, 486, 291, 312, 884, 30, 2718, 449, 1188, 4974, 13, 3699, 560, 307, 13429, 11, 307, 309, 30], "temperature": 0.0, "avg_logprob": -0.23796791296738845, "compression_ratio": 1.2426470588235294, "no_speech_prob": 7.766828275634907e-06}, {"id": 320, "seek": 232120, "start": 2331.2, "end": 2335.2, "text": " And int.", "tokens": [400, 560, 13], "temperature": 0.0, "avg_logprob": -0.23796791296738845, "compression_ratio": 1.2426470588235294, "no_speech_prob": 7.766828275634907e-06}, {"id": 321, "seek": 232120, "start": 2335.2, "end": 2338.2, "text": " Including both endpoints. OK.", "tokens": [27137, 1293, 917, 20552, 13, 2264, 13], "temperature": 0.0, "avg_logprob": -0.23796791296738845, "compression_ratio": 1.2426470588235294, "no_speech_prob": 7.766828275634907e-06}, {"id": 322, "seek": 232120, "start": 2338.2, "end": 2342.2, "text": " That's not what I expected.", "tokens": [663, 311, 406, 437, 286, 5176, 13], "temperature": 0.0, "avg_logprob": -0.23796791296738845, "compression_ratio": 1.2426470588235294, "no_speech_prob": 7.766828275634907e-06}, {"id": 323, "seek": 234220, "start": 2342.2, "end": 2354.2, "text": " Yeah, so by doing this with before call, we make sure that that K is available.", "tokens": [865, 11, 370, 538, 884, 341, 365, 949, 818, 11, 321, 652, 988, 300, 300, 591, 307, 2435, 13], "temperature": 0.0, "avg_logprob": -0.13344696435061368, "compression_ratio": 1.1982758620689655, "no_speech_prob": 3.7265438095346326e-06}, {"id": 324, "seek": 234220, "start": 2354.2, "end": 2362.2, "text": " Although how is that going to work? It's not.", "tokens": [5780, 577, 307, 300, 516, 281, 589, 30, 467, 311, 406, 13], "temperature": 0.0, "avg_logprob": -0.13344696435061368, "compression_ratio": 1.1982758620689655, "no_speech_prob": 3.7265438095346326e-06}, {"id": 325, "seek": 234220, "start": 2362.2, "end": 2366.2, "text": " That's a bug.", "tokens": [663, 311, 257, 7426, 13], "temperature": 0.0, "avg_logprob": -0.13344696435061368, "compression_ratio": 1.1982758620689655, "no_speech_prob": 3.7265438095346326e-06}, {"id": 326, "seek": 236620, "start": 2366.2, "end": 2372.2, "text": " So we're testing it only with this image.dihedral approach.", "tokens": [407, 321, 434, 4997, 309, 787, 365, 341, 3256, 13, 67, 4247, 24764, 3109, 13], "temperature": 0.0, "avg_logprob": -0.11931529699587355, "compression_ratio": 1.3629032258064515, "no_speech_prob": 5.25529685546644e-06}, {"id": 327, "seek": 236620, "start": 2372.2, "end": 2377.2, "text": " But we're not testing it with the function.", "tokens": [583, 321, 434, 406, 4997, 309, 365, 264, 2445, 13], "temperature": 0.0, "avg_logprob": -0.11931529699587355, "compression_ratio": 1.3629032258064515, "no_speech_prob": 5.25529685546644e-06}, {"id": 328, "seek": 236620, "start": 2377.2, "end": 2380.2, "text": " That was a mistake.", "tokens": [663, 390, 257, 6146, 13], "temperature": 0.0, "avg_logprob": -0.11931529699587355, "compression_ratio": 1.3629032258064515, "no_speech_prob": 5.25529685546644e-06}, {"id": 329, "seek": 236620, "start": 2380.2, "end": 2389.2, "text": " Because this K is going to be passed in here.", "tokens": [1436, 341, 591, 307, 516, 281, 312, 4678, 294, 510, 13], "temperature": 0.0, "avg_logprob": -0.11931529699587355, "compression_ratio": 1.3629032258064515, "no_speech_prob": 5.25529685546644e-06}, {"id": 330, "seek": 238920, "start": 2389.2, "end": 2409.2, "text": " All right, so let's we have to call that ourselves, which is no problem.", "tokens": [1057, 558, 11, 370, 718, 311, 321, 362, 281, 818, 300, 4175, 11, 597, 307, 572, 1154, 13], "temperature": 0.0, "avg_logprob": -0.16088540024227566, "compression_ratio": 1.183673469387755, "no_speech_prob": 1.9525057723512873e-05}, {"id": 331, "seek": 238920, "start": 2409.2, "end": 2417.2, "text": " Right. So I think we're going to have to go", "tokens": [1779, 13, 407, 286, 519, 321, 434, 516, 281, 362, 281, 352], "temperature": 0.0, "avg_logprob": -0.16088540024227566, "compression_ratio": 1.183673469387755, "no_speech_prob": 1.9525057723512873e-05}, {"id": 332, "seek": 241720, "start": 2417.2, "end": 2423.2, "text": " def end codes.", "tokens": [1060, 917, 14211, 13], "temperature": 0.0, "avg_logprob": -0.2000593306526305, "compression_ratio": 1.4161073825503356, "no_speech_prob": 1.0783158359117806e-05}, {"id": 333, "seek": 241720, "start": 2423.2, "end": 2431.2, "text": " Self, comma, x, colon, and then we list all the types we support.", "tokens": [16348, 11, 22117, 11, 2031, 11, 8255, 11, 293, 550, 321, 1329, 439, 264, 3467, 321, 1406, 13], "temperature": 0.0, "avg_logprob": -0.2000593306526305, "compression_ratio": 1.4161073825503356, "no_speech_prob": 1.0783158359117806e-05}, {"id": 334, "seek": 241720, "start": 2431.2, "end": 2435.2, "text": " Just all of those.", "tokens": [1449, 439, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.2000593306526305, "compression_ratio": 1.4161073825503356, "no_speech_prob": 1.0783158359117806e-05}, {"id": 335, "seek": 241720, "start": 2435.2, "end": 2437.2, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.2000593306526305, "compression_ratio": 1.4161073825503356, "no_speech_prob": 1.0783158359117806e-05}, {"id": 336, "seek": 241720, "start": 2437.2, "end": 2446.2, "text": " And so now there's no point passing this name along because we're not doing the automatic version.", "tokens": [400, 370, 586, 456, 311, 572, 935, 8437, 341, 1315, 2051, 570, 321, 434, 406, 884, 264, 12509, 3037, 13], "temperature": 0.0, "avg_logprob": -0.2000593306526305, "compression_ratio": 1.4161073825503356, "no_speech_prob": 1.0783158359117806e-05}, {"id": 337, "seek": 244620, "start": 2446.2, "end": 2451.2, "text": " And so now we will return", "tokens": [400, 370, 586, 321, 486, 2736], "temperature": 0.0, "avg_logprob": -0.14583741063657013, "compression_ratio": 1.2340425531914894, "no_speech_prob": 7.527873094659299e-06}, {"id": 338, "seek": 244620, "start": 2451.2, "end": 2457.2, "text": " x.dihedral", "tokens": [2031, 13, 67, 4247, 24764], "temperature": 0.0, "avg_logprob": -0.14583741063657013, "compression_ratio": 1.2340425531914894, "no_speech_prob": 7.527873094659299e-06}, {"id": 339, "seek": 244620, "start": 2457.2, "end": 2460.2, "text": " self.k.", "tokens": [2698, 13, 74, 13], "temperature": 0.0, "avg_logprob": -0.14583741063657013, "compression_ratio": 1.2340425531914894, "no_speech_prob": 7.527873094659299e-06}, {"id": 340, "seek": 244620, "start": 2460.2, "end": 2465.2, "text": " So now we need to make sure we have a test of that.", "tokens": [407, 586, 321, 643, 281, 652, 988, 321, 362, 257, 1500, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.14583741063657013, "compression_ratio": 1.2340425531914894, "no_speech_prob": 7.527873094659299e-06}, {"id": 341, "seek": 244620, "start": 2465.2, "end": 2468.2, "text": " So what we could do", "tokens": [407, 437, 321, 727, 360], "temperature": 0.0, "avg_logprob": -0.14583741063657013, "compression_ratio": 1.2340425531914894, "no_speech_prob": 7.527873094659299e-06}, {"id": 342, "seek": 246820, "start": 2468.2, "end": 2478.2, "text": " was we could create a transform here", "tokens": [390, 321, 727, 1884, 257, 4088, 510], "temperature": 0.0, "avg_logprob": -0.16109410085176168, "compression_ratio": 1.2065217391304348, "no_speech_prob": 3.288726929895347e-06}, {"id": 343, "seek": 246820, "start": 2478.2, "end": 2484.2, "text": " called a dihedral item transform.", "tokens": [1219, 257, 1026, 71, 24764, 3174, 4088, 13], "temperature": 0.0, "avg_logprob": -0.16109410085176168, "compression_ratio": 1.2065217391304348, "no_speech_prob": 3.288726929895347e-06}, {"id": 344, "seek": 246820, "start": 2484.2, "end": 2490.2, "text": " And let's do it with a p equals one.", "tokens": [400, 718, 311, 360, 309, 365, 257, 280, 6915, 472, 13], "temperature": 0.0, "avg_logprob": -0.16109410085176168, "compression_ratio": 1.2065217391304348, "no_speech_prob": 3.288726929895347e-06}, {"id": 345, "seek": 246820, "start": 2490.2, "end": 2493.2, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.16109410085176168, "compression_ratio": 1.2065217391304348, "no_speech_prob": 3.288726929895347e-06}, {"id": 346, "seek": 249320, "start": 2493.2, "end": 2500.2, "text": " So we're going to go and", "tokens": [407, 321, 434, 516, 281, 352, 293], "temperature": 0.0, "avg_logprob": -0.19912144944474502, "compression_ratio": 1.1590909090909092, "no_speech_prob": 4.860382432525512e-06}, {"id": 347, "seek": 249320, "start": 2500.2, "end": 2510.2, "text": " then we will go show, we will go f image.", "tokens": [550, 321, 486, 352, 855, 11, 321, 486, 352, 283, 3256, 13], "temperature": 0.0, "avg_logprob": -0.19912144944474502, "compression_ratio": 1.1590909090909092, "no_speech_prob": 4.860382432525512e-06}, {"id": 348, "seek": 249320, "start": 2510.2, "end": 2514.2, "text": " And we would say", "tokens": [400, 321, 576, 584], "temperature": 0.0, "avg_logprob": -0.19912144944474502, "compression_ratio": 1.1590909090909092, "no_speech_prob": 4.860382432525512e-06}, {"id": 349, "seek": 249320, "start": 2514.2, "end": 2519.2, "text": " field equals zero.", "tokens": [2519, 6915, 4018, 13], "temperature": 0.0, "avg_logprob": -0.19912144944474502, "compression_ratio": 1.1590909090909092, "no_speech_prob": 4.860382432525512e-06}, {"id": 350, "seek": 251920, "start": 2519.2, "end": 2528.2, "text": " There's no need to use the i because this is random this time. So hopefully we'll see a nice mix of random transforms.", "tokens": [821, 311, 572, 643, 281, 764, 264, 741, 570, 341, 307, 4974, 341, 565, 13, 407, 4696, 321, 603, 536, 257, 1481, 2890, 295, 4974, 35592, 13], "temperature": 0.0, "avg_logprob": -0.13033387064933777, "compression_ratio": 1.336, "no_speech_prob": 1.5445788449142128e-05}, {"id": 351, "seek": 251920, "start": 2528.2, "end": 2536.2, "text": " Let's see if that works.", "tokens": [961, 311, 536, 498, 300, 1985, 13], "temperature": 0.0, "avg_logprob": -0.13033387064933777, "compression_ratio": 1.336, "no_speech_prob": 1.5445788449142128e-05}, {"id": 352, "seek": 251920, "start": 2536.2, "end": 2546.2, "text": " And that needs a field.", "tokens": [400, 300, 2203, 257, 2519, 13], "temperature": 0.0, "avg_logprob": -0.13033387064933777, "compression_ratio": 1.336, "no_speech_prob": 1.5445788449142128e-05}, {"id": 353, "seek": 254620, "start": 2546.2, "end": 2550.2, "text": " And super needs a field.", "tokens": [400, 1687, 2203, 257, 2519, 13], "temperature": 0.0, "avg_logprob": -0.11653083978697311, "compression_ratio": 1.1666666666666667, "no_speech_prob": 5.093579147796845e-06}, {"id": 354, "seek": 254620, "start": 2550.2, "end": 2557.2, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.11653083978697311, "compression_ratio": 1.1666666666666667, "no_speech_prob": 5.093579147796845e-06}, {"id": 355, "seek": 254620, "start": 2557.2, "end": 2560.2, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.11653083978697311, "compression_ratio": 1.1666666666666667, "no_speech_prob": 5.093579147796845e-06}, {"id": 356, "seek": 254620, "start": 2560.2, "end": 2565.2, "text": " So we've got lots of different random", "tokens": [407, 321, 600, 658, 3195, 295, 819, 4974], "temperature": 0.0, "avg_logprob": -0.11653083978697311, "compression_ratio": 1.1666666666666667, "no_speech_prob": 5.093579147796845e-06}, {"id": 357, "seek": 254620, "start": 2565.2, "end": 2570.2, "text": " versions. So let's get rid of this one.", "tokens": [9606, 13, 407, 718, 311, 483, 3973, 295, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.11653083978697311, "compression_ratio": 1.1666666666666667, "no_speech_prob": 5.093579147796845e-06}, {"id": 358, "seek": 257020, "start": 2570.2, "end": 2579.2, "text": " We don't need it twice. OK.", "tokens": [492, 500, 380, 643, 309, 6091, 13, 2264, 13], "temperature": 0.0, "avg_logprob": -0.1723899608705102, "compression_ratio": 1.1538461538461537, "no_speech_prob": 6.540256890730234e-06}, {"id": 359, "seek": 257020, "start": 2579.2, "end": 2583.2, "text": " And this one, we can probably hide", "tokens": [400, 341, 472, 11, 321, 393, 1391, 6479], "temperature": 0.0, "avg_logprob": -0.1723899608705102, "compression_ratio": 1.1538461538461537, "no_speech_prob": 6.540256890730234e-06}, {"id": 360, "seek": 257020, "start": 2583.2, "end": 2594.2, "text": " because it's just testing it on tensor point as well.", "tokens": [570, 309, 311, 445, 4997, 309, 322, 40863, 935, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1723899608705102, "compression_ratio": 1.1538461538461537, "no_speech_prob": 6.540256890730234e-06}, {"id": 361, "seek": 257020, "start": 2594.2, "end": 2597.2, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1723899608705102, "compression_ratio": 1.1538461538461537, "no_speech_prob": 6.540256890730234e-06}, {"id": 362, "seek": 259720, "start": 2597.2, "end": 2603.2, "text": " So those are transforms that work on a single item at a time.", "tokens": [407, 729, 366, 35592, 300, 589, 322, 257, 2167, 3174, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.10585824749137782, "compression_ratio": 1.5401069518716577, "no_speech_prob": 3.340459898026893e-06}, {"id": 363, "seek": 259720, "start": 2603.2, "end": 2606.2, "text": " So here is", "tokens": [407, 510, 307], "temperature": 0.0, "avg_logprob": -0.10585824749137782, "compression_ratio": 1.5401069518716577, "no_speech_prob": 3.340459898026893e-06}, {"id": 364, "seek": 259720, "start": 2606.2, "end": 2609.2, "text": " something called crop pad,", "tokens": [746, 1219, 9086, 6887, 11], "temperature": 0.0, "avg_logprob": -0.10585824749137782, "compression_ratio": 1.5401069518716577, "no_speech_prob": 3.340459898026893e-06}, {"id": 365, "seek": 259720, "start": 2609.2, "end": 2613.2, "text": " which will either crop or pad,", "tokens": [597, 486, 2139, 9086, 420, 6887, 11], "temperature": 0.0, "avg_logprob": -0.10585824749137782, "compression_ratio": 1.5401069518716577, "no_speech_prob": 3.340459898026893e-06}, {"id": 366, "seek": 259720, "start": 2613.2, "end": 2621.2, "text": " depending on whatever is necessary to create the size that you ask for, which we've seen in other versions of Fast AI.", "tokens": [5413, 322, 2035, 307, 4818, 281, 1884, 264, 2744, 300, 291, 1029, 337, 11, 597, 321, 600, 1612, 294, 661, 9606, 295, 15968, 7318, 13], "temperature": 0.0, "avg_logprob": -0.10585824749137782, "compression_ratio": 1.5401069518716577, "no_speech_prob": 3.340459898026893e-06}, {"id": 367, "seek": 259720, "start": 2621.2, "end": 2626.2, "text": " So we've done the same idea. There's a", "tokens": [407, 321, 600, 1096, 264, 912, 1558, 13, 821, 311, 257], "temperature": 0.0, "avg_logprob": -0.10585824749137782, "compression_ratio": 1.5401069518716577, "no_speech_prob": 3.340459898026893e-06}, {"id": 368, "seek": 262620, "start": 2626.2, "end": 2631.2, "text": " crop pad, which calls something called do crop pad.", "tokens": [9086, 6887, 11, 597, 5498, 746, 1219, 360, 9086, 6887, 13], "temperature": 0.0, "avg_logprob": -0.16088180541992186, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.397633791901171e-06}, {"id": 369, "seek": 262620, "start": 2631.2, "end": 2636.2, "text": " And then do crop pad is", "tokens": [400, 550, 360, 9086, 6887, 307], "temperature": 0.0, "avg_logprob": -0.16088180541992186, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.397633791901171e-06}, {"id": 370, "seek": 262620, "start": 2636.2, "end": 2644.2, "text": " defined. Let's move everything around so it's easier to see what's going on.", "tokens": [7642, 13, 961, 311, 1286, 1203, 926, 370, 309, 311, 3571, 281, 536, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.16088180541992186, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.397633791901171e-06}, {"id": 371, "seek": 262620, "start": 2644.2, "end": 2652.2, "text": " There we go. For tensor B box, for tensor point, and for any kind of image.", "tokens": [821, 321, 352, 13, 1171, 40863, 363, 2424, 11, 337, 40863, 935, 11, 293, 337, 604, 733, 295, 3256, 13], "temperature": 0.0, "avg_logprob": -0.16088180541992186, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.397633791901171e-06}, {"id": 372, "seek": 265220, "start": 2652.2, "end": 2656.2, "text": " So since we now have", "tokens": [407, 1670, 321, 586, 362], "temperature": 0.0, "avg_logprob": -0.15063258373376096, "compression_ratio": 1.1797752808988764, "no_speech_prob": 1.3210025826992933e-05}, {"id": 373, "seek": 265220, "start": 2656.2, "end": 2662.2, "text": " that working, we can in our crop pad transform", "tokens": [300, 1364, 11, 321, 393, 294, 527, 9086, 6887, 4088], "temperature": 0.0, "avg_logprob": -0.15063258373376096, "compression_ratio": 1.1797752808988764, "no_speech_prob": 1.3210025826992933e-05}, {"id": 374, "seek": 266220, "start": 2662.2, "end": 2682.2, "text": " simply call, as you see, do crop pad.", "tokens": [2935, 818, 11, 382, 291, 536, 11, 360, 9086, 6887, 13], "temperature": 0.0, "avg_logprob": -0.09422473775015937, "compression_ratio": 1.1770833333333333, "no_speech_prob": 2.392224268987775e-05}, {"id": 375, "seek": 266220, "start": 2682.2, "end": 2691.2, "text": " Still some room to refactor this a little bit, but it's on the right track.", "tokens": [8291, 512, 1808, 281, 1895, 15104, 341, 257, 707, 857, 11, 457, 309, 311, 322, 264, 558, 2837, 13], "temperature": 0.0, "avg_logprob": -0.09422473775015937, "compression_ratio": 1.1770833333333333, "no_speech_prob": 2.392224268987775e-05}, {"id": 376, "seek": 269120, "start": 2691.2, "end": 2697.2, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.11745335315835886, "compression_ratio": 1.4285714285714286, "no_speech_prob": 6.4389278122689575e-06}, {"id": 377, "seek": 269120, "start": 2697.2, "end": 2705.2, "text": " And yeah, as you can see, you can choose what padding mode you want, reflection or border, zeros.", "tokens": [400, 1338, 11, 382, 291, 393, 536, 11, 291, 393, 2826, 437, 39562, 4391, 291, 528, 11, 12914, 420, 7838, 11, 35193, 13], "temperature": 0.0, "avg_logprob": -0.11745335315835886, "compression_ratio": 1.4285714285714286, "no_speech_prob": 6.4389278122689575e-06}, {"id": 378, "seek": 269120, "start": 2705.2, "end": 2711.2, "text": " So then we can use", "tokens": [407, 550, 321, 393, 764], "temperature": 0.0, "avg_logprob": -0.11745335315835886, "compression_ratio": 1.4285714285714286, "no_speech_prob": 6.4389278122689575e-06}, {"id": 379, "seek": 269120, "start": 2711.2, "end": 2717.2, "text": " something you can then inherit from that to create random crop just by changing before call.", "tokens": [746, 291, 393, 550, 21389, 490, 300, 281, 1884, 4974, 9086, 445, 538, 4473, 949, 818, 13], "temperature": 0.0, "avg_logprob": -0.11745335315835886, "compression_ratio": 1.4285714285714286, "no_speech_prob": 6.4389278122689575e-06}, {"id": 380, "seek": 271720, "start": 2717.2, "end": 2726.2, "text": " So do a random crop, as you can see. So here's some random crops of this doggy.", "tokens": [407, 360, 257, 4974, 9086, 11, 382, 291, 393, 536, 13, 407, 510, 311, 512, 4974, 16829, 295, 341, 3000, 1480, 13], "temperature": 0.0, "avg_logprob": -0.11838481161329481, "compression_ratio": 1.5898876404494382, "no_speech_prob": 5.4757318139309064e-05}, {"id": 381, "seek": 271720, "start": 2726.2, "end": 2735.2, "text": " And one of the nice things here is it'll automatically take the", "tokens": [400, 472, 295, 264, 1481, 721, 510, 307, 309, 603, 6772, 747, 264], "temperature": 0.0, "avg_logprob": -0.11838481161329481, "compression_ratio": 1.5898876404494382, "no_speech_prob": 5.4757318139309064e-05}, {"id": 382, "seek": 271720, "start": 2735.2, "end": 2744.2, "text": " oh, we should check this is actually working. We want it to take the center crop automatically on the validation set, although I don't know", "tokens": [1954, 11, 321, 820, 1520, 341, 307, 767, 1364, 13, 492, 528, 309, 281, 747, 264, 3056, 9086, 6772, 322, 264, 24071, 992, 11, 4878, 286, 500, 380, 458], "temperature": 0.0, "avg_logprob": -0.11838481161329481, "compression_ratio": 1.5898876404494382, "no_speech_prob": 5.4757318139309064e-05}, {"id": 383, "seek": 274420, "start": 2744.2, "end": 2752.2, "text": " if we actually have that set up.", "tokens": [498, 321, 767, 362, 300, 992, 493, 13], "temperature": 0.0, "avg_logprob": -0.14411348955971853, "compression_ratio": 1.3896103896103895, "no_speech_prob": 8.800980140222237e-06}, {"id": 384, "seek": 274420, "start": 2752.2, "end": 2759.2, "text": " OK, we can do resizing. Similar idea again, just inheriting from crop pad.", "tokens": [2264, 11, 321, 393, 360, 725, 3319, 13, 10905, 1558, 797, 11, 445, 9484, 1748, 490, 9086, 6887, 13], "temperature": 0.0, "avg_logprob": -0.14411348955971853, "compression_ratio": 1.3896103896103895, "no_speech_prob": 8.800980140222237e-06}, {"id": 385, "seek": 274420, "start": 2759.2, "end": 2766.2, "text": " The famous random resize crop used in pretty much all ImageNet solutions is just another kind of crop pad.", "tokens": [440, 4618, 4974, 50069, 9086, 1143, 294, 1238, 709, 439, 29903, 31890, 6547, 307, 445, 1071, 733, 295, 9086, 6887, 13], "temperature": 0.0, "avg_logprob": -0.14411348955971853, "compression_ratio": 1.3896103896103895, "no_speech_prob": 8.800980140222237e-06}, {"id": 386, "seek": 276620, "start": 2766.2, "end": 2777.2, "text": " So we don't need to go through all that. And then we start the random transforms that will work on the GPU.", "tokens": [407, 321, 500, 380, 643, 281, 352, 807, 439, 300, 13, 400, 550, 321, 722, 264, 4974, 35592, 300, 486, 589, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.09988575217164593, "compression_ratio": 1.6062176165803108, "no_speech_prob": 1.482342440795037e-06}, {"id": 387, "seek": 276620, "start": 2777.2, "end": 2780.2, "text": " And there's nothing", "tokens": [400, 456, 311, 1825], "temperature": 0.0, "avg_logprob": -0.09988575217164593, "compression_ratio": 1.6062176165803108, "no_speech_prob": 1.482342440795037e-06}, {"id": 388, "seek": 276620, "start": 2780.2, "end": 2785.2, "text": " particularly different about them. These don't need to be refactored a little bit.", "tokens": [4098, 819, 466, 552, 13, 1981, 500, 380, 643, 281, 312, 1895, 578, 2769, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.09988575217164593, "compression_ratio": 1.6062176165803108, "no_speech_prob": 1.482342440795037e-06}, {"id": 389, "seek": 276620, "start": 2785.2, "end": 2793.2, "text": " But yeah, same basic idea. There's a before call. There's encodes for the different types you want.", "tokens": [583, 1338, 11, 912, 3875, 1558, 13, 821, 311, 257, 949, 818, 13, 821, 311, 2058, 4789, 337, 264, 819, 3467, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.09988575217164593, "compression_ratio": 1.6062176165803108, "no_speech_prob": 1.482342440795037e-06}, {"id": 390, "seek": 279320, "start": 2793.2, "end": 2803.2, "text": " And they're just written so that the the matrix math works out with the extra batch dimension automatically.", "tokens": [400, 436, 434, 445, 3720, 370, 300, 264, 264, 8141, 5221, 1985, 484, 365, 264, 2857, 15245, 10139, 6772, 13], "temperature": 0.0, "avg_logprob": -0.11966760635375977, "compression_ratio": 1.282758620689655, "no_speech_prob": 3.5559298794396454e-06}, {"id": 391, "seek": 279320, "start": 2803.2, "end": 2813.2, "text": " So, for example, dihedral is done on the GPU by using an F1 transform.", "tokens": [407, 11, 337, 1365, 11, 1026, 71, 24764, 307, 1096, 322, 264, 18407, 538, 1228, 364, 479, 16, 4088, 13], "temperature": 0.0, "avg_logprob": -0.11966760635375977, "compression_ratio": 1.282758620689655, "no_speech_prob": 3.5559298794396454e-06}, {"id": 392, "seek": 279320, "start": 2813.2, "end": 2815.2, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.11966760635375977, "compression_ratio": 1.282758620689655, "no_speech_prob": 3.5559298794396454e-06}, {"id": 393, "seek": 281520, "start": 2815.2, "end": 2825.2, "text": " And most of this stuff, the F1 transforms and warps and stuff we did touch on in the last part too. So go check that out. And the lighting transforms also were done there.", "tokens": [400, 881, 295, 341, 1507, 11, 264, 479, 16, 35592, 293, 1516, 1878, 293, 1507, 321, 630, 2557, 322, 294, 264, 1036, 644, 886, 13, 407, 352, 1520, 300, 484, 13, 400, 264, 9577, 35592, 611, 645, 1096, 456, 13], "temperature": 0.0, "avg_logprob": -0.16419163303098816, "compression_ratio": 1.460122699386503, "no_speech_prob": 5.507360583578702e-06}, {"id": 394, "seek": 281520, "start": 2825.2, "end": 2829.2, "text": " If you've forgotten.", "tokens": [759, 291, 600, 11832, 13], "temperature": 0.0, "avg_logprob": -0.16419163303098816, "compression_ratio": 1.460122699386503, "no_speech_prob": 5.507360583578702e-06}, {"id": 395, "seek": 281520, "start": 2829.2, "end": 2832.2, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.16419163303098816, "compression_ratio": 1.460122699386503, "no_speech_prob": 5.507360583578702e-06}, {"id": 396, "seek": 281520, "start": 2832.2, "end": 2836.2, "text": " So then finally,", "tokens": [407, 550, 2721, 11], "temperature": 0.0, "avg_logprob": -0.16419163303098816, "compression_ratio": 1.460122699386503, "no_speech_prob": 5.507360583578702e-06}, {"id": 397, "seek": 281520, "start": 2836.2, "end": 2841.2, "text": " you can check out 21.", "tokens": [291, 393, 1520, 484, 5080, 13], "temperature": 0.0, "avg_logprob": -0.16419163303098816, "compression_ratio": 1.460122699386503, "no_speech_prob": 5.507360583578702e-06}, {"id": 398, "seek": 284120, "start": 2841.2, "end": 2846.2, "text": " So this is ImageNet.", "tokens": [407, 341, 307, 29903, 31890, 13], "temperature": 0.0, "avg_logprob": -0.23004092200327728, "compression_ratio": 1.3862068965517242, "no_speech_prob": 1.6536563407498761e-06}, {"id": 399, "seek": 284120, "start": 2846.2, "end": 2851.2, "text": " And", "tokens": [400], "temperature": 0.0, "avg_logprob": -0.23004092200327728, "compression_ratio": 1.3862068965517242, "no_speech_prob": 1.6536563407498761e-06}, {"id": 400, "seek": 284120, "start": 2851.2, "end": 2853.2, "text": " looks pretty familiar.", "tokens": [1542, 1238, 4963, 13], "temperature": 0.0, "avg_logprob": -0.23004092200327728, "compression_ratio": 1.3862068965517242, "no_speech_prob": 1.6536563407498761e-06}, {"id": 401, "seek": 284120, "start": 2853.2, "end": 2856.2, "text": " Untar data, get image files. So I'm not going to use data blocks here.", "tokens": [8256, 289, 1412, 11, 483, 3256, 7098, 13, 407, 286, 478, 406, 516, 281, 764, 1412, 8474, 510, 13], "temperature": 0.0, "avg_logprob": -0.23004092200327728, "compression_ratio": 1.3862068965517242, "no_speech_prob": 1.6536563407498761e-06}, {"id": 402, "seek": 284120, "start": 2856.2, "end": 2865.2, "text": " Obviously you could use data blocks as well, but this is doing it fairly manually.", "tokens": [7580, 291, 727, 764, 1412, 8474, 382, 731, 11, 457, 341, 307, 884, 309, 6457, 16945, 13], "temperature": 0.0, "avg_logprob": -0.23004092200327728, "compression_ratio": 1.3862068965517242, "no_speech_prob": 1.6536563407498761e-06}, {"id": 403, "seek": 286520, "start": 2865.2, "end": 2879.2, "text": " Hector of the rows. These tags are mentioned in the previous code walkthroughs. So check them out. Otherwise, just look in the scripts, starting with the number nine to see how they're defined.", "tokens": [389, 20814, 295, 264, 13241, 13, 1981, 18632, 366, 2835, 294, 264, 3894, 3089, 1792, 11529, 82, 13, 407, 1520, 552, 484, 13, 10328, 11, 445, 574, 294, 264, 23294, 11, 2891, 365, 264, 1230, 4949, 281, 536, 577, 436, 434, 7642, 13], "temperature": 0.0, "avg_logprob": -0.1597722018206561, "compression_ratio": 1.5657894736842106, "no_speech_prob": 1.3211306395533029e-05}, {"id": 404, "seek": 286520, "start": 2879.2, "end": 2889.2, "text": " All right. So transforms for the independent variable will just be create an image for the dependent. It will be for the parent label function and then categorize.", "tokens": [1057, 558, 13, 407, 35592, 337, 264, 6695, 7006, 486, 445, 312, 1884, 364, 3256, 337, 264, 12334, 13, 467, 486, 312, 337, 264, 2596, 7645, 2445, 293, 550, 19250, 1125, 13], "temperature": 0.0, "avg_logprob": -0.1597722018206561, "compression_ratio": 1.5657894736842106, "no_speech_prob": 1.3211306395533029e-05}, {"id": 405, "seek": 288920, "start": 2889.2, "end": 2895.2, "text": " And then for the tuples, we go tensor optionally flip.", "tokens": [400, 550, 337, 264, 2604, 2622, 11, 321, 352, 40863, 3614, 379, 7929, 13], "temperature": 0.0, "avg_logprob": -0.1816011428833008, "compression_ratio": 1.4870129870129871, "no_speech_prob": 5.25525547345751e-06}, {"id": 406, "seek": 288920, "start": 2895.2, "end": 2897.2, "text": " Random resize crop.", "tokens": [37603, 50069, 9086, 13], "temperature": 0.0, "avg_logprob": -0.1816011428833008, "compression_ratio": 1.4870129870129871, "no_speech_prob": 5.25525547345751e-06}, {"id": 407, "seek": 288920, "start": 2897.2, "end": 2902.2, "text": " Create a data source.", "tokens": [20248, 257, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.1816011428833008, "compression_ratio": 1.4870129870129871, "no_speech_prob": 5.25525547345751e-06}, {"id": 408, "seek": 288920, "start": 2902.2, "end": 2917.2, "text": " And then on the GPU, turn it into code, or on the batch, I should say, put it on the GPU, turn it into a float tensor, normalize it.", "tokens": [400, 550, 322, 264, 18407, 11, 1261, 309, 666, 3089, 11, 420, 322, 264, 15245, 11, 286, 820, 584, 11, 829, 309, 322, 264, 18407, 11, 1261, 309, 666, 257, 15706, 40863, 11, 2710, 1125, 309, 13], "temperature": 0.0, "avg_logprob": -0.1816011428833008, "compression_ratio": 1.4870129870129871, "no_speech_prob": 5.25525547345751e-06}, {"id": 409, "seek": 291720, "start": 2917.2, "end": 2920.2, "text": " And so then we can create a data bunch.", "tokens": [400, 370, 550, 321, 393, 1884, 257, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.13835528359484317, "compression_ratio": 1.4722222222222223, "no_speech_prob": 1.0615916835376993e-05}, {"id": 410, "seek": 291720, "start": 2920.2, "end": 2923.2, "text": " There it is.", "tokens": [821, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.13835528359484317, "compression_ratio": 1.4722222222222223, "no_speech_prob": 1.0615916835376993e-05}, {"id": 411, "seek": 291720, "start": 2923.2, "end": 2926.2, "text": " And here's the data block version of the same thing.", "tokens": [400, 510, 311, 264, 1412, 3461, 3037, 295, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.13835528359484317, "compression_ratio": 1.4722222222222223, "no_speech_prob": 1.0615916835376993e-05}, {"id": 412, "seek": 291720, "start": 2926.2, "end": 2929.2, "text": " So you can compare.", "tokens": [407, 291, 393, 6794, 13], "temperature": 0.0, "avg_logprob": -0.13835528359484317, "compression_ratio": 1.4722222222222223, "no_speech_prob": 1.0615916835376993e-05}, {"id": 413, "seek": 291720, "start": 2929.2, "end": 2934.2, "text": " And again, data bunch.", "tokens": [400, 797, 11, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.13835528359484317, "compression_ratio": 1.4722222222222223, "no_speech_prob": 1.0615916835376993e-05}, {"id": 414, "seek": 291720, "start": 2934.2, "end": 2937.2, "text": " So then", "tokens": [407, 550], "temperature": 0.0, "avg_logprob": -0.13835528359484317, "compression_ratio": 1.4722222222222223, "no_speech_prob": 1.0615916835376993e-05}, {"id": 415, "seek": 291720, "start": 2937.2, "end": 2941.2, "text": " these are some of these should need to be exported, but", "tokens": [613, 366, 512, 295, 613, 820, 643, 281, 312, 42055, 11, 457], "temperature": 0.0, "avg_logprob": -0.13835528359484317, "compression_ratio": 1.4722222222222223, "no_speech_prob": 1.0615916835376993e-05}, {"id": 416, "seek": 294120, "start": 2941.2, "end": 2949.2, "text": " we can create a CNN learner to wrap our learner a bit more conveniently like we did in version one.", "tokens": [321, 393, 1884, 257, 24859, 33347, 281, 7019, 527, 33347, 257, 857, 544, 44375, 411, 321, 630, 294, 3037, 472, 13], "temperature": 0.0, "avg_logprob": -0.10293461481730143, "compression_ratio": 1.2636363636363637, "no_speech_prob": 6.9621628426830284e-06}, {"id": 417, "seek": 294120, "start": 2949.2, "end": 2953.2, "text": " Label smoothing", "tokens": [10137, 338, 899, 6259, 571], "temperature": 0.0, "avg_logprob": -0.10293461481730143, "compression_ratio": 1.2636363636363637, "no_speech_prob": 6.9621628426830284e-06}, {"id": 418, "seek": 294120, "start": 2953.2, "end": 2956.2, "text": " and", "tokens": [293], "temperature": 0.0, "avg_logprob": -0.10293461481730143, "compression_ratio": 1.2636363636363637, "no_speech_prob": 6.9621628426830284e-06}, {"id": 419, "seek": 294120, "start": 2956.2, "end": 2957.2, "text": " fit.", "tokens": [3318, 13], "temperature": 0.0, "avg_logprob": -0.10293461481730143, "compression_ratio": 1.2636363636363637, "no_speech_prob": 6.9621628426830284e-06}, {"id": 420, "seek": 294120, "start": 2957.2, "end": 2966.2, "text": " And we can see", "tokens": [400, 321, 393, 536], "temperature": 0.0, "avg_logprob": -0.10293461481730143, "compression_ratio": 1.2636363636363637, "no_speech_prob": 6.9621628426830284e-06}, {"id": 421, "seek": 296620, "start": 2966.2, "end": 2982.2, "text": " if we have any augmentation.", "tokens": [498, 321, 362, 604, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.364603853225708, "compression_ratio": 0.8620689655172413, "no_speech_prob": 2.144277823390439e-05}, {"id": 422, "seek": 296620, "start": 2982.2, "end": 2987.2, "text": " Oh, that's it listed.", "tokens": [876, 11, 300, 311, 309, 10052, 13], "temperature": 0.0, "avg_logprob": -0.364603853225708, "compression_ratio": 0.8620689655172413, "no_speech_prob": 2.144277823390439e-05}, {"id": 423, "seek": 298720, "start": 2987.2, "end": 3000.2, "text": " Not sure we might be need to add that in. Actually, we tend not to add much augmentation because we tend to use mix up nowadays if we want to use or epochs.", "tokens": [1726, 988, 321, 1062, 312, 643, 281, 909, 300, 294, 13, 5135, 11, 321, 3928, 406, 281, 909, 709, 14501, 19631, 570, 321, 3928, 281, 764, 2890, 493, 13434, 498, 321, 528, 281, 764, 420, 30992, 28346, 13], "temperature": 0.0, "avg_logprob": -0.19204422143789437, "compression_ratio": 1.5549738219895288, "no_speech_prob": 2.090377847707714e-06}, {"id": 424, "seek": 298720, "start": 3000.2, "end": 3009.2, "text": " So, so we tested this on more epochs and he was getting slightly better results than we were version one.", "tokens": [407, 11, 370, 321, 8246, 341, 322, 544, 30992, 28346, 293, 415, 390, 1242, 4748, 1101, 3542, 813, 321, 645, 3037, 472, 13], "temperature": 0.0, "avg_logprob": -0.19204422143789437, "compression_ratio": 1.5549738219895288, "no_speech_prob": 2.090377847707714e-06}, {"id": 425, "seek": 298720, "start": 3009.2, "end": 3014.2, "text": " So I thought that was a good sign.", "tokens": [407, 286, 1194, 300, 390, 257, 665, 1465, 13], "temperature": 0.0, "avg_logprob": -0.19204422143789437, "compression_ratio": 1.5549738219895288, "no_speech_prob": 2.090377847707714e-06}, {"id": 426, "seek": 301420, "start": 3014.2, "end": 3017.2, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.192452216634945, "compression_ratio": 1.2148760330578512, "no_speech_prob": 9.422341236131615e-07}, {"id": 427, "seek": 301420, "start": 3017.2, "end": 3021.2, "text": " I think", "tokens": [286, 519], "temperature": 0.0, "avg_logprob": -0.192452216634945, "compression_ratio": 1.2148760330578512, "no_speech_prob": 9.422341236131615e-07}, {"id": 428, "seek": 301420, "start": 3021.2, "end": 3025.2, "text": " one more question torch vision models be used.", "tokens": [472, 544, 1168, 27822, 5201, 5245, 312, 1143, 13], "temperature": 0.0, "avg_logprob": -0.192452216634945, "compression_ratio": 1.2148760330578512, "no_speech_prob": 9.422341236131615e-07}, {"id": 429, "seek": 301420, "start": 3025.2, "end": 3030.2, "text": " Yeah, anything should be usable.", "tokens": [865, 11, 1340, 820, 312, 29975, 13], "temperature": 0.0, "avg_logprob": -0.192452216634945, "compression_ratio": 1.2148760330578512, "no_speech_prob": 9.422341236131615e-07}, {"id": 430, "seek": 301420, "start": 3030.2, "end": 3033.2, "text": " They're just models.", "tokens": [814, 434, 445, 5245, 13], "temperature": 0.0, "avg_logprob": -0.192452216634945, "compression_ratio": 1.2148760330578512, "no_speech_prob": 9.422341236131615e-07}, {"id": 431, "seek": 301420, "start": 3033.2, "end": 3038.2, "text": " So if you look at X ResNet,", "tokens": [407, 498, 291, 574, 412, 1783, 5015, 31890, 11], "temperature": 0.0, "avg_logprob": -0.192452216634945, "compression_ratio": 1.2148760330578512, "no_speech_prob": 9.422341236131615e-07}, {"id": 432, "seek": 303820, "start": 3038.2, "end": 3047.2, "text": " it's just a normal and sequential. So, yeah, there shouldn't be any special requirements.", "tokens": [309, 311, 445, 257, 2710, 293, 42881, 13, 407, 11, 1338, 11, 456, 4659, 380, 312, 604, 2121, 7728, 13], "temperature": 0.0, "avg_logprob": -0.11361014976930082, "compression_ratio": 1.591549295774648, "no_speech_prob": 1.788023269000405e-06}, {"id": 433, "seek": 303820, "start": 3047.2, "end": 3053.2, "text": " If you try using a model and it doesn't work, let us know.", "tokens": [759, 291, 853, 1228, 257, 2316, 293, 309, 1177, 380, 589, 11, 718, 505, 458, 13], "temperature": 0.0, "avg_logprob": -0.11361014976930082, "compression_ratio": 1.591549295774648, "no_speech_prob": 1.788023269000405e-06}, {"id": 434, "seek": 303820, "start": 3053.2, "end": 3056.2, "text": " I guess the stuff like transfer learning.", "tokens": [286, 2041, 264, 1507, 411, 5003, 2539, 13], "temperature": 0.0, "avg_logprob": -0.11361014976930082, "compression_ratio": 1.591549295774648, "no_speech_prob": 1.788023269000405e-06}, {"id": 435, "seek": 303820, "start": 3056.2, "end": 3061.2, "text": " Maybe that's something we can do in a future walkthrough. Yeah, we should probably do that in a future walkthrough.", "tokens": [2704, 300, 311, 746, 321, 393, 360, 294, 257, 2027, 1792, 11529, 13, 865, 11, 321, 820, 1391, 360, 300, 294, 257, 2027, 1792, 11529, 13], "temperature": 0.0, "avg_logprob": -0.11361014976930082, "compression_ratio": 1.591549295774648, "no_speech_prob": 1.788023269000405e-06}, {"id": 436, "seek": 303820, "start": 3061.2, "end": 3064.2, "text": " Talk about how that stuff works.", "tokens": [8780, 466, 577, 300, 1507, 1985, 13], "temperature": 0.0, "avg_logprob": -0.11361014976930082, "compression_ratio": 1.591549295774648, "no_speech_prob": 1.788023269000405e-06}, {"id": 437, "seek": 306420, "start": 3064.2, "end": 3071.2, "text": " All right. Thanks for joining everybody. See you on the forums and I'll let you know if we're going to do more of these in the future.", "tokens": [1057, 558, 13, 2561, 337, 5549, 2201, 13, 3008, 291, 322, 264, 26998, 293, 286, 603, 718, 291, 458, 498, 321, 434, 516, 281, 360, 544, 295, 613, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.10578015717593106, "compression_ratio": 1.3333333333333333, "no_speech_prob": 2.2076334062148817e-05}, {"id": 438, "seek": 307120, "start": 3071.2, "end": 3098.2, "text": " Thanks for coming along. Bye.", "tokens": [50364, 2561, 337, 1348, 2051, 13, 4621, 13, 51714], "temperature": 0.0, "avg_logprob": -0.20046956539154054, "compression_ratio": 0.7837837837837838, "no_speech_prob": 1.7289334209635854e-05}], "language": "en"}