{"text": " Hello Jono, hello Tanishq. Are you guys ready for lesson 21? Ready. Yep, I'm excited. I don't know what I would have said if you had said no. So good. I'm actually particularly excited because I had a little bit of a peak preview of something that Jono has been working on, which I think is a super cool demo of what's possible with very little code with MiniAI. So let me turn it over to Jono. Great, thanks Jeremy. Yeah, so as you'll see when it's back to Jeremy to talk through some of the experiments and things we've been doing, we've been using the fashion MNIST dataset at a really small scale and really rapidly try out these different ideas and see some maybe nuances or things that we'd like to explore further. And so as we were doing that, I started to think that maybe it was about time to explore just ramping up a level, seeing if we can go to the next slightly larger dataset, slightly harder difficulty, just to double check that these ideas still hold for longer training runs and different more difficult data. That's a really good idea because I feel pretty confident that the learnings from fashion MNIST are going to move across most of the time these things seem to, but sometimes they don't and it can be very hard to predict. So this seems like a very wise choice. Yeah, and so we'll keep ramping up, but as a next step, one above fashion MNIST, I thought I'd look at this data called CIFAR-10. And so CIFAR-10 dataset is a very popular dataset originally for things like image classification, but also now for all of this, any paper on generative modeling. It's kind of like the smallest dataset that you'll see in these papers. And so, yeah, if you look at the classification results, for example, pretty much every classification paper since they started tracking has reported results on CIFAR-10 as well as their larger datasets. And likewise, with image generation, very, very popular. All of the recent diffusion papers will usually report CIFAR-10, add their image net and then whatever large massive dataset they're training on. We were somewhat notable in 2018 for managing to train. So for CIFAR-10, 94% classification is kind of the benchmark. So there was a competition a few years ago where we managed to get to that point at a cost of like 26 cents worth of AWS time, I think, which won a big global competition. So I actually hate CIFAR-10, but we had some real fun with it a few years ago. Yeah, and it's good. It's a nice dataset for quickly testing things out. But we'll talk about why we also like us as a group don't like it at all and we'll pretty soon move on to something better. So one of the things you'll notice in this notebook, I'm basically using all of the same code that Jeremy is going to be looking at and explaining. So I won't go into too much. But the data sets also on Hugging Face. So we can load it just like we did the fashion MNIST and the images are three channel rather than single channel. So the shape of the data is slightly different to what we've been working with. That's weird. Yeah, so we have instead of a single channel image, we have a three channel red, green and blue image. And this is what a batch of data looks like. So you've got 32 images in your batch. So that's batch by channel by height by width, right? Yeah, batch by channel by height and width. I was a little confused by the 32 by 32. Oh, yeah, it's fine. I got it now. Batch size can be arbitrary. So if you plot these, one of the things if you look at this, okay, I can see these are different classes. Like I know this is an airplane, a frog, an airplane, but it's actually a puzzle with an airplane on the cover, a bird, a horse, a car. That one, if you squint, you can tell it's a deer, but only if you really know what you're looking for. And so when we started to talk about generating these images, this is actually quite frustrating. Like this, if I generated this, I'd say this might be the model doing a really bad job. And that it's actually that this is a boat, this is a dog. It's just that this is what the data looks like. And so I've actually got something that can help you out. I'll show later today, which is something like this. It's really actually hard to see whether it's good because the images are bad. It can be helpful to have a metric that generate that can see how good samples are. So I'll be showing a metric for that later today. Yeah. And that'll be great. And I hope to have like automated. But anyway, I just wanted to flag like for visually inspecting these, it's not great. And so we don't really like CIFAR-10 because it's hard to tell. But still a good one to test with. So the noise defy and everything, I'm following what Jeremy is going to be showing exactly. The code works without any changes because we're adding random noise in the same shape as our data. So even though our data now has three channels, the noise apply function still works fine. If we try and visualize the noise based images, because we're adding noise in the red, pink, blue channels. And some of that's quite extreme values. Yeah, it looks slightly different. Looks all crazy RGB. But you can see, for example, this frog doesn't have as much noise and it's vaguely visible. But it is, it's a nearly impossible task to look at this and tell what image is hiding under all of that noise. So I think this is really neat that you could use the same noiseify. Yeah. And it still works. Thanks to, it's not just that shape thing, but I guess just thanks to kind of PyTorch's broadcasting kind of stuff. This often happens. You can kind of change the dimensions of things and it just keeps working. Exactly. And we've been paying attention to those broadcasting rules and the right dimensions and so on. Cool. So I'm going to use the same sort of approach to loading the unit, except that now obviously I need to specify three input channels and three output channels. Because we're working with three channel images. But I did want to explore for this demo, like, okay, how could I maybe justify wanting to do this kind of experiment tracking thing that I'll talk about. And so I'm bumping up the size of the model substantially. I've gone from this is the default settings that we were using for fashion MNIST, but the diffuser's default unit has what, nearly 20 times as many parameters. 274 million versus 15 million. So we're going to try a larger model. We're going to try some log bit training. And so I could just do the same training that we've always done. Just in the notebook. Set up a learner with progress CV to kind of plot the loss. And subtract some metrics. But, yeah, I don't know about you, but once it's beyond a few minutes training, I quickly get a patient. And I have to wait for it to finish before we can sample. So I'm doing the DDPM sample, but I have to, I actually interrupted the training to say I just want to get a look at what it looks like initially. And to plot some samples. And, again, the sampling function works without any modification. But I'm passing in my size to be a three channel image. Yeah, and so this is like, we could do it like this. But at some point I would like to, A, keep track of what experiments I've tried. And, B, be able to see things as it's going over time, including, like, I would love to see what the samples look like if you generate it after the first epoch, after the second epoch. And so that's where my little callback that I've been playing with comes in. So just before you do that, I'll just mention, like, I mean, there are simple ways you could do that, right? Like, one popular way a lot of people do is that they'll save some sample images as files every epoch or two. Or we could, like, the same way that we have a updating plot as we train with fast progress, we could have an updating set of sample images. So there's a few ways we could solve that. That wouldn't handle the tracking that you mentioned of, like, looking over time at how different changes have improved things or made them worse, whatever that would, I guess, would require you kind of like saving multiple versions of a notebook or keeping some kind of research journal or something. That'd be a bit fiddly. It is. And all of that's doable. But I also find, like, I'm a little bit lazy sometimes. Maybe I don't write down what I'm trying or, yeah, I've saved untitled numbers 37 notebooks. So, yeah, the idea that I wanted to show here is just that there are lots of other solutions for this kind of experiment tracking and logging. And one that I really like is called Weights and Biases. So I'll explain what's going on in the code here, but I'm running a training with this additional Weights and Biases callback. And what it's doing is it's allowing me to log whatever I'd like. So I can log samples at different stages. Okay, so you're switching to a website here called W&B.AI. So that's where your callback is sending information to. Yeah. So Weights and Biases accounts are free for personal and academic use. And it's very, very, like, I don't think I know anyone who writes for Weights and Biases. But it's a very nice service. You sign in and you log in on your computer or you get a little authentication token. And then you're able to log these experiments and you can log into different projects. And what it gives you is for each experiment, anything that you call Weights and Biases.log at any step in the training, that's getting logged and sent to their server and stored somewhere where you can later, like, access it and display it. They have these plots that you can, you know, visualize easily. And you can also share them very easily in, like, these reports that integrate this data sort of interactively. And why that's nice is that later, like, you can go and look at, so this is now the project that I'm logging to. You can log multiple runs with different settings. And for each of those, you have all of these things that you've tracked, like, your training loss and validation. But you can also track your learning rate if you've been in a learning rate schedule. And you can save your model as an artifact and it'll get saved on their server. So you can see exactly what run produced what model. It logs the code if you set that to, you can save, you know, save code equals true. And then it creates a copy of your whole Python environment, what libraries were installed, what code you ran. So for being able to come back later and say, oh, these images here, these look really good. I can go back and see, oh, that was this experiment here. I can check what settings I used. In the initialization, you can log whatever configuration details you'd like in any comments. And yeah, there's other frameworks for this. Yeah, in some ways, it's kind of, initially, when I first saw Weights & Biases, it felt a bit weird to me, actually, like, sending your information off to an external website. Because, I mean, before Weights & Biases existed, the most popular way to do this was something called TensorBoard, which Google provides, which is actually a lot like this, but it's a little server that runs on your computer. And so, like, when you log things, it just puts it into this little database on your computer, which is totally fine. But I guess, actually, there are some benefits to having somebody else run this service, you know, instead of running your own little TensorBoard or whatever server. You know, one is that you can have multiple people working on a project, collaborating. So I've done that before, where we will each be sending, like, different sets of hyperparameters, and then they'll end up in the same place. Or if you want to be really antisocial, you know, you can interrupt your romantic dinner and look at your phone to see how your training's going. So, like, yeah, I'm not going to say it's, like, always the best approach to doing things, but I think there's definitely benefits to using this kind of service. And it looks like you're showing us that you can also create reports for sharing this, which is also pretty nifty. Yeah, yeah. So I like for working with other people, or, like, you want to show somebody the final results, and being able to, yeah, like, pull together the results from some different runs, or just say, oh, look, by the way, here's a set of examples from my two most recent, and things track to different steps. What do you think of this? And, yeah, being able to have this, like, place where everyone can go and they can inspect the different loss curves. For any run, they can say, oh, you know, what was the batch size for this? Let me go look at the info there. Okay, I didn't log it, but I logged how many epochs and the learning rate. So, yeah, I find it quite nice, especially in a team, or if you're doing lots and lots of experiments, to be able to, like, have this permanent record that somebody else deals with, and they have the storage and the tracking. Yeah, it's quite nice. Wait, and this is all the code you had to write? That's amazing. Yeah, so this is using the callback system. The way Waits and Biases works is that you start an experiment with this oneDB.init, and you can specify any, like, configurational settings that you've used there. And then anything you need to log is oneDB.log, and you pass in whatever the name of your value is, like, I'm logging the loss, and then the value. And once you've done oneDB.finish, and that syncs everything up and sends it to the server. Oh, this is wild, the way you've inherited from MetricCB, and you replaced that underscore log that we previously used to allow fast progress to do the logging, and you've replaced it to allow Waits and Biases to do the logging. So, yeah, it's really sweet. Yeah, yeah, so this is using the callback system. I wanted to do the things that MetricCB normally does, which is tracking different metrics that you pass in. So this will still do that, and I just offload to the super, like, the original MetricCB method for things like the after batch. But in addition to that, I'd also like to log the Waits and Biases. And so before I fit, I initialize the experiments. Every batch, I'm going to log the loss. After every epoch, the default metrics callback is going to accumulate the metrics and so on, and then it's going to call this underscore log function. So I chose to modify that to say I'm going to log my training loss. I'm going to log my validation loss if I'm doing validation, and I'd like to log some samples. And Waits and Biases is quite flexible in terms of what you can log. You can create images or videos or audio or whatever. But it also takes a matplotlib figure, and so I'm generating some samples and plotting them with show image and splitting back that matplotlib figure, which I can then log, and that becomes these pretty pictures that you can see over time, like every time that log function runs, which is after every epoch, you can go in and see what the images look like. So where did that be? Maybe we can make your code even simpler in the future. If we had show images, maybe it could have like an optional return fig parameter that returns the figure, and then we could replace those four lines of code with one, I suspect. Yeah. Yeah, and I mean, this, I just sort of threw this together. It's quite early still. You could also, what I've done in the past is usually just create a PIL image where you can, you know, make a grid or overlay text or whatever else you'd like, and then just log that as 1db.image. Otherwise, like apart from that, I'm just passing in this callback as an extra callback to my set of callbacks for the learner instead of a metric callback. And so when I call that out fit, I still get my little progress bar. I still get this printed out version because my log function still also prints those metrics just for debugging. But instead of having to like watch the progress in the notebook, I can set this running, disconnect from the server, go have dinner, and then I can check on my phone or whatever. What do the samples look like? And okay, cool. They're starting to look like less than random nonsense, but still not necessarily recognizable. Maybe we need to train for longer. That can be the next experiment. What I should probably do next is think of some extra metrics, but Jeremy is going to talk about that. So for now, that's pretty much all I had to show is just to say, yeah, it's worth as you move to these longer, 10 minutes, 1 hour, 10 hours, these experiments, it's worth setting up a bit of infrastructure for yourself so that you know what were the settings I used. Maybe you're saving the model so you have the artifact as a result. And yeah, I like this Wix devices approach, but there's lots of others. The main thing is that you're doing something to track these experiments beyond just creating 20 different versions of your notebook. I love it. One thing I was going to note that, I don't know if many people know, but weights and biases can also save the exact code that you used to run for that run. So if you make any changes to your code and then you don't know which version of your code you used for this particular experiment, so then you can figure out exactly what code you used. So it's all completely reproducible. And so I love weights and biases, all these different features it has. And I use weights and biases all the time for my own research, almost daily. I had to put it on just last night and check on it today morning. So I use it all the time for my own research. And yeah, I use it especially to just know like, oh, this run had this particular config. And then the models go straight into weights and biases. And then if I want to run a model on the test set, I literally actually take it off of weights and biases, like download it from weights and biases and run it on the test set. So I use it all the time. And also just having the ability to have everything reproducible and know exactly what you were doing. It's very convenient instead of having to manually track it in some sort of like, I guess, a big Excel sheet or some sort of journal or something like that. Sometimes this is a lot more convenient, I feel. So yeah. Lest we get into too much filling from weights and biases, I'm going to put a slightly alternative point of view, which is I don't use it or any experiment tracking framework myself. Not to say maybe I could get some benefits by doing so, but I fairly intentionally don't because I don't want to make it easy for myself to try a thousand different hyperparameters or do kind of like ill-directed, you know, sampling of things. I like to be very, like, directed, you know. And so that's kind of the workflow I'm looking for is one that allows that to happen, right? Constantly going back and refactoring and thinking, what did I learn and how do I change things from here? And never kind of doing like 17 learning rates and six architectures and whatever. Now, obviously that's not something that Jono is doing at the moment. It would be so easy for him to, you know, if he wanted to. I can make a script that just does a hundred runs with different models and different things. And then I can look at my biases and say filter by the best loss, which is very tempting. So I would say to people, like, yeah, definitely be aware that these tools exist. And I definitely agree that as we do this, which is early 2023, weights and biases is by far the best one I've seen. It has by far the best integration with fast AI. And as of today, if Jono's pushed yet, it has by far the best integration with mini AI. I think also fast AI is the best library for using with weights and biases. It works in both ways. So, yeah, no, it's there. Consider using it, but also consider not going crazy on experiments. Because, you know, I think experiments have their place, clearly. But also carefully thought out hypotheses, testing them, changing your code is overall the approach that I think is best. Well, thank you, Jono. I think that's awesome. I got some fun stuff to share as well. Or at least I think it's fun. And what I wanted to share is like, well, the first of all, I should say, we had said, we all had said that we were going to look at units this week. We are not going to look at units this week. But we have a good reason, which is that we had said we're going to go from foundations to stable diffusion. Well, that was also a lie, because we're actually going beyond stable diffusion. And so we're actually going to start showing today some new research directions. I'm going to describe the process that I'm using at the moment to investigate some new research directions. And we're also going to be looking at some other people's research directions that have gone beyond stable diffusion over the past few months. So we will get to units. But we haven't quite finished, you know, as it turns out, the training and sampling yet. Now, one challenge that I was having, as I started experimenting with new things, was started getting to the point where actually the generated images looked pretty good. And it felt like, you know, almost like being a parent, you know, each time a new set of images would come out, I would want to convince myself that these were the most beautiful. And so I, yeah, and like, when they're crap, it's obvious they're crap, you know, but when they're starting to look pretty good, it's very easy to convince yourself you're improving. So I wanted to have a metric which could tell me how good they were. Now, unfortunately, there is no such metric. There's no metric that actually says, do these images, would these images look to a human being like pictures of clothes? Because only talking to a person can do that. But there are some metrics which give you an approximation of that. And as it turns out, these metrics are not actually, they're not actually a replacement for human beings looking at things. But they're a useful addition. So, and I certainly found them useful. So I'm going to show you the two most common, well, there's really the one most common metric, which is called FID. And I'm going to show another one called KID. So let me describe and show how they work. And I'm going to demonstrate them using the model we trained in the last lesson. Which is in DDPM2. And you might remember, we trained one with mixed precision. And we saved it as fashion DDPM MP for mixed precision. Okay, so this is all the usual imports and stuff. This is all the usual stuff. But there's a slight difference this time, which is that we're going to try to get the FID for a model we've already trained. So basically to get the model we've already trained, to get its FID, we can just torch.load it. And then .cuda to pop it on the GPU. So I'm going to call that the S model, which is the model for samples, the samples model. And this is just a copied and pasted DDPM from the last time. So that's for sampling. So we're going to do sampling from that model. And so once we've sampled from the model, we're then going to try and calculate this score called the FID. Now what the FID is going to do is it's not going to say how good are these images. It's going to say how similar are they to real images. And so the way we're going to do that is we're going to actually look specifically at for the images that we generated in these samples. We're going to look at some statistics of some of the activations. So what we're going to do, we've generated these, we've generated these samples. And we're going to create a new data loader, which contains no training batches. And it contains one validation batch, which contains the samples. It doesn't actually matter what the dependent variable is. So I just put in the same dependent variable that we already had. And then what we're going to do is we're going to use that to extract some features from a model. Now what do we mean by that? So if you remember back to notebook 14, we created this thing called summary. And summary shows us at different blocks of our model, there are various different output shapes. In this case, it's a batch size of 1024. And so after the first block, we had 16 channels, 28 by 28. And then we had 32 channels, 14 by 14, and so forth. Until just before the final linear layer, we had the 1024 batches, and we had 512 channels with no height and width. Now the idea of fit and kit is that the distribution of these 512 channels for a real image has a particular kind of like signature. Right, it looks a particular way. And so what we're going to do is we're going to take our samples. We're going to run it through a model that's learned to predict, you know, fashion classes. And we're going to grab this layer, right. And then we're going to average it across a batch, right, to get 512 numbers. And those are going to represent the mean of each of those channels. So those channels might represent, for example, you know, does it have a pointed collar? Does it have, you know, smooth fabric? Does it have sharp heels? And so forth, right. And you could recognize that something is probably not a normal fashion image if it says, oh yes, it's got sharp heels and flowing fabric. It's like, oh, that doesn't sound like anything we recognize. Right. So there are certain kind of like sets of means of these activations that don't make sense. So that's. This is a metric for. It's not a metric for an individual image necessarily, but it's across a whole lot of images. So if I generate a bunch of fashion images and I want to say, does this look like a bunch of fashion images? If I look at the mean, like maybe X percent have this feature and X percent have that feature. So if I'm looking at those means, as I'm comparing the distribution within all these images I generated, do roughly the same amount have sharp collars as those in the training? Yeah, that's a very good point too. Or the features generated are similar. Yeah. And it's actually going to get even more sophisticated than that. But let's just start at that level, which is this features.mean. So the basic idea here is that we're going to take our samples and we're going to pass them through a pre-trained model that has learned to predict what type of fashion something is. And of course, we train some of those in this notebook. And specifically, we trained a nice 20 epoch one in the data augmentation section, which had a 94.3% accuracy. And so if we pass our samples through this model, we would expect to get some, you know, useful features. One thing that I found made this a bit complicated, though, is that this model was trained using data that had gone through this transformation of subtracting the mean and dividing by the standard deviation. And that's not what we're creating in our samples. And so generally speaking, samples in most of these kinds of diffusion models tend to be between negative one and one. So I actually added a new section to the very bottom of this notebook, which simply replaces the transform with something that goes from negative one to one. And just creates those data loaders and then trains something that can classify fashion. And I saved this as not data.org, but data.org2. So this is just exactly the same as before, but it's a fashion classifier where the inputs are expected to be between minus one and one. Having said that, it turns out that our images, our samples are not between minus one and one. But actually, if you go back and you look at DDPM2, we just use tf.toTensor. And that actually makes images that are between zero and one. So actually, that's a bug. Okay, so our images have a bug, which is they go between zero and one. So we'll look at fixing that in a moment. But for now, we're just trying to get the fit of our existing model. So let's do that. So what we need to do is we need to take the output of our model and we need to multiply by two. So that'll be between zero and two and subtract one. So that'll change our samples to be between minus one and one. And we can now pass them through our pre-trained fashion classifier. Okay, so now how do we get that the output of that pooling layer? Because that's actually what we want to remind you. We want the output of this layer. So just to kind of flex our, you know, PyTorch muscles, I'm going to show a couple of ways to do it. So we're going to load the model I just trained, the data-orctv model. And what we could do is, of course, we could use a hook. And we have a hooks callback. So we could just create a function which just depends the output. So very straightforward. Okay, because that's what we want. We want the output. And specifically, it's so we've got these are all sequentials. So we can just go through and go, oh, one, two, three, four, five, the layer that we want. Okay, and so that's the module that we want to hook. So once we've hooked that, we can pass that as a callback. And we can then, it's a bit weird calling fit, I suppose, because we're saying train equals false. But we're just basically capturing. This is just to put make one batch go through and grab the outputs. So this means now in our hook, there's now going to be a thing called outp, because we put it there. And we can grab, for example, a few of those to have a look. And yep, here we've got a 64 by 512 set of features. Okay, so that's one way we can do it. Another way we could do it is that actually sequential models are what's called in Python collections. They have certain, a certain API that they're expected to support. And out of something a collection can do, like a list, is you can call del to delete something. So we can delete this layer and this layer and be left with just these layers. And once we do that, that means we can just call capture preds, because now they don't have the last two layers. So we can just delete layers eight and seven, call capture preds. And one nice thing about this is it's going to give us the entire 10,000 images in the test set. So that's what I ended up deciding to do. There's lots of other ways I played around with which worked, but I decided to choose these two as being two good, pretty good techniques. Okay, so now we've got what do a thousand real images look like at the end of the pooling layer. So now we need to do the same for our sample. So we'll load up our fashion DDPM MP. We'll call sample. Let's just grab 256 images for now. Make them go between minus one and one. Make sure they look okay. And as I described before, created data loaders where the validation set just has one batch which contains our samples. And call capture preds. Okay, so that's going to give us our features. And the reason why is because we're passing the sample to model. And model is the classifier. Okay, which we've deleted the last two layers from. So that's going to give us our 256 by 512. So now we can get the means. Now, that's not really enough to tell us whether something looks like real images. So maybe I should draw here. So we started out with our batch of 256. And our channels of 512. And we squished them by taking their mean. So it's now just 256. A vector. So this is the, sorry, wrong way around. We squished them this way. By 512. Because this is the mean for each channel. Okay, and we did exactly the same thing for the much bigger, you know, full set of real images. So this is our samples. And this is our real. But when we squish it, that's 10,000 by 512. We get again 512. So we could now compare these two. Right, but you know, you could absolutely have some samples that don't look anything like images. But have similar averages for each channel. So we do a second thing, which is we create a covariance matrix. Now, if you've forgotten what this is, you should go back to our previous lesson where we looked at it. But just to remind you, a covariance matrix says, in this case, we do it across the channels. So it's going to be 512 by 512. So it's going to take each of these columns. And it says, in each cell, so here's cell 1, 1. Basically it says, what's the difference between, it basically is saying, what's the difference between each row, each element here, and the mean of the whole column, multiplied by the, exactly the same thing for a different column. Now on the diagonal, it's the same column twice. So that means that these in the diagonal is just the variance. Right. But more interestingly, the ones in the off diagonal, like here, is actually saying, what's the relationship between column 1 and column 2. Right. So if column 1 and column 2 are uncorrelated, then this would be 0. Right. If they were identical, right, then it would be the same as the variance in here. So that's how correlated are they. And why is this interesting? Well, if we do the same, exactly the same thing for the reals, that's going to give us another 512 by 512. And it's going to say things like, so let's say this first column was kind of like, you know, doesn't have pointy heels. And, sorry, heels, spell. And the second one might be, doesn't have flowing fabric. Right. And this is where we say, okay, if, you know, generally speaking, you would expect these to be negatively correlated. Right. So over here in the reals, this is probably going to have a negative. Right. Whereas if over here it was like 0 or even worse if it's positive, it'd be like, oh, those are probably not real. Right. Because it's very unlikely you're going to have images that have both pointy heels are positively associated with a flowing fabric. So we're basically looking for two data sets where their covariance matrices are kind of the same. And their means are also kind of the same. All right. So there are ways of comparing these, you know, basically comparing two sets of data to say, are they, you know, from the same distribution. And you can broadly think of it as being like, oh, they have pretty similar covariance matrices. So they have pretty similar mean vectors. And so this is basically what the Freschet inception distance does. Does that make sense so far, guys? Yes. It's really striking me now how strong the similarity is to when we were talking about like the style loss and the kinds of things. How do we share the types of features that occur together without worrying about like which items in the data set. The Gram-Schmidt matrices or whatever. Exactly. Yeah. Now, the particular way of comparing. So, OK, so I've got the means and I've got the covariances for my samples. And I've actually just created this little calc stats. Right. So I always I'm showing you how I build things, not just things that are built. Right. So I always create things step by step and check their shapes. Right. And then I paste them into our merge the cells, copy the cells and merge them into functions. So here's something that gets the means and the covariance matrix. So then I basically do a call that both for my sample features and for my features of the actual data set or the test set and the data set. Now, what I now do with that, if they have those features, I can calculate this thing called the Frechet inception distance, which is here. And basically what happens is we. Multiply together the two covariance matrices. And that's now going to make them like bigger. Right. So we now need to basically scale that down again. Now, if we were working with. You know, non matrices. You know, if you kind of like multiply two things together. Then to kind of bring it back down to the original scale, you know, you could kind of like take the square root. Right. So particularly if it was by itself, you took the square root, you get back to the original. And so we need to do exactly the same thing to. Renormalize these matrices. The problem is that we've got. Matrices. And we need to take. The matrix square root. Now, the matrix square root. You might not have come across this before, but it exists. And it's the thing where. The matrix square root of the matrix a times itself is a. Now, I'm going to slightly cheap because. We've used the float square root before and we did not re implement it from scratch. Because it's in the Python standard library. And also it wouldn't be particularly interesting. But basically the way you can calculate. The float square root from scratch. Is by using. There's lots of ways, but you know. The classic way that you might have done it in high school is to use Newton's method. Which is where you basically. Can solve if you're trying to calculate, you know, a equals. Root x. Then you're basically saying. A squared. Equals x, which means you're saying a squared minus x equals zero. And. That's an equation that you can solve and you can solve it by basically taking the derivative. And taking a step along the derivative a bunch of times. You can basically do the same thing to calculate the matrix square root. And so. Here it is. Right. It's the Newton method. But because it's symmetric it's slightly more complicated. So it's a Newton-Schurtz method. And I'm not going to go through it. But it's basically the same deal. You go through up to. 100 iterations. And you basically. Do something like traveling along that kind of derivative. And then you say, okay, well. The result. Times itself. Ought to equal. The original matrix. So let's subtract the matrix times itself from the original matrix. And see whether the absolute value is small. And if it is, we've calculated it. Okay. So that's basically how we do a matrix square root. So we do. That's that. And so now that we have strictly speaking implemented from scratch. We're allowed to use the one that already exists. I thought she doesn't have one. Sadly. So we have to use the one. Sci-Pi. Sci-Pi. Min-Alg. So this is basically going to give us. A measure of similarity. Between the two covariance matrices. And then. We. Here's the measure of similarity. Between the two. Main matrices. Which is just the sum of squared. Errors. And then. Basically for reasons that aren't interesting. We're going to use the one. Basically for reasons that aren't interesting. But it's just normalizing. We subtract what's called the trace. Which is the sum of the diagonal elements. And we subtract two times the trace of the. This thing. And that's called the Frechet inception distance. So a bit hand wavy on the math. Because I don't think it's particularly relevant to anything. But it gives you a number. Which represents. How similar. Is. You know. This. For the samples. To this. For some real data. Now. It's weird. It's called Frechet inception distance. When we've done nothing to do with inception. Well the reason why. Is that people do not normally use. The fast.ai. Part two. Custom fashioned. MNIST. Data org 2. Pickle. They normally use a more famous. Model. They normally use the inception model. Which was an image net winning model. From Google brain. From a few years ago. There's no reason whatsoever. That inception is. A good model to use for this. Just happens to be the one. Which the original paper used. And as a result. Everybody now uses that. Not because they are sheep. But because you want to be able to compare your results. With other people's results. Perhaps. We actually don't. We actually want to compare our results. From our other results. And we're going to get a much more. Accurate. Metric if we use a. Model that's good specifically. At recognizing fashion. So that's why we're using this. So very very few people bother. To use this most people just. Hip install. Python fit or whatever it's called. And use inception. But it's actually better to use. If you're comparing to papers. It's better to use a model that you've trained on your data. And you know it's good at that. So I guess this is not a. FED. It's a. Well maybe FED now stands for fashion. Fashion MNIST. I don't know what it stands for. I should do something. I wanted to. Bring up two other caveats. Of FID. Especially then like in the. The other thing is that FID. Is dependent on the number of samples. That you use. So as the number of samples they use. For measuring FID. It's you know it's more accurate. If you use more samples. And it's less accurate if you use less samples. It's actually biased. So if you use less samples. It's too high specifically. Yeah. So in papers you'll see them. Report how many samples they used. And so even in comparing to other papers. And comparing between different models. And different things you want to make sure. That you're comparing with the same amount of samples. Otherwise you know it might just be high. Because they just use less number of samples. Or something like this. So you want to make sure that's comparable. And then the other thing that is you know. Because I guess it's a kind of a side effect. If using the inception network. In these papers is the fact that. All of these are at size. 299 by 299. Which is like the size that the inception model was trained. So actually when you're applying this. Inception network for measuring this distance. You're going to be resizing your images. To 299 by 299. Which in you know different cases. That may not you know make much sense. So like in our case. We're working with 32 by 32. Or yeah 32 by 32. Or 28 by 28 images. These are very small images. And then we resize it to 299. Or in other cases. If you have an issue with some of these latest models. You have these large. 512 by 512. Or 1024 by 1024 images. And then you're you know. Kind of shrinking these images. To 299 by 299. And you're losing a lot of that detail. And quality in those images. So actually it's kind of become a problem. With some of these latest papers. When you look at the FID scores. And how they're comparing them. And then visually when you see them. They're comparing them to smaller images. But the FID score doesn't capture that as well. Because you're actually using these much smaller images. So there are a bunch of different caveats. And so FID you know. It's very good for like yeah. It's nice and simple and automated. You know for this sort of comparison. But you have to be aware of all these different caveats. Of this metric as well. So excellent segue. Because we're going to look at exactly those two things right now. And in fact. There is a metric. That compares the two distributions. In a way that is not biased. So it's not necessarily higher or lower. If you use more or less samples. And it's called the KID. Or KID. Which is the Kernel Inception Distance. It's actually significantly simpler to calculate. Than the Frechet Inception Distance. And basically what you do. Is you create a bunch of groups. A bunch of partitions. And you compare them. And you get a result. A bunch of partitions. And you go through each of those partitions. And you grab a few of your X's. At a time. And a few of your Y's. At a time. And then you calculate something called the MMD. Which is here. Which is basically. Again the details don't really matter. We basically do. A matrix product. And we actually take the cube of it. This K is for kernel. And we basically do that for. The first sample biased. Compared to itself. The second compared to itself. And the first compared to the second. And we then. Normalize them in various ways. And add the two. With themselves together. And subtract with the other one. And this one actually. Does not use the KID. And this one actually does not. Use the stats. It doesn't use the means. And covariance metrics. It uses the features directly. And the actual final result. Is basically the mean. Of this calculated across. Different little batches. Yeah again the math doesn't really. Matter as to. You know exactly. Why all these are exactly what they are. But it's going to give you again a measure. Of the similarity of these two distributions. At first I was confused. As to why people weren't using this. Because people don't tend to use this. And it doesn't have this. A nasty bias problem. And now that I've been using it for a while. I know why. Which is that it has a very high variance. Which means when I call it multiple times. With just like samples. It's very different values. And so I actually haven't found this useful. At all. So we're left in. The situation which is. Yeah we don't actually have a good unbiased metric. And I think that's. The truth of where we are. There is best practices. And even if we did. All I would tell you is like. How similar distributions are to each other. It doesn't actually tell you whether they look any good. So that's why. Pretty much all good papers. They have a section on human testing. But I've definitely found this. Useful for me. For like comparing. Fashion images which. Particularly like humans are good at looking at. Faces that are reasonably high resolution. And be like oh that eye looks kind of weird. But we're not good at looking at 28 by 28. Fashion images. So it's particularly helpful for stuff. That our brains aren't good at. So I basically wrap this up into a class. Which I called image eval. For evaluating images. And so what you're going to do is. You're going to pass in. A pre-trained model. A classifier. And your data loaders. Which is the thing that we're going to use. To basically calculate. The real images. So that's going to be. You know. The data loaders that were in this. Learn. So the real images. And so what it's going to do. In this class. Then again this is just copying and pasting. The previous lines of code. And putting them into a class. This is going to be then something that we call. Capture preds on. To get our features for the real images. And then we can also calculate the stats. For the real images. And so then we can call fit. By calling calc fit. The thing we already had. Passing in the stats for the real images. And calculate the stats. For the features. From our samples. Where the features are. The thing that we've seen before. We pass in our samples. Any random y value is fine. So I just have a single tensor there. And call capture preds. So we can now create an image. If our object. Passing in our classifier. Passing in our data loaders. With the real data. Any other callbacks you want. And if we call fit. Takes about a quarter of a second. And 33.9 is the fit. For our samples. So something that I think. Okay then kit. Kit's very going to be a very different scale. It's only 0.05. So kits are generally much smaller than fits. So I'm mainly going to be looking at fits. And so here's what happens. And so here's what happens. If we call fit. On sample 0. And then sample 50. And then sample 100. And so forth. All the way up to 900. And then we also do samples 975, 990, and 999. And so you can see. Over time our samples. Fits improved. So that's a good little test. There's something curious. About the fact that they stopped improving. So that's interesting. I've not seen anybody plot this graph before. I don't know if Jono or Tanishka. If you guys have. I feel like it's something people should be looking at. Because it's really telling you. Is your sampling. Making consistent improvements. And to clarify. This is like the predicted denoise sample. At the different stages during sampling right. Yes exactly. If I was to stop sampling now. And just go straight to the predicted X error. So I just want to check. Our samples. Yeah we preset. We add the X not hat at each time. Yep. Exactly. Same for kid. And I was hoping that they would look the same. And they do. So that's encouraging. That kid and fit are basically measuring the same thing. And then something else. That I haven't seen people do. But I think it's a very good idea. To use the same data. That you could get. Now that's a bit unfair. Because I think the different sizes. Our data. Is 512. Our sample is 256. But anyway it's a pretty huge difference. And then yeah. The second thing. That Tanishka talked about. Which I thought I'd actually show. Is what does it take to use. You know to get a real fit. I don't particularly feel like re-implementing the inception network. So I guess I'm cheating here. I'm just going to grab it from itorchfit. But there's absolutely no reason. To study the inception network. Because it's totally obsolete at this point. And as Tanishka mentioned. It wants 299 by 299 images. Which actually. You can just call resize input. To have that done for you. It also expects 3 channel images. So what I did. Is I created a wrapper. For an inception v3 model. That when you call forward. It takes your. Your. Batch. And replicates. The channel. Three times. So that's basically creating a. Three channel version of a black and white image. Just by replicating it three times. So with that. Wrapping and again. This is good like flexing. Of your PyTorch muscles. You know try to make sure. You can replicate this. That you can. Get an inception model. Working on your. Bash and MNIST samples. And yeah. Then from there. We can just pass that. To our image eval instead. And so on our samples. That gives us 63.8. And on a real batch of data. It gets 27.9. And like I find this. Like a good sign. That this is much less effective. Than our real fashioned MNIST classifier. Because like that's only. You know difference of. A ratio of three or so. You know the fact that our. Fid. For real data. Using a real classifier. With 6.6. Yeah. So that is. That and. We now have a Fid. More specifically we now have an image eval. Class. Did you guys have any. Questions or comments about that. Before we keep going. No. Let's just say again that. Pretty much every other Fid you see. Reported is going to be. You know set up for CIFAR 10. Tiny 32 by 32 pixels. Resized up to 299. And Fid through inception. That was trained on an image. Not CIFAR 10. So yeah it's bearing in mind that. Once again this is a slightly weird metric. And even things like. The types of image. Like the image resizing algorithms. In PyTorch and TensorFlow. Might be slightly different. Or you know if you saved your images as JPEGs. And then reloaded them. So just to reiterate. What this will like. The takeaway from all of this that I get. Is that it's really useful. Everything's the same. Like using the same backbone model. Using the same approach. The same number of samples. Then you can compare it's apples to apples. But yeah for one set of experiments. A Fid of 30 might be good. Because of the way everything's set up. And for another that might be terrible. So trying to compare to paper or whatever. So I'm going to. Maybe the approach. Is that like if you're doing your own experiments. You know these sorts of metrics are good. But then if you're going to compare to other models. It's best to rely on human studies. If you're comparing to other models. And that yeah I think that's kind of the. The sort of. Approach or mindset that. We should be having when it comes to this. Yeah or both you know. But yeah so we're going to see this is going to be. Very useful for us. And we're going to be using. The same. Pretty much all the time we're going to use the same. Number of samples and we're going to use the same. Fashion MNIST specific classifier. So. The first thing I wanted to do was fix our bug. And to remind you. The bug was that we. Had we were feeding into our. Unit in DDPM v2. And the original DDPM. Images that were from 0 to 1. And yeah. That's that's wrong. That's like nobody does that. Everybody feeds in images that are from minus. 1 to 1. So that's very easy to fix. You just. Jeremy just to ask like what why. Is that a bug. Why is a bug I mean it's like everybody. Knows it's a bug because that's what everybody does. Like I've never seen anybody do anything. Else and it's very easy to fix. So I fixed it by adding this to. DDPM v2. And I reran it. And it didn't work. It made it worse. And. This was the start. Of. You know a few horrible days. Of pain because. Like when you. You know. Fix a bug and it makes things worse. That generally suggests there's some other bug. Somewhere else that somehow is offset. Your first bargain. You know I basically went back through every other. Notebook. And every cell. And I did find at least one. Bug. Elsewhere which is that we hadn't been shuffling. Our training sets the whole time. So I fixed that. But it's got absolutely nothing to do with this. And I ended up going through everything from scratch. Three times. Rerunning everything three times checking every intermediate. Output three times so days of. You know. No progress at all. At which point. I then asked. John O's question to myself. More carefully and provided a less. Flippant response to myself. Which was. Well I don't know why everybody does this. Actually. So I asked. Anish can John O and I was like. And Pedro and I was like. If you guys seen any. Math papers. Whatever. That's based on. This particular. Input range. And yeah. You guys are both like. No I haven't. It's just what everybody does. So. At that point. It raised the possibility that like. Okay maybe. Maybe what everybody does is not the right thing to do. And. Is there any reason to believe it is the right thing to do. And given that it seemed like fixing the bug. Made it worse. Maybe not. And then but then it's like well. Okay we are pretty confident. From everything we've learned and discussed. That having centered data is better than. Uncentered data. So having data that go from zero to one. Clearly seems weird. So maybe the issue is not that we've changed. The center but that we've scaled it down. So rather than having a range of two. It's got a range of one. So at that point. You know. I did something very simple. Which was I. Did this. I subtracted point five. So now rather than going from naught to one. It goes from minus point five. To point five and so the theory. Here then was okay if. Our hypothesis is correct. The negative one to one range has no. Foundational reason for being. And we've accidentally hit on something. Which is that a range of one is better than a range of two. And this should be better still. Because this is a range of one. And it's centered properly. And so this is DDPM v3. And I ran that. And yes it. It appeared to be better. And this is great because now I've got fit. I was able to run fit on DDPM v2. And on DDPM v3. And it was dramatically, dramatically, dramatically better. And in fact I was running a lot. A lot of other experiments at the time. Which we will talk about soon. And like all of my experiments. Had totally fallen apart when I fixed the bug. And once I. Did this. All the things that I thought. Thought weren't working suddenly started working. So you know this is often the case. Is that. Bugs can. Outlight. Accidental discoveries. And the trick is always to be. Careful enough to recognize. When that's happened. Some people might remember the story. This is how the noble gases were discovered. A chemistry experiment. Went wrong. And left behind some strange bubbles. At the bottom of the test tube. Most people would just be like. Huh. Whoops. Bubbles. But people who are careful enough actually went. No there shouldn't be bubbles there. Let's test them carefully. It's like they don't react. Again most people would be like. Oh that didn't work. The reaction failed. But you know if you're really careful. You'll be like. Oh maybe the fact they don't react. When you first showed us this thing. I kind of said. The images looked fine. The fit was slightly worse. But it was okay. And if you trained it longer. It eventually got better mostly. There were some things that sampling. Occasionally went wrong. One image in a hundred or something like that. But it was like. This isn't like everything completely fell apart. No it's just the truth. It was slightly worse than expected. I tried a bunch of things. I just doubled my training time. And set a few runs going. And looked at the weights and biases stats later. And oh that seems like it's better now. It just needed to train for longer. And we have internet GPUs and lots of money. You wouldn't notice this. It wasn't like. The fact that you picked up on it. Showed that you had this deep intuition. For where it should be at this stage in training. Versus where it was. What the samples should look like. I've expected a fit of nine. And I'm getting 14. What's up here. And that was enough to start asking these questions. And you jumped on all. And started to think. Where this came from. I drive people crazy. That I work with. I don't know why you guys aren't crazy yet. But with this kind of like. No I need to know exactly why. This is not exactly what we expected. But yeah this is why. To find. When something's mysterious and weird. It means that there's something you didn't understand. And that's an opportunity to learn something new. So that's what we did. And so that was quite exciting. Because yeah going minus 0.5 to 0.5. Made the fit better still. I was definitely in. I moved from this frame of mind. From like. I was so depressed. I was so mad. I still remember when I spoke to Jotto. I was so upset. And then I was suddenly like. Oh my gosh we're actually onto something. So I started experimenting more. And a bit more confidence at this point. I guess. And one thing I started looking at. Was our schedule. We'd always been copying and pasting. This standard. Again set of stuff. Questioning everything. Why is this a standard? Why are these numbers here? And I didn't see any particular reason. Why those numbers were there. And I thought. We should maybe experiment with them. So to make it easier. I created a little function. That would return a schedule. Now you could create a new class. For a schedule. But something that's really cool. Is a thing in Python called SimpleNameSpace. Which is a construct in C. Basically lets you wrap up a little. Bunch of keys and values. As if it's an object. So I created this little. SimpleNameSpace. Which contains our alphas. Our alpha bars. And our sigmas. For our normal. EtaMax. Xs.02. N space. This is what we always do. But there's an alternative approach. Which is cosine schedule. Which is where you basically. Set alpha bar. Equal to. T. As a fraction of big T. Times pi over 2. Cosine of that. Squared. And if you make that your alpha bar. You can then basically. Reverse back out to calculate. What alpha must have been. And so we can create a schedule. For this cosine schedule as well. And. Yeah this cosine schedule. Is I think pretty recognized. As being better. Than this. Linear schedule. And so I thought. Okay it'll be interesting to look at. How they compare. And in fact. Really all that matters is. The alpha bar. Is you know. The total amount of. Noise that you're adding. So in DDPM. When we do noisify. You know it's. It's alpha bar. That we're actually using. The amount of the image. And 1 minus alpha bar. Exactly. Yeah. So I just printed those out. Plotted those. This linear schedule. And this cosine schedule. And you can really see the linear schedule. It really sucks badly. It's got a lot of time steps. Where it's basically about 0. And. You know. That's. Something we can't really do anything with. You know. Whereas the cosine schedule. Is really nice and smooth. And there's not many steps. There's not nearly one. So I was kind of inclined. To try using the cosine schedule. But then I thought well. It would be easy enough to get rid of this big flat bit. By just decreasing beta max. That would be another thing we can do. So I tried. Oh sorry first of all I should mention. That the other thing that's really important. Is the slope of these curves. Because that's how much things are stepping. During the sampling process. And so here's the slope of the lin. And you can see the cosine slope. Really nice right. You have. This nice smooth curve. Where else the linear is just a disaster. So yeah. If I change beta max to 0.01. That actually. Gets you nearly. The same curve as the cosine. So I thought that was very interesting. It kind of made me think. Like why on earth. Why is use 0.02 as the default. And so we actually talked to. Robin. Who is one of the two lead authors on the stable diffusion paper. And. We talked about all of these things. And he said oh yeah we noticed. Not exactly this. But we know we experimented with everything. And we noticed that when we decreased beta max. We got better results. And so actually stable diffusion uses beta max at 0.012. I think that might be a little bit higher. Than they should have picked. So it's interesting talking to Robin. To see like all of these kinds of experiments. And like things that we. Tried out. They had been there as well. And noticed the same things. That the inputs range as well. They have this magical factor of 0.18. So to whatever. They scale the latency by. And if you ask why. Oh yeah we want to delay this to be. Like roughly uniform range or whatever. But that's also like that's. Reducing the range of your. Inputs to. I think exactly. We independently discovered. And they independently discovered this idea. Yeah exactly. Yeah exactly. So we'll be talking more about. Like what's actually going on with that. Maybe next lesson. Anyway so here's the curves as well. They're also pretty close. So at this point I was kind of thinking. I'm going to try to do as little as possible. So I'm going to keep using a linear schedule. But I'm just going to change betamax to 0.01. For my next you know. Version of GDPM. So that's what I've got here. Linear schedule betamax 0.01. And so that I wouldn't really have to change any of my code. I then just put those in the same variable names. That I've always used. So then noisify is exactly the same. As it always has been. So now I just repeat. Everything that I've done before. And if I show a batch of data. I can already see. That there's you know. More actually recognizable images. Which I think is very encouraging. Previously they like almost all of them. Had been pure noise. Which is not a good sign. So okay so now I just train it. Exactly the same as GDPM v2. And so save this as fashion GDPM 3. Oh and then the other things I've done here. Is you know. This did turn out to work pretty well. I actually decided. Let's keep going even further. So I actually doubled all of my channels. From before. And I also increased the number of epochs by 3. Because things are going so well. I was like how well could they go. So we've got a bigger model. Trained for longer. It only takes a few minutes. So that's what the 25 here is. The number of epochs. And it's the same as it always has been. So. Create 512 samples. And here they are. And they definitely look to me. You know. Great. Like I'm not sure I could recognize. Whether these are real samples. Or generated samples. But luckily. You know we can test them. So we can load up our data org2. Delete the last two layers. Pass that to image val. And get a FID for our samples. And it's 8. And then. I chose 512 for a reason. Because that's our batch size. So then I can compare that like with like. For the FID for the actual data. And it's 6.6. So this is like hugely exciting to me. We've got down to a FID. That is nearly as good as. Real images. So I feel like. So I feel like this is. You know. In terms of image quality. For a small. Unconditional sampling. I feel like we're done. You know pretty much. And so at this point. I was like okay. Well can we make it faster. You know at the same quality. And I just wanted to experiment with a few things. Like really obvious ideas. And in particular I thought. We're calling this. A thousand times. Which means we're calling. This. A thousand times. Which is running the model. And that's slow. And most of the time. You just move a tiny bit. So the model is pretty much the same. You know the noise being predicted. Is pretty much the same. Which is obvious. Which is I decided let's only call the model. Every third time. You know. And maybe also just the last 50. To help it fine tune. I don't know if that's necessary. Other than that it's exactly the same. So now this is basically three times faster. And. Yeah. Samples look basically the same. So the fit is 9.78. Versus 8.1. And the normal variance of fit. So I don't know. You'd have to run this a few times. Or use bigger samples. But this is basically saying. Yeah you probably don't need to. Call the model a thousand times. I did something else slightly weird. Which is I basically said. Let's create a different schedule. For how often we call the model. Which is I created this thing called sampleAt. It basically said. When you're. Every 10. And then for the next few every 9. And then for the next few every 8. And so forth. And just for the last 100 do it every 1. So that makes it even faster. Samples look good. This is. You know it's definitely worse though now. But it's still not bad. So. Yeah I kind of felt like. All right this is encouraging. And this stuff before we fixed the. They looked really bad. You know. That's why I was thinking my code was full of bugs. So at this point I'm thinking. Okay we can create extremely high quality. Samples using ddpm. What's the like. You know best paper out there. For doing it faster. And the most popular paper for doing it faster. Is ddim. So I thought. We might switch to this next. So we're now at the point. Where we're not actually going to. Retrain our model at all. Right if you noticed. With these different sampling approaches. I didn't retrain the model at all. We're just saying okay we've got a model. The model knows how to. Estimate the noise in an image. How do we use that. To call it multiple times. To. Denoise using. Iterative refinement. As Jono calls it. And so. Ddim. Is a. Other way of doing that. So what we're going to do. I'm going to show you how I. Built. My own ddim. From scratch. And I kind of cheated. Which is a. There's already an existing one in diffusers. So I decided. I will use that first. Make sure everything works. And then I'll try and reimplement it from scratch. Myself. So that's kind of like. When there's an existing thing that works. That's what I like to do. And it's been really good. To have my own ddim from scratch. Because now I can modify it. And I've made it much more. Concise code than the diffusers version. So. Now. We had created this. Class called unit. Which. Asked the tuple of x's. Through as individual parameters. And returned the dot sample. But not surprisingly. The given that this comes from diffusers. And we want to use the diffuser schedulers. The diffusers. Schedulers. Assume this has not happened. It wants the x. As a tuple. And it expects to find the think.cod.sample. So here's something crazy. When we save. This thing. This pickle. It doesn't really know anything about the code. Right. It just knows that it's from a class. Called unit. So we can actually. Lie. We can say. Oh yeah. We can say. This is a model with no other changes. And python doesn't know or care. Right. So this we can now load up this model. And it's going to use this unit. Okay. So this is where it's useful to understand. How python works behind the scenes. Right it's it's it's a very simple. Programming language. So we've now got a model. Which we've trained. But it's not it's just going to. Work seamlessly. With the. Diffuser schedulers. So we'll start by actually repeating what we already know. How to do. Which is use a ddpm scheduler. So we have to tell it what beta we used. To train. And so we can grab some random data. And so. We could say. Okay we're going to start. At time step 999. So let's create a batch of data. And this is the way that diffuses thing works. Is you call scheduler.step. And that's the thing. Which does. Those lines. That's the thing. That calculates. Xt given noise. So that's what. Scheduler.step does. So that's why you pass in. Xt and the time step and the noise. And that's going to give you a new. Set. And so I ran that. As usual first. Cell by cell to make sure I understood how it all worked. I then copied those cells. And merged them together. And chucked them in a loop. So this is now going to go through all the time steps. Use a progress bar to see how we're going. Get the noise. Call step. And append. So this is just ddpm. But using diffusers. And not surprisingly. We got exactly the same results. As you know. Nice results. Very nice results. That we got from our own ddpm. And so we can now. Use the same code we've used before. To create our image evaluator. And I decided. Yeah we're now going to. Go right up to 2048. Images at a time. So it's now. This is the size I found. We're now down to 3.7. For our FID. Where else the data itself has a FID of 1.9. So again it's showing that our ddpm. Is basically. Very nearly. Unrecognizably different. From real data. Using its distribution of those activations. So then we can switch to ddim. By just saying ddim scheduler. And so with ddim. You can say I don't want to do all thousand steps. I just want to do 333 steps. So every third. So that's basically a bit like. A bit like. This sample skip. Of doing every third. But ddim as we'll see. Does it in a smarter way. And so here's. Exactly the same code. Basically as before. But I put it into a. Little function. Okay so I can basically. Pass in my model. The size. The scheduler. And then there's a parameter. Called Ada which is basically. How much noise to add. So just add all the noise. And so this is. Now going to take three times. This three times faster. And yeah the FIDs basically. The same. That's encouraging. So we're down to 200 steps. It's basically the same. 100 steps. And at this point. Okay the FIDs getting worse. And then. 50 steps. We're still. 25 steps. We're still. It's interesting like. When you get down to 25 steps. Like what does it look like. And you can see that. They're kind of like. They're too smooth. You know fabric swells so much. Or buckles or. Logos or patterns. As much you know as the. These ones. They've got a lot more texture to them. So that's kind of what tends to happen. So you can still like. Get. Something out pretty fast. But that's kind of how they suffer. So okay. So how does DDIM work. Well DDIM. Actually. In my opinion it makes things a lot easier. Than DDPM. So there's basically. An equation from the paper. Which Tanishq will explain. Shortly. But basically what you do. Is I've actually. Grabbed the sample function. From here. And I split it out into two bits. One bit. Is the bit that. Says what are the time steps. Creates that random starting point. Loops through. Finds what my current. A bar is. Gets the noise. And then. Basically does the same as shed.step. It calls some function. Right and then that's been pulled out. So this allows me to now. Create my own. Different steps. So I created a DDIM step. And basically. All I did was I. Took this. Equation. And I turned it into. Code actually this this one is a second equation. From the paper. Now it's a bit. Confusing which is that the notation. Here is different. DDPM what it calls alpha bar. This paper calls alpha. So you've got to look out for that. So basically you'll see. I basically go I've got here. Xt. Minus okay. One minus alpha bar is. We've created a call that beta bar. So beta bar dot square root. Times noise. This here is the. This is the neural net. So this here is the noise. Okay. And. Here I've got. My next. Xt. Is sorry. Yes here's my a bar. T1 square root. Times. This and you can see here it says predicted. X naught so here's my predicted. X naught plus. Beta bar t1. Minus sigma squared. Square root. Again here's noise. The same thing as here. Okay. And then. Plus a bit of random noise. Which we only do if you're not at the last step. So yeah. So I can call that. So I just did it for. So I'd rather than. Saying 100 steps. I said skip every skip 10 steps. So do 10 steps at a time. That's basically going to be 100 steps. And so you can see here actually. I'm better for my 100 steps. It's not bad at all. So. Yeah. I mean this has been. Getting to this point. It's been a bit of a lifesaver to be honest. Because you know I can now. Run. A batch of 2048 samples. I can sample them in under a minute. Which doesn't feel painful. And so. You know now at a point. Where I can actually get a pretty good. Measure of how I'm doing. In a pretty reasonable. Amount of time. And I can you know. Easily compare it. And I got to admit you know. The difference between a fit of 5 and 8 and 11. I can't necessarily tell the difference. So for fashion I think. Fit is better than my eyes. This as long as I use a consistent. Sample size. So. Yeah. Tanisha did you want to talk a bit about. You know. The ideas of why we do this. Or where it comes from. Or what the notation means. Can I say a little bit before we do that. Which is just that what you have there Jeremy. Which is like. A screenshot from the paper. And then the code that as closely as possible. Tries to follow that. Like the difference that makes for people. Is huge. Like I've got a little research team that I'm doing. Some you know contract work with. And the fact that like. It's called alpha in the D-dim paper. And alpha elsewhere. And then in the code that they were copying and pasting from. It was called A and B for alpha and B-dim. And it's like you can get things kind of working. By copying and pasting into things. And it's all just sort of kind of works. But just spending that time to literally. Take two screenshots from equation 14. And 16 from the paper. And rewrite the code so that it you know. With some comments and things. To say like this is what this is. This is that part from the equation. It like. You know the look of pain on their face. When I said oh by the way did you notice that like. It's called alpha there and alpha bar there. They're like yes how could they do that. You know it's just like. You could just tell how many hours have been spent. You know like grinding teeth. And saying what's wrong here. And doing notebooks. And you know the next engineer. To come along and work on that. And see the equation right there. And you can add rows and stuff. So I think you know. NBDev works particularly well. For this kind of development. Yeah. Thanks Jeno. Yeah. Before I talk about this. I just wanted to briefly. In the context of. All of these differing notations. I recently created this meme. Which I thought was relevant. In terms of like each paper basically. Has a different diffusion model. Notation. So it's just like this. They all try to come up with their own universal notation. And it just keeps proliferating. Let's just agree we should all use APL. Yes exactly. We need to implement diffusion models and APL somehow. All right. So yeah. The paper that we're. That you know Jeremy had implemented. Was this denoising diffusion. Implicit model paper. And. If you look at the paper. Again you can see like the notation. Could be again a little bit intimidating. But when we walk through it. We'll see it's not too bad actually. So I'll just bring up. I guess. Some of the important equations. And also comparing and contrasting. You know DDPM. And the notation of DDPM and the equations. With DDIM. Not only is it not too bad. I actually discovered it's making life a lot. The DDIM notation. And equations are a lot easier. To work with. Than DDPM. So I found my life is better. Since I discovered DDIM. Yes yes. A lot of people prefer to use DDIM as well. Yeah. So yeah basically. In. So. In both. DDIM and. In both DDIM and DDPM. We have this same sort of. Equation. This equation is exactly the same. This is telling us the predicted. The predicted. Denoised image. So we predict our. But basically we predict the. You can see my pointer right. Just want to confirm. By the way. The little double headed arrow in the top right. Does that. If you click that. Do you get more room. For us to see what's going on. Double headed arrow. Just above the. Yes. Yeah okay. So. So. So. So. So. So. So. So. So. So. So. So. So. So. So. So. So. So. So we have to scale. The noise. And subtract it out of. The. Original image and. That's how we would get our. Our. Predicted denoised image. Of course. This one before. for XT in the noisify function and rearranging it to solve for X naught. And that's what you... Yes, yes that's basically what this is. Yes, that's basically what this is. So basically the idea is, okay instead of, yeah, noisifying it where we're starting out with X zero and some noise and get an XT, we're doing the opposite. Where we have some noise and we have XT, so how can we get X zero? So that's what this equation is. So that's the predicted X zero or our, you know, predicted clean image. And this equation is the same for both DDPM and DDIM, but these distributions are what's different between DDPM and DDIM. So we have this distribution which tells us, okay, so if we have XT, which is our current noisy image, and X zero, which is our clean image, can we find out what some sort of intermediate noisy image is in that process? And that's XT minus one. So we have a distribution for that. And so that tells us how to get such an image. And so this is in the DDPM paper, they did divide some distribution and explain the math behind it. But yeah, basically they have some equations. So, you know, you have again a Gaussian distribution with some sort of mean and variance, but it's again, some form of, you have this sort of interpolation between your original clean image and your noisy image, and that gives you your intermediate less, slightly less noisy image. So that's what this is giving. Given a clean image and a noisy image, you're slightly less noisy image. And so the sampling procedure that we do with DDPM basically is predict the noisy, predict the X zero, and then plug it into this distribution to give you your slightly less noisy image. So maybe it's worth drawing that out. So like if we had, let's say some sort of, like, I don't know, I'm just making some sort of, I don't know, maybe a lot of some sort of better, yeah. Some sort of, so then in this case, I'm showing a one dimensional example, let's say you have some sort of point. So it's kind of a one dimensional example that's still in the sort of 2D space. But let's say you have some, any point on this, it represents an actual image that you want to sample from, right? So this is, you know, where your distribution of actual images would lie. And you want to estimate this. So when this sort of algorithm that we've been seeing here says that, okay, if we take some random point, this is some random point that we choose, you know, when we start out. And what we did is we learned this function, the score function to take us to this manifold, but it's only going to be accurate in some space. So it's going to be accurate, you know, it's going to be accurate in some area. So we get an estimate of the score function and it tells us the direction to move in. And it's going to give us the direction to predict our, our denoised image, right? So basically like, let's say, let's say, let's say you actually, your score function, sorry. So let's say your score function is actually in reality, some curve. Okay. So it's in reality, some curve that points to your, oops, it points here. So that's your score function. And you know, the value here, that's what... The score function basically means your gradient. Yeah. Yes, yes. It's a gradient. So, you know, we again, doing some form of, in this case, I guess you would say gradient ascent, because you're not really minimizing the score, you're maximizing it. You want, sorry, you're maximizing your, your, the likelihood of that data point being an actual data point. You want to go towards it. So you're, you're doing the sort of gradient ascent process. So you're following the gradient to, to get to that. So, so when we estimate, epsilon theta and predict our noise, what we're doing is we're getting the score value here. And then so we can, you know, follow that and we follow it to some point. I'm being kind of exaggerating here, but this point will now represent our X zero hat. Yeah. So yeah, our X zero hat. So and, and in reality, you know, that's not, maybe that's not going to be some point that is an actual point. It wouldn't be next to the distribution. So, you know, it's, it's not going to be a very good estimate of a clean image at the beginning, but, you know, we only have that estimate at the beginning at this point, and we have to follow it all the way to, to some place. So this is where we follow it to. And then we want to find some sort of X T minus one. So that's what our next point is. And so that's what our second distribution tells us. And it basically takes us all the way, takes us all the way back to maybe some point here. And now we can re-estimate the, the, the score function or yeah, our gradient over there, you know, do this prediction of noise. And, you know, it may be more accurate of a, of a score function and maybe we go somewhere here and then we re-estimate and get another point and then we follow it. And so that's kind of this iterative process where we're trying to follow this, the score function to your own point. And in order to do so, we first have to estimate our X zero hat, and then, and then basically add back some noise and to get, you know, a little bit, I get a new estimate and keep following and add back a little bit more noise and keep estimating. So that's what we're doing here in these two steps. We have our X zero hat, and then we have this distribution and that's how we do it regular DDPM. And it's that, I think that's the, maybe where the sort of breaking it up in two steps is a little bit clearer. And I don't think the DDPM paper really clarifies that, really talks about it too much. But the DDPM paper also really hammers that point home, I think, and especially in their, in their update equation. So the other, so that's the DDPM, but then with DDIM, Okay, go ahead. So before you do DDPM, just the one thing is that the, you look at your prediction, use that to make a step, but you also add back some additional noise that's always fixed. Right. DDPM, there's no parameters to control how much extra noise you add back at each step. Right, exactly. So, so, yeah, so when you're, let's see here. Yeah. So yeah, basically you won't be exactly at this point, you could be, you know, you're in that general vicinity and, you know, adding that noise also helps with, you know, you don't want to fall into, you know, specific modes where it's like, oh, you know, this is the most likely data point. You want to add some noise where you can like explore other data points as well. So yeah, there's some, you know, the noise also can help and that's something you really can't control with DDPM. And that's something that DDIM explores a little bit further is in terms of the noise and even trying to get rid of the noise altogether in DDIM. So with the DDIM paper, the main difference is literally this one equation. That's all, all really it is in terms of changing this distribution where you predict the less noisy equation, the less noisy, sorry, the less noisy image. And basically, as you can see, it's just, you have this additional parameter now which is sigma and the sigma controls how much noise, like we were just mentioning, is going to be part of this process. And you can actually, for example, if you want, you could set sigma to zero and then you can see here now you have a variance that would be zero. And so this becomes a completely deterministic process. So if you want, this could be completely deterministic. So that's one aspect of it. And then, yeah, so the other aspect, so one of the reasons it's called DDIM is just not DDPM because it's like not probabilistic anymore. It can be made deterministic. So the name was changed for that reason. But the other thing is like, you would think that you've kind of changed the model altogether with a new distribution altogether. And so you think, oh, wouldn't you have to like trade a different model for this purpose? But it turns out the math works out where the same model objective would work well with this distribution as well. And in fact, I think that's what they were setting out from the very beginning is what kind of other models can we get with the same objective? And so this is what they're able to do is you can make some, you can have this new parameter that you can introduce, in this case, kind of controlling the stochasticity of the model. And you can still use the same exact trained model that you had. So what this means is that this actually is just a new sampling algorithm and not anything new with the training itself. And this is just, yeah, just like we talked about a new way of sampling the model. And then, so yeah, this is how, you know, given now this equation, then you can rewrite your Xt minus one term. And again, by doing the same sort of thing where we split it up into predicting the X zero and then adding back to go back to your Xt. And also if you need to add a little bit of noise back in, like Jonathan was saying, you can do so. You have this extra term here and the sigma controls that term. And again, like we said, you have to be again, looking at the DDIM equation versus the DDPM equation. You have to be careful of the alphas here are referring to alpha bars in the DDPM equation. So that's the other caveat. So yeah. And you have this sigma t set to this particular value will give you back DDPM. So sometimes instead they will write basically, Jeremy mentioned this sort of, I guess, eta, which is equal to basically, yeah. So it's just basically, sigma is equal to eta times this coefficient. So, oops, so sorry, let me just go back. And so, in reality, so basically, yeah, in reality you take, what? Okay. You have an eta here. So it's like, yeah, this is where eta would go. So if it's one, it becomes regular DDPM. And if it's zero, of course, that's a deterministic case. So this is the eta that, you know, all these APIs and in the code that we have, also the code that Jeremy was showing, they have eta equals to one, which they say is corresponding to regular DDPM. This is actually where the eta would go in the equation. So finally, it's like, yeah, you could pass in sigma, right? Like if you weren't trying to match it in cleanest paper, you could just, oh, well, we have this parameter sigma that controls the amount of noise. So that's just taken, yeah, big mo scale as an argument. But for convenience, they said, let's create this new thing, eta, where zero means sigma is equal to zero, which if you look at the equation, that works. One means we match the DDP, the amount of noise that's in the like vanilla DDPM. And so then that gives you like a nice slice. You could say eta equals two or eight equals 0.7 or whatever. But it's, it's like got a meaningful unit of one equals the same as this previous reference work. Well, it's also convenient because it's sigma t, which is to say different time steps, unless you choose eta equals zero, which case it doesn't matter. Different time steps probably want different amounts of noise. And so here's, yeah, here's a reasonable way of, of scaling that noise. Then the last thing of importance, which is of course, one of the reasons that we were exploring this as the first place is to be able to do this sort of rapid sampling. So the basic idea here is that you can define a similar distribution where again, the math works out similarly, where now you have, let's say you have some subset of diffusion steps. So in this case, it uses tau variable. So for example, if, if you have, yeah, you say, let's say a subset of diffusion steps. So if it's like 10 diffusion steps, then tau one would just be zero. Then tau two would be 10. You know, you just keep going all the way up to say a thousand, but you've only got the, sorry, tau two would be a hundred. And then you go all the way up to a thousand. And so you'd get, you know, these, you'd get 10 diffusion steps. So that's what they're referring to when they have this, I guess, this tau, tau variable here. And so you can do these sorts of similar equation and similar derivation to show that this, this distribution here, again, meets the sort of objective that you use for training. And you can now use this for a faster sampling where basically all you have to do is you have to just select the appropriate alpha bar. And sorry, I, this one I've written out. So this one, actually the alpha bar is, you know, the regular alpha bar that we've talked about, but basically, sorry, it's a little bit confusing switching between different notations, but basically you have this distribution and then you just have to select the appropriate alpha bars. And it follows the math the same in terms of you have appropriate sampling process. So yeah, and I guess that's, it makes it a lot simpler in terms of doing this, I guess, accelerated sampling. Yeah, I guess with any other note, maybe other comments that maybe you guys had, or was this? Well, the key for me is that in this equation, we just have one, we only need one parameter, which is the alpha bar or alpha, depending on which notation is, and everything else is calculated from that. And so we don't have the, what DDPM calls the alpha or beta anymore. And that's more convenient for doing this kind of smaller number of steps because we can just jump straight from time step to alpha bar. And we can also then, it's particularly convenient with the cosine schedule because you can calculate the inverse of the cosine schedule function, which means you can also go from an alpha bar to a T. So it's really easy to like say like, Oh, what would alpha bar be 10 time steps previously to this one? You know, it's just, you could just call a function. We don't need, yeah, we don't need anything else. And so actually the original cosine schedule paper has to fuss around with various like kind of epsilon style, small numbers that they add to things to avoid getting weird numerical problems. And so, yeah, when we only deal with alpha bar, all that stuff also goes away. So, yeah. So looking, if you're looking at the DDIM code, you know, it's simpler code with less parameters than our DDPM code. And of course it's dramatically faster and it's also more flexible because we've got this eta thing we can play with. Yes. Yeah. And that's the other thing. It's like this idea of like, yeah, controlling stochasticity. I think that's something that's interesting to explore and we've been exploring that a bit now and I think we'll continue to explore that in terms of deterministic versus stochasticity. So, yeah. Also, it's worth talking about this, the sigma in that middle equation you've got there. So you've got the sigma t eta t adding the random noise. And intuitively it makes sense that if you're adding random noise there, you would need to have less. You want to move less back towards Xt, which is your noisy image. So that's why. And, you know, you've got the 1 minus alpha t minus 1 minus sigma squared. And then you're taking the square root of that. So basically that's just sigma, the square root of the squared. So you're subtracting sigma t from the direction pointing to Xt and adding it to the random noise or vice versa. So, yes, you know, everything's there for a reason, you know. Yes. And the predicted X0, that entire equation we've derived previously. And it remains the same in pretty much any diffusion model methodology. Well, as long as you're using, we'll be talking about actually some places where it's going to change probably next week. Yeah, I guess there's another thing where you're predicting noise. Yes. Yes. Yes. If you're predicting the noise, yes, there'll be. Okay. Yeah. So, so I think, you know, we will, we'll probably, yeah, let's wrap it up here so that we leave ourselves plenty of time to cover the kind of new research directions next lesson in more detail. But I just want to mention, like in terms of where we're at, just like we hit a kind of like, okay, we can now really predict classes for fashion MNIST a few weeks ago, where I think we're there now and like we can do stable diffusion sampling and units, except for the unit architecture for unconditional generation now, we basically can do fashion MNIST almost. So it's unrecognizably different to the real samples and DDIM is the scheduler that the original stable diffusion paper used. So, yeah, you know, we're actually about to go beyond stable diffusion for our sampling and unit training now. So I think we've, yeah, definitely meeting our stretch goals so far and all from scratch. Ruth waits and biases experiment logging. And you know, if you want it to have fun, there's no reason you couldn't like have a little callback that instead logs things into a SQLite database. And then you could write a little front end to show your experiments, you know, that'd be fun as well. Yeah. I mean, you could do also send you a text message when the loss gets good enough. Yeah. All right. Well, thanks guys. That was really fun. Thanks, everybody. All right. Bye. Okay. Talk to you later then. Bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.0, "text": " Hello Jono, hello Tanishq. Are you guys ready for lesson 21?", "tokens": [50364, 2425, 7745, 78, 11, 7751, 314, 7524, 80, 13, 2014, 291, 1074, 1919, 337, 6898, 5080, 30, 50664], "temperature": 0.0, "avg_logprob": -0.30885995864868165, "compression_ratio": 1.4836065573770492, "no_speech_prob": 0.004824281204491854}, {"id": 1, "seek": 0, "start": 6.0, "end": 8.0, "text": " Ready. Yep, I'm excited.", "tokens": [50664, 9944, 13, 7010, 11, 286, 478, 2919, 13, 50764], "temperature": 0.0, "avg_logprob": -0.30885995864868165, "compression_ratio": 1.4836065573770492, "no_speech_prob": 0.004824281204491854}, {"id": 2, "seek": 0, "start": 8.0, "end": 12.0, "text": " I don't know what I would have said if you had said no. So good.", "tokens": [50764, 286, 500, 380, 458, 437, 286, 576, 362, 848, 498, 291, 632, 848, 572, 13, 407, 665, 13, 50964], "temperature": 0.0, "avg_logprob": -0.30885995864868165, "compression_ratio": 1.4836065573770492, "no_speech_prob": 0.004824281204491854}, {"id": 3, "seek": 0, "start": 12.0, "end": 18.0, "text": " I'm actually particularly excited because I had a little bit of a peak preview of something that Jono has been working on,", "tokens": [50964, 286, 478, 767, 4098, 2919, 570, 286, 632, 257, 707, 857, 295, 257, 10651, 14281, 295, 746, 300, 7745, 78, 575, 668, 1364, 322, 11, 51264], "temperature": 0.0, "avg_logprob": -0.30885995864868165, "compression_ratio": 1.4836065573770492, "no_speech_prob": 0.004824281204491854}, {"id": 4, "seek": 0, "start": 18.0, "end": 27.0, "text": " which I think is a super cool demo of what's possible with very little code with MiniAI.", "tokens": [51264, 597, 286, 519, 307, 257, 1687, 1627, 10723, 295, 437, 311, 1944, 365, 588, 707, 3089, 365, 18239, 48698, 13, 51714], "temperature": 0.0, "avg_logprob": -0.30885995864868165, "compression_ratio": 1.4836065573770492, "no_speech_prob": 0.004824281204491854}, {"id": 5, "seek": 2700, "start": 27.0, "end": 30.0, "text": " So let me turn it over to Jono.", "tokens": [50364, 407, 718, 385, 1261, 309, 670, 281, 7745, 78, 13, 50514], "temperature": 0.0, "avg_logprob": -0.21587524729326737, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.05917692556977272}, {"id": 6, "seek": 2700, "start": 30.0, "end": 32.0, "text": " Great, thanks Jeremy.", "tokens": [50514, 3769, 11, 3231, 17809, 13, 50614], "temperature": 0.0, "avg_logprob": -0.21587524729326737, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.05917692556977272}, {"id": 7, "seek": 2700, "start": 32.0, "end": 38.0, "text": " Yeah, so as you'll see when it's back to Jeremy to talk through some of the experiments and things we've been doing,", "tokens": [50614, 865, 11, 370, 382, 291, 603, 536, 562, 309, 311, 646, 281, 17809, 281, 751, 807, 512, 295, 264, 12050, 293, 721, 321, 600, 668, 884, 11, 50914], "temperature": 0.0, "avg_logprob": -0.21587524729326737, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.05917692556977272}, {"id": 8, "seek": 2700, "start": 38.0, "end": 45.0, "text": " we've been using the fashion MNIST dataset at a really small scale and really rapidly try out these different ideas", "tokens": [50914, 321, 600, 668, 1228, 264, 6700, 376, 45, 19756, 28872, 412, 257, 534, 1359, 4373, 293, 534, 12910, 853, 484, 613, 819, 3487, 51264], "temperature": 0.0, "avg_logprob": -0.21587524729326737, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.05917692556977272}, {"id": 9, "seek": 2700, "start": 45.0, "end": 49.0, "text": " and see some maybe nuances or things that we'd like to explore further.", "tokens": [51264, 293, 536, 512, 1310, 38775, 420, 721, 300, 321, 1116, 411, 281, 6839, 3052, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21587524729326737, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.05917692556977272}, {"id": 10, "seek": 2700, "start": 49.0, "end": 55.0, "text": " And so as we were doing that, I started to think that maybe it was about time to explore just ramping up a level,", "tokens": [51464, 400, 370, 382, 321, 645, 884, 300, 11, 286, 1409, 281, 519, 300, 1310, 309, 390, 466, 565, 281, 6839, 445, 12428, 278, 493, 257, 1496, 11, 51764], "temperature": 0.0, "avg_logprob": -0.21587524729326737, "compression_ratio": 1.6445993031358885, "no_speech_prob": 0.05917692556977272}, {"id": 11, "seek": 5500, "start": 55.0, "end": 60.0, "text": " seeing if we can go to the next slightly larger dataset, slightly harder difficulty,", "tokens": [50364, 2577, 498, 321, 393, 352, 281, 264, 958, 4748, 4833, 28872, 11, 4748, 6081, 10360, 11, 50614], "temperature": 0.0, "avg_logprob": -0.25039030955388, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.02161313220858574}, {"id": 12, "seek": 5500, "start": 60.0, "end": 67.0, "text": " just to double check that these ideas still hold for longer training runs and different more difficult data.", "tokens": [50614, 445, 281, 3834, 1520, 300, 613, 3487, 920, 1797, 337, 2854, 3097, 6676, 293, 819, 544, 2252, 1412, 13, 50964], "temperature": 0.0, "avg_logprob": -0.25039030955388, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.02161313220858574}, {"id": 13, "seek": 5500, "start": 67.0, "end": 74.0, "text": " That's a really good idea because I feel pretty confident that the learnings from fashion MNIST are going to move across", "tokens": [50964, 663, 311, 257, 534, 665, 1558, 570, 286, 841, 1238, 6679, 300, 264, 2539, 82, 490, 6700, 376, 45, 19756, 366, 516, 281, 1286, 2108, 51314], "temperature": 0.0, "avg_logprob": -0.25039030955388, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.02161313220858574}, {"id": 14, "seek": 5500, "start": 74.0, "end": 79.0, "text": " most of the time these things seem to, but sometimes they don't and it can be very hard to predict.", "tokens": [51314, 881, 295, 264, 565, 613, 721, 1643, 281, 11, 457, 2171, 436, 500, 380, 293, 309, 393, 312, 588, 1152, 281, 6069, 13, 51564], "temperature": 0.0, "avg_logprob": -0.25039030955388, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.02161313220858574}, {"id": 15, "seek": 5500, "start": 79.0, "end": 83.0, "text": " So this seems like a very wise choice.", "tokens": [51564, 407, 341, 2544, 411, 257, 588, 10829, 3922, 13, 51764], "temperature": 0.0, "avg_logprob": -0.25039030955388, "compression_ratio": 1.6472727272727272, "no_speech_prob": 0.02161313220858574}, {"id": 16, "seek": 8300, "start": 83.0, "end": 89.0, "text": " Yeah, and so we'll keep ramping up, but as a next step, one above fashion MNIST,", "tokens": [50364, 865, 11, 293, 370, 321, 603, 1066, 12428, 278, 493, 11, 457, 382, 257, 958, 1823, 11, 472, 3673, 6700, 376, 45, 19756, 11, 50664], "temperature": 0.0, "avg_logprob": -0.20737679799397787, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.009409846737980843}, {"id": 17, "seek": 8300, "start": 89.0, "end": 93.0, "text": " I thought I'd look at this data called CIFAR-10.", "tokens": [50664, 286, 1194, 286, 1116, 574, 412, 341, 1412, 1219, 383, 12775, 1899, 12, 3279, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20737679799397787, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.009409846737980843}, {"id": 18, "seek": 8300, "start": 93.0, "end": 98.0, "text": " And so CIFAR-10 dataset is a very popular dataset originally for things like image classification,", "tokens": [50864, 400, 370, 383, 12775, 1899, 12, 3279, 28872, 307, 257, 588, 3743, 28872, 7993, 337, 721, 411, 3256, 21538, 11, 51114], "temperature": 0.0, "avg_logprob": -0.20737679799397787, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.009409846737980843}, {"id": 19, "seek": 8300, "start": 98.0, "end": 102.0, "text": " but also now for all of this, any paper on generative modeling.", "tokens": [51114, 457, 611, 586, 337, 439, 295, 341, 11, 604, 3035, 322, 1337, 1166, 15983, 13, 51314], "temperature": 0.0, "avg_logprob": -0.20737679799397787, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.009409846737980843}, {"id": 20, "seek": 8300, "start": 102.0, "end": 107.0, "text": " It's kind of like the smallest dataset that you'll see in these papers.", "tokens": [51314, 467, 311, 733, 295, 411, 264, 16998, 28872, 300, 291, 603, 536, 294, 613, 10577, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20737679799397787, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.009409846737980843}, {"id": 21, "seek": 8300, "start": 107.0, "end": 112.0, "text": " And so, yeah, if you look at the classification results, for example, pretty much every classification paper since", "tokens": [51564, 400, 370, 11, 1338, 11, 498, 291, 574, 412, 264, 21538, 3542, 11, 337, 1365, 11, 1238, 709, 633, 21538, 3035, 1670, 51814], "temperature": 0.0, "avg_logprob": -0.20737679799397787, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.009409846737980843}, {"id": 22, "seek": 11200, "start": 112.0, "end": 118.0, "text": " they started tracking has reported results on CIFAR-10 as well as their larger datasets.", "tokens": [50364, 436, 1409, 11603, 575, 7055, 3542, 322, 383, 12775, 1899, 12, 3279, 382, 731, 382, 641, 4833, 42856, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2839639245010004, "compression_ratio": 1.5219298245614035, "no_speech_prob": 0.04271805286407471}, {"id": 23, "seek": 11200, "start": 118.0, "end": 122.0, "text": " And likewise, with image generation, very, very popular.", "tokens": [50664, 400, 32407, 11, 365, 3256, 5125, 11, 588, 11, 588, 3743, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2839639245010004, "compression_ratio": 1.5219298245614035, "no_speech_prob": 0.04271805286407471}, {"id": 24, "seek": 11200, "start": 122.0, "end": 131.0, "text": " All of the recent diffusion papers will usually report CIFAR-10, add their image net and then whatever large massive dataset they're training on.", "tokens": [50864, 1057, 295, 264, 5162, 25242, 10577, 486, 2673, 2275, 383, 12775, 1899, 12, 3279, 11, 909, 641, 3256, 2533, 293, 550, 2035, 2416, 5994, 28872, 436, 434, 3097, 322, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2839639245010004, "compression_ratio": 1.5219298245614035, "no_speech_prob": 0.04271805286407471}, {"id": 25, "seek": 11200, "start": 131.0, "end": 137.0, "text": " We were somewhat notable in 2018 for managing to train.", "tokens": [51314, 492, 645, 8344, 22556, 294, 6096, 337, 11642, 281, 3847, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2839639245010004, "compression_ratio": 1.5219298245614035, "no_speech_prob": 0.04271805286407471}, {"id": 26, "seek": 13700, "start": 137.0, "end": 141.0, "text": " So for CIFAR-10, 94% classification is kind of the benchmark.", "tokens": [50364, 407, 337, 383, 12775, 1899, 12, 3279, 11, 30849, 4, 21538, 307, 733, 295, 264, 18927, 13, 50564], "temperature": 0.0, "avg_logprob": -0.16726747052422886, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.12748073041439056}, {"id": 27, "seek": 13700, "start": 141.0, "end": 155.0, "text": " So there was a competition a few years ago where we managed to get to that point at a cost of like 26 cents worth of AWS time, I think, which won a big global competition.", "tokens": [50564, 407, 456, 390, 257, 6211, 257, 1326, 924, 2057, 689, 321, 6453, 281, 483, 281, 300, 935, 412, 257, 2063, 295, 411, 7551, 14941, 3163, 295, 17650, 565, 11, 286, 519, 11, 597, 1582, 257, 955, 4338, 6211, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16726747052422886, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.12748073041439056}, {"id": 28, "seek": 13700, "start": 155.0, "end": 163.0, "text": " So I actually hate CIFAR-10, but we had some real fun with it a few years ago.", "tokens": [51264, 407, 286, 767, 4700, 383, 12775, 1899, 12, 3279, 11, 457, 321, 632, 512, 957, 1019, 365, 309, 257, 1326, 924, 2057, 13, 51664], "temperature": 0.0, "avg_logprob": -0.16726747052422886, "compression_ratio": 1.5072463768115942, "no_speech_prob": 0.12748073041439056}, {"id": 29, "seek": 16300, "start": 163.0, "end": 167.0, "text": " Yeah, and it's good. It's a nice dataset for quickly testing things out.", "tokens": [50364, 865, 11, 293, 309, 311, 665, 13, 467, 311, 257, 1481, 28872, 337, 2661, 4997, 721, 484, 13, 50564], "temperature": 0.0, "avg_logprob": -0.25053682239777453, "compression_ratio": 1.619607843137255, "no_speech_prob": 0.523170530796051}, {"id": 30, "seek": 16300, "start": 167.0, "end": 175.0, "text": " But we'll talk about why we also like us as a group don't like it at all and we'll pretty soon move on to something better.", "tokens": [50564, 583, 321, 603, 751, 466, 983, 321, 611, 411, 505, 382, 257, 1594, 500, 380, 411, 309, 412, 439, 293, 321, 603, 1238, 2321, 1286, 322, 281, 746, 1101, 13, 50964], "temperature": 0.0, "avg_logprob": -0.25053682239777453, "compression_ratio": 1.619607843137255, "no_speech_prob": 0.523170530796051}, {"id": 31, "seek": 16300, "start": 175.0, "end": 182.0, "text": " So one of the things you'll notice in this notebook, I'm basically using all of the same code that Jeremy is going to be looking at and explaining.", "tokens": [50964, 407, 472, 295, 264, 721, 291, 603, 3449, 294, 341, 21060, 11, 286, 478, 1936, 1228, 439, 295, 264, 912, 3089, 300, 17809, 307, 516, 281, 312, 1237, 412, 293, 13468, 13, 51314], "temperature": 0.0, "avg_logprob": -0.25053682239777453, "compression_ratio": 1.619607843137255, "no_speech_prob": 0.523170530796051}, {"id": 32, "seek": 16300, "start": 182.0, "end": 186.0, "text": " So I won't go into too much. But the data sets also on Hugging Face.", "tokens": [51314, 407, 286, 1582, 380, 352, 666, 886, 709, 13, 583, 264, 1412, 6352, 611, 322, 46892, 3249, 4047, 13, 51514], "temperature": 0.0, "avg_logprob": -0.25053682239777453, "compression_ratio": 1.619607843137255, "no_speech_prob": 0.523170530796051}, {"id": 33, "seek": 18600, "start": 186.0, "end": 193.0, "text": " So we can load it just like we did the fashion MNIST and the images are three channel rather than single channel.", "tokens": [50364, 407, 321, 393, 3677, 309, 445, 411, 321, 630, 264, 6700, 376, 45, 19756, 293, 264, 5267, 366, 1045, 2269, 2831, 813, 2167, 2269, 13, 50714], "temperature": 0.0, "avg_logprob": -0.23688634236653647, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.4842183589935303}, {"id": 34, "seek": 18600, "start": 193.0, "end": 203.0, "text": " So the shape of the data is slightly different to what we've been working with.", "tokens": [50714, 407, 264, 3909, 295, 264, 1412, 307, 4748, 819, 281, 437, 321, 600, 668, 1364, 365, 13, 51214], "temperature": 0.0, "avg_logprob": -0.23688634236653647, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.4842183589935303}, {"id": 35, "seek": 18600, "start": 203.0, "end": 205.0, "text": " That's weird.", "tokens": [51214, 663, 311, 3657, 13, 51314], "temperature": 0.0, "avg_logprob": -0.23688634236653647, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.4842183589935303}, {"id": 36, "seek": 18600, "start": 205.0, "end": 210.0, "text": " Yeah, so we have instead of a single channel image, we have a three channel red, green and blue image.", "tokens": [51314, 865, 11, 370, 321, 362, 2602, 295, 257, 2167, 2269, 3256, 11, 321, 362, 257, 1045, 2269, 2182, 11, 3092, 293, 3344, 3256, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23688634236653647, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.4842183589935303}, {"id": 37, "seek": 18600, "start": 210.0, "end": 212.0, "text": " And this is what a batch of data looks like.", "tokens": [51564, 400, 341, 307, 437, 257, 15245, 295, 1412, 1542, 411, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23688634236653647, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.4842183589935303}, {"id": 38, "seek": 21200, "start": 212.0, "end": 217.0, "text": " So you've got 32 images in your batch. So that's batch by channel by height by width, right?", "tokens": [50364, 407, 291, 600, 658, 8858, 5267, 294, 428, 15245, 13, 407, 300, 311, 15245, 538, 2269, 538, 6681, 538, 11402, 11, 558, 30, 50614], "temperature": 0.0, "avg_logprob": -0.25565413354148325, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.4802846908569336}, {"id": 39, "seek": 21200, "start": 217.0, "end": 219.0, "text": " Yeah, batch by channel by height and width.", "tokens": [50614, 865, 11, 15245, 538, 2269, 538, 6681, 293, 11402, 13, 50714], "temperature": 0.0, "avg_logprob": -0.25565413354148325, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.4802846908569336}, {"id": 40, "seek": 21200, "start": 219.0, "end": 222.0, "text": " I was a little confused by the 32 by 32.", "tokens": [50714, 286, 390, 257, 707, 9019, 538, 264, 8858, 538, 8858, 13, 50864], "temperature": 0.0, "avg_logprob": -0.25565413354148325, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.4802846908569336}, {"id": 41, "seek": 21200, "start": 222.0, "end": 224.0, "text": " Oh, yeah, it's fine. I got it now.", "tokens": [50864, 876, 11, 1338, 11, 309, 311, 2489, 13, 286, 658, 309, 586, 13, 50964], "temperature": 0.0, "avg_logprob": -0.25565413354148325, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.4802846908569336}, {"id": 42, "seek": 21200, "start": 224.0, "end": 226.0, "text": " Batch size can be arbitrary.", "tokens": [50964, 363, 852, 2744, 393, 312, 23211, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25565413354148325, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.4802846908569336}, {"id": 43, "seek": 21200, "start": 226.0, "end": 231.0, "text": " So if you plot these, one of the things if you look at this, okay, I can see these are different classes.", "tokens": [51064, 407, 498, 291, 7542, 613, 11, 472, 295, 264, 721, 498, 291, 574, 412, 341, 11, 1392, 11, 286, 393, 536, 613, 366, 819, 5359, 13, 51314], "temperature": 0.0, "avg_logprob": -0.25565413354148325, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.4802846908569336}, {"id": 44, "seek": 21200, "start": 231.0, "end": 238.0, "text": " Like I know this is an airplane, a frog, an airplane, but it's actually a puzzle with an airplane on the cover, a bird, a horse, a car.", "tokens": [51314, 1743, 286, 458, 341, 307, 364, 17130, 11, 257, 17259, 11, 364, 17130, 11, 457, 309, 311, 767, 257, 12805, 365, 364, 17130, 322, 264, 2060, 11, 257, 5255, 11, 257, 6832, 11, 257, 1032, 13, 51664], "temperature": 0.0, "avg_logprob": -0.25565413354148325, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.4802846908569336}, {"id": 45, "seek": 23800, "start": 238.0, "end": 243.0, "text": " That one, if you squint, you can tell it's a deer, but only if you really know what you're looking for.", "tokens": [50364, 663, 472, 11, 498, 291, 2339, 686, 11, 291, 393, 980, 309, 311, 257, 17120, 11, 457, 787, 498, 291, 534, 458, 437, 291, 434, 1237, 337, 13, 50614], "temperature": 0.0, "avg_logprob": -0.21113612878061558, "compression_ratio": 1.8339350180505416, "no_speech_prob": 0.422389417886734}, {"id": 46, "seek": 23800, "start": 243.0, "end": 247.0, "text": " And so when we started to talk about generating these images, this is actually quite frustrating.", "tokens": [50614, 400, 370, 562, 321, 1409, 281, 751, 466, 17746, 613, 5267, 11, 341, 307, 767, 1596, 16522, 13, 50814], "temperature": 0.0, "avg_logprob": -0.21113612878061558, "compression_ratio": 1.8339350180505416, "no_speech_prob": 0.422389417886734}, {"id": 47, "seek": 23800, "start": 247.0, "end": 252.0, "text": " Like this, if I generated this, I'd say this might be the model doing a really bad job.", "tokens": [50814, 1743, 341, 11, 498, 286, 10833, 341, 11, 286, 1116, 584, 341, 1062, 312, 264, 2316, 884, 257, 534, 1578, 1691, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21113612878061558, "compression_ratio": 1.8339350180505416, "no_speech_prob": 0.422389417886734}, {"id": 48, "seek": 23800, "start": 252.0, "end": 255.0, "text": " And that it's actually that this is a boat, this is a dog.", "tokens": [51064, 400, 300, 309, 311, 767, 300, 341, 307, 257, 6582, 11, 341, 307, 257, 3000, 13, 51214], "temperature": 0.0, "avg_logprob": -0.21113612878061558, "compression_ratio": 1.8339350180505416, "no_speech_prob": 0.422389417886734}, {"id": 49, "seek": 23800, "start": 255.0, "end": 257.0, "text": " It's just that this is what the data looks like.", "tokens": [51214, 467, 311, 445, 300, 341, 307, 437, 264, 1412, 1542, 411, 13, 51314], "temperature": 0.0, "avg_logprob": -0.21113612878061558, "compression_ratio": 1.8339350180505416, "no_speech_prob": 0.422389417886734}, {"id": 50, "seek": 23800, "start": 257.0, "end": 261.0, "text": " And so I've actually got something that can help you out.", "tokens": [51314, 400, 370, 286, 600, 767, 658, 746, 300, 393, 854, 291, 484, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21113612878061558, "compression_ratio": 1.8339350180505416, "no_speech_prob": 0.422389417886734}, {"id": 51, "seek": 23800, "start": 261.0, "end": 264.0, "text": " I'll show later today, which is something like this.", "tokens": [51514, 286, 603, 855, 1780, 965, 11, 597, 307, 746, 411, 341, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21113612878061558, "compression_ratio": 1.8339350180505416, "no_speech_prob": 0.422389417886734}, {"id": 52, "seek": 26400, "start": 264.0, "end": 267.0, "text": " It's really actually hard to see whether it's good because the images are bad.", "tokens": [50364, 467, 311, 534, 767, 1152, 281, 536, 1968, 309, 311, 665, 570, 264, 5267, 366, 1578, 13, 50514], "temperature": 0.0, "avg_logprob": -0.25639234631266816, "compression_ratio": 1.7579617834394905, "no_speech_prob": 0.344969779253006}, {"id": 53, "seek": 26400, "start": 267.0, "end": 272.0, "text": " It can be helpful to have a metric that generate that can see how good samples are.", "tokens": [50514, 467, 393, 312, 4961, 281, 362, 257, 20678, 300, 8460, 300, 393, 536, 577, 665, 10938, 366, 13, 50764], "temperature": 0.0, "avg_logprob": -0.25639234631266816, "compression_ratio": 1.7579617834394905, "no_speech_prob": 0.344969779253006}, {"id": 54, "seek": 26400, "start": 272.0, "end": 275.0, "text": " So I'll be showing a metric for that later today.", "tokens": [50764, 407, 286, 603, 312, 4099, 257, 20678, 337, 300, 1780, 965, 13, 50914], "temperature": 0.0, "avg_logprob": -0.25639234631266816, "compression_ratio": 1.7579617834394905, "no_speech_prob": 0.344969779253006}, {"id": 55, "seek": 26400, "start": 275.0, "end": 278.0, "text": " Yeah. And that'll be great.", "tokens": [50914, 865, 13, 400, 300, 603, 312, 869, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25639234631266816, "compression_ratio": 1.7579617834394905, "no_speech_prob": 0.344969779253006}, {"id": 56, "seek": 26400, "start": 278.0, "end": 279.0, "text": " And I hope to have like automated.", "tokens": [51064, 400, 286, 1454, 281, 362, 411, 18473, 13, 51114], "temperature": 0.0, "avg_logprob": -0.25639234631266816, "compression_ratio": 1.7579617834394905, "no_speech_prob": 0.344969779253006}, {"id": 57, "seek": 26400, "start": 279.0, "end": 282.0, "text": " But anyway, I just wanted to flag like for visually inspecting these, it's not great.", "tokens": [51114, 583, 4033, 11, 286, 445, 1415, 281, 7166, 411, 337, 19622, 15018, 278, 613, 11, 309, 311, 406, 869, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25639234631266816, "compression_ratio": 1.7579617834394905, "no_speech_prob": 0.344969779253006}, {"id": 58, "seek": 26400, "start": 282.0, "end": 285.0, "text": " And so we don't really like CIFAR-10 because it's hard to tell.", "tokens": [51264, 400, 370, 321, 500, 380, 534, 411, 383, 12775, 1899, 12, 3279, 570, 309, 311, 1152, 281, 980, 13, 51414], "temperature": 0.0, "avg_logprob": -0.25639234631266816, "compression_ratio": 1.7579617834394905, "no_speech_prob": 0.344969779253006}, {"id": 59, "seek": 26400, "start": 285.0, "end": 288.0, "text": " But still a good one to test with.", "tokens": [51414, 583, 920, 257, 665, 472, 281, 1500, 365, 13, 51564], "temperature": 0.0, "avg_logprob": -0.25639234631266816, "compression_ratio": 1.7579617834394905, "no_speech_prob": 0.344969779253006}, {"id": 60, "seek": 26400, "start": 288.0, "end": 293.0, "text": " So the noise defy and everything, I'm following what Jeremy is going to be showing exactly.", "tokens": [51564, 407, 264, 5658, 1060, 88, 293, 1203, 11, 286, 478, 3480, 437, 17809, 307, 516, 281, 312, 4099, 2293, 13, 51814], "temperature": 0.0, "avg_logprob": -0.25639234631266816, "compression_ratio": 1.7579617834394905, "no_speech_prob": 0.344969779253006}, {"id": 61, "seek": 29300, "start": 293.0, "end": 298.0, "text": " The code works without any changes because we're adding random noise in the same shape as our data.", "tokens": [50364, 440, 3089, 1985, 1553, 604, 2962, 570, 321, 434, 5127, 4974, 5658, 294, 264, 912, 3909, 382, 527, 1412, 13, 50614], "temperature": 0.0, "avg_logprob": -0.257182746637063, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.392069935798645}, {"id": 62, "seek": 29300, "start": 298.0, "end": 303.0, "text": " So even though our data now has three channels, the noise apply function still works fine.", "tokens": [50614, 407, 754, 1673, 527, 1412, 586, 575, 1045, 9235, 11, 264, 5658, 3079, 2445, 920, 1985, 2489, 13, 50864], "temperature": 0.0, "avg_logprob": -0.257182746637063, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.392069935798645}, {"id": 63, "seek": 29300, "start": 303.0, "end": 308.0, "text": " If we try and visualize the noise based images, because we're adding noise in the red, pink, blue channels.", "tokens": [50864, 759, 321, 853, 293, 23273, 264, 5658, 2361, 5267, 11, 570, 321, 434, 5127, 5658, 294, 264, 2182, 11, 7022, 11, 3344, 9235, 13, 51114], "temperature": 0.0, "avg_logprob": -0.257182746637063, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.392069935798645}, {"id": 64, "seek": 29300, "start": 308.0, "end": 311.0, "text": " And some of that's quite extreme values.", "tokens": [51114, 400, 512, 295, 300, 311, 1596, 8084, 4190, 13, 51264], "temperature": 0.0, "avg_logprob": -0.257182746637063, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.392069935798645}, {"id": 65, "seek": 29300, "start": 311.0, "end": 312.0, "text": " Yeah, it looks slightly different.", "tokens": [51264, 865, 11, 309, 1542, 4748, 819, 13, 51314], "temperature": 0.0, "avg_logprob": -0.257182746637063, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.392069935798645}, {"id": 66, "seek": 29300, "start": 312.0, "end": 314.0, "text": " Looks all crazy RGB.", "tokens": [51314, 10027, 439, 3219, 31231, 13, 51414], "temperature": 0.0, "avg_logprob": -0.257182746637063, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.392069935798645}, {"id": 67, "seek": 29300, "start": 314.0, "end": 319.0, "text": " But you can see, for example, this frog doesn't have as much noise and it's vaguely visible.", "tokens": [51414, 583, 291, 393, 536, 11, 337, 1365, 11, 341, 17259, 1177, 380, 362, 382, 709, 5658, 293, 309, 311, 13501, 48863, 8974, 13, 51664], "temperature": 0.0, "avg_logprob": -0.257182746637063, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.392069935798645}, {"id": 68, "seek": 31900, "start": 319.0, "end": 325.0, "text": " But it is, it's a nearly impossible task to look at this and tell what image is hiding under all of that noise.", "tokens": [50364, 583, 309, 307, 11, 309, 311, 257, 6217, 6243, 5633, 281, 574, 412, 341, 293, 980, 437, 3256, 307, 10596, 833, 439, 295, 300, 5658, 13, 50664], "temperature": 0.0, "avg_logprob": -0.28884190052479236, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.3921365737915039}, {"id": 69, "seek": 31900, "start": 325.0, "end": 330.0, "text": " So I think this is really neat that you could use the same noiseify.", "tokens": [50664, 407, 286, 519, 341, 307, 534, 10654, 300, 291, 727, 764, 264, 912, 5658, 2505, 13, 50914], "temperature": 0.0, "avg_logprob": -0.28884190052479236, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.3921365737915039}, {"id": 70, "seek": 31900, "start": 330.0, "end": 336.0, "text": " Yeah. And it still works.", "tokens": [50914, 865, 13, 400, 309, 920, 1985, 13, 51214], "temperature": 0.0, "avg_logprob": -0.28884190052479236, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.3921365737915039}, {"id": 71, "seek": 31900, "start": 336.0, "end": 343.0, "text": " Thanks to, it's not just that shape thing, but I guess just thanks to kind of PyTorch's broadcasting kind of stuff.", "tokens": [51214, 2561, 281, 11, 309, 311, 406, 445, 300, 3909, 551, 11, 457, 286, 2041, 445, 3231, 281, 733, 295, 9953, 51, 284, 339, 311, 30024, 733, 295, 1507, 13, 51564], "temperature": 0.0, "avg_logprob": -0.28884190052479236, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.3921365737915039}, {"id": 72, "seek": 31900, "start": 343.0, "end": 345.0, "text": " This often happens.", "tokens": [51564, 639, 2049, 2314, 13, 51664], "temperature": 0.0, "avg_logprob": -0.28884190052479236, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.3921365737915039}, {"id": 73, "seek": 31900, "start": 345.0, "end": 348.0, "text": " You can kind of change the dimensions of things and it just keeps working.", "tokens": [51664, 509, 393, 733, 295, 1319, 264, 12819, 295, 721, 293, 309, 445, 5965, 1364, 13, 51814], "temperature": 0.0, "avg_logprob": -0.28884190052479236, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.3921365737915039}, {"id": 74, "seek": 34800, "start": 348.0, "end": 353.0, "text": " Exactly. And we've been paying attention to those broadcasting rules and the right dimensions and so on.", "tokens": [50364, 7587, 13, 400, 321, 600, 668, 6229, 3202, 281, 729, 30024, 4474, 293, 264, 558, 12819, 293, 370, 322, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2036557391407044, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.12414345890283585}, {"id": 75, "seek": 34800, "start": 353.0, "end": 363.0, "text": " Cool. So I'm going to use the same sort of approach to loading the unit, except that now obviously I need to specify three input channels and three output channels.", "tokens": [50614, 8561, 13, 407, 286, 478, 516, 281, 764, 264, 912, 1333, 295, 3109, 281, 15114, 264, 4985, 11, 3993, 300, 586, 2745, 286, 643, 281, 16500, 1045, 4846, 9235, 293, 1045, 5598, 9235, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2036557391407044, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.12414345890283585}, {"id": 76, "seek": 34800, "start": 363.0, "end": 365.0, "text": " Because we're working with three channel images.", "tokens": [51114, 1436, 321, 434, 1364, 365, 1045, 2269, 5267, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2036557391407044, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.12414345890283585}, {"id": 77, "seek": 34800, "start": 365.0, "end": 374.0, "text": " But I did want to explore for this demo, like, okay, how could I maybe justify wanting to do this kind of experiment tracking thing that I'll talk about.", "tokens": [51214, 583, 286, 630, 528, 281, 6839, 337, 341, 10723, 11, 411, 11, 1392, 11, 577, 727, 286, 1310, 20833, 7935, 281, 360, 341, 733, 295, 5120, 11603, 551, 300, 286, 603, 751, 466, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2036557391407044, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.12414345890283585}, {"id": 78, "seek": 34800, "start": 374.0, "end": 377.0, "text": " And so I'm bumping up the size of the model substantially.", "tokens": [51664, 400, 370, 286, 478, 9961, 278, 493, 264, 2744, 295, 264, 2316, 30797, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2036557391407044, "compression_ratio": 1.664576802507837, "no_speech_prob": 0.12414345890283585}, {"id": 79, "seek": 37700, "start": 377.0, "end": 386.0, "text": " I've gone from this is the default settings that we were using for fashion MNIST, but the diffuser's default unit has what, nearly 20 times as many parameters.", "tokens": [50364, 286, 600, 2780, 490, 341, 307, 264, 7576, 6257, 300, 321, 645, 1228, 337, 6700, 376, 45, 19756, 11, 457, 264, 7593, 18088, 311, 7576, 4985, 575, 437, 11, 6217, 945, 1413, 382, 867, 9834, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2969476882725546, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.3592180907726288}, {"id": 80, "seek": 37700, "start": 386.0, "end": 390.0, "text": " 274 million versus 15 million.", "tokens": [50814, 7634, 19, 2459, 5717, 2119, 2459, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2969476882725546, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.3592180907726288}, {"id": 81, "seek": 37700, "start": 390.0, "end": 391.0, "text": " So we're going to try a larger model.", "tokens": [51014, 407, 321, 434, 516, 281, 853, 257, 4833, 2316, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2969476882725546, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.3592180907726288}, {"id": 82, "seek": 37700, "start": 391.0, "end": 394.0, "text": " We're going to try some log bit training.", "tokens": [51064, 492, 434, 516, 281, 853, 512, 3565, 857, 3097, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2969476882725546, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.3592180907726288}, {"id": 83, "seek": 39400, "start": 394.0, "end": 397.0, "text": " And so I could just do the same training that we've always done.", "tokens": [50364, 400, 370, 286, 727, 445, 360, 264, 912, 3097, 300, 321, 600, 1009, 1096, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2456849367563961, "compression_ratio": 1.61, "no_speech_prob": 0.9132832288742065}, {"id": 84, "seek": 39400, "start": 397.0, "end": 399.0, "text": " Just in the notebook.", "tokens": [50514, 1449, 294, 264, 21060, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2456849367563961, "compression_ratio": 1.61, "no_speech_prob": 0.9132832288742065}, {"id": 85, "seek": 39400, "start": 399.0, "end": 406.0, "text": " Set up a learner with progress CV to kind of plot the loss.", "tokens": [50614, 8928, 493, 257, 33347, 365, 4205, 22995, 281, 733, 295, 7542, 264, 4470, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2456849367563961, "compression_ratio": 1.61, "no_speech_prob": 0.9132832288742065}, {"id": 86, "seek": 39400, "start": 406.0, "end": 408.0, "text": " And subtract some metrics.", "tokens": [50964, 400, 16390, 512, 16367, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2456849367563961, "compression_ratio": 1.61, "no_speech_prob": 0.9132832288742065}, {"id": 87, "seek": 39400, "start": 408.0, "end": 414.0, "text": " But, yeah, I don't know about you, but once it's beyond a few minutes training, I quickly get a patient.", "tokens": [51064, 583, 11, 1338, 11, 286, 500, 380, 458, 466, 291, 11, 457, 1564, 309, 311, 4399, 257, 1326, 2077, 3097, 11, 286, 2661, 483, 257, 4537, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2456849367563961, "compression_ratio": 1.61, "no_speech_prob": 0.9132832288742065}, {"id": 88, "seek": 39400, "start": 414.0, "end": 416.0, "text": " And I have to wait for it to finish before we can sample.", "tokens": [51364, 400, 286, 362, 281, 1699, 337, 309, 281, 2413, 949, 321, 393, 6889, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2456849367563961, "compression_ratio": 1.61, "no_speech_prob": 0.9132832288742065}, {"id": 89, "seek": 39400, "start": 416.0, "end": 423.0, "text": " So I'm doing the DDPM sample, but I have to, I actually interrupted the training to say I just want to get a look at what it looks like initially.", "tokens": [51464, 407, 286, 478, 884, 264, 30778, 18819, 6889, 11, 457, 286, 362, 281, 11, 286, 767, 30329, 264, 3097, 281, 584, 286, 445, 528, 281, 483, 257, 574, 412, 437, 309, 1542, 411, 9105, 13, 51814], "temperature": 0.0, "avg_logprob": -0.2456849367563961, "compression_ratio": 1.61, "no_speech_prob": 0.9132832288742065}, {"id": 90, "seek": 42300, "start": 423.0, "end": 425.0, "text": " And to plot some samples.", "tokens": [50364, 400, 281, 7542, 512, 10938, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21321404825045367, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.30729666352272034}, {"id": 91, "seek": 42300, "start": 425.0, "end": 428.0, "text": " And, again, the sampling function works without any modification.", "tokens": [50464, 400, 11, 797, 11, 264, 21179, 2445, 1985, 1553, 604, 26747, 13, 50614], "temperature": 0.0, "avg_logprob": -0.21321404825045367, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.30729666352272034}, {"id": 92, "seek": 42300, "start": 428.0, "end": 431.0, "text": " But I'm passing in my size to be a three channel image.", "tokens": [50614, 583, 286, 478, 8437, 294, 452, 2744, 281, 312, 257, 1045, 2269, 3256, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21321404825045367, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.30729666352272034}, {"id": 93, "seek": 42300, "start": 431.0, "end": 435.0, "text": " Yeah, and so this is like, we could do it like this.", "tokens": [50764, 865, 11, 293, 370, 341, 307, 411, 11, 321, 727, 360, 309, 411, 341, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21321404825045367, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.30729666352272034}, {"id": 94, "seek": 42300, "start": 435.0, "end": 440.0, "text": " But at some point I would like to, A, keep track of what experiments I've tried.", "tokens": [50964, 583, 412, 512, 935, 286, 576, 411, 281, 11, 316, 11, 1066, 2837, 295, 437, 12050, 286, 600, 3031, 13, 51214], "temperature": 0.0, "avg_logprob": -0.21321404825045367, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.30729666352272034}, {"id": 95, "seek": 42300, "start": 440.0, "end": 450.0, "text": " And, B, be able to see things as it's going over time, including, like, I would love to see what the samples look like if you generate it after the first epoch, after the second epoch.", "tokens": [51214, 400, 11, 363, 11, 312, 1075, 281, 536, 721, 382, 309, 311, 516, 670, 565, 11, 3009, 11, 411, 11, 286, 576, 959, 281, 536, 437, 264, 10938, 574, 411, 498, 291, 8460, 309, 934, 264, 700, 30992, 339, 11, 934, 264, 1150, 30992, 339, 13, 51714], "temperature": 0.0, "avg_logprob": -0.21321404825045367, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.30729666352272034}, {"id": 96, "seek": 45000, "start": 450.0, "end": 454.0, "text": " And so that's where my little callback that I've been playing with comes in.", "tokens": [50364, 400, 370, 300, 311, 689, 452, 707, 818, 3207, 300, 286, 600, 668, 2433, 365, 1487, 294, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20698120594024658, "compression_ratio": 1.4898989898989898, "no_speech_prob": 0.05183963477611542}, {"id": 97, "seek": 45000, "start": 454.0, "end": 460.0, "text": " So just before you do that, I'll just mention, like, I mean, there are simple ways you could do that, right?", "tokens": [50564, 407, 445, 949, 291, 360, 300, 11, 286, 603, 445, 2152, 11, 411, 11, 286, 914, 11, 456, 366, 2199, 2098, 291, 727, 360, 300, 11, 558, 30, 50864], "temperature": 0.0, "avg_logprob": -0.20698120594024658, "compression_ratio": 1.4898989898989898, "no_speech_prob": 0.05183963477611542}, {"id": 98, "seek": 45000, "start": 460.0, "end": 467.0, "text": " Like, one popular way a lot of people do is that they'll save some sample images as files every epoch or two.", "tokens": [50864, 1743, 11, 472, 3743, 636, 257, 688, 295, 561, 360, 307, 300, 436, 603, 3155, 512, 6889, 5267, 382, 7098, 633, 30992, 339, 420, 732, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20698120594024658, "compression_ratio": 1.4898989898989898, "no_speech_prob": 0.05183963477611542}, {"id": 99, "seek": 46700, "start": 467.0, "end": 481.0, "text": " Or we could, like, the same way that we have a updating plot as we train with fast progress, we could have an updating set of sample images.", "tokens": [50364, 1610, 321, 727, 11, 411, 11, 264, 912, 636, 300, 321, 362, 257, 25113, 7542, 382, 321, 3847, 365, 2370, 4205, 11, 321, 727, 362, 364, 25113, 992, 295, 6889, 5267, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21444429670061385, "compression_ratio": 1.4409448818897639, "no_speech_prob": 0.23640364408493042}, {"id": 100, "seek": 46700, "start": 481.0, "end": 485.0, "text": " So there's a few ways we could solve that.", "tokens": [51064, 407, 456, 311, 257, 1326, 2098, 321, 727, 5039, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21444429670061385, "compression_ratio": 1.4409448818897639, "no_speech_prob": 0.23640364408493042}, {"id": 101, "seek": 48500, "start": 485.0, "end": 501.0, "text": " That wouldn't handle the tracking that you mentioned of, like, looking over time at how different changes have improved things or made them worse, whatever that would, I guess, would require you kind of like saving multiple versions of a notebook or keeping some kind of research journal or something.", "tokens": [50364, 663, 2759, 380, 4813, 264, 11603, 300, 291, 2835, 295, 11, 411, 11, 1237, 670, 565, 412, 577, 819, 2962, 362, 9689, 721, 420, 1027, 552, 5324, 11, 2035, 300, 576, 11, 286, 2041, 11, 576, 3651, 291, 733, 295, 411, 6816, 3866, 9606, 295, 257, 21060, 420, 5145, 512, 733, 295, 2132, 6708, 420, 746, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24867603390715842, "compression_ratio": 1.646103896103896, "no_speech_prob": 0.3773338794708252}, {"id": 102, "seek": 48500, "start": 501.0, "end": 503.0, "text": " That'd be a bit fiddly.", "tokens": [51164, 663, 1116, 312, 257, 857, 283, 14273, 356, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24867603390715842, "compression_ratio": 1.646103896103896, "no_speech_prob": 0.3773338794708252}, {"id": 103, "seek": 48500, "start": 503.0, "end": 504.0, "text": " It is.", "tokens": [51264, 467, 307, 13, 51314], "temperature": 0.0, "avg_logprob": -0.24867603390715842, "compression_ratio": 1.646103896103896, "no_speech_prob": 0.3773338794708252}, {"id": 104, "seek": 48500, "start": 504.0, "end": 505.0, "text": " And all of that's doable.", "tokens": [51314, 400, 439, 295, 300, 311, 41183, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24867603390715842, "compression_ratio": 1.646103896103896, "no_speech_prob": 0.3773338794708252}, {"id": 105, "seek": 48500, "start": 505.0, "end": 508.0, "text": " But I also find, like, I'm a little bit lazy sometimes.", "tokens": [51364, 583, 286, 611, 915, 11, 411, 11, 286, 478, 257, 707, 857, 14847, 2171, 13, 51514], "temperature": 0.0, "avg_logprob": -0.24867603390715842, "compression_ratio": 1.646103896103896, "no_speech_prob": 0.3773338794708252}, {"id": 106, "seek": 48500, "start": 508.0, "end": 514.0, "text": " Maybe I don't write down what I'm trying or, yeah, I've saved untitled numbers 37 notebooks.", "tokens": [51514, 2704, 286, 500, 380, 2464, 760, 437, 286, 478, 1382, 420, 11, 1338, 11, 286, 600, 6624, 1701, 270, 1493, 3547, 13435, 43782, 13, 51814], "temperature": 0.0, "avg_logprob": -0.24867603390715842, "compression_ratio": 1.646103896103896, "no_speech_prob": 0.3773338794708252}, {"id": 107, "seek": 51400, "start": 514.0, "end": 522.0, "text": " So, yeah, the idea that I wanted to show here is just that there are lots of other solutions for this kind of experiment tracking and logging.", "tokens": [50364, 407, 11, 1338, 11, 264, 1558, 300, 286, 1415, 281, 855, 510, 307, 445, 300, 456, 366, 3195, 295, 661, 6547, 337, 341, 733, 295, 5120, 11603, 293, 27991, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1854043688092913, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.1112346425652504}, {"id": 108, "seek": 51400, "start": 522.0, "end": 525.0, "text": " And one that I really like is called Weights and Biases.", "tokens": [50764, 400, 472, 300, 286, 534, 411, 307, 1219, 492, 5761, 293, 13007, 1957, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1854043688092913, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.1112346425652504}, {"id": 109, "seek": 51400, "start": 525.0, "end": 532.0, "text": " So I'll explain what's going on in the code here, but I'm running a training with this additional Weights and Biases callback.", "tokens": [50914, 407, 286, 603, 2903, 437, 311, 516, 322, 294, 264, 3089, 510, 11, 457, 286, 478, 2614, 257, 3097, 365, 341, 4497, 492, 5761, 293, 13007, 1957, 818, 3207, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1854043688092913, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.1112346425652504}, {"id": 110, "seek": 51400, "start": 532.0, "end": 536.0, "text": " And what it's doing is it's allowing me to log whatever I'd like.", "tokens": [51264, 400, 437, 309, 311, 884, 307, 309, 311, 8293, 385, 281, 3565, 2035, 286, 1116, 411, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1854043688092913, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.1112346425652504}, {"id": 111, "seek": 51400, "start": 536.0, "end": 540.0, "text": " So I can log samples at different stages.", "tokens": [51464, 407, 286, 393, 3565, 10938, 412, 819, 10232, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1854043688092913, "compression_ratio": 1.7086614173228347, "no_speech_prob": 0.1112346425652504}, {"id": 112, "seek": 54000, "start": 540.0, "end": 544.0, "text": " Okay, so you're switching to a website here called W&B.AI.", "tokens": [50364, 1033, 11, 370, 291, 434, 16493, 281, 257, 3144, 510, 1219, 343, 5, 33, 13, 48698, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24073662902369644, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.20178046822547913}, {"id": 113, "seek": 54000, "start": 544.0, "end": 548.0, "text": " So that's where your callback is sending information to.", "tokens": [50564, 407, 300, 311, 689, 428, 818, 3207, 307, 7750, 1589, 281, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24073662902369644, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.20178046822547913}, {"id": 114, "seek": 54000, "start": 548.0, "end": 549.0, "text": " Yeah.", "tokens": [50764, 865, 13, 50814], "temperature": 0.0, "avg_logprob": -0.24073662902369644, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.20178046822547913}, {"id": 115, "seek": 54000, "start": 549.0, "end": 553.0, "text": " So Weights and Biases accounts are free for personal and academic use.", "tokens": [50814, 407, 492, 5761, 293, 13007, 1957, 9402, 366, 1737, 337, 2973, 293, 7778, 764, 13, 51014], "temperature": 0.0, "avg_logprob": -0.24073662902369644, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.20178046822547913}, {"id": 116, "seek": 54000, "start": 553.0, "end": 556.0, "text": " And it's very, very, like, I don't think I know anyone who writes for Weights and Biases.", "tokens": [51014, 400, 309, 311, 588, 11, 588, 11, 411, 11, 286, 500, 380, 519, 286, 458, 2878, 567, 13657, 337, 492, 5761, 293, 13007, 1957, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24073662902369644, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.20178046822547913}, {"id": 117, "seek": 54000, "start": 556.0, "end": 558.0, "text": " But it's a very nice service.", "tokens": [51164, 583, 309, 311, 257, 588, 1481, 2643, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24073662902369644, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.20178046822547913}, {"id": 118, "seek": 54000, "start": 558.0, "end": 562.0, "text": " You sign in and you log in on your computer or you get a little authentication token.", "tokens": [51264, 509, 1465, 294, 293, 291, 3565, 294, 322, 428, 3820, 420, 291, 483, 257, 707, 26643, 14862, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24073662902369644, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.20178046822547913}, {"id": 119, "seek": 54000, "start": 562.0, "end": 567.0, "text": " And then you're able to log these experiments and you can log into different projects.", "tokens": [51464, 400, 550, 291, 434, 1075, 281, 3565, 613, 12050, 293, 291, 393, 3565, 666, 819, 4455, 13, 51714], "temperature": 0.0, "avg_logprob": -0.24073662902369644, "compression_ratio": 1.6552901023890785, "no_speech_prob": 0.20178046822547913}, {"id": 120, "seek": 56700, "start": 568.0, "end": 575.0, "text": " And what it gives you is for each experiment, anything that you call Weights and Biases.log at any step in the training,", "tokens": [50414, 400, 437, 309, 2709, 291, 307, 337, 1184, 5120, 11, 1340, 300, 291, 818, 492, 5761, 293, 13007, 1957, 13, 4987, 412, 604, 1823, 294, 264, 3097, 11, 50764], "temperature": 0.0, "avg_logprob": -0.2137120246887207, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.35929378867149353}, {"id": 121, "seek": 56700, "start": 575.0, "end": 581.0, "text": " that's getting logged and sent to their server and stored somewhere where you can later, like, access it and display it.", "tokens": [50764, 300, 311, 1242, 27231, 293, 2279, 281, 641, 7154, 293, 12187, 4079, 689, 291, 393, 1780, 11, 411, 11, 2105, 309, 293, 4674, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2137120246887207, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.35929378867149353}, {"id": 122, "seek": 56700, "start": 581.0, "end": 584.0, "text": " They have these plots that you can, you know, visualize easily.", "tokens": [51064, 814, 362, 613, 28609, 300, 291, 393, 11, 291, 458, 11, 23273, 3612, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2137120246887207, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.35929378867149353}, {"id": 123, "seek": 56700, "start": 584.0, "end": 591.0, "text": " And you can also share them very easily in, like, these reports that integrate this data sort of interactively.", "tokens": [51214, 400, 291, 393, 611, 2073, 552, 588, 3612, 294, 11, 411, 11, 613, 7122, 300, 13365, 341, 1412, 1333, 295, 4648, 3413, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2137120246887207, "compression_ratio": 1.6746987951807228, "no_speech_prob": 0.35929378867149353}, {"id": 124, "seek": 59100, "start": 592.0, "end": 598.0, "text": " And why that's nice is that later, like, you can go and look at, so this is now the project that I'm logging to.", "tokens": [50414, 400, 983, 300, 311, 1481, 307, 300, 1780, 11, 411, 11, 291, 393, 352, 293, 574, 412, 11, 370, 341, 307, 586, 264, 1716, 300, 286, 478, 27991, 281, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2365478958402361, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.5811555981636047}, {"id": 125, "seek": 59100, "start": 598.0, "end": 602.0, "text": " You can log multiple runs with different settings.", "tokens": [50714, 509, 393, 3565, 3866, 6676, 365, 819, 6257, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2365478958402361, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.5811555981636047}, {"id": 126, "seek": 59100, "start": 602.0, "end": 609.0, "text": " And for each of those, you have all of these things that you've tracked, like, your training loss and validation.", "tokens": [50914, 400, 337, 1184, 295, 729, 11, 291, 362, 439, 295, 613, 721, 300, 291, 600, 31703, 11, 411, 11, 428, 3097, 4470, 293, 24071, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2365478958402361, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.5811555981636047}, {"id": 127, "seek": 59100, "start": 609.0, "end": 613.0, "text": " But you can also track your learning rate if you've been in a learning rate schedule.", "tokens": [51264, 583, 291, 393, 611, 2837, 428, 2539, 3314, 498, 291, 600, 668, 294, 257, 2539, 3314, 7567, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2365478958402361, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.5811555981636047}, {"id": 128, "seek": 59100, "start": 613.0, "end": 617.0, "text": " And you can save your model as an artifact and it'll get saved on their server.", "tokens": [51464, 400, 291, 393, 3155, 428, 2316, 382, 364, 34806, 293, 309, 603, 483, 6624, 322, 641, 7154, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2365478958402361, "compression_ratio": 1.7372549019607844, "no_speech_prob": 0.5811555981636047}, {"id": 129, "seek": 61700, "start": 617.0, "end": 621.0, "text": " So you can see exactly what run produced what model.", "tokens": [50364, 407, 291, 393, 536, 2293, 437, 1190, 7126, 437, 2316, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21619263062110314, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.37011459469795227}, {"id": 130, "seek": 61700, "start": 621.0, "end": 626.0, "text": " It logs the code if you set that to, you can save, you know, save code equals true.", "tokens": [50564, 467, 20820, 264, 3089, 498, 291, 992, 300, 281, 11, 291, 393, 3155, 11, 291, 458, 11, 3155, 3089, 6915, 2074, 13, 50814], "temperature": 0.0, "avg_logprob": -0.21619263062110314, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.37011459469795227}, {"id": 131, "seek": 61700, "start": 626.0, "end": 631.0, "text": " And then it creates a copy of your whole Python environment, what libraries were installed, what code you ran.", "tokens": [50814, 400, 550, 309, 7829, 257, 5055, 295, 428, 1379, 15329, 2823, 11, 437, 15148, 645, 8899, 11, 437, 3089, 291, 5872, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21619263062110314, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.37011459469795227}, {"id": 132, "seek": 61700, "start": 631.0, "end": 637.0, "text": " So for being able to come back later and say, oh, these images here, these look really good.", "tokens": [51064, 407, 337, 885, 1075, 281, 808, 646, 1780, 293, 584, 11, 1954, 11, 613, 5267, 510, 11, 613, 574, 534, 665, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21619263062110314, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.37011459469795227}, {"id": 133, "seek": 61700, "start": 637.0, "end": 641.0, "text": " I can go back and see, oh, that was this experiment here.", "tokens": [51364, 286, 393, 352, 646, 293, 536, 11, 1954, 11, 300, 390, 341, 5120, 510, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21619263062110314, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.37011459469795227}, {"id": 134, "seek": 64100, "start": 641.0, "end": 645.0, "text": " I can check what settings I used.", "tokens": [50364, 286, 393, 1520, 437, 6257, 286, 1143, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2541141717330269, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.18472349643707275}, {"id": 135, "seek": 64100, "start": 645.0, "end": 653.0, "text": " In the initialization, you can log whatever configuration details you'd like in any comments.", "tokens": [50564, 682, 264, 5883, 2144, 11, 291, 393, 3565, 2035, 11694, 4365, 291, 1116, 411, 294, 604, 3053, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2541141717330269, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.18472349643707275}, {"id": 136, "seek": 64100, "start": 653.0, "end": 657.0, "text": " And yeah, there's other frameworks for this.", "tokens": [50964, 400, 1338, 11, 456, 311, 661, 29834, 337, 341, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2541141717330269, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.18472349643707275}, {"id": 137, "seek": 64100, "start": 657.0, "end": 664.0, "text": " Yeah, in some ways, it's kind of, initially, when I first saw Weights & Biases, it felt a bit weird to me, actually, like,", "tokens": [51164, 865, 11, 294, 512, 2098, 11, 309, 311, 733, 295, 11, 9105, 11, 562, 286, 700, 1866, 492, 5761, 3693, 13007, 1957, 11, 309, 2762, 257, 857, 3657, 281, 385, 11, 767, 11, 411, 11, 51514], "temperature": 0.0, "avg_logprob": -0.2541141717330269, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.18472349643707275}, {"id": 138, "seek": 64100, "start": 664.0, "end": 667.0, "text": " sending your information off to an external website.", "tokens": [51514, 7750, 428, 1589, 766, 281, 364, 8320, 3144, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2541141717330269, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.18472349643707275}, {"id": 139, "seek": 66700, "start": 667.0, "end": 673.0, "text": " Because, I mean, before Weights & Biases existed, the most popular way to do this was something called TensorBoard,", "tokens": [50364, 1436, 11, 286, 914, 11, 949, 492, 5761, 3693, 13007, 1957, 13135, 11, 264, 881, 3743, 636, 281, 360, 341, 390, 746, 1219, 34306, 22493, 515, 11, 50664], "temperature": 0.0, "avg_logprob": -0.18408265224722928, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.0780426412820816}, {"id": 140, "seek": 66700, "start": 673.0, "end": 681.0, "text": " which Google provides, which is actually a lot like this, but it's a little server that runs on your computer.", "tokens": [50664, 597, 3329, 6417, 11, 597, 307, 767, 257, 688, 411, 341, 11, 457, 309, 311, 257, 707, 7154, 300, 6676, 322, 428, 3820, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18408265224722928, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.0780426412820816}, {"id": 141, "seek": 66700, "start": 681.0, "end": 689.0, "text": " And so, like, when you log things, it just puts it into this little database on your computer, which is totally fine.", "tokens": [51064, 400, 370, 11, 411, 11, 562, 291, 3565, 721, 11, 309, 445, 8137, 309, 666, 341, 707, 8149, 322, 428, 3820, 11, 597, 307, 3879, 2489, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18408265224722928, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.0780426412820816}, {"id": 142, "seek": 68900, "start": 690.0, "end": 698.0, "text": " But I guess, actually, there are some benefits to having somebody else run this service, you know,", "tokens": [50414, 583, 286, 2041, 11, 767, 11, 456, 366, 512, 5311, 281, 1419, 2618, 1646, 1190, 341, 2643, 11, 291, 458, 11, 50814], "temperature": 0.0, "avg_logprob": -0.2024545380563447, "compression_ratio": 1.5573122529644268, "no_speech_prob": 0.008984108455479145}, {"id": 143, "seek": 68900, "start": 698.0, "end": 702.0, "text": " instead of running your own little TensorBoard or whatever server.", "tokens": [50814, 2602, 295, 2614, 428, 1065, 707, 34306, 22493, 515, 420, 2035, 7154, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2024545380563447, "compression_ratio": 1.5573122529644268, "no_speech_prob": 0.008984108455479145}, {"id": 144, "seek": 68900, "start": 702.0, "end": 708.0, "text": " You know, one is that you can have multiple people working on a project, collaborating.", "tokens": [51014, 509, 458, 11, 472, 307, 300, 291, 393, 362, 3866, 561, 1364, 322, 257, 1716, 11, 30188, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2024545380563447, "compression_ratio": 1.5573122529644268, "no_speech_prob": 0.008984108455479145}, {"id": 145, "seek": 68900, "start": 708.0, "end": 713.0, "text": " So I've done that before, where we will each be sending, like, different sets of hyperparameters,", "tokens": [51314, 407, 286, 600, 1096, 300, 949, 11, 689, 321, 486, 1184, 312, 7750, 11, 411, 11, 819, 6352, 295, 9848, 2181, 335, 6202, 11, 51564], "temperature": 0.0, "avg_logprob": -0.2024545380563447, "compression_ratio": 1.5573122529644268, "no_speech_prob": 0.008984108455479145}, {"id": 146, "seek": 68900, "start": 713.0, "end": 716.0, "text": " and then they'll end up in the same place.", "tokens": [51564, 293, 550, 436, 603, 917, 493, 294, 264, 912, 1081, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2024545380563447, "compression_ratio": 1.5573122529644268, "no_speech_prob": 0.008984108455479145}, {"id": 147, "seek": 71600, "start": 716.0, "end": 726.0, "text": " Or if you want to be really antisocial, you know, you can interrupt your romantic dinner and look at your phone to see how your training's going.", "tokens": [50364, 1610, 498, 291, 528, 281, 312, 534, 2511, 19227, 1013, 11, 291, 458, 11, 291, 393, 12729, 428, 13590, 6148, 293, 574, 412, 428, 2593, 281, 536, 577, 428, 3097, 311, 516, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17580330037625036, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.01615018956363201}, {"id": 148, "seek": 71600, "start": 726.0, "end": 732.0, "text": " So, like, yeah, I'm not going to say it's, like, always the best approach to doing things,", "tokens": [50864, 407, 11, 411, 11, 1338, 11, 286, 478, 406, 516, 281, 584, 309, 311, 11, 411, 11, 1009, 264, 1151, 3109, 281, 884, 721, 11, 51164], "temperature": 0.0, "avg_logprob": -0.17580330037625036, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.01615018956363201}, {"id": 149, "seek": 71600, "start": 732.0, "end": 736.0, "text": " but I think there's definitely benefits to using this kind of service.", "tokens": [51164, 457, 286, 519, 456, 311, 2138, 5311, 281, 1228, 341, 733, 295, 2643, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17580330037625036, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.01615018956363201}, {"id": 150, "seek": 71600, "start": 736.0, "end": 742.0, "text": " And it looks like you're showing us that you can also create reports for sharing this, which is also pretty nifty.", "tokens": [51364, 400, 309, 1542, 411, 291, 434, 4099, 505, 300, 291, 393, 611, 1884, 7122, 337, 5414, 341, 11, 597, 307, 611, 1238, 297, 37177, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17580330037625036, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.01615018956363201}, {"id": 151, "seek": 74200, "start": 742.0, "end": 753.0, "text": " Yeah, yeah. So I like for working with other people, or, like, you want to show somebody the final results,", "tokens": [50364, 865, 11, 1338, 13, 407, 286, 411, 337, 1364, 365, 661, 561, 11, 420, 11, 411, 11, 291, 528, 281, 855, 2618, 264, 2572, 3542, 11, 50914], "temperature": 0.0, "avg_logprob": -0.2750189615332562, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.191791370511055}, {"id": 152, "seek": 74200, "start": 753.0, "end": 757.0, "text": " and being able to, yeah, like, pull together the results from some different runs,", "tokens": [50914, 293, 885, 1075, 281, 11, 1338, 11, 411, 11, 2235, 1214, 264, 3542, 490, 512, 819, 6676, 11, 51114], "temperature": 0.0, "avg_logprob": -0.2750189615332562, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.191791370511055}, {"id": 153, "seek": 74200, "start": 757.0, "end": 766.0, "text": " or just say, oh, look, by the way, here's a set of examples from my two most recent,", "tokens": [51114, 420, 445, 584, 11, 1954, 11, 574, 11, 538, 264, 636, 11, 510, 311, 257, 992, 295, 5110, 490, 452, 732, 881, 5162, 11, 51564], "temperature": 0.0, "avg_logprob": -0.2750189615332562, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.191791370511055}, {"id": 154, "seek": 74200, "start": 766.0, "end": 770.0, "text": " and things track to different steps. What do you think of this?", "tokens": [51564, 293, 721, 2837, 281, 819, 4439, 13, 708, 360, 291, 519, 295, 341, 30, 51764], "temperature": 0.0, "avg_logprob": -0.2750189615332562, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.191791370511055}, {"id": 155, "seek": 77000, "start": 771.0, "end": 776.0, "text": " And, yeah, being able to have this, like, place where everyone can go and they can inspect the different loss curves.", "tokens": [50414, 400, 11, 1338, 11, 885, 1075, 281, 362, 341, 11, 411, 11, 1081, 689, 1518, 393, 352, 293, 436, 393, 15018, 264, 819, 4470, 19490, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20572377954210555, "compression_ratio": 1.5419847328244274, "no_speech_prob": 0.6037823557853699}, {"id": 156, "seek": 77000, "start": 776.0, "end": 783.0, "text": " For any run, they can say, oh, you know, what was the batch size for this? Let me go look at the info there.", "tokens": [50664, 1171, 604, 1190, 11, 436, 393, 584, 11, 1954, 11, 291, 458, 11, 437, 390, 264, 15245, 2744, 337, 341, 30, 961, 385, 352, 574, 412, 264, 13614, 456, 13, 51014], "temperature": 0.0, "avg_logprob": -0.20572377954210555, "compression_ratio": 1.5419847328244274, "no_speech_prob": 0.6037823557853699}, {"id": 157, "seek": 77000, "start": 783.0, "end": 787.0, "text": " Okay, I didn't log it, but I logged how many epochs and the learning rate.", "tokens": [51014, 1033, 11, 286, 994, 380, 3565, 309, 11, 457, 286, 27231, 577, 867, 30992, 28346, 293, 264, 2539, 3314, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20572377954210555, "compression_ratio": 1.5419847328244274, "no_speech_prob": 0.6037823557853699}, {"id": 158, "seek": 77000, "start": 787.0, "end": 793.0, "text": " So, yeah, I find it quite nice, especially in a team, or if you're doing lots and lots of experiments,", "tokens": [51214, 407, 11, 1338, 11, 286, 915, 309, 1596, 1481, 11, 2318, 294, 257, 1469, 11, 420, 498, 291, 434, 884, 3195, 293, 3195, 295, 12050, 11, 51514], "temperature": 0.0, "avg_logprob": -0.20572377954210555, "compression_ratio": 1.5419847328244274, "no_speech_prob": 0.6037823557853699}, {"id": 159, "seek": 79300, "start": 793.0, "end": 800.0, "text": " to be able to, like, have this permanent record that somebody else deals with, and they have the storage and the tracking.", "tokens": [50364, 281, 312, 1075, 281, 11, 411, 11, 362, 341, 10996, 2136, 300, 2618, 1646, 11215, 365, 11, 293, 436, 362, 264, 6725, 293, 264, 11603, 13, 50714], "temperature": 0.0, "avg_logprob": -0.28715558259383495, "compression_ratio": 1.6827309236947792, "no_speech_prob": 0.4034460783004761}, {"id": 160, "seek": 79300, "start": 800.0, "end": 802.0, "text": " Yeah, it's quite nice.", "tokens": [50714, 865, 11, 309, 311, 1596, 1481, 13, 50814], "temperature": 0.0, "avg_logprob": -0.28715558259383495, "compression_ratio": 1.6827309236947792, "no_speech_prob": 0.4034460783004761}, {"id": 161, "seek": 79300, "start": 802.0, "end": 806.0, "text": " Wait, and this is all the code you had to write? That's amazing.", "tokens": [50814, 3802, 11, 293, 341, 307, 439, 264, 3089, 291, 632, 281, 2464, 30, 663, 311, 2243, 13, 51014], "temperature": 0.0, "avg_logprob": -0.28715558259383495, "compression_ratio": 1.6827309236947792, "no_speech_prob": 0.4034460783004761}, {"id": 162, "seek": 79300, "start": 806.0, "end": 810.0, "text": " Yeah, so this is using the callback system.", "tokens": [51014, 865, 11, 370, 341, 307, 1228, 264, 818, 3207, 1185, 13, 51214], "temperature": 0.0, "avg_logprob": -0.28715558259383495, "compression_ratio": 1.6827309236947792, "no_speech_prob": 0.4034460783004761}, {"id": 163, "seek": 79300, "start": 810.0, "end": 816.0, "text": " The way Waits and Biases works is that you start an experiment with this oneDB.init,", "tokens": [51214, 440, 636, 3802, 82, 293, 363, 4609, 279, 1985, 307, 300, 291, 722, 364, 5120, 365, 341, 472, 27735, 13, 259, 270, 11, 51514], "temperature": 0.0, "avg_logprob": -0.28715558259383495, "compression_ratio": 1.6827309236947792, "no_speech_prob": 0.4034460783004761}, {"id": 164, "seek": 79300, "start": 816.0, "end": 820.0, "text": " and you can specify any, like, configurational settings that you've used there.", "tokens": [51514, 293, 291, 393, 16500, 604, 11, 411, 11, 22192, 1478, 6257, 300, 291, 600, 1143, 456, 13, 51714], "temperature": 0.0, "avg_logprob": -0.28715558259383495, "compression_ratio": 1.6827309236947792, "no_speech_prob": 0.4034460783004761}, {"id": 165, "seek": 82000, "start": 820.0, "end": 826.0, "text": " And then anything you need to log is oneDB.log, and you pass in whatever the name of your value is,", "tokens": [50364, 400, 550, 1340, 291, 643, 281, 3565, 307, 472, 27735, 13, 4987, 11, 293, 291, 1320, 294, 2035, 264, 1315, 295, 428, 2158, 307, 11, 50664], "temperature": 0.0, "avg_logprob": -0.22698648425116055, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.05418716371059418}, {"id": 166, "seek": 82000, "start": 826.0, "end": 829.0, "text": " like, I'm logging the loss, and then the value.", "tokens": [50664, 411, 11, 286, 478, 27991, 264, 4470, 11, 293, 550, 264, 2158, 13, 50814], "temperature": 0.0, "avg_logprob": -0.22698648425116055, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.05418716371059418}, {"id": 167, "seek": 82000, "start": 829.0, "end": 834.0, "text": " And once you've done oneDB.finish, and that syncs everything up and sends it to the server.", "tokens": [50814, 400, 1564, 291, 600, 1096, 472, 27735, 13, 5194, 742, 11, 293, 300, 5451, 14368, 1203, 493, 293, 14790, 309, 281, 264, 7154, 13, 51064], "temperature": 0.0, "avg_logprob": -0.22698648425116055, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.05418716371059418}, {"id": 168, "seek": 82000, "start": 834.0, "end": 840.0, "text": " Oh, this is wild, the way you've inherited from MetricCB, and you replaced that underscore log that we previously used", "tokens": [51064, 876, 11, 341, 307, 4868, 11, 264, 636, 291, 600, 27091, 490, 6377, 1341, 34, 33, 11, 293, 291, 10772, 300, 37556, 3565, 300, 321, 8046, 1143, 51364], "temperature": 0.0, "avg_logprob": -0.22698648425116055, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.05418716371059418}, {"id": 169, "seek": 82000, "start": 840.0, "end": 846.0, "text": " to allow fast progress to do the logging, and you've replaced it to allow Waits and Biases to do the logging.", "tokens": [51364, 281, 2089, 2370, 4205, 281, 360, 264, 27991, 11, 293, 291, 600, 10772, 309, 281, 2089, 3802, 82, 293, 13007, 1957, 281, 360, 264, 27991, 13, 51664], "temperature": 0.0, "avg_logprob": -0.22698648425116055, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.05418716371059418}, {"id": 170, "seek": 82000, "start": 846.0, "end": 848.0, "text": " So, yeah, it's really sweet.", "tokens": [51664, 407, 11, 1338, 11, 309, 311, 534, 3844, 13, 51764], "temperature": 0.0, "avg_logprob": -0.22698648425116055, "compression_ratio": 1.7877697841726619, "no_speech_prob": 0.05418716371059418}, {"id": 171, "seek": 84800, "start": 849.0, "end": 852.0, "text": " Yeah, yeah, so this is using the callback system.", "tokens": [50414, 865, 11, 1338, 11, 370, 341, 307, 1228, 264, 818, 3207, 1185, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18032520157950266, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.04740405082702637}, {"id": 172, "seek": 84800, "start": 852.0, "end": 858.0, "text": " I wanted to do the things that MetricCB normally does, which is tracking different metrics that you pass in.", "tokens": [50564, 286, 1415, 281, 360, 264, 721, 300, 6377, 1341, 34, 33, 5646, 775, 11, 597, 307, 11603, 819, 16367, 300, 291, 1320, 294, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18032520157950266, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.04740405082702637}, {"id": 173, "seek": 84800, "start": 858.0, "end": 866.0, "text": " So this will still do that, and I just offload to the super, like, the original MetricCB method for things like the after batch.", "tokens": [50864, 407, 341, 486, 920, 360, 300, 11, 293, 286, 445, 766, 2907, 281, 264, 1687, 11, 411, 11, 264, 3380, 6377, 1341, 34, 33, 3170, 337, 721, 411, 264, 934, 15245, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18032520157950266, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.04740405082702637}, {"id": 174, "seek": 84800, "start": 866.0, "end": 869.0, "text": " But in addition to that, I'd also like to log the Waits and Biases.", "tokens": [51264, 583, 294, 4500, 281, 300, 11, 286, 1116, 611, 411, 281, 3565, 264, 3802, 82, 293, 13007, 1957, 13, 51414], "temperature": 0.0, "avg_logprob": -0.18032520157950266, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.04740405082702637}, {"id": 175, "seek": 84800, "start": 869.0, "end": 873.0, "text": " And so before I fit, I initialize the experiments.", "tokens": [51414, 400, 370, 949, 286, 3318, 11, 286, 5883, 1125, 264, 12050, 13, 51614], "temperature": 0.0, "avg_logprob": -0.18032520157950266, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.04740405082702637}, {"id": 176, "seek": 87300, "start": 873.0, "end": 876.0, "text": " Every batch, I'm going to log the loss.", "tokens": [50364, 2048, 15245, 11, 286, 478, 516, 281, 3565, 264, 4470, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1936783077209953, "compression_ratio": 1.8, "no_speech_prob": 0.5154546499252319}, {"id": 177, "seek": 87300, "start": 876.0, "end": 883.0, "text": " After every epoch, the default metrics callback is going to accumulate the metrics and so on,", "tokens": [50514, 2381, 633, 30992, 339, 11, 264, 7576, 16367, 818, 3207, 307, 516, 281, 33384, 264, 16367, 293, 370, 322, 11, 50864], "temperature": 0.0, "avg_logprob": -0.1936783077209953, "compression_ratio": 1.8, "no_speech_prob": 0.5154546499252319}, {"id": 178, "seek": 87300, "start": 883.0, "end": 885.0, "text": " and then it's going to call this underscore log function.", "tokens": [50864, 293, 550, 309, 311, 516, 281, 818, 341, 37556, 3565, 2445, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1936783077209953, "compression_ratio": 1.8, "no_speech_prob": 0.5154546499252319}, {"id": 179, "seek": 87300, "start": 885.0, "end": 890.0, "text": " So I chose to modify that to say I'm going to log my training loss.", "tokens": [50964, 407, 286, 5111, 281, 16927, 300, 281, 584, 286, 478, 516, 281, 3565, 452, 3097, 4470, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1936783077209953, "compression_ratio": 1.8, "no_speech_prob": 0.5154546499252319}, {"id": 180, "seek": 87300, "start": 890.0, "end": 895.0, "text": " I'm going to log my validation loss if I'm doing validation, and I'd like to log some samples.", "tokens": [51214, 286, 478, 516, 281, 3565, 452, 24071, 4470, 498, 286, 478, 884, 24071, 11, 293, 286, 1116, 411, 281, 3565, 512, 10938, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1936783077209953, "compression_ratio": 1.8, "no_speech_prob": 0.5154546499252319}, {"id": 181, "seek": 87300, "start": 895.0, "end": 898.0, "text": " And Waits and Biases is quite flexible in terms of what you can log.", "tokens": [51464, 400, 3802, 82, 293, 13007, 1957, 307, 1596, 11358, 294, 2115, 295, 437, 291, 393, 3565, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1936783077209953, "compression_ratio": 1.8, "no_speech_prob": 0.5154546499252319}, {"id": 182, "seek": 87300, "start": 898.0, "end": 902.0, "text": " You can create images or videos or audio or whatever.", "tokens": [51614, 509, 393, 1884, 5267, 420, 2145, 420, 6278, 420, 2035, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1936783077209953, "compression_ratio": 1.8, "no_speech_prob": 0.5154546499252319}, {"id": 183, "seek": 90200, "start": 902.0, "end": 910.0, "text": " But it also takes a matplotlib figure, and so I'm generating some samples and plotting them with show image", "tokens": [50364, 583, 309, 611, 2516, 257, 3803, 564, 310, 38270, 2573, 11, 293, 370, 286, 478, 17746, 512, 10938, 293, 41178, 552, 365, 855, 3256, 50764], "temperature": 0.0, "avg_logprob": -0.27686643600463867, "compression_ratio": 1.75, "no_speech_prob": 0.05581909418106079}, {"id": 184, "seek": 90200, "start": 910.0, "end": 916.0, "text": " and splitting back that matplotlib figure, which I can then log, and that becomes these pretty pictures", "tokens": [50764, 293, 30348, 646, 300, 3803, 564, 310, 38270, 2573, 11, 597, 286, 393, 550, 3565, 11, 293, 300, 3643, 613, 1238, 5242, 51064], "temperature": 0.0, "avg_logprob": -0.27686643600463867, "compression_ratio": 1.75, "no_speech_prob": 0.05581909418106079}, {"id": 185, "seek": 90200, "start": 916.0, "end": 922.0, "text": " that you can see over time, like every time that log function runs, which is after every epoch,", "tokens": [51064, 300, 291, 393, 536, 670, 565, 11, 411, 633, 565, 300, 3565, 2445, 6676, 11, 597, 307, 934, 633, 30992, 339, 11, 51364], "temperature": 0.0, "avg_logprob": -0.27686643600463867, "compression_ratio": 1.75, "no_speech_prob": 0.05581909418106079}, {"id": 186, "seek": 90200, "start": 922.0, "end": 924.0, "text": " you can go in and see what the images look like.", "tokens": [51364, 291, 393, 352, 294, 293, 536, 437, 264, 5267, 574, 411, 13, 51464], "temperature": 0.0, "avg_logprob": -0.27686643600463867, "compression_ratio": 1.75, "no_speech_prob": 0.05581909418106079}, {"id": 187, "seek": 90200, "start": 924.0, "end": 925.0, "text": " So where did that be?", "tokens": [51464, 407, 689, 630, 300, 312, 30, 51514], "temperature": 0.0, "avg_logprob": -0.27686643600463867, "compression_ratio": 1.75, "no_speech_prob": 0.05581909418106079}, {"id": 188, "seek": 90200, "start": 925.0, "end": 928.0, "text": " Maybe we can make your code even simpler in the future.", "tokens": [51514, 2704, 321, 393, 652, 428, 3089, 754, 18587, 294, 264, 2027, 13, 51664], "temperature": 0.0, "avg_logprob": -0.27686643600463867, "compression_ratio": 1.75, "no_speech_prob": 0.05581909418106079}, {"id": 189, "seek": 92800, "start": 928.0, "end": 935.0, "text": " If we had show images, maybe it could have like an optional return fig parameter that returns the figure,", "tokens": [50364, 759, 321, 632, 855, 5267, 11, 1310, 309, 727, 362, 411, 364, 17312, 2736, 2147, 13075, 300, 11247, 264, 2573, 11, 50714], "temperature": 0.0, "avg_logprob": -0.2404874102904065, "compression_ratio": 1.5811965811965811, "no_speech_prob": 0.3072543740272522}, {"id": 190, "seek": 92800, "start": 935.0, "end": 939.0, "text": " and then we could replace those four lines of code with one, I suspect.", "tokens": [50714, 293, 550, 321, 727, 7406, 729, 1451, 3876, 295, 3089, 365, 472, 11, 286, 9091, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2404874102904065, "compression_ratio": 1.5811965811965811, "no_speech_prob": 0.3072543740272522}, {"id": 191, "seek": 92800, "start": 939.0, "end": 940.0, "text": " Yeah.", "tokens": [50914, 865, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2404874102904065, "compression_ratio": 1.5811965811965811, "no_speech_prob": 0.3072543740272522}, {"id": 192, "seek": 92800, "start": 940.0, "end": 944.0, "text": " Yeah, and I mean, this, I just sort of threw this together.", "tokens": [50964, 865, 11, 293, 286, 914, 11, 341, 11, 286, 445, 1333, 295, 11918, 341, 1214, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2404874102904065, "compression_ratio": 1.5811965811965811, "no_speech_prob": 0.3072543740272522}, {"id": 193, "seek": 92800, "start": 944.0, "end": 945.0, "text": " It's quite early still.", "tokens": [51164, 467, 311, 1596, 2440, 920, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2404874102904065, "compression_ratio": 1.5811965811965811, "no_speech_prob": 0.3072543740272522}, {"id": 194, "seek": 92800, "start": 945.0, "end": 951.0, "text": " You could also, what I've done in the past is usually just create a PIL image where you can, you know,", "tokens": [51214, 509, 727, 611, 11, 437, 286, 600, 1096, 294, 264, 1791, 307, 2673, 445, 1884, 257, 430, 4620, 3256, 689, 291, 393, 11, 291, 458, 11, 51514], "temperature": 0.0, "avg_logprob": -0.2404874102904065, "compression_ratio": 1.5811965811965811, "no_speech_prob": 0.3072543740272522}, {"id": 195, "seek": 95100, "start": 951.0, "end": 958.0, "text": " make a grid or overlay text or whatever else you'd like, and then just log that as 1db.image.", "tokens": [50364, 652, 257, 10748, 420, 31741, 2487, 420, 2035, 1646, 291, 1116, 411, 11, 293, 550, 445, 3565, 300, 382, 502, 67, 65, 13, 26624, 13, 50714], "temperature": 0.0, "avg_logprob": -0.21761911565607245, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.7979274392127991}, {"id": 196, "seek": 95100, "start": 958.0, "end": 965.0, "text": " Otherwise, like apart from that, I'm just passing in this callback as an extra callback to my set of callbacks", "tokens": [50714, 10328, 11, 411, 4936, 490, 300, 11, 286, 478, 445, 8437, 294, 341, 818, 3207, 382, 364, 2857, 818, 3207, 281, 452, 992, 295, 818, 17758, 51064], "temperature": 0.0, "avg_logprob": -0.21761911565607245, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.7979274392127991}, {"id": 197, "seek": 95100, "start": 965.0, "end": 968.0, "text": " for the learner instead of a metric callback.", "tokens": [51064, 337, 264, 33347, 2602, 295, 257, 20678, 818, 3207, 13, 51214], "temperature": 0.0, "avg_logprob": -0.21761911565607245, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.7979274392127991}, {"id": 198, "seek": 95100, "start": 968.0, "end": 972.0, "text": " And so when I call that out fit, I still get my little progress bar.", "tokens": [51214, 400, 370, 562, 286, 818, 300, 484, 3318, 11, 286, 920, 483, 452, 707, 4205, 2159, 13, 51414], "temperature": 0.0, "avg_logprob": -0.21761911565607245, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.7979274392127991}, {"id": 199, "seek": 95100, "start": 972.0, "end": 979.0, "text": " I still get this printed out version because my log function still also prints those metrics just for debugging.", "tokens": [51414, 286, 920, 483, 341, 13567, 484, 3037, 570, 452, 3565, 2445, 920, 611, 22305, 729, 16367, 445, 337, 45592, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21761911565607245, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.7979274392127991}, {"id": 200, "seek": 97900, "start": 980.0, "end": 985.0, "text": " But instead of having to like watch the progress in the notebook, I can set this running, disconnect from the server,", "tokens": [50414, 583, 2602, 295, 1419, 281, 411, 1159, 264, 4205, 294, 264, 21060, 11, 286, 393, 992, 341, 2614, 11, 14299, 490, 264, 7154, 11, 50664], "temperature": 0.0, "avg_logprob": -0.18709385879640658, "compression_ratio": 1.6143790849673203, "no_speech_prob": 0.18473267555236816}, {"id": 201, "seek": 97900, "start": 985.0, "end": 988.0, "text": " go have dinner, and then I can check on my phone or whatever.", "tokens": [50664, 352, 362, 6148, 11, 293, 550, 286, 393, 1520, 322, 452, 2593, 420, 2035, 13, 50814], "temperature": 0.0, "avg_logprob": -0.18709385879640658, "compression_ratio": 1.6143790849673203, "no_speech_prob": 0.18473267555236816}, {"id": 202, "seek": 97900, "start": 988.0, "end": 990.0, "text": " What do the samples look like?", "tokens": [50814, 708, 360, 264, 10938, 574, 411, 30, 50914], "temperature": 0.0, "avg_logprob": -0.18709385879640658, "compression_ratio": 1.6143790849673203, "no_speech_prob": 0.18473267555236816}, {"id": 203, "seek": 97900, "start": 990.0, "end": 991.0, "text": " And okay, cool.", "tokens": [50914, 400, 1392, 11, 1627, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18709385879640658, "compression_ratio": 1.6143790849673203, "no_speech_prob": 0.18473267555236816}, {"id": 204, "seek": 97900, "start": 991.0, "end": 997.0, "text": " They're starting to look like less than random nonsense, but still not necessarily recognizable.", "tokens": [50964, 814, 434, 2891, 281, 574, 411, 1570, 813, 4974, 14925, 11, 457, 920, 406, 4725, 40757, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18709385879640658, "compression_ratio": 1.6143790849673203, "no_speech_prob": 0.18473267555236816}, {"id": 205, "seek": 97900, "start": 997.0, "end": 999.0, "text": " Maybe we need to train for longer.", "tokens": [51264, 2704, 321, 643, 281, 3847, 337, 2854, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18709385879640658, "compression_ratio": 1.6143790849673203, "no_speech_prob": 0.18473267555236816}, {"id": 206, "seek": 97900, "start": 999.0, "end": 1001.0, "text": " That can be the next experiment.", "tokens": [51364, 663, 393, 312, 264, 958, 5120, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18709385879640658, "compression_ratio": 1.6143790849673203, "no_speech_prob": 0.18473267555236816}, {"id": 207, "seek": 97900, "start": 1001.0, "end": 1006.0, "text": " What I should probably do next is think of some extra metrics, but Jeremy is going to talk about that.", "tokens": [51464, 708, 286, 820, 1391, 360, 958, 307, 519, 295, 512, 2857, 16367, 11, 457, 17809, 307, 516, 281, 751, 466, 300, 13, 51714], "temperature": 0.0, "avg_logprob": -0.18709385879640658, "compression_ratio": 1.6143790849673203, "no_speech_prob": 0.18473267555236816}, {"id": 208, "seek": 100600, "start": 1006.0, "end": 1011.0, "text": " So for now, that's pretty much all I had to show is just to say, yeah, it's worth as you move to these longer,", "tokens": [50364, 407, 337, 586, 11, 300, 311, 1238, 709, 439, 286, 632, 281, 855, 307, 445, 281, 584, 11, 1338, 11, 309, 311, 3163, 382, 291, 1286, 281, 613, 2854, 11, 50614], "temperature": 0.0, "avg_logprob": -0.23469036647251673, "compression_ratio": 1.721875, "no_speech_prob": 0.11918394267559052}, {"id": 209, "seek": 100600, "start": 1011.0, "end": 1017.0, "text": " 10 minutes, 1 hour, 10 hours, these experiments, it's worth setting up a bit of infrastructure for yourself", "tokens": [50614, 1266, 2077, 11, 502, 1773, 11, 1266, 2496, 11, 613, 12050, 11, 309, 311, 3163, 3287, 493, 257, 857, 295, 6896, 337, 1803, 50914], "temperature": 0.0, "avg_logprob": -0.23469036647251673, "compression_ratio": 1.721875, "no_speech_prob": 0.11918394267559052}, {"id": 210, "seek": 100600, "start": 1017.0, "end": 1020.0, "text": " so that you know what were the settings I used.", "tokens": [50914, 370, 300, 291, 458, 437, 645, 264, 6257, 286, 1143, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23469036647251673, "compression_ratio": 1.721875, "no_speech_prob": 0.11918394267559052}, {"id": 211, "seek": 100600, "start": 1020.0, "end": 1023.0, "text": " Maybe you're saving the model so you have the artifact as a result.", "tokens": [51064, 2704, 291, 434, 6816, 264, 2316, 370, 291, 362, 264, 34806, 382, 257, 1874, 13, 51214], "temperature": 0.0, "avg_logprob": -0.23469036647251673, "compression_ratio": 1.721875, "no_speech_prob": 0.11918394267559052}, {"id": 212, "seek": 100600, "start": 1023.0, "end": 1027.0, "text": " And yeah, I like this Wix devices approach, but there's lots of others.", "tokens": [51214, 400, 1338, 11, 286, 411, 341, 343, 970, 5759, 3109, 11, 457, 456, 311, 3195, 295, 2357, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23469036647251673, "compression_ratio": 1.721875, "no_speech_prob": 0.11918394267559052}, {"id": 213, "seek": 100600, "start": 1027.0, "end": 1034.0, "text": " The main thing is that you're doing something to track these experiments beyond just creating 20 different versions of your notebook.", "tokens": [51414, 440, 2135, 551, 307, 300, 291, 434, 884, 746, 281, 2837, 613, 12050, 4399, 445, 4084, 945, 819, 9606, 295, 428, 21060, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23469036647251673, "compression_ratio": 1.721875, "no_speech_prob": 0.11918394267559052}, {"id": 214, "seek": 100600, "start": 1034.0, "end": 1035.0, "text": " I love it.", "tokens": [51764, 286, 959, 309, 13, 51814], "temperature": 0.0, "avg_logprob": -0.23469036647251673, "compression_ratio": 1.721875, "no_speech_prob": 0.11918394267559052}, {"id": 215, "seek": 103500, "start": 1035.0, "end": 1045.0, "text": " One thing I was going to note that, I don't know if many people know, but weights and biases can also save the exact code that you used to run for that run.", "tokens": [50364, 1485, 551, 286, 390, 516, 281, 3637, 300, 11, 286, 500, 380, 458, 498, 867, 561, 458, 11, 457, 17443, 293, 32152, 393, 611, 3155, 264, 1900, 3089, 300, 291, 1143, 281, 1190, 337, 300, 1190, 13, 50864], "temperature": 0.0, "avg_logprob": -0.227094973050631, "compression_ratio": 1.8269896193771626, "no_speech_prob": 0.018544599413871765}, {"id": 216, "seek": 103500, "start": 1045.0, "end": 1051.0, "text": " So if you make any changes to your code and then you don't know which version of your code you used for this particular experiment,", "tokens": [50864, 407, 498, 291, 652, 604, 2962, 281, 428, 3089, 293, 550, 291, 500, 380, 458, 597, 3037, 295, 428, 3089, 291, 1143, 337, 341, 1729, 5120, 11, 51164], "temperature": 0.0, "avg_logprob": -0.227094973050631, "compression_ratio": 1.8269896193771626, "no_speech_prob": 0.018544599413871765}, {"id": 217, "seek": 103500, "start": 1051.0, "end": 1054.0, "text": " so then you can figure out exactly what code you used.", "tokens": [51164, 370, 550, 291, 393, 2573, 484, 2293, 437, 3089, 291, 1143, 13, 51314], "temperature": 0.0, "avg_logprob": -0.227094973050631, "compression_ratio": 1.8269896193771626, "no_speech_prob": 0.018544599413871765}, {"id": 218, "seek": 103500, "start": 1054.0, "end": 1056.0, "text": " So it's all completely reproducible.", "tokens": [51314, 407, 309, 311, 439, 2584, 11408, 32128, 13, 51414], "temperature": 0.0, "avg_logprob": -0.227094973050631, "compression_ratio": 1.8269896193771626, "no_speech_prob": 0.018544599413871765}, {"id": 219, "seek": 103500, "start": 1056.0, "end": 1060.0, "text": " And so I love weights and biases, all these different features it has.", "tokens": [51414, 400, 370, 286, 959, 17443, 293, 32152, 11, 439, 613, 819, 4122, 309, 575, 13, 51614], "temperature": 0.0, "avg_logprob": -0.227094973050631, "compression_ratio": 1.8269896193771626, "no_speech_prob": 0.018544599413871765}, {"id": 220, "seek": 103500, "start": 1060.0, "end": 1064.0, "text": " And I use weights and biases all the time for my own research, almost daily.", "tokens": [51614, 400, 286, 764, 17443, 293, 32152, 439, 264, 565, 337, 452, 1065, 2132, 11, 1920, 5212, 13, 51814], "temperature": 0.0, "avg_logprob": -0.227094973050631, "compression_ratio": 1.8269896193771626, "no_speech_prob": 0.018544599413871765}, {"id": 221, "seek": 106400, "start": 1064.0, "end": 1068.0, "text": " I had to put it on just last night and check on it today morning.", "tokens": [50364, 286, 632, 281, 829, 309, 322, 445, 1036, 1818, 293, 1520, 322, 309, 965, 2446, 13, 50564], "temperature": 0.0, "avg_logprob": -0.22145430466224408, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.30390381813049316}, {"id": 222, "seek": 106400, "start": 1068.0, "end": 1071.0, "text": " So I use it all the time for my own research.", "tokens": [50564, 407, 286, 764, 309, 439, 264, 565, 337, 452, 1065, 2132, 13, 50714], "temperature": 0.0, "avg_logprob": -0.22145430466224408, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.30390381813049316}, {"id": 223, "seek": 106400, "start": 1071.0, "end": 1076.0, "text": " And yeah, I use it especially to just know like, oh, this run had this particular config.", "tokens": [50714, 400, 1338, 11, 286, 764, 309, 2318, 281, 445, 458, 411, 11, 1954, 11, 341, 1190, 632, 341, 1729, 6662, 13, 50964], "temperature": 0.0, "avg_logprob": -0.22145430466224408, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.30390381813049316}, {"id": 224, "seek": 106400, "start": 1076.0, "end": 1079.0, "text": " And then the models go straight into weights and biases.", "tokens": [50964, 400, 550, 264, 5245, 352, 2997, 666, 17443, 293, 32152, 13, 51114], "temperature": 0.0, "avg_logprob": -0.22145430466224408, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.30390381813049316}, {"id": 225, "seek": 106400, "start": 1079.0, "end": 1084.0, "text": " And then if I want to run a model on the test set, I literally actually take it off of weights and biases,", "tokens": [51114, 400, 550, 498, 286, 528, 281, 1190, 257, 2316, 322, 264, 1500, 992, 11, 286, 3736, 767, 747, 309, 766, 295, 17443, 293, 32152, 11, 51364], "temperature": 0.0, "avg_logprob": -0.22145430466224408, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.30390381813049316}, {"id": 226, "seek": 106400, "start": 1084.0, "end": 1087.0, "text": " like download it from weights and biases and run it on the test set.", "tokens": [51364, 411, 5484, 309, 490, 17443, 293, 32152, 293, 1190, 309, 322, 264, 1500, 992, 13, 51514], "temperature": 0.0, "avg_logprob": -0.22145430466224408, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.30390381813049316}, {"id": 227, "seek": 106400, "start": 1087.0, "end": 1088.0, "text": " So I use it all the time.", "tokens": [51514, 407, 286, 764, 309, 439, 264, 565, 13, 51564], "temperature": 0.0, "avg_logprob": -0.22145430466224408, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.30390381813049316}, {"id": 228, "seek": 106400, "start": 1088.0, "end": 1093.0, "text": " And also just having the ability to have everything reproducible and know exactly what you were doing.", "tokens": [51564, 400, 611, 445, 1419, 264, 3485, 281, 362, 1203, 11408, 32128, 293, 458, 2293, 437, 291, 645, 884, 13, 51814], "temperature": 0.0, "avg_logprob": -0.22145430466224408, "compression_ratio": 1.9084745762711866, "no_speech_prob": 0.30390381813049316}, {"id": 229, "seek": 109300, "start": 1093.0, "end": 1099.0, "text": " It's very convenient instead of having to manually track it in some sort of like, I guess, a big Excel sheet", "tokens": [50364, 467, 311, 588, 10851, 2602, 295, 1419, 281, 16945, 2837, 309, 294, 512, 1333, 295, 411, 11, 286, 2041, 11, 257, 955, 19060, 8193, 50664], "temperature": 0.0, "avg_logprob": -0.23536789771353844, "compression_ratio": 1.588, "no_speech_prob": 0.25379079580307007}, {"id": 230, "seek": 109300, "start": 1099.0, "end": 1101.0, "text": " or some sort of journal or something like that.", "tokens": [50664, 420, 512, 1333, 295, 6708, 420, 746, 411, 300, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23536789771353844, "compression_ratio": 1.588, "no_speech_prob": 0.25379079580307007}, {"id": 231, "seek": 109300, "start": 1101.0, "end": 1105.0, "text": " Sometimes this is a lot more convenient, I feel.", "tokens": [50764, 4803, 341, 307, 257, 688, 544, 10851, 11, 286, 841, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23536789771353844, "compression_ratio": 1.588, "no_speech_prob": 0.25379079580307007}, {"id": 232, "seek": 109300, "start": 1105.0, "end": 1106.0, "text": " So yeah.", "tokens": [50964, 407, 1338, 13, 51014], "temperature": 0.0, "avg_logprob": -0.23536789771353844, "compression_ratio": 1.588, "no_speech_prob": 0.25379079580307007}, {"id": 233, "seek": 109300, "start": 1106.0, "end": 1113.0, "text": " Lest we get into too much filling from weights and biases, I'm going to put a slightly alternative point of view,", "tokens": [51014, 441, 377, 321, 483, 666, 886, 709, 10623, 490, 17443, 293, 32152, 11, 286, 478, 516, 281, 829, 257, 4748, 8535, 935, 295, 1910, 11, 51364], "temperature": 0.0, "avg_logprob": -0.23536789771353844, "compression_ratio": 1.588, "no_speech_prob": 0.25379079580307007}, {"id": 234, "seek": 109300, "start": 1113.0, "end": 1121.0, "text": " which is I don't use it or any experiment tracking framework myself.", "tokens": [51364, 597, 307, 286, 500, 380, 764, 309, 420, 604, 5120, 11603, 8388, 2059, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23536789771353844, "compression_ratio": 1.588, "no_speech_prob": 0.25379079580307007}, {"id": 235, "seek": 112100, "start": 1121.0, "end": 1130.0, "text": " Not to say maybe I could get some benefits by doing so, but I fairly intentionally don't because I don't want to make it easy", "tokens": [50364, 1726, 281, 584, 1310, 286, 727, 483, 512, 5311, 538, 884, 370, 11, 457, 286, 6457, 22062, 500, 380, 570, 286, 500, 380, 528, 281, 652, 309, 1858, 50814], "temperature": 0.0, "avg_logprob": -0.22837433257660308, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.01281712856143713}, {"id": 236, "seek": 112100, "start": 1130.0, "end": 1139.0, "text": " for myself to try a thousand different hyperparameters or do kind of like ill-directed, you know, sampling of things.", "tokens": [50814, 337, 2059, 281, 853, 257, 4714, 819, 9848, 2181, 335, 6202, 420, 360, 733, 295, 411, 3171, 12, 44868, 292, 11, 291, 458, 11, 21179, 295, 721, 13, 51264], "temperature": 0.0, "avg_logprob": -0.22837433257660308, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.01281712856143713}, {"id": 237, "seek": 112100, "start": 1139.0, "end": 1146.0, "text": " I like to be very, like, directed, you know.", "tokens": [51264, 286, 411, 281, 312, 588, 11, 411, 11, 12898, 11, 291, 458, 13, 51614], "temperature": 0.0, "avg_logprob": -0.22837433257660308, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.01281712856143713}, {"id": 238, "seek": 114600, "start": 1146.0, "end": 1152.0, "text": " And so that's kind of the workflow I'm looking for is one that allows that to happen, right?", "tokens": [50364, 400, 370, 300, 311, 733, 295, 264, 20993, 286, 478, 1237, 337, 307, 472, 300, 4045, 300, 281, 1051, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.2389519771682882, "compression_ratio": 1.5992217898832686, "no_speech_prob": 0.337870717048645}, {"id": 239, "seek": 114600, "start": 1152.0, "end": 1157.0, "text": " Constantly going back and refactoring and thinking, what did I learn and how do I change things from here?", "tokens": [50664, 8574, 3627, 516, 646, 293, 1895, 578, 3662, 293, 1953, 11, 437, 630, 286, 1466, 293, 577, 360, 286, 1319, 721, 490, 510, 30, 50914], "temperature": 0.0, "avg_logprob": -0.2389519771682882, "compression_ratio": 1.5992217898832686, "no_speech_prob": 0.337870717048645}, {"id": 240, "seek": 114600, "start": 1157.0, "end": 1163.0, "text": " And never kind of doing like 17 learning rates and six architectures and whatever.", "tokens": [50914, 400, 1128, 733, 295, 884, 411, 3282, 2539, 6846, 293, 2309, 6331, 1303, 293, 2035, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2389519771682882, "compression_ratio": 1.5992217898832686, "no_speech_prob": 0.337870717048645}, {"id": 241, "seek": 114600, "start": 1163.0, "end": 1168.0, "text": " Now, obviously that's not something that Jono is doing at the moment.", "tokens": [51214, 823, 11, 2745, 300, 311, 406, 746, 300, 7745, 78, 307, 884, 412, 264, 1623, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2389519771682882, "compression_ratio": 1.5992217898832686, "no_speech_prob": 0.337870717048645}, {"id": 242, "seek": 114600, "start": 1168.0, "end": 1172.0, "text": " It would be so easy for him to, you know, if he wanted to.", "tokens": [51464, 467, 576, 312, 370, 1858, 337, 796, 281, 11, 291, 458, 11, 498, 415, 1415, 281, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2389519771682882, "compression_ratio": 1.5992217898832686, "no_speech_prob": 0.337870717048645}, {"id": 243, "seek": 117200, "start": 1172.0, "end": 1177.0, "text": " I can make a script that just does a hundred runs with different models and different things.", "tokens": [50364, 286, 393, 652, 257, 5755, 300, 445, 775, 257, 3262, 6676, 365, 819, 5245, 293, 819, 721, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2123721586454899, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.2876352369785309}, {"id": 244, "seek": 117200, "start": 1177.0, "end": 1182.0, "text": " And then I can look at my biases and say filter by the best loss, which is very tempting.", "tokens": [50614, 400, 550, 286, 393, 574, 412, 452, 32152, 293, 584, 6608, 538, 264, 1151, 4470, 11, 597, 307, 588, 37900, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2123721586454899, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.2876352369785309}, {"id": 245, "seek": 117200, "start": 1182.0, "end": 1187.0, "text": " So I would say to people, like, yeah, definitely be aware that these tools exist.", "tokens": [50864, 407, 286, 576, 584, 281, 561, 11, 411, 11, 1338, 11, 2138, 312, 3650, 300, 613, 3873, 2514, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2123721586454899, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.2876352369785309}, {"id": 246, "seek": 117200, "start": 1187.0, "end": 1195.0, "text": " And I definitely agree that as we do this, which is early 2023, weights and biases is by far the best one I've seen.", "tokens": [51114, 400, 286, 2138, 3986, 300, 382, 321, 360, 341, 11, 597, 307, 2440, 44377, 11, 17443, 293, 32152, 307, 538, 1400, 264, 1151, 472, 286, 600, 1612, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2123721586454899, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.2876352369785309}, {"id": 247, "seek": 117200, "start": 1195.0, "end": 1198.0, "text": " It has by far the best integration with fast AI.", "tokens": [51514, 467, 575, 538, 1400, 264, 1151, 10980, 365, 2370, 7318, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2123721586454899, "compression_ratio": 1.6968503937007875, "no_speech_prob": 0.2876352369785309}, {"id": 248, "seek": 119800, "start": 1198.0, "end": 1204.0, "text": " And as of today, if Jono's pushed yet, it has by far the best integration with mini AI.", "tokens": [50364, 400, 382, 295, 965, 11, 498, 508, 8957, 311, 9152, 1939, 11, 309, 575, 538, 1400, 264, 1151, 10980, 365, 8382, 7318, 13, 50664], "temperature": 0.0, "avg_logprob": -0.25891861915588377, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005384325049817562}, {"id": 249, "seek": 119800, "start": 1204.0, "end": 1210.0, "text": " I think also fast AI is the best library for using with weights and biases.", "tokens": [50664, 286, 519, 611, 2370, 7318, 307, 264, 1151, 6405, 337, 1228, 365, 17443, 293, 32152, 13, 50964], "temperature": 0.0, "avg_logprob": -0.25891861915588377, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005384325049817562}, {"id": 250, "seek": 119800, "start": 1210.0, "end": 1212.0, "text": " It works in both ways.", "tokens": [50964, 467, 1985, 294, 1293, 2098, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25891861915588377, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005384325049817562}, {"id": 251, "seek": 119800, "start": 1212.0, "end": 1216.0, "text": " So, yeah, no, it's there.", "tokens": [51064, 407, 11, 1338, 11, 572, 11, 309, 311, 456, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25891861915588377, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005384325049817562}, {"id": 252, "seek": 119800, "start": 1216.0, "end": 1224.0, "text": " Consider using it, but also consider not going crazy on experiments.", "tokens": [51264, 17416, 1228, 309, 11, 457, 611, 1949, 406, 516, 3219, 322, 12050, 13, 51664], "temperature": 0.0, "avg_logprob": -0.25891861915588377, "compression_ratio": 1.4867724867724867, "no_speech_prob": 0.005384325049817562}, {"id": 253, "seek": 122400, "start": 1224.0, "end": 1229.0, "text": " Because, you know, I think experiments have their place, clearly.", "tokens": [50364, 1436, 11, 291, 458, 11, 286, 519, 12050, 362, 641, 1081, 11, 4448, 13, 50614], "temperature": 0.0, "avg_logprob": -0.25544480808445663, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.05107178911566734}, {"id": 254, "seek": 122400, "start": 1229.0, "end": 1240.0, "text": " But also carefully thought out hypotheses, testing them, changing your code is overall the approach that I think is best.", "tokens": [50614, 583, 611, 7500, 1194, 484, 49969, 11, 4997, 552, 11, 4473, 428, 3089, 307, 4787, 264, 3109, 300, 286, 519, 307, 1151, 13, 51164], "temperature": 0.0, "avg_logprob": -0.25544480808445663, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.05107178911566734}, {"id": 255, "seek": 122400, "start": 1240.0, "end": 1244.0, "text": " Well, thank you, Jono.", "tokens": [51164, 1042, 11, 1309, 291, 11, 7745, 78, 13, 51364], "temperature": 0.0, "avg_logprob": -0.25544480808445663, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.05107178911566734}, {"id": 256, "seek": 122400, "start": 1244.0, "end": 1246.0, "text": " I think that's awesome.", "tokens": [51364, 286, 519, 300, 311, 3476, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25544480808445663, "compression_ratio": 1.4444444444444444, "no_speech_prob": 0.05107178911566734}, {"id": 257, "seek": 124600, "start": 1246.0, "end": 1251.0, "text": " I got some fun stuff to share as well.", "tokens": [50364, 286, 658, 512, 1019, 1507, 281, 2073, 382, 731, 13, 50614], "temperature": 0.0, "avg_logprob": -0.22558231595196301, "compression_ratio": 1.6645569620253164, "no_speech_prob": 0.09129812568426132}, {"id": 258, "seek": 124600, "start": 1251.0, "end": 1254.0, "text": " Or at least I think it's fun.", "tokens": [50614, 1610, 412, 1935, 286, 519, 309, 311, 1019, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22558231595196301, "compression_ratio": 1.6645569620253164, "no_speech_prob": 0.09129812568426132}, {"id": 259, "seek": 124600, "start": 1254.0, "end": 1267.0, "text": " And what I wanted to share is like, well, the first of all, I should say, we had said, we all had said that we were going to look at units this week.", "tokens": [50764, 400, 437, 286, 1415, 281, 2073, 307, 411, 11, 731, 11, 264, 700, 295, 439, 11, 286, 820, 584, 11, 321, 632, 848, 11, 321, 439, 632, 848, 300, 321, 645, 516, 281, 574, 412, 6815, 341, 1243, 13, 51414], "temperature": 0.0, "avg_logprob": -0.22558231595196301, "compression_ratio": 1.6645569620253164, "no_speech_prob": 0.09129812568426132}, {"id": 260, "seek": 124600, "start": 1267.0, "end": 1270.0, "text": " We are not going to look at units this week.", "tokens": [51414, 492, 366, 406, 516, 281, 574, 412, 6815, 341, 1243, 13, 51564], "temperature": 0.0, "avg_logprob": -0.22558231595196301, "compression_ratio": 1.6645569620253164, "no_speech_prob": 0.09129812568426132}, {"id": 261, "seek": 127000, "start": 1271.0, "end": 1279.0, "text": " But we have a good reason, which is that we had said we're going to go from foundations to stable diffusion.", "tokens": [50414, 583, 321, 362, 257, 665, 1778, 11, 597, 307, 300, 321, 632, 848, 321, 434, 516, 281, 352, 490, 22467, 281, 8351, 25242, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19904437010315643, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.6145978569984436}, {"id": 262, "seek": 127000, "start": 1279.0, "end": 1283.0, "text": " Well, that was also a lie, because we're actually going beyond stable diffusion.", "tokens": [50814, 1042, 11, 300, 390, 611, 257, 4544, 11, 570, 321, 434, 767, 516, 4399, 8351, 25242, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19904437010315643, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.6145978569984436}, {"id": 263, "seek": 127000, "start": 1283.0, "end": 1289.0, "text": " And so we're actually going to start showing today some new research directions.", "tokens": [51014, 400, 370, 321, 434, 767, 516, 281, 722, 4099, 965, 512, 777, 2132, 11095, 13, 51314], "temperature": 0.0, "avg_logprob": -0.19904437010315643, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.6145978569984436}, {"id": 264, "seek": 127000, "start": 1289.0, "end": 1294.0, "text": " I'm going to describe the process that I'm using at the moment to investigate some new research directions.", "tokens": [51314, 286, 478, 516, 281, 6786, 264, 1399, 300, 286, 478, 1228, 412, 264, 1623, 281, 15013, 512, 777, 2132, 11095, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19904437010315643, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.6145978569984436}, {"id": 265, "seek": 129400, "start": 1294.0, "end": 1303.0, "text": " And we're also going to be looking at some other people's research directions that have gone beyond stable diffusion over the past few months.", "tokens": [50364, 400, 321, 434, 611, 516, 281, 312, 1237, 412, 512, 661, 561, 311, 2132, 11095, 300, 362, 2780, 4399, 8351, 25242, 670, 264, 1791, 1326, 2493, 13, 50814], "temperature": 0.0, "avg_logprob": -0.18471518016996838, "compression_ratio": 1.4382022471910112, "no_speech_prob": 0.13471783697605133}, {"id": 266, "seek": 129400, "start": 1303.0, "end": 1307.0, "text": " So we will get to units.", "tokens": [50814, 407, 321, 486, 483, 281, 6815, 13, 51014], "temperature": 0.0, "avg_logprob": -0.18471518016996838, "compression_ratio": 1.4382022471910112, "no_speech_prob": 0.13471783697605133}, {"id": 267, "seek": 129400, "start": 1307.0, "end": 1315.0, "text": " But we haven't quite finished, you know, as it turns out, the training and sampling yet.", "tokens": [51014, 583, 321, 2378, 380, 1596, 4335, 11, 291, 458, 11, 382, 309, 4523, 484, 11, 264, 3097, 293, 21179, 1939, 13, 51414], "temperature": 0.0, "avg_logprob": -0.18471518016996838, "compression_ratio": 1.4382022471910112, "no_speech_prob": 0.13471783697605133}, {"id": 268, "seek": 131500, "start": 1316.0, "end": 1333.0, "text": " Now, one challenge that I was having, as I started experimenting with new things, was started getting to the point where actually the generated images looked pretty good.", "tokens": [50414, 823, 11, 472, 3430, 300, 286, 390, 1419, 11, 382, 286, 1409, 29070, 365, 777, 721, 11, 390, 1409, 1242, 281, 264, 935, 689, 767, 264, 10833, 5267, 2956, 1238, 665, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2554982768164741, "compression_ratio": 1.3709677419354838, "no_speech_prob": 0.03731761500239372}, {"id": 269, "seek": 133300, "start": 1333.0, "end": 1347.0, "text": " And it felt like, you know, almost like being a parent, you know, each time a new set of images would come out, I would want to convince myself that these were the most beautiful.", "tokens": [50364, 400, 309, 2762, 411, 11, 291, 458, 11, 1920, 411, 885, 257, 2596, 11, 291, 458, 11, 1184, 565, 257, 777, 992, 295, 5267, 576, 808, 484, 11, 286, 576, 528, 281, 13447, 2059, 300, 613, 645, 264, 881, 2238, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20639811391415802, "compression_ratio": 1.7156398104265402, "no_speech_prob": 0.0053001102060079575}, {"id": 270, "seek": 133300, "start": 1347.0, "end": 1357.0, "text": " And so I, yeah, and like, when they're crap, it's obvious they're crap, you know, but when they're starting to look pretty good, it's very easy to convince yourself you're improving.", "tokens": [51064, 400, 370, 286, 11, 1338, 11, 293, 411, 11, 562, 436, 434, 12426, 11, 309, 311, 6322, 436, 434, 12426, 11, 291, 458, 11, 457, 562, 436, 434, 2891, 281, 574, 1238, 665, 11, 309, 311, 588, 1858, 281, 13447, 1803, 291, 434, 11470, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20639811391415802, "compression_ratio": 1.7156398104265402, "no_speech_prob": 0.0053001102060079575}, {"id": 271, "seek": 135700, "start": 1357.0, "end": 1364.0, "text": " So I wanted to have a metric which could tell me how good they were.", "tokens": [50364, 407, 286, 1415, 281, 362, 257, 20678, 597, 727, 980, 385, 577, 665, 436, 645, 13, 50714], "temperature": 0.0, "avg_logprob": -0.18906469123308048, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.08149876445531845}, {"id": 272, "seek": 135700, "start": 1364.0, "end": 1368.0, "text": " Now, unfortunately, there is no such metric.", "tokens": [50714, 823, 11, 7015, 11, 456, 307, 572, 1270, 20678, 13, 50914], "temperature": 0.0, "avg_logprob": -0.18906469123308048, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.08149876445531845}, {"id": 273, "seek": 135700, "start": 1368.0, "end": 1377.0, "text": " There's no metric that actually says, do these images, would these images look to a human being like pictures of clothes?", "tokens": [50914, 821, 311, 572, 20678, 300, 767, 1619, 11, 360, 613, 5267, 11, 576, 613, 5267, 574, 281, 257, 1952, 885, 411, 5242, 295, 5534, 30, 51364], "temperature": 0.0, "avg_logprob": -0.18906469123308048, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.08149876445531845}, {"id": 274, "seek": 135700, "start": 1377.0, "end": 1380.0, "text": " Because only talking to a person can do that.", "tokens": [51364, 1436, 787, 1417, 281, 257, 954, 393, 360, 300, 13, 51514], "temperature": 0.0, "avg_logprob": -0.18906469123308048, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.08149876445531845}, {"id": 275, "seek": 135700, "start": 1380.0, "end": 1384.0, "text": " But there are some metrics which give you an approximation of that.", "tokens": [51514, 583, 456, 366, 512, 16367, 597, 976, 291, 364, 28023, 295, 300, 13, 51714], "temperature": 0.0, "avg_logprob": -0.18906469123308048, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.08149876445531845}, {"id": 276, "seek": 138400, "start": 1384.0, "end": 1397.0, "text": " And as it turns out, these metrics are not actually, they're not actually a replacement for human beings looking at things.", "tokens": [50364, 400, 382, 309, 4523, 484, 11, 613, 16367, 366, 406, 767, 11, 436, 434, 406, 767, 257, 14419, 337, 1952, 8958, 1237, 412, 721, 13, 51014], "temperature": 0.0, "avg_logprob": -0.22370206093301578, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.25375092029571533}, {"id": 277, "seek": 138400, "start": 1397.0, "end": 1400.0, "text": " But they're a useful addition.", "tokens": [51014, 583, 436, 434, 257, 4420, 4500, 13, 51164], "temperature": 0.0, "avg_logprob": -0.22370206093301578, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.25375092029571533}, {"id": 278, "seek": 138400, "start": 1400.0, "end": 1403.0, "text": " So, and I certainly found them useful.", "tokens": [51164, 407, 11, 293, 286, 3297, 1352, 552, 4420, 13, 51314], "temperature": 0.0, "avg_logprob": -0.22370206093301578, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.25375092029571533}, {"id": 279, "seek": 140300, "start": 1403.0, "end": 1409.0, "text": " So I'm going to show you the two most common, well, there's really the one most common metric, which is called FID.", "tokens": [50364, 407, 286, 478, 516, 281, 855, 291, 264, 732, 881, 2689, 11, 731, 11, 456, 311, 534, 264, 472, 881, 2689, 20678, 11, 597, 307, 1219, 479, 2777, 13, 50664], "temperature": 0.0, "avg_logprob": -0.27033442157810017, "compression_ratio": 1.489051094890511, "no_speech_prob": 0.22788822650909424}, {"id": 280, "seek": 140300, "start": 1409.0, "end": 1412.0, "text": " And I'm going to show another one called KID.", "tokens": [50664, 400, 286, 478, 516, 281, 855, 1071, 472, 1219, 591, 2777, 13, 50814], "temperature": 0.0, "avg_logprob": -0.27033442157810017, "compression_ratio": 1.489051094890511, "no_speech_prob": 0.22788822650909424}, {"id": 281, "seek": 140300, "start": 1412.0, "end": 1422.0, "text": " So let me describe and show how they work.", "tokens": [50814, 407, 718, 385, 6786, 293, 855, 577, 436, 589, 13, 51314], "temperature": 0.0, "avg_logprob": -0.27033442157810017, "compression_ratio": 1.489051094890511, "no_speech_prob": 0.22788822650909424}, {"id": 282, "seek": 142200, "start": 1422.0, "end": 1429.0, "text": " And I'm going to demonstrate them using the model we trained in the last lesson.", "tokens": [50364, 400, 286, 478, 516, 281, 11698, 552, 1228, 264, 2316, 321, 8895, 294, 264, 1036, 6898, 13, 50714], "temperature": 0.0, "avg_logprob": -0.26050603957403273, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.009705089032649994}, {"id": 283, "seek": 142200, "start": 1429.0, "end": 1432.0, "text": " Which is in DDPM2.", "tokens": [50714, 3013, 307, 294, 413, 11373, 44, 17, 13, 50864], "temperature": 0.0, "avg_logprob": -0.26050603957403273, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.009705089032649994}, {"id": 284, "seek": 142200, "start": 1432.0, "end": 1437.0, "text": " And you might remember, we trained one with mixed precision.", "tokens": [50864, 400, 291, 1062, 1604, 11, 321, 8895, 472, 365, 7467, 18356, 13, 51114], "temperature": 0.0, "avg_logprob": -0.26050603957403273, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.009705089032649994}, {"id": 285, "seek": 142200, "start": 1437.0, "end": 1443.0, "text": " And we saved it as fashion DDPM MP for mixed precision.", "tokens": [51114, 400, 321, 6624, 309, 382, 6700, 413, 11373, 44, 14146, 337, 7467, 18356, 13, 51414], "temperature": 0.0, "avg_logprob": -0.26050603957403273, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.009705089032649994}, {"id": 286, "seek": 142200, "start": 1443.0, "end": 1448.0, "text": " Okay, so this is all the usual imports and stuff.", "tokens": [51414, 1033, 11, 370, 341, 307, 439, 264, 7713, 41596, 293, 1507, 13, 51664], "temperature": 0.0, "avg_logprob": -0.26050603957403273, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.009705089032649994}, {"id": 287, "seek": 142200, "start": 1448.0, "end": 1451.0, "text": " This is all the usual stuff.", "tokens": [51664, 639, 307, 439, 264, 7713, 1507, 13, 51814], "temperature": 0.0, "avg_logprob": -0.26050603957403273, "compression_ratio": 1.5691489361702127, "no_speech_prob": 0.009705089032649994}, {"id": 288, "seek": 145100, "start": 1451.0, "end": 1459.0, "text": " But there's a slight difference this time, which is that we're going to try to get the FID for a model we've already trained.", "tokens": [50364, 583, 456, 311, 257, 4036, 2649, 341, 565, 11, 597, 307, 300, 321, 434, 516, 281, 853, 281, 483, 264, 479, 2777, 337, 257, 2316, 321, 600, 1217, 8895, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21256416563003783, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006263185641728342}, {"id": 289, "seek": 145100, "start": 1459.0, "end": 1467.0, "text": " So basically to get the model we've already trained, to get its FID, we can just torch.load it.", "tokens": [50764, 407, 1936, 281, 483, 264, 2316, 321, 600, 1217, 8895, 11, 281, 483, 1080, 479, 2777, 11, 321, 393, 445, 27822, 13, 2907, 309, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21256416563003783, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006263185641728342}, {"id": 290, "seek": 145100, "start": 1467.0, "end": 1470.0, "text": " And then .cuda to pop it on the GPU.", "tokens": [51164, 400, 550, 2411, 66, 11152, 281, 1665, 309, 322, 264, 18407, 13, 51314], "temperature": 0.0, "avg_logprob": -0.21256416563003783, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006263185641728342}, {"id": 291, "seek": 145100, "start": 1470.0, "end": 1474.0, "text": " So I'm going to call that the S model, which is the model for samples, the samples model.", "tokens": [51314, 407, 286, 478, 516, 281, 818, 300, 264, 318, 2316, 11, 597, 307, 264, 2316, 337, 10938, 11, 264, 10938, 2316, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21256416563003783, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006263185641728342}, {"id": 292, "seek": 145100, "start": 1474.0, "end": 1478.0, "text": " And this is just a copied and pasted DDPM from the last time.", "tokens": [51514, 400, 341, 307, 445, 257, 25365, 293, 1791, 292, 413, 11373, 44, 490, 264, 1036, 565, 13, 51714], "temperature": 0.0, "avg_logprob": -0.21256416563003783, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006263185641728342}, {"id": 293, "seek": 145100, "start": 1478.0, "end": 1480.0, "text": " So that's for sampling.", "tokens": [51714, 407, 300, 311, 337, 21179, 13, 51814], "temperature": 0.0, "avg_logprob": -0.21256416563003783, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.0006263185641728342}, {"id": 294, "seek": 148000, "start": 1480.0, "end": 1483.0, "text": " So we're going to do sampling from that model.", "tokens": [50364, 407, 321, 434, 516, 281, 360, 21179, 490, 300, 2316, 13, 50514], "temperature": 0.0, "avg_logprob": -0.21860627430241283, "compression_ratio": 1.7590361445783131, "no_speech_prob": 9.027758642332628e-05}, {"id": 295, "seek": 148000, "start": 1483.0, "end": 1492.0, "text": " And so once we've sampled from the model, we're then going to try and calculate this score called the FID.", "tokens": [50514, 400, 370, 1564, 321, 600, 3247, 15551, 490, 264, 2316, 11, 321, 434, 550, 516, 281, 853, 293, 8873, 341, 6175, 1219, 264, 479, 2777, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21860627430241283, "compression_ratio": 1.7590361445783131, "no_speech_prob": 9.027758642332628e-05}, {"id": 296, "seek": 148000, "start": 1492.0, "end": 1499.0, "text": " Now what the FID is going to do is it's not going to say how good are these images.", "tokens": [50964, 823, 437, 264, 479, 2777, 307, 516, 281, 360, 307, 309, 311, 406, 516, 281, 584, 577, 665, 366, 613, 5267, 13, 51314], "temperature": 0.0, "avg_logprob": -0.21860627430241283, "compression_ratio": 1.7590361445783131, "no_speech_prob": 9.027758642332628e-05}, {"id": 297, "seek": 148000, "start": 1499.0, "end": 1507.0, "text": " It's going to say how similar are they to real images.", "tokens": [51314, 467, 311, 516, 281, 584, 577, 2531, 366, 436, 281, 957, 5267, 13, 51714], "temperature": 0.0, "avg_logprob": -0.21860627430241283, "compression_ratio": 1.7590361445783131, "no_speech_prob": 9.027758642332628e-05}, {"id": 298, "seek": 150700, "start": 1507.0, "end": 1518.0, "text": " And so the way we're going to do that is we're going to actually look specifically at for the images that we generated in these samples.", "tokens": [50364, 400, 370, 264, 636, 321, 434, 516, 281, 360, 300, 307, 321, 434, 516, 281, 767, 574, 4682, 412, 337, 264, 5267, 300, 321, 10833, 294, 613, 10938, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1965100194366885, "compression_ratio": 1.844155844155844, "no_speech_prob": 0.0003799747792072594}, {"id": 299, "seek": 150700, "start": 1518.0, "end": 1524.0, "text": " We're going to look at some statistics of some of the activations.", "tokens": [50914, 492, 434, 516, 281, 574, 412, 512, 12523, 295, 512, 295, 264, 2430, 763, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1965100194366885, "compression_ratio": 1.844155844155844, "no_speech_prob": 0.0003799747792072594}, {"id": 300, "seek": 150700, "start": 1524.0, "end": 1530.0, "text": " So what we're going to do, we've generated these, we've generated these samples.", "tokens": [51214, 407, 437, 321, 434, 516, 281, 360, 11, 321, 600, 10833, 613, 11, 321, 600, 10833, 613, 10938, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1965100194366885, "compression_ratio": 1.844155844155844, "no_speech_prob": 0.0003799747792072594}, {"id": 301, "seek": 153000, "start": 1531.0, "end": 1539.0, "text": " And we're going to create a new data loader, which contains no training batches.", "tokens": [50414, 400, 321, 434, 516, 281, 1884, 257, 777, 1412, 450, 8312, 11, 597, 8306, 572, 3097, 15245, 279, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1740978052327921, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.029308365657925606}, {"id": 302, "seek": 153000, "start": 1539.0, "end": 1543.0, "text": " And it contains one validation batch, which contains the samples.", "tokens": [50814, 400, 309, 8306, 472, 24071, 15245, 11, 597, 8306, 264, 10938, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1740978052327921, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.029308365657925606}, {"id": 303, "seek": 153000, "start": 1543.0, "end": 1546.0, "text": " It doesn't actually matter what the dependent variable is.", "tokens": [51014, 467, 1177, 380, 767, 1871, 437, 264, 12334, 7006, 307, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1740978052327921, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.029308365657925606}, {"id": 304, "seek": 153000, "start": 1546.0, "end": 1549.0, "text": " So I just put in the same dependent variable that we already had.", "tokens": [51164, 407, 286, 445, 829, 294, 264, 912, 12334, 7006, 300, 321, 1217, 632, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1740978052327921, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.029308365657925606}, {"id": 305, "seek": 153000, "start": 1549.0, "end": 1559.0, "text": " And then what we're going to do is we're going to use that to extract some features from a model.", "tokens": [51314, 400, 550, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 764, 300, 281, 8947, 512, 4122, 490, 257, 2316, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1740978052327921, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.029308365657925606}, {"id": 306, "seek": 155900, "start": 1559.0, "end": 1561.0, "text": " Now what do we mean by that?", "tokens": [50364, 823, 437, 360, 321, 914, 538, 300, 30, 50464], "temperature": 0.0, "avg_logprob": -0.21532113001896785, "compression_ratio": 1.3764044943820224, "no_speech_prob": 0.0004173127526883036}, {"id": 307, "seek": 155900, "start": 1561.0, "end": 1568.0, "text": " So if you remember back to notebook 14, we created this thing called summary.", "tokens": [50464, 407, 498, 291, 1604, 646, 281, 21060, 3499, 11, 321, 2942, 341, 551, 1219, 12691, 13, 50814], "temperature": 0.0, "avg_logprob": -0.21532113001896785, "compression_ratio": 1.3764044943820224, "no_speech_prob": 0.0004173127526883036}, {"id": 308, "seek": 155900, "start": 1568.0, "end": 1577.0, "text": " And summary shows us at different blocks of our model, there are various different output shapes.", "tokens": [50814, 400, 12691, 3110, 505, 412, 819, 8474, 295, 527, 2316, 11, 456, 366, 3683, 819, 5598, 10854, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21532113001896785, "compression_ratio": 1.3764044943820224, "no_speech_prob": 0.0004173127526883036}, {"id": 309, "seek": 155900, "start": 1577.0, "end": 1579.0, "text": " In this case, it's a batch size of 1024.", "tokens": [51264, 682, 341, 1389, 11, 309, 311, 257, 15245, 2744, 295, 1266, 7911, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21532113001896785, "compression_ratio": 1.3764044943820224, "no_speech_prob": 0.0004173127526883036}, {"id": 310, "seek": 157900, "start": 1579.0, "end": 1585.0, "text": " And so after the first block, we had 16 channels, 28 by 28.", "tokens": [50364, 400, 370, 934, 264, 700, 3461, 11, 321, 632, 3165, 9235, 11, 7562, 538, 7562, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24246825033159397, "compression_ratio": 1.5266666666666666, "no_speech_prob": 0.19425077736377716}, {"id": 311, "seek": 157900, "start": 1585.0, "end": 1588.0, "text": " And then we had 32 channels, 14 by 14, and so forth.", "tokens": [50664, 400, 550, 321, 632, 8858, 9235, 11, 3499, 538, 3499, 11, 293, 370, 5220, 13, 50814], "temperature": 0.0, "avg_logprob": -0.24246825033159397, "compression_ratio": 1.5266666666666666, "no_speech_prob": 0.19425077736377716}, {"id": 312, "seek": 157900, "start": 1588.0, "end": 1602.0, "text": " Until just before the final linear layer, we had the 1024 batches, and we had 512 channels with no height and width.", "tokens": [50814, 9088, 445, 949, 264, 2572, 8213, 4583, 11, 321, 632, 264, 1266, 7911, 15245, 279, 11, 293, 321, 632, 1025, 4762, 9235, 365, 572, 6681, 293, 11402, 13, 51514], "temperature": 0.0, "avg_logprob": -0.24246825033159397, "compression_ratio": 1.5266666666666666, "no_speech_prob": 0.19425077736377716}, {"id": 313, "seek": 160200, "start": 1602.0, "end": 1617.0, "text": " Now the idea of fit and kit is that the distribution of these 512 channels for a real image has a particular kind of like signature.", "tokens": [50364, 823, 264, 1558, 295, 3318, 293, 8260, 307, 300, 264, 7316, 295, 613, 1025, 4762, 9235, 337, 257, 957, 3256, 575, 257, 1729, 733, 295, 411, 13397, 13, 51114], "temperature": 0.0, "avg_logprob": -0.2329426906147941, "compression_ratio": 1.4683544303797469, "no_speech_prob": 0.004538240842521191}, {"id": 314, "seek": 160200, "start": 1617.0, "end": 1620.0, "text": " Right, it looks a particular way.", "tokens": [51114, 1779, 11, 309, 1542, 257, 1729, 636, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2329426906147941, "compression_ratio": 1.4683544303797469, "no_speech_prob": 0.004538240842521191}, {"id": 315, "seek": 160200, "start": 1620.0, "end": 1623.0, "text": " And so what we're going to do is we're going to take our samples.", "tokens": [51264, 400, 370, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 747, 527, 10938, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2329426906147941, "compression_ratio": 1.4683544303797469, "no_speech_prob": 0.004538240842521191}, {"id": 316, "seek": 162300, "start": 1624.0, "end": 1632.0, "text": " We're going to run it through a model that's learned to predict, you know, fashion classes.", "tokens": [50414, 492, 434, 516, 281, 1190, 309, 807, 257, 2316, 300, 311, 3264, 281, 6069, 11, 291, 458, 11, 6700, 5359, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19402260529367546, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.0994419977068901}, {"id": 317, "seek": 162300, "start": 1632.0, "end": 1636.0, "text": " And we're going to grab this layer, right.", "tokens": [50814, 400, 321, 434, 516, 281, 4444, 341, 4583, 11, 558, 13, 51014], "temperature": 0.0, "avg_logprob": -0.19402260529367546, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.0994419977068901}, {"id": 318, "seek": 162300, "start": 1636.0, "end": 1643.0, "text": " And then we're going to average it across a batch, right, to get 512 numbers.", "tokens": [51014, 400, 550, 321, 434, 516, 281, 4274, 309, 2108, 257, 15245, 11, 558, 11, 281, 483, 1025, 4762, 3547, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19402260529367546, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.0994419977068901}, {"id": 319, "seek": 162300, "start": 1643.0, "end": 1648.0, "text": " And those are going to represent the mean of each of those channels.", "tokens": [51364, 400, 729, 366, 516, 281, 2906, 264, 914, 295, 1184, 295, 729, 9235, 13, 51614], "temperature": 0.0, "avg_logprob": -0.19402260529367546, "compression_ratio": 1.5965909090909092, "no_speech_prob": 0.0994419977068901}, {"id": 320, "seek": 164800, "start": 1648.0, "end": 1655.0, "text": " So those channels might represent, for example, you know, does it have a pointed collar?", "tokens": [50364, 407, 729, 9235, 1062, 2906, 11, 337, 1365, 11, 291, 458, 11, 775, 309, 362, 257, 10932, 20672, 30, 50714], "temperature": 0.0, "avg_logprob": -0.18390272884834102, "compression_ratio": 1.5728643216080402, "no_speech_prob": 0.004399321507662535}, {"id": 321, "seek": 164800, "start": 1655.0, "end": 1660.0, "text": " Does it have, you know, smooth fabric?", "tokens": [50714, 4402, 309, 362, 11, 291, 458, 11, 5508, 7253, 30, 50964], "temperature": 0.0, "avg_logprob": -0.18390272884834102, "compression_ratio": 1.5728643216080402, "no_speech_prob": 0.004399321507662535}, {"id": 322, "seek": 164800, "start": 1660.0, "end": 1662.0, "text": " Does it have sharp heels?", "tokens": [50964, 4402, 309, 362, 8199, 19502, 30, 51064], "temperature": 0.0, "avg_logprob": -0.18390272884834102, "compression_ratio": 1.5728643216080402, "no_speech_prob": 0.004399321507662535}, {"id": 323, "seek": 164800, "start": 1662.0, "end": 1664.0, "text": " And so forth, right.", "tokens": [51064, 400, 370, 5220, 11, 558, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18390272884834102, "compression_ratio": 1.5728643216080402, "no_speech_prob": 0.004399321507662535}, {"id": 324, "seek": 164800, "start": 1664.0, "end": 1676.0, "text": " And you could recognize that something is probably not a normal fashion image if it says, oh yes, it's got sharp heels and flowing fabric.", "tokens": [51164, 400, 291, 727, 5521, 300, 746, 307, 1391, 406, 257, 2710, 6700, 3256, 498, 309, 1619, 11, 1954, 2086, 11, 309, 311, 658, 8199, 19502, 293, 13974, 7253, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18390272884834102, "compression_ratio": 1.5728643216080402, "no_speech_prob": 0.004399321507662535}, {"id": 325, "seek": 167600, "start": 1676.0, "end": 1679.0, "text": " It's like, oh, that doesn't sound like anything we recognize.", "tokens": [50364, 467, 311, 411, 11, 1954, 11, 300, 1177, 380, 1626, 411, 1340, 321, 5521, 13, 50514], "temperature": 0.0, "avg_logprob": -0.20981636397335507, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.036766111850738525}, {"id": 326, "seek": 167600, "start": 1679.0, "end": 1680.0, "text": " Right.", "tokens": [50514, 1779, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20981636397335507, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.036766111850738525}, {"id": 327, "seek": 167600, "start": 1680.0, "end": 1687.0, "text": " So there are certain kind of like sets of means of these activations that don't make sense.", "tokens": [50564, 407, 456, 366, 1629, 733, 295, 411, 6352, 295, 1355, 295, 613, 2430, 763, 300, 500, 380, 652, 2020, 13, 50914], "temperature": 0.0, "avg_logprob": -0.20981636397335507, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.036766111850738525}, {"id": 328, "seek": 167600, "start": 1687.0, "end": 1688.0, "text": " So that's.", "tokens": [50914, 407, 300, 311, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20981636397335507, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.036766111850738525}, {"id": 329, "seek": 167600, "start": 1688.0, "end": 1692.0, "text": " This is a metric for.", "tokens": [50964, 639, 307, 257, 20678, 337, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20981636397335507, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.036766111850738525}, {"id": 330, "seek": 167600, "start": 1692.0, "end": 1697.0, "text": " It's not a metric for an individual image necessarily, but it's across a whole lot of images.", "tokens": [51164, 467, 311, 406, 257, 20678, 337, 364, 2609, 3256, 4725, 11, 457, 309, 311, 2108, 257, 1379, 688, 295, 5267, 13, 51414], "temperature": 0.0, "avg_logprob": -0.20981636397335507, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.036766111850738525}, {"id": 331, "seek": 167600, "start": 1697.0, "end": 1703.0, "text": " So if I generate a bunch of fashion images and I want to say, does this look like a bunch of fashion images?", "tokens": [51414, 407, 498, 286, 8460, 257, 3840, 295, 6700, 5267, 293, 286, 528, 281, 584, 11, 775, 341, 574, 411, 257, 3840, 295, 6700, 5267, 30, 51714], "temperature": 0.0, "avg_logprob": -0.20981636397335507, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.036766111850738525}, {"id": 332, "seek": 170300, "start": 1703.0, "end": 1708.0, "text": " If I look at the mean, like maybe X percent have this feature and X percent have that feature.", "tokens": [50364, 759, 286, 574, 412, 264, 914, 11, 411, 1310, 1783, 3043, 362, 341, 4111, 293, 1783, 3043, 362, 300, 4111, 13, 50614], "temperature": 0.0, "avg_logprob": -0.24944846610712812, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03461645543575287}, {"id": 333, "seek": 170300, "start": 1708.0, "end": 1717.0, "text": " So if I'm looking at those means, as I'm comparing the distribution within all these images I generated, do roughly the same amount have sharp collars as those in the training?", "tokens": [50614, 407, 498, 286, 478, 1237, 412, 729, 1355, 11, 382, 286, 478, 15763, 264, 7316, 1951, 439, 613, 5267, 286, 10833, 11, 360, 9810, 264, 912, 2372, 362, 8199, 1263, 685, 382, 729, 294, 264, 3097, 30, 51064], "temperature": 0.0, "avg_logprob": -0.24944846610712812, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03461645543575287}, {"id": 334, "seek": 170300, "start": 1717.0, "end": 1719.0, "text": " Yeah, that's a very good point too.", "tokens": [51064, 865, 11, 300, 311, 257, 588, 665, 935, 886, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24944846610712812, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03461645543575287}, {"id": 335, "seek": 170300, "start": 1719.0, "end": 1721.0, "text": " Or the features generated are similar.", "tokens": [51164, 1610, 264, 4122, 10833, 366, 2531, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24944846610712812, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03461645543575287}, {"id": 336, "seek": 170300, "start": 1721.0, "end": 1722.0, "text": " Yeah.", "tokens": [51264, 865, 13, 51314], "temperature": 0.0, "avg_logprob": -0.24944846610712812, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03461645543575287}, {"id": 337, "seek": 170300, "start": 1722.0, "end": 1724.0, "text": " And it's actually going to get even more sophisticated than that.", "tokens": [51314, 400, 309, 311, 767, 516, 281, 483, 754, 544, 16950, 813, 300, 13, 51414], "temperature": 0.0, "avg_logprob": -0.24944846610712812, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03461645543575287}, {"id": 338, "seek": 170300, "start": 1724.0, "end": 1727.0, "text": " But let's just start at that level, which is this features.mean.", "tokens": [51414, 583, 718, 311, 445, 722, 412, 300, 1496, 11, 597, 307, 341, 4122, 13, 1398, 282, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24944846610712812, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.03461645543575287}, {"id": 339, "seek": 172700, "start": 1727.0, "end": 1742.0, "text": " So the basic idea here is that we're going to take our samples and we're going to pass them through a pre-trained model that has learned to predict what type of fashion something is.", "tokens": [50364, 407, 264, 3875, 1558, 510, 307, 300, 321, 434, 516, 281, 747, 527, 10938, 293, 321, 434, 516, 281, 1320, 552, 807, 257, 659, 12, 17227, 2001, 2316, 300, 575, 3264, 281, 6069, 437, 2010, 295, 6700, 746, 307, 13, 51114], "temperature": 0.0, "avg_logprob": -0.22441202907238977, "compression_ratio": 1.5063291139240507, "no_speech_prob": 0.05578644573688507}, {"id": 340, "seek": 172700, "start": 1742.0, "end": 1749.0, "text": " And of course, we train some of those in this notebook.", "tokens": [51114, 400, 295, 1164, 11, 321, 3847, 512, 295, 729, 294, 341, 21060, 13, 51464], "temperature": 0.0, "avg_logprob": -0.22441202907238977, "compression_ratio": 1.5063291139240507, "no_speech_prob": 0.05578644573688507}, {"id": 341, "seek": 174900, "start": 1749.0, "end": 1758.0, "text": " And specifically, we trained a nice 20 epoch one in the data augmentation section, which had a 94.3% accuracy.", "tokens": [50364, 400, 4682, 11, 321, 8895, 257, 1481, 945, 30992, 339, 472, 294, 264, 1412, 14501, 19631, 3541, 11, 597, 632, 257, 30849, 13, 18, 4, 14170, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19519857774701035, "compression_ratio": 1.3416149068322982, "no_speech_prob": 0.0069005461409688}, {"id": 342, "seek": 174900, "start": 1758.0, "end": 1767.0, "text": " And so if we pass our samples through this model, we would expect to get some, you know, useful features.", "tokens": [50814, 400, 370, 498, 321, 1320, 527, 10938, 807, 341, 2316, 11, 321, 576, 2066, 281, 483, 512, 11, 291, 458, 11, 4420, 4122, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19519857774701035, "compression_ratio": 1.3416149068322982, "no_speech_prob": 0.0069005461409688}, {"id": 343, "seek": 176700, "start": 1767.0, "end": 1781.0, "text": " One thing that I found made this a bit complicated, though, is that this model was trained using data that had gone through this transformation of subtracting the mean and dividing by the standard deviation.", "tokens": [50364, 1485, 551, 300, 286, 1352, 1027, 341, 257, 857, 6179, 11, 1673, 11, 307, 300, 341, 2316, 390, 8895, 1228, 1412, 300, 632, 2780, 807, 341, 9887, 295, 16390, 278, 264, 914, 293, 26764, 538, 264, 3832, 25163, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1929926788597776, "compression_ratio": 1.5449101796407185, "no_speech_prob": 0.18230405449867249}, {"id": 344, "seek": 176700, "start": 1781.0, "end": 1788.0, "text": " And that's not what we're creating in our samples.", "tokens": [51064, 400, 300, 311, 406, 437, 321, 434, 4084, 294, 527, 10938, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1929926788597776, "compression_ratio": 1.5449101796407185, "no_speech_prob": 0.18230405449867249}, {"id": 345, "seek": 178800, "start": 1789.0, "end": 1799.0, "text": " And so generally speaking, samples in most of these kinds of diffusion models tend to be between negative one and one.", "tokens": [50414, 400, 370, 5101, 4124, 11, 10938, 294, 881, 295, 613, 3685, 295, 25242, 5245, 3928, 281, 312, 1296, 3671, 472, 293, 472, 13, 50914], "temperature": 0.0, "avg_logprob": -0.21402098768848485, "compression_ratio": 1.5, "no_speech_prob": 0.05339442566037178}, {"id": 346, "seek": 178800, "start": 1799.0, "end": 1810.0, "text": " So I actually added a new section to the very bottom of this notebook, which simply replaces the transform with something that goes from negative one to one.", "tokens": [50914, 407, 286, 767, 3869, 257, 777, 3541, 281, 264, 588, 2767, 295, 341, 21060, 11, 597, 2935, 46734, 264, 4088, 365, 746, 300, 1709, 490, 3671, 472, 281, 472, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21402098768848485, "compression_ratio": 1.5, "no_speech_prob": 0.05339442566037178}, {"id": 347, "seek": 181000, "start": 1811.0, "end": 1819.0, "text": " And just creates those data loaders and then trains something that can classify fashion.", "tokens": [50414, 400, 445, 7829, 729, 1412, 3677, 433, 293, 550, 16329, 746, 300, 393, 33872, 6700, 13, 50814], "temperature": 0.0, "avg_logprob": -0.24308670588902065, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.04534628242254257}, {"id": 348, "seek": 181000, "start": 1819.0, "end": 1823.0, "text": " And I saved this as not data.org, but data.org2.", "tokens": [50814, 400, 286, 6624, 341, 382, 406, 1412, 13, 4646, 11, 457, 1412, 13, 4646, 17, 13, 51014], "temperature": 0.0, "avg_logprob": -0.24308670588902065, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.04534628242254257}, {"id": 349, "seek": 181000, "start": 1823.0, "end": 1832.0, "text": " So this is just exactly the same as before, but it's a fashion classifier where the inputs are expected to be between minus one and one.", "tokens": [51014, 407, 341, 307, 445, 2293, 264, 912, 382, 949, 11, 457, 309, 311, 257, 6700, 1508, 9902, 689, 264, 15743, 366, 5176, 281, 312, 1296, 3175, 472, 293, 472, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24308670588902065, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.04534628242254257}, {"id": 350, "seek": 183200, "start": 1833.0, "end": 1841.0, "text": " Having said that, it turns out that our images, our samples are not between minus one and one.", "tokens": [50414, 10222, 848, 300, 11, 309, 4523, 484, 300, 527, 5267, 11, 527, 10938, 366, 406, 1296, 3175, 472, 293, 472, 13, 50814], "temperature": 0.0, "avg_logprob": -0.19180140557227196, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.005729535594582558}, {"id": 351, "seek": 183200, "start": 1841.0, "end": 1852.0, "text": " But actually, if you go back and you look at DDPM2, we just use tf.toTensor.", "tokens": [50814, 583, 767, 11, 498, 291, 352, 646, 293, 291, 574, 412, 413, 11373, 44, 17, 11, 321, 445, 764, 256, 69, 13, 1353, 51, 23153, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19180140557227196, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.005729535594582558}, {"id": 352, "seek": 183200, "start": 1852.0, "end": 1856.0, "text": " And that actually makes images that are between zero and one.", "tokens": [51364, 400, 300, 767, 1669, 5267, 300, 366, 1296, 4018, 293, 472, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19180140557227196, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.005729535594582558}, {"id": 353, "seek": 183200, "start": 1856.0, "end": 1859.0, "text": " So actually, that's a bug.", "tokens": [51564, 407, 767, 11, 300, 311, 257, 7426, 13, 51714], "temperature": 0.0, "avg_logprob": -0.19180140557227196, "compression_ratio": 1.4942528735632183, "no_speech_prob": 0.005729535594582558}, {"id": 354, "seek": 185900, "start": 1859.0, "end": 1866.0, "text": " Okay, so our images have a bug, which is they go between zero and one.", "tokens": [50364, 1033, 11, 370, 527, 5267, 362, 257, 7426, 11, 597, 307, 436, 352, 1296, 4018, 293, 472, 13, 50714], "temperature": 0.0, "avg_logprob": -0.18410699507769415, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0017821099609136581}, {"id": 355, "seek": 185900, "start": 1866.0, "end": 1867.0, "text": " So we'll look at fixing that in a moment.", "tokens": [50714, 407, 321, 603, 574, 412, 19442, 300, 294, 257, 1623, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18410699507769415, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0017821099609136581}, {"id": 356, "seek": 185900, "start": 1867.0, "end": 1871.0, "text": " But for now, we're just trying to get the fit of our existing model.", "tokens": [50764, 583, 337, 586, 11, 321, 434, 445, 1382, 281, 483, 264, 3318, 295, 527, 6741, 2316, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18410699507769415, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0017821099609136581}, {"id": 357, "seek": 185900, "start": 1871.0, "end": 1872.0, "text": " So let's do that.", "tokens": [50964, 407, 718, 311, 360, 300, 13, 51014], "temperature": 0.0, "avg_logprob": -0.18410699507769415, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0017821099609136581}, {"id": 358, "seek": 185900, "start": 1872.0, "end": 1882.0, "text": " So what we need to do is we need to take the output of our model and we need to multiply by two.", "tokens": [51014, 407, 437, 321, 643, 281, 360, 307, 321, 643, 281, 747, 264, 5598, 295, 527, 2316, 293, 321, 643, 281, 12972, 538, 732, 13, 51514], "temperature": 0.0, "avg_logprob": -0.18410699507769415, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0017821099609136581}, {"id": 359, "seek": 185900, "start": 1882.0, "end": 1884.0, "text": " So that'll be between zero and two and subtract one.", "tokens": [51514, 407, 300, 603, 312, 1296, 4018, 293, 732, 293, 16390, 472, 13, 51614], "temperature": 0.0, "avg_logprob": -0.18410699507769415, "compression_ratio": 1.6698564593301435, "no_speech_prob": 0.0017821099609136581}, {"id": 360, "seek": 188400, "start": 1884.0, "end": 1888.0, "text": " So that'll change our samples to be between minus one and one.", "tokens": [50364, 407, 300, 603, 1319, 527, 10938, 281, 312, 1296, 3175, 472, 293, 472, 13, 50564], "temperature": 0.0, "avg_logprob": -0.206482422657502, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.014955162070691586}, {"id": 361, "seek": 188400, "start": 1888.0, "end": 1893.0, "text": " And we can now pass them through our pre-trained fashion classifier.", "tokens": [50564, 400, 321, 393, 586, 1320, 552, 807, 527, 659, 12, 17227, 2001, 6700, 1508, 9902, 13, 50814], "temperature": 0.0, "avg_logprob": -0.206482422657502, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.014955162070691586}, {"id": 362, "seek": 188400, "start": 1893.0, "end": 1899.0, "text": " Okay, so now how do we get that the output of that pooling layer?", "tokens": [50814, 1033, 11, 370, 586, 577, 360, 321, 483, 300, 264, 5598, 295, 300, 7005, 278, 4583, 30, 51114], "temperature": 0.0, "avg_logprob": -0.206482422657502, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.014955162070691586}, {"id": 363, "seek": 188400, "start": 1899.0, "end": 1902.0, "text": " Because that's actually what we want to remind you.", "tokens": [51114, 1436, 300, 311, 767, 437, 321, 528, 281, 4160, 291, 13, 51264], "temperature": 0.0, "avg_logprob": -0.206482422657502, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.014955162070691586}, {"id": 364, "seek": 188400, "start": 1902.0, "end": 1910.0, "text": " We want the output of this layer.", "tokens": [51264, 492, 528, 264, 5598, 295, 341, 4583, 13, 51664], "temperature": 0.0, "avg_logprob": -0.206482422657502, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.014955162070691586}, {"id": 365, "seek": 191000, "start": 1911.0, "end": 1920.0, "text": " So just to kind of flex our, you know, PyTorch muscles, I'm going to show a couple of ways to do it.", "tokens": [50414, 407, 445, 281, 733, 295, 5896, 527, 11, 291, 458, 11, 9953, 51, 284, 339, 9530, 11, 286, 478, 516, 281, 855, 257, 1916, 295, 2098, 281, 360, 309, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2544532049269903, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.011686375364661217}, {"id": 366, "seek": 191000, "start": 1920.0, "end": 1926.0, "text": " So we're going to load the model I just trained, the data-orctv model.", "tokens": [50864, 407, 321, 434, 516, 281, 3677, 264, 2316, 286, 445, 8895, 11, 264, 1412, 12, 284, 349, 85, 2316, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2544532049269903, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.011686375364661217}, {"id": 367, "seek": 191000, "start": 1926.0, "end": 1930.0, "text": " And what we could do is, of course, we could use a hook.", "tokens": [51164, 400, 437, 321, 727, 360, 307, 11, 295, 1164, 11, 321, 727, 764, 257, 6328, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2544532049269903, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.011686375364661217}, {"id": 368, "seek": 191000, "start": 1930.0, "end": 1932.0, "text": " And we have a hooks callback.", "tokens": [51364, 400, 321, 362, 257, 26485, 818, 3207, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2544532049269903, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.011686375364661217}, {"id": 369, "seek": 193200, "start": 1933.0, "end": 1939.0, "text": " So we could just create a function which just depends the output.", "tokens": [50414, 407, 321, 727, 445, 1884, 257, 2445, 597, 445, 5946, 264, 5598, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2549275148262098, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.029311375692486763}, {"id": 370, "seek": 193200, "start": 1939.0, "end": 1941.0, "text": " So very straightforward.", "tokens": [50714, 407, 588, 15325, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2549275148262098, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.029311375692486763}, {"id": 371, "seek": 193200, "start": 1941.0, "end": 1942.0, "text": " Okay, because that's what we want.", "tokens": [50814, 1033, 11, 570, 300, 311, 437, 321, 528, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2549275148262098, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.029311375692486763}, {"id": 372, "seek": 193200, "start": 1942.0, "end": 1943.0, "text": " We want the output.", "tokens": [50864, 492, 528, 264, 5598, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2549275148262098, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.029311375692486763}, {"id": 373, "seek": 193200, "start": 1943.0, "end": 1951.0, "text": " And specifically, it's so we've got these are all sequentials.", "tokens": [50914, 400, 4682, 11, 309, 311, 370, 321, 600, 658, 613, 366, 439, 42881, 82, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2549275148262098, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.029311375692486763}, {"id": 374, "seek": 193200, "start": 1951.0, "end": 1955.0, "text": " So we can just go through and go, oh, one, two, three, four, five, the layer that we want.", "tokens": [51314, 407, 321, 393, 445, 352, 807, 293, 352, 11, 1954, 11, 472, 11, 732, 11, 1045, 11, 1451, 11, 1732, 11, 264, 4583, 300, 321, 528, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2549275148262098, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.029311375692486763}, {"id": 375, "seek": 193200, "start": 1955.0, "end": 1960.0, "text": " Okay, and so that's the module that we want to hook.", "tokens": [51514, 1033, 11, 293, 370, 300, 311, 264, 10088, 300, 321, 528, 281, 6328, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2549275148262098, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.029311375692486763}, {"id": 376, "seek": 196000, "start": 1960.0, "end": 1964.0, "text": " So once we've hooked that, we can pass that as a callback.", "tokens": [50364, 407, 1564, 321, 600, 20410, 300, 11, 321, 393, 1320, 300, 382, 257, 818, 3207, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19518296057436646, "compression_ratio": 1.6459143968871595, "no_speech_prob": 0.003172650234773755}, {"id": 377, "seek": 196000, "start": 1964.0, "end": 1970.0, "text": " And we can then, it's a bit weird calling fit, I suppose, because we're saying train equals false.", "tokens": [50564, 400, 321, 393, 550, 11, 309, 311, 257, 857, 3657, 5141, 3318, 11, 286, 7297, 11, 570, 321, 434, 1566, 3847, 6915, 7908, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19518296057436646, "compression_ratio": 1.6459143968871595, "no_speech_prob": 0.003172650234773755}, {"id": 378, "seek": 196000, "start": 1970.0, "end": 1972.0, "text": " But we're just basically capturing.", "tokens": [50864, 583, 321, 434, 445, 1936, 23384, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19518296057436646, "compression_ratio": 1.6459143968871595, "no_speech_prob": 0.003172650234773755}, {"id": 379, "seek": 196000, "start": 1972.0, "end": 1977.0, "text": " This is just to put make one batch go through and grab the outputs.", "tokens": [50964, 639, 307, 445, 281, 829, 652, 472, 15245, 352, 807, 293, 4444, 264, 23930, 13, 51214], "temperature": 0.0, "avg_logprob": -0.19518296057436646, "compression_ratio": 1.6459143968871595, "no_speech_prob": 0.003172650234773755}, {"id": 380, "seek": 196000, "start": 1977.0, "end": 1985.0, "text": " So this means now in our hook, there's now going to be a thing called outp, because we put it there.", "tokens": [51214, 407, 341, 1355, 586, 294, 527, 6328, 11, 456, 311, 586, 516, 281, 312, 257, 551, 1219, 484, 79, 11, 570, 321, 829, 309, 456, 13, 51614], "temperature": 0.0, "avg_logprob": -0.19518296057436646, "compression_ratio": 1.6459143968871595, "no_speech_prob": 0.003172650234773755}, {"id": 381, "seek": 196000, "start": 1985.0, "end": 1989.0, "text": " And we can grab, for example, a few of those to have a look.", "tokens": [51614, 400, 321, 393, 4444, 11, 337, 1365, 11, 257, 1326, 295, 729, 281, 362, 257, 574, 13, 51814], "temperature": 0.0, "avg_logprob": -0.19518296057436646, "compression_ratio": 1.6459143968871595, "no_speech_prob": 0.003172650234773755}, {"id": 382, "seek": 198900, "start": 1989.0, "end": 1994.0, "text": " And yep, here we've got a 64 by 512 set of features.", "tokens": [50364, 400, 18633, 11, 510, 321, 600, 658, 257, 12145, 538, 1025, 4762, 992, 295, 4122, 13, 50614], "temperature": 0.0, "avg_logprob": -0.20369259740265322, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.00022692984202876687}, {"id": 383, "seek": 198900, "start": 1994.0, "end": 1997.0, "text": " Okay, so that's one way we can do it.", "tokens": [50614, 1033, 11, 370, 300, 311, 472, 636, 321, 393, 360, 309, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20369259740265322, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.00022692984202876687}, {"id": 384, "seek": 198900, "start": 1997.0, "end": 2006.0, "text": " Another way we could do it is that actually sequential models are what's called in Python collections.", "tokens": [50764, 3996, 636, 321, 727, 360, 309, 307, 300, 767, 42881, 5245, 366, 437, 311, 1219, 294, 15329, 16641, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20369259740265322, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.00022692984202876687}, {"id": 385, "seek": 198900, "start": 2006.0, "end": 2011.0, "text": " They have certain, a certain API that they're expected to support.", "tokens": [51214, 814, 362, 1629, 11, 257, 1629, 9362, 300, 436, 434, 5176, 281, 1406, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20369259740265322, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.00022692984202876687}, {"id": 386, "seek": 201100, "start": 2011.0, "end": 2018.0, "text": " And out of something a collection can do, like a list, is you can call del to delete something.", "tokens": [50364, 400, 484, 295, 746, 257, 5765, 393, 360, 11, 411, 257, 1329, 11, 307, 291, 393, 818, 1103, 281, 12097, 746, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2179636693262792, "compression_ratio": 1.7918781725888324, "no_speech_prob": 0.15607456862926483}, {"id": 387, "seek": 201100, "start": 2018.0, "end": 2028.0, "text": " So we can delete this layer and this layer and be left with just these layers.", "tokens": [50714, 407, 321, 393, 12097, 341, 4583, 293, 341, 4583, 293, 312, 1411, 365, 445, 613, 7914, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2179636693262792, "compression_ratio": 1.7918781725888324, "no_speech_prob": 0.15607456862926483}, {"id": 388, "seek": 201100, "start": 2028.0, "end": 2034.0, "text": " And once we do that, that means we can just call capture preds, because now they don't have the last two layers.", "tokens": [51214, 400, 1564, 321, 360, 300, 11, 300, 1355, 321, 393, 445, 818, 7983, 3852, 82, 11, 570, 586, 436, 500, 380, 362, 264, 1036, 732, 7914, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2179636693262792, "compression_ratio": 1.7918781725888324, "no_speech_prob": 0.15607456862926483}, {"id": 389, "seek": 201100, "start": 2034.0, "end": 2039.0, "text": " So we can just delete layers eight and seven, call capture preds.", "tokens": [51514, 407, 321, 393, 445, 12097, 7914, 3180, 293, 3407, 11, 818, 7983, 3852, 82, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2179636693262792, "compression_ratio": 1.7918781725888324, "no_speech_prob": 0.15607456862926483}, {"id": 390, "seek": 203900, "start": 2039.0, "end": 2046.0, "text": " And one nice thing about this is it's going to give us the entire 10,000 images in the test set.", "tokens": [50364, 400, 472, 1481, 551, 466, 341, 307, 309, 311, 516, 281, 976, 505, 264, 2302, 1266, 11, 1360, 5267, 294, 264, 1500, 992, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2138874360493251, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.001501127379015088}, {"id": 391, "seek": 203900, "start": 2046.0, "end": 2050.0, "text": " So that's what I ended up deciding to do.", "tokens": [50714, 407, 300, 311, 437, 286, 4590, 493, 17990, 281, 360, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2138874360493251, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.001501127379015088}, {"id": 392, "seek": 203900, "start": 2050.0, "end": 2056.0, "text": " There's lots of other ways I played around with which worked, but I decided to choose these two as being two good, pretty good techniques.", "tokens": [50914, 821, 311, 3195, 295, 661, 2098, 286, 3737, 926, 365, 597, 2732, 11, 457, 286, 3047, 281, 2826, 613, 732, 382, 885, 732, 665, 11, 1238, 665, 7512, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2138874360493251, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.001501127379015088}, {"id": 393, "seek": 203900, "start": 2056.0, "end": 2064.0, "text": " Okay, so now we've got what do a thousand real images look like at the end of the pooling layer.", "tokens": [51214, 1033, 11, 370, 586, 321, 600, 658, 437, 360, 257, 4714, 957, 5267, 574, 411, 412, 264, 917, 295, 264, 7005, 278, 4583, 13, 51614], "temperature": 0.0, "avg_logprob": -0.2138874360493251, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.001501127379015088}, {"id": 394, "seek": 203900, "start": 2064.0, "end": 2067.0, "text": " So now we need to do the same for our sample.", "tokens": [51614, 407, 586, 321, 643, 281, 360, 264, 912, 337, 527, 6889, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2138874360493251, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.001501127379015088}, {"id": 395, "seek": 206700, "start": 2067.0, "end": 2073.0, "text": " So we'll load up our fashion DDPM MP.", "tokens": [50364, 407, 321, 603, 3677, 493, 527, 6700, 413, 11373, 44, 14146, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24364254086516623, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.015905655920505524}, {"id": 396, "seek": 206700, "start": 2073.0, "end": 2075.0, "text": " We'll call sample.", "tokens": [50664, 492, 603, 818, 6889, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24364254086516623, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.015905655920505524}, {"id": 397, "seek": 206700, "start": 2075.0, "end": 2078.0, "text": " Let's just grab 256 images for now.", "tokens": [50764, 961, 311, 445, 4444, 38882, 5267, 337, 586, 13, 50914], "temperature": 0.0, "avg_logprob": -0.24364254086516623, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.015905655920505524}, {"id": 398, "seek": 206700, "start": 2078.0, "end": 2081.0, "text": " Make them go between minus one and one.", "tokens": [50914, 4387, 552, 352, 1296, 3175, 472, 293, 472, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24364254086516623, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.015905655920505524}, {"id": 399, "seek": 206700, "start": 2081.0, "end": 2083.0, "text": " Make sure they look okay.", "tokens": [51064, 4387, 988, 436, 574, 1392, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24364254086516623, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.015905655920505524}, {"id": 400, "seek": 206700, "start": 2083.0, "end": 2091.0, "text": " And as I described before, created data loaders where the validation set just has one batch which contains our samples.", "tokens": [51164, 400, 382, 286, 7619, 949, 11, 2942, 1412, 3677, 433, 689, 264, 24071, 992, 445, 575, 472, 15245, 597, 8306, 527, 10938, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24364254086516623, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.015905655920505524}, {"id": 401, "seek": 206700, "start": 2091.0, "end": 2093.0, "text": " And call capture preds.", "tokens": [51564, 400, 818, 7983, 3852, 82, 13, 51664], "temperature": 0.0, "avg_logprob": -0.24364254086516623, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.015905655920505524}, {"id": 402, "seek": 209300, "start": 2094.0, "end": 2106.0, "text": " Okay, so that's going to give us our features.", "tokens": [50414, 1033, 11, 370, 300, 311, 516, 281, 976, 505, 527, 4122, 13, 51014], "temperature": 0.0, "avg_logprob": -0.21305340853604404, "compression_ratio": 1.4014598540145986, "no_speech_prob": 0.012624155730009079}, {"id": 403, "seek": 209300, "start": 2106.0, "end": 2111.0, "text": " And the reason why is because we're passing the sample to model.", "tokens": [51014, 400, 264, 1778, 983, 307, 570, 321, 434, 8437, 264, 6889, 281, 2316, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21305340853604404, "compression_ratio": 1.4014598540145986, "no_speech_prob": 0.012624155730009079}, {"id": 404, "seek": 209300, "start": 2111.0, "end": 2116.0, "text": " And model is the classifier.", "tokens": [51264, 400, 2316, 307, 264, 1508, 9902, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21305340853604404, "compression_ratio": 1.4014598540145986, "no_speech_prob": 0.012624155730009079}, {"id": 405, "seek": 209300, "start": 2116.0, "end": 2119.0, "text": " Okay, which we've deleted the last two layers from.", "tokens": [51514, 1033, 11, 597, 321, 600, 22981, 264, 1036, 732, 7914, 490, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21305340853604404, "compression_ratio": 1.4014598540145986, "no_speech_prob": 0.012624155730009079}, {"id": 406, "seek": 211900, "start": 2119.0, "end": 2124.0, "text": " So that's going to give us our 256 by 512.", "tokens": [50364, 407, 300, 311, 516, 281, 976, 505, 527, 38882, 538, 1025, 4762, 13, 50614], "temperature": 0.0, "avg_logprob": -0.19020408283580434, "compression_ratio": 1.3071428571428572, "no_speech_prob": 0.0013457729946821928}, {"id": 407, "seek": 211900, "start": 2124.0, "end": 2127.0, "text": " So now we can get the means.", "tokens": [50614, 407, 586, 321, 393, 483, 264, 1355, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19020408283580434, "compression_ratio": 1.3071428571428572, "no_speech_prob": 0.0013457729946821928}, {"id": 408, "seek": 211900, "start": 2127.0, "end": 2140.0, "text": " Now, that's not really enough to tell us whether something looks like real images.", "tokens": [50764, 823, 11, 300, 311, 406, 534, 1547, 281, 980, 505, 1968, 746, 1542, 411, 957, 5267, 13, 51414], "temperature": 0.0, "avg_logprob": -0.19020408283580434, "compression_ratio": 1.3071428571428572, "no_speech_prob": 0.0013457729946821928}, {"id": 409, "seek": 211900, "start": 2140.0, "end": 2144.0, "text": " So maybe I should draw here.", "tokens": [51414, 407, 1310, 286, 820, 2642, 510, 13, 51614], "temperature": 0.0, "avg_logprob": -0.19020408283580434, "compression_ratio": 1.3071428571428572, "no_speech_prob": 0.0013457729946821928}, {"id": 410, "seek": 214400, "start": 2144.0, "end": 2160.0, "text": " So we started out with our batch of 256.", "tokens": [50364, 407, 321, 1409, 484, 365, 527, 15245, 295, 38882, 13, 51164], "temperature": 0.0, "avg_logprob": -0.25590168911477795, "compression_ratio": 1.0, "no_speech_prob": 0.03114117495715618}, {"id": 411, "seek": 214400, "start": 2160.0, "end": 2169.0, "text": " And our channels of 512.", "tokens": [51164, 400, 527, 9235, 295, 1025, 4762, 13, 51614], "temperature": 0.0, "avg_logprob": -0.25590168911477795, "compression_ratio": 1.0, "no_speech_prob": 0.03114117495715618}, {"id": 412, "seek": 216900, "start": 2169.0, "end": 2175.0, "text": " And we squished them by taking their mean.", "tokens": [50364, 400, 321, 2339, 4729, 552, 538, 1940, 641, 914, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2741948127746582, "compression_ratio": 1.2456140350877194, "no_speech_prob": 0.06953739374876022}, {"id": 413, "seek": 216900, "start": 2175.0, "end": 2179.0, "text": " So it's now just 256.", "tokens": [50664, 407, 309, 311, 586, 445, 38882, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2741948127746582, "compression_ratio": 1.2456140350877194, "no_speech_prob": 0.06953739374876022}, {"id": 414, "seek": 216900, "start": 2179.0, "end": 2180.0, "text": " A vector.", "tokens": [50864, 316, 8062, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2741948127746582, "compression_ratio": 1.2456140350877194, "no_speech_prob": 0.06953739374876022}, {"id": 415, "seek": 216900, "start": 2180.0, "end": 2188.0, "text": " So this is the, sorry, wrong way around.", "tokens": [50914, 407, 341, 307, 264, 11, 2597, 11, 2085, 636, 926, 13, 51314], "temperature": 0.0, "avg_logprob": -0.2741948127746582, "compression_ratio": 1.2456140350877194, "no_speech_prob": 0.06953739374876022}, {"id": 416, "seek": 216900, "start": 2188.0, "end": 2191.0, "text": " We squished them this way.", "tokens": [51314, 492, 2339, 4729, 552, 341, 636, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2741948127746582, "compression_ratio": 1.2456140350877194, "no_speech_prob": 0.06953739374876022}, {"id": 417, "seek": 219100, "start": 2191.0, "end": 2192.0, "text": " By 512.", "tokens": [50364, 3146, 1025, 4762, 13, 50414], "temperature": 0.0, "avg_logprob": -0.1966512362162272, "compression_ratio": 1.3617021276595744, "no_speech_prob": 0.3207305371761322}, {"id": 418, "seek": 219100, "start": 2192.0, "end": 2201.0, "text": " Because this is the mean for each channel.", "tokens": [50414, 1436, 341, 307, 264, 914, 337, 1184, 2269, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1966512362162272, "compression_ratio": 1.3617021276595744, "no_speech_prob": 0.3207305371761322}, {"id": 419, "seek": 219100, "start": 2201.0, "end": 2209.0, "text": " Okay, and we did exactly the same thing for the much bigger, you know, full set of real images.", "tokens": [50864, 1033, 11, 293, 321, 630, 2293, 264, 912, 551, 337, 264, 709, 3801, 11, 291, 458, 11, 1577, 992, 295, 957, 5267, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1966512362162272, "compression_ratio": 1.3617021276595744, "no_speech_prob": 0.3207305371761322}, {"id": 420, "seek": 219100, "start": 2209.0, "end": 2212.0, "text": " So this is our samples.", "tokens": [51264, 407, 341, 307, 527, 10938, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1966512362162272, "compression_ratio": 1.3617021276595744, "no_speech_prob": 0.3207305371761322}, {"id": 421, "seek": 219100, "start": 2212.0, "end": 2215.0, "text": " And this is our real.", "tokens": [51414, 400, 341, 307, 527, 957, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1966512362162272, "compression_ratio": 1.3617021276595744, "no_speech_prob": 0.3207305371761322}, {"id": 422, "seek": 221500, "start": 2215.0, "end": 2222.0, "text": " But when we squish it, that's 10,000 by 512.", "tokens": [50364, 583, 562, 321, 31379, 309, 11, 300, 311, 1266, 11, 1360, 538, 1025, 4762, 13, 50714], "temperature": 0.0, "avg_logprob": -0.2549108975175498, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.15815779566764832}, {"id": 423, "seek": 221500, "start": 2222.0, "end": 2229.0, "text": " We get again 512.", "tokens": [50714, 492, 483, 797, 1025, 4762, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2549108975175498, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.15815779566764832}, {"id": 424, "seek": 221500, "start": 2229.0, "end": 2231.0, "text": " So we could now compare these two.", "tokens": [51064, 407, 321, 727, 586, 6794, 613, 732, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2549108975175498, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.15815779566764832}, {"id": 425, "seek": 221500, "start": 2231.0, "end": 2238.0, "text": " Right, but you know, you could absolutely have some samples that don't look anything like images.", "tokens": [51164, 1779, 11, 457, 291, 458, 11, 291, 727, 3122, 362, 512, 10938, 300, 500, 380, 574, 1340, 411, 5267, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2549108975175498, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.15815779566764832}, {"id": 426, "seek": 221500, "start": 2238.0, "end": 2243.0, "text": " But have similar averages for each channel.", "tokens": [51514, 583, 362, 2531, 42257, 337, 1184, 2269, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2549108975175498, "compression_ratio": 1.3735632183908046, "no_speech_prob": 0.15815779566764832}, {"id": 427, "seek": 224300, "start": 2243.0, "end": 2250.0, "text": " So we do a second thing, which is we create a covariance matrix.", "tokens": [50364, 407, 321, 360, 257, 1150, 551, 11, 597, 307, 321, 1884, 257, 49851, 719, 8141, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1795171037012217, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.06951592862606049}, {"id": 428, "seek": 224300, "start": 2250.0, "end": 2254.0, "text": " Now, if you've forgotten what this is, you should go back to our previous lesson where we looked at it.", "tokens": [50714, 823, 11, 498, 291, 600, 11832, 437, 341, 307, 11, 291, 820, 352, 646, 281, 527, 3894, 6898, 689, 321, 2956, 412, 309, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1795171037012217, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.06951592862606049}, {"id": 429, "seek": 224300, "start": 2254.0, "end": 2261.0, "text": " But just to remind you, a covariance matrix says, in this case, we do it across the channels.", "tokens": [50914, 583, 445, 281, 4160, 291, 11, 257, 49851, 719, 8141, 1619, 11, 294, 341, 1389, 11, 321, 360, 309, 2108, 264, 9235, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1795171037012217, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.06951592862606049}, {"id": 430, "seek": 224300, "start": 2261.0, "end": 2266.0, "text": " So it's going to be 512 by 512.", "tokens": [51264, 407, 309, 311, 516, 281, 312, 1025, 4762, 538, 1025, 4762, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1795171037012217, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.06951592862606049}, {"id": 431, "seek": 224300, "start": 2266.0, "end": 2270.0, "text": " So it's going to take each of these columns.", "tokens": [51514, 407, 309, 311, 516, 281, 747, 1184, 295, 613, 13766, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1795171037012217, "compression_ratio": 1.591549295774648, "no_speech_prob": 0.06951592862606049}, {"id": 432, "seek": 227000, "start": 2270.0, "end": 2277.0, "text": " And it says, in each cell, so here's cell 1, 1.", "tokens": [50364, 400, 309, 1619, 11, 294, 1184, 2815, 11, 370, 510, 311, 2815, 502, 11, 502, 13, 50714], "temperature": 0.0, "avg_logprob": -0.28681304842926736, "compression_ratio": 1.7783783783783784, "no_speech_prob": 0.16882836818695068}, {"id": 433, "seek": 227000, "start": 2277.0, "end": 2284.0, "text": " Basically it says, what's the difference between, it basically is saying, what's the difference between each row,", "tokens": [50714, 8537, 309, 1619, 11, 437, 311, 264, 2649, 1296, 11, 309, 1936, 307, 1566, 11, 437, 311, 264, 2649, 1296, 1184, 5386, 11, 51064], "temperature": 0.0, "avg_logprob": -0.28681304842926736, "compression_ratio": 1.7783783783783784, "no_speech_prob": 0.16882836818695068}, {"id": 434, "seek": 227000, "start": 2284.0, "end": 2294.0, "text": " each element here, and the mean of the whole column, multiplied by the, exactly the same thing for a different column.", "tokens": [51064, 1184, 4478, 510, 11, 293, 264, 914, 295, 264, 1379, 7738, 11, 17207, 538, 264, 11, 2293, 264, 912, 551, 337, 257, 819, 7738, 13, 51564], "temperature": 0.0, "avg_logprob": -0.28681304842926736, "compression_ratio": 1.7783783783783784, "no_speech_prob": 0.16882836818695068}, {"id": 435, "seek": 227000, "start": 2294.0, "end": 2296.0, "text": " Now on the diagonal, it's the same column twice.", "tokens": [51564, 823, 322, 264, 21539, 11, 309, 311, 264, 912, 7738, 6091, 13, 51664], "temperature": 0.0, "avg_logprob": -0.28681304842926736, "compression_ratio": 1.7783783783783784, "no_speech_prob": 0.16882836818695068}, {"id": 436, "seek": 229600, "start": 2296.0, "end": 2300.0, "text": " So that means that these in the diagonal is just the variance.", "tokens": [50364, 407, 300, 1355, 300, 613, 294, 264, 21539, 307, 445, 264, 21977, 13, 50564], "temperature": 0.0, "avg_logprob": -0.235443377494812, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.03161625936627388}, {"id": 437, "seek": 229600, "start": 2300.0, "end": 2302.0, "text": " Right.", "tokens": [50564, 1779, 13, 50664], "temperature": 0.0, "avg_logprob": -0.235443377494812, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.03161625936627388}, {"id": 438, "seek": 229600, "start": 2302.0, "end": 2313.0, "text": " But more interestingly, the ones in the off diagonal, like here, is actually saying, what's the relationship between column 1 and column 2.", "tokens": [50664, 583, 544, 25873, 11, 264, 2306, 294, 264, 766, 21539, 11, 411, 510, 11, 307, 767, 1566, 11, 437, 311, 264, 2480, 1296, 7738, 502, 293, 7738, 568, 13, 51214], "temperature": 0.0, "avg_logprob": -0.235443377494812, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.03161625936627388}, {"id": 439, "seek": 229600, "start": 2313.0, "end": 2314.0, "text": " Right.", "tokens": [51214, 1779, 13, 51264], "temperature": 0.0, "avg_logprob": -0.235443377494812, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.03161625936627388}, {"id": 440, "seek": 229600, "start": 2314.0, "end": 2318.0, "text": " So if column 1 and column 2 are uncorrelated, then this would be 0.", "tokens": [51264, 407, 498, 7738, 502, 293, 7738, 568, 366, 6219, 284, 12004, 11, 550, 341, 576, 312, 1958, 13, 51464], "temperature": 0.0, "avg_logprob": -0.235443377494812, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.03161625936627388}, {"id": 441, "seek": 229600, "start": 2318.0, "end": 2320.0, "text": " Right.", "tokens": [51464, 1779, 13, 51564], "temperature": 0.0, "avg_logprob": -0.235443377494812, "compression_ratio": 1.6348314606741574, "no_speech_prob": 0.03161625936627388}, {"id": 442, "seek": 232000, "start": 2320.0, "end": 2327.0, "text": " If they were identical, right, then it would be the same as the variance in here.", "tokens": [50364, 759, 436, 645, 14800, 11, 558, 11, 550, 309, 576, 312, 264, 912, 382, 264, 21977, 294, 510, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1902463840988447, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.1918780654668808}, {"id": 443, "seek": 232000, "start": 2327.0, "end": 2329.0, "text": " So that's how correlated are they.", "tokens": [50714, 407, 300, 311, 577, 38574, 366, 436, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1902463840988447, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.1918780654668808}, {"id": 444, "seek": 232000, "start": 2329.0, "end": 2331.0, "text": " And why is this interesting?", "tokens": [50814, 400, 983, 307, 341, 1880, 30, 50914], "temperature": 0.0, "avg_logprob": -0.1902463840988447, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.1918780654668808}, {"id": 445, "seek": 232000, "start": 2331.0, "end": 2338.0, "text": " Well, if we do the same, exactly the same thing for the reals, that's going to give us another 512 by 512.", "tokens": [50914, 1042, 11, 498, 321, 360, 264, 912, 11, 2293, 264, 912, 551, 337, 264, 957, 82, 11, 300, 311, 516, 281, 976, 505, 1071, 1025, 4762, 538, 1025, 4762, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1902463840988447, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.1918780654668808}, {"id": 446, "seek": 232000, "start": 2338.0, "end": 2348.0, "text": " And it's going to say things like, so let's say this first column was kind of like, you know, doesn't have pointy heels.", "tokens": [51264, 400, 309, 311, 516, 281, 584, 721, 411, 11, 370, 718, 311, 584, 341, 700, 7738, 390, 733, 295, 411, 11, 291, 458, 11, 1177, 380, 362, 935, 88, 19502, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1902463840988447, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.1918780654668808}, {"id": 447, "seek": 234800, "start": 2348.0, "end": 2351.0, "text": " And, sorry, heels, spell.", "tokens": [50364, 400, 11, 2597, 11, 19502, 11, 9827, 13, 50514], "temperature": 0.0, "avg_logprob": -0.22784743198128635, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0037071823608130217}, {"id": 448, "seek": 234800, "start": 2351.0, "end": 2355.0, "text": " And the second one might be, doesn't have flowing fabric.", "tokens": [50514, 400, 264, 1150, 472, 1062, 312, 11, 1177, 380, 362, 13974, 7253, 13, 50714], "temperature": 0.0, "avg_logprob": -0.22784743198128635, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0037071823608130217}, {"id": 449, "seek": 234800, "start": 2355.0, "end": 2357.0, "text": " Right.", "tokens": [50714, 1779, 13, 50814], "temperature": 0.0, "avg_logprob": -0.22784743198128635, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0037071823608130217}, {"id": 450, "seek": 234800, "start": 2357.0, "end": 2365.0, "text": " And this is where we say, okay, if, you know, generally speaking, you would expect these to be negatively correlated.", "tokens": [50814, 400, 341, 307, 689, 321, 584, 11, 1392, 11, 498, 11, 291, 458, 11, 5101, 4124, 11, 291, 576, 2066, 613, 281, 312, 29519, 38574, 13, 51214], "temperature": 0.0, "avg_logprob": -0.22784743198128635, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0037071823608130217}, {"id": 451, "seek": 234800, "start": 2365.0, "end": 2367.0, "text": " Right.", "tokens": [51214, 1779, 13, 51314], "temperature": 0.0, "avg_logprob": -0.22784743198128635, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0037071823608130217}, {"id": 452, "seek": 234800, "start": 2367.0, "end": 2372.0, "text": " So over here in the reals, this is probably going to have a negative.", "tokens": [51314, 407, 670, 510, 294, 264, 957, 82, 11, 341, 307, 1391, 516, 281, 362, 257, 3671, 13, 51564], "temperature": 0.0, "avg_logprob": -0.22784743198128635, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0037071823608130217}, {"id": 453, "seek": 234800, "start": 2372.0, "end": 2374.0, "text": " Right.", "tokens": [51564, 1779, 13, 51664], "temperature": 0.0, "avg_logprob": -0.22784743198128635, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.0037071823608130217}, {"id": 454, "seek": 237400, "start": 2374.0, "end": 2380.0, "text": " Whereas if over here it was like 0 or even worse if it's positive, it'd be like, oh, those are probably not real.", "tokens": [50364, 13813, 498, 670, 510, 309, 390, 411, 1958, 420, 754, 5324, 498, 309, 311, 3353, 11, 309, 1116, 312, 411, 11, 1954, 11, 729, 366, 1391, 406, 957, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23514492809772491, "compression_ratio": 1.4651162790697674, "no_speech_prob": 0.12073218077421188}, {"id": 455, "seek": 237400, "start": 2380.0, "end": 2381.0, "text": " Right.", "tokens": [50664, 1779, 13, 50714], "temperature": 0.0, "avg_logprob": -0.23514492809772491, "compression_ratio": 1.4651162790697674, "no_speech_prob": 0.12073218077421188}, {"id": 456, "seek": 237400, "start": 2381.0, "end": 2388.0, "text": " Because it's very unlikely you're going to have images that have both pointy heels are positively associated with a flowing fabric.", "tokens": [50714, 1436, 309, 311, 588, 17518, 291, 434, 516, 281, 362, 5267, 300, 362, 1293, 935, 88, 19502, 366, 25795, 6615, 365, 257, 13974, 7253, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23514492809772491, "compression_ratio": 1.4651162790697674, "no_speech_prob": 0.12073218077421188}, {"id": 457, "seek": 238800, "start": 2388.0, "end": 2399.0, "text": " So we're basically looking for two data sets where their covariance matrices are kind of the same.", "tokens": [50364, 407, 321, 434, 1936, 1237, 337, 732, 1412, 6352, 689, 641, 49851, 719, 32284, 366, 733, 295, 264, 912, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2616933031779964, "compression_ratio": 1.3944954128440368, "no_speech_prob": 0.08500351756811142}, {"id": 458, "seek": 238800, "start": 2399.0, "end": 2406.0, "text": " And their means are also kind of the same.", "tokens": [50914, 400, 641, 1355, 366, 611, 733, 295, 264, 912, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2616933031779964, "compression_ratio": 1.3944954128440368, "no_speech_prob": 0.08500351756811142}, {"id": 459, "seek": 238800, "start": 2406.0, "end": 2408.0, "text": " All right.", "tokens": [51264, 1057, 558, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2616933031779964, "compression_ratio": 1.3944954128440368, "no_speech_prob": 0.08500351756811142}, {"id": 460, "seek": 240800, "start": 2408.0, "end": 2426.0, "text": " So there are ways of comparing these, you know, basically comparing two sets of data to say, are they, you know, from the same distribution.", "tokens": [50364, 407, 456, 366, 2098, 295, 15763, 613, 11, 291, 458, 11, 1936, 15763, 732, 6352, 295, 1412, 281, 584, 11, 366, 436, 11, 291, 458, 11, 490, 264, 912, 7316, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19884788288789637, "compression_ratio": 1.6411764705882352, "no_speech_prob": 0.21191757917404175}, {"id": 461, "seek": 240800, "start": 2426.0, "end": 2430.0, "text": " And you can broadly think of it as being like, oh, they have pretty similar covariance matrices.", "tokens": [51264, 400, 291, 393, 19511, 519, 295, 309, 382, 885, 411, 11, 1954, 11, 436, 362, 1238, 2531, 49851, 719, 32284, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19884788288789637, "compression_ratio": 1.6411764705882352, "no_speech_prob": 0.21191757917404175}, {"id": 462, "seek": 240800, "start": 2430.0, "end": 2435.0, "text": " So they have pretty similar mean vectors.", "tokens": [51464, 407, 436, 362, 1238, 2531, 914, 18875, 13, 51714], "temperature": 0.0, "avg_logprob": -0.19884788288789637, "compression_ratio": 1.6411764705882352, "no_speech_prob": 0.21191757917404175}, {"id": 463, "seek": 243500, "start": 2435.0, "end": 2442.0, "text": " And so this is basically what the Freschet inception distance does.", "tokens": [50364, 400, 370, 341, 307, 1936, 437, 264, 479, 495, 36433, 49834, 4560, 775, 13, 50714], "temperature": 0.0, "avg_logprob": -0.4261016845703125, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.16880793869495392}, {"id": 464, "seek": 243500, "start": 2442.0, "end": 2446.0, "text": " Does that make sense so far, guys?", "tokens": [50714, 4402, 300, 652, 2020, 370, 1400, 11, 1074, 30, 50914], "temperature": 0.0, "avg_logprob": -0.4261016845703125, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.16880793869495392}, {"id": 465, "seek": 243500, "start": 2446.0, "end": 2447.0, "text": " Yes.", "tokens": [50914, 1079, 13, 50964], "temperature": 0.0, "avg_logprob": -0.4261016845703125, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.16880793869495392}, {"id": 466, "seek": 243500, "start": 2447.0, "end": 2456.0, "text": " It's really striking me now how strong the similarity is to when we were talking about like the style loss and the kinds of things.", "tokens": [50964, 467, 311, 534, 18559, 385, 586, 577, 2068, 264, 32194, 307, 281, 562, 321, 645, 1417, 466, 411, 264, 3758, 4470, 293, 264, 3685, 295, 721, 13, 51414], "temperature": 0.0, "avg_logprob": -0.4261016845703125, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.16880793869495392}, {"id": 467, "seek": 243500, "start": 2456.0, "end": 2462.0, "text": " How do we share the types of features that occur together without worrying about like which items in the data set.", "tokens": [51414, 1012, 360, 321, 2073, 264, 3467, 295, 4122, 300, 5160, 1214, 1553, 18788, 466, 411, 597, 4754, 294, 264, 1412, 992, 13, 51714], "temperature": 0.0, "avg_logprob": -0.4261016845703125, "compression_ratio": 1.5803571428571428, "no_speech_prob": 0.16880793869495392}, {"id": 468, "seek": 246200, "start": 2463.0, "end": 2466.0, "text": " The Gram-Schmidt matrices or whatever.", "tokens": [50414, 440, 22130, 12, 31560, 39000, 32284, 420, 2035, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2486797495091215, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.08383674919605255}, {"id": 469, "seek": 246200, "start": 2466.0, "end": 2467.0, "text": " Exactly.", "tokens": [50564, 7587, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2486797495091215, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.08383674919605255}, {"id": 470, "seek": 246200, "start": 2467.0, "end": 2468.0, "text": " Yeah.", "tokens": [50614, 865, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2486797495091215, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.08383674919605255}, {"id": 471, "seek": 246200, "start": 2468.0, "end": 2475.0, "text": " Now, the particular way of comparing.", "tokens": [50664, 823, 11, 264, 1729, 636, 295, 15763, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2486797495091215, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.08383674919605255}, {"id": 472, "seek": 246200, "start": 2475.0, "end": 2482.0, "text": " So, OK, so I've got the means and I've got the covariances for my samples.", "tokens": [51014, 407, 11, 2264, 11, 370, 286, 600, 658, 264, 1355, 293, 286, 600, 658, 264, 598, 8517, 21518, 337, 452, 10938, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2486797495091215, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.08383674919605255}, {"id": 473, "seek": 246200, "start": 2482.0, "end": 2485.0, "text": " And I've actually just created this little calc stats.", "tokens": [51364, 400, 286, 600, 767, 445, 2942, 341, 707, 2104, 66, 18152, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2486797495091215, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.08383674919605255}, {"id": 474, "seek": 246200, "start": 2485.0, "end": 2486.0, "text": " Right.", "tokens": [51514, 1779, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2486797495091215, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.08383674919605255}, {"id": 475, "seek": 246200, "start": 2486.0, "end": 2489.0, "text": " So I always I'm showing you how I build things, not just things that are built.", "tokens": [51564, 407, 286, 1009, 286, 478, 4099, 291, 577, 286, 1322, 721, 11, 406, 445, 721, 300, 366, 3094, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2486797495091215, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.08383674919605255}, {"id": 476, "seek": 248900, "start": 2489.0, "end": 2490.0, "text": " Right.", "tokens": [50364, 1779, 13, 50414], "temperature": 0.0, "avg_logprob": -0.23602941301133898, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.003027679631486535}, {"id": 477, "seek": 248900, "start": 2490.0, "end": 2492.0, "text": " So I always create things step by step and check their shapes.", "tokens": [50414, 407, 286, 1009, 1884, 721, 1823, 538, 1823, 293, 1520, 641, 10854, 13, 50514], "temperature": 0.0, "avg_logprob": -0.23602941301133898, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.003027679631486535}, {"id": 478, "seek": 248900, "start": 2492.0, "end": 2493.0, "text": " Right.", "tokens": [50514, 1779, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23602941301133898, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.003027679631486535}, {"id": 479, "seek": 248900, "start": 2493.0, "end": 2499.0, "text": " And then I paste them into our merge the cells, copy the cells and merge them into functions.", "tokens": [50564, 400, 550, 286, 9163, 552, 666, 527, 22183, 264, 5438, 11, 5055, 264, 5438, 293, 22183, 552, 666, 6828, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23602941301133898, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.003027679631486535}, {"id": 480, "seek": 248900, "start": 2499.0, "end": 2506.0, "text": " So here's something that gets the means and the covariance matrix.", "tokens": [50864, 407, 510, 311, 746, 300, 2170, 264, 1355, 293, 264, 49851, 719, 8141, 13, 51214], "temperature": 0.0, "avg_logprob": -0.23602941301133898, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.003027679631486535}, {"id": 481, "seek": 250600, "start": 2506.0, "end": 2519.0, "text": " So then I basically do a call that both for my sample features and for my features of the actual data set or the test set and the data set.", "tokens": [50364, 407, 550, 286, 1936, 360, 257, 818, 300, 1293, 337, 452, 6889, 4122, 293, 337, 452, 4122, 295, 264, 3539, 1412, 992, 420, 264, 1500, 992, 293, 264, 1412, 992, 13, 51014], "temperature": 0.0, "avg_logprob": -0.2792387008666992, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.03405167534947395}, {"id": 482, "seek": 250600, "start": 2519.0, "end": 2527.0, "text": " Now, what I now do with that, if they have those features, I can calculate this thing called the Frechet inception distance, which is here.", "tokens": [51014, 823, 11, 437, 286, 586, 360, 365, 300, 11, 498, 436, 362, 729, 4122, 11, 286, 393, 8873, 341, 551, 1219, 264, 6142, 36433, 49834, 4560, 11, 597, 307, 510, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2792387008666992, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.03405167534947395}, {"id": 483, "seek": 252700, "start": 2528.0, "end": 2533.0, "text": " And basically what happens is we.", "tokens": [50414, 400, 1936, 437, 2314, 307, 321, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18283966871408316, "compression_ratio": 1.3503649635036497, "no_speech_prob": 0.2224249690771103}, {"id": 484, "seek": 252700, "start": 2533.0, "end": 2537.0, "text": " Multiply together the two covariance matrices.", "tokens": [50664, 31150, 356, 1214, 264, 732, 49851, 719, 32284, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18283966871408316, "compression_ratio": 1.3503649635036497, "no_speech_prob": 0.2224249690771103}, {"id": 485, "seek": 252700, "start": 2537.0, "end": 2541.0, "text": " And that's now going to make them like bigger.", "tokens": [50864, 400, 300, 311, 586, 516, 281, 652, 552, 411, 3801, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18283966871408316, "compression_ratio": 1.3503649635036497, "no_speech_prob": 0.2224249690771103}, {"id": 486, "seek": 252700, "start": 2541.0, "end": 2542.0, "text": " Right.", "tokens": [51064, 1779, 13, 51114], "temperature": 0.0, "avg_logprob": -0.18283966871408316, "compression_ratio": 1.3503649635036497, "no_speech_prob": 0.2224249690771103}, {"id": 487, "seek": 252700, "start": 2542.0, "end": 2544.0, "text": " So we now need to basically scale that down again.", "tokens": [51114, 407, 321, 586, 643, 281, 1936, 4373, 300, 760, 797, 13, 51214], "temperature": 0.0, "avg_logprob": -0.18283966871408316, "compression_ratio": 1.3503649635036497, "no_speech_prob": 0.2224249690771103}, {"id": 488, "seek": 254400, "start": 2544.0, "end": 2548.0, "text": " Now, if we were working with.", "tokens": [50364, 823, 11, 498, 321, 645, 1364, 365, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23125903947012766, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.14989271759986877}, {"id": 489, "seek": 254400, "start": 2548.0, "end": 2550.0, "text": " You know, non matrices.", "tokens": [50564, 509, 458, 11, 2107, 32284, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23125903947012766, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.14989271759986877}, {"id": 490, "seek": 254400, "start": 2550.0, "end": 2555.0, "text": " You know, if you kind of like multiply two things together.", "tokens": [50664, 509, 458, 11, 498, 291, 733, 295, 411, 12972, 732, 721, 1214, 13, 50914], "temperature": 0.0, "avg_logprob": -0.23125903947012766, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.14989271759986877}, {"id": 491, "seek": 254400, "start": 2555.0, "end": 2560.0, "text": " Then to kind of bring it back down to the original scale, you know, you could kind of like take the square root.", "tokens": [50914, 1396, 281, 733, 295, 1565, 309, 646, 760, 281, 264, 3380, 4373, 11, 291, 458, 11, 291, 727, 733, 295, 411, 747, 264, 3732, 5593, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23125903947012766, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.14989271759986877}, {"id": 492, "seek": 254400, "start": 2560.0, "end": 2561.0, "text": " Right.", "tokens": [51164, 1779, 13, 51214], "temperature": 0.0, "avg_logprob": -0.23125903947012766, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.14989271759986877}, {"id": 493, "seek": 254400, "start": 2561.0, "end": 2565.0, "text": " So particularly if it was by itself, you took the square root, you get back to the original.", "tokens": [51214, 407, 4098, 498, 309, 390, 538, 2564, 11, 291, 1890, 264, 3732, 5593, 11, 291, 483, 646, 281, 264, 3380, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23125903947012766, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.14989271759986877}, {"id": 494, "seek": 254400, "start": 2565.0, "end": 2568.0, "text": " And so we need to do exactly the same thing to.", "tokens": [51414, 400, 370, 321, 643, 281, 360, 2293, 264, 912, 551, 281, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23125903947012766, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.14989271759986877}, {"id": 495, "seek": 254400, "start": 2568.0, "end": 2571.0, "text": " Renormalize these matrices.", "tokens": [51564, 12883, 24440, 1125, 613, 32284, 13, 51714], "temperature": 0.0, "avg_logprob": -0.23125903947012766, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.14989271759986877}, {"id": 496, "seek": 257100, "start": 2571.0, "end": 2574.0, "text": " The problem is that we've got.", "tokens": [50364, 440, 1154, 307, 300, 321, 600, 658, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2114805553270423, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0039451839402318}, {"id": 497, "seek": 257100, "start": 2574.0, "end": 2576.0, "text": " Matrices.", "tokens": [50514, 6789, 24373, 13, 50614], "temperature": 0.0, "avg_logprob": -0.2114805553270423, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0039451839402318}, {"id": 498, "seek": 257100, "start": 2576.0, "end": 2579.0, "text": " And we need to take.", "tokens": [50614, 400, 321, 643, 281, 747, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2114805553270423, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0039451839402318}, {"id": 499, "seek": 257100, "start": 2579.0, "end": 2580.0, "text": " The matrix square root.", "tokens": [50764, 440, 8141, 3732, 5593, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2114805553270423, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0039451839402318}, {"id": 500, "seek": 257100, "start": 2580.0, "end": 2582.0, "text": " Now, the matrix square root.", "tokens": [50814, 823, 11, 264, 8141, 3732, 5593, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2114805553270423, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0039451839402318}, {"id": 501, "seek": 257100, "start": 2582.0, "end": 2585.0, "text": " You might not have come across this before, but it exists.", "tokens": [50914, 509, 1062, 406, 362, 808, 2108, 341, 949, 11, 457, 309, 8198, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2114805553270423, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0039451839402318}, {"id": 502, "seek": 257100, "start": 2585.0, "end": 2589.0, "text": " And it's the thing where.", "tokens": [51064, 400, 309, 311, 264, 551, 689, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2114805553270423, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0039451839402318}, {"id": 503, "seek": 257100, "start": 2589.0, "end": 2594.0, "text": " The matrix square root of the matrix a times itself is a.", "tokens": [51264, 440, 8141, 3732, 5593, 295, 264, 8141, 257, 1413, 2564, 307, 257, 13, 51514], "temperature": 0.0, "avg_logprob": -0.2114805553270423, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0039451839402318}, {"id": 504, "seek": 257100, "start": 2594.0, "end": 2599.0, "text": " Now, I'm going to slightly cheap because.", "tokens": [51514, 823, 11, 286, 478, 516, 281, 4748, 7084, 570, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2114805553270423, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0039451839402318}, {"id": 505, "seek": 259900, "start": 2599.0, "end": 2604.0, "text": " We've used the float square root before and we did not re implement it from scratch.", "tokens": [50364, 492, 600, 1143, 264, 15706, 3732, 5593, 949, 293, 321, 630, 406, 319, 4445, 309, 490, 8459, 13, 50614], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 506, "seek": 259900, "start": 2604.0, "end": 2607.0, "text": " Because it's in the Python standard library.", "tokens": [50614, 1436, 309, 311, 294, 264, 15329, 3832, 6405, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 507, "seek": 259900, "start": 2607.0, "end": 2609.0, "text": " And also it wouldn't be particularly interesting.", "tokens": [50764, 400, 611, 309, 2759, 380, 312, 4098, 1880, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 508, "seek": 259900, "start": 2609.0, "end": 2612.0, "text": " But basically the way you can calculate.", "tokens": [50864, 583, 1936, 264, 636, 291, 393, 8873, 13, 51014], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 509, "seek": 259900, "start": 2612.0, "end": 2614.0, "text": " The float square root from scratch.", "tokens": [51014, 440, 15706, 3732, 5593, 490, 8459, 13, 51114], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 510, "seek": 259900, "start": 2614.0, "end": 2616.0, "text": " Is by using.", "tokens": [51114, 1119, 538, 1228, 13, 51214], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 511, "seek": 259900, "start": 2616.0, "end": 2618.0, "text": " There's lots of ways, but you know.", "tokens": [51214, 821, 311, 3195, 295, 2098, 11, 457, 291, 458, 13, 51314], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 512, "seek": 259900, "start": 2618.0, "end": 2621.0, "text": " The classic way that you might have done it in high school is to use Newton's method.", "tokens": [51314, 440, 7230, 636, 300, 291, 1062, 362, 1096, 309, 294, 1090, 1395, 307, 281, 764, 19541, 311, 3170, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 513, "seek": 259900, "start": 2621.0, "end": 2623.0, "text": " Which is where you basically.", "tokens": [51464, 3013, 307, 689, 291, 1936, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 514, "seek": 259900, "start": 2623.0, "end": 2627.0, "text": " Can solve if you're trying to calculate, you know, a equals.", "tokens": [51564, 1664, 5039, 498, 291, 434, 1382, 281, 8873, 11, 291, 458, 11, 257, 6915, 13, 51764], "temperature": 0.0, "avg_logprob": -0.24400296549158773, "compression_ratio": 1.6912280701754385, "no_speech_prob": 0.0028894932474941015}, {"id": 515, "seek": 262700, "start": 2628.0, "end": 2631.0, "text": " Root x.", "tokens": [50414, 3101, 310, 2031, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24927118991283662, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.009411526843905449}, {"id": 516, "seek": 262700, "start": 2631.0, "end": 2633.0, "text": " Then you're basically saying.", "tokens": [50564, 1396, 291, 434, 1936, 1566, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24927118991283662, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.009411526843905449}, {"id": 517, "seek": 262700, "start": 2633.0, "end": 2635.0, "text": " A squared.", "tokens": [50664, 316, 8889, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24927118991283662, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.009411526843905449}, {"id": 518, "seek": 262700, "start": 2635.0, "end": 2641.0, "text": " Equals x, which means you're saying a squared minus x equals zero.", "tokens": [50764, 15624, 1124, 2031, 11, 597, 1355, 291, 434, 1566, 257, 8889, 3175, 2031, 6915, 4018, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24927118991283662, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.009411526843905449}, {"id": 519, "seek": 262700, "start": 2641.0, "end": 2642.0, "text": " And.", "tokens": [51064, 400, 13, 51114], "temperature": 0.0, "avg_logprob": -0.24927118991283662, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.009411526843905449}, {"id": 520, "seek": 262700, "start": 2642.0, "end": 2647.0, "text": " That's an equation that you can solve and you can solve it by basically taking the derivative.", "tokens": [51114, 663, 311, 364, 5367, 300, 291, 393, 5039, 293, 291, 393, 5039, 309, 538, 1936, 1940, 264, 13760, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24927118991283662, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.009411526843905449}, {"id": 521, "seek": 262700, "start": 2647.0, "end": 2650.0, "text": " And taking a step along the derivative a bunch of times.", "tokens": [51364, 400, 1940, 257, 1823, 2051, 264, 13760, 257, 3840, 295, 1413, 13, 51514], "temperature": 0.0, "avg_logprob": -0.24927118991283662, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.009411526843905449}, {"id": 522, "seek": 262700, "start": 2650.0, "end": 2656.0, "text": " You can basically do the same thing to calculate the matrix square root.", "tokens": [51514, 509, 393, 1936, 360, 264, 912, 551, 281, 8873, 264, 8141, 3732, 5593, 13, 51814], "temperature": 0.0, "avg_logprob": -0.24927118991283662, "compression_ratio": 1.751269035532995, "no_speech_prob": 0.009411526843905449}, {"id": 523, "seek": 265600, "start": 2656.0, "end": 2660.0, "text": " And so.", "tokens": [50364, 400, 370, 13, 50564], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 524, "seek": 265600, "start": 2660.0, "end": 2662.0, "text": " Here it is.", "tokens": [50564, 1692, 309, 307, 13, 50664], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 525, "seek": 265600, "start": 2662.0, "end": 2663.0, "text": " Right.", "tokens": [50664, 1779, 13, 50714], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 526, "seek": 265600, "start": 2663.0, "end": 2664.0, "text": " It's the Newton method.", "tokens": [50714, 467, 311, 264, 19541, 3170, 13, 50764], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 527, "seek": 265600, "start": 2664.0, "end": 2667.0, "text": " But because it's symmetric it's slightly more complicated.", "tokens": [50764, 583, 570, 309, 311, 32330, 309, 311, 4748, 544, 6179, 13, 50914], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 528, "seek": 265600, "start": 2667.0, "end": 2669.0, "text": " So it's a Newton-Schurtz method.", "tokens": [50914, 407, 309, 311, 257, 19541, 12, 31560, 374, 23643, 3170, 13, 51014], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 529, "seek": 265600, "start": 2669.0, "end": 2671.0, "text": " And I'm not going to go through it.", "tokens": [51014, 400, 286, 478, 406, 516, 281, 352, 807, 309, 13, 51114], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 530, "seek": 265600, "start": 2671.0, "end": 2673.0, "text": " But it's basically the same deal.", "tokens": [51114, 583, 309, 311, 1936, 264, 912, 2028, 13, 51214], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 531, "seek": 265600, "start": 2673.0, "end": 2674.0, "text": " You go through up to.", "tokens": [51214, 509, 352, 807, 493, 281, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 532, "seek": 265600, "start": 2674.0, "end": 2676.0, "text": " 100 iterations.", "tokens": [51264, 2319, 36540, 13, 51364], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 533, "seek": 265600, "start": 2676.0, "end": 2678.0, "text": " And you basically.", "tokens": [51364, 400, 291, 1936, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 534, "seek": 265600, "start": 2678.0, "end": 2681.0, "text": " Do something like traveling along that kind of derivative.", "tokens": [51464, 1144, 746, 411, 9712, 2051, 300, 733, 295, 13760, 13, 51614], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 535, "seek": 265600, "start": 2681.0, "end": 2683.0, "text": " And then you say, okay, well.", "tokens": [51614, 400, 550, 291, 584, 11, 1392, 11, 731, 13, 51714], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 536, "seek": 265600, "start": 2683.0, "end": 2685.0, "text": " The result.", "tokens": [51714, 440, 1874, 13, 51814], "temperature": 0.0, "avg_logprob": -0.25628608067830405, "compression_ratio": 1.5611814345991561, "no_speech_prob": 0.0001740029692882672}, {"id": 537, "seek": 268500, "start": 2685.0, "end": 2687.0, "text": " Times itself.", "tokens": [50364, 11366, 2564, 13, 50464], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 538, "seek": 268500, "start": 2687.0, "end": 2689.0, "text": " Ought to equal.", "tokens": [50464, 422, 1599, 281, 2681, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 539, "seek": 268500, "start": 2689.0, "end": 2691.0, "text": " The original matrix.", "tokens": [50564, 440, 3380, 8141, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 540, "seek": 268500, "start": 2691.0, "end": 2694.0, "text": " So let's subtract the matrix times itself from the original matrix.", "tokens": [50664, 407, 718, 311, 16390, 264, 8141, 1413, 2564, 490, 264, 3380, 8141, 13, 50814], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 541, "seek": 268500, "start": 2694.0, "end": 2697.0, "text": " And see whether the absolute value is small.", "tokens": [50814, 400, 536, 1968, 264, 8236, 2158, 307, 1359, 13, 50964], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 542, "seek": 268500, "start": 2697.0, "end": 2699.0, "text": " And if it is, we've calculated it.", "tokens": [50964, 400, 498, 309, 307, 11, 321, 600, 15598, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 543, "seek": 268500, "start": 2699.0, "end": 2700.0, "text": " Okay.", "tokens": [51064, 1033, 13, 51114], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 544, "seek": 268500, "start": 2700.0, "end": 2703.0, "text": " So that's basically how we do a matrix square root.", "tokens": [51114, 407, 300, 311, 1936, 577, 321, 360, 257, 8141, 3732, 5593, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 545, "seek": 268500, "start": 2703.0, "end": 2704.0, "text": " So we do.", "tokens": [51264, 407, 321, 360, 13, 51314], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 546, "seek": 268500, "start": 2704.0, "end": 2705.0, "text": " That's that.", "tokens": [51314, 663, 311, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 547, "seek": 268500, "start": 2705.0, "end": 2708.0, "text": " And so now that we have strictly speaking implemented from scratch.", "tokens": [51364, 400, 370, 586, 300, 321, 362, 20792, 4124, 12270, 490, 8459, 13, 51514], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 548, "seek": 268500, "start": 2708.0, "end": 2710.0, "text": " We're allowed to use the one that already exists.", "tokens": [51514, 492, 434, 4350, 281, 764, 264, 472, 300, 1217, 8198, 13, 51614], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 549, "seek": 268500, "start": 2710.0, "end": 2712.0, "text": " I thought she doesn't have one.", "tokens": [51614, 286, 1194, 750, 1177, 380, 362, 472, 13, 51714], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 550, "seek": 268500, "start": 2712.0, "end": 2713.0, "text": " Sadly.", "tokens": [51714, 29628, 13, 51764], "temperature": 0.0, "avg_logprob": -0.24949288183404494, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.0003982091147918254}, {"id": 551, "seek": 271300, "start": 2713.0, "end": 2715.0, "text": " So we have to use the one.", "tokens": [50364, 407, 321, 362, 281, 764, 264, 472, 13, 50464], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 552, "seek": 271300, "start": 2715.0, "end": 2716.0, "text": " Sci-Pi.", "tokens": [50464, 16942, 12, 47, 72, 13, 50514], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 553, "seek": 271300, "start": 2716.0, "end": 2717.0, "text": " Sci-Pi.", "tokens": [50514, 16942, 12, 47, 72, 13, 50564], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 554, "seek": 271300, "start": 2717.0, "end": 2718.0, "text": " Min-Alg.", "tokens": [50564, 2829, 12, 9171, 70, 13, 50614], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 555, "seek": 271300, "start": 2718.0, "end": 2721.0, "text": " So this is basically going to give us.", "tokens": [50614, 407, 341, 307, 1936, 516, 281, 976, 505, 13, 50764], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 556, "seek": 271300, "start": 2721.0, "end": 2724.0, "text": " A measure of similarity.", "tokens": [50764, 316, 3481, 295, 32194, 13, 50914], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 557, "seek": 271300, "start": 2724.0, "end": 2727.0, "text": " Between the two covariance matrices.", "tokens": [50914, 18967, 264, 732, 49851, 719, 32284, 13, 51064], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 558, "seek": 271300, "start": 2727.0, "end": 2728.0, "text": " And then.", "tokens": [51064, 400, 550, 13, 51114], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 559, "seek": 271300, "start": 2728.0, "end": 2729.0, "text": " We.", "tokens": [51114, 492, 13, 51164], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 560, "seek": 271300, "start": 2729.0, "end": 2731.0, "text": " Here's the measure of similarity.", "tokens": [51164, 1692, 311, 264, 3481, 295, 32194, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 561, "seek": 271300, "start": 2731.0, "end": 2732.0, "text": " Between the two.", "tokens": [51264, 18967, 264, 732, 13, 51314], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 562, "seek": 271300, "start": 2732.0, "end": 2734.0, "text": " Main matrices.", "tokens": [51314, 12383, 32284, 13, 51414], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 563, "seek": 271300, "start": 2734.0, "end": 2735.0, "text": " Which is just the sum of squared.", "tokens": [51414, 3013, 307, 445, 264, 2408, 295, 8889, 13, 51464], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 564, "seek": 271300, "start": 2735.0, "end": 2736.0, "text": " Errors.", "tokens": [51464, 3300, 9734, 13, 51514], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 565, "seek": 271300, "start": 2736.0, "end": 2737.0, "text": " And then.", "tokens": [51514, 400, 550, 13, 51564], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 566, "seek": 271300, "start": 2737.0, "end": 2739.0, "text": " Basically for reasons that aren't interesting.", "tokens": [51564, 8537, 337, 4112, 300, 3212, 380, 1880, 13, 51664], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 567, "seek": 271300, "start": 2739.0, "end": 2741.0, "text": " We're going to use the one.", "tokens": [51664, 492, 434, 516, 281, 764, 264, 472, 13, 51764], "temperature": 0.0, "avg_logprob": -0.3692130451054536, "compression_ratio": 1.7342995169082125, "no_speech_prob": 0.00955875776708126}, {"id": 568, "seek": 274100, "start": 2741.0, "end": 2743.0, "text": " Basically for reasons that aren't interesting.", "tokens": [50364, 8537, 337, 4112, 300, 3212, 380, 1880, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 569, "seek": 274100, "start": 2743.0, "end": 2745.0, "text": " But it's just normalizing.", "tokens": [50464, 583, 309, 311, 445, 2710, 3319, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 570, "seek": 274100, "start": 2745.0, "end": 2747.0, "text": " We subtract what's called the trace.", "tokens": [50564, 492, 16390, 437, 311, 1219, 264, 13508, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 571, "seek": 274100, "start": 2747.0, "end": 2749.0, "text": " Which is the sum of the diagonal elements.", "tokens": [50664, 3013, 307, 264, 2408, 295, 264, 21539, 4959, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 572, "seek": 274100, "start": 2749.0, "end": 2751.0, "text": " And we subtract two times the trace of the.", "tokens": [50764, 400, 321, 16390, 732, 1413, 264, 13508, 295, 264, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 573, "seek": 274100, "start": 2751.0, "end": 2753.0, "text": " This thing.", "tokens": [50864, 639, 551, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 574, "seek": 274100, "start": 2753.0, "end": 2756.0, "text": " And that's called the Frechet inception distance.", "tokens": [50964, 400, 300, 311, 1219, 264, 6142, 36433, 49834, 4560, 13, 51114], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 575, "seek": 274100, "start": 2756.0, "end": 2759.0, "text": " So a bit hand wavy on the math.", "tokens": [51114, 407, 257, 857, 1011, 261, 15498, 322, 264, 5221, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 576, "seek": 274100, "start": 2759.0, "end": 2761.0, "text": " Because I don't think it's particularly relevant to anything.", "tokens": [51264, 1436, 286, 500, 380, 519, 309, 311, 4098, 7340, 281, 1340, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 577, "seek": 274100, "start": 2761.0, "end": 2764.0, "text": " But it gives you a number.", "tokens": [51364, 583, 309, 2709, 291, 257, 1230, 13, 51514], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 578, "seek": 274100, "start": 2764.0, "end": 2766.0, "text": " Which represents.", "tokens": [51514, 3013, 8855, 13, 51614], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 579, "seek": 274100, "start": 2766.0, "end": 2767.0, "text": " How similar.", "tokens": [51614, 1012, 2531, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 580, "seek": 274100, "start": 2767.0, "end": 2769.0, "text": " Is.", "tokens": [51664, 1119, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21090154647827147, "compression_ratio": 1.653386454183267, "no_speech_prob": 0.00912526436150074}, {"id": 581, "seek": 276900, "start": 2769.0, "end": 2771.0, "text": " You know.", "tokens": [50364, 509, 458, 13, 50464], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 582, "seek": 276900, "start": 2771.0, "end": 2772.0, "text": " This.", "tokens": [50464, 639, 13, 50514], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 583, "seek": 276900, "start": 2772.0, "end": 2773.0, "text": " For the samples.", "tokens": [50514, 1171, 264, 10938, 13, 50564], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 584, "seek": 276900, "start": 2773.0, "end": 2774.0, "text": " To this.", "tokens": [50564, 1407, 341, 13, 50614], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 585, "seek": 276900, "start": 2774.0, "end": 2775.0, "text": " For some real data.", "tokens": [50614, 1171, 512, 957, 1412, 13, 50664], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 586, "seek": 276900, "start": 2775.0, "end": 2776.0, "text": " Now.", "tokens": [50664, 823, 13, 50714], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 587, "seek": 276900, "start": 2776.0, "end": 2777.0, "text": " It's weird.", "tokens": [50714, 467, 311, 3657, 13, 50764], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 588, "seek": 276900, "start": 2777.0, "end": 2779.0, "text": " It's called Frechet inception distance.", "tokens": [50764, 467, 311, 1219, 6142, 36433, 49834, 4560, 13, 50864], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 589, "seek": 276900, "start": 2779.0, "end": 2781.0, "text": " When we've done nothing to do with inception.", "tokens": [50864, 1133, 321, 600, 1096, 1825, 281, 360, 365, 49834, 13, 50964], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 590, "seek": 276900, "start": 2781.0, "end": 2783.0, "text": " Well the reason why.", "tokens": [50964, 1042, 264, 1778, 983, 13, 51064], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 591, "seek": 276900, "start": 2783.0, "end": 2785.0, "text": " Is that people do not normally use.", "tokens": [51064, 1119, 300, 561, 360, 406, 5646, 764, 13, 51164], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 592, "seek": 276900, "start": 2785.0, "end": 2787.0, "text": " The fast.ai.", "tokens": [51164, 440, 2370, 13, 1301, 13, 51264], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 593, "seek": 276900, "start": 2787.0, "end": 2789.0, "text": " Part two.", "tokens": [51264, 4100, 732, 13, 51364], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 594, "seek": 276900, "start": 2789.0, "end": 2790.0, "text": " Custom fashioned.", "tokens": [51364, 16649, 40646, 13, 51414], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 595, "seek": 276900, "start": 2790.0, "end": 2791.0, "text": " MNIST.", "tokens": [51414, 376, 45, 19756, 13, 51464], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 596, "seek": 276900, "start": 2791.0, "end": 2792.0, "text": " Data org 2.", "tokens": [51464, 11888, 14045, 568, 13, 51514], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 597, "seek": 276900, "start": 2792.0, "end": 2793.0, "text": " Pickle.", "tokens": [51514, 14129, 306, 13, 51564], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 598, "seek": 276900, "start": 2793.0, "end": 2795.0, "text": " They normally use a more famous.", "tokens": [51564, 814, 5646, 764, 257, 544, 4618, 13, 51664], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 599, "seek": 276900, "start": 2795.0, "end": 2796.0, "text": " Model.", "tokens": [51664, 17105, 13, 51714], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 600, "seek": 276900, "start": 2796.0, "end": 2798.0, "text": " They normally use the inception model.", "tokens": [51714, 814, 5646, 764, 264, 49834, 2316, 13, 51814], "temperature": 0.0, "avg_logprob": -0.292889409990453, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.001432499848306179}, {"id": 601, "seek": 279800, "start": 2798.0, "end": 2800.0, "text": " Which was an image net winning model.", "tokens": [50364, 3013, 390, 364, 3256, 2533, 8224, 2316, 13, 50464], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 602, "seek": 279800, "start": 2800.0, "end": 2802.0, "text": " From Google brain.", "tokens": [50464, 3358, 3329, 3567, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 603, "seek": 279800, "start": 2802.0, "end": 2804.0, "text": " From a few years ago.", "tokens": [50564, 3358, 257, 1326, 924, 2057, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 604, "seek": 279800, "start": 2804.0, "end": 2806.0, "text": " There's no reason whatsoever.", "tokens": [50664, 821, 311, 572, 1778, 17076, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 605, "seek": 279800, "start": 2806.0, "end": 2808.0, "text": " That inception is.", "tokens": [50764, 663, 49834, 307, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 606, "seek": 279800, "start": 2808.0, "end": 2810.0, "text": " A good model to use for this.", "tokens": [50864, 316, 665, 2316, 281, 764, 337, 341, 13, 50964], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 607, "seek": 279800, "start": 2810.0, "end": 2812.0, "text": " Just happens to be the one.", "tokens": [50964, 1449, 2314, 281, 312, 264, 472, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 608, "seek": 279800, "start": 2812.0, "end": 2814.0, "text": " Which the original paper used.", "tokens": [51064, 3013, 264, 3380, 3035, 1143, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 609, "seek": 279800, "start": 2814.0, "end": 2816.0, "text": " And as a result.", "tokens": [51164, 400, 382, 257, 1874, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 610, "seek": 279800, "start": 2816.0, "end": 2818.0, "text": " Everybody now uses that.", "tokens": [51264, 7646, 586, 4960, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 611, "seek": 279800, "start": 2818.0, "end": 2820.0, "text": " Not because they are sheep.", "tokens": [51364, 1726, 570, 436, 366, 14213, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 612, "seek": 279800, "start": 2820.0, "end": 2822.0, "text": " But because you want to be able to compare your results.", "tokens": [51464, 583, 570, 291, 528, 281, 312, 1075, 281, 6794, 428, 3542, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 613, "seek": 279800, "start": 2822.0, "end": 2824.0, "text": " With other people's results.", "tokens": [51564, 2022, 661, 561, 311, 3542, 13, 51664], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 614, "seek": 279800, "start": 2824.0, "end": 2825.0, "text": " Perhaps.", "tokens": [51664, 10517, 13, 51714], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 615, "seek": 279800, "start": 2825.0, "end": 2827.0, "text": " We actually don't.", "tokens": [51714, 492, 767, 500, 380, 13, 51814], "temperature": 0.0, "avg_logprob": -0.24009302795910445, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.02194506675004959}, {"id": 616, "seek": 282700, "start": 2827.0, "end": 2829.0, "text": " We actually want to compare our results.", "tokens": [50364, 492, 767, 528, 281, 6794, 527, 3542, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 617, "seek": 282700, "start": 2829.0, "end": 2831.0, "text": " From our other results.", "tokens": [50464, 3358, 527, 661, 3542, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 618, "seek": 282700, "start": 2831.0, "end": 2833.0, "text": " And we're going to get a much more.", "tokens": [50564, 400, 321, 434, 516, 281, 483, 257, 709, 544, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 619, "seek": 282700, "start": 2833.0, "end": 2835.0, "text": " Accurate.", "tokens": [50664, 5725, 33144, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 620, "seek": 282700, "start": 2835.0, "end": 2837.0, "text": " Metric if we use a.", "tokens": [50764, 6377, 1341, 498, 321, 764, 257, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 621, "seek": 282700, "start": 2837.0, "end": 2839.0, "text": " Model that's good specifically.", "tokens": [50864, 17105, 300, 311, 665, 4682, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 622, "seek": 282700, "start": 2839.0, "end": 2841.0, "text": " At recognizing fashion.", "tokens": [50964, 1711, 18538, 6700, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 623, "seek": 282700, "start": 2841.0, "end": 2843.0, "text": " So that's why we're using this.", "tokens": [51064, 407, 300, 311, 983, 321, 434, 1228, 341, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 624, "seek": 282700, "start": 2843.0, "end": 2845.0, "text": " So very very few people bother.", "tokens": [51164, 407, 588, 588, 1326, 561, 8677, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 625, "seek": 282700, "start": 2845.0, "end": 2847.0, "text": " To use this most people just.", "tokens": [51264, 1407, 764, 341, 881, 561, 445, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 626, "seek": 282700, "start": 2847.0, "end": 2849.0, "text": " Hip install.", "tokens": [51364, 29596, 3625, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 627, "seek": 282700, "start": 2849.0, "end": 2851.0, "text": " Python fit or whatever it's called.", "tokens": [51464, 15329, 3318, 420, 2035, 309, 311, 1219, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 628, "seek": 282700, "start": 2851.0, "end": 2853.0, "text": " And use inception.", "tokens": [51564, 400, 764, 49834, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 629, "seek": 282700, "start": 2853.0, "end": 2855.0, "text": " But it's actually better to use.", "tokens": [51664, 583, 309, 311, 767, 1101, 281, 764, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18866295373740316, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.00012730405433103442}, {"id": 630, "seek": 285500, "start": 2855.0, "end": 2857.0, "text": " If you're comparing to papers.", "tokens": [50364, 759, 291, 434, 15763, 281, 10577, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 631, "seek": 285500, "start": 2857.0, "end": 2859.0, "text": " It's better to use a model that you've trained on your data.", "tokens": [50464, 467, 311, 1101, 281, 764, 257, 2316, 300, 291, 600, 8895, 322, 428, 1412, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 632, "seek": 285500, "start": 2859.0, "end": 2861.0, "text": " And you know it's good at that.", "tokens": [50564, 400, 291, 458, 309, 311, 665, 412, 300, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 633, "seek": 285500, "start": 2861.0, "end": 2863.0, "text": " So I guess this is not a.", "tokens": [50664, 407, 286, 2041, 341, 307, 406, 257, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 634, "seek": 285500, "start": 2863.0, "end": 2865.0, "text": " FED.", "tokens": [50764, 479, 4731, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 635, "seek": 285500, "start": 2865.0, "end": 2867.0, "text": " It's a.", "tokens": [50864, 467, 311, 257, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 636, "seek": 285500, "start": 2867.0, "end": 2869.0, "text": " Well maybe FED now stands for fashion.", "tokens": [50964, 1042, 1310, 479, 4731, 586, 7382, 337, 6700, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 637, "seek": 285500, "start": 2869.0, "end": 2871.0, "text": " Fashion MNIST.", "tokens": [51064, 32782, 376, 45, 19756, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 638, "seek": 285500, "start": 2871.0, "end": 2873.0, "text": " I don't know what it stands for.", "tokens": [51164, 286, 500, 380, 458, 437, 309, 7382, 337, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 639, "seek": 285500, "start": 2873.0, "end": 2875.0, "text": " I should do something.", "tokens": [51264, 286, 820, 360, 746, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 640, "seek": 285500, "start": 2875.0, "end": 2877.0, "text": " I wanted to.", "tokens": [51364, 286, 1415, 281, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 641, "seek": 285500, "start": 2877.0, "end": 2879.0, "text": " Bring up two other caveats.", "tokens": [51464, 12842, 493, 732, 661, 11730, 1720, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 642, "seek": 285500, "start": 2879.0, "end": 2881.0, "text": " Of FID.", "tokens": [51564, 2720, 479, 2777, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 643, "seek": 285500, "start": 2881.0, "end": 2883.0, "text": " Especially then like in the.", "tokens": [51664, 8545, 550, 411, 294, 264, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2727929382324219, "compression_ratio": 1.5086206896551724, "no_speech_prob": 0.1111847460269928}, {"id": 644, "seek": 288300, "start": 2883.0, "end": 2885.0, "text": " The other thing is that FID.", "tokens": [50364, 440, 661, 551, 307, 300, 479, 2777, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 645, "seek": 288300, "start": 2885.0, "end": 2887.0, "text": " Is dependent on the number of samples.", "tokens": [50464, 1119, 12334, 322, 264, 1230, 295, 10938, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 646, "seek": 288300, "start": 2887.0, "end": 2889.0, "text": " That you use.", "tokens": [50564, 663, 291, 764, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 647, "seek": 288300, "start": 2889.0, "end": 2891.0, "text": " So as the number of samples they use.", "tokens": [50664, 407, 382, 264, 1230, 295, 10938, 436, 764, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 648, "seek": 288300, "start": 2891.0, "end": 2893.0, "text": " For measuring FID.", "tokens": [50764, 1171, 13389, 479, 2777, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 649, "seek": 288300, "start": 2893.0, "end": 2895.0, "text": " It's you know it's more accurate.", "tokens": [50864, 467, 311, 291, 458, 309, 311, 544, 8559, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 650, "seek": 288300, "start": 2895.0, "end": 2897.0, "text": " If you use more samples.", "tokens": [50964, 759, 291, 764, 544, 10938, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 651, "seek": 288300, "start": 2897.0, "end": 2899.0, "text": " And it's less accurate if you use less samples.", "tokens": [51064, 400, 309, 311, 1570, 8559, 498, 291, 764, 1570, 10938, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 652, "seek": 288300, "start": 2899.0, "end": 2901.0, "text": " It's actually biased.", "tokens": [51164, 467, 311, 767, 28035, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 653, "seek": 288300, "start": 2901.0, "end": 2903.0, "text": " So if you use less samples.", "tokens": [51264, 407, 498, 291, 764, 1570, 10938, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 654, "seek": 288300, "start": 2903.0, "end": 2905.0, "text": " It's too high specifically.", "tokens": [51364, 467, 311, 886, 1090, 4682, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 655, "seek": 288300, "start": 2905.0, "end": 2907.0, "text": " Yeah.", "tokens": [51464, 865, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 656, "seek": 288300, "start": 2907.0, "end": 2909.0, "text": " So in papers you'll see them.", "tokens": [51564, 407, 294, 10577, 291, 603, 536, 552, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 657, "seek": 288300, "start": 2909.0, "end": 2911.0, "text": " Report how many samples they used.", "tokens": [51664, 16057, 577, 867, 10938, 436, 1143, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20732325744628907, "compression_ratio": 1.8851674641148326, "no_speech_prob": 0.020643260329961777}, {"id": 658, "seek": 291100, "start": 2911.0, "end": 2913.0, "text": " And so even in comparing to other papers.", "tokens": [50364, 400, 370, 754, 294, 15763, 281, 661, 10577, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 659, "seek": 291100, "start": 2913.0, "end": 2915.0, "text": " And comparing between different models.", "tokens": [50464, 400, 15763, 1296, 819, 5245, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 660, "seek": 291100, "start": 2915.0, "end": 2917.0, "text": " And different things you want to make sure.", "tokens": [50564, 400, 819, 721, 291, 528, 281, 652, 988, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 661, "seek": 291100, "start": 2917.0, "end": 2919.0, "text": " That you're comparing with the same amount of samples.", "tokens": [50664, 663, 291, 434, 15763, 365, 264, 912, 2372, 295, 10938, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 662, "seek": 291100, "start": 2919.0, "end": 2921.0, "text": " Otherwise you know it might just be high.", "tokens": [50764, 10328, 291, 458, 309, 1062, 445, 312, 1090, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 663, "seek": 291100, "start": 2921.0, "end": 2923.0, "text": " Because they just use less number of samples.", "tokens": [50864, 1436, 436, 445, 764, 1570, 1230, 295, 10938, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 664, "seek": 291100, "start": 2923.0, "end": 2925.0, "text": " Or something like this.", "tokens": [50964, 1610, 746, 411, 341, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 665, "seek": 291100, "start": 2925.0, "end": 2927.0, "text": " So you want to make sure that's comparable.", "tokens": [51064, 407, 291, 528, 281, 652, 988, 300, 311, 25323, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 666, "seek": 291100, "start": 2927.0, "end": 2929.0, "text": " And then the other thing that is you know.", "tokens": [51164, 400, 550, 264, 661, 551, 300, 307, 291, 458, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 667, "seek": 291100, "start": 2929.0, "end": 2931.0, "text": " Because I guess it's a kind of a side effect.", "tokens": [51264, 1436, 286, 2041, 309, 311, 257, 733, 295, 257, 1252, 1802, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 668, "seek": 291100, "start": 2931.0, "end": 2933.0, "text": " If using the inception network.", "tokens": [51364, 759, 1228, 264, 49834, 3209, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 669, "seek": 291100, "start": 2933.0, "end": 2935.0, "text": " In these papers is the fact that.", "tokens": [51464, 682, 613, 10577, 307, 264, 1186, 300, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 670, "seek": 291100, "start": 2935.0, "end": 2937.0, "text": " All of these are at size.", "tokens": [51564, 1057, 295, 613, 366, 412, 2744, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 671, "seek": 291100, "start": 2937.0, "end": 2939.0, "text": " 299 by 299.", "tokens": [51664, 568, 8494, 538, 568, 8494, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2105996138384553, "compression_ratio": 1.8241379310344827, "no_speech_prob": 0.0912250429391861}, {"id": 672, "seek": 293900, "start": 2939.0, "end": 2941.0, "text": " Which is like the size that the inception model was trained.", "tokens": [50364, 3013, 307, 411, 264, 2744, 300, 264, 49834, 2316, 390, 8895, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 673, "seek": 293900, "start": 2941.0, "end": 2943.0, "text": " So actually when you're applying this.", "tokens": [50464, 407, 767, 562, 291, 434, 9275, 341, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 674, "seek": 293900, "start": 2943.0, "end": 2945.0, "text": " Inception network for measuring this distance.", "tokens": [50564, 682, 7311, 3209, 337, 13389, 341, 4560, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 675, "seek": 293900, "start": 2945.0, "end": 2947.0, "text": " You're going to be resizing your images.", "tokens": [50664, 509, 434, 516, 281, 312, 725, 3319, 428, 5267, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 676, "seek": 293900, "start": 2947.0, "end": 2949.0, "text": " To 299 by 299.", "tokens": [50764, 1407, 568, 8494, 538, 568, 8494, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 677, "seek": 293900, "start": 2949.0, "end": 2951.0, "text": " Which in you know different cases.", "tokens": [50864, 3013, 294, 291, 458, 819, 3331, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 678, "seek": 293900, "start": 2951.0, "end": 2953.0, "text": " That may not you know make much sense.", "tokens": [50964, 663, 815, 406, 291, 458, 652, 709, 2020, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 679, "seek": 293900, "start": 2953.0, "end": 2955.0, "text": " So like in our case.", "tokens": [51064, 407, 411, 294, 527, 1389, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 680, "seek": 293900, "start": 2955.0, "end": 2957.0, "text": " We're working with 32 by 32.", "tokens": [51164, 492, 434, 1364, 365, 8858, 538, 8858, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 681, "seek": 293900, "start": 2957.0, "end": 2959.0, "text": " Or yeah 32 by 32.", "tokens": [51264, 1610, 1338, 8858, 538, 8858, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 682, "seek": 293900, "start": 2959.0, "end": 2961.0, "text": " Or 28 by 28 images.", "tokens": [51364, 1610, 7562, 538, 7562, 5267, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 683, "seek": 293900, "start": 2961.0, "end": 2963.0, "text": " These are very small images.", "tokens": [51464, 1981, 366, 588, 1359, 5267, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 684, "seek": 293900, "start": 2963.0, "end": 2965.0, "text": " And then we resize it to 299.", "tokens": [51564, 400, 550, 321, 50069, 309, 281, 568, 8494, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 685, "seek": 293900, "start": 2965.0, "end": 2967.0, "text": " Or in other cases.", "tokens": [51664, 1610, 294, 661, 3331, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20012306993025064, "compression_ratio": 1.6870229007633588, "no_speech_prob": 0.24778832495212555}, {"id": 686, "seek": 296700, "start": 2967.0, "end": 2969.0, "text": " If you have an issue with some of these latest models.", "tokens": [50364, 759, 291, 362, 364, 2734, 365, 512, 295, 613, 6792, 5245, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 687, "seek": 296700, "start": 2969.0, "end": 2971.0, "text": " You have these large.", "tokens": [50464, 509, 362, 613, 2416, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 688, "seek": 296700, "start": 2971.0, "end": 2973.0, "text": " 512 by 512.", "tokens": [50564, 1025, 4762, 538, 1025, 4762, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 689, "seek": 296700, "start": 2973.0, "end": 2975.0, "text": " Or 1024 by 1024 images.", "tokens": [50664, 1610, 1266, 7911, 538, 1266, 7911, 5267, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 690, "seek": 296700, "start": 2975.0, "end": 2977.0, "text": " And then you're you know.", "tokens": [50764, 400, 550, 291, 434, 291, 458, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 691, "seek": 296700, "start": 2977.0, "end": 2979.0, "text": " Kind of shrinking these images.", "tokens": [50864, 9242, 295, 41684, 613, 5267, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 692, "seek": 296700, "start": 2979.0, "end": 2981.0, "text": " To 299 by 299.", "tokens": [50964, 1407, 568, 8494, 538, 568, 8494, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 693, "seek": 296700, "start": 2981.0, "end": 2983.0, "text": " And you're losing a lot of that detail.", "tokens": [51064, 400, 291, 434, 7027, 257, 688, 295, 300, 2607, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 694, "seek": 296700, "start": 2983.0, "end": 2985.0, "text": " And quality in those images.", "tokens": [51164, 400, 3125, 294, 729, 5267, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 695, "seek": 296700, "start": 2985.0, "end": 2987.0, "text": " So actually it's kind of become a problem.", "tokens": [51264, 407, 767, 309, 311, 733, 295, 1813, 257, 1154, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 696, "seek": 296700, "start": 2987.0, "end": 2989.0, "text": " With some of these latest papers.", "tokens": [51364, 2022, 512, 295, 613, 6792, 10577, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 697, "seek": 296700, "start": 2989.0, "end": 2991.0, "text": " When you look at the FID scores.", "tokens": [51464, 1133, 291, 574, 412, 264, 479, 2777, 13444, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 698, "seek": 296700, "start": 2991.0, "end": 2993.0, "text": " And how they're comparing them.", "tokens": [51564, 400, 577, 436, 434, 15763, 552, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 699, "seek": 296700, "start": 2993.0, "end": 2995.0, "text": " And then visually when you see them.", "tokens": [51664, 400, 550, 19622, 562, 291, 536, 552, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17022438325743744, "compression_ratio": 1.7530364372469636, "no_speech_prob": 0.7600313425064087}, {"id": 700, "seek": 299500, "start": 2995.0, "end": 2997.0, "text": " They're comparing them to smaller images.", "tokens": [50364, 814, 434, 15763, 552, 281, 4356, 5267, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 701, "seek": 299500, "start": 2997.0, "end": 2999.0, "text": " But the FID score doesn't capture that as well.", "tokens": [50464, 583, 264, 479, 2777, 6175, 1177, 380, 7983, 300, 382, 731, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 702, "seek": 299500, "start": 2999.0, "end": 3001.0, "text": " Because you're actually using these much smaller images.", "tokens": [50564, 1436, 291, 434, 767, 1228, 613, 709, 4356, 5267, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 703, "seek": 299500, "start": 3001.0, "end": 3003.0, "text": " So there are a bunch of different caveats.", "tokens": [50664, 407, 456, 366, 257, 3840, 295, 819, 11730, 1720, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 704, "seek": 299500, "start": 3003.0, "end": 3005.0, "text": " And so FID you know.", "tokens": [50764, 400, 370, 479, 2777, 291, 458, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 705, "seek": 299500, "start": 3005.0, "end": 3007.0, "text": " It's very good for like yeah.", "tokens": [50864, 467, 311, 588, 665, 337, 411, 1338, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 706, "seek": 299500, "start": 3007.0, "end": 3009.0, "text": " It's nice and simple and automated.", "tokens": [50964, 467, 311, 1481, 293, 2199, 293, 18473, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 707, "seek": 299500, "start": 3009.0, "end": 3011.0, "text": " You know for this sort of comparison.", "tokens": [51064, 509, 458, 337, 341, 1333, 295, 9660, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 708, "seek": 299500, "start": 3011.0, "end": 3013.0, "text": " But you have to be aware of all these different caveats.", "tokens": [51164, 583, 291, 362, 281, 312, 3650, 295, 439, 613, 819, 11730, 1720, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 709, "seek": 299500, "start": 3013.0, "end": 3015.0, "text": " Of this metric as well.", "tokens": [51264, 2720, 341, 20678, 382, 731, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 710, "seek": 299500, "start": 3015.0, "end": 3017.0, "text": " So excellent segue.", "tokens": [51364, 407, 7103, 33850, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 711, "seek": 299500, "start": 3017.0, "end": 3019.0, "text": " Because we're going to look at exactly those two things right now.", "tokens": [51464, 1436, 321, 434, 516, 281, 574, 412, 2293, 729, 732, 721, 558, 586, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 712, "seek": 299500, "start": 3019.0, "end": 3021.0, "text": " And in fact.", "tokens": [51564, 400, 294, 1186, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 713, "seek": 299500, "start": 3021.0, "end": 3023.0, "text": " There is a metric.", "tokens": [51664, 821, 307, 257, 20678, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20038441249302455, "compression_ratio": 1.7602739726027397, "no_speech_prob": 0.1499478965997696}, {"id": 714, "seek": 302300, "start": 3023.0, "end": 3025.0, "text": " That compares the two distributions.", "tokens": [50364, 663, 38334, 264, 732, 37870, 13, 50464], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 715, "seek": 302300, "start": 3025.0, "end": 3027.0, "text": " In a way that is not biased.", "tokens": [50464, 682, 257, 636, 300, 307, 406, 28035, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 716, "seek": 302300, "start": 3027.0, "end": 3029.0, "text": " So it's not necessarily higher or lower.", "tokens": [50564, 407, 309, 311, 406, 4725, 2946, 420, 3126, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 717, "seek": 302300, "start": 3029.0, "end": 3031.0, "text": " If you use more or less samples.", "tokens": [50664, 759, 291, 764, 544, 420, 1570, 10938, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 718, "seek": 302300, "start": 3031.0, "end": 3033.0, "text": " And it's called the KID.", "tokens": [50764, 400, 309, 311, 1219, 264, 591, 2777, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 719, "seek": 302300, "start": 3033.0, "end": 3035.0, "text": " Or KID.", "tokens": [50864, 1610, 591, 2777, 13, 50964], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 720, "seek": 302300, "start": 3035.0, "end": 3037.0, "text": " Which is the Kernel Inception Distance.", "tokens": [50964, 3013, 307, 264, 40224, 338, 682, 7311, 9840, 719, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 721, "seek": 302300, "start": 3037.0, "end": 3039.0, "text": " It's actually significantly simpler to calculate.", "tokens": [51064, 467, 311, 767, 10591, 18587, 281, 8873, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 722, "seek": 302300, "start": 3039.0, "end": 3041.0, "text": " Than the Frechet Inception Distance.", "tokens": [51164, 18289, 264, 6142, 36433, 682, 7311, 9840, 719, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 723, "seek": 302300, "start": 3041.0, "end": 3043.0, "text": " And basically what you do.", "tokens": [51264, 400, 1936, 437, 291, 360, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 724, "seek": 302300, "start": 3043.0, "end": 3045.0, "text": " Is you create a bunch of groups.", "tokens": [51364, 1119, 291, 1884, 257, 3840, 295, 3935, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 725, "seek": 302300, "start": 3045.0, "end": 3047.0, "text": " A bunch of partitions.", "tokens": [51464, 316, 3840, 295, 644, 2451, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 726, "seek": 302300, "start": 3047.0, "end": 3049.0, "text": " And you compare them.", "tokens": [51564, 400, 291, 6794, 552, 13, 51664], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 727, "seek": 302300, "start": 3049.0, "end": 3051.0, "text": " And you get a result.", "tokens": [51664, 400, 291, 483, 257, 1874, 13, 51764], "temperature": 0.0, "avg_logprob": -0.24848215816585162, "compression_ratio": 1.6771653543307086, "no_speech_prob": 0.0002066219167318195}, {"id": 728, "seek": 305100, "start": 3051.0, "end": 3053.0, "text": " A bunch of partitions.", "tokens": [50364, 316, 3840, 295, 644, 2451, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 729, "seek": 305100, "start": 3053.0, "end": 3055.0, "text": " And you go through each of those partitions.", "tokens": [50464, 400, 291, 352, 807, 1184, 295, 729, 644, 2451, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 730, "seek": 305100, "start": 3055.0, "end": 3057.0, "text": " And you grab a few of your X's.", "tokens": [50564, 400, 291, 4444, 257, 1326, 295, 428, 1783, 311, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 731, "seek": 305100, "start": 3057.0, "end": 3059.0, "text": " At a time.", "tokens": [50664, 1711, 257, 565, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 732, "seek": 305100, "start": 3059.0, "end": 3061.0, "text": " And a few of your Y's.", "tokens": [50764, 400, 257, 1326, 295, 428, 398, 311, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 733, "seek": 305100, "start": 3061.0, "end": 3063.0, "text": " At a time.", "tokens": [50864, 1711, 257, 565, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 734, "seek": 305100, "start": 3063.0, "end": 3065.0, "text": " And then you calculate something called the MMD.", "tokens": [50964, 400, 550, 291, 8873, 746, 1219, 264, 34191, 35, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 735, "seek": 305100, "start": 3067.0, "end": 3069.0, "text": " Which is here.", "tokens": [51164, 3013, 307, 510, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 736, "seek": 305100, "start": 3069.0, "end": 3071.0, "text": " Which is basically.", "tokens": [51264, 3013, 307, 1936, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 737, "seek": 305100, "start": 3071.0, "end": 3073.0, "text": " Again the details don't really matter.", "tokens": [51364, 3764, 264, 4365, 500, 380, 534, 1871, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 738, "seek": 305100, "start": 3073.0, "end": 3075.0, "text": " We basically do.", "tokens": [51464, 492, 1936, 360, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 739, "seek": 305100, "start": 3075.0, "end": 3077.0, "text": " A matrix product.", "tokens": [51564, 316, 8141, 1674, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1668088389377968, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.015659645199775696}, {"id": 740, "seek": 307700, "start": 3077.0, "end": 3079.0, "text": " And we actually take the cube of it.", "tokens": [50364, 400, 321, 767, 747, 264, 13728, 295, 309, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 741, "seek": 307700, "start": 3079.0, "end": 3081.0, "text": " This K is for kernel.", "tokens": [50464, 639, 591, 307, 337, 28256, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 742, "seek": 307700, "start": 3081.0, "end": 3083.0, "text": " And we basically do that for.", "tokens": [50564, 400, 321, 1936, 360, 300, 337, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 743, "seek": 307700, "start": 3083.0, "end": 3085.0, "text": " The first sample biased.", "tokens": [50664, 440, 700, 6889, 28035, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 744, "seek": 307700, "start": 3085.0, "end": 3087.0, "text": " Compared to itself.", "tokens": [50764, 30539, 281, 2564, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 745, "seek": 307700, "start": 3087.0, "end": 3089.0, "text": " The second compared to itself.", "tokens": [50864, 440, 1150, 5347, 281, 2564, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 746, "seek": 307700, "start": 3089.0, "end": 3091.0, "text": " And the first compared to the second.", "tokens": [50964, 400, 264, 700, 5347, 281, 264, 1150, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 747, "seek": 307700, "start": 3091.0, "end": 3093.0, "text": " And we then.", "tokens": [51064, 400, 321, 550, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 748, "seek": 307700, "start": 3093.0, "end": 3095.0, "text": " Normalize them in various ways.", "tokens": [51164, 21277, 1125, 552, 294, 3683, 2098, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 749, "seek": 307700, "start": 3095.0, "end": 3097.0, "text": " And add the two.", "tokens": [51264, 400, 909, 264, 732, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 750, "seek": 307700, "start": 3097.0, "end": 3099.0, "text": " With themselves together.", "tokens": [51364, 2022, 2969, 1214, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 751, "seek": 307700, "start": 3099.0, "end": 3101.0, "text": " And subtract with the other one.", "tokens": [51464, 400, 16390, 365, 264, 661, 472, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 752, "seek": 307700, "start": 3101.0, "end": 3103.0, "text": " And this one actually.", "tokens": [51564, 400, 341, 472, 767, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 753, "seek": 307700, "start": 3103.0, "end": 3105.0, "text": " Does not use the KID.", "tokens": [51664, 4402, 406, 764, 264, 591, 2777, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2222866928368284, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0010816401336342096}, {"id": 754, "seek": 310500, "start": 3105.0, "end": 3107.0, "text": " And this one actually does not.", "tokens": [50364, 400, 341, 472, 767, 775, 406, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 755, "seek": 310500, "start": 3107.0, "end": 3109.0, "text": " Use the stats.", "tokens": [50464, 8278, 264, 18152, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 756, "seek": 310500, "start": 3109.0, "end": 3111.0, "text": " It doesn't use the means.", "tokens": [50564, 467, 1177, 380, 764, 264, 1355, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 757, "seek": 310500, "start": 3111.0, "end": 3113.0, "text": " And covariance metrics.", "tokens": [50664, 400, 49851, 719, 16367, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 758, "seek": 310500, "start": 3113.0, "end": 3115.0, "text": " It uses the features directly.", "tokens": [50764, 467, 4960, 264, 4122, 3838, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 759, "seek": 310500, "start": 3119.0, "end": 3121.0, "text": " And the actual final result.", "tokens": [51064, 400, 264, 3539, 2572, 1874, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 760, "seek": 310500, "start": 3121.0, "end": 3123.0, "text": " Is basically the mean.", "tokens": [51164, 1119, 1936, 264, 914, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 761, "seek": 310500, "start": 3123.0, "end": 3125.0, "text": " Of this calculated across.", "tokens": [51264, 2720, 341, 15598, 2108, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 762, "seek": 310500, "start": 3125.0, "end": 3127.0, "text": " Different little batches.", "tokens": [51364, 20825, 707, 15245, 279, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 763, "seek": 310500, "start": 3127.0, "end": 3129.0, "text": " Yeah again the math doesn't really.", "tokens": [51464, 865, 797, 264, 5221, 1177, 380, 534, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 764, "seek": 310500, "start": 3129.0, "end": 3131.0, "text": " Matter as to.", "tokens": [51564, 20285, 382, 281, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 765, "seek": 310500, "start": 3131.0, "end": 3133.0, "text": " You know exactly.", "tokens": [51664, 509, 458, 2293, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21045220416525137, "compression_ratio": 1.5625, "no_speech_prob": 0.0005702843773178756}, {"id": 766, "seek": 313300, "start": 3133.0, "end": 3135.0, "text": " Why all these are exactly what they are.", "tokens": [50364, 1545, 439, 613, 366, 2293, 437, 436, 366, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 767, "seek": 313300, "start": 3135.0, "end": 3137.0, "text": " But it's going to give you again a measure.", "tokens": [50464, 583, 309, 311, 516, 281, 976, 291, 797, 257, 3481, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 768, "seek": 313300, "start": 3137.0, "end": 3139.0, "text": " Of the similarity of these two distributions.", "tokens": [50564, 2720, 264, 32194, 295, 613, 732, 37870, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 769, "seek": 313300, "start": 3141.0, "end": 3143.0, "text": " At first I was confused.", "tokens": [50764, 1711, 700, 286, 390, 9019, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 770, "seek": 313300, "start": 3143.0, "end": 3145.0, "text": " As to why people weren't using this.", "tokens": [50864, 1018, 281, 983, 561, 4999, 380, 1228, 341, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 771, "seek": 313300, "start": 3145.0, "end": 3147.0, "text": " Because people don't tend to use this.", "tokens": [50964, 1436, 561, 500, 380, 3928, 281, 764, 341, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 772, "seek": 313300, "start": 3147.0, "end": 3149.0, "text": " And it doesn't have this.", "tokens": [51064, 400, 309, 1177, 380, 362, 341, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 773, "seek": 313300, "start": 3149.0, "end": 3151.0, "text": " A nasty bias problem.", "tokens": [51164, 316, 17923, 12577, 1154, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 774, "seek": 313300, "start": 3151.0, "end": 3153.0, "text": " And now that I've been using it for a while.", "tokens": [51264, 400, 586, 300, 286, 600, 668, 1228, 309, 337, 257, 1339, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 775, "seek": 313300, "start": 3153.0, "end": 3155.0, "text": " I know why.", "tokens": [51364, 286, 458, 983, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 776, "seek": 313300, "start": 3155.0, "end": 3157.0, "text": " Which is that it has a very high variance.", "tokens": [51464, 3013, 307, 300, 309, 575, 257, 588, 1090, 21977, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 777, "seek": 313300, "start": 3157.0, "end": 3159.0, "text": " Which means when I call it multiple times.", "tokens": [51564, 3013, 1355, 562, 286, 818, 309, 3866, 1413, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 778, "seek": 313300, "start": 3159.0, "end": 3161.0, "text": " With just like samples.", "tokens": [51664, 2022, 445, 411, 10938, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18660309820464163, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.03409392386674881}, {"id": 779, "seek": 316100, "start": 3161.0, "end": 3163.0, "text": " It's very different values.", "tokens": [50364, 467, 311, 588, 819, 4190, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 780, "seek": 316100, "start": 3163.0, "end": 3165.0, "text": " And so I actually haven't found this useful.", "tokens": [50464, 400, 370, 286, 767, 2378, 380, 1352, 341, 4420, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 781, "seek": 316100, "start": 3165.0, "end": 3167.0, "text": " At all.", "tokens": [50564, 1711, 439, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 782, "seek": 316100, "start": 3169.0, "end": 3171.0, "text": " So we're left in.", "tokens": [50764, 407, 321, 434, 1411, 294, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 783, "seek": 316100, "start": 3171.0, "end": 3173.0, "text": " The situation which is.", "tokens": [50864, 440, 2590, 597, 307, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 784, "seek": 316100, "start": 3173.0, "end": 3175.0, "text": " Yeah we don't actually have a good unbiased metric.", "tokens": [50964, 865, 321, 500, 380, 767, 362, 257, 665, 517, 5614, 1937, 20678, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 785, "seek": 316100, "start": 3175.0, "end": 3177.0, "text": " And I think that's.", "tokens": [51064, 400, 286, 519, 300, 311, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 786, "seek": 316100, "start": 3177.0, "end": 3179.0, "text": " The truth of where we are.", "tokens": [51164, 440, 3494, 295, 689, 321, 366, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 787, "seek": 316100, "start": 3179.0, "end": 3181.0, "text": " There is best practices.", "tokens": [51264, 821, 307, 1151, 7525, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 788, "seek": 316100, "start": 3181.0, "end": 3183.0, "text": " And even if we did.", "tokens": [51364, 400, 754, 498, 321, 630, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 789, "seek": 316100, "start": 3183.0, "end": 3185.0, "text": " All I would tell you is like.", "tokens": [51464, 1057, 286, 576, 980, 291, 307, 411, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 790, "seek": 316100, "start": 3185.0, "end": 3187.0, "text": " How similar distributions are to each other.", "tokens": [51564, 1012, 2531, 37870, 366, 281, 1184, 661, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 791, "seek": 316100, "start": 3187.0, "end": 3189.0, "text": " It doesn't actually tell you whether they look any good.", "tokens": [51664, 467, 1177, 380, 767, 980, 291, 1968, 436, 574, 604, 665, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20815534514140308, "compression_ratio": 1.6446280991735538, "no_speech_prob": 0.004398512188345194}, {"id": 792, "seek": 318900, "start": 3189.0, "end": 3191.0, "text": " So that's why.", "tokens": [50364, 407, 300, 311, 983, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 793, "seek": 318900, "start": 3191.0, "end": 3193.0, "text": " Pretty much all good papers.", "tokens": [50464, 10693, 709, 439, 665, 10577, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 794, "seek": 318900, "start": 3193.0, "end": 3195.0, "text": " They have a section on human testing.", "tokens": [50564, 814, 362, 257, 3541, 322, 1952, 4997, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 795, "seek": 318900, "start": 3195.0, "end": 3197.0, "text": " But I've definitely found this.", "tokens": [50664, 583, 286, 600, 2138, 1352, 341, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 796, "seek": 318900, "start": 3197.0, "end": 3199.0, "text": " Useful for me.", "tokens": [50764, 8278, 906, 337, 385, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 797, "seek": 318900, "start": 3199.0, "end": 3201.0, "text": " For like comparing.", "tokens": [50864, 1171, 411, 15763, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 798, "seek": 318900, "start": 3201.0, "end": 3203.0, "text": " Fashion images which.", "tokens": [50964, 32782, 5267, 597, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 799, "seek": 318900, "start": 3203.0, "end": 3205.0, "text": " Particularly like humans are good at looking at.", "tokens": [51064, 32281, 411, 6255, 366, 665, 412, 1237, 412, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 800, "seek": 318900, "start": 3205.0, "end": 3207.0, "text": " Faces that are reasonably high resolution.", "tokens": [51164, 479, 2116, 300, 366, 23551, 1090, 8669, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 801, "seek": 318900, "start": 3207.0, "end": 3209.0, "text": " And be like oh that eye looks kind of weird.", "tokens": [51264, 400, 312, 411, 1954, 300, 3313, 1542, 733, 295, 3657, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 802, "seek": 318900, "start": 3209.0, "end": 3211.0, "text": " But we're not good at looking at 28 by 28.", "tokens": [51364, 583, 321, 434, 406, 665, 412, 1237, 412, 7562, 538, 7562, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 803, "seek": 318900, "start": 3211.0, "end": 3213.0, "text": " Fashion images.", "tokens": [51464, 32782, 5267, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 804, "seek": 318900, "start": 3213.0, "end": 3215.0, "text": " So it's particularly helpful for stuff.", "tokens": [51564, 407, 309, 311, 4098, 4961, 337, 1507, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 805, "seek": 318900, "start": 3215.0, "end": 3217.0, "text": " That our brains aren't good at.", "tokens": [51664, 663, 527, 15442, 3212, 380, 665, 412, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21405650675296783, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0007096104673109949}, {"id": 806, "seek": 321700, "start": 3217.0, "end": 3219.0, "text": " So I basically wrap this up into a class.", "tokens": [50364, 407, 286, 1936, 7019, 341, 493, 666, 257, 1508, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 807, "seek": 321700, "start": 3219.0, "end": 3221.0, "text": " Which I called image eval.", "tokens": [50464, 3013, 286, 1219, 3256, 1073, 304, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 808, "seek": 321700, "start": 3221.0, "end": 3223.0, "text": " For evaluating images.", "tokens": [50564, 1171, 27479, 5267, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 809, "seek": 321700, "start": 3223.0, "end": 3225.0, "text": " And so what you're going to do is.", "tokens": [50664, 400, 370, 437, 291, 434, 516, 281, 360, 307, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 810, "seek": 321700, "start": 3225.0, "end": 3227.0, "text": " You're going to pass in.", "tokens": [50764, 509, 434, 516, 281, 1320, 294, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 811, "seek": 321700, "start": 3227.0, "end": 3229.0, "text": " A pre-trained model.", "tokens": [50864, 316, 659, 12, 17227, 2001, 2316, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 812, "seek": 321700, "start": 3229.0, "end": 3231.0, "text": " A classifier.", "tokens": [50964, 316, 1508, 9902, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 813, "seek": 321700, "start": 3231.0, "end": 3233.0, "text": " And your data loaders.", "tokens": [51064, 400, 428, 1412, 3677, 433, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 814, "seek": 321700, "start": 3233.0, "end": 3235.0, "text": " Which is the thing that we're going to use.", "tokens": [51164, 3013, 307, 264, 551, 300, 321, 434, 516, 281, 764, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 815, "seek": 321700, "start": 3235.0, "end": 3237.0, "text": " To basically calculate.", "tokens": [51264, 1407, 1936, 8873, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 816, "seek": 321700, "start": 3237.0, "end": 3239.0, "text": " The real images.", "tokens": [51364, 440, 957, 5267, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 817, "seek": 321700, "start": 3239.0, "end": 3241.0, "text": " So that's going to be.", "tokens": [51464, 407, 300, 311, 516, 281, 312, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 818, "seek": 321700, "start": 3241.0, "end": 3243.0, "text": " You know.", "tokens": [51564, 509, 458, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 819, "seek": 321700, "start": 3243.0, "end": 3245.0, "text": " The data loaders that were in this.", "tokens": [51664, 440, 1412, 3677, 433, 300, 645, 294, 341, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18291436172113185, "compression_ratio": 1.7536231884057971, "no_speech_prob": 0.0011333862785249949}, {"id": 820, "seek": 324500, "start": 3245.0, "end": 3247.0, "text": " Learn.", "tokens": [50364, 17216, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 821, "seek": 324500, "start": 3247.0, "end": 3249.0, "text": " So the real images.", "tokens": [50464, 407, 264, 957, 5267, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 822, "seek": 324500, "start": 3249.0, "end": 3251.0, "text": " And so what it's going to do.", "tokens": [50564, 400, 370, 437, 309, 311, 516, 281, 360, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 823, "seek": 324500, "start": 3251.0, "end": 3253.0, "text": " In this class.", "tokens": [50664, 682, 341, 1508, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 824, "seek": 324500, "start": 3253.0, "end": 3255.0, "text": " Then again this is just copying and pasting.", "tokens": [50764, 1396, 797, 341, 307, 445, 27976, 293, 1791, 278, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 825, "seek": 324500, "start": 3255.0, "end": 3257.0, "text": " The previous lines of code.", "tokens": [50864, 440, 3894, 3876, 295, 3089, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 826, "seek": 324500, "start": 3257.0, "end": 3259.0, "text": " And putting them into a class.", "tokens": [50964, 400, 3372, 552, 666, 257, 1508, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 827, "seek": 324500, "start": 3259.0, "end": 3261.0, "text": " This is going to be then something that we call.", "tokens": [51064, 639, 307, 516, 281, 312, 550, 746, 300, 321, 818, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 828, "seek": 324500, "start": 3261.0, "end": 3263.0, "text": " Capture preds on.", "tokens": [51164, 9480, 540, 3852, 82, 322, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 829, "seek": 324500, "start": 3263.0, "end": 3265.0, "text": " To get our features for the real images.", "tokens": [51264, 1407, 483, 527, 4122, 337, 264, 957, 5267, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 830, "seek": 324500, "start": 3265.0, "end": 3267.0, "text": " And then we can also calculate the stats.", "tokens": [51364, 400, 550, 321, 393, 611, 8873, 264, 18152, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 831, "seek": 324500, "start": 3267.0, "end": 3269.0, "text": " For the real images.", "tokens": [51464, 1171, 264, 957, 5267, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 832, "seek": 324500, "start": 3269.0, "end": 3271.0, "text": " And so then we can call fit.", "tokens": [51564, 400, 370, 550, 321, 393, 818, 3318, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 833, "seek": 324500, "start": 3271.0, "end": 3273.0, "text": " By calling calc fit.", "tokens": [51664, 3146, 5141, 2104, 66, 3318, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2123975528506782, "compression_ratio": 1.7918552036199096, "no_speech_prob": 0.0022870246320962906}, {"id": 834, "seek": 327300, "start": 3273.0, "end": 3275.0, "text": " The thing we already had.", "tokens": [50364, 440, 551, 321, 1217, 632, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 835, "seek": 327300, "start": 3275.0, "end": 3277.0, "text": " Passing in the stats for the real images.", "tokens": [50464, 10319, 278, 294, 264, 18152, 337, 264, 957, 5267, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 836, "seek": 327300, "start": 3277.0, "end": 3279.0, "text": " And calculate the stats.", "tokens": [50564, 400, 8873, 264, 18152, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 837, "seek": 327300, "start": 3279.0, "end": 3281.0, "text": " For the features.", "tokens": [50664, 1171, 264, 4122, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 838, "seek": 327300, "start": 3281.0, "end": 3283.0, "text": " From our samples.", "tokens": [50764, 3358, 527, 10938, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 839, "seek": 327300, "start": 3283.0, "end": 3285.0, "text": " Where the features are.", "tokens": [50864, 2305, 264, 4122, 366, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 840, "seek": 327300, "start": 3285.0, "end": 3287.0, "text": " The thing that we've seen before.", "tokens": [50964, 440, 551, 300, 321, 600, 1612, 949, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 841, "seek": 327300, "start": 3287.0, "end": 3289.0, "text": " We pass in our samples.", "tokens": [51064, 492, 1320, 294, 527, 10938, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 842, "seek": 327300, "start": 3289.0, "end": 3291.0, "text": " Any random y value is fine.", "tokens": [51164, 2639, 4974, 288, 2158, 307, 2489, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 843, "seek": 327300, "start": 3291.0, "end": 3293.0, "text": " So I just have a single tensor there.", "tokens": [51264, 407, 286, 445, 362, 257, 2167, 40863, 456, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 844, "seek": 327300, "start": 3293.0, "end": 3295.0, "text": " And call capture preds.", "tokens": [51364, 400, 818, 7983, 3852, 82, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 845, "seek": 327300, "start": 3295.0, "end": 3297.0, "text": " So we can now create an image.", "tokens": [51464, 407, 321, 393, 586, 1884, 364, 3256, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 846, "seek": 327300, "start": 3297.0, "end": 3299.0, "text": " If our object.", "tokens": [51564, 759, 527, 2657, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 847, "seek": 327300, "start": 3299.0, "end": 3301.0, "text": " Passing in our classifier.", "tokens": [51664, 10319, 278, 294, 527, 1508, 9902, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17931045404001444, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.019715920090675354}, {"id": 848, "seek": 330100, "start": 3301.0, "end": 3303.0, "text": " Passing in our data loaders.", "tokens": [50364, 10319, 278, 294, 527, 1412, 3677, 433, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 849, "seek": 330100, "start": 3303.0, "end": 3305.0, "text": " With the real data.", "tokens": [50464, 2022, 264, 957, 1412, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 850, "seek": 330100, "start": 3305.0, "end": 3307.0, "text": " Any other callbacks you want.", "tokens": [50564, 2639, 661, 818, 17758, 291, 528, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 851, "seek": 330100, "start": 3307.0, "end": 3309.0, "text": " And if we call fit.", "tokens": [50664, 400, 498, 321, 818, 3318, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 852, "seek": 330100, "start": 3309.0, "end": 3311.0, "text": " Takes about a quarter of a second.", "tokens": [50764, 44347, 466, 257, 6555, 295, 257, 1150, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 853, "seek": 330100, "start": 3311.0, "end": 3313.0, "text": " And 33.9 is the fit.", "tokens": [50864, 400, 11816, 13, 24, 307, 264, 3318, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 854, "seek": 330100, "start": 3313.0, "end": 3315.0, "text": " For our samples.", "tokens": [50964, 1171, 527, 10938, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 855, "seek": 330100, "start": 3315.0, "end": 3317.0, "text": " So something that I think.", "tokens": [51064, 407, 746, 300, 286, 519, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 856, "seek": 330100, "start": 3317.0, "end": 3319.0, "text": " Okay then kit.", "tokens": [51164, 1033, 550, 8260, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 857, "seek": 330100, "start": 3319.0, "end": 3321.0, "text": " Kit's very going to be a very different scale.", "tokens": [51264, 23037, 311, 588, 516, 281, 312, 257, 588, 819, 4373, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 858, "seek": 330100, "start": 3321.0, "end": 3323.0, "text": " It's only 0.05.", "tokens": [51364, 467, 311, 787, 1958, 13, 13328, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 859, "seek": 330100, "start": 3323.0, "end": 3325.0, "text": " So kits are generally much smaller than fits.", "tokens": [51464, 407, 22095, 366, 5101, 709, 4356, 813, 9001, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 860, "seek": 330100, "start": 3325.0, "end": 3327.0, "text": " So I'm mainly going to be looking at fits.", "tokens": [51564, 407, 286, 478, 8704, 516, 281, 312, 1237, 412, 9001, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 861, "seek": 330100, "start": 3327.0, "end": 3329.0, "text": " And so here's what happens.", "tokens": [51664, 400, 370, 510, 311, 437, 2314, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21238574544892055, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.0027572456747293472}, {"id": 862, "seek": 332900, "start": 3329.0, "end": 3331.0, "text": " And so here's what happens.", "tokens": [50364, 400, 370, 510, 311, 437, 2314, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 863, "seek": 332900, "start": 3331.0, "end": 3333.0, "text": " If we call fit.", "tokens": [50464, 759, 321, 818, 3318, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 864, "seek": 332900, "start": 3333.0, "end": 3335.0, "text": " On sample 0.", "tokens": [50564, 1282, 6889, 1958, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 865, "seek": 332900, "start": 3335.0, "end": 3337.0, "text": " And then sample 50.", "tokens": [50664, 400, 550, 6889, 2625, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 866, "seek": 332900, "start": 3337.0, "end": 3339.0, "text": " And then sample 100.", "tokens": [50764, 400, 550, 6889, 2319, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 867, "seek": 332900, "start": 3339.0, "end": 3341.0, "text": " And so forth.", "tokens": [50864, 400, 370, 5220, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 868, "seek": 332900, "start": 3341.0, "end": 3343.0, "text": " All the way up to 900.", "tokens": [50964, 1057, 264, 636, 493, 281, 22016, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 869, "seek": 332900, "start": 3343.0, "end": 3345.0, "text": " And then we also do samples 975, 990, and 999.", "tokens": [51064, 400, 550, 321, 611, 360, 10938, 1722, 11901, 11, 1722, 7771, 11, 293, 1722, 8494, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 870, "seek": 332900, "start": 3345.0, "end": 3347.0, "text": " And so you can see.", "tokens": [51164, 400, 370, 291, 393, 536, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 871, "seek": 332900, "start": 3347.0, "end": 3349.0, "text": " Over time our samples.", "tokens": [51264, 4886, 565, 527, 10938, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 872, "seek": 332900, "start": 3349.0, "end": 3351.0, "text": " Fits improved.", "tokens": [51364, 479, 1208, 9689, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 873, "seek": 332900, "start": 3351.0, "end": 3353.0, "text": " So that's a good little test.", "tokens": [51464, 407, 300, 311, 257, 665, 707, 1500, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 874, "seek": 332900, "start": 3353.0, "end": 3355.0, "text": " There's something curious.", "tokens": [51564, 821, 311, 746, 6369, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 875, "seek": 332900, "start": 3355.0, "end": 3357.0, "text": " About the fact that they stopped improving.", "tokens": [51664, 7769, 264, 1186, 300, 436, 5936, 11470, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17618937452300257, "compression_ratio": 1.6037735849056605, "no_speech_prob": 0.0005112373037263751}, {"id": 876, "seek": 335700, "start": 3357.0, "end": 3359.0, "text": " So that's interesting.", "tokens": [50364, 407, 300, 311, 1880, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 877, "seek": 335700, "start": 3359.0, "end": 3361.0, "text": " I've not seen anybody plot this graph before.", "tokens": [50464, 286, 600, 406, 1612, 4472, 7542, 341, 4295, 949, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 878, "seek": 335700, "start": 3361.0, "end": 3363.0, "text": " I don't know if Jono or Tanishka.", "tokens": [50564, 286, 500, 380, 458, 498, 7745, 78, 420, 314, 7524, 2330, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 879, "seek": 335700, "start": 3363.0, "end": 3365.0, "text": " If you guys have.", "tokens": [50664, 759, 291, 1074, 362, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 880, "seek": 335700, "start": 3365.0, "end": 3367.0, "text": " I feel like it's something people should be looking at.", "tokens": [50764, 286, 841, 411, 309, 311, 746, 561, 820, 312, 1237, 412, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 881, "seek": 335700, "start": 3367.0, "end": 3369.0, "text": " Because it's really telling you.", "tokens": [50864, 1436, 309, 311, 534, 3585, 291, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 882, "seek": 335700, "start": 3369.0, "end": 3371.0, "text": " Is your sampling.", "tokens": [50964, 1119, 428, 21179, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 883, "seek": 335700, "start": 3371.0, "end": 3373.0, "text": " Making consistent improvements.", "tokens": [51064, 14595, 8398, 13797, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 884, "seek": 335700, "start": 3373.0, "end": 3375.0, "text": " And to clarify.", "tokens": [51164, 400, 281, 17594, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 885, "seek": 335700, "start": 3375.0, "end": 3377.0, "text": " This is like the predicted denoise sample.", "tokens": [51264, 639, 307, 411, 264, 19147, 1441, 38800, 6889, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 886, "seek": 335700, "start": 3377.0, "end": 3379.0, "text": " At the different stages during sampling right.", "tokens": [51364, 1711, 264, 819, 10232, 1830, 21179, 558, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 887, "seek": 335700, "start": 3379.0, "end": 3381.0, "text": " Yes exactly.", "tokens": [51464, 1079, 2293, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 888, "seek": 335700, "start": 3381.0, "end": 3383.0, "text": " If I was to stop sampling now.", "tokens": [51564, 759, 286, 390, 281, 1590, 21179, 586, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 889, "seek": 335700, "start": 3383.0, "end": 3385.0, "text": " And just go straight to the predicted X error.", "tokens": [51664, 400, 445, 352, 2997, 281, 264, 19147, 1783, 6713, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1894248350885988, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.002396615454927087}, {"id": 890, "seek": 338500, "start": 3385.0, "end": 3387.0, "text": " So I just want to check.", "tokens": [50364, 407, 286, 445, 528, 281, 1520, 13, 50464], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 891, "seek": 338500, "start": 3387.0, "end": 3389.0, "text": " Our samples.", "tokens": [50464, 2621, 10938, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 892, "seek": 338500, "start": 3389.0, "end": 3391.0, "text": " Yeah we preset.", "tokens": [50564, 865, 321, 659, 405, 83, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 893, "seek": 338500, "start": 3391.0, "end": 3393.0, "text": " We add the X not hat at each time.", "tokens": [50664, 492, 909, 264, 1783, 406, 2385, 412, 1184, 565, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 894, "seek": 338500, "start": 3393.0, "end": 3395.0, "text": " Yep.", "tokens": [50764, 7010, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 895, "seek": 338500, "start": 3395.0, "end": 3397.0, "text": " Exactly.", "tokens": [50864, 7587, 13, 50964], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 896, "seek": 338500, "start": 3397.0, "end": 3399.0, "text": " Same for kid.", "tokens": [50964, 10635, 337, 1636, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 897, "seek": 338500, "start": 3399.0, "end": 3401.0, "text": " And I was hoping that they would look the same.", "tokens": [51064, 400, 286, 390, 7159, 300, 436, 576, 574, 264, 912, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 898, "seek": 338500, "start": 3401.0, "end": 3403.0, "text": " And they do.", "tokens": [51164, 400, 436, 360, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 899, "seek": 338500, "start": 3403.0, "end": 3405.0, "text": " So that's encouraging.", "tokens": [51264, 407, 300, 311, 14580, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 900, "seek": 338500, "start": 3405.0, "end": 3407.0, "text": " That kid and fit are basically measuring the same thing.", "tokens": [51364, 663, 1636, 293, 3318, 366, 1936, 13389, 264, 912, 551, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 901, "seek": 338500, "start": 3407.0, "end": 3409.0, "text": " And then something else.", "tokens": [51464, 400, 550, 746, 1646, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 902, "seek": 338500, "start": 3409.0, "end": 3411.0, "text": " That I haven't seen people do.", "tokens": [51564, 663, 286, 2378, 380, 1612, 561, 360, 13, 51664], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 903, "seek": 338500, "start": 3411.0, "end": 3413.0, "text": " But I think it's a very good idea.", "tokens": [51664, 583, 286, 519, 309, 311, 257, 588, 665, 1558, 13, 51764], "temperature": 0.0, "avg_logprob": -0.24111857656705177, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.0027571911923587322}, {"id": 904, "seek": 341300, "start": 3413.0, "end": 3415.0, "text": " To use the same data.", "tokens": [50364, 1407, 764, 264, 912, 1412, 13, 50464], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 905, "seek": 341300, "start": 3415.0, "end": 3417.0, "text": " That you could get.", "tokens": [50464, 663, 291, 727, 483, 13, 50564], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 906, "seek": 341300, "start": 3417.0, "end": 3419.0, "text": " Now that's a bit unfair.", "tokens": [50564, 823, 300, 311, 257, 857, 17019, 13, 50664], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 907, "seek": 341300, "start": 3419.0, "end": 3421.0, "text": " Because I think the different sizes.", "tokens": [50664, 1436, 286, 519, 264, 819, 11602, 13, 50764], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 908, "seek": 341300, "start": 3421.0, "end": 3423.0, "text": " Our data.", "tokens": [50764, 2621, 1412, 13, 50864], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 909, "seek": 341300, "start": 3423.0, "end": 3425.0, "text": " Is 512.", "tokens": [50864, 1119, 1025, 4762, 13, 50964], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 910, "seek": 341300, "start": 3425.0, "end": 3427.0, "text": " Our sample is 256.", "tokens": [50964, 2621, 6889, 307, 38882, 13, 51064], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 911, "seek": 341300, "start": 3427.0, "end": 3429.0, "text": " But anyway it's a pretty huge difference.", "tokens": [51064, 583, 4033, 309, 311, 257, 1238, 2603, 2649, 13, 51164], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 912, "seek": 341300, "start": 3429.0, "end": 3431.0, "text": " And then yeah.", "tokens": [51164, 400, 550, 1338, 13, 51264], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 913, "seek": 341300, "start": 3431.0, "end": 3433.0, "text": " The second thing.", "tokens": [51264, 440, 1150, 551, 13, 51364], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 914, "seek": 341300, "start": 3433.0, "end": 3435.0, "text": " That Tanishka talked about.", "tokens": [51364, 663, 314, 7524, 2330, 2825, 466, 13, 51464], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 915, "seek": 341300, "start": 3435.0, "end": 3437.0, "text": " Which I thought I'd actually show.", "tokens": [51464, 3013, 286, 1194, 286, 1116, 767, 855, 13, 51564], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 916, "seek": 341300, "start": 3437.0, "end": 3439.0, "text": " Is what does it take to use.", "tokens": [51564, 1119, 437, 775, 309, 747, 281, 764, 13, 51664], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 917, "seek": 341300, "start": 3439.0, "end": 3441.0, "text": " You know to get a real fit.", "tokens": [51664, 509, 458, 281, 483, 257, 957, 3318, 13, 51764], "temperature": 0.4, "avg_logprob": -0.29492071400518005, "compression_ratio": 1.4823008849557522, "no_speech_prob": 0.2749520540237427}, {"id": 918, "seek": 344100, "start": 3441.0, "end": 3443.0, "text": " I don't particularly feel like re-implementing the inception network.", "tokens": [50364, 286, 500, 380, 4098, 841, 411, 319, 12, 332, 43704, 278, 264, 49834, 3209, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 919, "seek": 344100, "start": 3443.0, "end": 3445.0, "text": " So I guess I'm cheating here.", "tokens": [50464, 407, 286, 2041, 286, 478, 18309, 510, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 920, "seek": 344100, "start": 3445.0, "end": 3447.0, "text": " I'm just going to grab it from itorchfit.", "tokens": [50564, 286, 478, 445, 516, 281, 4444, 309, 490, 309, 284, 339, 6845, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 921, "seek": 344100, "start": 3447.0, "end": 3449.0, "text": " But there's absolutely no reason.", "tokens": [50664, 583, 456, 311, 3122, 572, 1778, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 922, "seek": 344100, "start": 3449.0, "end": 3451.0, "text": " To study the inception network.", "tokens": [50764, 1407, 2979, 264, 49834, 3209, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 923, "seek": 344100, "start": 3451.0, "end": 3453.0, "text": " Because it's totally obsolete at this point.", "tokens": [50864, 1436, 309, 311, 3879, 46333, 412, 341, 935, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 924, "seek": 344100, "start": 3455.0, "end": 3457.0, "text": " And as Tanishka mentioned.", "tokens": [51064, 400, 382, 314, 7524, 2330, 2835, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 925, "seek": 344100, "start": 3457.0, "end": 3459.0, "text": " It wants 299 by 299 images.", "tokens": [51164, 467, 2738, 568, 8494, 538, 568, 8494, 5267, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 926, "seek": 344100, "start": 3459.0, "end": 3461.0, "text": " Which actually.", "tokens": [51264, 3013, 767, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 927, "seek": 344100, "start": 3461.0, "end": 3463.0, "text": " You can just call resize input.", "tokens": [51364, 509, 393, 445, 818, 50069, 4846, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 928, "seek": 344100, "start": 3463.0, "end": 3465.0, "text": " To have that done for you.", "tokens": [51464, 1407, 362, 300, 1096, 337, 291, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 929, "seek": 344100, "start": 3465.0, "end": 3467.0, "text": " It also expects 3 channel images.", "tokens": [51564, 467, 611, 33280, 805, 2269, 5267, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 930, "seek": 344100, "start": 3467.0, "end": 3469.0, "text": " So what I did.", "tokens": [51664, 407, 437, 286, 630, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1939033624780087, "compression_ratio": 1.5787545787545787, "no_speech_prob": 0.048830654472112656}, {"id": 931, "seek": 346900, "start": 3469.0, "end": 3471.0, "text": " Is I created a wrapper.", "tokens": [50364, 1119, 286, 2942, 257, 46906, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 932, "seek": 346900, "start": 3471.0, "end": 3473.0, "text": " For an inception v3 model.", "tokens": [50464, 1171, 364, 49834, 371, 18, 2316, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 933, "seek": 346900, "start": 3473.0, "end": 3475.0, "text": " That when you call forward.", "tokens": [50564, 663, 562, 291, 818, 2128, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 934, "seek": 346900, "start": 3475.0, "end": 3477.0, "text": " It takes your.", "tokens": [50664, 467, 2516, 428, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 935, "seek": 346900, "start": 3477.0, "end": 3479.0, "text": " Your.", "tokens": [50764, 2260, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 936, "seek": 346900, "start": 3479.0, "end": 3481.0, "text": " Batch.", "tokens": [50864, 363, 852, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 937, "seek": 346900, "start": 3481.0, "end": 3483.0, "text": " And replicates.", "tokens": [50964, 400, 3248, 299, 1024, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 938, "seek": 346900, "start": 3483.0, "end": 3485.0, "text": " The channel.", "tokens": [51064, 440, 2269, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 939, "seek": 346900, "start": 3485.0, "end": 3487.0, "text": " Three times.", "tokens": [51164, 6244, 1413, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 940, "seek": 346900, "start": 3487.0, "end": 3489.0, "text": " So that's basically creating a.", "tokens": [51264, 407, 300, 311, 1936, 4084, 257, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 941, "seek": 346900, "start": 3489.0, "end": 3491.0, "text": " Three channel version of a black and white image.", "tokens": [51364, 6244, 2269, 3037, 295, 257, 2211, 293, 2418, 3256, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 942, "seek": 346900, "start": 3491.0, "end": 3493.0, "text": " Just by replicating it three times.", "tokens": [51464, 1449, 538, 3248, 30541, 309, 1045, 1413, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 943, "seek": 346900, "start": 3493.0, "end": 3495.0, "text": " So with that.", "tokens": [51564, 407, 365, 300, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 944, "seek": 346900, "start": 3495.0, "end": 3497.0, "text": " Wrapping and again.", "tokens": [51664, 343, 424, 3759, 293, 797, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18874784616323617, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0021154589485377073}, {"id": 945, "seek": 349700, "start": 3497.0, "end": 3499.0, "text": " This is good like flexing.", "tokens": [50364, 639, 307, 665, 411, 5896, 278, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 946, "seek": 349700, "start": 3499.0, "end": 3501.0, "text": " Of your PyTorch muscles.", "tokens": [50464, 2720, 428, 9953, 51, 284, 339, 9530, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 947, "seek": 349700, "start": 3501.0, "end": 3503.0, "text": " You know try to make sure.", "tokens": [50564, 509, 458, 853, 281, 652, 988, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 948, "seek": 349700, "start": 3503.0, "end": 3505.0, "text": " You can replicate this.", "tokens": [50664, 509, 393, 25356, 341, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 949, "seek": 349700, "start": 3505.0, "end": 3507.0, "text": " That you can.", "tokens": [50764, 663, 291, 393, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 950, "seek": 349700, "start": 3507.0, "end": 3509.0, "text": " Get an inception model.", "tokens": [50864, 3240, 364, 49834, 2316, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 951, "seek": 349700, "start": 3509.0, "end": 3511.0, "text": " Working on your.", "tokens": [50964, 18337, 322, 428, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 952, "seek": 349700, "start": 3511.0, "end": 3513.0, "text": " Bash and MNIST samples.", "tokens": [51064, 43068, 293, 376, 45, 19756, 10938, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 953, "seek": 349700, "start": 3513.0, "end": 3515.0, "text": " And yeah.", "tokens": [51164, 400, 1338, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 954, "seek": 349700, "start": 3515.0, "end": 3517.0, "text": " Then from there.", "tokens": [51264, 1396, 490, 456, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 955, "seek": 349700, "start": 3517.0, "end": 3519.0, "text": " We can just pass that.", "tokens": [51364, 492, 393, 445, 1320, 300, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 956, "seek": 349700, "start": 3519.0, "end": 3521.0, "text": " To our image eval instead.", "tokens": [51464, 1407, 527, 3256, 1073, 304, 2602, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 957, "seek": 349700, "start": 3521.0, "end": 3523.0, "text": " And so on our samples.", "tokens": [51564, 400, 370, 322, 527, 10938, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 958, "seek": 349700, "start": 3523.0, "end": 3525.0, "text": " That gives us 63.8.", "tokens": [51664, 663, 2709, 505, 25082, 13, 23, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19908469807017934, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.003944714087992907}, {"id": 959, "seek": 352500, "start": 3525.0, "end": 3527.0, "text": " And on a real batch of data.", "tokens": [50364, 400, 322, 257, 957, 15245, 295, 1412, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 960, "seek": 352500, "start": 3527.0, "end": 3529.0, "text": " It gets 27.9.", "tokens": [50464, 467, 2170, 7634, 13, 24, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 961, "seek": 352500, "start": 3529.0, "end": 3531.0, "text": " And like I find this.", "tokens": [50564, 400, 411, 286, 915, 341, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 962, "seek": 352500, "start": 3531.0, "end": 3533.0, "text": " Like a good sign.", "tokens": [50664, 1743, 257, 665, 1465, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 963, "seek": 352500, "start": 3533.0, "end": 3535.0, "text": " That this is much less effective.", "tokens": [50764, 663, 341, 307, 709, 1570, 4942, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 964, "seek": 352500, "start": 3535.0, "end": 3537.0, "text": " Than our real fashioned MNIST classifier.", "tokens": [50864, 18289, 527, 957, 40646, 376, 45, 19756, 1508, 9902, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 965, "seek": 352500, "start": 3537.0, "end": 3539.0, "text": " Because like that's only.", "tokens": [50964, 1436, 411, 300, 311, 787, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 966, "seek": 352500, "start": 3539.0, "end": 3541.0, "text": " You know difference of.", "tokens": [51064, 509, 458, 2649, 295, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 967, "seek": 352500, "start": 3541.0, "end": 3543.0, "text": " A ratio of three or so.", "tokens": [51164, 316, 8509, 295, 1045, 420, 370, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 968, "seek": 352500, "start": 3543.0, "end": 3545.0, "text": " You know the fact that our.", "tokens": [51264, 509, 458, 264, 1186, 300, 527, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 969, "seek": 352500, "start": 3545.0, "end": 3547.0, "text": " Fid.", "tokens": [51364, 479, 327, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 970, "seek": 352500, "start": 3547.0, "end": 3549.0, "text": " For real data.", "tokens": [51464, 1171, 957, 1412, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 971, "seek": 352500, "start": 3549.0, "end": 3551.0, "text": " Using a real classifier.", "tokens": [51564, 11142, 257, 957, 1508, 9902, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 972, "seek": 352500, "start": 3551.0, "end": 3553.0, "text": " With 6.6.", "tokens": [51664, 2022, 1386, 13, 21, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21759137692658798, "compression_ratio": 1.4928909952606635, "no_speech_prob": 0.040836602449417114}, {"id": 973, "seek": 355300, "start": 3553.0, "end": 3555.0, "text": " Yeah.", "tokens": [50364, 865, 13, 50464], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 974, "seek": 355300, "start": 3555.0, "end": 3557.0, "text": " So that is.", "tokens": [50464, 407, 300, 307, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 975, "seek": 355300, "start": 3557.0, "end": 3559.0, "text": " That and.", "tokens": [50564, 663, 293, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 976, "seek": 355300, "start": 3559.0, "end": 3561.0, "text": " We now have a Fid.", "tokens": [50664, 492, 586, 362, 257, 479, 327, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 977, "seek": 355300, "start": 3561.0, "end": 3563.0, "text": " More specifically we now have an image eval.", "tokens": [50764, 5048, 4682, 321, 586, 362, 364, 3256, 1073, 304, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 978, "seek": 355300, "start": 3563.0, "end": 3565.0, "text": " Class.", "tokens": [50864, 9471, 13, 50964], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 979, "seek": 355300, "start": 3565.0, "end": 3567.0, "text": " Did you guys have any.", "tokens": [50964, 2589, 291, 1074, 362, 604, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 980, "seek": 355300, "start": 3567.0, "end": 3569.0, "text": " Questions or comments about that.", "tokens": [51064, 27738, 420, 3053, 466, 300, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 981, "seek": 355300, "start": 3569.0, "end": 3571.0, "text": " Before we keep going.", "tokens": [51164, 4546, 321, 1066, 516, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 982, "seek": 355300, "start": 3571.0, "end": 3573.0, "text": " No.", "tokens": [51264, 883, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 983, "seek": 355300, "start": 3573.0, "end": 3575.0, "text": " Let's just say again that.", "tokens": [51364, 961, 311, 445, 584, 797, 300, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 984, "seek": 355300, "start": 3575.0, "end": 3577.0, "text": " Pretty much every other Fid you see.", "tokens": [51464, 10693, 709, 633, 661, 479, 327, 291, 536, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 985, "seek": 355300, "start": 3577.0, "end": 3579.0, "text": " Reported is going to be.", "tokens": [51564, 3696, 14813, 307, 516, 281, 312, 13, 51664], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 986, "seek": 355300, "start": 3579.0, "end": 3581.0, "text": " You know set up for CIFAR 10.", "tokens": [51664, 509, 458, 992, 493, 337, 383, 12775, 1899, 1266, 13, 51764], "temperature": 0.0, "avg_logprob": -0.24726234782825818, "compression_ratio": 1.4150943396226414, "no_speech_prob": 0.000842587323859334}, {"id": 987, "seek": 358100, "start": 3581.0, "end": 3583.0, "text": " Tiny 32 by 32 pixels.", "tokens": [50364, 39992, 8858, 538, 8858, 18668, 13, 50464], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 988, "seek": 358100, "start": 3583.0, "end": 3585.0, "text": " Resized up to 299.", "tokens": [50464, 5015, 1602, 493, 281, 568, 8494, 13, 50564], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 989, "seek": 358100, "start": 3585.0, "end": 3587.0, "text": " And Fid through inception.", "tokens": [50564, 400, 479, 327, 807, 49834, 13, 50664], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 990, "seek": 358100, "start": 3587.0, "end": 3589.0, "text": " That was trained on an image.", "tokens": [50664, 663, 390, 8895, 322, 364, 3256, 13, 50764], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 991, "seek": 358100, "start": 3589.0, "end": 3591.0, "text": " Not CIFAR 10.", "tokens": [50764, 1726, 383, 12775, 1899, 1266, 13, 50864], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 992, "seek": 358100, "start": 3591.0, "end": 3593.0, "text": " So yeah it's bearing in mind that.", "tokens": [50864, 407, 1338, 309, 311, 17350, 294, 1575, 300, 13, 50964], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 993, "seek": 358100, "start": 3593.0, "end": 3595.0, "text": " Once again this is a slightly weird metric.", "tokens": [50964, 3443, 797, 341, 307, 257, 4748, 3657, 20678, 13, 51064], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 994, "seek": 358100, "start": 3595.0, "end": 3597.0, "text": " And even things like.", "tokens": [51064, 400, 754, 721, 411, 13, 51164], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 995, "seek": 358100, "start": 3597.0, "end": 3599.0, "text": " The types of image.", "tokens": [51164, 440, 3467, 295, 3256, 13, 51264], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 996, "seek": 358100, "start": 3599.0, "end": 3601.0, "text": " Like the image resizing algorithms.", "tokens": [51264, 1743, 264, 3256, 725, 3319, 14642, 13, 51364], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 997, "seek": 358100, "start": 3601.0, "end": 3603.0, "text": " In PyTorch and TensorFlow.", "tokens": [51364, 682, 9953, 51, 284, 339, 293, 37624, 13, 51464], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 998, "seek": 358100, "start": 3603.0, "end": 3605.0, "text": " Might be slightly different.", "tokens": [51464, 23964, 312, 4748, 819, 13, 51564], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 999, "seek": 358100, "start": 3605.0, "end": 3607.0, "text": " Or you know if you saved your images as JPEGs.", "tokens": [51564, 1610, 291, 458, 498, 291, 6624, 428, 5267, 382, 508, 5208, 33715, 13, 51664], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 1000, "seek": 358100, "start": 3607.0, "end": 3609.0, "text": " And then reloaded them.", "tokens": [51664, 400, 550, 25628, 292, 552, 13, 51764], "temperature": 0.0, "avg_logprob": -0.28039349696432897, "compression_ratio": 1.4794007490636705, "no_speech_prob": 0.06753139197826385}, {"id": 1001, "seek": 360900, "start": 3609.0, "end": 3611.0, "text": " So just to reiterate.", "tokens": [50364, 407, 445, 281, 33528, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1002, "seek": 360900, "start": 3611.0, "end": 3613.0, "text": " What this will like.", "tokens": [50464, 708, 341, 486, 411, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1003, "seek": 360900, "start": 3613.0, "end": 3615.0, "text": " The takeaway from all of this that I get.", "tokens": [50564, 440, 30681, 490, 439, 295, 341, 300, 286, 483, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1004, "seek": 360900, "start": 3615.0, "end": 3617.0, "text": " Is that it's really useful.", "tokens": [50664, 1119, 300, 309, 311, 534, 4420, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1005, "seek": 360900, "start": 3617.0, "end": 3619.0, "text": " Everything's the same.", "tokens": [50764, 5471, 311, 264, 912, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1006, "seek": 360900, "start": 3619.0, "end": 3621.0, "text": " Like using the same backbone model.", "tokens": [50864, 1743, 1228, 264, 912, 34889, 2316, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1007, "seek": 360900, "start": 3621.0, "end": 3623.0, "text": " Using the same approach.", "tokens": [50964, 11142, 264, 912, 3109, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1008, "seek": 360900, "start": 3623.0, "end": 3625.0, "text": " The same number of samples.", "tokens": [51064, 440, 912, 1230, 295, 10938, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1009, "seek": 360900, "start": 3625.0, "end": 3627.0, "text": " Then you can compare it's apples to apples.", "tokens": [51164, 1396, 291, 393, 6794, 309, 311, 16814, 281, 16814, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1010, "seek": 360900, "start": 3627.0, "end": 3629.0, "text": " But yeah for one set of experiments.", "tokens": [51264, 583, 1338, 337, 472, 992, 295, 12050, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1011, "seek": 360900, "start": 3629.0, "end": 3631.0, "text": " A Fid of 30 might be good.", "tokens": [51364, 316, 479, 327, 295, 2217, 1062, 312, 665, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1012, "seek": 360900, "start": 3631.0, "end": 3633.0, "text": " Because of the way everything's set up.", "tokens": [51464, 1436, 295, 264, 636, 1203, 311, 992, 493, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1013, "seek": 360900, "start": 3633.0, "end": 3635.0, "text": " And for another that might be terrible.", "tokens": [51564, 400, 337, 1071, 300, 1062, 312, 6237, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1014, "seek": 360900, "start": 3635.0, "end": 3637.0, "text": " So trying to compare to paper or whatever.", "tokens": [51664, 407, 1382, 281, 6794, 281, 3035, 420, 2035, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23020291149168087, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.14217452704906464}, {"id": 1015, "seek": 363700, "start": 3637.0, "end": 3639.0, "text": " So I'm going to.", "tokens": [50364, 407, 286, 478, 516, 281, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1016, "seek": 363700, "start": 3639.0, "end": 3641.0, "text": " Maybe the approach.", "tokens": [50464, 2704, 264, 3109, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1017, "seek": 363700, "start": 3641.0, "end": 3643.0, "text": " Is that like if you're doing your own experiments.", "tokens": [50564, 1119, 300, 411, 498, 291, 434, 884, 428, 1065, 12050, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1018, "seek": 363700, "start": 3643.0, "end": 3645.0, "text": " You know these sorts of metrics are good.", "tokens": [50664, 509, 458, 613, 7527, 295, 16367, 366, 665, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1019, "seek": 363700, "start": 3645.0, "end": 3647.0, "text": " But then if you're going to compare to other models.", "tokens": [50764, 583, 550, 498, 291, 434, 516, 281, 6794, 281, 661, 5245, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1020, "seek": 363700, "start": 3647.0, "end": 3649.0, "text": " It's best to rely on human studies.", "tokens": [50864, 467, 311, 1151, 281, 10687, 322, 1952, 5313, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1021, "seek": 363700, "start": 3649.0, "end": 3651.0, "text": " If you're comparing to other models.", "tokens": [50964, 759, 291, 434, 15763, 281, 661, 5245, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1022, "seek": 363700, "start": 3651.0, "end": 3653.0, "text": " And that yeah I think that's kind of the.", "tokens": [51064, 400, 300, 1338, 286, 519, 300, 311, 733, 295, 264, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1023, "seek": 363700, "start": 3653.0, "end": 3655.0, "text": " The sort of.", "tokens": [51164, 440, 1333, 295, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1024, "seek": 363700, "start": 3655.0, "end": 3657.0, "text": " Approach or mindset that.", "tokens": [51264, 29551, 608, 420, 12543, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1025, "seek": 363700, "start": 3657.0, "end": 3659.0, "text": " We should be having when it comes to this.", "tokens": [51364, 492, 820, 312, 1419, 562, 309, 1487, 281, 341, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1026, "seek": 363700, "start": 3659.0, "end": 3661.0, "text": " Yeah or both you know.", "tokens": [51464, 865, 420, 1293, 291, 458, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1027, "seek": 363700, "start": 3661.0, "end": 3663.0, "text": " But yeah so we're going to see this is going to be.", "tokens": [51564, 583, 1338, 370, 321, 434, 516, 281, 536, 341, 307, 516, 281, 312, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1028, "seek": 363700, "start": 3663.0, "end": 3665.0, "text": " Very useful for us.", "tokens": [51664, 4372, 4420, 337, 505, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2084064352101293, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.042697299271821976}, {"id": 1029, "seek": 366500, "start": 3665.0, "end": 3667.0, "text": " And we're going to be using.", "tokens": [50364, 400, 321, 434, 516, 281, 312, 1228, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1030, "seek": 366500, "start": 3667.0, "end": 3669.0, "text": " The same.", "tokens": [50464, 440, 912, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1031, "seek": 366500, "start": 3669.0, "end": 3671.0, "text": " Pretty much all the time we're going to use the same.", "tokens": [50564, 10693, 709, 439, 264, 565, 321, 434, 516, 281, 764, 264, 912, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1032, "seek": 366500, "start": 3671.0, "end": 3673.0, "text": " Number of samples and we're going to use the same.", "tokens": [50664, 5118, 295, 10938, 293, 321, 434, 516, 281, 764, 264, 912, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1033, "seek": 366500, "start": 3673.0, "end": 3675.0, "text": " Fashion MNIST specific classifier.", "tokens": [50764, 32782, 376, 45, 19756, 2685, 1508, 9902, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1034, "seek": 366500, "start": 3675.0, "end": 3677.0, "text": " So.", "tokens": [50864, 407, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1035, "seek": 366500, "start": 3677.0, "end": 3679.0, "text": " The first thing I wanted to do was fix our bug.", "tokens": [50964, 440, 700, 551, 286, 1415, 281, 360, 390, 3191, 527, 7426, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1036, "seek": 366500, "start": 3679.0, "end": 3681.0, "text": " And to remind you.", "tokens": [51064, 400, 281, 4160, 291, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1037, "seek": 366500, "start": 3681.0, "end": 3683.0, "text": " The bug was that we.", "tokens": [51164, 440, 7426, 390, 300, 321, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1038, "seek": 366500, "start": 3683.0, "end": 3685.0, "text": " Had we were feeding into our.", "tokens": [51264, 12298, 321, 645, 12919, 666, 527, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1039, "seek": 366500, "start": 3685.0, "end": 3687.0, "text": " Unit in DDPM v2.", "tokens": [51364, 27894, 294, 413, 11373, 44, 371, 17, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1040, "seek": 366500, "start": 3687.0, "end": 3689.0, "text": " And the original DDPM.", "tokens": [51464, 400, 264, 3380, 413, 11373, 44, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1041, "seek": 366500, "start": 3689.0, "end": 3691.0, "text": " Images that were from 0 to 1.", "tokens": [51564, 4331, 1660, 300, 645, 490, 1958, 281, 502, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1042, "seek": 366500, "start": 3691.0, "end": 3693.0, "text": " And yeah.", "tokens": [51664, 400, 1338, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2478972413486108, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.15191017091274261}, {"id": 1043, "seek": 369300, "start": 3693.0, "end": 3695.0, "text": " That's that's wrong.", "tokens": [50364, 663, 311, 300, 311, 2085, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1044, "seek": 369300, "start": 3695.0, "end": 3697.0, "text": " That's like nobody does that.", "tokens": [50464, 663, 311, 411, 5079, 775, 300, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1045, "seek": 369300, "start": 3697.0, "end": 3699.0, "text": " Everybody feeds in images that are from minus.", "tokens": [50564, 7646, 23712, 294, 5267, 300, 366, 490, 3175, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1046, "seek": 369300, "start": 3699.0, "end": 3701.0, "text": " 1 to 1.", "tokens": [50664, 502, 281, 502, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1047, "seek": 369300, "start": 3701.0, "end": 3703.0, "text": " So that's very easy to fix.", "tokens": [50764, 407, 300, 311, 588, 1858, 281, 3191, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1048, "seek": 369300, "start": 3703.0, "end": 3705.0, "text": " You just.", "tokens": [50864, 509, 445, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1049, "seek": 369300, "start": 3705.0, "end": 3707.0, "text": " Jeremy just to ask like what why.", "tokens": [50964, 17809, 445, 281, 1029, 411, 437, 983, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1050, "seek": 369300, "start": 3707.0, "end": 3709.0, "text": " Is that a bug.", "tokens": [51064, 1119, 300, 257, 7426, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1051, "seek": 369300, "start": 3709.0, "end": 3711.0, "text": " Why is a bug I mean it's like everybody.", "tokens": [51164, 1545, 307, 257, 7426, 286, 914, 309, 311, 411, 2201, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1052, "seek": 369300, "start": 3711.0, "end": 3713.0, "text": " Knows it's a bug because that's what everybody does.", "tokens": [51264, 10519, 1509, 309, 311, 257, 7426, 570, 300, 311, 437, 2201, 775, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1053, "seek": 369300, "start": 3713.0, "end": 3715.0, "text": " Like I've never seen anybody do anything.", "tokens": [51364, 1743, 286, 600, 1128, 1612, 4472, 360, 1340, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1054, "seek": 369300, "start": 3715.0, "end": 3717.0, "text": " Else and it's very easy to fix.", "tokens": [51464, 45472, 293, 309, 311, 588, 1858, 281, 3191, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1055, "seek": 369300, "start": 3717.0, "end": 3719.0, "text": " So I fixed it by adding this to.", "tokens": [51564, 407, 286, 6806, 309, 538, 5127, 341, 281, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1056, "seek": 369300, "start": 3719.0, "end": 3721.0, "text": " DDPM v2.", "tokens": [51664, 413, 11373, 44, 371, 17, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23025489027482748, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.0009398877737112343}, {"id": 1057, "seek": 372100, "start": 3721.0, "end": 3723.0, "text": " And I reran it.", "tokens": [50364, 400, 286, 43819, 282, 309, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1058, "seek": 372100, "start": 3723.0, "end": 3725.0, "text": " And it didn't work.", "tokens": [50464, 400, 309, 994, 380, 589, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1059, "seek": 372100, "start": 3725.0, "end": 3727.0, "text": " It made it worse.", "tokens": [50564, 467, 1027, 309, 5324, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1060, "seek": 372100, "start": 3727.0, "end": 3729.0, "text": " And.", "tokens": [50664, 400, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1061, "seek": 372100, "start": 3729.0, "end": 3731.0, "text": " This was the start.", "tokens": [50764, 639, 390, 264, 722, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1062, "seek": 372100, "start": 3731.0, "end": 3733.0, "text": " Of.", "tokens": [50864, 2720, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1063, "seek": 372100, "start": 3733.0, "end": 3735.0, "text": " You know a few horrible days.", "tokens": [50964, 509, 458, 257, 1326, 9263, 1708, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1064, "seek": 372100, "start": 3735.0, "end": 3737.0, "text": " Of pain because.", "tokens": [51064, 2720, 1822, 570, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1065, "seek": 372100, "start": 3737.0, "end": 3739.0, "text": " Like when you.", "tokens": [51164, 1743, 562, 291, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1066, "seek": 372100, "start": 3739.0, "end": 3741.0, "text": " You know.", "tokens": [51264, 509, 458, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1067, "seek": 372100, "start": 3741.0, "end": 3743.0, "text": " Fix a bug and it makes things worse.", "tokens": [51364, 25538, 257, 7426, 293, 309, 1669, 721, 5324, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1068, "seek": 372100, "start": 3743.0, "end": 3745.0, "text": " That generally suggests there's some other bug.", "tokens": [51464, 663, 5101, 13409, 456, 311, 512, 661, 7426, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1069, "seek": 372100, "start": 3745.0, "end": 3747.0, "text": " Somewhere else that somehow is offset.", "tokens": [51564, 34500, 1646, 300, 6063, 307, 18687, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1070, "seek": 372100, "start": 3747.0, "end": 3749.0, "text": " Your first bargain.", "tokens": [51664, 2260, 700, 34302, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2003040313720703, "compression_ratio": 1.4825870646766168, "no_speech_prob": 0.0024342138785868883}, {"id": 1071, "seek": 374900, "start": 3749.0, "end": 3751.0, "text": " You know I basically went back through every other.", "tokens": [50364, 509, 458, 286, 1936, 1437, 646, 807, 633, 661, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1072, "seek": 374900, "start": 3751.0, "end": 3753.0, "text": " Notebook.", "tokens": [50464, 11633, 2939, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1073, "seek": 374900, "start": 3753.0, "end": 3755.0, "text": " And every cell.", "tokens": [50564, 400, 633, 2815, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1074, "seek": 374900, "start": 3755.0, "end": 3757.0, "text": " And I did find at least one.", "tokens": [50664, 400, 286, 630, 915, 412, 1935, 472, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1075, "seek": 374900, "start": 3757.0, "end": 3759.0, "text": " Bug.", "tokens": [50764, 23821, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1076, "seek": 374900, "start": 3759.0, "end": 3761.0, "text": " Elsewhere which is that we hadn't been shuffling.", "tokens": [50864, 45472, 1992, 597, 307, 300, 321, 8782, 380, 668, 402, 1245, 1688, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1077, "seek": 374900, "start": 3761.0, "end": 3763.0, "text": " Our training sets the whole time.", "tokens": [50964, 2621, 3097, 6352, 264, 1379, 565, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1078, "seek": 374900, "start": 3763.0, "end": 3765.0, "text": " So I fixed that.", "tokens": [51064, 407, 286, 6806, 300, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1079, "seek": 374900, "start": 3765.0, "end": 3767.0, "text": " But it's got absolutely nothing to do with this.", "tokens": [51164, 583, 309, 311, 658, 3122, 1825, 281, 360, 365, 341, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1080, "seek": 374900, "start": 3767.0, "end": 3769.0, "text": " And I ended up going through everything from scratch.", "tokens": [51264, 400, 286, 4590, 493, 516, 807, 1203, 490, 8459, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1081, "seek": 374900, "start": 3769.0, "end": 3771.0, "text": " Three times.", "tokens": [51364, 6244, 1413, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1082, "seek": 374900, "start": 3771.0, "end": 3773.0, "text": " Rerunning everything three times checking every intermediate.", "tokens": [51464, 497, 260, 25589, 1203, 1045, 1413, 8568, 633, 19376, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1083, "seek": 374900, "start": 3773.0, "end": 3775.0, "text": " Output three times so days of.", "tokens": [51564, 5925, 2582, 1045, 1413, 370, 1708, 295, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1084, "seek": 374900, "start": 3775.0, "end": 3777.0, "text": " You know.", "tokens": [51664, 509, 458, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20245469461275836, "compression_ratio": 1.68359375, "no_speech_prob": 0.0695122629404068}, {"id": 1085, "seek": 377700, "start": 3777.0, "end": 3779.0, "text": " No progress at all.", "tokens": [50364, 220, 4540, 4205, 412, 439, 13, 50464], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1086, "seek": 377700, "start": 3779.0, "end": 3781.0, "text": " At which point.", "tokens": [50464, 1711, 597, 935, 13, 50564], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1087, "seek": 377700, "start": 3781.0, "end": 3783.0, "text": " I then asked.", "tokens": [50564, 286, 550, 2351, 13, 50664], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1088, "seek": 377700, "start": 3783.0, "end": 3785.0, "text": " John O's question to myself.", "tokens": [50664, 2619, 422, 311, 1168, 281, 2059, 13, 50764], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1089, "seek": 377700, "start": 3785.0, "end": 3787.0, "text": " More carefully and provided a less.", "tokens": [50764, 5048, 7500, 293, 5649, 257, 1570, 13, 50864], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1090, "seek": 377700, "start": 3787.0, "end": 3789.0, "text": " Flippant response to myself.", "tokens": [50864, 479, 2081, 427, 394, 4134, 281, 2059, 13, 50964], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1091, "seek": 377700, "start": 3789.0, "end": 3791.0, "text": " Which was.", "tokens": [50964, 3013, 390, 13, 51064], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1092, "seek": 377700, "start": 3791.0, "end": 3793.0, "text": " Well I don't know why everybody does this.", "tokens": [51064, 1042, 286, 500, 380, 458, 983, 2201, 775, 341, 13, 51164], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1093, "seek": 377700, "start": 3793.0, "end": 3795.0, "text": " Actually.", "tokens": [51164, 5135, 13, 51264], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1094, "seek": 377700, "start": 3795.0, "end": 3797.0, "text": " So I asked.", "tokens": [51264, 407, 286, 2351, 13, 51364], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1095, "seek": 377700, "start": 3797.0, "end": 3799.0, "text": " Anish can John O and I was like.", "tokens": [51364, 1107, 742, 393, 2619, 422, 293, 286, 390, 411, 13, 51464], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1096, "seek": 377700, "start": 3799.0, "end": 3801.0, "text": " And Pedro and I was like.", "tokens": [51464, 400, 26662, 293, 286, 390, 411, 13, 51564], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1097, "seek": 377700, "start": 3801.0, "end": 3803.0, "text": " If you guys seen any.", "tokens": [51564, 759, 291, 1074, 1612, 604, 13, 51664], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1098, "seek": 377700, "start": 3803.0, "end": 3805.0, "text": " Math papers.", "tokens": [51664, 15776, 10577, 13, 51764], "temperature": 0.2, "avg_logprob": -0.39554186984225437, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.31353530287742615}, {"id": 1099, "seek": 380500, "start": 3805.0, "end": 3807.0, "text": " Whatever.", "tokens": [50364, 8541, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1100, "seek": 380500, "start": 3807.0, "end": 3809.0, "text": " That's based on.", "tokens": [50464, 663, 311, 2361, 322, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1101, "seek": 380500, "start": 3809.0, "end": 3811.0, "text": " This particular.", "tokens": [50564, 639, 1729, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1102, "seek": 380500, "start": 3811.0, "end": 3813.0, "text": " Input range.", "tokens": [50664, 682, 2582, 3613, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1103, "seek": 380500, "start": 3813.0, "end": 3815.0, "text": " And yeah.", "tokens": [50764, 400, 1338, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1104, "seek": 380500, "start": 3815.0, "end": 3817.0, "text": " You guys are both like.", "tokens": [50864, 509, 1074, 366, 1293, 411, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1105, "seek": 380500, "start": 3817.0, "end": 3819.0, "text": " No I haven't.", "tokens": [50964, 883, 286, 2378, 380, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1106, "seek": 380500, "start": 3819.0, "end": 3821.0, "text": " It's just what everybody does.", "tokens": [51064, 467, 311, 445, 437, 2201, 775, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1107, "seek": 380500, "start": 3821.0, "end": 3823.0, "text": " So.", "tokens": [51164, 407, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1108, "seek": 380500, "start": 3823.0, "end": 3825.0, "text": " At that point.", "tokens": [51264, 1711, 300, 935, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1109, "seek": 380500, "start": 3825.0, "end": 3827.0, "text": " It raised the possibility that like.", "tokens": [51364, 467, 6005, 264, 7959, 300, 411, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1110, "seek": 380500, "start": 3827.0, "end": 3829.0, "text": " Okay maybe.", "tokens": [51464, 1033, 1310, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1111, "seek": 380500, "start": 3829.0, "end": 3831.0, "text": " Maybe what everybody does is not the right thing to do.", "tokens": [51564, 2704, 437, 2201, 775, 307, 406, 264, 558, 551, 281, 360, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1112, "seek": 380500, "start": 3831.0, "end": 3833.0, "text": " And.", "tokens": [51664, 400, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18185579400313528, "compression_ratio": 1.5, "no_speech_prob": 0.0005110659985803068}, {"id": 1113, "seek": 383300, "start": 3833.0, "end": 3835.0, "text": " Is there any reason to believe it is the right thing to do.", "tokens": [50364, 1119, 456, 604, 1778, 281, 1697, 309, 307, 264, 558, 551, 281, 360, 13, 50464], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1114, "seek": 383300, "start": 3837.0, "end": 3839.0, "text": " And given that it seemed like fixing the bug.", "tokens": [50564, 400, 2212, 300, 309, 6576, 411, 19442, 264, 7426, 13, 50664], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1115, "seek": 383300, "start": 3839.0, "end": 3841.0, "text": " Made it worse.", "tokens": [50664, 18330, 309, 5324, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1116, "seek": 383300, "start": 3841.0, "end": 3843.0, "text": " Maybe not.", "tokens": [50764, 2704, 406, 13, 50864], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1117, "seek": 383300, "start": 3843.0, "end": 3845.0, "text": " And then but then it's like well.", "tokens": [50864, 400, 550, 457, 550, 309, 311, 411, 731, 13, 50964], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1118, "seek": 383300, "start": 3845.0, "end": 3847.0, "text": " Okay we are pretty confident.", "tokens": [50964, 1033, 321, 366, 1238, 6679, 13, 51064], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1119, "seek": 383300, "start": 3847.0, "end": 3849.0, "text": " From everything we've learned and discussed.", "tokens": [51064, 3358, 1203, 321, 600, 3264, 293, 7152, 13, 51164], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1120, "seek": 383300, "start": 3849.0, "end": 3851.0, "text": " That having centered data is better than.", "tokens": [51164, 663, 1419, 18988, 1412, 307, 1101, 813, 13, 51264], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1121, "seek": 383300, "start": 3851.0, "end": 3853.0, "text": " Uncentered data.", "tokens": [51264, 1156, 36814, 1412, 13, 51364], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1122, "seek": 383300, "start": 3853.0, "end": 3855.0, "text": " So having data that go from zero to one.", "tokens": [51364, 407, 1419, 1412, 300, 352, 490, 4018, 281, 472, 13, 51464], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1123, "seek": 383300, "start": 3855.0, "end": 3857.0, "text": " Clearly seems weird.", "tokens": [51464, 24120, 2544, 3657, 13, 51564], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1124, "seek": 383300, "start": 3857.0, "end": 3859.0, "text": " So maybe the issue is not that we've changed.", "tokens": [51564, 407, 1310, 264, 2734, 307, 406, 300, 321, 600, 3105, 13, 51664], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1125, "seek": 383300, "start": 3859.0, "end": 3861.0, "text": " The center but that we've scaled it down.", "tokens": [51664, 440, 3056, 457, 300, 321, 600, 36039, 309, 760, 13, 51764], "temperature": 0.0, "avg_logprob": -0.22078573241714358, "compression_ratio": 1.6943396226415095, "no_speech_prob": 0.0018675189930945635}, {"id": 1126, "seek": 386100, "start": 3861.0, "end": 3863.0, "text": " So rather than having a range of two.", "tokens": [50364, 407, 2831, 813, 1419, 257, 3613, 295, 732, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1127, "seek": 386100, "start": 3863.0, "end": 3865.0, "text": " It's got a range of one.", "tokens": [50464, 467, 311, 658, 257, 3613, 295, 472, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1128, "seek": 386100, "start": 3865.0, "end": 3867.0, "text": " So at that point.", "tokens": [50564, 407, 412, 300, 935, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1129, "seek": 386100, "start": 3867.0, "end": 3869.0, "text": " You know.", "tokens": [50664, 509, 458, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1130, "seek": 386100, "start": 3869.0, "end": 3871.0, "text": " I did something very simple.", "tokens": [50764, 286, 630, 746, 588, 2199, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1131, "seek": 386100, "start": 3871.0, "end": 3873.0, "text": " Which was I.", "tokens": [50864, 3013, 390, 286, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1132, "seek": 386100, "start": 3875.0, "end": 3877.0, "text": " Did this.", "tokens": [51064, 2589, 341, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1133, "seek": 386100, "start": 3877.0, "end": 3879.0, "text": " I subtracted point five.", "tokens": [51164, 286, 16390, 292, 935, 1732, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1134, "seek": 386100, "start": 3879.0, "end": 3881.0, "text": " So now rather than going from naught to one.", "tokens": [51264, 407, 586, 2831, 813, 516, 490, 13138, 281, 472, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1135, "seek": 386100, "start": 3881.0, "end": 3883.0, "text": " It goes from minus point five.", "tokens": [51364, 467, 1709, 490, 3175, 935, 1732, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1136, "seek": 386100, "start": 3883.0, "end": 3885.0, "text": " To point five and so the theory.", "tokens": [51464, 1407, 935, 1732, 293, 370, 264, 5261, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1137, "seek": 386100, "start": 3885.0, "end": 3887.0, "text": " Here then was okay if.", "tokens": [51564, 1692, 550, 390, 1392, 498, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1138, "seek": 386100, "start": 3887.0, "end": 3889.0, "text": " Our hypothesis is correct.", "tokens": [51664, 2621, 17291, 307, 3006, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19385351958098235, "compression_ratio": 1.63, "no_speech_prob": 0.0007793143740855157}, {"id": 1139, "seek": 388900, "start": 3889.0, "end": 3891.0, "text": " The negative one to one range has no.", "tokens": [50364, 440, 3671, 472, 281, 472, 3613, 575, 572, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1140, "seek": 388900, "start": 3893.0, "end": 3895.0, "text": " Foundational reason for being.", "tokens": [50564, 8207, 1478, 1778, 337, 885, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1141, "seek": 388900, "start": 3895.0, "end": 3897.0, "text": " And we've accidentally hit on something.", "tokens": [50664, 400, 321, 600, 15715, 2045, 322, 746, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1142, "seek": 388900, "start": 3897.0, "end": 3899.0, "text": " Which is that a range of one is better than a range of two.", "tokens": [50764, 3013, 307, 300, 257, 3613, 295, 472, 307, 1101, 813, 257, 3613, 295, 732, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1143, "seek": 388900, "start": 3899.0, "end": 3901.0, "text": " And this should be better still.", "tokens": [50864, 400, 341, 820, 312, 1101, 920, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1144, "seek": 388900, "start": 3901.0, "end": 3903.0, "text": " Because this is a range of one.", "tokens": [50964, 1436, 341, 307, 257, 3613, 295, 472, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1145, "seek": 388900, "start": 3903.0, "end": 3905.0, "text": " And it's centered properly.", "tokens": [51064, 400, 309, 311, 18988, 6108, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1146, "seek": 388900, "start": 3905.0, "end": 3907.0, "text": " And so this is DDPM v3.", "tokens": [51164, 400, 370, 341, 307, 413, 11373, 44, 371, 18, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1147, "seek": 388900, "start": 3907.0, "end": 3909.0, "text": " And I ran that.", "tokens": [51264, 400, 286, 5872, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1148, "seek": 388900, "start": 3909.0, "end": 3911.0, "text": " And yes it.", "tokens": [51364, 400, 2086, 309, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1149, "seek": 388900, "start": 3911.0, "end": 3913.0, "text": " It appeared to be better.", "tokens": [51464, 467, 8516, 281, 312, 1101, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1150, "seek": 388900, "start": 3913.0, "end": 3915.0, "text": " And this is great because now I've got fit.", "tokens": [51564, 400, 341, 307, 869, 570, 586, 286, 600, 658, 3318, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1151, "seek": 388900, "start": 3915.0, "end": 3917.0, "text": " I was able to run fit on DDPM v2.", "tokens": [51664, 286, 390, 1075, 281, 1190, 3318, 322, 413, 11373, 44, 371, 17, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1926427308250876, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0009110125247389078}, {"id": 1152, "seek": 391700, "start": 3917.0, "end": 3919.0, "text": " And on DDPM v3.", "tokens": [50364, 400, 322, 413, 11373, 44, 371, 18, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1153, "seek": 391700, "start": 3919.0, "end": 3921.0, "text": " And it was dramatically, dramatically, dramatically better.", "tokens": [50464, 400, 309, 390, 17548, 11, 17548, 11, 17548, 1101, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1154, "seek": 391700, "start": 3923.0, "end": 3925.0, "text": " And in fact I was running a lot.", "tokens": [50664, 400, 294, 1186, 286, 390, 2614, 257, 688, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1155, "seek": 391700, "start": 3925.0, "end": 3927.0, "text": " A lot of other experiments at the time.", "tokens": [50764, 316, 688, 295, 661, 12050, 412, 264, 565, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1156, "seek": 391700, "start": 3927.0, "end": 3929.0, "text": " Which we will talk about soon.", "tokens": [50864, 3013, 321, 486, 751, 466, 2321, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1157, "seek": 391700, "start": 3929.0, "end": 3931.0, "text": " And like all of my experiments.", "tokens": [50964, 400, 411, 439, 295, 452, 12050, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1158, "seek": 391700, "start": 3931.0, "end": 3933.0, "text": " Had totally fallen apart when I fixed the bug.", "tokens": [51064, 12298, 3879, 11547, 4936, 562, 286, 6806, 264, 7426, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1159, "seek": 391700, "start": 3933.0, "end": 3935.0, "text": " And once I.", "tokens": [51164, 400, 1564, 286, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1160, "seek": 391700, "start": 3935.0, "end": 3937.0, "text": " Did this.", "tokens": [51264, 2589, 341, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1161, "seek": 391700, "start": 3937.0, "end": 3939.0, "text": " All the things that I thought.", "tokens": [51364, 1057, 264, 721, 300, 286, 1194, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1162, "seek": 391700, "start": 3939.0, "end": 3941.0, "text": " Thought weren't working suddenly started working.", "tokens": [51464, 23058, 4999, 380, 1364, 5800, 1409, 1364, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1163, "seek": 391700, "start": 3943.0, "end": 3945.0, "text": " So you know this is often the case.", "tokens": [51664, 407, 291, 458, 341, 307, 2049, 264, 1389, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20135452400924814, "compression_ratio": 1.6337448559670782, "no_speech_prob": 0.004904392175376415}, {"id": 1164, "seek": 394500, "start": 3945.0, "end": 3947.0, "text": " Is that.", "tokens": [50364, 1119, 300, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1165, "seek": 394500, "start": 3947.0, "end": 3949.0, "text": " Bugs can.", "tokens": [50464, 363, 14950, 393, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1166, "seek": 394500, "start": 3949.0, "end": 3951.0, "text": " Outlight.", "tokens": [50564, 5925, 2764, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1167, "seek": 394500, "start": 3951.0, "end": 3953.0, "text": " Accidental discoveries.", "tokens": [50664, 5725, 47023, 28400, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1168, "seek": 394500, "start": 3953.0, "end": 3955.0, "text": " And the trick is always to be.", "tokens": [50764, 400, 264, 4282, 307, 1009, 281, 312, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1169, "seek": 394500, "start": 3957.0, "end": 3959.0, "text": " Careful enough to recognize.", "tokens": [50964, 32932, 1547, 281, 5521, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1170, "seek": 394500, "start": 3959.0, "end": 3961.0, "text": " When that's happened.", "tokens": [51064, 1133, 300, 311, 2011, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1171, "seek": 394500, "start": 3961.0, "end": 3963.0, "text": " Some people might remember the story.", "tokens": [51164, 2188, 561, 1062, 1604, 264, 1657, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1172, "seek": 394500, "start": 3963.0, "end": 3965.0, "text": " This is how the noble gases were discovered.", "tokens": [51264, 639, 307, 577, 264, 20171, 21452, 645, 6941, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1173, "seek": 394500, "start": 3965.0, "end": 3967.0, "text": " A chemistry experiment.", "tokens": [51364, 316, 12558, 5120, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1174, "seek": 394500, "start": 3967.0, "end": 3969.0, "text": " Went wrong.", "tokens": [51464, 31809, 2085, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1175, "seek": 394500, "start": 3969.0, "end": 3971.0, "text": " And left behind some strange bubbles.", "tokens": [51564, 400, 1411, 2261, 512, 5861, 16295, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1176, "seek": 394500, "start": 3971.0, "end": 3973.0, "text": " At the bottom of the test tube.", "tokens": [51664, 1711, 264, 2767, 295, 264, 1500, 9917, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1957197383958466, "compression_ratio": 1.4884792626728112, "no_speech_prob": 0.00019109233107883483}, {"id": 1177, "seek": 397300, "start": 3973.0, "end": 3975.0, "text": " Most people would just be like.", "tokens": [50364, 4534, 561, 576, 445, 312, 411, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1178, "seek": 397300, "start": 3975.0, "end": 3977.0, "text": " Huh.", "tokens": [50464, 8063, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1179, "seek": 397300, "start": 3977.0, "end": 3979.0, "text": " Whoops.", "tokens": [50564, 45263, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1180, "seek": 397300, "start": 3979.0, "end": 3981.0, "text": " Bubbles.", "tokens": [50664, 25489, 8806, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1181, "seek": 397300, "start": 3981.0, "end": 3983.0, "text": " But people who are careful enough actually went.", "tokens": [50764, 583, 561, 567, 366, 5026, 1547, 767, 1437, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1182, "seek": 397300, "start": 3983.0, "end": 3985.0, "text": " No there shouldn't be bubbles there.", "tokens": [50864, 883, 456, 4659, 380, 312, 16295, 456, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1183, "seek": 397300, "start": 3985.0, "end": 3987.0, "text": " Let's test them carefully.", "tokens": [50964, 961, 311, 1500, 552, 7500, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1184, "seek": 397300, "start": 3987.0, "end": 3989.0, "text": " It's like they don't react.", "tokens": [51064, 467, 311, 411, 436, 500, 380, 4515, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1185, "seek": 397300, "start": 3989.0, "end": 3991.0, "text": " Again most people would be like.", "tokens": [51164, 3764, 881, 561, 576, 312, 411, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1186, "seek": 397300, "start": 3991.0, "end": 3993.0, "text": " Oh that didn't work.", "tokens": [51264, 876, 300, 994, 380, 589, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1187, "seek": 397300, "start": 3993.0, "end": 3995.0, "text": " The reaction failed.", "tokens": [51364, 440, 5480, 7612, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1188, "seek": 397300, "start": 3995.0, "end": 3997.0, "text": " But you know if you're really careful.", "tokens": [51464, 583, 291, 458, 498, 291, 434, 534, 5026, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1189, "seek": 397300, "start": 3997.0, "end": 3999.0, "text": " You'll be like.", "tokens": [51564, 509, 603, 312, 411, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1190, "seek": 397300, "start": 3999.0, "end": 4001.0, "text": " Oh maybe the fact they don't react.", "tokens": [51664, 876, 1310, 264, 1186, 436, 500, 380, 4515, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21696052551269532, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.007343529723584652}, {"id": 1191, "seek": 400100, "start": 4001.0, "end": 4003.0, "text": " When you first showed us this thing.", "tokens": [50364, 1133, 291, 700, 4712, 505, 341, 551, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1192, "seek": 400100, "start": 4003.0, "end": 4005.0, "text": " I kind of said.", "tokens": [50464, 286, 733, 295, 848, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1193, "seek": 400100, "start": 4005.0, "end": 4007.0, "text": " The images looked fine.", "tokens": [50564, 440, 5267, 2956, 2489, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1194, "seek": 400100, "start": 4007.0, "end": 4009.0, "text": " The fit was slightly worse.", "tokens": [50664, 440, 3318, 390, 4748, 5324, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1195, "seek": 400100, "start": 4009.0, "end": 4011.0, "text": " But it was okay.", "tokens": [50764, 583, 309, 390, 1392, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1196, "seek": 400100, "start": 4011.0, "end": 4013.0, "text": " And if you trained it longer.", "tokens": [50864, 400, 498, 291, 8895, 309, 2854, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1197, "seek": 400100, "start": 4013.0, "end": 4015.0, "text": " It eventually got better mostly.", "tokens": [50964, 467, 4728, 658, 1101, 5240, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1198, "seek": 400100, "start": 4015.0, "end": 4017.0, "text": " There were some things that sampling.", "tokens": [51064, 821, 645, 512, 721, 300, 21179, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1199, "seek": 400100, "start": 4017.0, "end": 4019.0, "text": " Occasionally went wrong.", "tokens": [51164, 26191, 6822, 379, 1437, 2085, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1200, "seek": 400100, "start": 4019.0, "end": 4021.0, "text": " One image in a hundred or something like that.", "tokens": [51264, 1485, 3256, 294, 257, 3262, 420, 746, 411, 300, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1201, "seek": 400100, "start": 4021.0, "end": 4023.0, "text": " But it was like.", "tokens": [51364, 583, 309, 390, 411, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1202, "seek": 400100, "start": 4023.0, "end": 4025.0, "text": " This isn't like everything completely fell apart.", "tokens": [51464, 639, 1943, 380, 411, 1203, 2584, 5696, 4936, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1203, "seek": 400100, "start": 4025.0, "end": 4027.0, "text": " No it's just the truth.", "tokens": [51564, 883, 309, 311, 445, 264, 3494, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1204, "seek": 400100, "start": 4027.0, "end": 4029.0, "text": " It was slightly worse than expected.", "tokens": [51664, 467, 390, 4748, 5324, 813, 5176, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23208709654769277, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.6955459117889404}, {"id": 1205, "seek": 402900, "start": 4029.0, "end": 4031.0, "text": " I tried a bunch of things.", "tokens": [50364, 286, 3031, 257, 3840, 295, 721, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1206, "seek": 402900, "start": 4031.0, "end": 4033.0, "text": " I just doubled my training time.", "tokens": [50464, 286, 445, 24405, 452, 3097, 565, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1207, "seek": 402900, "start": 4033.0, "end": 4035.0, "text": " And set a few runs going.", "tokens": [50564, 400, 992, 257, 1326, 6676, 516, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1208, "seek": 402900, "start": 4035.0, "end": 4037.0, "text": " And looked at the weights and biases stats later.", "tokens": [50664, 400, 2956, 412, 264, 17443, 293, 32152, 18152, 1780, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1209, "seek": 402900, "start": 4037.0, "end": 4039.0, "text": " And oh that seems like it's better now.", "tokens": [50764, 400, 1954, 300, 2544, 411, 309, 311, 1101, 586, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1210, "seek": 402900, "start": 4039.0, "end": 4041.0, "text": " It just needed to train for longer.", "tokens": [50864, 467, 445, 2978, 281, 3847, 337, 2854, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1211, "seek": 402900, "start": 4041.0, "end": 4043.0, "text": " And we have internet GPUs and lots of money.", "tokens": [50964, 400, 321, 362, 4705, 18407, 82, 293, 3195, 295, 1460, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1212, "seek": 402900, "start": 4043.0, "end": 4045.0, "text": " You wouldn't notice this.", "tokens": [51064, 509, 2759, 380, 3449, 341, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1213, "seek": 402900, "start": 4045.0, "end": 4047.0, "text": " It wasn't like.", "tokens": [51164, 467, 2067, 380, 411, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1214, "seek": 402900, "start": 4047.0, "end": 4049.0, "text": " The fact that you picked up on it.", "tokens": [51264, 440, 1186, 300, 291, 6183, 493, 322, 309, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1215, "seek": 402900, "start": 4049.0, "end": 4051.0, "text": " Showed that you had this deep intuition.", "tokens": [51364, 6895, 292, 300, 291, 632, 341, 2452, 24002, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1216, "seek": 402900, "start": 4051.0, "end": 4053.0, "text": " For where it should be at this stage in training.", "tokens": [51464, 1171, 689, 309, 820, 312, 412, 341, 3233, 294, 3097, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1217, "seek": 402900, "start": 4053.0, "end": 4055.0, "text": " Versus where it was.", "tokens": [51564, 12226, 301, 689, 309, 390, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1218, "seek": 402900, "start": 4055.0, "end": 4057.0, "text": " What the samples should look like.", "tokens": [51664, 708, 264, 10938, 820, 574, 411, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2502988801969515, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.7899256348609924}, {"id": 1219, "seek": 405700, "start": 4057.0, "end": 4059.0, "text": " I've expected a fit of nine.", "tokens": [50364, 286, 600, 5176, 257, 3318, 295, 4949, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1220, "seek": 405700, "start": 4059.0, "end": 4061.0, "text": " And I'm getting 14.", "tokens": [50464, 400, 286, 478, 1242, 3499, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1221, "seek": 405700, "start": 4061.0, "end": 4063.0, "text": " What's up here.", "tokens": [50564, 708, 311, 493, 510, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1222, "seek": 405700, "start": 4063.0, "end": 4065.0, "text": " And that was enough to start asking these questions.", "tokens": [50664, 400, 300, 390, 1547, 281, 722, 3365, 613, 1651, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1223, "seek": 405700, "start": 4065.0, "end": 4067.0, "text": " And you jumped on all.", "tokens": [50764, 400, 291, 13864, 322, 439, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1224, "seek": 405700, "start": 4067.0, "end": 4069.0, "text": " And started to think.", "tokens": [50864, 400, 1409, 281, 519, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1225, "seek": 405700, "start": 4069.0, "end": 4071.0, "text": " Where this came from.", "tokens": [50964, 2305, 341, 1361, 490, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1226, "seek": 405700, "start": 4071.0, "end": 4073.0, "text": " I drive people crazy.", "tokens": [51064, 286, 3332, 561, 3219, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1227, "seek": 405700, "start": 4073.0, "end": 4075.0, "text": " That I work with.", "tokens": [51164, 663, 286, 589, 365, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1228, "seek": 405700, "start": 4075.0, "end": 4077.0, "text": " I don't know why you guys aren't crazy yet.", "tokens": [51264, 286, 500, 380, 458, 983, 291, 1074, 3212, 380, 3219, 1939, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1229, "seek": 405700, "start": 4077.0, "end": 4079.0, "text": " But with this kind of like.", "tokens": [51364, 583, 365, 341, 733, 295, 411, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1230, "seek": 405700, "start": 4079.0, "end": 4081.0, "text": " No I need to know exactly why.", "tokens": [51464, 883, 286, 643, 281, 458, 2293, 983, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1231, "seek": 405700, "start": 4081.0, "end": 4083.0, "text": " This is not exactly what we expected.", "tokens": [51564, 639, 307, 406, 2293, 437, 321, 5176, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1232, "seek": 405700, "start": 4083.0, "end": 4085.0, "text": " But yeah this is why.", "tokens": [51664, 583, 1338, 341, 307, 983, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23729825398278614, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.24452638626098633}, {"id": 1233, "seek": 408500, "start": 4085.0, "end": 4087.0, "text": " To find.", "tokens": [50364, 1407, 915, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1234, "seek": 408500, "start": 4087.0, "end": 4089.0, "text": " When something's mysterious and weird.", "tokens": [50464, 1133, 746, 311, 13831, 293, 3657, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1235, "seek": 408500, "start": 4089.0, "end": 4091.0, "text": " It means that there's something you didn't understand.", "tokens": [50564, 467, 1355, 300, 456, 311, 746, 291, 994, 380, 1223, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1236, "seek": 408500, "start": 4091.0, "end": 4093.0, "text": " And that's an opportunity to learn something new.", "tokens": [50664, 400, 300, 311, 364, 2650, 281, 1466, 746, 777, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1237, "seek": 408500, "start": 4093.0, "end": 4095.0, "text": " So that's what we did.", "tokens": [50764, 407, 300, 311, 437, 321, 630, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1238, "seek": 408500, "start": 4099.0, "end": 4101.0, "text": " And so that was quite exciting.", "tokens": [51064, 400, 370, 300, 390, 1596, 4670, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1239, "seek": 408500, "start": 4101.0, "end": 4103.0, "text": " Because yeah going minus 0.5 to 0.5.", "tokens": [51164, 1436, 1338, 516, 3175, 1958, 13, 20, 281, 1958, 13, 20, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1240, "seek": 408500, "start": 4103.0, "end": 4105.0, "text": " Made the fit better still.", "tokens": [51264, 18330, 264, 3318, 1101, 920, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1241, "seek": 408500, "start": 4107.0, "end": 4109.0, "text": " I was definitely in.", "tokens": [51464, 286, 390, 2138, 294, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1242, "seek": 408500, "start": 4109.0, "end": 4111.0, "text": " I moved from this frame of mind.", "tokens": [51564, 286, 4259, 490, 341, 3920, 295, 1575, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1243, "seek": 408500, "start": 4111.0, "end": 4113.0, "text": " From like.", "tokens": [51664, 3358, 411, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20033184532980317, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.032064467668533325}, {"id": 1244, "seek": 411300, "start": 4113.0, "end": 4115.0, "text": " I was so depressed.", "tokens": [50364, 286, 390, 370, 18713, 13, 50464], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1245, "seek": 411300, "start": 4115.0, "end": 4117.0, "text": " I was so mad.", "tokens": [50464, 286, 390, 370, 5244, 13, 50564], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1246, "seek": 411300, "start": 4117.0, "end": 4119.0, "text": " I still remember when I spoke to Jotto.", "tokens": [50564, 286, 920, 1604, 562, 286, 7179, 281, 508, 18838, 13, 50664], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1247, "seek": 411300, "start": 4119.0, "end": 4121.0, "text": " I was so upset.", "tokens": [50664, 286, 390, 370, 8340, 13, 50764], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1248, "seek": 411300, "start": 4121.0, "end": 4123.0, "text": " And then I was suddenly like.", "tokens": [50764, 400, 550, 286, 390, 5800, 411, 13, 50864], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1249, "seek": 411300, "start": 4123.0, "end": 4125.0, "text": " Oh my gosh we're actually onto something.", "tokens": [50864, 876, 452, 6502, 321, 434, 767, 3911, 746, 13, 50964], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1250, "seek": 411300, "start": 4125.0, "end": 4127.0, "text": " So I started experimenting more.", "tokens": [50964, 407, 286, 1409, 29070, 544, 13, 51064], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1251, "seek": 411300, "start": 4127.0, "end": 4129.0, "text": " And a bit more confidence at this point.", "tokens": [51064, 400, 257, 857, 544, 6687, 412, 341, 935, 13, 51164], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1252, "seek": 411300, "start": 4129.0, "end": 4131.0, "text": " I guess.", "tokens": [51164, 286, 2041, 13, 51264], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1253, "seek": 411300, "start": 4131.0, "end": 4133.0, "text": " And one thing I started looking at.", "tokens": [51264, 400, 472, 551, 286, 1409, 1237, 412, 13, 51364], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1254, "seek": 411300, "start": 4133.0, "end": 4135.0, "text": " Was our schedule.", "tokens": [51364, 3027, 527, 7567, 13, 51464], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1255, "seek": 411300, "start": 4135.0, "end": 4137.0, "text": " We'd always been copying and pasting.", "tokens": [51464, 492, 1116, 1009, 668, 27976, 293, 1791, 278, 13, 51564], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1256, "seek": 411300, "start": 4137.0, "end": 4139.0, "text": " This standard.", "tokens": [51564, 639, 3832, 13, 51664], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1257, "seek": 411300, "start": 4139.0, "end": 4141.0, "text": " Again set of stuff.", "tokens": [51664, 3764, 992, 295, 1507, 13, 51764], "temperature": 0.0, "avg_logprob": -0.255452624822067, "compression_ratio": 1.5991379310344827, "no_speech_prob": 0.022970562800765038}, {"id": 1258, "seek": 414100, "start": 4141.0, "end": 4143.0, "text": " Questioning everything.", "tokens": [50364, 14464, 278, 1203, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1259, "seek": 414100, "start": 4143.0, "end": 4145.0, "text": " Why is this a standard?", "tokens": [50464, 1545, 307, 341, 257, 3832, 30, 50564], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1260, "seek": 414100, "start": 4145.0, "end": 4147.0, "text": " Why are these numbers here?", "tokens": [50564, 1545, 366, 613, 3547, 510, 30, 50664], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1261, "seek": 414100, "start": 4147.0, "end": 4149.0, "text": " And I didn't see any particular reason.", "tokens": [50664, 400, 286, 994, 380, 536, 604, 1729, 1778, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1262, "seek": 414100, "start": 4149.0, "end": 4151.0, "text": " Why those numbers were there.", "tokens": [50764, 1545, 729, 3547, 645, 456, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1263, "seek": 414100, "start": 4151.0, "end": 4153.0, "text": " And I thought.", "tokens": [50864, 400, 286, 1194, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1264, "seek": 414100, "start": 4153.0, "end": 4155.0, "text": " We should maybe experiment with them.", "tokens": [50964, 492, 820, 1310, 5120, 365, 552, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1265, "seek": 414100, "start": 4155.0, "end": 4157.0, "text": " So to make it easier.", "tokens": [51064, 407, 281, 652, 309, 3571, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1266, "seek": 414100, "start": 4157.0, "end": 4159.0, "text": " I created a little function.", "tokens": [51164, 286, 2942, 257, 707, 2445, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1267, "seek": 414100, "start": 4159.0, "end": 4161.0, "text": " That would return a schedule.", "tokens": [51264, 663, 576, 2736, 257, 7567, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1268, "seek": 414100, "start": 4161.0, "end": 4163.0, "text": " Now you could create a new class.", "tokens": [51364, 823, 291, 727, 1884, 257, 777, 1508, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1269, "seek": 414100, "start": 4163.0, "end": 4165.0, "text": " For a schedule.", "tokens": [51464, 1171, 257, 7567, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1270, "seek": 414100, "start": 4165.0, "end": 4167.0, "text": " But something that's really cool.", "tokens": [51564, 583, 746, 300, 311, 534, 1627, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1271, "seek": 414100, "start": 4167.0, "end": 4169.0, "text": " Is a thing in Python called SimpleNameSpace.", "tokens": [51664, 1119, 257, 551, 294, 15329, 1219, 21532, 45, 529, 44306, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23380676905314127, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.018543215468525887}, {"id": 1272, "seek": 416900, "start": 4169.0, "end": 4171.0, "text": " Which is a construct in C.", "tokens": [50364, 3013, 307, 257, 7690, 294, 383, 13, 50464], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1273, "seek": 416900, "start": 4171.0, "end": 4173.0, "text": " Basically lets you wrap up a little.", "tokens": [50464, 8537, 6653, 291, 7019, 493, 257, 707, 13, 50564], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1274, "seek": 416900, "start": 4173.0, "end": 4175.0, "text": " Bunch of keys and values.", "tokens": [50564, 363, 1680, 295, 9317, 293, 4190, 13, 50664], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1275, "seek": 416900, "start": 4175.0, "end": 4177.0, "text": " As if it's an object.", "tokens": [50664, 1018, 498, 309, 311, 364, 2657, 13, 50764], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1276, "seek": 416900, "start": 4177.0, "end": 4179.0, "text": " So I created this little.", "tokens": [50764, 407, 286, 2942, 341, 707, 13, 50864], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1277, "seek": 416900, "start": 4179.0, "end": 4181.0, "text": " SimpleNameSpace.", "tokens": [50864, 21532, 45, 529, 44306, 13, 50964], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1278, "seek": 416900, "start": 4181.0, "end": 4183.0, "text": " Which contains our alphas.", "tokens": [50964, 3013, 8306, 527, 419, 7485, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1279, "seek": 416900, "start": 4183.0, "end": 4185.0, "text": " Our alpha bars.", "tokens": [51064, 2621, 8961, 10228, 13, 51164], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1280, "seek": 416900, "start": 4185.0, "end": 4187.0, "text": " And our sigmas.", "tokens": [51164, 400, 527, 4556, 3799, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1281, "seek": 416900, "start": 4187.0, "end": 4189.0, "text": " For our normal.", "tokens": [51264, 1171, 527, 2710, 13, 51364], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1282, "seek": 416900, "start": 4189.0, "end": 4191.0, "text": " EtaMax.", "tokens": [51364, 462, 1328, 36025, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1283, "seek": 416900, "start": 4191.0, "end": 4193.0, "text": " Xs.02.", "tokens": [51464, 1783, 82, 13, 12756, 13, 51564], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1284, "seek": 416900, "start": 4193.0, "end": 4195.0, "text": " N space.", "tokens": [51564, 426, 1901, 13, 51664], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1285, "seek": 416900, "start": 4195.0, "end": 4197.0, "text": " This is what we always do.", "tokens": [51664, 639, 307, 437, 321, 1009, 360, 13, 51764], "temperature": 0.0, "avg_logprob": -0.25108565224541557, "compression_ratio": 1.3930348258706469, "no_speech_prob": 0.17991623282432556}, {"id": 1286, "seek": 419700, "start": 4197.0, "end": 4199.0, "text": " But there's an alternative approach.", "tokens": [50364, 583, 456, 311, 364, 8535, 3109, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1287, "seek": 419700, "start": 4199.0, "end": 4201.0, "text": " Which is cosine schedule.", "tokens": [50464, 3013, 307, 23565, 7567, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1288, "seek": 419700, "start": 4201.0, "end": 4203.0, "text": " Which is where you basically.", "tokens": [50564, 3013, 307, 689, 291, 1936, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1289, "seek": 419700, "start": 4203.0, "end": 4205.0, "text": " Set alpha bar.", "tokens": [50664, 8928, 8961, 2159, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1290, "seek": 419700, "start": 4205.0, "end": 4207.0, "text": " Equal to.", "tokens": [50764, 15624, 304, 281, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1291, "seek": 419700, "start": 4207.0, "end": 4209.0, "text": " T.", "tokens": [50864, 314, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1292, "seek": 419700, "start": 4209.0, "end": 4211.0, "text": " As a fraction of big T.", "tokens": [50964, 1018, 257, 14135, 295, 955, 314, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1293, "seek": 419700, "start": 4211.0, "end": 4213.0, "text": " Times pi over 2.", "tokens": [51064, 11366, 3895, 670, 568, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1294, "seek": 419700, "start": 4213.0, "end": 4215.0, "text": " Cosine of that.", "tokens": [51164, 15855, 533, 295, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1295, "seek": 419700, "start": 4215.0, "end": 4217.0, "text": " Squared.", "tokens": [51264, 8683, 1642, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1296, "seek": 419700, "start": 4217.0, "end": 4219.0, "text": " And if you make that your alpha bar.", "tokens": [51364, 400, 498, 291, 652, 300, 428, 8961, 2159, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1297, "seek": 419700, "start": 4219.0, "end": 4221.0, "text": " You can then basically.", "tokens": [51464, 509, 393, 550, 1936, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1298, "seek": 419700, "start": 4221.0, "end": 4223.0, "text": " Reverse back out to calculate.", "tokens": [51564, 26314, 405, 646, 484, 281, 8873, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1299, "seek": 419700, "start": 4223.0, "end": 4225.0, "text": " What alpha must have been.", "tokens": [51664, 708, 8961, 1633, 362, 668, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21376351856050038, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.16005858778953552}, {"id": 1300, "seek": 422500, "start": 4225.0, "end": 4227.0, "text": " And so we can create a schedule.", "tokens": [50364, 400, 370, 321, 393, 1884, 257, 7567, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1301, "seek": 422500, "start": 4227.0, "end": 4229.0, "text": " For this cosine schedule as well.", "tokens": [50464, 1171, 341, 23565, 7567, 382, 731, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1302, "seek": 422500, "start": 4229.0, "end": 4231.0, "text": " And.", "tokens": [50564, 400, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1303, "seek": 422500, "start": 4231.0, "end": 4233.0, "text": " Yeah this cosine schedule.", "tokens": [50664, 865, 341, 23565, 7567, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1304, "seek": 422500, "start": 4233.0, "end": 4235.0, "text": " Is I think pretty recognized.", "tokens": [50764, 1119, 286, 519, 1238, 9823, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1305, "seek": 422500, "start": 4235.0, "end": 4237.0, "text": " As being better.", "tokens": [50864, 1018, 885, 1101, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1306, "seek": 422500, "start": 4237.0, "end": 4239.0, "text": " Than this.", "tokens": [50964, 18289, 341, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1307, "seek": 422500, "start": 4239.0, "end": 4241.0, "text": " Linear schedule.", "tokens": [51064, 14670, 289, 7567, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1308, "seek": 422500, "start": 4241.0, "end": 4243.0, "text": " And so I thought.", "tokens": [51164, 400, 370, 286, 1194, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1309, "seek": 422500, "start": 4243.0, "end": 4245.0, "text": " Okay it'll be interesting to look at.", "tokens": [51264, 1033, 309, 603, 312, 1880, 281, 574, 412, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1310, "seek": 422500, "start": 4245.0, "end": 4247.0, "text": " How they compare.", "tokens": [51364, 1012, 436, 6794, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1311, "seek": 422500, "start": 4247.0, "end": 4249.0, "text": " And in fact.", "tokens": [51464, 400, 294, 1186, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1312, "seek": 422500, "start": 4249.0, "end": 4251.0, "text": " Really all that matters is.", "tokens": [51564, 4083, 439, 300, 7001, 307, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1313, "seek": 422500, "start": 4251.0, "end": 4253.0, "text": " The alpha bar.", "tokens": [51664, 440, 8961, 2159, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19945905704309444, "compression_ratio": 1.5459183673469388, "no_speech_prob": 0.0006771539920009673}, {"id": 1314, "seek": 425300, "start": 4253.0, "end": 4255.0, "text": " Is you know.", "tokens": [50364, 1119, 291, 458, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1315, "seek": 425300, "start": 4255.0, "end": 4257.0, "text": " The total amount of.", "tokens": [50464, 440, 3217, 2372, 295, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1316, "seek": 425300, "start": 4257.0, "end": 4259.0, "text": " Noise that you're adding.", "tokens": [50564, 44821, 300, 291, 434, 5127, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1317, "seek": 425300, "start": 4259.0, "end": 4261.0, "text": " So in DDPM.", "tokens": [50664, 407, 294, 413, 11373, 44, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1318, "seek": 425300, "start": 4261.0, "end": 4263.0, "text": " When we do noisify.", "tokens": [50764, 1133, 321, 360, 572, 271, 2505, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1319, "seek": 425300, "start": 4263.0, "end": 4265.0, "text": " You know it's.", "tokens": [50864, 509, 458, 309, 311, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1320, "seek": 425300, "start": 4265.0, "end": 4267.0, "text": " It's alpha bar.", "tokens": [50964, 467, 311, 8961, 2159, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1321, "seek": 425300, "start": 4267.0, "end": 4269.0, "text": " That we're actually using.", "tokens": [51064, 663, 321, 434, 767, 1228, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1322, "seek": 425300, "start": 4269.0, "end": 4271.0, "text": " The amount of the image.", "tokens": [51164, 440, 2372, 295, 264, 3256, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1323, "seek": 425300, "start": 4271.0, "end": 4273.0, "text": " And 1 minus alpha bar.", "tokens": [51264, 400, 502, 3175, 8961, 2159, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1324, "seek": 425300, "start": 4273.0, "end": 4275.0, "text": " Exactly.", "tokens": [51364, 7587, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1325, "seek": 425300, "start": 4275.0, "end": 4277.0, "text": " Yeah.", "tokens": [51464, 865, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1326, "seek": 425300, "start": 4277.0, "end": 4279.0, "text": " So I just printed those out.", "tokens": [51564, 407, 286, 445, 13567, 729, 484, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1327, "seek": 425300, "start": 4279.0, "end": 4281.0, "text": " Plotted those.", "tokens": [51664, 2149, 11252, 729, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21219614236661705, "compression_ratio": 1.4301675977653632, "no_speech_prob": 0.0022168608848005533}, {"id": 1328, "seek": 428100, "start": 4281.0, "end": 4283.0, "text": " This linear schedule.", "tokens": [50364, 639, 8213, 7567, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1329, "seek": 428100, "start": 4283.0, "end": 4285.0, "text": " And this cosine schedule.", "tokens": [50464, 400, 341, 23565, 7567, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1330, "seek": 428100, "start": 4285.0, "end": 4287.0, "text": " And you can really see the linear schedule.", "tokens": [50564, 400, 291, 393, 534, 536, 264, 8213, 7567, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1331, "seek": 428100, "start": 4287.0, "end": 4289.0, "text": " It really sucks badly.", "tokens": [50664, 467, 534, 15846, 13425, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1332, "seek": 428100, "start": 4289.0, "end": 4291.0, "text": " It's got a lot of time steps.", "tokens": [50764, 467, 311, 658, 257, 688, 295, 565, 4439, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1333, "seek": 428100, "start": 4291.0, "end": 4293.0, "text": " Where it's basically about 0.", "tokens": [50864, 2305, 309, 311, 1936, 466, 1958, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1334, "seek": 428100, "start": 4293.0, "end": 4295.0, "text": " And.", "tokens": [50964, 400, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1335, "seek": 428100, "start": 4295.0, "end": 4297.0, "text": " You know.", "tokens": [51064, 509, 458, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1336, "seek": 428100, "start": 4297.0, "end": 4299.0, "text": " That's.", "tokens": [51164, 663, 311, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1337, "seek": 428100, "start": 4299.0, "end": 4301.0, "text": " Something we can't really do anything with.", "tokens": [51264, 6595, 321, 393, 380, 534, 360, 1340, 365, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1338, "seek": 428100, "start": 4301.0, "end": 4303.0, "text": " You know.", "tokens": [51364, 509, 458, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1339, "seek": 428100, "start": 4303.0, "end": 4305.0, "text": " Whereas the cosine schedule.", "tokens": [51464, 13813, 264, 23565, 7567, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1340, "seek": 428100, "start": 4305.0, "end": 4307.0, "text": " Is really nice and smooth.", "tokens": [51564, 1119, 534, 1481, 293, 5508, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1341, "seek": 428100, "start": 4307.0, "end": 4309.0, "text": " And there's not many steps.", "tokens": [51664, 400, 456, 311, 406, 867, 4439, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1660153754403658, "compression_ratio": 1.7819148936170213, "no_speech_prob": 0.31988948583602905}, {"id": 1342, "seek": 430900, "start": 4309.0, "end": 4311.0, "text": " There's not nearly one.", "tokens": [50364, 821, 311, 406, 6217, 472, 13, 50464], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1343, "seek": 430900, "start": 4311.0, "end": 4313.0, "text": " So I was kind of inclined.", "tokens": [50464, 407, 286, 390, 733, 295, 28173, 13, 50564], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1344, "seek": 430900, "start": 4313.0, "end": 4315.0, "text": " To try using the cosine schedule.", "tokens": [50564, 1407, 853, 1228, 264, 23565, 7567, 13, 50664], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1345, "seek": 430900, "start": 4315.0, "end": 4317.0, "text": " But then I thought well.", "tokens": [50664, 583, 550, 286, 1194, 731, 13, 50764], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1346, "seek": 430900, "start": 4317.0, "end": 4319.0, "text": " It would be easy enough to get rid of this big flat bit.", "tokens": [50764, 467, 576, 312, 1858, 1547, 281, 483, 3973, 295, 341, 955, 4962, 857, 13, 50864], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1347, "seek": 430900, "start": 4319.0, "end": 4321.0, "text": " By just decreasing beta max.", "tokens": [50864, 3146, 445, 23223, 9861, 11469, 13, 50964], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1348, "seek": 430900, "start": 4321.0, "end": 4323.0, "text": " That would be another thing we can do.", "tokens": [50964, 663, 576, 312, 1071, 551, 321, 393, 360, 13, 51064], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1349, "seek": 430900, "start": 4323.0, "end": 4325.0, "text": " So I tried.", "tokens": [51064, 407, 286, 3031, 13, 51164], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1350, "seek": 430900, "start": 4325.0, "end": 4327.0, "text": " Oh sorry first of all I should mention.", "tokens": [51164, 876, 2597, 700, 295, 439, 286, 820, 2152, 13, 51264], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1351, "seek": 430900, "start": 4327.0, "end": 4329.0, "text": " That the other thing that's really important.", "tokens": [51264, 663, 264, 661, 551, 300, 311, 534, 1021, 13, 51364], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1352, "seek": 430900, "start": 4329.0, "end": 4331.0, "text": " Is the slope of these curves.", "tokens": [51364, 1119, 264, 13525, 295, 613, 19490, 13, 51464], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1353, "seek": 430900, "start": 4331.0, "end": 4333.0, "text": " Because that's how much things are stepping.", "tokens": [51464, 1436, 300, 311, 577, 709, 721, 366, 16821, 13, 51564], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1354, "seek": 430900, "start": 4333.0, "end": 4335.0, "text": " During the sampling process.", "tokens": [51564, 6842, 264, 21179, 1399, 13, 51664], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1355, "seek": 430900, "start": 4335.0, "end": 4337.0, "text": " And so here's the slope of the lin.", "tokens": [51664, 400, 370, 510, 311, 264, 13525, 295, 264, 22896, 13, 51764], "temperature": 0.0, "avg_logprob": -0.250337573065274, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.09531760215759277}, {"id": 1356, "seek": 433700, "start": 4337.0, "end": 4339.0, "text": " And you can see the cosine slope.", "tokens": [50364, 400, 291, 393, 536, 264, 23565, 13525, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1357, "seek": 433700, "start": 4339.0, "end": 4341.0, "text": " Really nice right.", "tokens": [50464, 4083, 1481, 558, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1358, "seek": 433700, "start": 4341.0, "end": 4343.0, "text": " You have.", "tokens": [50564, 509, 362, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1359, "seek": 433700, "start": 4343.0, "end": 4345.0, "text": " This nice smooth curve.", "tokens": [50664, 639, 1481, 5508, 7605, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1360, "seek": 433700, "start": 4345.0, "end": 4347.0, "text": " Where else the linear is just a disaster.", "tokens": [50764, 2305, 1646, 264, 8213, 307, 445, 257, 11293, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1361, "seek": 433700, "start": 4347.0, "end": 4349.0, "text": " So yeah.", "tokens": [50864, 407, 1338, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1362, "seek": 433700, "start": 4349.0, "end": 4351.0, "text": " If I change beta max to 0.01.", "tokens": [50964, 759, 286, 1319, 9861, 11469, 281, 1958, 13, 10607, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1363, "seek": 433700, "start": 4351.0, "end": 4353.0, "text": " That actually.", "tokens": [51064, 663, 767, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1364, "seek": 433700, "start": 4353.0, "end": 4355.0, "text": " Gets you nearly.", "tokens": [51164, 460, 1385, 291, 6217, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1365, "seek": 433700, "start": 4355.0, "end": 4357.0, "text": " The same curve as the cosine.", "tokens": [51264, 440, 912, 7605, 382, 264, 23565, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1366, "seek": 433700, "start": 4359.0, "end": 4361.0, "text": " So I thought that was very interesting.", "tokens": [51464, 407, 286, 1194, 300, 390, 588, 1880, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1367, "seek": 433700, "start": 4361.0, "end": 4363.0, "text": " It kind of made me think.", "tokens": [51564, 467, 733, 295, 1027, 385, 519, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1368, "seek": 433700, "start": 4363.0, "end": 4365.0, "text": " Like why on earth.", "tokens": [51664, 1743, 983, 322, 4120, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1825035458519345, "compression_ratio": 1.4741784037558685, "no_speech_prob": 0.0033761183731257915}, {"id": 1369, "seek": 436500, "start": 4365.0, "end": 4367.0, "text": " Why is use 0.02 as the default.", "tokens": [50364, 1545, 307, 764, 1958, 13, 12756, 382, 264, 7576, 13, 50464], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1370, "seek": 436500, "start": 4367.0, "end": 4369.0, "text": " And so we actually talked to.", "tokens": [50464, 400, 370, 321, 767, 2825, 281, 13, 50564], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1371, "seek": 436500, "start": 4369.0, "end": 4371.0, "text": " Robin.", "tokens": [50564, 16533, 13, 50664], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1372, "seek": 436500, "start": 4371.0, "end": 4373.0, "text": " Who is one of the two lead authors on the stable diffusion paper.", "tokens": [50664, 2102, 307, 472, 295, 264, 732, 1477, 16552, 322, 264, 8351, 25242, 3035, 13, 50764], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1373, "seek": 436500, "start": 4373.0, "end": 4375.0, "text": " And.", "tokens": [50764, 400, 13, 50864], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1374, "seek": 436500, "start": 4375.0, "end": 4377.0, "text": " We talked about all of these things.", "tokens": [50864, 492, 2825, 466, 439, 295, 613, 721, 13, 50964], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1375, "seek": 436500, "start": 4377.0, "end": 4379.0, "text": " And he said oh yeah we noticed.", "tokens": [50964, 400, 415, 848, 1954, 1338, 321, 5694, 13, 51064], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1376, "seek": 436500, "start": 4379.0, "end": 4381.0, "text": " Not exactly this.", "tokens": [51064, 1726, 2293, 341, 13, 51164], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1377, "seek": 436500, "start": 4381.0, "end": 4383.0, "text": " But we know we experimented with everything.", "tokens": [51164, 583, 321, 458, 321, 5120, 292, 365, 1203, 13, 51264], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1378, "seek": 436500, "start": 4383.0, "end": 4385.0, "text": " And we noticed that when we decreased beta max.", "tokens": [51264, 400, 321, 5694, 300, 562, 321, 24436, 9861, 11469, 13, 51364], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1379, "seek": 436500, "start": 4385.0, "end": 4387.0, "text": " We got better results.", "tokens": [51364, 492, 658, 1101, 3542, 13, 51464], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1380, "seek": 436500, "start": 4387.0, "end": 4389.0, "text": " And so actually stable diffusion uses beta max at 0.012.", "tokens": [51464, 400, 370, 767, 8351, 25242, 4960, 9861, 11469, 412, 1958, 13, 15, 4762, 13, 51564], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1381, "seek": 436500, "start": 4389.0, "end": 4391.0, "text": " I think that might be a little bit higher.", "tokens": [51564, 286, 519, 300, 1062, 312, 257, 707, 857, 2946, 13, 51664], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1382, "seek": 436500, "start": 4391.0, "end": 4393.0, "text": " Than they should have picked.", "tokens": [51664, 18289, 436, 820, 362, 6183, 13, 51764], "temperature": 0.0, "avg_logprob": -0.27438886903172777, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.08874522894620895}, {"id": 1383, "seek": 439300, "start": 4393.0, "end": 4395.0, "text": " So it's interesting talking to Robin.", "tokens": [50364, 407, 309, 311, 1880, 1417, 281, 16533, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1384, "seek": 439300, "start": 4395.0, "end": 4397.0, "text": " To see like all of these kinds of experiments.", "tokens": [50464, 1407, 536, 411, 439, 295, 613, 3685, 295, 12050, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1385, "seek": 439300, "start": 4397.0, "end": 4399.0, "text": " And like things that we.", "tokens": [50564, 400, 411, 721, 300, 321, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1386, "seek": 439300, "start": 4399.0, "end": 4401.0, "text": " Tried out.", "tokens": [50664, 314, 2428, 484, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1387, "seek": 439300, "start": 4401.0, "end": 4403.0, "text": " They had been there as well.", "tokens": [50764, 814, 632, 668, 456, 382, 731, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1388, "seek": 439300, "start": 4403.0, "end": 4405.0, "text": " And noticed the same things.", "tokens": [50864, 400, 5694, 264, 912, 721, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1389, "seek": 439300, "start": 4405.0, "end": 4407.0, "text": " That the inputs range as well.", "tokens": [50964, 663, 264, 15743, 3613, 382, 731, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1390, "seek": 439300, "start": 4407.0, "end": 4409.0, "text": " They have this magical factor of 0.18.", "tokens": [51064, 814, 362, 341, 12066, 5952, 295, 1958, 13, 6494, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1391, "seek": 439300, "start": 4409.0, "end": 4411.0, "text": " So to whatever.", "tokens": [51164, 407, 281, 2035, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1392, "seek": 439300, "start": 4411.0, "end": 4413.0, "text": " They scale the latency by.", "tokens": [51264, 814, 4373, 264, 27043, 538, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1393, "seek": 439300, "start": 4413.0, "end": 4415.0, "text": " And if you ask why.", "tokens": [51364, 400, 498, 291, 1029, 983, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1394, "seek": 439300, "start": 4415.0, "end": 4417.0, "text": " Oh yeah we want to delay this to be.", "tokens": [51464, 876, 1338, 321, 528, 281, 8577, 341, 281, 312, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1395, "seek": 439300, "start": 4417.0, "end": 4419.0, "text": " Like roughly uniform range or whatever.", "tokens": [51564, 1743, 9810, 9452, 3613, 420, 2035, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1396, "seek": 439300, "start": 4419.0, "end": 4421.0, "text": " But that's also like that's.", "tokens": [51664, 583, 300, 311, 611, 411, 300, 311, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2832683888516685, "compression_ratio": 1.6482213438735178, "no_speech_prob": 0.07053505629301071}, {"id": 1397, "seek": 442100, "start": 4421.0, "end": 4423.0, "text": " Reducing the range of your.", "tokens": [50364, 4477, 1311, 278, 264, 3613, 295, 428, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1398, "seek": 442100, "start": 4423.0, "end": 4425.0, "text": " Inputs to.", "tokens": [50464, 682, 2582, 82, 281, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1399, "seek": 442100, "start": 4425.0, "end": 4427.0, "text": " I think exactly.", "tokens": [50564, 286, 519, 2293, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1400, "seek": 442100, "start": 4427.0, "end": 4429.0, "text": " We independently discovered.", "tokens": [50664, 492, 21761, 6941, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1401, "seek": 442100, "start": 4429.0, "end": 4431.0, "text": " And they independently discovered this idea.", "tokens": [50764, 400, 436, 21761, 6941, 341, 1558, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1402, "seek": 442100, "start": 4431.0, "end": 4433.0, "text": " Yeah exactly.", "tokens": [50864, 865, 2293, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1403, "seek": 442100, "start": 4433.0, "end": 4435.0, "text": " Yeah exactly.", "tokens": [50964, 865, 2293, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1404, "seek": 442100, "start": 4435.0, "end": 4437.0, "text": " So we'll be talking more about.", "tokens": [51064, 407, 321, 603, 312, 1417, 544, 466, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1405, "seek": 442100, "start": 4437.0, "end": 4439.0, "text": " Like what's actually going on with that.", "tokens": [51164, 1743, 437, 311, 767, 516, 322, 365, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1406, "seek": 442100, "start": 4439.0, "end": 4441.0, "text": " Maybe next lesson.", "tokens": [51264, 2704, 958, 6898, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1407, "seek": 442100, "start": 4443.0, "end": 4445.0, "text": " Anyway so here's the curves as well.", "tokens": [51464, 5684, 370, 510, 311, 264, 19490, 382, 731, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1408, "seek": 442100, "start": 4445.0, "end": 4447.0, "text": " They're also pretty close.", "tokens": [51564, 814, 434, 611, 1238, 1998, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1409, "seek": 442100, "start": 4447.0, "end": 4449.0, "text": " So at this point I was kind of thinking.", "tokens": [51664, 407, 412, 341, 935, 286, 390, 733, 295, 1953, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2181390126546224, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.032577138394117355}, {"id": 1410, "seek": 444900, "start": 4449.0, "end": 4451.0, "text": " I'm going to try to do as little as possible.", "tokens": [50364, 286, 478, 516, 281, 853, 281, 360, 382, 707, 382, 1944, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1411, "seek": 444900, "start": 4451.0, "end": 4453.0, "text": " So I'm going to keep using a linear schedule.", "tokens": [50464, 407, 286, 478, 516, 281, 1066, 1228, 257, 8213, 7567, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1412, "seek": 444900, "start": 4453.0, "end": 4455.0, "text": " But I'm just going to change betamax to 0.01.", "tokens": [50564, 583, 286, 478, 445, 516, 281, 1319, 778, 2404, 87, 281, 1958, 13, 10607, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1413, "seek": 444900, "start": 4455.0, "end": 4457.0, "text": " For my next you know.", "tokens": [50664, 1171, 452, 958, 291, 458, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1414, "seek": 444900, "start": 4457.0, "end": 4459.0, "text": " Version of GDPM.", "tokens": [50764, 35965, 295, 19599, 44, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1415, "seek": 444900, "start": 4459.0, "end": 4461.0, "text": " So that's what I've got here.", "tokens": [50864, 407, 300, 311, 437, 286, 600, 658, 510, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1416, "seek": 444900, "start": 4461.0, "end": 4463.0, "text": " Linear schedule betamax 0.01.", "tokens": [50964, 14670, 289, 7567, 778, 2404, 87, 1958, 13, 10607, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1417, "seek": 444900, "start": 4463.0, "end": 4465.0, "text": " And so that I wouldn't really have to change any of my code.", "tokens": [51064, 400, 370, 300, 286, 2759, 380, 534, 362, 281, 1319, 604, 295, 452, 3089, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1418, "seek": 444900, "start": 4465.0, "end": 4467.0, "text": " I then just put those in the same variable names.", "tokens": [51164, 286, 550, 445, 829, 729, 294, 264, 912, 7006, 5288, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1419, "seek": 444900, "start": 4467.0, "end": 4469.0, "text": " That I've always used.", "tokens": [51264, 663, 286, 600, 1009, 1143, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1420, "seek": 444900, "start": 4469.0, "end": 4471.0, "text": " So then noisify is exactly the same.", "tokens": [51364, 407, 550, 572, 271, 2505, 307, 2293, 264, 912, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1421, "seek": 444900, "start": 4471.0, "end": 4473.0, "text": " As it always has been.", "tokens": [51464, 1018, 309, 1009, 575, 668, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1422, "seek": 444900, "start": 4473.0, "end": 4475.0, "text": " So now I just repeat.", "tokens": [51564, 407, 586, 286, 445, 7149, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1423, "seek": 444900, "start": 4475.0, "end": 4477.0, "text": " Everything that I've done before.", "tokens": [51664, 5471, 300, 286, 600, 1096, 949, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2255565235449833, "compression_ratio": 1.6933797909407666, "no_speech_prob": 0.08148599416017532}, {"id": 1424, "seek": 447700, "start": 4477.0, "end": 4479.0, "text": " And if I show a batch of data.", "tokens": [50364, 400, 498, 286, 855, 257, 15245, 295, 1412, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1425, "seek": 447700, "start": 4479.0, "end": 4481.0, "text": " I can already see.", "tokens": [50464, 286, 393, 1217, 536, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1426, "seek": 447700, "start": 4481.0, "end": 4483.0, "text": " That there's you know.", "tokens": [50564, 663, 456, 311, 291, 458, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1427, "seek": 447700, "start": 4483.0, "end": 4485.0, "text": " More actually recognizable images.", "tokens": [50664, 5048, 767, 40757, 5267, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1428, "seek": 447700, "start": 4485.0, "end": 4487.0, "text": " Which I think is very encouraging.", "tokens": [50764, 3013, 286, 519, 307, 588, 14580, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1429, "seek": 447700, "start": 4487.0, "end": 4489.0, "text": " Previously they like almost all of them.", "tokens": [50864, 33606, 436, 411, 1920, 439, 295, 552, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1430, "seek": 447700, "start": 4489.0, "end": 4491.0, "text": " Had been pure noise.", "tokens": [50964, 12298, 668, 6075, 5658, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1431, "seek": 447700, "start": 4491.0, "end": 4493.0, "text": " Which is not a good sign.", "tokens": [51064, 3013, 307, 406, 257, 665, 1465, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1432, "seek": 447700, "start": 4493.0, "end": 4495.0, "text": " So okay so now I just train it.", "tokens": [51164, 407, 1392, 370, 586, 286, 445, 3847, 309, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1433, "seek": 447700, "start": 4495.0, "end": 4497.0, "text": " Exactly the same as GDPM v2.", "tokens": [51264, 7587, 264, 912, 382, 19599, 44, 371, 17, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1434, "seek": 447700, "start": 4501.0, "end": 4503.0, "text": " And so save this as fashion GDPM 3.", "tokens": [51564, 400, 370, 3155, 341, 382, 6700, 19599, 44, 805, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1435, "seek": 447700, "start": 4503.0, "end": 4505.0, "text": " Oh and then the other things I've done here.", "tokens": [51664, 876, 293, 550, 264, 661, 721, 286, 600, 1096, 510, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2367901598286425, "compression_ratio": 1.4703557312252964, "no_speech_prob": 0.025168178603053093}, {"id": 1436, "seek": 450500, "start": 4505.0, "end": 4507.0, "text": " Is you know.", "tokens": [50364, 1119, 291, 458, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1437, "seek": 450500, "start": 4507.0, "end": 4509.0, "text": " This did turn out to work pretty well.", "tokens": [50464, 639, 630, 1261, 484, 281, 589, 1238, 731, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1438, "seek": 450500, "start": 4509.0, "end": 4511.0, "text": " I actually decided.", "tokens": [50564, 286, 767, 3047, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1439, "seek": 450500, "start": 4511.0, "end": 4513.0, "text": " Let's keep going even further.", "tokens": [50664, 961, 311, 1066, 516, 754, 3052, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1440, "seek": 450500, "start": 4513.0, "end": 4515.0, "text": " So I actually doubled all of my channels.", "tokens": [50764, 407, 286, 767, 24405, 439, 295, 452, 9235, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1441, "seek": 450500, "start": 4515.0, "end": 4517.0, "text": " From before.", "tokens": [50864, 3358, 949, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1442, "seek": 450500, "start": 4517.0, "end": 4519.0, "text": " And I also increased the number of epochs by 3.", "tokens": [50964, 400, 286, 611, 6505, 264, 1230, 295, 30992, 28346, 538, 805, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1443, "seek": 450500, "start": 4519.0, "end": 4521.0, "text": " Because things are going so well.", "tokens": [51064, 1436, 721, 366, 516, 370, 731, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1444, "seek": 450500, "start": 4521.0, "end": 4523.0, "text": " I was like how well could they go.", "tokens": [51164, 286, 390, 411, 577, 731, 727, 436, 352, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1445, "seek": 450500, "start": 4523.0, "end": 4525.0, "text": " So we've got a bigger model.", "tokens": [51264, 407, 321, 600, 658, 257, 3801, 2316, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1446, "seek": 450500, "start": 4525.0, "end": 4527.0, "text": " Trained for longer.", "tokens": [51364, 5403, 2001, 337, 2854, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1447, "seek": 450500, "start": 4527.0, "end": 4529.0, "text": " It only takes a few minutes.", "tokens": [51464, 467, 787, 2516, 257, 1326, 2077, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1448, "seek": 450500, "start": 4529.0, "end": 4531.0, "text": " So that's what the 25 here is.", "tokens": [51564, 407, 300, 311, 437, 264, 3552, 510, 307, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1449, "seek": 450500, "start": 4531.0, "end": 4533.0, "text": " The number of epochs.", "tokens": [51664, 440, 1230, 295, 30992, 28346, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1725300485773604, "compression_ratio": 1.575875486381323, "no_speech_prob": 0.00028239656239748}, {"id": 1450, "seek": 453300, "start": 4533.0, "end": 4535.0, "text": " And it's the same as it always has been.", "tokens": [50364, 400, 309, 311, 264, 912, 382, 309, 1009, 575, 668, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1451, "seek": 453300, "start": 4535.0, "end": 4537.0, "text": " So.", "tokens": [50464, 407, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1452, "seek": 453300, "start": 4537.0, "end": 4539.0, "text": " Create 512 samples.", "tokens": [50564, 20248, 1025, 4762, 10938, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1453, "seek": 453300, "start": 4539.0, "end": 4541.0, "text": " And here they are.", "tokens": [50664, 400, 510, 436, 366, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1454, "seek": 453300, "start": 4541.0, "end": 4543.0, "text": " And they definitely look to me.", "tokens": [50764, 400, 436, 2138, 574, 281, 385, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1455, "seek": 453300, "start": 4543.0, "end": 4545.0, "text": " You know.", "tokens": [50864, 509, 458, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1456, "seek": 453300, "start": 4545.0, "end": 4547.0, "text": " Great.", "tokens": [50964, 3769, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1457, "seek": 453300, "start": 4547.0, "end": 4549.0, "text": " Like I'm not sure I could recognize.", "tokens": [51064, 1743, 286, 478, 406, 988, 286, 727, 5521, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1458, "seek": 453300, "start": 4549.0, "end": 4551.0, "text": " Whether these are real samples.", "tokens": [51164, 8503, 613, 366, 957, 10938, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1459, "seek": 453300, "start": 4551.0, "end": 4553.0, "text": " Or generated samples.", "tokens": [51264, 1610, 10833, 10938, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1460, "seek": 453300, "start": 4553.0, "end": 4555.0, "text": " But luckily.", "tokens": [51364, 583, 22880, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1461, "seek": 453300, "start": 4555.0, "end": 4557.0, "text": " You know we can test them.", "tokens": [51464, 509, 458, 321, 393, 1500, 552, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1462, "seek": 453300, "start": 4557.0, "end": 4559.0, "text": " So we can load up our data org2.", "tokens": [51564, 407, 321, 393, 3677, 493, 527, 1412, 14045, 17, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1463, "seek": 453300, "start": 4559.0, "end": 4561.0, "text": " Delete the last two layers.", "tokens": [51664, 49452, 264, 1036, 732, 7914, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23104549754749645, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.02095901407301426}, {"id": 1464, "seek": 456100, "start": 4561.0, "end": 4563.0, "text": " Pass that to image val.", "tokens": [50364, 10319, 300, 281, 3256, 1323, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1465, "seek": 456100, "start": 4563.0, "end": 4565.0, "text": " And get a FID for our samples.", "tokens": [50464, 400, 483, 257, 479, 2777, 337, 527, 10938, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1466, "seek": 456100, "start": 4565.0, "end": 4567.0, "text": " And it's 8.", "tokens": [50564, 400, 309, 311, 1649, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1467, "seek": 456100, "start": 4567.0, "end": 4569.0, "text": " And then.", "tokens": [50664, 400, 550, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1468, "seek": 456100, "start": 4569.0, "end": 4571.0, "text": " I chose 512 for a reason.", "tokens": [50764, 286, 5111, 1025, 4762, 337, 257, 1778, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1469, "seek": 456100, "start": 4571.0, "end": 4573.0, "text": " Because that's our batch size.", "tokens": [50864, 1436, 300, 311, 527, 15245, 2744, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1470, "seek": 456100, "start": 4573.0, "end": 4575.0, "text": " So then I can compare that like with like.", "tokens": [50964, 407, 550, 286, 393, 6794, 300, 411, 365, 411, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1471, "seek": 456100, "start": 4575.0, "end": 4577.0, "text": " For the FID for the actual data.", "tokens": [51064, 1171, 264, 479, 2777, 337, 264, 3539, 1412, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1472, "seek": 456100, "start": 4577.0, "end": 4579.0, "text": " And it's 6.6.", "tokens": [51164, 400, 309, 311, 1386, 13, 21, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1473, "seek": 456100, "start": 4579.0, "end": 4581.0, "text": " So this is like hugely exciting to me.", "tokens": [51264, 407, 341, 307, 411, 27417, 4670, 281, 385, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1474, "seek": 456100, "start": 4581.0, "end": 4583.0, "text": " We've got down to a FID.", "tokens": [51364, 492, 600, 658, 760, 281, 257, 479, 2777, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1475, "seek": 456100, "start": 4583.0, "end": 4585.0, "text": " That is nearly as good as.", "tokens": [51464, 663, 307, 6217, 382, 665, 382, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1476, "seek": 456100, "start": 4585.0, "end": 4587.0, "text": " Real images.", "tokens": [51564, 8467, 5267, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1477, "seek": 456100, "start": 4587.0, "end": 4589.0, "text": " So I feel like.", "tokens": [51664, 407, 286, 841, 411, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17216281440314346, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0006361790001392365}, {"id": 1478, "seek": 458900, "start": 4589.0, "end": 4591.0, "text": " So I feel like this is.", "tokens": [50364, 407, 286, 841, 411, 341, 307, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1479, "seek": 458900, "start": 4591.0, "end": 4593.0, "text": " You know.", "tokens": [50464, 509, 458, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1480, "seek": 458900, "start": 4593.0, "end": 4595.0, "text": " In terms of image quality.", "tokens": [50564, 682, 2115, 295, 3256, 3125, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1481, "seek": 458900, "start": 4595.0, "end": 4597.0, "text": " For a small.", "tokens": [50664, 1171, 257, 1359, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1482, "seek": 458900, "start": 4597.0, "end": 4599.0, "text": " Unconditional sampling.", "tokens": [50764, 1156, 18882, 2628, 21179, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1483, "seek": 458900, "start": 4599.0, "end": 4601.0, "text": " I feel like we're done.", "tokens": [50864, 286, 841, 411, 321, 434, 1096, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1484, "seek": 458900, "start": 4601.0, "end": 4603.0, "text": " You know pretty much.", "tokens": [50964, 509, 458, 1238, 709, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1485, "seek": 458900, "start": 4603.0, "end": 4605.0, "text": " And so at this point.", "tokens": [51064, 400, 370, 412, 341, 935, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1486, "seek": 458900, "start": 4605.0, "end": 4607.0, "text": " I was like okay.", "tokens": [51164, 286, 390, 411, 1392, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1487, "seek": 458900, "start": 4607.0, "end": 4609.0, "text": " Well can we make it faster.", "tokens": [51264, 1042, 393, 321, 652, 309, 4663, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1488, "seek": 458900, "start": 4609.0, "end": 4611.0, "text": " You know at the same quality.", "tokens": [51364, 509, 458, 412, 264, 912, 3125, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1489, "seek": 458900, "start": 4611.0, "end": 4613.0, "text": " And I just wanted to experiment with a few things.", "tokens": [51464, 400, 286, 445, 1415, 281, 5120, 365, 257, 1326, 721, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1490, "seek": 458900, "start": 4613.0, "end": 4615.0, "text": " Like really obvious ideas.", "tokens": [51564, 1743, 534, 6322, 3487, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1491, "seek": 458900, "start": 4615.0, "end": 4617.0, "text": " And in particular I thought.", "tokens": [51664, 400, 294, 1729, 286, 1194, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17643386439273231, "compression_ratio": 1.5772727272727274, "no_speech_prob": 0.0012841369025409222}, {"id": 1492, "seek": 461700, "start": 4617.0, "end": 4619.0, "text": " We're calling this.", "tokens": [50364, 492, 434, 5141, 341, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1493, "seek": 461700, "start": 4621.0, "end": 4623.0, "text": " A thousand times.", "tokens": [50564, 316, 4714, 1413, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1494, "seek": 461700, "start": 4623.0, "end": 4625.0, "text": " Which means we're calling.", "tokens": [50664, 3013, 1355, 321, 434, 5141, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1495, "seek": 461700, "start": 4627.0, "end": 4629.0, "text": " This.", "tokens": [50864, 639, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1496, "seek": 461700, "start": 4629.0, "end": 4631.0, "text": " A thousand times.", "tokens": [50964, 316, 4714, 1413, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1497, "seek": 461700, "start": 4631.0, "end": 4633.0, "text": " Which is running the model.", "tokens": [51064, 3013, 307, 2614, 264, 2316, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1498, "seek": 461700, "start": 4633.0, "end": 4635.0, "text": " And that's slow.", "tokens": [51164, 400, 300, 311, 2964, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1499, "seek": 461700, "start": 4635.0, "end": 4637.0, "text": " And most of the time.", "tokens": [51264, 400, 881, 295, 264, 565, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1500, "seek": 461700, "start": 4637.0, "end": 4639.0, "text": " You just move a tiny bit.", "tokens": [51364, 509, 445, 1286, 257, 5870, 857, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1501, "seek": 461700, "start": 4639.0, "end": 4641.0, "text": " So the model is pretty much the same.", "tokens": [51464, 407, 264, 2316, 307, 1238, 709, 264, 912, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1502, "seek": 461700, "start": 4641.0, "end": 4643.0, "text": " You know the noise being predicted.", "tokens": [51564, 509, 458, 264, 5658, 885, 19147, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1503, "seek": 461700, "start": 4643.0, "end": 4645.0, "text": " Is pretty much the same.", "tokens": [51664, 1119, 1238, 709, 264, 912, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18716678824476016, "compression_ratio": 1.7610062893081762, "no_speech_prob": 0.0001488301350036636}, {"id": 1504, "seek": 464500, "start": 4645.0, "end": 4647.0, "text": " Which is obvious.", "tokens": [50364, 3013, 307, 6322, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1505, "seek": 464500, "start": 4647.0, "end": 4649.0, "text": " Which is I decided let's only call the model.", "tokens": [50464, 3013, 307, 286, 3047, 718, 311, 787, 818, 264, 2316, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1506, "seek": 464500, "start": 4649.0, "end": 4651.0, "text": " Every third time.", "tokens": [50564, 2048, 2636, 565, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1507, "seek": 464500, "start": 4651.0, "end": 4653.0, "text": " You know.", "tokens": [50664, 509, 458, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1508, "seek": 464500, "start": 4653.0, "end": 4655.0, "text": " And maybe also just the last 50.", "tokens": [50764, 400, 1310, 611, 445, 264, 1036, 2625, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1509, "seek": 464500, "start": 4655.0, "end": 4657.0, "text": " To help it fine tune.", "tokens": [50864, 1407, 854, 309, 2489, 10864, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1510, "seek": 464500, "start": 4657.0, "end": 4659.0, "text": " I don't know if that's necessary.", "tokens": [50964, 286, 500, 380, 458, 498, 300, 311, 4818, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1511, "seek": 464500, "start": 4659.0, "end": 4661.0, "text": " Other than that it's exactly the same.", "tokens": [51064, 5358, 813, 300, 309, 311, 2293, 264, 912, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1512, "seek": 464500, "start": 4661.0, "end": 4663.0, "text": " So now this is basically three times faster.", "tokens": [51164, 407, 586, 341, 307, 1936, 1045, 1413, 4663, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1513, "seek": 464500, "start": 4663.0, "end": 4665.0, "text": " And.", "tokens": [51264, 400, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1514, "seek": 464500, "start": 4665.0, "end": 4667.0, "text": " Yeah.", "tokens": [51364, 865, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1515, "seek": 464500, "start": 4667.0, "end": 4669.0, "text": " Samples look basically the same.", "tokens": [51464, 4832, 2622, 574, 1936, 264, 912, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1516, "seek": 464500, "start": 4669.0, "end": 4671.0, "text": " So the fit is 9.78.", "tokens": [51564, 407, 264, 3318, 307, 1722, 13, 30693, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1517, "seek": 464500, "start": 4671.0, "end": 4673.0, "text": " Versus 8.1.", "tokens": [51664, 12226, 301, 1649, 13, 16, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18107870069600768, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.17531433701515198}, {"id": 1518, "seek": 467300, "start": 4673.0, "end": 4675.0, "text": " And the normal variance of fit.", "tokens": [50364, 400, 264, 2710, 21977, 295, 3318, 13, 50464], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1519, "seek": 467300, "start": 4675.0, "end": 4677.0, "text": " So I don't know.", "tokens": [50464, 407, 286, 500, 380, 458, 13, 50564], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1520, "seek": 467300, "start": 4677.0, "end": 4679.0, "text": " You'd have to run this a few times.", "tokens": [50564, 509, 1116, 362, 281, 1190, 341, 257, 1326, 1413, 13, 50664], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1521, "seek": 467300, "start": 4679.0, "end": 4681.0, "text": " Or use bigger samples.", "tokens": [50664, 1610, 764, 3801, 10938, 13, 50764], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1522, "seek": 467300, "start": 4681.0, "end": 4683.0, "text": " But this is basically saying.", "tokens": [50764, 583, 341, 307, 1936, 1566, 13, 50864], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1523, "seek": 467300, "start": 4683.0, "end": 4685.0, "text": " Yeah you probably don't need to.", "tokens": [50864, 865, 291, 1391, 500, 380, 643, 281, 13, 50964], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1524, "seek": 467300, "start": 4685.0, "end": 4687.0, "text": " Call the model a thousand times.", "tokens": [50964, 7807, 264, 2316, 257, 4714, 1413, 13, 51064], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1525, "seek": 467300, "start": 4687.0, "end": 4689.0, "text": " I did something else slightly weird.", "tokens": [51064, 286, 630, 746, 1646, 4748, 3657, 13, 51164], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1526, "seek": 467300, "start": 4689.0, "end": 4691.0, "text": " Which is I basically said.", "tokens": [51164, 3013, 307, 286, 1936, 848, 13, 51264], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1527, "seek": 467300, "start": 4691.0, "end": 4693.0, "text": " Let's create a different schedule.", "tokens": [51264, 961, 311, 1884, 257, 819, 7567, 13, 51364], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1528, "seek": 467300, "start": 4693.0, "end": 4695.0, "text": " For how often we call the model.", "tokens": [51364, 1171, 577, 2049, 321, 818, 264, 2316, 13, 51464], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1529, "seek": 467300, "start": 4695.0, "end": 4697.0, "text": " Which is I created this thing called sampleAt.", "tokens": [51464, 3013, 307, 286, 2942, 341, 551, 1219, 6889, 18684, 13, 51564], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1530, "seek": 467300, "start": 4697.0, "end": 4699.0, "text": " It basically said.", "tokens": [51564, 467, 1936, 848, 13, 51664], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1531, "seek": 467300, "start": 4699.0, "end": 4701.0, "text": " When you're.", "tokens": [51664, 1133, 291, 434, 13, 51764], "temperature": 0.0, "avg_logprob": -0.212863037109375, "compression_ratio": 1.656, "no_speech_prob": 0.0912991613149643}, {"id": 1532, "seek": 470100, "start": 4701.0, "end": 4703.0, "text": " Every 10.", "tokens": [50364, 2048, 1266, 13, 50464], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1533, "seek": 470100, "start": 4703.0, "end": 4705.0, "text": " And then for the next few every 9.", "tokens": [50464, 400, 550, 337, 264, 958, 1326, 633, 1722, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1534, "seek": 470100, "start": 4705.0, "end": 4707.0, "text": " And then for the next few every 8.", "tokens": [50564, 400, 550, 337, 264, 958, 1326, 633, 1649, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1535, "seek": 470100, "start": 4707.0, "end": 4709.0, "text": " And so forth.", "tokens": [50664, 400, 370, 5220, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1536, "seek": 470100, "start": 4709.0, "end": 4711.0, "text": " And just for the last 100 do it every 1.", "tokens": [50764, 400, 445, 337, 264, 1036, 2319, 360, 309, 633, 502, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1537, "seek": 470100, "start": 4711.0, "end": 4713.0, "text": " So that makes it even faster.", "tokens": [50864, 407, 300, 1669, 309, 754, 4663, 13, 50964], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1538, "seek": 470100, "start": 4713.0, "end": 4715.0, "text": " Samples look good.", "tokens": [50964, 4832, 2622, 574, 665, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1539, "seek": 470100, "start": 4715.0, "end": 4717.0, "text": " This is.", "tokens": [51064, 639, 307, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1540, "seek": 470100, "start": 4717.0, "end": 4719.0, "text": " You know it's definitely worse though now.", "tokens": [51164, 509, 458, 309, 311, 2138, 5324, 1673, 586, 13, 51264], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1541, "seek": 470100, "start": 4719.0, "end": 4721.0, "text": " But it's still not bad.", "tokens": [51264, 583, 309, 311, 920, 406, 1578, 13, 51364], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1542, "seek": 470100, "start": 4721.0, "end": 4723.0, "text": " So.", "tokens": [51364, 407, 13, 51464], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1543, "seek": 470100, "start": 4723.0, "end": 4725.0, "text": " Yeah I kind of felt like.", "tokens": [51464, 865, 286, 733, 295, 2762, 411, 13, 51564], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1544, "seek": 470100, "start": 4725.0, "end": 4727.0, "text": " All right this is encouraging.", "tokens": [51564, 1057, 558, 341, 307, 14580, 13, 51664], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1545, "seek": 470100, "start": 4727.0, "end": 4729.0, "text": " And this stuff before we fixed the.", "tokens": [51664, 400, 341, 1507, 949, 321, 6806, 264, 13, 51764], "temperature": 0.0, "avg_logprob": -0.24605393409729004, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.17542147636413574}, {"id": 1546, "seek": 472900, "start": 4729.0, "end": 4731.0, "text": " They looked really bad.", "tokens": [50364, 814, 2956, 534, 1578, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1547, "seek": 472900, "start": 4731.0, "end": 4733.0, "text": " You know.", "tokens": [50464, 509, 458, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1548, "seek": 472900, "start": 4733.0, "end": 4735.0, "text": " That's why I was thinking my code was full of bugs.", "tokens": [50564, 663, 311, 983, 286, 390, 1953, 452, 3089, 390, 1577, 295, 15120, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1549, "seek": 472900, "start": 4735.0, "end": 4737.0, "text": " So at this point I'm thinking.", "tokens": [50664, 407, 412, 341, 935, 286, 478, 1953, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1550, "seek": 472900, "start": 4737.0, "end": 4739.0, "text": " Okay we can create extremely high quality.", "tokens": [50764, 1033, 321, 393, 1884, 4664, 1090, 3125, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1551, "seek": 472900, "start": 4739.0, "end": 4741.0, "text": " Samples using ddpm.", "tokens": [50864, 4832, 2622, 1228, 274, 67, 14395, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1552, "seek": 472900, "start": 4741.0, "end": 4743.0, "text": " What's the like.", "tokens": [50964, 708, 311, 264, 411, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1553, "seek": 472900, "start": 4743.0, "end": 4745.0, "text": " You know best paper out there.", "tokens": [51064, 509, 458, 1151, 3035, 484, 456, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1554, "seek": 472900, "start": 4745.0, "end": 4747.0, "text": " For doing it faster.", "tokens": [51164, 1171, 884, 309, 4663, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1555, "seek": 472900, "start": 4747.0, "end": 4749.0, "text": " And the most popular paper for doing it faster.", "tokens": [51264, 400, 264, 881, 3743, 3035, 337, 884, 309, 4663, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1556, "seek": 472900, "start": 4749.0, "end": 4751.0, "text": " Is ddim.", "tokens": [51364, 1119, 274, 67, 332, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1557, "seek": 472900, "start": 4751.0, "end": 4753.0, "text": " So I thought.", "tokens": [51464, 407, 286, 1194, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1558, "seek": 472900, "start": 4753.0, "end": 4755.0, "text": " We might switch to this next.", "tokens": [51564, 492, 1062, 3679, 281, 341, 958, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1559, "seek": 472900, "start": 4755.0, "end": 4757.0, "text": " So we're now at the point.", "tokens": [51664, 407, 321, 434, 586, 412, 264, 935, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21370599365234375, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.026743346825242043}, {"id": 1560, "seek": 475700, "start": 4757.0, "end": 4759.0, "text": " Where we're not actually going to.", "tokens": [50364, 2305, 321, 434, 406, 767, 516, 281, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1561, "seek": 475700, "start": 4759.0, "end": 4761.0, "text": " Retrain our model at all.", "tokens": [50464, 11495, 7146, 527, 2316, 412, 439, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1562, "seek": 475700, "start": 4761.0, "end": 4763.0, "text": " Right if you noticed.", "tokens": [50564, 1779, 498, 291, 5694, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1563, "seek": 475700, "start": 4763.0, "end": 4765.0, "text": " With these different sampling approaches.", "tokens": [50664, 2022, 613, 819, 21179, 11587, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1564, "seek": 475700, "start": 4765.0, "end": 4767.0, "text": " I didn't retrain the model at all.", "tokens": [50764, 286, 994, 380, 1533, 7146, 264, 2316, 412, 439, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1565, "seek": 475700, "start": 4767.0, "end": 4769.0, "text": " We're just saying okay we've got a model.", "tokens": [50864, 492, 434, 445, 1566, 1392, 321, 600, 658, 257, 2316, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1566, "seek": 475700, "start": 4769.0, "end": 4771.0, "text": " The model knows how to.", "tokens": [50964, 440, 2316, 3255, 577, 281, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1567, "seek": 475700, "start": 4771.0, "end": 4773.0, "text": " Estimate the noise in an image.", "tokens": [51064, 4410, 2905, 264, 5658, 294, 364, 3256, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1568, "seek": 475700, "start": 4773.0, "end": 4775.0, "text": " How do we use that.", "tokens": [51164, 1012, 360, 321, 764, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1569, "seek": 475700, "start": 4775.0, "end": 4777.0, "text": " To call it multiple times.", "tokens": [51264, 1407, 818, 309, 3866, 1413, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1570, "seek": 475700, "start": 4777.0, "end": 4779.0, "text": " To.", "tokens": [51364, 1407, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1571, "seek": 475700, "start": 4779.0, "end": 4781.0, "text": " Denoise using.", "tokens": [51464, 413, 5808, 908, 1228, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1572, "seek": 475700, "start": 4781.0, "end": 4783.0, "text": " Iterative refinement.", "tokens": [51564, 286, 391, 1166, 1895, 30229, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1573, "seek": 475700, "start": 4783.0, "end": 4785.0, "text": " As Jono calls it.", "tokens": [51664, 1018, 7745, 78, 5498, 309, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19387392137871415, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.017441319301724434}, {"id": 1574, "seek": 478500, "start": 4785.0, "end": 4787.0, "text": " And so.", "tokens": [50364, 400, 370, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1575, "seek": 478500, "start": 4787.0, "end": 4789.0, "text": " Ddim.", "tokens": [50464, 413, 67, 332, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1576, "seek": 478500, "start": 4789.0, "end": 4791.0, "text": " Is a.", "tokens": [50564, 1119, 257, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1577, "seek": 478500, "start": 4791.0, "end": 4793.0, "text": " Other way of doing that.", "tokens": [50664, 5358, 636, 295, 884, 300, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1578, "seek": 478500, "start": 4793.0, "end": 4795.0, "text": " So what we're going to do.", "tokens": [50764, 407, 437, 321, 434, 516, 281, 360, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1579, "seek": 478500, "start": 4795.0, "end": 4797.0, "text": " I'm going to show you how I.", "tokens": [50864, 286, 478, 516, 281, 855, 291, 577, 286, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1580, "seek": 478500, "start": 4797.0, "end": 4799.0, "text": " Built.", "tokens": [50964, 49822, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1581, "seek": 478500, "start": 4799.0, "end": 4801.0, "text": " My own ddim.", "tokens": [51064, 1222, 1065, 274, 67, 332, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1582, "seek": 478500, "start": 4801.0, "end": 4803.0, "text": " From scratch.", "tokens": [51164, 3358, 8459, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1583, "seek": 478500, "start": 4803.0, "end": 4805.0, "text": " And I kind of cheated.", "tokens": [51264, 400, 286, 733, 295, 28079, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1584, "seek": 478500, "start": 4805.0, "end": 4807.0, "text": " Which is a.", "tokens": [51364, 3013, 307, 257, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1585, "seek": 478500, "start": 4807.0, "end": 4809.0, "text": " There's already an existing one in diffusers.", "tokens": [51464, 821, 311, 1217, 364, 6741, 472, 294, 7593, 301, 433, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1586, "seek": 478500, "start": 4809.0, "end": 4811.0, "text": " So I decided.", "tokens": [51564, 407, 286, 3047, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1587, "seek": 478500, "start": 4811.0, "end": 4813.0, "text": " I will use that first.", "tokens": [51664, 286, 486, 764, 300, 700, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19847208658854168, "compression_ratio": 1.423728813559322, "no_speech_prob": 5.390957812778652e-05}, {"id": 1588, "seek": 481300, "start": 4813.0, "end": 4815.0, "text": " Make sure everything works.", "tokens": [50364, 4387, 988, 1203, 1985, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1589, "seek": 481300, "start": 4815.0, "end": 4817.0, "text": " And then I'll try and reimplement it from scratch.", "tokens": [50464, 400, 550, 286, 603, 853, 293, 33433, 43704, 309, 490, 8459, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1590, "seek": 481300, "start": 4817.0, "end": 4819.0, "text": " Myself.", "tokens": [50564, 37795, 1967, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1591, "seek": 481300, "start": 4819.0, "end": 4821.0, "text": " So that's kind of like.", "tokens": [50664, 407, 300, 311, 733, 295, 411, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1592, "seek": 481300, "start": 4821.0, "end": 4823.0, "text": " When there's an existing thing that works.", "tokens": [50764, 1133, 456, 311, 364, 6741, 551, 300, 1985, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1593, "seek": 481300, "start": 4823.0, "end": 4825.0, "text": " That's what I like to do.", "tokens": [50864, 663, 311, 437, 286, 411, 281, 360, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1594, "seek": 481300, "start": 4825.0, "end": 4827.0, "text": " And it's been really good.", "tokens": [50964, 400, 309, 311, 668, 534, 665, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1595, "seek": 481300, "start": 4827.0, "end": 4829.0, "text": " To have my own ddim from scratch.", "tokens": [51064, 1407, 362, 452, 1065, 274, 67, 332, 490, 8459, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1596, "seek": 481300, "start": 4829.0, "end": 4831.0, "text": " Because now I can modify it.", "tokens": [51164, 1436, 586, 286, 393, 16927, 309, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1597, "seek": 481300, "start": 4831.0, "end": 4833.0, "text": " And I've made it much more.", "tokens": [51264, 400, 286, 600, 1027, 309, 709, 544, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1598, "seek": 481300, "start": 4833.0, "end": 4835.0, "text": " Concise code than the diffusers version.", "tokens": [51364, 18200, 908, 3089, 813, 264, 7593, 301, 433, 3037, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1599, "seek": 481300, "start": 4835.0, "end": 4837.0, "text": " So.", "tokens": [51464, 407, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1600, "seek": 481300, "start": 4837.0, "end": 4839.0, "text": " Now.", "tokens": [51564, 823, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1601, "seek": 481300, "start": 4839.0, "end": 4841.0, "text": " We had created this.", "tokens": [51664, 492, 632, 2942, 341, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1611726531982422, "compression_ratio": 1.5726495726495726, "no_speech_prob": 0.00020662280439864844}, {"id": 1602, "seek": 484100, "start": 4841.0, "end": 4843.0, "text": " Class called unit.", "tokens": [50364, 9471, 1219, 4985, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1603, "seek": 484100, "start": 4845.0, "end": 4847.0, "text": " Which.", "tokens": [50564, 3013, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1604, "seek": 484100, "start": 4847.0, "end": 4849.0, "text": " Asked the tuple of x's.", "tokens": [50664, 12320, 292, 264, 2604, 781, 295, 2031, 311, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1605, "seek": 484100, "start": 4849.0, "end": 4851.0, "text": " Through as individual parameters.", "tokens": [50764, 8927, 382, 2609, 9834, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1606, "seek": 484100, "start": 4851.0, "end": 4853.0, "text": " And returned the dot sample.", "tokens": [50864, 400, 8752, 264, 5893, 6889, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1607, "seek": 484100, "start": 4853.0, "end": 4855.0, "text": " But not surprisingly.", "tokens": [50964, 583, 406, 17600, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1608, "seek": 484100, "start": 4855.0, "end": 4857.0, "text": " The given that this comes from diffusers.", "tokens": [51064, 440, 2212, 300, 341, 1487, 490, 7593, 301, 433, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1609, "seek": 484100, "start": 4857.0, "end": 4859.0, "text": " And we want to use the diffuser schedulers.", "tokens": [51164, 400, 321, 528, 281, 764, 264, 7593, 18088, 12000, 433, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1610, "seek": 484100, "start": 4861.0, "end": 4863.0, "text": " The diffusers.", "tokens": [51364, 440, 7593, 301, 433, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1611, "seek": 484100, "start": 4863.0, "end": 4865.0, "text": " Schedulers.", "tokens": [51464, 44926, 425, 433, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1612, "seek": 484100, "start": 4865.0, "end": 4867.0, "text": " Assume this has not happened.", "tokens": [51564, 6281, 2540, 341, 575, 406, 2011, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1613, "seek": 484100, "start": 4867.0, "end": 4869.0, "text": " It wants the x.", "tokens": [51664, 467, 2738, 264, 2031, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21964495522635324, "compression_ratio": 1.5421052631578946, "no_speech_prob": 5.9208232414675876e-05}, {"id": 1614, "seek": 486900, "start": 4869.0, "end": 4871.0, "text": " As a tuple.", "tokens": [50364, 1018, 257, 2604, 781, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1615, "seek": 486900, "start": 4871.0, "end": 4873.0, "text": " And it expects to find the think.cod.sample.", "tokens": [50464, 400, 309, 33280, 281, 915, 264, 519, 13, 1291, 67, 13, 19988, 781, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1616, "seek": 486900, "start": 4873.0, "end": 4875.0, "text": " So here's something crazy.", "tokens": [50564, 407, 510, 311, 746, 3219, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1617, "seek": 486900, "start": 4875.0, "end": 4877.0, "text": " When we save.", "tokens": [50664, 1133, 321, 3155, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1618, "seek": 486900, "start": 4877.0, "end": 4879.0, "text": " This thing.", "tokens": [50764, 639, 551, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1619, "seek": 486900, "start": 4879.0, "end": 4881.0, "text": " This pickle.", "tokens": [50864, 639, 31433, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1620, "seek": 486900, "start": 4881.0, "end": 4883.0, "text": " It doesn't really know anything about the code.", "tokens": [50964, 467, 1177, 380, 534, 458, 1340, 466, 264, 3089, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1621, "seek": 486900, "start": 4883.0, "end": 4885.0, "text": " Right.", "tokens": [51064, 1779, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1622, "seek": 486900, "start": 4885.0, "end": 4887.0, "text": " It just knows that it's from a class.", "tokens": [51164, 467, 445, 3255, 300, 309, 311, 490, 257, 1508, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1623, "seek": 486900, "start": 4887.0, "end": 4889.0, "text": " Called unit.", "tokens": [51264, 45001, 4985, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1624, "seek": 486900, "start": 4889.0, "end": 4891.0, "text": " So we can actually.", "tokens": [51364, 407, 321, 393, 767, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1625, "seek": 486900, "start": 4891.0, "end": 4893.0, "text": " Lie.", "tokens": [51464, 11197, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1626, "seek": 486900, "start": 4893.0, "end": 4895.0, "text": " We can say.", "tokens": [51564, 492, 393, 584, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1627, "seek": 486900, "start": 4895.0, "end": 4897.0, "text": " Oh yeah.", "tokens": [51664, 876, 1338, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2197273877950815, "compression_ratio": 1.4421052631578948, "no_speech_prob": 0.00024922628654167056}, {"id": 1628, "seek": 489700, "start": 4897.0, "end": 4899.0, "text": " We can say.", "tokens": [50364, 492, 393, 584, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1629, "seek": 489700, "start": 4899.0, "end": 4901.0, "text": " This is a model with no other changes.", "tokens": [50464, 639, 307, 257, 2316, 365, 572, 661, 2962, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1630, "seek": 489700, "start": 4901.0, "end": 4903.0, "text": " And python doesn't know or care.", "tokens": [50564, 400, 38797, 1177, 380, 458, 420, 1127, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1631, "seek": 489700, "start": 4903.0, "end": 4905.0, "text": " Right.", "tokens": [50664, 1779, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1632, "seek": 489700, "start": 4905.0, "end": 4907.0, "text": " So this we can now load up this model.", "tokens": [50764, 407, 341, 321, 393, 586, 3677, 493, 341, 2316, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1633, "seek": 489700, "start": 4907.0, "end": 4909.0, "text": " And it's going to use this unit.", "tokens": [50864, 400, 309, 311, 516, 281, 764, 341, 4985, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1634, "seek": 489700, "start": 4909.0, "end": 4911.0, "text": " Okay.", "tokens": [50964, 1033, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1635, "seek": 489700, "start": 4911.0, "end": 4913.0, "text": " So this is where it's useful to understand.", "tokens": [51064, 407, 341, 307, 689, 309, 311, 4420, 281, 1223, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1636, "seek": 489700, "start": 4913.0, "end": 4915.0, "text": " How python works behind the scenes.", "tokens": [51164, 1012, 38797, 1985, 2261, 264, 8026, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1637, "seek": 489700, "start": 4915.0, "end": 4917.0, "text": " Right it's it's it's a very simple.", "tokens": [51264, 1779, 309, 311, 309, 311, 309, 311, 257, 588, 2199, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1638, "seek": 489700, "start": 4917.0, "end": 4919.0, "text": " Programming language.", "tokens": [51364, 8338, 2810, 2856, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1639, "seek": 489700, "start": 4919.0, "end": 4921.0, "text": " So we've now got a model.", "tokens": [51464, 407, 321, 600, 586, 658, 257, 2316, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1640, "seek": 489700, "start": 4921.0, "end": 4923.0, "text": " Which we've trained.", "tokens": [51564, 3013, 321, 600, 8895, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1641, "seek": 489700, "start": 4923.0, "end": 4925.0, "text": " But it's not it's just going to.", "tokens": [51664, 583, 309, 311, 406, 309, 311, 445, 516, 281, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2393309423165728, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.010811432264745235}, {"id": 1642, "seek": 492500, "start": 4925.0, "end": 4927.0, "text": " Work seamlessly.", "tokens": [50364, 6603, 38083, 13, 50464], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1643, "seek": 492500, "start": 4927.0, "end": 4929.0, "text": " With the.", "tokens": [50464, 2022, 264, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1644, "seek": 492500, "start": 4929.0, "end": 4931.0, "text": " Diffuser schedulers.", "tokens": [50564, 413, 3661, 18088, 12000, 433, 13, 50664], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1645, "seek": 492500, "start": 4931.0, "end": 4933.0, "text": " So we'll start by actually repeating what we already know.", "tokens": [50664, 407, 321, 603, 722, 538, 767, 18617, 437, 321, 1217, 458, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1646, "seek": 492500, "start": 4933.0, "end": 4935.0, "text": " How to do.", "tokens": [50764, 1012, 281, 360, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1647, "seek": 492500, "start": 4935.0, "end": 4937.0, "text": " Which is use a ddpm scheduler.", "tokens": [50864, 3013, 307, 764, 257, 274, 67, 14395, 12000, 260, 13, 50964], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1648, "seek": 492500, "start": 4937.0, "end": 4939.0, "text": " So we have to tell it what beta we used.", "tokens": [50964, 407, 321, 362, 281, 980, 309, 437, 9861, 321, 1143, 13, 51064], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1649, "seek": 492500, "start": 4939.0, "end": 4941.0, "text": " To train.", "tokens": [51064, 1407, 3847, 13, 51164], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1650, "seek": 492500, "start": 4941.0, "end": 4943.0, "text": " And so we can grab some random data.", "tokens": [51164, 400, 370, 321, 393, 4444, 512, 4974, 1412, 13, 51264], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1651, "seek": 492500, "start": 4943.0, "end": 4945.0, "text": " And so.", "tokens": [51264, 400, 370, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1652, "seek": 492500, "start": 4945.0, "end": 4947.0, "text": " We could say.", "tokens": [51364, 492, 727, 584, 13, 51464], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1653, "seek": 492500, "start": 4947.0, "end": 4949.0, "text": " Okay we're going to start.", "tokens": [51464, 1033, 321, 434, 516, 281, 722, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1654, "seek": 492500, "start": 4949.0, "end": 4951.0, "text": " At time step 999.", "tokens": [51564, 1711, 565, 1823, 1722, 8494, 13, 51664], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1655, "seek": 492500, "start": 4951.0, "end": 4953.0, "text": " So let's create a batch of data.", "tokens": [51664, 407, 718, 311, 1884, 257, 15245, 295, 1412, 13, 51764], "temperature": 0.0, "avg_logprob": -0.23189401626586914, "compression_ratio": 1.5272727272727273, "no_speech_prob": 0.05827099457383156}, {"id": 1656, "seek": 495300, "start": 4953.0, "end": 4955.0, "text": " And this is the way that diffuses thing works.", "tokens": [50364, 400, 341, 307, 264, 636, 300, 7593, 8355, 551, 1985, 13, 50464], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1657, "seek": 495300, "start": 4955.0, "end": 4957.0, "text": " Is you call scheduler.step.", "tokens": [50464, 1119, 291, 818, 12000, 260, 13, 16792, 13, 50564], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1658, "seek": 495300, "start": 4957.0, "end": 4959.0, "text": " And that's the thing.", "tokens": [50564, 400, 300, 311, 264, 551, 13, 50664], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1659, "seek": 495300, "start": 4959.0, "end": 4961.0, "text": " Which does.", "tokens": [50664, 3013, 775, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1660, "seek": 495300, "start": 4961.0, "end": 4963.0, "text": " Those lines.", "tokens": [50764, 3950, 3876, 13, 50864], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1661, "seek": 495300, "start": 4963.0, "end": 4965.0, "text": " That's the thing.", "tokens": [50864, 663, 311, 264, 551, 13, 50964], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1662, "seek": 495300, "start": 4965.0, "end": 4967.0, "text": " That calculates.", "tokens": [50964, 663, 4322, 1024, 13, 51064], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1663, "seek": 495300, "start": 4967.0, "end": 4969.0, "text": " Xt given noise.", "tokens": [51064, 1783, 83, 2212, 5658, 13, 51164], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1664, "seek": 495300, "start": 4969.0, "end": 4971.0, "text": " So that's what.", "tokens": [51164, 407, 300, 311, 437, 13, 51264], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1665, "seek": 495300, "start": 4971.0, "end": 4973.0, "text": " Scheduler.step does.", "tokens": [51264, 44926, 26318, 13, 16792, 775, 13, 51364], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1666, "seek": 495300, "start": 4973.0, "end": 4975.0, "text": " So that's why you pass in.", "tokens": [51364, 407, 300, 311, 983, 291, 1320, 294, 13, 51464], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1667, "seek": 495300, "start": 4975.0, "end": 4977.0, "text": " Xt and the time step and the noise.", "tokens": [51464, 1783, 83, 293, 264, 565, 1823, 293, 264, 5658, 13, 51564], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1668, "seek": 495300, "start": 4977.0, "end": 4979.0, "text": " And that's going to give you a new.", "tokens": [51564, 400, 300, 311, 516, 281, 976, 291, 257, 777, 13, 51664], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1669, "seek": 495300, "start": 4979.0, "end": 4981.0, "text": " Set.", "tokens": [51664, 8928, 13, 51764], "temperature": 0.0, "avg_logprob": -0.22182106149607692, "compression_ratio": 1.7885714285714285, "no_speech_prob": 0.003428329946473241}, {"id": 1670, "seek": 498100, "start": 4981.0, "end": 4983.0, "text": " And so I ran that.", "tokens": [50364, 400, 370, 286, 5872, 300, 13, 50464], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1671, "seek": 498100, "start": 4983.0, "end": 4985.0, "text": " As usual first.", "tokens": [50464, 1018, 7713, 700, 13, 50564], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1672, "seek": 498100, "start": 4985.0, "end": 4987.0, "text": " Cell by cell to make sure I understood how it all worked.", "tokens": [50564, 28859, 538, 2815, 281, 652, 988, 286, 7320, 577, 309, 439, 2732, 13, 50664], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1673, "seek": 498100, "start": 4987.0, "end": 4989.0, "text": " I then copied those cells.", "tokens": [50664, 286, 550, 25365, 729, 5438, 13, 50764], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1674, "seek": 498100, "start": 4989.0, "end": 4991.0, "text": " And merged them together.", "tokens": [50764, 400, 36427, 552, 1214, 13, 50864], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1675, "seek": 498100, "start": 4991.0, "end": 4993.0, "text": " And chucked them in a loop.", "tokens": [50864, 400, 20870, 292, 552, 294, 257, 6367, 13, 50964], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1676, "seek": 498100, "start": 4993.0, "end": 4995.0, "text": " So this is now going to go through all the time steps.", "tokens": [50964, 407, 341, 307, 586, 516, 281, 352, 807, 439, 264, 565, 4439, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1677, "seek": 498100, "start": 4995.0, "end": 4997.0, "text": " Use a progress bar to see how we're going.", "tokens": [51064, 8278, 257, 4205, 2159, 281, 536, 577, 321, 434, 516, 13, 51164], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1678, "seek": 498100, "start": 4997.0, "end": 4999.0, "text": " Get the noise.", "tokens": [51164, 3240, 264, 5658, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1679, "seek": 498100, "start": 4999.0, "end": 5001.0, "text": " Call step.", "tokens": [51264, 7807, 1823, 13, 51364], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1680, "seek": 498100, "start": 5001.0, "end": 5003.0, "text": " And append.", "tokens": [51364, 400, 34116, 13, 51464], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1681, "seek": 498100, "start": 5003.0, "end": 5005.0, "text": " So this is just ddpm.", "tokens": [51464, 407, 341, 307, 445, 274, 67, 14395, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1682, "seek": 498100, "start": 5005.0, "end": 5007.0, "text": " But using diffusers.", "tokens": [51564, 583, 1228, 7593, 301, 433, 13, 51664], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1683, "seek": 498100, "start": 5007.0, "end": 5009.0, "text": " And not surprisingly.", "tokens": [51664, 400, 406, 17600, 13, 51764], "temperature": 0.0, "avg_logprob": -0.16606538526473508, "compression_ratio": 1.5982905982905984, "no_speech_prob": 0.034613702446222305}, {"id": 1684, "seek": 500900, "start": 5009.0, "end": 5011.0, "text": " We got exactly the same results.", "tokens": [50364, 492, 658, 2293, 264, 912, 3542, 13, 50464], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1685, "seek": 500900, "start": 5011.0, "end": 5013.0, "text": " As you know.", "tokens": [50464, 1018, 291, 458, 13, 50564], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1686, "seek": 500900, "start": 5013.0, "end": 5015.0, "text": " Nice results.", "tokens": [50564, 5490, 3542, 13, 50664], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1687, "seek": 500900, "start": 5015.0, "end": 5017.0, "text": " Very nice results.", "tokens": [50664, 4372, 1481, 3542, 13, 50764], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1688, "seek": 500900, "start": 5017.0, "end": 5019.0, "text": " That we got from our own ddpm.", "tokens": [50764, 663, 321, 658, 490, 527, 1065, 274, 67, 14395, 13, 50864], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1689, "seek": 500900, "start": 5019.0, "end": 5021.0, "text": " And so we can now.", "tokens": [50864, 400, 370, 321, 393, 586, 13, 50964], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1690, "seek": 500900, "start": 5021.0, "end": 5023.0, "text": " Use the same code we've used before.", "tokens": [50964, 8278, 264, 912, 3089, 321, 600, 1143, 949, 13, 51064], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1691, "seek": 500900, "start": 5023.0, "end": 5025.0, "text": " To create our image evaluator.", "tokens": [51064, 1407, 1884, 527, 3256, 6133, 1639, 13, 51164], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1692, "seek": 500900, "start": 5025.0, "end": 5027.0, "text": " And I decided.", "tokens": [51164, 400, 286, 3047, 13, 51264], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1693, "seek": 500900, "start": 5027.0, "end": 5029.0, "text": " Yeah we're now going to.", "tokens": [51264, 865, 321, 434, 586, 516, 281, 13, 51364], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1694, "seek": 500900, "start": 5029.0, "end": 5031.0, "text": " Go right up to 2048.", "tokens": [51364, 1037, 558, 493, 281, 945, 13318, 13, 51464], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1695, "seek": 500900, "start": 5031.0, "end": 5033.0, "text": " Images at a time.", "tokens": [51464, 4331, 1660, 412, 257, 565, 13, 51564], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1696, "seek": 500900, "start": 5033.0, "end": 5035.0, "text": " So it's now.", "tokens": [51564, 407, 309, 311, 586, 13, 51664], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1697, "seek": 500900, "start": 5035.0, "end": 5037.0, "text": " This is the size I found.", "tokens": [51664, 639, 307, 264, 2744, 286, 1352, 13, 51764], "temperature": 0.0, "avg_logprob": -0.22772320385636954, "compression_ratio": 1.5023923444976077, "no_speech_prob": 0.13110116124153137}, {"id": 1698, "seek": 503700, "start": 5037.0, "end": 5039.0, "text": " We're now down to 3.7.", "tokens": [50364, 492, 434, 586, 760, 281, 805, 13, 22, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1699, "seek": 503700, "start": 5039.0, "end": 5041.0, "text": " For our FID.", "tokens": [50464, 1171, 527, 479, 2777, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1700, "seek": 503700, "start": 5041.0, "end": 5043.0, "text": " Where else the data itself has a FID of 1.9.", "tokens": [50564, 2305, 1646, 264, 1412, 2564, 575, 257, 479, 2777, 295, 502, 13, 24, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1701, "seek": 503700, "start": 5043.0, "end": 5045.0, "text": " So again it's showing that our ddpm.", "tokens": [50664, 407, 797, 309, 311, 4099, 300, 527, 274, 67, 14395, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1702, "seek": 503700, "start": 5045.0, "end": 5047.0, "text": " Is basically.", "tokens": [50764, 1119, 1936, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1703, "seek": 503700, "start": 5047.0, "end": 5049.0, "text": " Very nearly.", "tokens": [50864, 4372, 6217, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1704, "seek": 503700, "start": 5049.0, "end": 5051.0, "text": " Unrecognizably different.", "tokens": [50964, 1156, 13867, 2912, 590, 1188, 819, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1705, "seek": 503700, "start": 5051.0, "end": 5053.0, "text": " From real data.", "tokens": [51064, 3358, 957, 1412, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1706, "seek": 503700, "start": 5053.0, "end": 5055.0, "text": " Using its distribution of those activations.", "tokens": [51164, 11142, 1080, 7316, 295, 729, 2430, 763, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1707, "seek": 503700, "start": 5055.0, "end": 5057.0, "text": " So then we can switch to ddim.", "tokens": [51264, 407, 550, 321, 393, 3679, 281, 274, 67, 332, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1708, "seek": 503700, "start": 5057.0, "end": 5059.0, "text": " By just saying ddim scheduler.", "tokens": [51364, 3146, 445, 1566, 274, 67, 332, 12000, 260, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1709, "seek": 503700, "start": 5059.0, "end": 5061.0, "text": " And so with ddim.", "tokens": [51464, 400, 370, 365, 274, 67, 332, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1710, "seek": 503700, "start": 5061.0, "end": 5063.0, "text": " You can say I don't want to do all thousand steps.", "tokens": [51564, 509, 393, 584, 286, 500, 380, 528, 281, 360, 439, 4714, 4439, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1711, "seek": 503700, "start": 5063.0, "end": 5065.0, "text": " I just want to do 333 steps.", "tokens": [51664, 286, 445, 528, 281, 360, 805, 10191, 4439, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20197398226026078, "compression_ratio": 1.5214007782101167, "no_speech_prob": 0.0057295230217278}, {"id": 1712, "seek": 506500, "start": 5065.0, "end": 5067.0, "text": " So every third.", "tokens": [50364, 407, 633, 2636, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1713, "seek": 506500, "start": 5067.0, "end": 5069.0, "text": " So that's basically a bit like.", "tokens": [50464, 407, 300, 311, 1936, 257, 857, 411, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1714, "seek": 506500, "start": 5069.0, "end": 5071.0, "text": " A bit like.", "tokens": [50564, 316, 857, 411, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1715, "seek": 506500, "start": 5071.0, "end": 5073.0, "text": " This sample skip.", "tokens": [50664, 639, 6889, 10023, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1716, "seek": 506500, "start": 5073.0, "end": 5075.0, "text": " Of doing every third.", "tokens": [50764, 2720, 884, 633, 2636, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1717, "seek": 506500, "start": 5075.0, "end": 5077.0, "text": " But ddim as we'll see.", "tokens": [50864, 583, 274, 67, 332, 382, 321, 603, 536, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1718, "seek": 506500, "start": 5077.0, "end": 5079.0, "text": " Does it in a smarter way.", "tokens": [50964, 4402, 309, 294, 257, 20294, 636, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1719, "seek": 506500, "start": 5079.0, "end": 5081.0, "text": " And so here's.", "tokens": [51064, 400, 370, 510, 311, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1720, "seek": 506500, "start": 5081.0, "end": 5083.0, "text": " Exactly the same code.", "tokens": [51164, 7587, 264, 912, 3089, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1721, "seek": 506500, "start": 5083.0, "end": 5085.0, "text": " Basically as before.", "tokens": [51264, 8537, 382, 949, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1722, "seek": 506500, "start": 5085.0, "end": 5087.0, "text": " But I put it into a.", "tokens": [51364, 583, 286, 829, 309, 666, 257, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1723, "seek": 506500, "start": 5087.0, "end": 5089.0, "text": " Little function.", "tokens": [51464, 8022, 2445, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1724, "seek": 506500, "start": 5089.0, "end": 5091.0, "text": " Okay so I can basically.", "tokens": [51564, 1033, 370, 286, 393, 1936, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1725, "seek": 506500, "start": 5091.0, "end": 5093.0, "text": " Pass in my model.", "tokens": [51664, 10319, 294, 452, 2316, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18141437026689639, "compression_ratio": 1.5, "no_speech_prob": 0.004681222140789032}, {"id": 1726, "seek": 509300, "start": 5093.0, "end": 5095.0, "text": " The size.", "tokens": [50364, 440, 2744, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1727, "seek": 509300, "start": 5095.0, "end": 5097.0, "text": " The scheduler.", "tokens": [50464, 440, 12000, 260, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1728, "seek": 509300, "start": 5097.0, "end": 5099.0, "text": " And then there's a parameter.", "tokens": [50564, 400, 550, 456, 311, 257, 13075, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1729, "seek": 509300, "start": 5099.0, "end": 5101.0, "text": " Called Ada which is basically.", "tokens": [50664, 45001, 32276, 597, 307, 1936, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1730, "seek": 509300, "start": 5101.0, "end": 5103.0, "text": " How much noise to add.", "tokens": [50764, 1012, 709, 5658, 281, 909, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1731, "seek": 509300, "start": 5103.0, "end": 5105.0, "text": " So just add all the noise.", "tokens": [50864, 407, 445, 909, 439, 264, 5658, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1732, "seek": 509300, "start": 5105.0, "end": 5107.0, "text": " And so this is.", "tokens": [50964, 400, 370, 341, 307, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1733, "seek": 509300, "start": 5107.0, "end": 5109.0, "text": " Now going to take three times.", "tokens": [51064, 823, 516, 281, 747, 1045, 1413, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1734, "seek": 509300, "start": 5109.0, "end": 5111.0, "text": " This three times faster.", "tokens": [51164, 639, 1045, 1413, 4663, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1735, "seek": 509300, "start": 5111.0, "end": 5113.0, "text": " And yeah the FIDs basically.", "tokens": [51264, 400, 1338, 264, 479, 2777, 82, 1936, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1736, "seek": 509300, "start": 5113.0, "end": 5115.0, "text": " The same.", "tokens": [51364, 440, 912, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1737, "seek": 509300, "start": 5115.0, "end": 5117.0, "text": " That's encouraging.", "tokens": [51464, 663, 311, 14580, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1738, "seek": 509300, "start": 5117.0, "end": 5119.0, "text": " So we're down to 200 steps.", "tokens": [51564, 407, 321, 434, 760, 281, 2331, 4439, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1739, "seek": 509300, "start": 5119.0, "end": 5121.0, "text": " It's basically the same.", "tokens": [51664, 467, 311, 1936, 264, 912, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2716759147994015, "compression_ratio": 1.5870646766169154, "no_speech_prob": 0.0003249166766181588}, {"id": 1740, "seek": 512100, "start": 5121.0, "end": 5123.0, "text": " 100 steps.", "tokens": [50364, 2319, 4439, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1741, "seek": 512100, "start": 5123.0, "end": 5125.0, "text": " And at this point.", "tokens": [50464, 400, 412, 341, 935, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1742, "seek": 512100, "start": 5125.0, "end": 5127.0, "text": " Okay the FIDs getting worse.", "tokens": [50564, 1033, 264, 479, 2777, 82, 1242, 5324, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1743, "seek": 512100, "start": 5129.0, "end": 5131.0, "text": " And then.", "tokens": [50764, 400, 550, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1744, "seek": 512100, "start": 5131.0, "end": 5133.0, "text": " 50 steps.", "tokens": [50864, 2625, 4439, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1745, "seek": 512100, "start": 5133.0, "end": 5135.0, "text": " We're still.", "tokens": [50964, 492, 434, 920, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1746, "seek": 512100, "start": 5135.0, "end": 5137.0, "text": " 25 steps.", "tokens": [51064, 3552, 4439, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1747, "seek": 512100, "start": 5137.0, "end": 5139.0, "text": " We're still. It's interesting like.", "tokens": [51164, 492, 434, 920, 13, 467, 311, 1880, 411, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1748, "seek": 512100, "start": 5139.0, "end": 5141.0, "text": " When you get down to 25 steps.", "tokens": [51264, 1133, 291, 483, 760, 281, 3552, 4439, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1749, "seek": 512100, "start": 5141.0, "end": 5143.0, "text": " Like what does it look like.", "tokens": [51364, 1743, 437, 775, 309, 574, 411, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1750, "seek": 512100, "start": 5143.0, "end": 5145.0, "text": " And you can see that.", "tokens": [51464, 400, 291, 393, 536, 300, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1751, "seek": 512100, "start": 5145.0, "end": 5147.0, "text": " They're kind of like.", "tokens": [51564, 814, 434, 733, 295, 411, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1752, "seek": 512100, "start": 5147.0, "end": 5149.0, "text": " They're too smooth.", "tokens": [51664, 814, 434, 886, 5508, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17938868853510642, "compression_ratio": 1.562874251497006, "no_speech_prob": 0.00022340523719321936}, {"id": 1753, "seek": 514900, "start": 5149.0, "end": 5151.0, "text": " You know fabric swells so much.", "tokens": [50364, 509, 458, 7253, 34251, 82, 370, 709, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1754, "seek": 514900, "start": 5151.0, "end": 5153.0, "text": " Or buckles or.", "tokens": [50464, 1610, 14894, 904, 420, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1755, "seek": 514900, "start": 5153.0, "end": 5155.0, "text": " Logos or patterns.", "tokens": [50564, 10824, 329, 420, 8294, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1756, "seek": 514900, "start": 5155.0, "end": 5157.0, "text": " As much you know as the.", "tokens": [50664, 1018, 709, 291, 458, 382, 264, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1757, "seek": 514900, "start": 5157.0, "end": 5159.0, "text": " These ones.", "tokens": [50764, 1981, 2306, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1758, "seek": 514900, "start": 5159.0, "end": 5161.0, "text": " They've got a lot more texture to them.", "tokens": [50864, 814, 600, 658, 257, 688, 544, 8091, 281, 552, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1759, "seek": 514900, "start": 5161.0, "end": 5163.0, "text": " So that's kind of what tends to happen.", "tokens": [50964, 407, 300, 311, 733, 295, 437, 12258, 281, 1051, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1760, "seek": 514900, "start": 5163.0, "end": 5165.0, "text": " So you can still like.", "tokens": [51064, 407, 291, 393, 920, 411, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1761, "seek": 514900, "start": 5165.0, "end": 5167.0, "text": " Get.", "tokens": [51164, 3240, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1762, "seek": 514900, "start": 5167.0, "end": 5169.0, "text": " Something out pretty fast.", "tokens": [51264, 6595, 484, 1238, 2370, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1763, "seek": 514900, "start": 5169.0, "end": 5171.0, "text": " But that's kind of how they suffer.", "tokens": [51364, 583, 300, 311, 733, 295, 577, 436, 9753, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1764, "seek": 514900, "start": 5171.0, "end": 5173.0, "text": " So okay.", "tokens": [51464, 407, 1392, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1765, "seek": 514900, "start": 5173.0, "end": 5175.0, "text": " So how does DDIM work.", "tokens": [51564, 407, 577, 775, 413, 3085, 44, 589, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1766, "seek": 514900, "start": 5175.0, "end": 5177.0, "text": " Well DDIM.", "tokens": [51664, 1042, 413, 3085, 44, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18723821640014648, "compression_ratio": 1.5047619047619047, "no_speech_prob": 0.00025710935005918145}, {"id": 1767, "seek": 517700, "start": 5177.0, "end": 5179.0, "text": " Actually.", "tokens": [50364, 5135, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1768, "seek": 517700, "start": 5179.0, "end": 5181.0, "text": " In my opinion it makes things a lot easier.", "tokens": [50464, 682, 452, 4800, 309, 1669, 721, 257, 688, 3571, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1769, "seek": 517700, "start": 5181.0, "end": 5183.0, "text": " Than DDPM.", "tokens": [50564, 18289, 30778, 18819, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1770, "seek": 517700, "start": 5183.0, "end": 5185.0, "text": " So there's basically.", "tokens": [50664, 407, 456, 311, 1936, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1771, "seek": 517700, "start": 5185.0, "end": 5187.0, "text": " An equation from the paper.", "tokens": [50764, 1107, 5367, 490, 264, 3035, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1772, "seek": 517700, "start": 5187.0, "end": 5189.0, "text": " Which Tanishq will explain.", "tokens": [50864, 3013, 314, 7524, 80, 486, 2903, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1773, "seek": 517700, "start": 5189.0, "end": 5191.0, "text": " Shortly.", "tokens": [50964, 40109, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1774, "seek": 517700, "start": 5193.0, "end": 5195.0, "text": " But basically what you do.", "tokens": [51164, 583, 1936, 437, 291, 360, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1775, "seek": 517700, "start": 5195.0, "end": 5197.0, "text": " Is I've actually.", "tokens": [51264, 1119, 286, 600, 767, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1776, "seek": 517700, "start": 5197.0, "end": 5199.0, "text": " Grabbed the sample function.", "tokens": [51364, 20357, 2883, 264, 6889, 2445, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1777, "seek": 517700, "start": 5201.0, "end": 5203.0, "text": " From here.", "tokens": [51564, 3358, 510, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1778, "seek": 517700, "start": 5203.0, "end": 5205.0, "text": " And I split it out into two bits.", "tokens": [51664, 400, 286, 7472, 309, 484, 666, 732, 9239, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2076392540564904, "compression_ratio": 1.40625, "no_speech_prob": 0.00042385418782941997}, {"id": 1779, "seek": 520500, "start": 5205.0, "end": 5207.0, "text": " One bit.", "tokens": [50364, 1485, 857, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1780, "seek": 520500, "start": 5207.0, "end": 5209.0, "text": " Is the bit that.", "tokens": [50464, 1119, 264, 857, 300, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1781, "seek": 520500, "start": 5209.0, "end": 5211.0, "text": " Says what are the time steps.", "tokens": [50564, 36780, 437, 366, 264, 565, 4439, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1782, "seek": 520500, "start": 5211.0, "end": 5213.0, "text": " Creates that random starting point.", "tokens": [50664, 11972, 279, 300, 4974, 2891, 935, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1783, "seek": 520500, "start": 5213.0, "end": 5215.0, "text": " Loops through.", "tokens": [50764, 6130, 3370, 807, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1784, "seek": 520500, "start": 5215.0, "end": 5217.0, "text": " Finds what my current.", "tokens": [50864, 11809, 82, 437, 452, 2190, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1785, "seek": 520500, "start": 5217.0, "end": 5219.0, "text": " A bar is.", "tokens": [50964, 316, 2159, 307, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1786, "seek": 520500, "start": 5219.0, "end": 5221.0, "text": " Gets the noise.", "tokens": [51064, 460, 1385, 264, 5658, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1787, "seek": 520500, "start": 5221.0, "end": 5223.0, "text": " And then.", "tokens": [51164, 400, 550, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1788, "seek": 520500, "start": 5223.0, "end": 5225.0, "text": " Basically does the same as shed.step.", "tokens": [51264, 8537, 775, 264, 912, 382, 14951, 13, 16792, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1789, "seek": 520500, "start": 5225.0, "end": 5227.0, "text": " It calls some function.", "tokens": [51364, 467, 5498, 512, 2445, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1790, "seek": 520500, "start": 5227.0, "end": 5229.0, "text": " Right and then that's been pulled out.", "tokens": [51464, 1779, 293, 550, 300, 311, 668, 7373, 484, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1791, "seek": 520500, "start": 5229.0, "end": 5231.0, "text": " So this allows me to now.", "tokens": [51564, 407, 341, 4045, 385, 281, 586, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1792, "seek": 520500, "start": 5231.0, "end": 5233.0, "text": " Create my own.", "tokens": [51664, 20248, 452, 1065, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17789750629001194, "compression_ratio": 1.535, "no_speech_prob": 3.219111022190191e-05}, {"id": 1793, "seek": 523300, "start": 5233.0, "end": 5235.0, "text": " Different steps.", "tokens": [50364, 20825, 4439, 13, 50464], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1794, "seek": 523300, "start": 5235.0, "end": 5237.0, "text": " So I created a DDIM step.", "tokens": [50464, 407, 286, 2942, 257, 413, 3085, 44, 1823, 13, 50564], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1795, "seek": 523300, "start": 5237.0, "end": 5239.0, "text": " And basically.", "tokens": [50564, 400, 1936, 13, 50664], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1796, "seek": 523300, "start": 5239.0, "end": 5241.0, "text": " All I did was I.", "tokens": [50664, 1057, 286, 630, 390, 286, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1797, "seek": 523300, "start": 5241.0, "end": 5243.0, "text": " Took this.", "tokens": [50764, 38288, 341, 13, 50864], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1798, "seek": 523300, "start": 5243.0, "end": 5245.0, "text": " Equation.", "tokens": [50864, 15624, 399, 13, 50964], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1799, "seek": 523300, "start": 5245.0, "end": 5247.0, "text": " And I turned it into.", "tokens": [50964, 400, 286, 3574, 309, 666, 13, 51064], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1800, "seek": 523300, "start": 5247.0, "end": 5249.0, "text": " Code actually this this one is a second equation.", "tokens": [51064, 15549, 767, 341, 341, 472, 307, 257, 1150, 5367, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1801, "seek": 523300, "start": 5249.0, "end": 5251.0, "text": " From the paper.", "tokens": [51164, 3358, 264, 3035, 13, 51264], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1802, "seek": 523300, "start": 5251.0, "end": 5253.0, "text": " Now it's a bit.", "tokens": [51264, 823, 309, 311, 257, 857, 13, 51364], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1803, "seek": 523300, "start": 5253.0, "end": 5255.0, "text": " Confusing which is that the notation.", "tokens": [51364, 11701, 7981, 597, 307, 300, 264, 24657, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1804, "seek": 523300, "start": 5255.0, "end": 5257.0, "text": " Here is different.", "tokens": [51464, 1692, 307, 819, 13, 51564], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1805, "seek": 523300, "start": 5257.0, "end": 5259.0, "text": " DDPM what it calls alpha bar.", "tokens": [51564, 413, 11373, 44, 437, 309, 5498, 8961, 2159, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1806, "seek": 523300, "start": 5259.0, "end": 5261.0, "text": " This paper calls alpha.", "tokens": [51664, 639, 3035, 5498, 8961, 13, 51764], "temperature": 0.0, "avg_logprob": -0.18577138218310996, "compression_ratio": 1.5422885572139304, "no_speech_prob": 3.591221320675686e-05}, {"id": 1807, "seek": 526100, "start": 5261.0, "end": 5263.0, "text": " So you've got to look out for that.", "tokens": [50364, 407, 291, 600, 658, 281, 574, 484, 337, 300, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1808, "seek": 526100, "start": 5263.0, "end": 5265.0, "text": " So basically you'll see.", "tokens": [50464, 407, 1936, 291, 603, 536, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1809, "seek": 526100, "start": 5265.0, "end": 5267.0, "text": " I basically go I've got here.", "tokens": [50564, 286, 1936, 352, 286, 600, 658, 510, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1810, "seek": 526100, "start": 5267.0, "end": 5269.0, "text": " Xt.", "tokens": [50664, 1783, 83, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1811, "seek": 526100, "start": 5269.0, "end": 5271.0, "text": " Minus okay.", "tokens": [50764, 2829, 301, 1392, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1812, "seek": 526100, "start": 5271.0, "end": 5273.0, "text": " One minus alpha bar is.", "tokens": [50864, 1485, 3175, 8961, 2159, 307, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1813, "seek": 526100, "start": 5273.0, "end": 5275.0, "text": " We've created a call that beta bar.", "tokens": [50964, 492, 600, 2942, 257, 818, 300, 9861, 2159, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1814, "seek": 526100, "start": 5275.0, "end": 5277.0, "text": " So beta bar dot square root.", "tokens": [51064, 407, 9861, 2159, 5893, 3732, 5593, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1815, "seek": 526100, "start": 5277.0, "end": 5279.0, "text": " Times noise.", "tokens": [51164, 11366, 5658, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1816, "seek": 526100, "start": 5279.0, "end": 5281.0, "text": " This here is the.", "tokens": [51264, 639, 510, 307, 264, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1817, "seek": 526100, "start": 5281.0, "end": 5283.0, "text": " This is the neural net.", "tokens": [51364, 639, 307, 264, 18161, 2533, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1818, "seek": 526100, "start": 5283.0, "end": 5285.0, "text": " So this here is the noise.", "tokens": [51464, 407, 341, 510, 307, 264, 5658, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1819, "seek": 526100, "start": 5285.0, "end": 5287.0, "text": " Okay.", "tokens": [51564, 1033, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1820, "seek": 526100, "start": 5287.0, "end": 5289.0, "text": " And.", "tokens": [51664, 400, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2226205931769477, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0009848900372162461}, {"id": 1821, "seek": 528900, "start": 5289.0, "end": 5291.0, "text": " Here I've got.", "tokens": [50364, 1692, 286, 600, 658, 13, 50464], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1822, "seek": 528900, "start": 5291.0, "end": 5293.0, "text": " My next.", "tokens": [50464, 1222, 958, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1823, "seek": 528900, "start": 5293.0, "end": 5295.0, "text": " Xt.", "tokens": [50564, 1783, 83, 13, 50664], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1824, "seek": 528900, "start": 5295.0, "end": 5297.0, "text": " Is sorry.", "tokens": [50664, 1119, 2597, 13, 50764], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1825, "seek": 528900, "start": 5297.0, "end": 5299.0, "text": " Yes here's my a bar.", "tokens": [50764, 1079, 510, 311, 452, 257, 2159, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1826, "seek": 528900, "start": 5299.0, "end": 5301.0, "text": " T1 square root.", "tokens": [50864, 314, 16, 3732, 5593, 13, 50964], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1827, "seek": 528900, "start": 5301.0, "end": 5303.0, "text": " Times.", "tokens": [50964, 11366, 13, 51064], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1828, "seek": 528900, "start": 5303.0, "end": 5305.0, "text": " This and you can see here it says predicted.", "tokens": [51064, 639, 293, 291, 393, 536, 510, 309, 1619, 19147, 13, 51164], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1829, "seek": 528900, "start": 5305.0, "end": 5307.0, "text": " X naught so here's my predicted.", "tokens": [51164, 1783, 13138, 370, 510, 311, 452, 19147, 13, 51264], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1830, "seek": 528900, "start": 5307.0, "end": 5309.0, "text": " X naught plus.", "tokens": [51264, 1783, 13138, 1804, 13, 51364], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1831, "seek": 528900, "start": 5309.0, "end": 5311.0, "text": " Beta bar t1.", "tokens": [51364, 33286, 2159, 256, 16, 13, 51464], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1832, "seek": 528900, "start": 5311.0, "end": 5313.0, "text": " Minus sigma squared.", "tokens": [51464, 2829, 301, 12771, 8889, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1833, "seek": 528900, "start": 5313.0, "end": 5315.0, "text": " Square root.", "tokens": [51564, 16463, 5593, 13, 51664], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1834, "seek": 528900, "start": 5315.0, "end": 5317.0, "text": " Again here's noise.", "tokens": [51664, 3764, 510, 311, 5658, 13, 51764], "temperature": 0.0, "avg_logprob": -0.21995585305350168, "compression_ratio": 1.5253164556962024, "no_speech_prob": 0.00037997454637661576}, {"id": 1835, "seek": 531700, "start": 5317.0, "end": 5319.0, "text": " The same thing as here.", "tokens": [50364, 440, 912, 551, 382, 510, 13, 50464], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1836, "seek": 531700, "start": 5319.0, "end": 5321.0, "text": " Okay.", "tokens": [50464, 1033, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1837, "seek": 531700, "start": 5321.0, "end": 5323.0, "text": " And then.", "tokens": [50564, 400, 550, 13, 50664], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1838, "seek": 531700, "start": 5323.0, "end": 5325.0, "text": " Plus a bit of random noise.", "tokens": [50664, 7721, 257, 857, 295, 4974, 5658, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1839, "seek": 531700, "start": 5325.0, "end": 5327.0, "text": " Which we only do if you're not at the last step.", "tokens": [50764, 3013, 321, 787, 360, 498, 291, 434, 406, 412, 264, 1036, 1823, 13, 50864], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1840, "seek": 531700, "start": 5327.0, "end": 5329.0, "text": " So yeah.", "tokens": [50864, 407, 1338, 13, 50964], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1841, "seek": 531700, "start": 5329.0, "end": 5331.0, "text": " So I can call that.", "tokens": [50964, 407, 286, 393, 818, 300, 13, 51064], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1842, "seek": 531700, "start": 5331.0, "end": 5333.0, "text": " So I just did it for.", "tokens": [51064, 407, 286, 445, 630, 309, 337, 13, 51164], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1843, "seek": 531700, "start": 5333.0, "end": 5335.0, "text": " So I'd rather than.", "tokens": [51164, 407, 286, 1116, 2831, 813, 13, 51264], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1844, "seek": 531700, "start": 5335.0, "end": 5337.0, "text": " Saying 100 steps.", "tokens": [51264, 34087, 2319, 4439, 13, 51364], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1845, "seek": 531700, "start": 5337.0, "end": 5339.0, "text": " I said skip every skip 10 steps.", "tokens": [51364, 286, 848, 10023, 633, 10023, 1266, 4439, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1846, "seek": 531700, "start": 5339.0, "end": 5341.0, "text": " So do 10 steps at a time.", "tokens": [51464, 407, 360, 1266, 4439, 412, 257, 565, 13, 51564], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1847, "seek": 531700, "start": 5341.0, "end": 5343.0, "text": " That's basically going to be 100 steps.", "tokens": [51564, 663, 311, 1936, 516, 281, 312, 2319, 4439, 13, 51664], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1848, "seek": 531700, "start": 5343.0, "end": 5345.0, "text": " And so you can see here actually.", "tokens": [51664, 400, 370, 291, 393, 536, 510, 767, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20690118471781413, "compression_ratio": 1.572093023255814, "no_speech_prob": 0.0008165359613485634}, {"id": 1849, "seek": 534500, "start": 5345.0, "end": 5347.0, "text": " I'm better for my 100 steps.", "tokens": [50364, 286, 478, 1101, 337, 452, 2319, 4439, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1850, "seek": 534500, "start": 5347.0, "end": 5349.0, "text": " It's not bad at all.", "tokens": [50464, 467, 311, 406, 1578, 412, 439, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1851, "seek": 534500, "start": 5349.0, "end": 5351.0, "text": " So.", "tokens": [50564, 407, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1852, "seek": 534500, "start": 5351.0, "end": 5353.0, "text": " Yeah.", "tokens": [50664, 865, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1853, "seek": 534500, "start": 5353.0, "end": 5355.0, "text": " I mean this has been.", "tokens": [50764, 286, 914, 341, 575, 668, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1854, "seek": 534500, "start": 5357.0, "end": 5359.0, "text": " Getting to this point.", "tokens": [50964, 13674, 281, 341, 935, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1855, "seek": 534500, "start": 5359.0, "end": 5361.0, "text": " It's been a bit of a lifesaver to be honest.", "tokens": [51064, 467, 311, 668, 257, 857, 295, 257, 4545, 13708, 331, 281, 312, 3245, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1856, "seek": 534500, "start": 5361.0, "end": 5363.0, "text": " Because you know I can now.", "tokens": [51164, 1436, 291, 458, 286, 393, 586, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1857, "seek": 534500, "start": 5363.0, "end": 5365.0, "text": " Run.", "tokens": [51264, 8950, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1858, "seek": 534500, "start": 5365.0, "end": 5367.0, "text": " A batch of 2048 samples.", "tokens": [51364, 316, 15245, 295, 945, 13318, 10938, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1859, "seek": 534500, "start": 5367.0, "end": 5369.0, "text": " I can sample them in under a minute.", "tokens": [51464, 286, 393, 6889, 552, 294, 833, 257, 3456, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1860, "seek": 534500, "start": 5369.0, "end": 5371.0, "text": " Which doesn't feel painful.", "tokens": [51564, 3013, 1177, 380, 841, 11697, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1861, "seek": 534500, "start": 5371.0, "end": 5373.0, "text": " And so.", "tokens": [51664, 400, 370, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2285704162885558, "compression_ratio": 1.4141414141414141, "no_speech_prob": 0.007814318872988224}, {"id": 1862, "seek": 537300, "start": 5373.0, "end": 5375.0, "text": " You know now at a point.", "tokens": [50364, 509, 458, 586, 412, 257, 935, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1863, "seek": 537300, "start": 5375.0, "end": 5377.0, "text": " Where I can actually get a pretty good.", "tokens": [50464, 2305, 286, 393, 767, 483, 257, 1238, 665, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1864, "seek": 537300, "start": 5377.0, "end": 5379.0, "text": " Measure of how I'm doing.", "tokens": [50564, 41436, 295, 577, 286, 478, 884, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1865, "seek": 537300, "start": 5379.0, "end": 5381.0, "text": " In a pretty reasonable.", "tokens": [50664, 682, 257, 1238, 10585, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1866, "seek": 537300, "start": 5381.0, "end": 5383.0, "text": " Amount of time.", "tokens": [50764, 2012, 792, 295, 565, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1867, "seek": 537300, "start": 5383.0, "end": 5385.0, "text": " And I can you know.", "tokens": [50864, 400, 286, 393, 291, 458, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1868, "seek": 537300, "start": 5385.0, "end": 5387.0, "text": " Easily compare it.", "tokens": [50964, 46879, 953, 6794, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1869, "seek": 537300, "start": 5387.0, "end": 5389.0, "text": " And I got to admit you know.", "tokens": [51064, 400, 286, 658, 281, 9796, 291, 458, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1870, "seek": 537300, "start": 5389.0, "end": 5391.0, "text": " The difference between a fit of 5 and 8 and 11.", "tokens": [51164, 440, 2649, 1296, 257, 3318, 295, 1025, 293, 1649, 293, 2975, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1871, "seek": 537300, "start": 5391.0, "end": 5393.0, "text": " I can't necessarily tell the difference.", "tokens": [51264, 286, 393, 380, 4725, 980, 264, 2649, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1872, "seek": 537300, "start": 5393.0, "end": 5395.0, "text": " So for fashion I think.", "tokens": [51364, 407, 337, 6700, 286, 519, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1873, "seek": 537300, "start": 5395.0, "end": 5397.0, "text": " Fit is better than my eyes.", "tokens": [51464, 29263, 307, 1101, 813, 452, 2575, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1874, "seek": 537300, "start": 5397.0, "end": 5399.0, "text": " This as long as I use a consistent.", "tokens": [51564, 639, 382, 938, 382, 286, 764, 257, 8398, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1875, "seek": 537300, "start": 5399.0, "end": 5401.0, "text": " Sample size.", "tokens": [51664, 4832, 781, 2744, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1853325217962265, "compression_ratio": 1.5772357723577235, "no_speech_prob": 9.761162073118612e-05}, {"id": 1876, "seek": 540100, "start": 5401.0, "end": 5403.0, "text": " So.", "tokens": [50364, 407, 13, 50464], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1877, "seek": 540100, "start": 5403.0, "end": 5405.0, "text": " Yeah.", "tokens": [50464, 865, 13, 50564], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1878, "seek": 540100, "start": 5405.0, "end": 5407.0, "text": " Tanisha did you want to talk a bit about.", "tokens": [50564, 314, 7524, 64, 630, 291, 528, 281, 751, 257, 857, 466, 13, 50664], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1879, "seek": 540100, "start": 5407.0, "end": 5409.0, "text": " You know.", "tokens": [50664, 509, 458, 13, 50764], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1880, "seek": 540100, "start": 5409.0, "end": 5411.0, "text": " The ideas of why we do this.", "tokens": [50764, 440, 3487, 295, 983, 321, 360, 341, 13, 50864], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1881, "seek": 540100, "start": 5411.0, "end": 5413.0, "text": " Or where it comes from.", "tokens": [50864, 1610, 689, 309, 1487, 490, 13, 50964], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1882, "seek": 540100, "start": 5413.0, "end": 5415.0, "text": " Or what the notation means.", "tokens": [50964, 1610, 437, 264, 24657, 1355, 13, 51064], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1883, "seek": 540100, "start": 5415.0, "end": 5417.0, "text": " Can I say a little bit before we do that.", "tokens": [51064, 1664, 286, 584, 257, 707, 857, 949, 321, 360, 300, 13, 51164], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1884, "seek": 540100, "start": 5417.0, "end": 5419.0, "text": " Which is just that what you have there Jeremy.", "tokens": [51164, 3013, 307, 445, 300, 437, 291, 362, 456, 17809, 13, 51264], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1885, "seek": 540100, "start": 5419.0, "end": 5421.0, "text": " Which is like.", "tokens": [51264, 3013, 307, 411, 13, 51364], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1886, "seek": 540100, "start": 5421.0, "end": 5423.0, "text": " A screenshot from the paper.", "tokens": [51364, 316, 27712, 490, 264, 3035, 13, 51464], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1887, "seek": 540100, "start": 5423.0, "end": 5425.0, "text": " And then the code that as closely as possible.", "tokens": [51464, 400, 550, 264, 3089, 300, 382, 8185, 382, 1944, 13, 51564], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1888, "seek": 540100, "start": 5425.0, "end": 5427.0, "text": " Tries to follow that.", "tokens": [51564, 314, 2244, 281, 1524, 300, 13, 51664], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1889, "seek": 540100, "start": 5427.0, "end": 5429.0, "text": " Like the difference that makes for people.", "tokens": [51664, 1743, 264, 2649, 300, 1669, 337, 561, 13, 51764], "temperature": 0.0, "avg_logprob": -0.199416991203062, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.0694846361875534}, {"id": 1890, "seek": 542900, "start": 5429.0, "end": 5431.0, "text": " Is huge.", "tokens": [50364, 1119, 2603, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1891, "seek": 542900, "start": 5431.0, "end": 5433.0, "text": " Like I've got a little research team that I'm doing.", "tokens": [50464, 1743, 286, 600, 658, 257, 707, 2132, 1469, 300, 286, 478, 884, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1892, "seek": 542900, "start": 5433.0, "end": 5435.0, "text": " Some you know contract work with.", "tokens": [50564, 2188, 291, 458, 4364, 589, 365, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1893, "seek": 542900, "start": 5435.0, "end": 5437.0, "text": " And the fact that like.", "tokens": [50664, 400, 264, 1186, 300, 411, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1894, "seek": 542900, "start": 5437.0, "end": 5439.0, "text": " It's called alpha in the D-dim paper.", "tokens": [50764, 467, 311, 1219, 8961, 294, 264, 413, 12, 13595, 3035, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1895, "seek": 542900, "start": 5439.0, "end": 5441.0, "text": " And alpha elsewhere.", "tokens": [50864, 400, 8961, 14517, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1896, "seek": 542900, "start": 5441.0, "end": 5443.0, "text": " And then in the code that they were copying and pasting from.", "tokens": [50964, 400, 550, 294, 264, 3089, 300, 436, 645, 27976, 293, 1791, 278, 490, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1897, "seek": 542900, "start": 5443.0, "end": 5445.0, "text": " It was called A and B for alpha and B-dim.", "tokens": [51064, 467, 390, 1219, 316, 293, 363, 337, 8961, 293, 363, 12, 13595, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1898, "seek": 542900, "start": 5445.0, "end": 5447.0, "text": " And it's like you can get things kind of working.", "tokens": [51164, 400, 309, 311, 411, 291, 393, 483, 721, 733, 295, 1364, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1899, "seek": 542900, "start": 5447.0, "end": 5449.0, "text": " By copying and pasting into things.", "tokens": [51264, 3146, 27976, 293, 1791, 278, 666, 721, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1900, "seek": 542900, "start": 5449.0, "end": 5451.0, "text": " And it's all just sort of kind of works.", "tokens": [51364, 400, 309, 311, 439, 445, 1333, 295, 733, 295, 1985, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1901, "seek": 542900, "start": 5451.0, "end": 5453.0, "text": " But just spending that time to literally.", "tokens": [51464, 583, 445, 6434, 300, 565, 281, 3736, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1902, "seek": 542900, "start": 5453.0, "end": 5455.0, "text": " Take two screenshots from equation 14.", "tokens": [51564, 3664, 732, 40661, 490, 5367, 3499, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1903, "seek": 542900, "start": 5455.0, "end": 5457.0, "text": " And 16 from the paper.", "tokens": [51664, 400, 3165, 490, 264, 3035, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2781065398571538, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.32404860854148865}, {"id": 1904, "seek": 545700, "start": 5457.0, "end": 5459.0, "text": " And rewrite the code so that it you know.", "tokens": [50364, 400, 28132, 264, 3089, 370, 300, 309, 291, 458, 13, 50464], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1905, "seek": 545700, "start": 5459.0, "end": 5461.0, "text": " With some comments and things.", "tokens": [50464, 2022, 512, 3053, 293, 721, 13, 50564], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1906, "seek": 545700, "start": 5461.0, "end": 5463.0, "text": " To say like this is what this is.", "tokens": [50564, 1407, 584, 411, 341, 307, 437, 341, 307, 13, 50664], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1907, "seek": 545700, "start": 5463.0, "end": 5465.0, "text": " This is that part from the equation.", "tokens": [50664, 639, 307, 300, 644, 490, 264, 5367, 13, 50764], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1908, "seek": 545700, "start": 5465.0, "end": 5467.0, "text": " It like.", "tokens": [50764, 467, 411, 13, 50864], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1909, "seek": 545700, "start": 5467.0, "end": 5469.0, "text": " You know the look of pain on their face.", "tokens": [50864, 509, 458, 264, 574, 295, 1822, 322, 641, 1851, 13, 50964], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1910, "seek": 545700, "start": 5469.0, "end": 5471.0, "text": " When I said oh by the way did you notice that like.", "tokens": [50964, 1133, 286, 848, 1954, 538, 264, 636, 630, 291, 3449, 300, 411, 13, 51064], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1911, "seek": 545700, "start": 5471.0, "end": 5473.0, "text": " It's called alpha there and alpha bar there.", "tokens": [51064, 467, 311, 1219, 8961, 456, 293, 8961, 2159, 456, 13, 51164], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1912, "seek": 545700, "start": 5473.0, "end": 5475.0, "text": " They're like yes how could they do that.", "tokens": [51164, 814, 434, 411, 2086, 577, 727, 436, 360, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1913, "seek": 545700, "start": 5475.0, "end": 5477.0, "text": " You know it's just like.", "tokens": [51264, 509, 458, 309, 311, 445, 411, 13, 51364], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1914, "seek": 545700, "start": 5477.0, "end": 5479.0, "text": " You could just tell how many hours have been spent.", "tokens": [51364, 509, 727, 445, 980, 577, 867, 2496, 362, 668, 4418, 13, 51464], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1915, "seek": 545700, "start": 5479.0, "end": 5481.0, "text": " You know like grinding teeth.", "tokens": [51464, 509, 458, 411, 25300, 7798, 13, 51564], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1916, "seek": 545700, "start": 5481.0, "end": 5483.0, "text": " And saying what's wrong here.", "tokens": [51564, 400, 1566, 437, 311, 2085, 510, 13, 51664], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1917, "seek": 545700, "start": 5483.0, "end": 5485.0, "text": " And doing notebooks.", "tokens": [51664, 400, 884, 43782, 13, 51764], "temperature": 0.0, "avg_logprob": -0.25325926144917804, "compression_ratio": 1.7912087912087913, "no_speech_prob": 0.18006721138954163}, {"id": 1918, "seek": 548500, "start": 5485.0, "end": 5487.0, "text": " And you know the next engineer.", "tokens": [50364, 400, 291, 458, 264, 958, 11403, 13, 50464], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1919, "seek": 548500, "start": 5487.0, "end": 5489.0, "text": " To come along and work on that.", "tokens": [50464, 1407, 808, 2051, 293, 589, 322, 300, 13, 50564], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1920, "seek": 548500, "start": 5491.0, "end": 5493.0, "text": " And see the equation right there.", "tokens": [50664, 400, 536, 264, 5367, 558, 456, 13, 50764], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1921, "seek": 548500, "start": 5493.0, "end": 5495.0, "text": " And you can add rows and stuff.", "tokens": [50764, 400, 291, 393, 909, 13241, 293, 1507, 13, 50864], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1922, "seek": 548500, "start": 5495.0, "end": 5497.0, "text": " So I think you know.", "tokens": [50864, 407, 286, 519, 291, 458, 13, 50964], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1923, "seek": 548500, "start": 5497.0, "end": 5499.0, "text": " NBDev works particularly well.", "tokens": [50964, 426, 33, 11089, 85, 1985, 4098, 731, 13, 51064], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1924, "seek": 548500, "start": 5499.0, "end": 5501.0, "text": " For this kind of development.", "tokens": [51064, 1171, 341, 733, 295, 3250, 13, 51164], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1925, "seek": 548500, "start": 5501.0, "end": 5503.0, "text": " Yeah.", "tokens": [51164, 865, 13, 51264], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1926, "seek": 548500, "start": 5503.0, "end": 5505.0, "text": " Thanks Jeno.", "tokens": [51264, 2561, 508, 5808, 13, 51364], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1927, "seek": 548500, "start": 5505.0, "end": 5507.0, "text": " Yeah.", "tokens": [51364, 865, 13, 51464], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1928, "seek": 548500, "start": 5507.0, "end": 5509.0, "text": " Before I talk about this.", "tokens": [51464, 4546, 286, 751, 466, 341, 13, 51564], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1929, "seek": 548500, "start": 5509.0, "end": 5511.0, "text": " I just wanted to briefly.", "tokens": [51564, 286, 445, 1415, 281, 10515, 13, 51664], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1930, "seek": 548500, "start": 5511.0, "end": 5513.0, "text": " In the context of.", "tokens": [51664, 682, 264, 4319, 295, 13, 51764], "temperature": 0.0, "avg_logprob": -0.3053615347852985, "compression_ratio": 1.497560975609756, "no_speech_prob": 0.006002945359796286}, {"id": 1931, "seek": 551300, "start": 5513.0, "end": 5515.0, "text": " All of these differing notations.", "tokens": [50364, 1057, 295, 613, 743, 278, 406, 763, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1932, "seek": 551300, "start": 5515.0, "end": 5517.0, "text": " I recently created this meme.", "tokens": [50464, 286, 3938, 2942, 341, 21701, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1933, "seek": 551300, "start": 5517.0, "end": 5519.0, "text": " Which I thought was relevant.", "tokens": [50564, 3013, 286, 1194, 390, 7340, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1934, "seek": 551300, "start": 5519.0, "end": 5521.0, "text": " In terms of like each paper basically.", "tokens": [50664, 682, 2115, 295, 411, 1184, 3035, 1936, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1935, "seek": 551300, "start": 5521.0, "end": 5523.0, "text": " Has a different diffusion model.", "tokens": [50764, 8646, 257, 819, 25242, 2316, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1936, "seek": 551300, "start": 5523.0, "end": 5525.0, "text": " Notation.", "tokens": [50864, 1726, 399, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1937, "seek": 551300, "start": 5525.0, "end": 5527.0, "text": " So it's just like this.", "tokens": [50964, 407, 309, 311, 445, 411, 341, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1938, "seek": 551300, "start": 5527.0, "end": 5529.0, "text": " They all try to come up with their own universal notation.", "tokens": [51064, 814, 439, 853, 281, 808, 493, 365, 641, 1065, 11455, 24657, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1939, "seek": 551300, "start": 5529.0, "end": 5531.0, "text": " And it just keeps proliferating.", "tokens": [51164, 400, 309, 445, 5965, 24398, 9361, 990, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1940, "seek": 551300, "start": 5531.0, "end": 5533.0, "text": " Let's just agree we should all use APL.", "tokens": [51264, 961, 311, 445, 3986, 321, 820, 439, 764, 5372, 43, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1941, "seek": 551300, "start": 5535.0, "end": 5537.0, "text": " Yes exactly.", "tokens": [51464, 1079, 2293, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1942, "seek": 551300, "start": 5537.0, "end": 5539.0, "text": " We need to implement diffusion models and APL somehow.", "tokens": [51564, 492, 643, 281, 4445, 25242, 5245, 293, 5372, 43, 6063, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2213459180748981, "compression_ratio": 1.5896414342629481, "no_speech_prob": 0.005137740634381771}, {"id": 1943, "seek": 553900, "start": 5539.0, "end": 5541.0, "text": " All right.", "tokens": [50364, 1057, 558, 13, 50464], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1944, "seek": 553900, "start": 5541.0, "end": 5543.0, "text": " So yeah.", "tokens": [50464, 407, 1338, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1945, "seek": 553900, "start": 5543.0, "end": 5545.0, "text": " The paper that we're.", "tokens": [50564, 440, 3035, 300, 321, 434, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1946, "seek": 553900, "start": 5545.0, "end": 5547.0, "text": " That you know Jeremy had implemented.", "tokens": [50664, 663, 291, 458, 17809, 632, 12270, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1947, "seek": 553900, "start": 5547.0, "end": 5549.0, "text": " Was this denoising diffusion.", "tokens": [50764, 3027, 341, 1441, 78, 3436, 25242, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1948, "seek": 553900, "start": 5549.0, "end": 5551.0, "text": " Implicit model paper.", "tokens": [50864, 4331, 4770, 270, 2316, 3035, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1949, "seek": 553900, "start": 5551.0, "end": 5553.0, "text": " And.", "tokens": [50964, 400, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1950, "seek": 553900, "start": 5553.0, "end": 5555.0, "text": " If you look at the paper.", "tokens": [51064, 759, 291, 574, 412, 264, 3035, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1951, "seek": 553900, "start": 5555.0, "end": 5557.0, "text": " Again you can see like the notation.", "tokens": [51164, 3764, 291, 393, 536, 411, 264, 24657, 13, 51264], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1952, "seek": 553900, "start": 5557.0, "end": 5559.0, "text": " Could be again a little bit intimidating.", "tokens": [51264, 7497, 312, 797, 257, 707, 857, 29714, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1953, "seek": 553900, "start": 5559.0, "end": 5561.0, "text": " But when we walk through it.", "tokens": [51364, 583, 562, 321, 1792, 807, 309, 13, 51464], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1954, "seek": 553900, "start": 5561.0, "end": 5563.0, "text": " We'll see it's not too bad actually.", "tokens": [51464, 492, 603, 536, 309, 311, 406, 886, 1578, 767, 13, 51564], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1955, "seek": 553900, "start": 5563.0, "end": 5565.0, "text": " So I'll just bring up.", "tokens": [51564, 407, 286, 603, 445, 1565, 493, 13, 51664], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1956, "seek": 553900, "start": 5565.0, "end": 5567.0, "text": " I guess.", "tokens": [51664, 286, 2041, 13, 51764], "temperature": 0.0, "avg_logprob": -0.17861367945085493, "compression_ratio": 1.4933920704845816, "no_speech_prob": 0.012418188154697418}, {"id": 1957, "seek": 556700, "start": 5567.0, "end": 5569.0, "text": " Some of the important equations.", "tokens": [50364, 2188, 295, 264, 1021, 11787, 13, 50464], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1958, "seek": 556700, "start": 5569.0, "end": 5571.0, "text": " And also comparing and contrasting.", "tokens": [50464, 400, 611, 15763, 293, 8712, 278, 13, 50564], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1959, "seek": 556700, "start": 5571.0, "end": 5573.0, "text": " You know DDPM.", "tokens": [50564, 509, 458, 30778, 18819, 13, 50664], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1960, "seek": 556700, "start": 5573.0, "end": 5575.0, "text": " And the notation of DDPM and the equations.", "tokens": [50664, 400, 264, 24657, 295, 30778, 18819, 293, 264, 11787, 13, 50764], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1961, "seek": 556700, "start": 5575.0, "end": 5577.0, "text": " With DDIM.", "tokens": [50764, 2022, 30778, 6324, 13, 50864], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1962, "seek": 556700, "start": 5577.0, "end": 5579.0, "text": " Not only is it not too bad.", "tokens": [50864, 1726, 787, 307, 309, 406, 886, 1578, 13, 50964], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1963, "seek": 556700, "start": 5579.0, "end": 5581.0, "text": " I actually discovered it's making life a lot.", "tokens": [50964, 286, 767, 6941, 309, 311, 1455, 993, 257, 688, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1964, "seek": 556700, "start": 5581.0, "end": 5583.0, "text": " The DDIM notation.", "tokens": [51064, 440, 30778, 6324, 24657, 13, 51164], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1965, "seek": 556700, "start": 5583.0, "end": 5585.0, "text": " And equations are a lot easier.", "tokens": [51164, 400, 11787, 366, 257, 688, 3571, 13, 51264], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1966, "seek": 556700, "start": 5585.0, "end": 5587.0, "text": " To work with.", "tokens": [51264, 1407, 589, 365, 13, 51364], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1967, "seek": 556700, "start": 5587.0, "end": 5589.0, "text": " Than DDPM.", "tokens": [51364, 18289, 30778, 18819, 13, 51464], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1968, "seek": 556700, "start": 5589.0, "end": 5591.0, "text": " So I found my life is better.", "tokens": [51464, 407, 286, 1352, 452, 993, 307, 1101, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1969, "seek": 556700, "start": 5591.0, "end": 5593.0, "text": " Since I discovered DDIM.", "tokens": [51564, 4162, 286, 6941, 30778, 6324, 13, 51664], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1970, "seek": 556700, "start": 5593.0, "end": 5595.0, "text": " Yes yes.", "tokens": [51664, 1079, 2086, 13, 51764], "temperature": 0.0, "avg_logprob": -0.16878007416032317, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.02555334009230137}, {"id": 1971, "seek": 559500, "start": 5595.0, "end": 5597.0, "text": " A lot of people prefer to use DDIM as well.", "tokens": [50364, 316, 688, 295, 561, 4382, 281, 764, 30778, 6324, 382, 731, 13, 50464], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1972, "seek": 559500, "start": 5597.0, "end": 5599.0, "text": " Yeah.", "tokens": [50464, 865, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1973, "seek": 559500, "start": 5599.0, "end": 5601.0, "text": " So yeah basically.", "tokens": [50564, 407, 1338, 1936, 13, 50664], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1974, "seek": 559500, "start": 5601.0, "end": 5603.0, "text": " In.", "tokens": [50664, 682, 13, 50764], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1975, "seek": 559500, "start": 5603.0, "end": 5605.0, "text": " So.", "tokens": [50764, 407, 13, 50864], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1976, "seek": 559500, "start": 5605.0, "end": 5607.0, "text": " In both.", "tokens": [50864, 682, 1293, 13, 50964], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1977, "seek": 559500, "start": 5607.0, "end": 5609.0, "text": " DDIM and.", "tokens": [50964, 30778, 6324, 293, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1978, "seek": 559500, "start": 5609.0, "end": 5611.0, "text": " In both DDIM and DDPM.", "tokens": [51064, 682, 1293, 30778, 6324, 293, 30778, 18819, 13, 51164], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1979, "seek": 559500, "start": 5611.0, "end": 5613.0, "text": " We have this same sort of.", "tokens": [51164, 492, 362, 341, 912, 1333, 295, 13, 51264], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1980, "seek": 559500, "start": 5613.0, "end": 5615.0, "text": " Equation.", "tokens": [51264, 15624, 399, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1981, "seek": 559500, "start": 5615.0, "end": 5617.0, "text": " This equation is exactly the same.", "tokens": [51364, 639, 5367, 307, 2293, 264, 912, 13, 51464], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1982, "seek": 559500, "start": 5617.0, "end": 5619.0, "text": " This is telling us the predicted.", "tokens": [51464, 639, 307, 3585, 505, 264, 19147, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1983, "seek": 559500, "start": 5619.0, "end": 5621.0, "text": " The predicted.", "tokens": [51564, 440, 19147, 13, 51664], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1984, "seek": 559500, "start": 5621.0, "end": 5623.0, "text": " Denoised image.", "tokens": [51664, 413, 5808, 2640, 3256, 13, 51764], "temperature": 0.0, "avg_logprob": -0.19005981599441682, "compression_ratio": 1.526946107784431, "no_speech_prob": 0.5034911036491394}, {"id": 1985, "seek": 562300, "start": 5623.0, "end": 5625.0, "text": " So we predict our.", "tokens": [50364, 407, 321, 6069, 527, 13, 50464], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1986, "seek": 562300, "start": 5625.0, "end": 5627.0, "text": " But basically we predict the.", "tokens": [50464, 583, 1936, 321, 6069, 264, 13, 50564], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1987, "seek": 562300, "start": 5627.0, "end": 5629.0, "text": " You can see my pointer right.", "tokens": [50564, 509, 393, 536, 452, 23918, 558, 13, 50664], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1988, "seek": 562300, "start": 5629.0, "end": 5631.0, "text": " Just want to confirm.", "tokens": [50664, 1449, 528, 281, 9064, 13, 50764], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1989, "seek": 562300, "start": 5631.0, "end": 5633.0, "text": " By the way.", "tokens": [50764, 3146, 264, 636, 13, 50864], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1990, "seek": 562300, "start": 5633.0, "end": 5635.0, "text": " The little double headed arrow in the top right.", "tokens": [50864, 440, 707, 3834, 12798, 11610, 294, 264, 1192, 558, 13, 50964], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1991, "seek": 562300, "start": 5635.0, "end": 5637.0, "text": " Does that.", "tokens": [50964, 4402, 300, 13, 51064], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1992, "seek": 562300, "start": 5637.0, "end": 5639.0, "text": " If you click that.", "tokens": [51064, 759, 291, 2052, 300, 13, 51164], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1993, "seek": 562300, "start": 5639.0, "end": 5641.0, "text": " Do you get more room.", "tokens": [51164, 1144, 291, 483, 544, 1808, 13, 51264], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1994, "seek": 562300, "start": 5641.0, "end": 5643.0, "text": " For us to see what's going on.", "tokens": [51264, 1171, 505, 281, 536, 437, 311, 516, 322, 13, 51364], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1995, "seek": 562300, "start": 5643.0, "end": 5645.0, "text": " Double headed arrow.", "tokens": [51364, 16633, 12798, 11610, 13, 51464], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1996, "seek": 562300, "start": 5645.0, "end": 5647.0, "text": " Just above the.", "tokens": [51464, 1449, 3673, 264, 13, 51564], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1997, "seek": 562300, "start": 5647.0, "end": 5649.0, "text": " Yes.", "tokens": [51564, 1079, 13, 51664], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1998, "seek": 562300, "start": 5649.0, "end": 5651.0, "text": " Yeah okay.", "tokens": [51664, 865, 1392, 13, 51764], "temperature": 0.0, "avg_logprob": -0.28048998638264183, "compression_ratio": 1.563157894736842, "no_speech_prob": 0.15807902812957764}, {"id": 1999, "seek": 565100, "start": 5651.0, "end": 5653.0, "text": " So.", "tokens": [50364, 407, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2000, "seek": 565100, "start": 5653.0, "end": 5655.0, "text": " So.", "tokens": [50464, 407, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2001, "seek": 565100, "start": 5655.0, "end": 5657.0, "text": " So.", "tokens": [50564, 407, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2002, "seek": 565100, "start": 5657.0, "end": 5659.0, "text": " So.", "tokens": [50664, 407, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2003, "seek": 565100, "start": 5659.0, "end": 5661.0, "text": " So.", "tokens": [50764, 407, 13, 50864], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2004, "seek": 565100, "start": 5661.0, "end": 5663.0, "text": " So.", "tokens": [50864, 407, 13, 50964], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2005, "seek": 565100, "start": 5663.0, "end": 5665.0, "text": " So.", "tokens": [50964, 407, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2006, "seek": 565100, "start": 5665.0, "end": 5667.0, "text": " So.", "tokens": [51064, 407, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2007, "seek": 565100, "start": 5667.0, "end": 5669.0, "text": " So.", "tokens": [51164, 407, 13, 51264], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2008, "seek": 565100, "start": 5669.0, "end": 5671.0, "text": " So.", "tokens": [51264, 407, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2009, "seek": 565100, "start": 5671.0, "end": 5673.0, "text": " So.", "tokens": [51364, 407, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2010, "seek": 565100, "start": 5673.0, "end": 5675.0, "text": " So.", "tokens": [51464, 407, 13, 51564], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2011, "seek": 565100, "start": 5675.0, "end": 5677.0, "text": " So.", "tokens": [51564, 407, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2012, "seek": 565100, "start": 5677.0, "end": 5679.0, "text": " So.", "tokens": [51664, 407, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2205869247173441, "compression_ratio": 3.6666666666666665, "no_speech_prob": 0.8097121119499207}, {"id": 2013, "seek": 567900, "start": 5679.0, "end": 5681.0, "text": " So.", "tokens": [50364, 407, 13, 50464], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2014, "seek": 567900, "start": 5681.0, "end": 5683.0, "text": " So.", "tokens": [50464, 407, 13, 50564], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2015, "seek": 567900, "start": 5683.0, "end": 5685.0, "text": " So.", "tokens": [50564, 407, 13, 50664], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2016, "seek": 567900, "start": 5685.0, "end": 5687.0, "text": " So.", "tokens": [50664, 407, 13, 50764], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2017, "seek": 567900, "start": 5687.0, "end": 5689.0, "text": " So we have to scale.", "tokens": [50764, 407, 321, 362, 281, 4373, 13, 50864], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2018, "seek": 567900, "start": 5689.0, "end": 5691.0, "text": " The noise.", "tokens": [50864, 440, 5658, 13, 50964], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2019, "seek": 567900, "start": 5691.0, "end": 5693.0, "text": " And subtract it out of.", "tokens": [50964, 400, 16390, 309, 484, 295, 13, 51064], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2020, "seek": 567900, "start": 5693.0, "end": 5695.0, "text": " The.", "tokens": [51064, 440, 13, 51164], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2021, "seek": 567900, "start": 5695.0, "end": 5697.0, "text": " Original image and.", "tokens": [51164, 30022, 3256, 293, 13, 51264], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2022, "seek": 567900, "start": 5697.0, "end": 5699.0, "text": " That's how we would get our.", "tokens": [51264, 663, 311, 577, 321, 576, 483, 527, 13, 51364], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2023, "seek": 567900, "start": 5699.0, "end": 5701.0, "text": " Our.", "tokens": [51364, 2621, 13, 51464], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2024, "seek": 567900, "start": 5701.0, "end": 5703.0, "text": " Predicted denoised image.", "tokens": [51464, 430, 24945, 292, 1441, 78, 2640, 3256, 13, 51564], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2025, "seek": 567900, "start": 5703.0, "end": 5705.0, "text": " Of course.", "tokens": [51564, 220, 23919, 1164, 13, 51664], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2026, "seek": 567900, "start": 5705.0, "end": 5707.0, "text": " This one before.", "tokens": [51664, 639, 472, 21312, 418, 13, 51764], "temperature": 0.8, "avg_logprob": -0.41734172022619914, "compression_ratio": 1.4045801526717556, "no_speech_prob": 0.2117583453655243}, {"id": 2027, "seek": 570700, "start": 5707.0, "end": 5715.76, "text": " for XT in the noisify function and rearranging it to solve for X naught.", "tokens": [50364, 337, 1783, 51, 294, 264, 572, 271, 2505, 2445, 293, 29875, 9741, 309, 281, 5039, 337, 1783, 13138, 13, 50802], "temperature": 0.0, "avg_logprob": -0.30941641958136307, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.14794690907001495}, {"id": 2028, "seek": 570700, "start": 5715.76, "end": 5720.16, "text": " And that's what you... Yes, yes that's basically what this is. Yes, that's", "tokens": [50802, 400, 300, 311, 437, 291, 485, 1079, 11, 2086, 300, 311, 1936, 437, 341, 307, 13, 1079, 11, 300, 311, 51022], "temperature": 0.0, "avg_logprob": -0.30941641958136307, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.14794690907001495}, {"id": 2029, "seek": 570700, "start": 5720.16, "end": 5725.24, "text": " basically what this is. So basically the idea is, okay instead of, yeah, noisifying", "tokens": [51022, 1936, 437, 341, 307, 13, 407, 1936, 264, 1558, 307, 11, 1392, 2602, 295, 11, 1338, 11, 572, 271, 5489, 51276], "temperature": 0.0, "avg_logprob": -0.30941641958136307, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.14794690907001495}, {"id": 2030, "seek": 570700, "start": 5725.24, "end": 5730.24, "text": " it where we're starting out with X zero and some noise and get an XT, we're doing", "tokens": [51276, 309, 689, 321, 434, 2891, 484, 365, 1783, 4018, 293, 512, 5658, 293, 483, 364, 1783, 51, 11, 321, 434, 884, 51526], "temperature": 0.0, "avg_logprob": -0.30941641958136307, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.14794690907001495}, {"id": 2031, "seek": 570700, "start": 5730.24, "end": 5734.52, "text": " the opposite. Where we have some noise and we have XT, so how can we get X zero?", "tokens": [51526, 264, 6182, 13, 2305, 321, 362, 512, 5658, 293, 321, 362, 1783, 51, 11, 370, 577, 393, 321, 483, 1783, 4018, 30, 51740], "temperature": 0.0, "avg_logprob": -0.30941641958136307, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.14794690907001495}, {"id": 2032, "seek": 573452, "start": 5734.52, "end": 5739.68, "text": " So that's what this equation is. So that's the predicted X zero or our, you", "tokens": [50364, 407, 300, 311, 437, 341, 5367, 307, 13, 407, 300, 311, 264, 19147, 1783, 4018, 420, 527, 11, 291, 50622], "temperature": 0.0, "avg_logprob": -0.25306470305831347, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0013884284999221563}, {"id": 2033, "seek": 573452, "start": 5739.68, "end": 5744.360000000001, "text": " know, predicted clean image. And this equation is the same for both DDPM and", "tokens": [50622, 458, 11, 19147, 2541, 3256, 13, 400, 341, 5367, 307, 264, 912, 337, 1293, 30778, 18819, 293, 50856], "temperature": 0.0, "avg_logprob": -0.25306470305831347, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0013884284999221563}, {"id": 2034, "seek": 573452, "start": 5744.360000000001, "end": 5751.240000000001, "text": " DDIM, but these distributions are what's different between DDPM and DDIM. So we", "tokens": [50856, 413, 3085, 44, 11, 457, 613, 37870, 366, 437, 311, 819, 1296, 413, 11373, 44, 293, 413, 3085, 44, 13, 407, 321, 51200], "temperature": 0.0, "avg_logprob": -0.25306470305831347, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0013884284999221563}, {"id": 2035, "seek": 573452, "start": 5751.240000000001, "end": 5757.88, "text": " have this distribution which tells us, okay, so if we have XT, which is our", "tokens": [51200, 362, 341, 7316, 597, 5112, 505, 11, 1392, 11, 370, 498, 321, 362, 1783, 51, 11, 597, 307, 527, 51532], "temperature": 0.0, "avg_logprob": -0.25306470305831347, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0013884284999221563}, {"id": 2036, "seek": 573452, "start": 5757.88, "end": 5764.160000000001, "text": " current noisy image, and X zero, which is our clean image, can we find out what", "tokens": [51532, 2190, 24518, 3256, 11, 293, 1783, 4018, 11, 597, 307, 527, 2541, 3256, 11, 393, 321, 915, 484, 437, 51846], "temperature": 0.0, "avg_logprob": -0.25306470305831347, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.0013884284999221563}, {"id": 2037, "seek": 576416, "start": 5764.24, "end": 5769.4, "text": " some sort of intermediate noisy image is in that process? And that's XT minus one.", "tokens": [50368, 512, 1333, 295, 19376, 24518, 3256, 307, 294, 300, 1399, 30, 400, 300, 311, 1783, 51, 3175, 472, 13, 50626], "temperature": 0.0, "avg_logprob": -0.2788032762932055, "compression_ratio": 1.6638297872340426, "no_speech_prob": 4.832164995605126e-05}, {"id": 2038, "seek": 576416, "start": 5769.8, "end": 5775.5599999999995, "text": " So we have a distribution for that. And so that tells us how to get such an", "tokens": [50646, 407, 321, 362, 257, 7316, 337, 300, 13, 400, 370, 300, 5112, 505, 577, 281, 483, 1270, 364, 50934], "temperature": 0.0, "avg_logprob": -0.2788032762932055, "compression_ratio": 1.6638297872340426, "no_speech_prob": 4.832164995605126e-05}, {"id": 2039, "seek": 576416, "start": 5775.5599999999995, "end": 5781.8, "text": " image. And so this is in the DDPM paper, they did divide some distribution and", "tokens": [50934, 3256, 13, 400, 370, 341, 307, 294, 264, 30778, 18819, 3035, 11, 436, 630, 9845, 512, 7316, 293, 51246], "temperature": 0.0, "avg_logprob": -0.2788032762932055, "compression_ratio": 1.6638297872340426, "no_speech_prob": 4.832164995605126e-05}, {"id": 2040, "seek": 576416, "start": 5781.8, "end": 5786.84, "text": " explain the math behind it. But yeah, basically they have some equations. So,", "tokens": [51246, 2903, 264, 5221, 2261, 309, 13, 583, 1338, 11, 1936, 436, 362, 512, 11787, 13, 407, 11, 51498], "temperature": 0.0, "avg_logprob": -0.2788032762932055, "compression_ratio": 1.6638297872340426, "no_speech_prob": 4.832164995605126e-05}, {"id": 2041, "seek": 576416, "start": 5786.96, "end": 5792.28, "text": " you know, you have again a Gaussian distribution with some sort of mean and", "tokens": [51504, 291, 458, 11, 291, 362, 797, 257, 39148, 7316, 365, 512, 1333, 295, 914, 293, 51770], "temperature": 0.0, "avg_logprob": -0.2788032762932055, "compression_ratio": 1.6638297872340426, "no_speech_prob": 4.832164995605126e-05}, {"id": 2042, "seek": 579228, "start": 5792.28, "end": 5797.32, "text": " variance, but it's again, some form of, you have this sort of interpolation", "tokens": [50364, 21977, 11, 457, 309, 311, 797, 11, 512, 1254, 295, 11, 291, 362, 341, 1333, 295, 44902, 399, 50616], "temperature": 0.0, "avg_logprob": -0.27403108175698815, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00014883083349559456}, {"id": 2043, "seek": 579228, "start": 5797.32, "end": 5805.12, "text": " between your original clean image and your noisy image, and that gives you your", "tokens": [50616, 1296, 428, 3380, 2541, 3256, 293, 428, 24518, 3256, 11, 293, 300, 2709, 291, 428, 51006], "temperature": 0.0, "avg_logprob": -0.27403108175698815, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00014883083349559456}, {"id": 2044, "seek": 579228, "start": 5806.36, "end": 5810.599999999999, "text": " intermediate less, slightly less noisy image. So that's what this is giving.", "tokens": [51068, 19376, 1570, 11, 4748, 1570, 24518, 3256, 13, 407, 300, 311, 437, 341, 307, 2902, 13, 51280], "temperature": 0.0, "avg_logprob": -0.27403108175698815, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00014883083349559456}, {"id": 2045, "seek": 579228, "start": 5811.36, "end": 5817.0, "text": " Given a clean image and a noisy image, you're slightly less noisy image. And so", "tokens": [51318, 18600, 257, 2541, 3256, 293, 257, 24518, 3256, 11, 291, 434, 4748, 1570, 24518, 3256, 13, 400, 370, 51600], "temperature": 0.0, "avg_logprob": -0.27403108175698815, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.00014883083349559456}, {"id": 2046, "seek": 581700, "start": 5817.12, "end": 5824.64, "text": " the sampling procedure that we do with DDPM basically is predict the noisy,", "tokens": [50370, 264, 21179, 10747, 300, 321, 360, 365, 30778, 18819, 1936, 307, 6069, 264, 24518, 11, 50746], "temperature": 0.0, "avg_logprob": -0.24920007160731725, "compression_ratio": 1.5219512195121951, "no_speech_prob": 0.0010004154173657298}, {"id": 2047, "seek": 581700, "start": 5824.76, "end": 5830.6, "text": " predict the X zero, and then plug it into this distribution to give you your", "tokens": [50752, 6069, 264, 1783, 4018, 11, 293, 550, 5452, 309, 666, 341, 7316, 281, 976, 291, 428, 51044], "temperature": 0.0, "avg_logprob": -0.24920007160731725, "compression_ratio": 1.5219512195121951, "no_speech_prob": 0.0010004154173657298}, {"id": 2048, "seek": 581700, "start": 5831.12, "end": 5838.48, "text": " slightly less noisy image. So maybe it's worth drawing that out. So like if we", "tokens": [51070, 4748, 1570, 24518, 3256, 13, 407, 1310, 309, 311, 3163, 6316, 300, 484, 13, 407, 411, 498, 321, 51438], "temperature": 0.0, "avg_logprob": -0.24920007160731725, "compression_ratio": 1.5219512195121951, "no_speech_prob": 0.0010004154173657298}, {"id": 2049, "seek": 581700, "start": 5838.48, "end": 5843.8, "text": " had, let's say some sort of, like, I don't know, I'm just making some sort of, I", "tokens": [51438, 632, 11, 718, 311, 584, 512, 1333, 295, 11, 411, 11, 286, 500, 380, 458, 11, 286, 478, 445, 1455, 512, 1333, 295, 11, 286, 51704], "temperature": 0.0, "avg_logprob": -0.24920007160731725, "compression_ratio": 1.5219512195121951, "no_speech_prob": 0.0010004154173657298}, {"id": 2050, "seek": 584380, "start": 5843.84, "end": 5849.8, "text": " don't know, maybe a lot of some sort of better, yeah. Some sort of, so then in", "tokens": [50366, 500, 380, 458, 11, 1310, 257, 688, 295, 512, 1333, 295, 1101, 11, 1338, 13, 2188, 1333, 295, 11, 370, 550, 294, 50664], "temperature": 0.0, "avg_logprob": -0.268388408099034, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0007915895548649132}, {"id": 2051, "seek": 584380, "start": 5849.8, "end": 5853.4800000000005, "text": " this case, I'm showing a one dimensional example, let's say you have some sort of", "tokens": [50664, 341, 1389, 11, 286, 478, 4099, 257, 472, 18795, 1365, 11, 718, 311, 584, 291, 362, 512, 1333, 295, 50848], "temperature": 0.0, "avg_logprob": -0.268388408099034, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0007915895548649132}, {"id": 2052, "seek": 584380, "start": 5854.360000000001, "end": 5857.76, "text": " point. So it's kind of a one dimensional example that's still in the sort of 2D", "tokens": [50892, 935, 13, 407, 309, 311, 733, 295, 257, 472, 18795, 1365, 300, 311, 920, 294, 264, 1333, 295, 568, 35, 51062], "temperature": 0.0, "avg_logprob": -0.268388408099034, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0007915895548649132}, {"id": 2053, "seek": 584380, "start": 5857.76, "end": 5863.360000000001, "text": " space. But let's say you have some, any point on this, it represents an actual", "tokens": [51062, 1901, 13, 583, 718, 311, 584, 291, 362, 512, 11, 604, 935, 322, 341, 11, 309, 8855, 364, 3539, 51342], "temperature": 0.0, "avg_logprob": -0.268388408099034, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0007915895548649132}, {"id": 2054, "seek": 584380, "start": 5863.360000000001, "end": 5866.68, "text": " image that you want to sample from, right? So this is, you know, where your", "tokens": [51342, 3256, 300, 291, 528, 281, 6889, 490, 11, 558, 30, 407, 341, 307, 11, 291, 458, 11, 689, 428, 51508], "temperature": 0.0, "avg_logprob": -0.268388408099034, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0007915895548649132}, {"id": 2055, "seek": 584380, "start": 5866.68, "end": 5872.96, "text": " distribution of actual images would lie. And you want to estimate this. So when", "tokens": [51508, 7316, 295, 3539, 5267, 576, 4544, 13, 400, 291, 528, 281, 12539, 341, 13, 407, 562, 51822], "temperature": 0.0, "avg_logprob": -0.268388408099034, "compression_ratio": 1.8627450980392157, "no_speech_prob": 0.0007915895548649132}, {"id": 2056, "seek": 587296, "start": 5873.08, "end": 5876.92, "text": " this sort of algorithm that we've been seeing here says that, okay, if we take", "tokens": [50370, 341, 1333, 295, 9284, 300, 321, 600, 668, 2577, 510, 1619, 300, 11, 1392, 11, 498, 321, 747, 50562], "temperature": 0.0, "avg_logprob": -0.2096259307861328, "compression_ratio": 1.9390243902439024, "no_speech_prob": 0.00018235166498925537}, {"id": 2057, "seek": 587296, "start": 5877.04, "end": 5882.24, "text": " some random point, this is some random point that we choose, you know, when we", "tokens": [50568, 512, 4974, 935, 11, 341, 307, 512, 4974, 935, 300, 321, 2826, 11, 291, 458, 11, 562, 321, 50828], "temperature": 0.0, "avg_logprob": -0.2096259307861328, "compression_ratio": 1.9390243902439024, "no_speech_prob": 0.00018235166498925537}, {"id": 2058, "seek": 587296, "start": 5882.24, "end": 5888.56, "text": " start out. And what we did is we learned this function, the score function to take", "tokens": [50828, 722, 484, 13, 400, 437, 321, 630, 307, 321, 3264, 341, 2445, 11, 264, 6175, 2445, 281, 747, 51144], "temperature": 0.0, "avg_logprob": -0.2096259307861328, "compression_ratio": 1.9390243902439024, "no_speech_prob": 0.00018235166498925537}, {"id": 2059, "seek": 587296, "start": 5888.56, "end": 5892.68, "text": " us to this manifold, but it's only going to be accurate in some space. So it's", "tokens": [51144, 505, 281, 341, 47138, 11, 457, 309, 311, 787, 516, 281, 312, 8559, 294, 512, 1901, 13, 407, 309, 311, 51350], "temperature": 0.0, "avg_logprob": -0.2096259307861328, "compression_ratio": 1.9390243902439024, "no_speech_prob": 0.00018235166498925537}, {"id": 2060, "seek": 587296, "start": 5892.68, "end": 5898.28, "text": " going to be accurate, you know, it's going to be accurate in some area. So we", "tokens": [51350, 516, 281, 312, 8559, 11, 291, 458, 11, 309, 311, 516, 281, 312, 8559, 294, 512, 1859, 13, 407, 321, 51630], "temperature": 0.0, "avg_logprob": -0.2096259307861328, "compression_ratio": 1.9390243902439024, "no_speech_prob": 0.00018235166498925537}, {"id": 2061, "seek": 587296, "start": 5898.28, "end": 5901.4800000000005, "text": " get an estimate of the score function and it tells us the direction to move in.", "tokens": [51630, 483, 364, 12539, 295, 264, 6175, 2445, 293, 309, 5112, 505, 264, 3513, 281, 1286, 294, 13, 51790], "temperature": 0.0, "avg_logprob": -0.2096259307861328, "compression_ratio": 1.9390243902439024, "no_speech_prob": 0.00018235166498925537}, {"id": 2062, "seek": 590148, "start": 5901.719999999999, "end": 5907.5599999999995, "text": " And it's going to give us the direction to predict our, our denoised image, right?", "tokens": [50376, 400, 309, 311, 516, 281, 976, 505, 264, 3513, 281, 6069, 527, 11, 527, 1441, 78, 2640, 3256, 11, 558, 30, 50668], "temperature": 0.0, "avg_logprob": -0.29317068675207714, "compression_ratio": 1.9570815450643777, "no_speech_prob": 6.401981954695657e-05}, {"id": 2063, "seek": 590148, "start": 5907.5599999999995, "end": 5913.679999999999, "text": " So basically like, let's say, let's say, let's say you actually, your score", "tokens": [50668, 407, 1936, 411, 11, 718, 311, 584, 11, 718, 311, 584, 11, 718, 311, 584, 291, 767, 11, 428, 6175, 50974], "temperature": 0.0, "avg_logprob": -0.29317068675207714, "compression_ratio": 1.9570815450643777, "no_speech_prob": 6.401981954695657e-05}, {"id": 2064, "seek": 590148, "start": 5913.679999999999, "end": 5918.2, "text": " function, sorry. So let's say your score function is actually in reality, some", "tokens": [50974, 2445, 11, 2597, 13, 407, 718, 311, 584, 428, 6175, 2445, 307, 767, 294, 4103, 11, 512, 51200], "temperature": 0.0, "avg_logprob": -0.29317068675207714, "compression_ratio": 1.9570815450643777, "no_speech_prob": 6.401981954695657e-05}, {"id": 2065, "seek": 590148, "start": 5918.2, "end": 5922.48, "text": " curve. Okay. So it's in reality, some curve that points to your, oops, it", "tokens": [51200, 7605, 13, 1033, 13, 407, 309, 311, 294, 4103, 11, 512, 7605, 300, 2793, 281, 428, 11, 34166, 11, 309, 51414], "temperature": 0.0, "avg_logprob": -0.29317068675207714, "compression_ratio": 1.9570815450643777, "no_speech_prob": 6.401981954695657e-05}, {"id": 2066, "seek": 590148, "start": 5922.48, "end": 5926.599999999999, "text": " points here. So that's your score function. And you know, the value here,", "tokens": [51414, 2793, 510, 13, 407, 300, 311, 428, 6175, 2445, 13, 400, 291, 458, 11, 264, 2158, 510, 11, 51620], "temperature": 0.0, "avg_logprob": -0.29317068675207714, "compression_ratio": 1.9570815450643777, "no_speech_prob": 6.401981954695657e-05}, {"id": 2067, "seek": 590148, "start": 5926.599999999999, "end": 5927.0, "text": " that's what...", "tokens": [51620, 300, 311, 437, 485, 51640], "temperature": 0.0, "avg_logprob": -0.29317068675207714, "compression_ratio": 1.9570815450643777, "no_speech_prob": 6.401981954695657e-05}, {"id": 2068, "seek": 590148, "start": 5927.0, "end": 5929.4, "text": " The score function basically means your gradient. Yeah.", "tokens": [51640, 440, 6175, 2445, 1936, 1355, 428, 16235, 13, 865, 13, 51760], "temperature": 0.0, "avg_logprob": -0.29317068675207714, "compression_ratio": 1.9570815450643777, "no_speech_prob": 6.401981954695657e-05}, {"id": 2069, "seek": 592940, "start": 5930.4, "end": 5935.4, "text": " Yes, yes. It's a gradient. So, you know, we again, doing some form of, in this", "tokens": [50414, 1079, 11, 2086, 13, 467, 311, 257, 16235, 13, 407, 11, 291, 458, 11, 321, 797, 11, 884, 512, 1254, 295, 11, 294, 341, 50664], "temperature": 0.0, "avg_logprob": -0.2406788468360901, "compression_ratio": 1.8647540983606556, "no_speech_prob": 3.7052566767670214e-05}, {"id": 2070, "seek": 592940, "start": 5935.4, "end": 5938.5199999999995, "text": " case, I guess you would say gradient ascent, because you're not really", "tokens": [50664, 1389, 11, 286, 2041, 291, 576, 584, 16235, 382, 2207, 11, 570, 291, 434, 406, 534, 50820], "temperature": 0.0, "avg_logprob": -0.2406788468360901, "compression_ratio": 1.8647540983606556, "no_speech_prob": 3.7052566767670214e-05}, {"id": 2071, "seek": 592940, "start": 5939.44, "end": 5943.12, "text": " minimizing the score, you're maximizing it. You want, sorry, you're maximizing", "tokens": [50866, 46608, 264, 6175, 11, 291, 434, 5138, 3319, 309, 13, 509, 528, 11, 2597, 11, 291, 434, 5138, 3319, 51050], "temperature": 0.0, "avg_logprob": -0.2406788468360901, "compression_ratio": 1.8647540983606556, "no_speech_prob": 3.7052566767670214e-05}, {"id": 2072, "seek": 592940, "start": 5943.12, "end": 5947.759999999999, "text": " your, your, the likelihood of that data point being an actual data point. You", "tokens": [51050, 428, 11, 428, 11, 264, 22119, 295, 300, 1412, 935, 885, 364, 3539, 1412, 935, 13, 509, 51282], "temperature": 0.0, "avg_logprob": -0.2406788468360901, "compression_ratio": 1.8647540983606556, "no_speech_prob": 3.7052566767670214e-05}, {"id": 2073, "seek": 592940, "start": 5947.759999999999, "end": 5951.92, "text": " want to go towards it. So you're, you're doing the sort of gradient ascent", "tokens": [51282, 528, 281, 352, 3030, 309, 13, 407, 291, 434, 11, 291, 434, 884, 264, 1333, 295, 16235, 382, 2207, 51490], "temperature": 0.0, "avg_logprob": -0.2406788468360901, "compression_ratio": 1.8647540983606556, "no_speech_prob": 3.7052566767670214e-05}, {"id": 2074, "seek": 592940, "start": 5951.92, "end": 5958.04, "text": " process. So you're following the gradient to, to get to that. So, so when", "tokens": [51490, 1399, 13, 407, 291, 434, 3480, 264, 16235, 281, 11, 281, 483, 281, 300, 13, 407, 11, 370, 562, 51796], "temperature": 0.0, "avg_logprob": -0.2406788468360901, "compression_ratio": 1.8647540983606556, "no_speech_prob": 3.7052566767670214e-05}, {"id": 2075, "seek": 595804, "start": 5958.04, "end": 5964.08, "text": " we estimate, epsilon theta and predict our noise, what we're doing is we're", "tokens": [50364, 321, 12539, 11, 17889, 9725, 293, 6069, 527, 5658, 11, 437, 321, 434, 884, 307, 321, 434, 50666], "temperature": 0.0, "avg_logprob": -0.28235084019350204, "compression_ratio": 1.5678391959798994, "no_speech_prob": 5.6495729950256646e-05}, {"id": 2076, "seek": 595804, "start": 5964.08, "end": 5970.0, "text": " getting the score value here. And then so we can, you know, follow that and we", "tokens": [50666, 1242, 264, 6175, 2158, 510, 13, 400, 550, 370, 321, 393, 11, 291, 458, 11, 1524, 300, 293, 321, 50962], "temperature": 0.0, "avg_logprob": -0.28235084019350204, "compression_ratio": 1.5678391959798994, "no_speech_prob": 5.6495729950256646e-05}, {"id": 2077, "seek": 595804, "start": 5970.0, "end": 5976.32, "text": " follow it to some point. I'm being kind of exaggerating here, but this point", "tokens": [50962, 1524, 309, 281, 512, 935, 13, 286, 478, 885, 733, 295, 454, 559, 1321, 990, 510, 11, 457, 341, 935, 51278], "temperature": 0.0, "avg_logprob": -0.28235084019350204, "compression_ratio": 1.5678391959798994, "no_speech_prob": 5.6495729950256646e-05}, {"id": 2078, "seek": 595804, "start": 5976.64, "end": 5986.4, "text": " will now represent our X zero hat. Yeah. So yeah, our X zero hat. So and, and in", "tokens": [51294, 486, 586, 2906, 527, 1783, 4018, 2385, 13, 865, 13, 407, 1338, 11, 527, 1783, 4018, 2385, 13, 407, 293, 11, 293, 294, 51782], "temperature": 0.0, "avg_logprob": -0.28235084019350204, "compression_ratio": 1.5678391959798994, "no_speech_prob": 5.6495729950256646e-05}, {"id": 2079, "seek": 598640, "start": 5986.4, "end": 5989.839999999999, "text": " reality, you know, that's not, maybe that's not going to be some point that", "tokens": [50364, 4103, 11, 291, 458, 11, 300, 311, 406, 11, 1310, 300, 311, 406, 516, 281, 312, 512, 935, 300, 50536], "temperature": 0.0, "avg_logprob": -0.2030073574611119, "compression_ratio": 1.8815165876777251, "no_speech_prob": 4.5393524487735704e-05}, {"id": 2080, "seek": 598640, "start": 5989.839999999999, "end": 5995.24, "text": " is an actual point. It wouldn't be next to the distribution. So, you know, it's,", "tokens": [50536, 307, 364, 3539, 935, 13, 467, 2759, 380, 312, 958, 281, 264, 7316, 13, 407, 11, 291, 458, 11, 309, 311, 11, 50806], "temperature": 0.0, "avg_logprob": -0.2030073574611119, "compression_ratio": 1.8815165876777251, "no_speech_prob": 4.5393524487735704e-05}, {"id": 2081, "seek": 598640, "start": 5995.32, "end": 6000.4, "text": " it's not going to be a very good estimate of a clean image at the beginning, but,", "tokens": [50810, 309, 311, 406, 516, 281, 312, 257, 588, 665, 12539, 295, 257, 2541, 3256, 412, 264, 2863, 11, 457, 11, 51064], "temperature": 0.0, "avg_logprob": -0.2030073574611119, "compression_ratio": 1.8815165876777251, "no_speech_prob": 4.5393524487735704e-05}, {"id": 2082, "seek": 598640, "start": 6000.44, "end": 6003.719999999999, "text": " you know, we only have that estimate at the beginning at this point, and we have", "tokens": [51066, 291, 458, 11, 321, 787, 362, 300, 12539, 412, 264, 2863, 412, 341, 935, 11, 293, 321, 362, 51230], "temperature": 0.0, "avg_logprob": -0.2030073574611119, "compression_ratio": 1.8815165876777251, "no_speech_prob": 4.5393524487735704e-05}, {"id": 2083, "seek": 598640, "start": 6003.719999999999, "end": 6008.5599999999995, "text": " to follow it all the way to, to some place. So this is where we follow it to.", "tokens": [51230, 281, 1524, 309, 439, 264, 636, 281, 11, 281, 512, 1081, 13, 407, 341, 307, 689, 321, 1524, 309, 281, 13, 51472], "temperature": 0.0, "avg_logprob": -0.2030073574611119, "compression_ratio": 1.8815165876777251, "no_speech_prob": 4.5393524487735704e-05}, {"id": 2084, "seek": 600856, "start": 6009.240000000001, "end": 6016.72, "text": " And then we want to find some sort of X T minus one. So that's what our next point", "tokens": [50398, 400, 550, 321, 528, 281, 915, 512, 1333, 295, 1783, 314, 3175, 472, 13, 407, 300, 311, 437, 527, 958, 935, 50772], "temperature": 0.0, "avg_logprob": -0.258994412976642, "compression_ratio": 1.6648936170212767, "no_speech_prob": 0.02675437182188034}, {"id": 2085, "seek": 600856, "start": 6016.72, "end": 6021.8, "text": " is. And so that's what our second distribution tells us. And it basically", "tokens": [50772, 307, 13, 400, 370, 300, 311, 437, 527, 1150, 7316, 5112, 505, 13, 400, 309, 1936, 51026], "temperature": 0.0, "avg_logprob": -0.258994412976642, "compression_ratio": 1.6648936170212767, "no_speech_prob": 0.02675437182188034}, {"id": 2086, "seek": 600856, "start": 6022.64, "end": 6028.04, "text": " takes us all the way, takes us all the way back to maybe some point here. And", "tokens": [51068, 2516, 505, 439, 264, 636, 11, 2516, 505, 439, 264, 636, 646, 281, 1310, 512, 935, 510, 13, 400, 51338], "temperature": 0.0, "avg_logprob": -0.258994412976642, "compression_ratio": 1.6648936170212767, "no_speech_prob": 0.02675437182188034}, {"id": 2087, "seek": 600856, "start": 6028.080000000001, "end": 6033.84, "text": " now we can re-estimate the, the, the score function or yeah, our gradient over", "tokens": [51340, 586, 321, 393, 319, 12, 377, 2905, 264, 11, 264, 11, 264, 6175, 2445, 420, 1338, 11, 527, 16235, 670, 51628], "temperature": 0.0, "avg_logprob": -0.258994412976642, "compression_ratio": 1.6648936170212767, "no_speech_prob": 0.02675437182188034}, {"id": 2088, "seek": 603384, "start": 6033.88, "end": 6038.08, "text": " there, you know, do this prediction of noise. And, you know, it may be more", "tokens": [50366, 456, 11, 291, 458, 11, 360, 341, 17630, 295, 5658, 13, 400, 11, 291, 458, 11, 309, 815, 312, 544, 50576], "temperature": 0.0, "avg_logprob": -0.22757535610558852, "compression_ratio": 1.7702702702702702, "no_speech_prob": 0.02479401044547558}, {"id": 2089, "seek": 603384, "start": 6038.08, "end": 6043.64, "text": " accurate of a, of a score function and maybe we go somewhere here and then we", "tokens": [50576, 8559, 295, 257, 11, 295, 257, 6175, 2445, 293, 1310, 321, 352, 4079, 510, 293, 550, 321, 50854], "temperature": 0.0, "avg_logprob": -0.22757535610558852, "compression_ratio": 1.7702702702702702, "no_speech_prob": 0.02479401044547558}, {"id": 2090, "seek": 603384, "start": 6043.64, "end": 6047.76, "text": " re-estimate and get another point and then we follow it. And so that's kind of", "tokens": [50854, 319, 12, 377, 2905, 293, 483, 1071, 935, 293, 550, 321, 1524, 309, 13, 400, 370, 300, 311, 733, 295, 51060], "temperature": 0.0, "avg_logprob": -0.22757535610558852, "compression_ratio": 1.7702702702702702, "no_speech_prob": 0.02479401044547558}, {"id": 2091, "seek": 603384, "start": 6047.76, "end": 6052.96, "text": " this iterative process where we're trying to follow this, the score function to", "tokens": [51060, 341, 17138, 1166, 1399, 689, 321, 434, 1382, 281, 1524, 341, 11, 264, 6175, 2445, 281, 51320], "temperature": 0.0, "avg_logprob": -0.22757535610558852, "compression_ratio": 1.7702702702702702, "no_speech_prob": 0.02479401044547558}, {"id": 2092, "seek": 603384, "start": 6052.96, "end": 6058.08, "text": " your own point. And in order to do so, we first have to estimate our X zero hat,", "tokens": [51320, 428, 1065, 935, 13, 400, 294, 1668, 281, 360, 370, 11, 321, 700, 362, 281, 12539, 527, 1783, 4018, 2385, 11, 51576], "temperature": 0.0, "avg_logprob": -0.22757535610558852, "compression_ratio": 1.7702702702702702, "no_speech_prob": 0.02479401044547558}, {"id": 2093, "seek": 605808, "start": 6058.2, "end": 6066.48, "text": " and then, and then basically add back some noise and to get, you know, a little", "tokens": [50370, 293, 550, 11, 293, 550, 1936, 909, 646, 512, 5658, 293, 281, 483, 11, 291, 458, 11, 257, 707, 50784], "temperature": 0.0, "avg_logprob": -0.24605187663325556, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000597640872001648}, {"id": 2094, "seek": 605808, "start": 6066.48, "end": 6069.88, "text": " bit, I get a new estimate and keep following and add back a little bit more", "tokens": [50784, 857, 11, 286, 483, 257, 777, 12539, 293, 1066, 3480, 293, 909, 646, 257, 707, 857, 544, 50954], "temperature": 0.0, "avg_logprob": -0.24605187663325556, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000597640872001648}, {"id": 2095, "seek": 605808, "start": 6069.88, "end": 6075.0, "text": " noise and keep estimating. So that's what we're doing here in these two steps.", "tokens": [50954, 5658, 293, 1066, 8017, 990, 13, 407, 300, 311, 437, 321, 434, 884, 510, 294, 613, 732, 4439, 13, 51210], "temperature": 0.0, "avg_logprob": -0.24605187663325556, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000597640872001648}, {"id": 2096, "seek": 605808, "start": 6075.0, "end": 6080.0, "text": " We have our X zero hat, and then we have this distribution and that's how we do", "tokens": [51210, 492, 362, 527, 1783, 4018, 2385, 11, 293, 550, 321, 362, 341, 7316, 293, 300, 311, 577, 321, 360, 51460], "temperature": 0.0, "avg_logprob": -0.24605187663325556, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000597640872001648}, {"id": 2097, "seek": 605808, "start": 6080.0, "end": 6085.16, "text": " it regular DDPM. And it's that, I think that's the, maybe where the sort of", "tokens": [51460, 309, 3890, 413, 11373, 44, 13, 400, 309, 311, 300, 11, 286, 519, 300, 311, 264, 11, 1310, 689, 264, 1333, 295, 51718], "temperature": 0.0, "avg_logprob": -0.24605187663325556, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.000597640872001648}, {"id": 2098, "seek": 608516, "start": 6085.48, "end": 6090.599999999999, "text": " breaking it up in two steps is a little bit clearer. And I don't think the DDPM", "tokens": [50380, 7697, 309, 493, 294, 732, 4439, 307, 257, 707, 857, 26131, 13, 400, 286, 500, 380, 519, 264, 413, 11373, 44, 50636], "temperature": 0.0, "avg_logprob": -0.32941734890977875, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005274504655972123}, {"id": 2099, "seek": 608516, "start": 6090.599999999999, "end": 6096.8, "text": " paper really clarifies that, really talks about it too much. But the DDPM paper", "tokens": [50636, 3035, 534, 6093, 11221, 300, 11, 534, 6686, 466, 309, 886, 709, 13, 583, 264, 413, 11373, 44, 3035, 50946], "temperature": 0.0, "avg_logprob": -0.32941734890977875, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005274504655972123}, {"id": 2100, "seek": 608516, "start": 6096.8, "end": 6101.24, "text": " also really hammers that point home, I think, and especially in their, in their", "tokens": [50946, 611, 534, 36600, 433, 300, 935, 1280, 11, 286, 519, 11, 293, 2318, 294, 641, 11, 294, 641, 51168], "temperature": 0.0, "avg_logprob": -0.32941734890977875, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005274504655972123}, {"id": 2101, "seek": 608516, "start": 6101.24, "end": 6107.44, "text": " update equation. So the other, so that's the DDPM, but then with DDIM,", "tokens": [51168, 5623, 5367, 13, 407, 264, 661, 11, 370, 300, 311, 264, 413, 11373, 44, 11, 457, 550, 365, 413, 3085, 44, 11, 51478], "temperature": 0.0, "avg_logprob": -0.32941734890977875, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005274504655972123}, {"id": 2102, "seek": 608516, "start": 6108.5599999999995, "end": 6109.04, "text": " Okay, go ahead.", "tokens": [51534, 1033, 11, 352, 2286, 13, 51558], "temperature": 0.0, "avg_logprob": -0.32941734890977875, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005274504655972123}, {"id": 2103, "seek": 608516, "start": 6109.04, "end": 6112.76, "text": " So before you do DDPM, just the one thing is that the, you look at your", "tokens": [51558, 407, 949, 291, 360, 413, 11373, 44, 11, 445, 264, 472, 551, 307, 300, 264, 11, 291, 574, 412, 428, 51744], "temperature": 0.0, "avg_logprob": -0.32941734890977875, "compression_ratio": 1.6583333333333334, "no_speech_prob": 0.0005274504655972123}, {"id": 2104, "seek": 611276, "start": 6112.76, "end": 6117.4400000000005, "text": " prediction, use that to make a step, but you also add back some additional noise", "tokens": [50364, 17630, 11, 764, 300, 281, 652, 257, 1823, 11, 457, 291, 611, 909, 646, 512, 4497, 5658, 50598], "temperature": 0.0, "avg_logprob": -0.2730697201144311, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.006903371773660183}, {"id": 2105, "seek": 611276, "start": 6117.4800000000005, "end": 6119.0, "text": " that's always fixed.", "tokens": [50600, 300, 311, 1009, 6806, 13, 50676], "temperature": 0.0, "avg_logprob": -0.2730697201144311, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.006903371773660183}, {"id": 2106, "seek": 611276, "start": 6119.0, "end": 6119.400000000001, "text": " Right.", "tokens": [50676, 1779, 13, 50696], "temperature": 0.0, "avg_logprob": -0.2730697201144311, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.006903371773660183}, {"id": 2107, "seek": 611276, "start": 6119.68, "end": 6122.8, "text": " DDPM, there's no parameters to control how much extra noise you add back at each", "tokens": [50710, 413, 11373, 44, 11, 456, 311, 572, 9834, 281, 1969, 577, 709, 2857, 5658, 291, 909, 646, 412, 1184, 50866], "temperature": 0.0, "avg_logprob": -0.2730697201144311, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.006903371773660183}, {"id": 2108, "seek": 611276, "start": 6122.8, "end": 6123.08, "text": " step.", "tokens": [50866, 1823, 13, 50880], "temperature": 0.0, "avg_logprob": -0.2730697201144311, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.006903371773660183}, {"id": 2109, "seek": 611276, "start": 6124.360000000001, "end": 6131.2, "text": " Right, exactly. So, so, yeah, so when you're, let's see here. Yeah. So yeah,", "tokens": [50944, 1779, 11, 2293, 13, 407, 11, 370, 11, 1338, 11, 370, 562, 291, 434, 11, 718, 311, 536, 510, 13, 865, 13, 407, 1338, 11, 51286], "temperature": 0.0, "avg_logprob": -0.2730697201144311, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.006903371773660183}, {"id": 2110, "seek": 611276, "start": 6131.2, "end": 6135.0, "text": " basically you won't be exactly at this point, you could be, you know, you're in", "tokens": [51286, 1936, 291, 1582, 380, 312, 2293, 412, 341, 935, 11, 291, 727, 312, 11, 291, 458, 11, 291, 434, 294, 51476], "temperature": 0.0, "avg_logprob": -0.2730697201144311, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.006903371773660183}, {"id": 2111, "seek": 611276, "start": 6135.0, "end": 6139.52, "text": " that general vicinity and, you know, adding that noise also helps with, you", "tokens": [51476, 300, 2674, 42387, 293, 11, 291, 458, 11, 5127, 300, 5658, 611, 3665, 365, 11, 291, 51702], "temperature": 0.0, "avg_logprob": -0.2730697201144311, "compression_ratio": 1.691699604743083, "no_speech_prob": 0.006903371773660183}, {"id": 2112, "seek": 613952, "start": 6139.52, "end": 6145.56, "text": " know, you don't want to fall into, you know, specific modes where it's like,", "tokens": [50364, 458, 11, 291, 500, 380, 528, 281, 2100, 666, 11, 291, 458, 11, 2685, 14068, 689, 309, 311, 411, 11, 50666], "temperature": 0.0, "avg_logprob": -0.23640081450695127, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.0005527336033992469}, {"id": 2113, "seek": 613952, "start": 6145.56, "end": 6149.68, "text": " oh, you know, this is the most likely data point. You want to add some noise", "tokens": [50666, 1954, 11, 291, 458, 11, 341, 307, 264, 881, 3700, 1412, 935, 13, 509, 528, 281, 909, 512, 5658, 50872], "temperature": 0.0, "avg_logprob": -0.23640081450695127, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.0005527336033992469}, {"id": 2114, "seek": 613952, "start": 6149.68, "end": 6153.56, "text": " where you can like explore other data points as well. So yeah, there's some,", "tokens": [50872, 689, 291, 393, 411, 6839, 661, 1412, 2793, 382, 731, 13, 407, 1338, 11, 456, 311, 512, 11, 51066], "temperature": 0.0, "avg_logprob": -0.23640081450695127, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.0005527336033992469}, {"id": 2115, "seek": 613952, "start": 6154.280000000001, "end": 6158.52, "text": " you know, the noise also can help and that's something you really can't control", "tokens": [51102, 291, 458, 11, 264, 5658, 611, 393, 854, 293, 300, 311, 746, 291, 534, 393, 380, 1969, 51314], "temperature": 0.0, "avg_logprob": -0.23640081450695127, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.0005527336033992469}, {"id": 2116, "seek": 613952, "start": 6158.52, "end": 6162.84, "text": " with DDPM. And that's something that DDIM explores a little bit further is in", "tokens": [51314, 365, 413, 11373, 44, 13, 400, 300, 311, 746, 300, 413, 3085, 44, 45473, 257, 707, 857, 3052, 307, 294, 51530], "temperature": 0.0, "avg_logprob": -0.23640081450695127, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.0005527336033992469}, {"id": 2117, "seek": 613952, "start": 6162.84, "end": 6167.84, "text": " terms of the noise and even trying to get rid of the noise altogether in DDIM.", "tokens": [51530, 2115, 295, 264, 5658, 293, 754, 1382, 281, 483, 3973, 295, 264, 5658, 19051, 294, 413, 3085, 44, 13, 51780], "temperature": 0.0, "avg_logprob": -0.23640081450695127, "compression_ratio": 1.8458498023715415, "no_speech_prob": 0.0005527336033992469}, {"id": 2118, "seek": 616784, "start": 6168.56, "end": 6175.04, "text": " So with the DDIM paper, the main difference is literally this one equation.", "tokens": [50400, 407, 365, 264, 413, 3085, 44, 3035, 11, 264, 2135, 2649, 307, 3736, 341, 472, 5367, 13, 50724], "temperature": 0.0, "avg_logprob": -0.26501667963994013, "compression_ratio": 1.5678391959798994, "no_speech_prob": 9.314116323366761e-05}, {"id": 2119, "seek": 616784, "start": 6175.04, "end": 6181.68, "text": " That's all, all really it is in terms of changing this distribution where you", "tokens": [50724, 663, 311, 439, 11, 439, 534, 309, 307, 294, 2115, 295, 4473, 341, 7316, 689, 291, 51056], "temperature": 0.0, "avg_logprob": -0.26501667963994013, "compression_ratio": 1.5678391959798994, "no_speech_prob": 9.314116323366761e-05}, {"id": 2120, "seek": 616784, "start": 6181.68, "end": 6189.28, "text": " predict the less noisy equation, the less noisy, sorry, the less noisy image.", "tokens": [51056, 6069, 264, 1570, 24518, 5367, 11, 264, 1570, 24518, 11, 2597, 11, 264, 1570, 24518, 3256, 13, 51436], "temperature": 0.0, "avg_logprob": -0.26501667963994013, "compression_ratio": 1.5678391959798994, "no_speech_prob": 9.314116323366761e-05}, {"id": 2121, "seek": 616784, "start": 6190.32, "end": 6197.32, "text": " And basically, as you can see, it's just, you have this additional parameter now", "tokens": [51488, 400, 1936, 11, 382, 291, 393, 536, 11, 309, 311, 445, 11, 291, 362, 341, 4497, 13075, 586, 51838], "temperature": 0.0, "avg_logprob": -0.26501667963994013, "compression_ratio": 1.5678391959798994, "no_speech_prob": 9.314116323366761e-05}, {"id": 2122, "seek": 619784, "start": 6198.24, "end": 6202.96, "text": " which is sigma and the sigma controls how much noise, like we were just", "tokens": [50384, 597, 307, 12771, 293, 264, 12771, 9003, 577, 709, 5658, 11, 411, 321, 645, 445, 50620], "temperature": 0.0, "avg_logprob": -0.2516040802001953, "compression_ratio": 1.758139534883721, "no_speech_prob": 3.168749390169978e-05}, {"id": 2123, "seek": 619784, "start": 6202.96, "end": 6208.28, "text": " mentioning, is going to be part of this process. And you can actually, for", "tokens": [50620, 18315, 11, 307, 516, 281, 312, 644, 295, 341, 1399, 13, 400, 291, 393, 767, 11, 337, 50886], "temperature": 0.0, "avg_logprob": -0.2516040802001953, "compression_ratio": 1.758139534883721, "no_speech_prob": 3.168749390169978e-05}, {"id": 2124, "seek": 619784, "start": 6208.28, "end": 6212.0, "text": " example, if you want, you could set sigma to zero and then you can see here now", "tokens": [50886, 1365, 11, 498, 291, 528, 11, 291, 727, 992, 12771, 281, 4018, 293, 550, 291, 393, 536, 510, 586, 51072], "temperature": 0.0, "avg_logprob": -0.2516040802001953, "compression_ratio": 1.758139534883721, "no_speech_prob": 3.168749390169978e-05}, {"id": 2125, "seek": 619784, "start": 6212.0, "end": 6215.72, "text": " you have a variance that would be zero. And so this becomes a completely", "tokens": [51072, 291, 362, 257, 21977, 300, 576, 312, 4018, 13, 400, 370, 341, 3643, 257, 2584, 51258], "temperature": 0.0, "avg_logprob": -0.2516040802001953, "compression_ratio": 1.758139534883721, "no_speech_prob": 3.168749390169978e-05}, {"id": 2126, "seek": 619784, "start": 6215.72, "end": 6220.0, "text": " deterministic process. So if you want, this could be completely deterministic.", "tokens": [51258, 15957, 3142, 1399, 13, 407, 498, 291, 528, 11, 341, 727, 312, 2584, 15957, 3142, 13, 51472], "temperature": 0.0, "avg_logprob": -0.2516040802001953, "compression_ratio": 1.758139534883721, "no_speech_prob": 3.168749390169978e-05}, {"id": 2127, "seek": 622000, "start": 6220.24, "end": 6223.56, "text": " So that's one aspect of it.", "tokens": [50376, 407, 300, 311, 472, 4171, 295, 309, 13, 50542], "temperature": 0.0, "avg_logprob": -0.3101545699099277, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0014549841871485114}, {"id": 2128, "seek": 622000, "start": 6225.4, "end": 6234.56, "text": " And then, yeah, so the other aspect, so one of the reasons it's called DDIM is", "tokens": [50634, 400, 550, 11, 1338, 11, 370, 264, 661, 4171, 11, 370, 472, 295, 264, 4112, 309, 311, 1219, 413, 3085, 44, 307, 51092], "temperature": 0.0, "avg_logprob": -0.3101545699099277, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0014549841871485114}, {"id": 2129, "seek": 622000, "start": 6234.56, "end": 6239.52, "text": " just not DDPM because it's like not probabilistic anymore. It can be made", "tokens": [51092, 445, 406, 413, 11373, 44, 570, 309, 311, 411, 406, 31959, 3142, 3602, 13, 467, 393, 312, 1027, 51340], "temperature": 0.0, "avg_logprob": -0.3101545699099277, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0014549841871485114}, {"id": 2130, "seek": 622000, "start": 6239.52, "end": 6244.4, "text": " deterministic. So the name was changed for that reason. But the other thing is", "tokens": [51340, 15957, 3142, 13, 407, 264, 1315, 390, 3105, 337, 300, 1778, 13, 583, 264, 661, 551, 307, 51584], "temperature": 0.0, "avg_logprob": -0.3101545699099277, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0014549841871485114}, {"id": 2131, "seek": 622000, "start": 6244.4, "end": 6248.96, "text": " like, you would think that you've kind of changed the model altogether with a new", "tokens": [51584, 411, 11, 291, 576, 519, 300, 291, 600, 733, 295, 3105, 264, 2316, 19051, 365, 257, 777, 51812], "temperature": 0.0, "avg_logprob": -0.3101545699099277, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0014549841871485114}, {"id": 2132, "seek": 624896, "start": 6249.0, "end": 6253.52, "text": " distribution altogether. And so you think, oh, wouldn't you have to like", "tokens": [50366, 7316, 19051, 13, 400, 370, 291, 519, 11, 1954, 11, 2759, 380, 291, 362, 281, 411, 50592], "temperature": 0.0, "avg_logprob": -0.25394930881736555, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.0006262711249291897}, {"id": 2133, "seek": 624896, "start": 6253.52, "end": 6257.36, "text": " trade a different model for this purpose? But it turns out the math works out", "tokens": [50592, 4923, 257, 819, 2316, 337, 341, 4334, 30, 583, 309, 4523, 484, 264, 5221, 1985, 484, 50784], "temperature": 0.0, "avg_logprob": -0.25394930881736555, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.0006262711249291897}, {"id": 2134, "seek": 624896, "start": 6257.36, "end": 6262.88, "text": " where the same model objective would work well with this distribution as well.", "tokens": [50784, 689, 264, 912, 2316, 10024, 576, 589, 731, 365, 341, 7316, 382, 731, 13, 51060], "temperature": 0.0, "avg_logprob": -0.25394930881736555, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.0006262711249291897}, {"id": 2135, "seek": 624896, "start": 6263.52, "end": 6266.88, "text": " And in fact, I think that's what they were setting out from the very beginning", "tokens": [51092, 400, 294, 1186, 11, 286, 519, 300, 311, 437, 436, 645, 3287, 484, 490, 264, 588, 2863, 51260], "temperature": 0.0, "avg_logprob": -0.25394930881736555, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.0006262711249291897}, {"id": 2136, "seek": 624896, "start": 6266.88, "end": 6273.6, "text": " is what kind of other models can we get with the same objective? And so this is", "tokens": [51260, 307, 437, 733, 295, 661, 5245, 393, 321, 483, 365, 264, 912, 10024, 30, 400, 370, 341, 307, 51596], "temperature": 0.0, "avg_logprob": -0.25394930881736555, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.0006262711249291897}, {"id": 2137, "seek": 624896, "start": 6273.64, "end": 6278.16, "text": " what they're able to do is you can make some, you can have this new parameter", "tokens": [51598, 437, 436, 434, 1075, 281, 360, 307, 291, 393, 652, 512, 11, 291, 393, 362, 341, 777, 13075, 51824], "temperature": 0.0, "avg_logprob": -0.25394930881736555, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.0006262711249291897}, {"id": 2138, "seek": 627816, "start": 6278.16, "end": 6282.5599999999995, "text": " that you can introduce, in this case, kind of controlling the stochasticity of", "tokens": [50364, 300, 291, 393, 5366, 11, 294, 341, 1389, 11, 733, 295, 14905, 264, 342, 8997, 2750, 507, 295, 50584], "temperature": 0.0, "avg_logprob": -0.27466003711407, "compression_ratio": 1.6774193548387097, "no_speech_prob": 8.749795233597979e-05}, {"id": 2139, "seek": 627816, "start": 6282.5599999999995, "end": 6294.96, "text": " the model. And you can still use the same exact trained model that you had.", "tokens": [50584, 264, 2316, 13, 400, 291, 393, 920, 764, 264, 912, 1900, 8895, 2316, 300, 291, 632, 13, 51204], "temperature": 0.0, "avg_logprob": -0.27466003711407, "compression_ratio": 1.6774193548387097, "no_speech_prob": 8.749795233597979e-05}, {"id": 2140, "seek": 627816, "start": 6295.2, "end": 6300.08, "text": " So what this means is that this actually is just a new sampling algorithm and not", "tokens": [51216, 407, 437, 341, 1355, 307, 300, 341, 767, 307, 445, 257, 777, 21179, 9284, 293, 406, 51460], "temperature": 0.0, "avg_logprob": -0.27466003711407, "compression_ratio": 1.6774193548387097, "no_speech_prob": 8.749795233597979e-05}, {"id": 2141, "seek": 627816, "start": 6300.16, "end": 6303.96, "text": " anything new with the training itself. And this is just, yeah, just like we", "tokens": [51464, 1340, 777, 365, 264, 3097, 2564, 13, 400, 341, 307, 445, 11, 1338, 11, 445, 411, 321, 51654], "temperature": 0.0, "avg_logprob": -0.27466003711407, "compression_ratio": 1.6774193548387097, "no_speech_prob": 8.749795233597979e-05}, {"id": 2142, "seek": 630396, "start": 6303.96, "end": 6309.64, "text": " talked about a new way of sampling the model. And then, so yeah, this is how,", "tokens": [50364, 2825, 466, 257, 777, 636, 295, 21179, 264, 2316, 13, 400, 550, 11, 370, 1338, 11, 341, 307, 577, 11, 50648], "temperature": 0.0, "avg_logprob": -0.28871771994601475, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0038237683475017548}, {"id": 2143, "seek": 630396, "start": 6309.76, "end": 6316.2, "text": " you know, given now this equation, then you can rewrite your Xt minus one term.", "tokens": [50654, 291, 458, 11, 2212, 586, 341, 5367, 11, 550, 291, 393, 28132, 428, 1783, 83, 3175, 472, 1433, 13, 50976], "temperature": 0.0, "avg_logprob": -0.28871771994601475, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0038237683475017548}, {"id": 2144, "seek": 630396, "start": 6316.6, "end": 6321.04, "text": " And again, by doing the same sort of thing where we split it up into predicting the", "tokens": [50996, 400, 797, 11, 538, 884, 264, 912, 1333, 295, 551, 689, 321, 7472, 309, 493, 666, 32884, 264, 51218], "temperature": 0.0, "avg_logprob": -0.28871771994601475, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0038237683475017548}, {"id": 2145, "seek": 630396, "start": 6321.04, "end": 6330.68, "text": " X zero and then adding back to go back to your Xt. And also if you need to add a", "tokens": [51218, 1783, 4018, 293, 550, 5127, 646, 281, 352, 646, 281, 428, 1783, 83, 13, 400, 611, 498, 291, 643, 281, 909, 257, 51700], "temperature": 0.0, "avg_logprob": -0.28871771994601475, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0038237683475017548}, {"id": 2146, "seek": 633068, "start": 6330.68, "end": 6336.84, "text": " little bit of noise back in, like Jonathan was saying, you can do so. You have this", "tokens": [50364, 707, 857, 295, 5658, 646, 294, 11, 411, 15471, 390, 1566, 11, 291, 393, 360, 370, 13, 509, 362, 341, 50672], "temperature": 0.0, "avg_logprob": -0.26554217283753145, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.00353676313534379}, {"id": 2147, "seek": 633068, "start": 6336.84, "end": 6343.8, "text": " extra term here and the sigma controls that term. And again, like we said, you", "tokens": [50672, 2857, 1433, 510, 293, 264, 12771, 9003, 300, 1433, 13, 400, 797, 11, 411, 321, 848, 11, 291, 51020], "temperature": 0.0, "avg_logprob": -0.26554217283753145, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.00353676313534379}, {"id": 2148, "seek": 633068, "start": 6343.8, "end": 6348.52, "text": " have to be again, looking at the DDIM equation versus the DDPM equation. You", "tokens": [51020, 362, 281, 312, 797, 11, 1237, 412, 264, 413, 3085, 44, 5367, 5717, 264, 413, 11373, 44, 5367, 13, 509, 51256], "temperature": 0.0, "avg_logprob": -0.26554217283753145, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.00353676313534379}, {"id": 2149, "seek": 633068, "start": 6348.52, "end": 6353.52, "text": " have to be careful of the alphas here are referring to alpha bars in the DDPM", "tokens": [51256, 362, 281, 312, 5026, 295, 264, 419, 7485, 510, 366, 13761, 281, 8961, 10228, 294, 264, 413, 11373, 44, 51506], "temperature": 0.0, "avg_logprob": -0.26554217283753145, "compression_ratio": 1.6091370558375635, "no_speech_prob": 0.00353676313534379}, {"id": 2150, "seek": 635352, "start": 6353.6, "end": 6362.320000000001, "text": " equation. So that's the other caveat. So yeah. And you have this sigma t set to", "tokens": [50368, 5367, 13, 407, 300, 311, 264, 661, 43012, 13, 407, 1338, 13, 400, 291, 362, 341, 12771, 256, 992, 281, 50804], "temperature": 0.0, "avg_logprob": -0.2874657415574597, "compression_ratio": 1.369942196531792, "no_speech_prob": 0.11753830313682556}, {"id": 2151, "seek": 635352, "start": 6362.320000000001, "end": 6368.76, "text": " this particular value will give you back DDPM. So sometimes instead they will", "tokens": [50804, 341, 1729, 2158, 486, 976, 291, 646, 413, 11373, 44, 13, 407, 2171, 2602, 436, 486, 51126], "temperature": 0.0, "avg_logprob": -0.2874657415574597, "compression_ratio": 1.369942196531792, "no_speech_prob": 0.11753830313682556}, {"id": 2152, "seek": 635352, "start": 6368.76, "end": 6379.68, "text": " write basically, Jeremy mentioned this sort of, I guess, eta, which is equal to", "tokens": [51126, 2464, 1936, 11, 17809, 2835, 341, 1333, 295, 11, 286, 2041, 11, 32415, 11, 597, 307, 2681, 281, 51672], "temperature": 0.0, "avg_logprob": -0.2874657415574597, "compression_ratio": 1.369942196531792, "no_speech_prob": 0.11753830313682556}, {"id": 2153, "seek": 637968, "start": 6379.68, "end": 6387.96, "text": " basically, yeah. So it's just basically, sigma is equal to eta times this", "tokens": [50364, 1936, 11, 1338, 13, 407, 309, 311, 445, 1936, 11, 12771, 307, 2681, 281, 32415, 1413, 341, 50778], "temperature": 0.0, "avg_logprob": -0.3550258435701069, "compression_ratio": 1.5786802030456852, "no_speech_prob": 0.01427959743887186}, {"id": 2154, "seek": 637968, "start": 6388.08, "end": 6396.08, "text": " coefficient. So, oops, so sorry, let me just go back. And so, in reality, so", "tokens": [50784, 17619, 13, 407, 11, 34166, 11, 370, 2597, 11, 718, 385, 445, 352, 646, 13, 400, 370, 11, 294, 4103, 11, 370, 51184], "temperature": 0.0, "avg_logprob": -0.3550258435701069, "compression_ratio": 1.5786802030456852, "no_speech_prob": 0.01427959743887186}, {"id": 2155, "seek": 637968, "start": 6396.08, "end": 6403.88, "text": " basically, yeah, in reality you take, what? Okay. You have an eta here. So it's", "tokens": [51184, 1936, 11, 1338, 11, 294, 4103, 291, 747, 11, 437, 30, 1033, 13, 509, 362, 364, 32415, 510, 13, 407, 309, 311, 51574], "temperature": 0.0, "avg_logprob": -0.3550258435701069, "compression_ratio": 1.5786802030456852, "no_speech_prob": 0.01427959743887186}, {"id": 2156, "seek": 637968, "start": 6403.88, "end": 6408.68, "text": " like, yeah, this is where eta would go. So if it's one, it becomes regular DDPM.", "tokens": [51574, 411, 11, 1338, 11, 341, 307, 689, 32415, 576, 352, 13, 407, 498, 309, 311, 472, 11, 309, 3643, 3890, 413, 11373, 44, 13, 51814], "temperature": 0.0, "avg_logprob": -0.3550258435701069, "compression_ratio": 1.5786802030456852, "no_speech_prob": 0.01427959743887186}, {"id": 2157, "seek": 640868, "start": 6408.68, "end": 6412.280000000001, "text": " And if it's zero, of course, that's a deterministic case. So this is the eta", "tokens": [50364, 400, 498, 309, 311, 4018, 11, 295, 1164, 11, 300, 311, 257, 15957, 3142, 1389, 13, 407, 341, 307, 264, 32415, 50544], "temperature": 0.0, "avg_logprob": -0.2523092567373853, "compression_ratio": 1.6, "no_speech_prob": 0.0002959541161544621}, {"id": 2158, "seek": 640868, "start": 6412.280000000001, "end": 6417.84, "text": " that, you know, all these APIs and in the code that we have, also the code that", "tokens": [50544, 300, 11, 291, 458, 11, 439, 613, 21445, 293, 294, 264, 3089, 300, 321, 362, 11, 611, 264, 3089, 300, 50822], "temperature": 0.0, "avg_logprob": -0.2523092567373853, "compression_ratio": 1.6, "no_speech_prob": 0.0002959541161544621}, {"id": 2159, "seek": 640868, "start": 6417.84, "end": 6424.360000000001, "text": " Jeremy was showing, they have eta equals to one, which they say is corresponding", "tokens": [50822, 17809, 390, 4099, 11, 436, 362, 32415, 6915, 281, 472, 11, 597, 436, 584, 307, 11760, 51148], "temperature": 0.0, "avg_logprob": -0.2523092567373853, "compression_ratio": 1.6, "no_speech_prob": 0.0002959541161544621}, {"id": 2160, "seek": 640868, "start": 6424.360000000001, "end": 6431.76, "text": " to regular DDPM. This is actually where the eta would go in the equation. So", "tokens": [51148, 281, 3890, 413, 11373, 44, 13, 639, 307, 767, 689, 264, 32415, 576, 352, 294, 264, 5367, 13, 407, 51518], "temperature": 0.0, "avg_logprob": -0.2523092567373853, "compression_ratio": 1.6, "no_speech_prob": 0.0002959541161544621}, {"id": 2161, "seek": 640868, "start": 6431.76, "end": 6436.64, "text": " finally, it's like, yeah, you could pass in sigma, right? Like if you weren't", "tokens": [51518, 2721, 11, 309, 311, 411, 11, 1338, 11, 291, 727, 1320, 294, 12771, 11, 558, 30, 1743, 498, 291, 4999, 380, 51762], "temperature": 0.0, "avg_logprob": -0.2523092567373853, "compression_ratio": 1.6, "no_speech_prob": 0.0002959541161544621}, {"id": 2162, "seek": 643664, "start": 6436.64, "end": 6439.200000000001, "text": " trying to match it in cleanest paper, you could just, oh, well, we have this", "tokens": [50364, 1382, 281, 2995, 309, 294, 2541, 377, 3035, 11, 291, 727, 445, 11, 1954, 11, 731, 11, 321, 362, 341, 50492], "temperature": 0.0, "avg_logprob": -0.3031739378287122, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.08386311680078506}, {"id": 2163, "seek": 643664, "start": 6439.200000000001, "end": 6442.08, "text": " parameter sigma that controls the amount of noise. So that's just taken, yeah,", "tokens": [50492, 13075, 12771, 300, 9003, 264, 2372, 295, 5658, 13, 407, 300, 311, 445, 2726, 11, 1338, 11, 50636], "temperature": 0.0, "avg_logprob": -0.3031739378287122, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.08386311680078506}, {"id": 2164, "seek": 643664, "start": 6442.12, "end": 6446.160000000001, "text": " big mo scale as an argument. But for convenience, they said, let's create this", "tokens": [50638, 955, 705, 4373, 382, 364, 6770, 13, 583, 337, 19283, 11, 436, 848, 11, 718, 311, 1884, 341, 50840], "temperature": 0.0, "avg_logprob": -0.3031739378287122, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.08386311680078506}, {"id": 2165, "seek": 643664, "start": 6446.160000000001, "end": 6451.56, "text": " new thing, eta, where zero means sigma is equal to zero, which if you look at the", "tokens": [50840, 777, 551, 11, 32415, 11, 689, 4018, 1355, 12771, 307, 2681, 281, 4018, 11, 597, 498, 291, 574, 412, 264, 51110], "temperature": 0.0, "avg_logprob": -0.3031739378287122, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.08386311680078506}, {"id": 2166, "seek": 643664, "start": 6451.56, "end": 6457.4400000000005, "text": " equation, that works. One means we match the DDP, the amount of noise that's in", "tokens": [51110, 5367, 11, 300, 1985, 13, 1485, 1355, 321, 2995, 264, 413, 11373, 11, 264, 2372, 295, 5658, 300, 311, 294, 51404], "temperature": 0.0, "avg_logprob": -0.3031739378287122, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.08386311680078506}, {"id": 2167, "seek": 643664, "start": 6457.4400000000005, "end": 6461.240000000001, "text": " the like vanilla DDPM. And so then that gives you like a nice slice. You could", "tokens": [51404, 264, 411, 17528, 413, 11373, 44, 13, 400, 370, 550, 300, 2709, 291, 411, 257, 1481, 13153, 13, 509, 727, 51594], "temperature": 0.0, "avg_logprob": -0.3031739378287122, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.08386311680078506}, {"id": 2168, "seek": 643664, "start": 6461.240000000001, "end": 6466.08, "text": " say eta equals two or eight equals 0.7 or whatever. But it's, it's like got a", "tokens": [51594, 584, 32415, 6915, 732, 420, 3180, 6915, 1958, 13, 22, 420, 2035, 13, 583, 309, 311, 11, 309, 311, 411, 658, 257, 51836], "temperature": 0.0, "avg_logprob": -0.3031739378287122, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.08386311680078506}, {"id": 2169, "seek": 646608, "start": 6466.08, "end": 6470.12, "text": " meaningful unit of one equals the same as this previous reference work.", "tokens": [50364, 10995, 4985, 295, 472, 6915, 264, 912, 382, 341, 3894, 6408, 589, 13, 50566], "temperature": 0.0, "avg_logprob": -0.2967868718233975, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.00781413447111845}, {"id": 2170, "seek": 646608, "start": 6470.48, "end": 6476.2, "text": " Well, it's also convenient because it's sigma t, which is to say different time", "tokens": [50584, 1042, 11, 309, 311, 611, 10851, 570, 309, 311, 12771, 256, 11, 597, 307, 281, 584, 819, 565, 50870], "temperature": 0.0, "avg_logprob": -0.2967868718233975, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.00781413447111845}, {"id": 2171, "seek": 646608, "start": 6476.2, "end": 6481.32, "text": " steps, unless you choose eta equals zero, which case it doesn't matter. Different", "tokens": [50870, 4439, 11, 5969, 291, 2826, 32415, 6915, 4018, 11, 597, 1389, 309, 1177, 380, 1871, 13, 20825, 51126], "temperature": 0.0, "avg_logprob": -0.2967868718233975, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.00781413447111845}, {"id": 2172, "seek": 646608, "start": 6481.32, "end": 6486.68, "text": " time steps probably want different amounts of noise. And so here's, yeah,", "tokens": [51126, 565, 4439, 1391, 528, 819, 11663, 295, 5658, 13, 400, 370, 510, 311, 11, 1338, 11, 51394], "temperature": 0.0, "avg_logprob": -0.2967868718233975, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.00781413447111845}, {"id": 2173, "seek": 646608, "start": 6486.8, "end": 6490.96, "text": " here's a reasonable way of, of scaling that noise.", "tokens": [51400, 510, 311, 257, 10585, 636, 295, 11, 295, 21589, 300, 5658, 13, 51608], "temperature": 0.0, "avg_logprob": -0.2967868718233975, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.00781413447111845}, {"id": 2174, "seek": 649096, "start": 6491.4800000000005, "end": 6496.44, "text": " Then the last thing of importance, which is of course, one of the reasons that we", "tokens": [50390, 1396, 264, 1036, 551, 295, 7379, 11, 597, 307, 295, 1164, 11, 472, 295, 264, 4112, 300, 321, 50638], "temperature": 0.0, "avg_logprob": -0.37652508624188313, "compression_ratio": 1.5707070707070707, "no_speech_prob": 0.00036255898885428905}, {"id": 2175, "seek": 649096, "start": 6496.44, "end": 6501.4800000000005, "text": " were exploring this as the first place is to be able to do this sort of rapid", "tokens": [50638, 645, 12736, 341, 382, 264, 700, 1081, 307, 281, 312, 1075, 281, 360, 341, 1333, 295, 7558, 50890], "temperature": 0.0, "avg_logprob": -0.37652508624188313, "compression_ratio": 1.5707070707070707, "no_speech_prob": 0.00036255898885428905}, {"id": 2176, "seek": 649096, "start": 6501.56, "end": 6512.08, "text": " sampling. So the basic idea here is that you can define a similar distribution", "tokens": [50894, 21179, 13, 407, 264, 3875, 1558, 510, 307, 300, 291, 393, 6964, 257, 2531, 7316, 51420], "temperature": 0.0, "avg_logprob": -0.37652508624188313, "compression_ratio": 1.5707070707070707, "no_speech_prob": 0.00036255898885428905}, {"id": 2177, "seek": 649096, "start": 6512.84, "end": 6518.72, "text": " where again, the math works out similarly, where now you have, let's say", "tokens": [51458, 689, 797, 11, 264, 5221, 1985, 484, 14138, 11, 689, 586, 291, 362, 11, 718, 311, 584, 51752], "temperature": 0.0, "avg_logprob": -0.37652508624188313, "compression_ratio": 1.5707070707070707, "no_speech_prob": 0.00036255898885428905}, {"id": 2178, "seek": 651872, "start": 6518.72, "end": 6524.64, "text": " you have some subset of diffusion steps. So in this case, it uses tau variable.", "tokens": [50364, 291, 362, 512, 25993, 295, 25242, 4439, 13, 407, 294, 341, 1389, 11, 309, 4960, 17842, 7006, 13, 50660], "temperature": 0.0, "avg_logprob": -0.2798302643490534, "compression_ratio": 1.888, "no_speech_prob": 0.012051818892359734}, {"id": 2179, "seek": 651872, "start": 6524.8, "end": 6529.68, "text": " So for example, if, if you have, yeah, you say, let's say a subset of diffusion", "tokens": [50668, 407, 337, 1365, 11, 498, 11, 498, 291, 362, 11, 1338, 11, 291, 584, 11, 718, 311, 584, 257, 25993, 295, 25242, 50912], "temperature": 0.0, "avg_logprob": -0.2798302643490534, "compression_ratio": 1.888, "no_speech_prob": 0.012051818892359734}, {"id": 2180, "seek": 651872, "start": 6529.68, "end": 6534.16, "text": " steps. So if it's like 10 diffusion steps, then tau one would just be zero.", "tokens": [50912, 4439, 13, 407, 498, 309, 311, 411, 1266, 25242, 4439, 11, 550, 17842, 472, 576, 445, 312, 4018, 13, 51136], "temperature": 0.0, "avg_logprob": -0.2798302643490534, "compression_ratio": 1.888, "no_speech_prob": 0.012051818892359734}, {"id": 2181, "seek": 651872, "start": 6534.16, "end": 6538.6, "text": " Then tau two would be 10. You know, you just keep going all the way up to say", "tokens": [51136, 1396, 17842, 732, 576, 312, 1266, 13, 509, 458, 11, 291, 445, 1066, 516, 439, 264, 636, 493, 281, 584, 51358], "temperature": 0.0, "avg_logprob": -0.2798302643490534, "compression_ratio": 1.888, "no_speech_prob": 0.012051818892359734}, {"id": 2182, "seek": 651872, "start": 6538.6, "end": 6542.76, "text": " a thousand, but you've only got the, sorry, tau two would be a hundred. And", "tokens": [51358, 257, 4714, 11, 457, 291, 600, 787, 658, 264, 11, 2597, 11, 17842, 732, 576, 312, 257, 3262, 13, 400, 51566], "temperature": 0.0, "avg_logprob": -0.2798302643490534, "compression_ratio": 1.888, "no_speech_prob": 0.012051818892359734}, {"id": 2183, "seek": 651872, "start": 6542.76, "end": 6546.320000000001, "text": " then you go all the way up to a thousand. And so you'd get, you know, these, you'd", "tokens": [51566, 550, 291, 352, 439, 264, 636, 493, 281, 257, 4714, 13, 400, 370, 291, 1116, 483, 11, 291, 458, 11, 613, 11, 291, 1116, 51744], "temperature": 0.0, "avg_logprob": -0.2798302643490534, "compression_ratio": 1.888, "no_speech_prob": 0.012051818892359734}, {"id": 2184, "seek": 654632, "start": 6546.32, "end": 6550.36, "text": " get 10 diffusion steps. So that's what they're referring to when they have this,", "tokens": [50364, 483, 1266, 25242, 4439, 13, 407, 300, 311, 437, 436, 434, 13761, 281, 562, 436, 362, 341, 11, 50566], "temperature": 0.0, "avg_logprob": -0.2914019823074341, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0004954439937137067}, {"id": 2185, "seek": 654632, "start": 6550.679999999999, "end": 6558.24, "text": " I guess, this tau, tau variable here. And so you can do these sorts of similar", "tokens": [50582, 286, 2041, 11, 341, 17842, 11, 17842, 7006, 510, 13, 400, 370, 291, 393, 360, 613, 7527, 295, 2531, 50960], "temperature": 0.0, "avg_logprob": -0.2914019823074341, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0004954439937137067}, {"id": 2186, "seek": 654632, "start": 6558.24, "end": 6565.5199999999995, "text": " equation and similar derivation to show that this, this distribution here, again,", "tokens": [50960, 5367, 293, 2531, 10151, 399, 281, 855, 300, 341, 11, 341, 7316, 510, 11, 797, 11, 51324], "temperature": 0.0, "avg_logprob": -0.2914019823074341, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0004954439937137067}, {"id": 2187, "seek": 654632, "start": 6567.2, "end": 6571.44, "text": " meets the sort of objective that you use for training. And you can now use this", "tokens": [51408, 13961, 264, 1333, 295, 10024, 300, 291, 764, 337, 3097, 13, 400, 291, 393, 586, 764, 341, 51620], "temperature": 0.0, "avg_logprob": -0.2914019823074341, "compression_ratio": 1.5970149253731343, "no_speech_prob": 0.0004954439937137067}, {"id": 2188, "seek": 657144, "start": 6571.48, "end": 6577.4, "text": " for a faster sampling where basically all you have to do is you have to just select", "tokens": [50366, 337, 257, 4663, 21179, 689, 1936, 439, 291, 362, 281, 360, 307, 291, 362, 281, 445, 3048, 50662], "temperature": 0.0, "avg_logprob": -0.2750325494883012, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.03619510680437088}, {"id": 2189, "seek": 657144, "start": 6577.4, "end": 6583.04, "text": " the appropriate alpha bar. And sorry, I, this one I've written out. So this one,", "tokens": [50662, 264, 6854, 8961, 2159, 13, 400, 2597, 11, 286, 11, 341, 472, 286, 600, 3720, 484, 13, 407, 341, 472, 11, 50944], "temperature": 0.0, "avg_logprob": -0.2750325494883012, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.03619510680437088}, {"id": 2190, "seek": 657144, "start": 6583.12, "end": 6586.5199999999995, "text": " actually the alpha bar is, you know, the regular alpha bar that we've talked about,", "tokens": [50948, 767, 264, 8961, 2159, 307, 11, 291, 458, 11, 264, 3890, 8961, 2159, 300, 321, 600, 2825, 466, 11, 51118], "temperature": 0.0, "avg_logprob": -0.2750325494883012, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.03619510680437088}, {"id": 2191, "seek": 657144, "start": 6586.759999999999, "end": 6591.24, "text": " but basically, sorry, it's a little bit confusing switching between different", "tokens": [51130, 457, 1936, 11, 2597, 11, 309, 311, 257, 707, 857, 13181, 16493, 1296, 819, 51354], "temperature": 0.0, "avg_logprob": -0.2750325494883012, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.03619510680437088}, {"id": 2192, "seek": 657144, "start": 6592.28, "end": 6596.16, "text": " notations, but basically you have this distribution and then you just have to", "tokens": [51406, 406, 763, 11, 457, 1936, 291, 362, 341, 7316, 293, 550, 291, 445, 362, 281, 51600], "temperature": 0.0, "avg_logprob": -0.2750325494883012, "compression_ratio": 1.7264957264957266, "no_speech_prob": 0.03619510680437088}, {"id": 2193, "seek": 659616, "start": 6596.16, "end": 6604.04, "text": " select the appropriate alpha bars. And it follows the math the same in terms of you", "tokens": [50364, 3048, 264, 6854, 8961, 10228, 13, 400, 309, 10002, 264, 5221, 264, 912, 294, 2115, 295, 291, 50758], "temperature": 0.0, "avg_logprob": -0.26526368048883253, "compression_ratio": 1.5732484076433122, "no_speech_prob": 0.0008827674901112914}, {"id": 2194, "seek": 659616, "start": 6604.04, "end": 6612.24, "text": " have appropriate sampling process. So yeah, and I guess that's, it makes it a lot", "tokens": [50758, 362, 6854, 21179, 1399, 13, 407, 1338, 11, 293, 286, 2041, 300, 311, 11, 309, 1669, 309, 257, 688, 51168], "temperature": 0.0, "avg_logprob": -0.26526368048883253, "compression_ratio": 1.5732484076433122, "no_speech_prob": 0.0008827674901112914}, {"id": 2195, "seek": 659616, "start": 6612.24, "end": 6622.76, "text": " simpler in terms of doing this, I guess, accelerated sampling. Yeah, I guess with", "tokens": [51168, 18587, 294, 2115, 295, 884, 341, 11, 286, 2041, 11, 29763, 21179, 13, 865, 11, 286, 2041, 365, 51694], "temperature": 0.0, "avg_logprob": -0.26526368048883253, "compression_ratio": 1.5732484076433122, "no_speech_prob": 0.0008827674901112914}, {"id": 2196, "seek": 662276, "start": 6622.84, "end": 6626.92, "text": " any other note, maybe other comments that maybe you guys had, or was this?", "tokens": [50368, 604, 661, 3637, 11, 1310, 661, 3053, 300, 1310, 291, 1074, 632, 11, 420, 390, 341, 30, 50572], "temperature": 0.0, "avg_logprob": -0.31279943102882024, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0018382980488240719}, {"id": 2197, "seek": 662276, "start": 6626.96, "end": 6638.360000000001, "text": " Well, the key for me is that in this equation, we just have one, we only need", "tokens": [50574, 1042, 11, 264, 2141, 337, 385, 307, 300, 294, 341, 5367, 11, 321, 445, 362, 472, 11, 321, 787, 643, 51144], "temperature": 0.0, "avg_logprob": -0.31279943102882024, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0018382980488240719}, {"id": 2198, "seek": 662276, "start": 6638.360000000001, "end": 6642.72, "text": " one parameter, which is the alpha bar or alpha, depending on which notation is,", "tokens": [51144, 472, 13075, 11, 597, 307, 264, 8961, 2159, 420, 8961, 11, 5413, 322, 597, 24657, 307, 11, 51362], "temperature": 0.0, "avg_logprob": -0.31279943102882024, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0018382980488240719}, {"id": 2199, "seek": 662276, "start": 6642.96, "end": 6650.92, "text": " and everything else is calculated from that. And so we don't have the, what DDPM", "tokens": [51374, 293, 1203, 1646, 307, 15598, 490, 300, 13, 400, 370, 321, 500, 380, 362, 264, 11, 437, 413, 11373, 44, 51772], "temperature": 0.0, "avg_logprob": -0.31279943102882024, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0018382980488240719}, {"id": 2200, "seek": 665092, "start": 6650.96, "end": 6657.8, "text": " calls the alpha or beta anymore. And that's more convenient for doing this kind of", "tokens": [50366, 5498, 264, 8961, 420, 9861, 3602, 13, 400, 300, 311, 544, 10851, 337, 884, 341, 733, 295, 50708], "temperature": 0.0, "avg_logprob": -0.2629193623860677, "compression_ratio": 1.705, "no_speech_prob": 7.484328671125695e-05}, {"id": 2201, "seek": 665092, "start": 6658.64, "end": 6666.4, "text": " smaller number of steps because we can just jump straight from time step to alpha bar.", "tokens": [50750, 4356, 1230, 295, 4439, 570, 321, 393, 445, 3012, 2997, 490, 565, 1823, 281, 8961, 2159, 13, 51138], "temperature": 0.0, "avg_logprob": -0.2629193623860677, "compression_ratio": 1.705, "no_speech_prob": 7.484328671125695e-05}, {"id": 2202, "seek": 665092, "start": 6667.32, "end": 6673.4800000000005, "text": " And we can also then, it's particularly convenient with the cosine schedule because", "tokens": [51184, 400, 321, 393, 611, 550, 11, 309, 311, 4098, 10851, 365, 264, 23565, 7567, 570, 51492], "temperature": 0.0, "avg_logprob": -0.2629193623860677, "compression_ratio": 1.705, "no_speech_prob": 7.484328671125695e-05}, {"id": 2203, "seek": 665092, "start": 6673.4800000000005, "end": 6678.24, "text": " you can calculate the inverse of the cosine schedule function, which means you can also", "tokens": [51492, 291, 393, 8873, 264, 17340, 295, 264, 23565, 7567, 2445, 11, 597, 1355, 291, 393, 611, 51730], "temperature": 0.0, "avg_logprob": -0.2629193623860677, "compression_ratio": 1.705, "no_speech_prob": 7.484328671125695e-05}, {"id": 2204, "seek": 667824, "start": 6678.28, "end": 6682.92, "text": " go from an alpha bar to a T. So it's really easy to like say like, Oh, what would alpha", "tokens": [50366, 352, 490, 364, 8961, 2159, 281, 257, 314, 13, 407, 309, 311, 534, 1858, 281, 411, 584, 411, 11, 876, 11, 437, 576, 8961, 50598], "temperature": 0.0, "avg_logprob": -0.2655509312947591, "compression_ratio": 1.5066666666666666, "no_speech_prob": 0.00048782225348986685}, {"id": 2205, "seek": 667824, "start": 6682.92, "end": 6689.12, "text": " bar be 10 time steps previously to this one? You know, it's just, you could just call a", "tokens": [50598, 2159, 312, 1266, 565, 4439, 8046, 281, 341, 472, 30, 509, 458, 11, 309, 311, 445, 11, 291, 727, 445, 818, 257, 50908], "temperature": 0.0, "avg_logprob": -0.2655509312947591, "compression_ratio": 1.5066666666666666, "no_speech_prob": 0.00048782225348986685}, {"id": 2206, "seek": 667824, "start": 6689.12, "end": 6693.639999999999, "text": " function. We don't need, yeah, we don't need anything else. And so actually the", "tokens": [50908, 2445, 13, 492, 500, 380, 643, 11, 1338, 11, 321, 500, 380, 643, 1340, 1646, 13, 400, 370, 767, 264, 51134], "temperature": 0.0, "avg_logprob": -0.2655509312947591, "compression_ratio": 1.5066666666666666, "no_speech_prob": 0.00048782225348986685}, {"id": 2207, "seek": 667824, "start": 6693.639999999999, "end": 6703.84, "text": " original cosine schedule paper has to fuss around with various like kind of epsilon", "tokens": [51134, 3380, 23565, 7567, 3035, 575, 281, 34792, 926, 365, 3683, 411, 733, 295, 17889, 51644], "temperature": 0.0, "avg_logprob": -0.2655509312947591, "compression_ratio": 1.5066666666666666, "no_speech_prob": 0.00048782225348986685}, {"id": 2208, "seek": 670384, "start": 6703.84, "end": 6709.400000000001, "text": " style, small numbers that they add to things to avoid getting weird numerical problems.", "tokens": [50364, 3758, 11, 1359, 3547, 300, 436, 909, 281, 721, 281, 5042, 1242, 3657, 29054, 2740, 13, 50642], "temperature": 0.0, "avg_logprob": -0.27044957617054816, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.02404654026031494}, {"id": 2209, "seek": 670384, "start": 6709.6, "end": 6716.96, "text": " And so, yeah, when we only deal with alpha bar, all that stuff also goes away. So, yeah.", "tokens": [50652, 400, 370, 11, 1338, 11, 562, 321, 787, 2028, 365, 8961, 2159, 11, 439, 300, 1507, 611, 1709, 1314, 13, 407, 11, 1338, 13, 51020], "temperature": 0.0, "avg_logprob": -0.27044957617054816, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.02404654026031494}, {"id": 2210, "seek": 670384, "start": 6716.96, "end": 6725.0, "text": " So looking, if you're looking at the DDIM code, you know, it's simpler code with less", "tokens": [51020, 407, 1237, 11, 498, 291, 434, 1237, 412, 264, 413, 3085, 44, 3089, 11, 291, 458, 11, 309, 311, 18587, 3089, 365, 1570, 51422], "temperature": 0.0, "avg_logprob": -0.27044957617054816, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.02404654026031494}, {"id": 2211, "seek": 670384, "start": 6725.0, "end": 6731.68, "text": " parameters than our DDPM code. And of course it's dramatically faster and it's also", "tokens": [51422, 9834, 813, 527, 413, 11373, 44, 3089, 13, 400, 295, 1164, 309, 311, 17548, 4663, 293, 309, 311, 611, 51756], "temperature": 0.0, "avg_logprob": -0.27044957617054816, "compression_ratio": 1.5727272727272728, "no_speech_prob": 0.02404654026031494}, {"id": 2212, "seek": 673168, "start": 6731.72, "end": 6733.96, "text": " more flexible because we've got this eta thing we can play with.", "tokens": [50366, 544, 11358, 570, 321, 600, 658, 341, 32415, 551, 321, 393, 862, 365, 13, 50478], "temperature": 0.0, "avg_logprob": -0.23837382217933392, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.015422502532601357}, {"id": 2213, "seek": 673168, "start": 6735.72, "end": 6740.8, "text": " Yes. Yeah. And that's the other thing. It's like this idea of like, yeah, controlling", "tokens": [50566, 1079, 13, 865, 13, 400, 300, 311, 264, 661, 551, 13, 467, 311, 411, 341, 1558, 295, 411, 11, 1338, 11, 14905, 50820], "temperature": 0.0, "avg_logprob": -0.23837382217933392, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.015422502532601357}, {"id": 2214, "seek": 673168, "start": 6740.84, "end": 6745.4400000000005, "text": " stochasticity. I think that's something that's interesting to explore and we've been", "tokens": [50822, 342, 8997, 2750, 507, 13, 286, 519, 300, 311, 746, 300, 311, 1880, 281, 6839, 293, 321, 600, 668, 51052], "temperature": 0.0, "avg_logprob": -0.23837382217933392, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.015422502532601357}, {"id": 2215, "seek": 673168, "start": 6745.4400000000005, "end": 6749.200000000001, "text": " exploring that a bit now and I think we'll continue to explore that in terms of", "tokens": [51052, 12736, 300, 257, 857, 586, 293, 286, 519, 321, 603, 2354, 281, 6839, 300, 294, 2115, 295, 51240], "temperature": 0.0, "avg_logprob": -0.23837382217933392, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.015422502532601357}, {"id": 2216, "seek": 673168, "start": 6749.4400000000005, "end": 6752.200000000001, "text": " deterministic versus stochasticity. So, yeah.", "tokens": [51252, 15957, 3142, 5717, 342, 8997, 2750, 507, 13, 407, 11, 1338, 13, 51390], "temperature": 0.0, "avg_logprob": -0.23837382217933392, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.015422502532601357}, {"id": 2217, "seek": 673168, "start": 6752.240000000001, "end": 6756.88, "text": " Also, it's worth talking about this, the sigma in that middle equation you've got", "tokens": [51392, 2743, 11, 309, 311, 3163, 1417, 466, 341, 11, 264, 12771, 294, 300, 2808, 5367, 291, 600, 658, 51624], "temperature": 0.0, "avg_logprob": -0.23837382217933392, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.015422502532601357}, {"id": 2218, "seek": 675688, "start": 6756.88, "end": 6761.96, "text": " there. So you've got the sigma t eta t adding the random noise. And intuitively it", "tokens": [50364, 456, 13, 407, 291, 600, 658, 264, 12771, 256, 32415, 256, 5127, 264, 4974, 5658, 13, 400, 46506, 309, 50618], "temperature": 0.0, "avg_logprob": -0.27897243176476433, "compression_ratio": 1.8425531914893618, "no_speech_prob": 0.04144718497991562}, {"id": 2219, "seek": 675688, "start": 6761.96, "end": 6766.8, "text": " makes sense that if you're adding random noise there, you would need to have less.", "tokens": [50618, 1669, 2020, 300, 498, 291, 434, 5127, 4974, 5658, 456, 11, 291, 576, 643, 281, 362, 1570, 13, 50860], "temperature": 0.0, "avg_logprob": -0.27897243176476433, "compression_ratio": 1.8425531914893618, "no_speech_prob": 0.04144718497991562}, {"id": 2220, "seek": 675688, "start": 6767.32, "end": 6771.08, "text": " You want to move less back towards Xt, which is your noisy image.", "tokens": [50886, 509, 528, 281, 1286, 1570, 646, 3030, 1783, 83, 11, 597, 307, 428, 24518, 3256, 13, 51074], "temperature": 0.0, "avg_logprob": -0.27897243176476433, "compression_ratio": 1.8425531914893618, "no_speech_prob": 0.04144718497991562}, {"id": 2221, "seek": 675688, "start": 6771.72, "end": 6772.76, "text": " So that's why.", "tokens": [51106, 407, 300, 311, 983, 13, 51158], "temperature": 0.0, "avg_logprob": -0.27897243176476433, "compression_ratio": 1.8425531914893618, "no_speech_prob": 0.04144718497991562}, {"id": 2222, "seek": 675688, "start": 6772.84, "end": 6778.68, "text": " And, you know, you've got the 1 minus alpha t minus 1 minus sigma squared.", "tokens": [51162, 400, 11, 291, 458, 11, 291, 600, 658, 264, 502, 3175, 8961, 256, 3175, 502, 3175, 12771, 8889, 13, 51454], "temperature": 0.0, "avg_logprob": -0.27897243176476433, "compression_ratio": 1.8425531914893618, "no_speech_prob": 0.04144718497991562}, {"id": 2223, "seek": 675688, "start": 6779.32, "end": 6780.72, "text": " And then you're taking the square root of that.", "tokens": [51486, 400, 550, 291, 434, 1940, 264, 3732, 5593, 295, 300, 13, 51556], "temperature": 0.0, "avg_logprob": -0.27897243176476433, "compression_ratio": 1.8425531914893618, "no_speech_prob": 0.04144718497991562}, {"id": 2224, "seek": 675688, "start": 6780.76, "end": 6784.16, "text": " So basically that's just sigma, the square root of the squared.", "tokens": [51558, 407, 1936, 300, 311, 445, 12771, 11, 264, 3732, 5593, 295, 264, 8889, 13, 51728], "temperature": 0.0, "avg_logprob": -0.27897243176476433, "compression_ratio": 1.8425531914893618, "no_speech_prob": 0.04144718497991562}, {"id": 2225, "seek": 678416, "start": 6784.68, "end": 6791.2, "text": " So you're subtracting sigma t from the direction pointing to Xt and adding it to the", "tokens": [50390, 407, 291, 434, 16390, 278, 12771, 256, 490, 264, 3513, 12166, 281, 1783, 83, 293, 5127, 309, 281, 264, 50716], "temperature": 0.0, "avg_logprob": -0.30546281451270696, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.0003101437177974731}, {"id": 2226, "seek": 678416, "start": 6791.2, "end": 6793.5199999999995, "text": " random noise or vice versa.", "tokens": [50716, 4974, 5658, 420, 11964, 25650, 13, 50832], "temperature": 0.0, "avg_logprob": -0.30546281451270696, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.0003101437177974731}, {"id": 2227, "seek": 678416, "start": 6793.5599999999995, "end": 6800.36, "text": " So, yes, you know, everything's there for a reason, you know.", "tokens": [50834, 407, 11, 2086, 11, 291, 458, 11, 1203, 311, 456, 337, 257, 1778, 11, 291, 458, 13, 51174], "temperature": 0.0, "avg_logprob": -0.30546281451270696, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.0003101437177974731}, {"id": 2228, "seek": 678416, "start": 6800.76, "end": 6801.24, "text": " Yes.", "tokens": [51194, 1079, 13, 51218], "temperature": 0.0, "avg_logprob": -0.30546281451270696, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.0003101437177974731}, {"id": 2229, "seek": 678416, "start": 6802.16, "end": 6806.76, "text": " And the predicted X0, that entire equation we've derived previously.", "tokens": [51264, 400, 264, 19147, 1783, 15, 11, 300, 2302, 5367, 321, 600, 18949, 8046, 13, 51494], "temperature": 0.0, "avg_logprob": -0.30546281451270696, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.0003101437177974731}, {"id": 2230, "seek": 678416, "start": 6808.76, "end": 6814.12, "text": " And it remains the same in pretty much any diffusion model methodology.", "tokens": [51594, 400, 309, 7023, 264, 912, 294, 1238, 709, 604, 25242, 2316, 24850, 13, 51862], "temperature": 0.0, "avg_logprob": -0.30546281451270696, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.0003101437177974731}, {"id": 2231, "seek": 681416, "start": 6814.28, "end": 6817.48, "text": " Well, as long as you're using, we'll be talking about actually some places where it's", "tokens": [50370, 1042, 11, 382, 938, 382, 291, 434, 1228, 11, 321, 603, 312, 1417, 466, 767, 512, 3190, 689, 309, 311, 50530], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2232, "seek": 681416, "start": 6817.48, "end": 6819.32, "text": " going to change probably next week.", "tokens": [50530, 516, 281, 1319, 1391, 958, 1243, 13, 50622], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2233, "seek": 681416, "start": 6819.639999999999, "end": 6822.08, "text": " Yeah, I guess there's another thing where you're predicting noise.", "tokens": [50638, 865, 11, 286, 2041, 456, 311, 1071, 551, 689, 291, 434, 32884, 5658, 13, 50760], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2234, "seek": 681416, "start": 6822.24, "end": 6822.5199999999995, "text": " Yes.", "tokens": [50768, 1079, 13, 50782], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2235, "seek": 681416, "start": 6823.5199999999995, "end": 6824.0, "text": " Yes.", "tokens": [50832, 1079, 13, 50856], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2236, "seek": 681416, "start": 6824.16, "end": 6824.48, "text": " Yes.", "tokens": [50864, 1079, 13, 50880], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2237, "seek": 681416, "start": 6824.76, "end": 6826.44, "text": " If you're predicting the noise, yes, there'll be.", "tokens": [50894, 759, 291, 434, 32884, 264, 5658, 11, 2086, 11, 456, 603, 312, 13, 50978], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2238, "seek": 681416, "start": 6826.599999999999, "end": 6826.84, "text": " Okay.", "tokens": [50986, 1033, 13, 50998], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2239, "seek": 681416, "start": 6827.92, "end": 6828.2, "text": " Yeah.", "tokens": [51052, 865, 13, 51066], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2240, "seek": 681416, "start": 6828.8, "end": 6837.5199999999995, "text": " So, so I think, you know, we will, we'll probably, yeah, let's wrap it up here so that", "tokens": [51096, 407, 11, 370, 286, 519, 11, 291, 458, 11, 321, 486, 11, 321, 603, 1391, 11, 1338, 11, 718, 311, 7019, 309, 493, 510, 370, 300, 51532], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2241, "seek": 681416, "start": 6837.5199999999995, "end": 6842.48, "text": " we leave ourselves plenty of time to cover the kind of new research directions next lesson", "tokens": [51532, 321, 1856, 4175, 7140, 295, 565, 281, 2060, 264, 733, 295, 777, 2132, 11095, 958, 6898, 51780], "temperature": 0.0, "avg_logprob": -0.36400125943697414, "compression_ratio": 1.7038461538461538, "no_speech_prob": 0.00023048474395181984}, {"id": 2242, "seek": 684248, "start": 6842.959999999999, "end": 6843.719999999999, "text": " in more detail.", "tokens": [50388, 294, 544, 2607, 13, 50426], "temperature": 0.0, "avg_logprob": -0.26721866005345396, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.005218967795372009}, {"id": 2243, "seek": 684248, "start": 6843.719999999999, "end": 6849.44, "text": " But I just want to mention, like in terms of where we're at, just like we hit a kind of", "tokens": [50426, 583, 286, 445, 528, 281, 2152, 11, 411, 294, 2115, 295, 689, 321, 434, 412, 11, 445, 411, 321, 2045, 257, 733, 295, 50712], "temperature": 0.0, "avg_logprob": -0.26721866005345396, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.005218967795372009}, {"id": 2244, "seek": 684248, "start": 6849.44, "end": 6855.28, "text": " like, okay, we can now really predict classes for fashion MNIST a few weeks ago, where I", "tokens": [50712, 411, 11, 1392, 11, 321, 393, 586, 534, 6069, 5359, 337, 6700, 376, 45, 19756, 257, 1326, 3259, 2057, 11, 689, 286, 51004], "temperature": 0.0, "avg_logprob": -0.26721866005345396, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.005218967795372009}, {"id": 2245, "seek": 684248, "start": 6855.28, "end": 6862.719999999999, "text": " think we're there now and like we can do stable diffusion sampling and units, except for the", "tokens": [51004, 519, 321, 434, 456, 586, 293, 411, 321, 393, 360, 8351, 25242, 21179, 293, 6815, 11, 3993, 337, 264, 51376], "temperature": 0.0, "avg_logprob": -0.26721866005345396, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.005218967795372009}, {"id": 2246, "seek": 684248, "start": 6862.719999999999, "end": 6868.32, "text": " unit architecture for unconditional generation now, we basically can do fashion MNIST", "tokens": [51376, 4985, 9482, 337, 47916, 5125, 586, 11, 321, 1936, 393, 360, 6700, 376, 45, 19756, 51656], "temperature": 0.0, "avg_logprob": -0.26721866005345396, "compression_ratio": 1.6130434782608696, "no_speech_prob": 0.005218967795372009}, {"id": 2247, "seek": 686832, "start": 6868.96, "end": 6869.5199999999995, "text": " almost.", "tokens": [50396, 1920, 13, 50424], "temperature": 0.0, "avg_logprob": -0.41599088640355353, "compression_ratio": 1.4610778443113772, "no_speech_prob": 7.599760283483192e-05}, {"id": 2248, "seek": 686832, "start": 6870.16, "end": 6876.96, "text": " So it's unrecognizably different to the real samples and DDIM is the scheduler that the", "tokens": [50456, 407, 309, 311, 517, 13867, 2912, 590, 1188, 819, 281, 264, 957, 10938, 293, 413, 3085, 44, 307, 264, 12000, 260, 300, 264, 50796], "temperature": 0.0, "avg_logprob": -0.41599088640355353, "compression_ratio": 1.4610778443113772, "no_speech_prob": 7.599760283483192e-05}, {"id": 2249, "seek": 686832, "start": 6876.96, "end": 6879.44, "text": " original stable diffusion paper used.", "tokens": [50796, 3380, 8351, 25242, 3035, 1143, 13, 50920], "temperature": 0.0, "avg_logprob": -0.41599088640355353, "compression_ratio": 1.4610778443113772, "no_speech_prob": 7.599760283483192e-05}, {"id": 2250, "seek": 686832, "start": 6881.599999999999, "end": 6891.92, "text": " So, yeah, you know, we're actually about to go beyond stable diffusion for our sampling", "tokens": [51028, 407, 11, 1338, 11, 291, 458, 11, 321, 434, 767, 466, 281, 352, 4399, 8351, 25242, 337, 527, 21179, 51544], "temperature": 0.0, "avg_logprob": -0.41599088640355353, "compression_ratio": 1.4610778443113772, "no_speech_prob": 7.599760283483192e-05}, {"id": 2251, "seek": 686832, "start": 6891.92, "end": 6893.04, "text": " and unit training now.", "tokens": [51544, 293, 4985, 3097, 586, 13, 51600], "temperature": 0.0, "avg_logprob": -0.41599088640355353, "compression_ratio": 1.4610778443113772, "no_speech_prob": 7.599760283483192e-05}, {"id": 2252, "seek": 689304, "start": 6893.36, "end": 6903.44, "text": " So I think we've, yeah, definitely meeting our stretch goals so far and all from scratch.", "tokens": [50380, 407, 286, 519, 321, 600, 11, 1338, 11, 2138, 3440, 527, 5985, 5493, 370, 1400, 293, 439, 490, 8459, 13, 50884], "temperature": 0.0, "avg_logprob": -0.41447647412618, "compression_ratio": 1.433673469387755, "no_speech_prob": 0.03160886839032173}, {"id": 2253, "seek": 689304, "start": 6904.88, "end": 6906.8, "text": " Ruth waits and biases experiment logging.", "tokens": [50956, 23544, 40597, 293, 32152, 5120, 27991, 13, 51052], "temperature": 0.0, "avg_logprob": -0.41447647412618, "compression_ratio": 1.433673469387755, "no_speech_prob": 0.03160886839032173}, {"id": 2254, "seek": 689304, "start": 6910.32, "end": 6915.76, "text": " And you know, if you want it to have fun, there's no reason you couldn't like have a", "tokens": [51228, 400, 291, 458, 11, 498, 291, 528, 309, 281, 362, 1019, 11, 456, 311, 572, 1778, 291, 2809, 380, 411, 362, 257, 51500], "temperature": 0.0, "avg_logprob": -0.41447647412618, "compression_ratio": 1.433673469387755, "no_speech_prob": 0.03160886839032173}, {"id": 2255, "seek": 689304, "start": 6915.76, "end": 6919.68, "text": " little callback that instead logs things into a SQLite database.", "tokens": [51500, 707, 818, 3207, 300, 2602, 20820, 721, 666, 257, 19200, 642, 8149, 13, 51696], "temperature": 0.0, "avg_logprob": -0.41447647412618, "compression_ratio": 1.433673469387755, "no_speech_prob": 0.03160886839032173}, {"id": 2256, "seek": 691968, "start": 6919.76, "end": 6925.280000000001, "text": " And then you could write a little front end to show your experiments, you know, that'd", "tokens": [50368, 400, 550, 291, 727, 2464, 257, 707, 1868, 917, 281, 855, 428, 12050, 11, 291, 458, 11, 300, 1116, 50644], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2257, "seek": 691968, "start": 6925.280000000001, "end": 6925.84, "text": " be fun as well.", "tokens": [50644, 312, 1019, 382, 731, 13, 50672], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2258, "seek": 691968, "start": 6926.88, "end": 6927.360000000001, "text": " Yeah.", "tokens": [50724, 865, 13, 50748], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2259, "seek": 691968, "start": 6927.360000000001, "end": 6930.64, "text": " I mean, you could do also send you a text message when the loss gets good enough.", "tokens": [50748, 286, 914, 11, 291, 727, 360, 611, 2845, 291, 257, 2487, 3636, 562, 264, 4470, 2170, 665, 1547, 13, 50912], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2260, "seek": 691968, "start": 6932.320000000001, "end": 6932.88, "text": " Yeah.", "tokens": [50996, 865, 13, 51024], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2261, "seek": 691968, "start": 6934.4800000000005, "end": 6935.04, "text": " All right.", "tokens": [51104, 1057, 558, 13, 51132], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2262, "seek": 691968, "start": 6935.04, "end": 6936.0, "text": " Well, thanks guys.", "tokens": [51132, 1042, 11, 3231, 1074, 13, 51180], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2263, "seek": 691968, "start": 6936.0, "end": 6936.8, "text": " That was really fun.", "tokens": [51180, 663, 390, 534, 1019, 13, 51220], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2264, "seek": 691968, "start": 6938.08, "end": 6938.8, "text": " Thanks, everybody.", "tokens": [51284, 2561, 11, 2201, 13, 51320], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2265, "seek": 691968, "start": 6939.68, "end": 6940.16, "text": " All right.", "tokens": [51364, 1057, 558, 13, 51388], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2266, "seek": 691968, "start": 6941.04, "end": 6941.6, "text": " Bye.", "tokens": [51432, 4621, 13, 51460], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2267, "seek": 691968, "start": 6941.6, "end": 6942.08, "text": " Okay.", "tokens": [51460, 1033, 13, 51484], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2268, "seek": 691968, "start": 6942.08, "end": 6943.200000000001, "text": " Talk to you later then.", "tokens": [51484, 8780, 281, 291, 1780, 550, 13, 51540], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}, {"id": 2269, "seek": 691968, "start": 6943.200000000001, "end": 6943.76, "text": " Bye.", "tokens": [51540, 4621, 13, 51568], "temperature": 0.0, "avg_logprob": -0.4962189285843461, "compression_ratio": 1.5388349514563107, "no_speech_prob": 0.0025106037501245737}], "language": "en"}