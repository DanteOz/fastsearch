{"text": " Hey everybody, can you see me and hear me okay? Great. Sorry about the delay. YouTube streaming doesn't quite work on Firefox properly. Thanks Google. Alright. I'm not quite sure what we're going to talk about today as usual, but I do have some place to start. Which is in 02. I realize there's one piece I didn't tell you about. Which is in TypeDispatch. If you haven't seen it, there's a very nice walkthrough of TypeDispatch on the forums now. Among Aurora, the basic idea of TypeDispatch is kind of quite well described in the tests. Which is that here is a bunch of functions and they take different things. And underneath, you can see, so we create a TypeDispatch object with that list of functions and then we treat it like a dictionary, passing in some type, and it tells us what function you should call to use that type. As you can see. And then, as well as doing that, more importantly, you can treat it like a function. It's a callable, and you can pass it something. In this case, I'm passing it the normal int. So it's going to go to the numbers.integral version, which would return x plus 1, and we check, yes, it has returned x plus 1. Something that I didn't look at last time, though, was this other cell underneath it. Which is exactly the same thing, but this time these functions take self as well. And we create a TypeDispatch object as usual. We then insert that TypeDispatch object as an attribute of this class, and we're going to call the attribute f. And now we call a.f. And we get back again, 2. Now there's something a bit magic going on here. How did Python know, or how to type dispatch know, that a.f should be passed as self as well as the x? And the answer is, by default, it doesn't. a.f is just a, it's just an attribute of this class. There's nothing particularly to say that it should be passed as self. So how did it do that? And actually, it would be good to do another test, make sure it's getting a real self. So maybe we should like, what if we did something like def m. Actually, I don't know, it would be kind of interesting. Which would be, let's take the bool one, and instead of just return x, why don't we go self.foo equals a. So in that case, we would expect to be able to go a.f false, for example. So that's going to call it with a boolean, which should call this version. So after that, we should find that a.foo is a. Let's run that. And it is, and it worked. So it is correctly binding, somehow, self to the, this object. So the way that happens is a bit of magic, where when we call the back over in typeless batch, in dunder call, it checks for a special thing called self.instance, it stands for self.instance. It finds out whether this is an instance, in an instance of something. And if it is, then self.instance is not none, in which case, instead of using the function that it's looked up, it wraps it as a method. So it's a method where the method is this function and the instance it's bound to is this instance. So this is how you turn, this is how you turn a function into a method. OK, so that's fine. But how on earth does it know what self.inst is? Somehow self.inst has to be set to, in this case, a. And the answer is that in Python, when you go a.f, like this, it's actually going to call a special method of whatever class f is in. And the method it calls is called dunder get. So we've never seen this before. Dunder get, so this is again, remember the place to learn about all this stuff is the Python data model documentation. So we could look for dunder get. And here we are. It's called to get the attribute of the owner class or an instance of that class. The instance is the instance that the attribute was accessed through. So in this case, dunder get is going to be called and it's going to be passed in as self, the value of this f thing. But more interestingly, it's going to be also passed in as inst, the value of the thing before the dot a. And so that means we can just go self.inst equals inst. And so now from now on, the type dispatch object knows what instance it's been called on. So we just go self.inst equals inst. And so then later on, when we call the function, we check if it's not none and indeed it's not none. And so then we wrap it as a method. So that's again, like just super nice Python extensible data model that lets us do anything we want to. And so in this case, this is kind of wonderful magic where, you know, I was really surprised this was possible when I learned about it. I really wanted it to work, which I thought it would be able to have both functions and methods and have my new dispatch automatically handle both. And then it does. This is how this is how it does. So that is, yeah, I think that's pretty great. OK, so something that I added with Sylvia this morning actually was we added one more thing to our transform class, which is as well as encodes and decodes. We've also added setups. So setups will be called by setup as before. But now setups is a type dispatch object. So the codes changed a tiny bit. I've put encodes, decodes and setups into this couple. And so now we go through for name in those three methods and we create our type dispatch objects. That's all in the meta class. And the reason for that is that we're starting to work on rapids. Rapids, if you haven't seen it, is a very nice project from Nvidia, which provides something a bit like pandas, but that runs on the GPU. And it's only a bit like pandas. It's not pandas. So we basically want to create tabular transforms that work automatically, correctly on rapids data frames and on pandas data frames. And that includes we want the setup to work appropriately. And so now thanks to this, we can now do that. So. Yeah, so that's why we just added that. So some slight changes to the code from last time. They're very small. All right. Well, let's keep working back through the details of these things that use this then, shall we? So we've done zero two. Oops. And so let's now look at zero. So in zero three, we can import that thing we just made, the code dot data dot transform. And what we're going to do is we're going to create pipeline. So pipeline. As usual, it's probably easiest just to look at the tests. So a pipeline is an object which is so we just create a pipeline called pipe. And it's an object which is callable. So this is an empty pipeline. So an empty pipeline always returns whatever it's given. It has the same as item behavior as transforms do. And so if you say set as item on a pipeline, it will set the as item Boolean in all of the transforms in that pipeline to that value. So in this case, we're going to say false. And so if we set it to false, then we pass in a. Topple confirm back a couple. So where it gets more interesting is if we create a pipeline. That does something. So here's a pipeline with two. Transforms. The first transform is something which encoding turns something into an int decoding turns its back into a float. And these are the capital versions, capitalized versions, which are the fast AI versions that know how to show themselves. One of the main reasons we use it in tests is to make sure that the retaining types works properly. And then here's a transform, which simply remember you can create a transform either by subclassing or by. That's getting so here's a transform, which is going to set encodes to this negative function and the decodes to the same negative function. So there's two transforms. And so those are the two transforms in our pipeline. So if we start with the value two point zero. And then we. Pop that into our pipeline. Then the first thing it's going to do is make it a negative because that's the first thing in a pipeline that's going to become negative two. And then the second thing it's going to do is it's going to turn it into a capital I int. So test equals type checks that this is equal to this and not only is it equal, but exactly the same type. So this is now into minus two as expected. And so you can see what the pipeline is doing is it's calling. Taking this value and it calls this function first. So that makes it negative two point oh and then this function second, which makes it capital I int of negative two. And that's all it's doing. So that is function composition. When we call pipe decode, it will simply call the decodes of each thing in the reverse order. So if we start with T, which we know is int negative two and we call decode on the pipe. The first thing I'll do, we go in transform to this one decodes. So it'll turn it back into a float. That's now negative two point zero. And then the second thing it will do is to go to decodes of negative transform, which is just again negative. And so that's going to be a capital F float two point oh. Confirm. Yes, it is capital F float two point oh. So how does that work? Let's take a look at pipeline. The key thing that pipeline does when we call dunder call is it calls a function called compose transforms. Passing in the value, which in this case was the value two point oh. And it's going to pass in the list of functions. And so that list of functions is just the thing that we pass to the pipeline constructor. So we just set self dot F's to a list of those functions. We will turn them into transforms for those that aren't transforms. And we will sort them by order. If they have an order. So compose transforms is the key thing that's actually doing the work. And so that's. Yeah. Compose transforms that's going to take some value to calculate the composed functions on and some list of transforms. And are we encoding or decoding? Are we going in forward order or reverse order? And this is basically a pretty classic function composition loop. You go through each function. You call it and you replace your current value with the result. And then you go back and do that again. Keep doing that for everything in the. In the list of functions. And so you can see you can use compose transforms. So here's some examples of some functions. So anytime you want to know how something like. It's used internally like this works you can see the tests for the thing that's used internally before you worry about how it's being used in for example pipeline. So here's the test of composing some plain functions. And then here's a test of composing some transforms. Because you can always use functions as transforms. And in this case as long as we're not going to pass in is an equals false. It's not going to try and do anything other than just call the callable. So that's how the pipeline does call. And it's also how the pipeline does decode. It's just going to call compose transforms and say is encode is false and reverse equals true. So that's that's the simple bit there. Where it gets interesting is when we call pipeline show. What is pipeline show do so intuitively what it does is it takes T. And remember T is a capital I int minus two. And it decodes it one transform at a time in reverse order until it gets to a data type that has a show method. Data type that is showable. Now in this case a capital I int. Is already showable a capital I int. Int. It's sort of a definition. Capital I int is just an int that inherits from both small int and show title. And show and it has no other code in it. And show title remember is just a class which has a show method. And shows it by calling show title. And show title by the way if you're passing in a no context at all it just prints whatever it's passed in. And if you pass in a plot it'll show it as a title on the plot. So show title three as you can see. So in this case pipe.show T. And remember T is minus two simply prints out minus two. And the reason for that is that because this is already something that's showable so there's no decoding that needs to be done. For those of you didn't see it earlier notice that the way I test that this prints something out is I make that a lambda. Which takes no arguments. And that's the first thing that you pass to this test stood it out method. And that tests that this function when run prints that to stood it out. That's a nice way to check what's happening with our show methods. When as item is false in our pipeline and we call pipe.show. Pipe.show will call show on each element of the tuple that's passed in. Because remember when as item equals false in transforms it's basically saying you should apply the transform to each element of a tuple that's passed in. And so when you show it you should show on each element of the tuple that's passed in. And the reason for that is for stuff like when you're doing show batch. Unlike the pets data set you've got two things in the tuple of the batch you've got the images and you've got the labels. And so we want to show the image and then show the label. So in this case when I say pipe.show and pass in 1 comma 2. And that's going to print minus 1 and then print minus 2. It's calling show on each element of that tuple. And notice it's also applied the pipeline to each element of that tuple. So each one has been negated and turned into an int. OK. So that's pipeline and so show. Is going to go through our functions in reverse order. It'll see if it can show it without doing any decoding. And if it can then I'm done. If it can't it will try to decode it with this function and then it will go back and try again. See if we can show it now. And if it can't go to the next part the next earlier function in the pipeline. Decode. Can I show it now? And so forth. And so all underscore show is doing is it's just checking whether as item is true or not. And then it's checking that whether there is a show method for this type or not. For everything in that type or not. And then if there is then it's going to show them. OK. So not super exciting code. But conceptually interesting this idea of being able to decode and show things turns out to be super helpful. OK. So here you can see where. Creating some. Functions some of which only operate on certain types. And so here we've got a function one function that operates on tensor image one that operates on everything. One that operates on PIO images. And so here's something which is going to call image open resize. And then turn that into a tensor image and then. Take it's negative. So we should find at the end of all that that we have a tensor image. Which we do. And we check that we have the right values. If we get rid of the F1 piece. So we just open the image and then turn it into a tensor image. We should be able to show it. So that's making sure that we can. OK. So now's a good time to talk about filtering. Actually not. Let's talk about filtering after we talk about the data source class. OK. So we've kind of covered these ones before. So then a transformed list is something where we're going to pass in a list of items. And a list of transforms. And it's going to create a pipeline with those transforms. And it's going to. So it's a subclass of triphoned base which is a subclass of L. So it's just passing the items back up to the L constructor. So it's going to basically be a list of items. But it's also got this pipeline in it. And so this is where you can learn some new interesting stuff in L. Because L actually lets us create, it's kind of designed to let us create some more interesting types of collections. So in this case, you can see what happens in L when I call get item. It actually calls self dot underscore gets if you have an iterator of indexes. Otherwise it calls self dot underscore get. And self dot underscore get by default, assuming there's no ILOCK. So as long as this is not a pandas data frame, it just returns the Ith element. But what we can do in to firm list is we can override underscore get. And we will continue to call capital L's underscore get. But then we will call our pipeline. Right. So this is how we end up with something that we can say. Let's create a to firm list. The items are one, two, three. Our pipeline is going to be negative and then our int to firm transform. And then we now have something that we can treat like a list. We can subscript into it and it's going to grab the first thing, which is in this case 2.0, and apply the pipeline to it. So we end up with int negative two. So this is starting to really look like something that has nice PyTorch data set behavior. So you could absolutely use this as a PyTorch data set, which indeed we did that pretty close to when we started these walkthroughs in 08. Here is to firm DS. So going right back to it, we created an imagery size of transform that can encode an image by resizing it. We then created a pipeline. And then we actually do something a bit more complex. So we have to come back to this in a moment. We use a to firm DS, not a to firm list. OK, so let's get going to to firm DS so we can see how to make a that the reason the reason that to firm list isn't quite everything we want for a data set is normally a data set when you index into it should return two things, independent variable and dependent variable. And so far we only have something that kind of returns one thing. So what we can do is we can make something slightly more interesting called to firm DS, which now it's very, very, very similar to to firm list. Right. So it's still inheriting from to firm base, which in turn inherits from L, still passes the items into it. But this time it creates a few to firm lists and specifically it creates one for each list of transforms you pass in. So now we don't just pass in white one pipeline, but we pass in N pipelines where N usually is two. We usually want to set up an X pipeline and a Y pipeline, an independent variable pipeline and a dependent variable pipeline. So we go through each of those pipelines and we create a transformed list with the same items, but the different set of transforms. And so this is actually the thing that we used in the pets tutorial because we said, oh, let's have we're going to start with a list of items is a list of file names. And the first pipeline will treat it as an image, the path to an image. It will open the image, resize it, turn it into a tensor and make it a float. And the second pipeline will treat it as a source of a label and it will label it and categorize it. And so inside, in fact, let's look at it. We run this. We should be able to look inside TDS and we should find this self dot TLS and that should contain two transfer from lists with the same items. So let's take a look. TDS dot TLS. Yep. So there are is our transformed lists. So the zero one. They have items. As you can see, and it should have also a pipeline in it. Let's go back and check to from list that pipeline will be called. Yeah. Called to firms. It does. So there's one zero one. OK, so there's our two transforms. So it's going to be applying these different pipelines to exactly the same items. And so that's why then when we say. T equals TDS zero, we're getting back an image. And category. And you can see the types here. And so when we say TDS decode. Here is. Here is TDS decode. It's going to go through each of those transform lists. And decode each one. So, yeah, so Max, yes, both pipelines are going to start with the same thing because the two firm lists I'm creating are both being passed exactly the same list of items. And so when you think about it, this is like how exactly the one for X opens the path as images and the second creates labels from the paths. Well done. So, yeah, so here is pipeline one. Let's see if we can use it right. So let's grab items. So here's items that we passed into a different. Yes. So here's items zero. There's a path. And so when you think about it, like whatever your independent independent variables are, they they're kind of being somehow derived from the same place. That's kind of like what a labeling function is. So let's create an item called like so. So here's the item. And so let's create our function for X would be TDS. Dot two firms. TLS zero. So here's our that's our first pipeline. Right. And then our second pipeline is tedious. And so there's both our pipelines. So if we then apply effects. To our item. We get out image. And if you apply F.Y. To our item. We get back our category. So, yeah, so that's kind of a useful thing to try doing is to like just see what's going on inside. So could two firms. Yes. Except couples instead of items. Well, I mean, it's not as dead off like the items can be couples. So, yes, absolutely. Because it's just calling a pipeline. And so let's try it. Right. So let's try. I think so. Let's create some items. Equals. Zero comma one comma. One comma two. Comma. Three comma four. Right. So there's some items, which is a list of couples. And so we could create like a function. So there's a function. In Python called item getter. So if I call effects is item get a zero. The way that works is that. She does try to make this more helpful by making this a capital L. So if I apply. Fx to every element of that I get back. As you can see. The first element of each couple. So let's create effects and if why. And so now we do it. Why will get the second element of each couple. And so we could create a. Fmds. Which the items of it are it's. And we're going to pass in two pipelines. The first pipeline just contains effects. And the second pipeline just contains Fy. OK. So now if we look at TDS. Zero. There you go. OK. So it's going to take the. Zero element. Which is the couple zero one. And then it was going to pass it through through two functions. The first function is I didn't get a zero. It turns zero thing. The second function is. I didn't get a one which returns the index one thing. And then it's going to put them back into a couple. So hopefully that answers your question as well. David you just have to make sure that your items contain whatever information is necessary. To construct your data that you end up want to end up in your mini batches. Thanks to all those very very good questions. OK. So you know and to be clear like remember. This you know. So when I got to this over a period of about 25 iterations and pretty much rewrites over a period of many weeks. And so like it's. This is very simple but the. They go together in very neat ways which you know most people don't have to understand all these details. But you folks you're here because you do want to understand all these details. It's it's it's it. Don't be. But don't let it bother you that it's going to take a while probably before it all clicks into place. But hopefully these notebooks can help it click into place. OK. So yeah. So like going back to to notebook. Oh wait would be a really great thing to do. You know kind of as as as homework if you want to do some homework before tomorrow. Because you'll understand all the pieces I know. All right. So that is to find the S and to find a different list. In practice you probably won't use to find list much because most of the time you want multiple sets of transforms because you want to create a data loader which is going to have a mini batch with couples of things. So you want to find the S most of the time. But to fit to fit to find the S users to find list. So it's a very very. Yeah. Remember these things are very very small. Each one's very very small. So try to make sure you get a good intuitive understanding of what each thing does and read through the tests and understand like why did we add that test. You know because these tests are not arbitrary. They're the set of things we think provides kind of the best clarity around the details of what this thing does. And remember that the methods section has tests as well so that you can learn more information about what all these different methods do. OK. So now something new. Oh no this is not user 0 5. So I think we've done all this before. So get split and label. We've seen all that before. Category that we've seen before. Oh we didn't look at pipeline setup. OK. So we've talked briefly about pipeline setup before. So in something like categorize if you don't pass a vocab in to categorize it uses setup to automatically create a category. So a vocab and a vocab is a category map class which is this very small little thing which simply will call dot unique on the list of items to find out the vocab unless it's a pandas data frame in the categorical series in which case the pandas already has that done for us. So the key thing here is calling setup or setups because it's a transform. The transform method that's a type dispatch method. So if we look at pipeline. So if we can find some setup examples. You know have good setup examples. That sounds like an oversight. I guess the setup examples probably won't come to all we look at data source. Well here's a good place to look at them. So let's learn about setups by looking at categorize. So categorize I've already taken you through this code. The key thing is that we we need to make sure we call setup at exactly the right time. If you look at here in pets. We need to first we need to label. And then we need to categorize. And more importantly when we create a vocab we need to create a vocab on the after calling the label. So what happens is that setup is going to be called also as part of the pipeline. So if you look at the pipeline. Here it is his setup. We what we actually do is we set self dot functions to an empty list. So we say we actually don't know what our transforms are. And then we store that list of functions in a temporary thing called to firms. And then we go through each to firm. And add it. And what ad does is add then call setup and then adds it to the list. So the reason we do it in this rather awkward way is because this way when we call categorize. It will have already added the label to the pipeline. So it's going to go through and it's going to say OK the first thing is sorry. The first thing is label. So it'll self to add label which doesn't really have a setup. So just adds it to the list and then it will add. Categorize. And notice it called setup before it adds it right because we can't append it before we call it setup. And so that's why the setups is going to get the. It's not going to get the raw paths it's going to get the paths after the labels have been extracted from them. So this is kind of like a. Yes it's really important detail that we found pretty tricky to get right. But now that it's there we find just super handy because the right information goes automatically to the right parts of the pipeline. And so things can set themselves up automatically. So that's really handy. So that's the key thing to kind of understand in categorize is that setup. Yes it's really the first time we properly test and display how setup works. And so you can see here we create a TFMDS with cat dog cat as our items and our pipeline is just a. Categorize transform. And so at the end of that the vocab should be cat dog. It is. So body categorized doesn't have any new information. It's the same stuff. It's a good way that you can check it out to get a second kind of angle on how setup works. So now that we've got all that we have all the information we need to create to from the L. So now if you go back and look at TFMDL again it'll be more straightforward. So you can see that we go through each of after item before batch after batch. So these are all things in the data loaders kind of list of methods that goes through. And if you pass in any of those keyword arguments then it will grab that keyword argument. And turn it into a pipeline. OK. And. We'll then set it up. And notice here it passes in self because the pipeline setup you know generally speaking it needs to know what items to set up with. So for example in categorize. It's the setup is receiving the actual list of. Labeled items to create a vocab with. OK. So that's the key thing here is we now know what these pipelines are. And so you can now also look and see how the code is actually working. And it's called calling decode on each of those things in the pipeline. OK. So now we can look at some more examples. So we now can see CUDA is just a transform that has an encodes and decodes and encodes. We've seen this one before. Puts it on the device and decodes puts on the CPU. And this is pretty cool because I don't think there are any other. Frameworks that will like automatically put things on the back on the CPU for you when you're all done with them for the purpose of displaying them or whatever. You don't have any memory links. But to float tensor we've seen. Normalization we've seen. And data bunch we've seen. OK. So we're kind of gradually working back up here. Nice. And hopefully. Yes. We're now up to 06 which is really what I wanted to get to today. And so 06 introduces data source. And to remember what data source does we look at the 08 pets tutorial. Data source is something which is almost identical to TFMDS. In fact, TFMDS. Let's go back and have a look at our. Version of pets with TFMDS. This is the TFMDS version of pets. We had two sets of transforms one which is PO image create one which was labeled and categorized. Then we created a TFMDS passing in the items and the transforms. And then we made that into a data loader passing in some after item. Transforms to happen there. Notice that if I copy just the TDS get out and paste it here. The TDS. Let's find them up so you can see. As you can see, TFMDS and the data source versions are almost identical. And the way you use them is almost identical. The difference is one extra argument, which is the filters. The filters tell the data source. How to do. This, which is to get a subset and all it does literally is subset. One. Simply returns a new TFMDS which contains not items, but items. For split IDX one. So. To remind you, this is a while ago. Split IDX. Was just our just a couple with two things in it, which is the list of indexes that are in the training set and the list of indexes in the validation set. So this. And pets.subset one has another name, which is. That valid. That's exactly the same thing. And pets.subset zero is called also called dot train. So all this data source is doing is it's giving us something that looks like two different TFMDS. One which is going to give us back things from the validation set and one that's going to give us back things from the training set. And the way it does that is by passing in. Filters. So the way that works is actually. Nice and easy. As you can see data source is much less than a screen of code. And quite a lot of that is actually the thing to create a data bunch. But the actual thing. You know, so as you can see it, it's a subclass of TFMDS. Right. So it behaves a lot like TFMDS because it is a TFMDS. But it's a TFMDS that also has. Subset. And so subset is something that's going to pass. This TFMDS into something called make subset. And so make subset. Is something that's going to grab all of our transforms. And it's going to create, as we discussed, a new TFMDS. Containing just the subset. Of the items that are in filts I. So that's the split index is zero or split index is one. And it's going to pass in. The transforms. And a key thing is going to also pass in is do setup equals false. Because I don't need to recreate the vocab. We already have one. For instance. So this is just a TFMDS for a subset of items. That's basically all the data. That's basically all the data sources. So like in terms of the other code here. It's just to do a bit of kind of bookkeeping and checking and stuff. So for example. These filters IDs that we pass in. You can pass in as many as you like. Normally it will be two. A list of indexes for the training set. Not listed for the validation set. You can do more. And so like I just check here to make sure that there's no indexes in the training set. That are also in the validation set. So we kind of try to make sure that good data science practices are followed. It will let you know if they're not. OK. So there's something else though interesting about our filters. And that is that when we create the subset. We actually pass into TFMDS. A filter parameter. So what does that do? So. So as you can see TFMDS. Takes a filter argument. And it doesn't really do anything with it other than it passes it onto the TFM lists it creates. So fine. Let's look at that. So TFM list. Gets a filter argument. And what does it do with it? And the answer is nothing much. Just passes it onto the pipeline that it creates. OK. So what does the pipeline do with it? The pipeline grabs the filter. And what does it do with it? It stores it. Because when we call call or decode. It passes it as a parameter to call or decode. So what does compose to films do with it? And the answer is. Nothing really. It's just a keyword argument. That it passes to our function. What does our function do with it? What does our transform do with it? And the answer is. Whatever you like. So the key insight here is that our transforms actually have the ability to know. Whether they're being called on the training set or the validation set. And actually by default is something that it does with that. Which is when you create a function. A transform. You can actually pass in a filter. And if you pass in a filter when you create the transform. That says this transform should only be applied. On that particular subset. So for example. Data augmentation. The data augmentation. Transforms I think by default always set filter to zero. Because a filter equals none. It means you should apply it all the time. But a filter equals zero. It means you should only apply this to the training set. Which is what we want right. We want our data augmentation only applied to the training set. So when we call this transform. It's going to be passed. The filter. Because remember the pipeline passed it along. And you can see here. If our filter is not none. And the filter for this function is not this transforms filter. It does nothing at all. Ok so that's the default behavior for a transform. Is that it will be disabled. If you set the transforms filter. And then you call it with some different filter. So this is. Yeah this is like just another of these nice things to make sure that you don't accidentally do things that you wouldn't want to do. Where we make sure that it's only being called on the training set. That's appropriate. So most of the time you don't have to worry about it right. Because most of the time. When you create a transform. You're not passing in a filter. Right. So most of the time this just does nothing at all. But if you do. Or more generally if you have some transform that's not. Seems to be not doing anything. And you should check maybe you created it with a filter. So yes Max a filter is just an integer. I think yes it's just an integer. But you know you could inherit from transform. And and replace how underscore core works and actually have things that work differently. For training versus validation. So you know that the key thing here is that the infrastructure is in place. That functions that transforms can behave differently. They actually know where they're being called from. So you can see in the data source tests. Let's start by looking at them right. So here's some items not through for. So here's a data source. The north through four and the pipeline it's going to apply is do nothing at all. So it's an empty pipeline. So the data source has a list of filters. And we didn't pass in any filters. So it's just going to by default have one filter which is everything in the list. So if we just grab. Item number two. Then here is zero one two and it should return. OK. If we grab items one and two. You're going to get back one and two and notice they're being turned into couples. And the reason for that is that remember this is a. To from DS and to from DS is take a list of pipelines and create a couple with an element for each pipeline. So we have one pipeline. So we get back. Couples with one thing in. This is what you want in by torch. Mini batches right. A data set and a data loader should return. Doubles. So Petro's question is should we call retain type back here. And the answer is no. Retained type. Gets past two things. The new result of whatever functions we called and the original thing we were passed in. And it makes sure that this. Res has the same type as this. If res ends up as a subclass of this. Res ends up a tensor and X is a tensor image. It will turn res into a tensor image. In this case. Nothing happened to X. It didn't change so we we have no retained type to do it's already the same type as X because it is X. OK. You can also index into to from lists and therefore data sources with masks. Bullion masks instead of indexes. So that's just that. They also work on data frames. This is important that they work on data frames. It's not just they work on data frames that they work on data frames in a optimized way. So they'll actually use the ILOC method in data frame to do things efficiently. OK. How do we set up a pipeline where a transform of X depends on Y. Let's look at that next time. More sometime in the next couple of days. That's a great question. And do remind me in the next couple of days if I forget. OK. So then you can see here's the same thing basically passing in our range with no transforms. But this time it's passing some filters. So now there are two sets of filters and there's subset zero which is the same as the training set. There's subset one which is the same as the validation set. So that's that. Oh, batteries. That's fine. And the filters could also be masks. They don't have to be ints. Great. OK. Well, I think that's enough for today. So, yeah, let me know any questions you've got. But hopefully these things are starting to come together. All right. Thanks, everybody. See you next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 19.0, "text": " Hey everybody, can you see me and hear me okay?", "tokens": [1911, 2201, 11, 393, 291, 536, 385, 293, 1568, 385, 1392, 30], "temperature": 0.0, "avg_logprob": -0.599806891547309, "compression_ratio": 1.013157894736842, "no_speech_prob": 0.18664656579494476}, {"id": 1, "seek": 0, "start": 19.0, "end": 25.16, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.599806891547309, "compression_ratio": 1.013157894736842, "no_speech_prob": 0.18664656579494476}, {"id": 2, "seek": 0, "start": 25.16, "end": 28.16, "text": " Sorry about the delay.", "tokens": [4919, 466, 264, 8577, 13], "temperature": 0.0, "avg_logprob": -0.599806891547309, "compression_ratio": 1.013157894736842, "no_speech_prob": 0.18664656579494476}, {"id": 3, "seek": 2816, "start": 28.16, "end": 33.16, "text": " YouTube streaming doesn't quite work on Firefox properly.", "tokens": [3088, 11791, 1177, 380, 1596, 589, 322, 46613, 6108, 13], "temperature": 0.0, "avg_logprob": -0.2333899548179225, "compression_ratio": 1.2611464968152866, "no_speech_prob": 0.0009232305455952883}, {"id": 4, "seek": 2816, "start": 33.16, "end": 38.16, "text": " Thanks Google.", "tokens": [2561, 3329, 13], "temperature": 0.0, "avg_logprob": -0.2333899548179225, "compression_ratio": 1.2611464968152866, "no_speech_prob": 0.0009232305455952883}, {"id": 5, "seek": 2816, "start": 38.16, "end": 42.16, "text": " Alright.", "tokens": [2798, 13], "temperature": 0.0, "avg_logprob": -0.2333899548179225, "compression_ratio": 1.2611464968152866, "no_speech_prob": 0.0009232305455952883}, {"id": 6, "seek": 2816, "start": 42.16, "end": 49.16, "text": " I'm not quite sure what we're going to talk about today as usual, but I do have some place to start.", "tokens": [286, 478, 406, 1596, 988, 437, 321, 434, 516, 281, 751, 466, 965, 382, 7713, 11, 457, 286, 360, 362, 512, 1081, 281, 722, 13], "temperature": 0.0, "avg_logprob": -0.2333899548179225, "compression_ratio": 1.2611464968152866, "no_speech_prob": 0.0009232305455952883}, {"id": 7, "seek": 2816, "start": 49.16, "end": 53.16, "text": " Which is in 02.", "tokens": [3013, 307, 294, 37202, 13], "temperature": 0.0, "avg_logprob": -0.2333899548179225, "compression_ratio": 1.2611464968152866, "no_speech_prob": 0.0009232305455952883}, {"id": 8, "seek": 5316, "start": 53.16, "end": 58.16, "text": " I realize there's one piece I didn't tell you about.", "tokens": [286, 4325, 456, 311, 472, 2522, 286, 994, 380, 980, 291, 466, 13], "temperature": 0.0, "avg_logprob": -0.12181599934895833, "compression_ratio": 1.310077519379845, "no_speech_prob": 6.602817302336916e-05}, {"id": 9, "seek": 5316, "start": 58.16, "end": 61.16, "text": " Which is in TypeDispatch.", "tokens": [3013, 307, 294, 15576, 35, 7631, 852, 13], "temperature": 0.0, "avg_logprob": -0.12181599934895833, "compression_ratio": 1.310077519379845, "no_speech_prob": 6.602817302336916e-05}, {"id": 10, "seek": 5316, "start": 61.16, "end": 66.16, "text": " If you haven't seen it,", "tokens": [759, 291, 2378, 380, 1612, 309, 11], "temperature": 0.0, "avg_logprob": -0.12181599934895833, "compression_ratio": 1.310077519379845, "no_speech_prob": 6.602817302336916e-05}, {"id": 11, "seek": 5316, "start": 66.16, "end": 73.16, "text": " there's a very nice walkthrough of TypeDispatch", "tokens": [456, 311, 257, 588, 1481, 1792, 11529, 295, 15576, 35, 7631, 852], "temperature": 0.0, "avg_logprob": -0.12181599934895833, "compression_ratio": 1.310077519379845, "no_speech_prob": 6.602817302336916e-05}, {"id": 12, "seek": 5316, "start": 73.16, "end": 82.16, "text": " on the forums now.", "tokens": [322, 264, 26998, 586, 13], "temperature": 0.0, "avg_logprob": -0.12181599934895833, "compression_ratio": 1.310077519379845, "no_speech_prob": 6.602817302336916e-05}, {"id": 13, "seek": 8216, "start": 82.16, "end": 87.16, "text": " Among Aurora,", "tokens": [16119, 40663, 11], "temperature": 0.0, "avg_logprob": -0.1478506594288106, "compression_ratio": 1.3308823529411764, "no_speech_prob": 8.087926107691601e-05}, {"id": 14, "seek": 8216, "start": 87.16, "end": 94.16, "text": " the basic idea of TypeDispatch is kind of quite well described in the tests.", "tokens": [264, 3875, 1558, 295, 15576, 35, 7631, 852, 307, 733, 295, 1596, 731, 7619, 294, 264, 6921, 13], "temperature": 0.0, "avg_logprob": -0.1478506594288106, "compression_ratio": 1.3308823529411764, "no_speech_prob": 8.087926107691601e-05}, {"id": 15, "seek": 8216, "start": 94.16, "end": 104.16, "text": " Which is that here is a bunch of functions and they take different things.", "tokens": [3013, 307, 300, 510, 307, 257, 3840, 295, 6828, 293, 436, 747, 819, 721, 13], "temperature": 0.0, "avg_logprob": -0.1478506594288106, "compression_ratio": 1.3308823529411764, "no_speech_prob": 8.087926107691601e-05}, {"id": 16, "seek": 8216, "start": 104.16, "end": 109.16, "text": " And underneath,", "tokens": [400, 7223, 11], "temperature": 0.0, "avg_logprob": -0.1478506594288106, "compression_ratio": 1.3308823529411764, "no_speech_prob": 8.087926107691601e-05}, {"id": 17, "seek": 10916, "start": 109.16, "end": 116.16, "text": " you can see, so we create a TypeDispatch object with that list of functions and then we treat it", "tokens": [291, 393, 536, 11, 370, 321, 1884, 257, 15576, 35, 7631, 852, 2657, 365, 300, 1329, 295, 6828, 293, 550, 321, 2387, 309], "temperature": 0.0, "avg_logprob": -0.14245564260600527, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00012140991748310626}, {"id": 18, "seek": 10916, "start": 116.16, "end": 124.16, "text": " like a dictionary, passing in some type, and it tells us what function you should call to use that type.", "tokens": [411, 257, 25890, 11, 8437, 294, 512, 2010, 11, 293, 309, 5112, 505, 437, 2445, 291, 820, 818, 281, 764, 300, 2010, 13], "temperature": 0.0, "avg_logprob": -0.14245564260600527, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00012140991748310626}, {"id": 19, "seek": 10916, "start": 124.16, "end": 129.16, "text": " As you can see.", "tokens": [1018, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.14245564260600527, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00012140991748310626}, {"id": 20, "seek": 10916, "start": 129.16, "end": 135.16, "text": " And then, as well as doing that, more importantly, you can treat it like a function.", "tokens": [400, 550, 11, 382, 731, 382, 884, 300, 11, 544, 8906, 11, 291, 393, 2387, 309, 411, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.14245564260600527, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00012140991748310626}, {"id": 21, "seek": 13516, "start": 135.16, "end": 140.16, "text": " It's a callable, and you can pass it something. In this case, I'm passing it the normal int.", "tokens": [467, 311, 257, 818, 712, 11, 293, 291, 393, 1320, 309, 746, 13, 682, 341, 1389, 11, 286, 478, 8437, 309, 264, 2710, 560, 13], "temperature": 0.0, "avg_logprob": -0.16403839200042014, "compression_ratio": 1.525, "no_speech_prob": 2.429838241368998e-05}, {"id": 22, "seek": 13516, "start": 140.16, "end": 152.16, "text": " So it's going to go to the numbers.integral version, which would return x plus 1, and we check, yes, it has returned x plus 1.", "tokens": [407, 309, 311, 516, 281, 352, 281, 264, 3547, 13, 31131, 304, 3037, 11, 597, 576, 2736, 2031, 1804, 502, 11, 293, 321, 1520, 11, 2086, 11, 309, 575, 8752, 2031, 1804, 502, 13], "temperature": 0.0, "avg_logprob": -0.16403839200042014, "compression_ratio": 1.525, "no_speech_prob": 2.429838241368998e-05}, {"id": 23, "seek": 13516, "start": 152.16, "end": 160.16, "text": " Something that I didn't look at last time, though, was this other cell underneath it.", "tokens": [6595, 300, 286, 994, 380, 574, 412, 1036, 565, 11, 1673, 11, 390, 341, 661, 2815, 7223, 309, 13], "temperature": 0.0, "avg_logprob": -0.16403839200042014, "compression_ratio": 1.525, "no_speech_prob": 2.429838241368998e-05}, {"id": 24, "seek": 16016, "start": 160.16, "end": 169.16, "text": " Which is exactly the same thing, but this time these functions take self as well.", "tokens": [3013, 307, 2293, 264, 912, 551, 11, 457, 341, 565, 613, 6828, 747, 2698, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.09617797642537992, "compression_ratio": 1.5757575757575757, "no_speech_prob": 2.2125150280771777e-05}, {"id": 25, "seek": 16016, "start": 169.16, "end": 173.16, "text": " And we create a TypeDispatch object as usual.", "tokens": [400, 321, 1884, 257, 15576, 35, 7631, 852, 2657, 382, 7713, 13], "temperature": 0.0, "avg_logprob": -0.09617797642537992, "compression_ratio": 1.5757575757575757, "no_speech_prob": 2.2125150280771777e-05}, {"id": 26, "seek": 16016, "start": 173.16, "end": 182.16, "text": " We then insert that TypeDispatch object as an attribute of this class, and we're going to call the attribute f.", "tokens": [492, 550, 8969, 300, 15576, 35, 7631, 852, 2657, 382, 364, 19667, 295, 341, 1508, 11, 293, 321, 434, 516, 281, 818, 264, 19667, 283, 13], "temperature": 0.0, "avg_logprob": -0.09617797642537992, "compression_ratio": 1.5757575757575757, "no_speech_prob": 2.2125150280771777e-05}, {"id": 27, "seek": 16016, "start": 182.16, "end": 188.16, "text": " And now we call a.f.", "tokens": [400, 586, 321, 818, 257, 13, 69, 13], "temperature": 0.0, "avg_logprob": -0.09617797642537992, "compression_ratio": 1.5757575757575757, "no_speech_prob": 2.2125150280771777e-05}, {"id": 28, "seek": 18816, "start": 188.16, "end": 191.16, "text": " And we get back again, 2.", "tokens": [400, 321, 483, 646, 797, 11, 568, 13], "temperature": 0.0, "avg_logprob": -0.1522030556338957, "compression_ratio": 1.436842105263158, "no_speech_prob": 2.014511301240418e-05}, {"id": 29, "seek": 18816, "start": 191.16, "end": 194.16, "text": " Now there's something a bit magic going on here.", "tokens": [823, 456, 311, 746, 257, 857, 5585, 516, 322, 510, 13], "temperature": 0.0, "avg_logprob": -0.1522030556338957, "compression_ratio": 1.436842105263158, "no_speech_prob": 2.014511301240418e-05}, {"id": 30, "seek": 18816, "start": 194.16, "end": 206.16, "text": " How did Python know, or how to type dispatch know, that a.f should be passed as self as well as the x?", "tokens": [1012, 630, 15329, 458, 11, 420, 577, 281, 2010, 4920, 852, 458, 11, 300, 257, 13, 69, 820, 312, 4678, 382, 2698, 382, 731, 382, 264, 2031, 30], "temperature": 0.0, "avg_logprob": -0.1522030556338957, "compression_ratio": 1.436842105263158, "no_speech_prob": 2.014511301240418e-05}, {"id": 31, "seek": 18816, "start": 206.16, "end": 210.16, "text": " And the answer is, by default, it doesn't.", "tokens": [400, 264, 1867, 307, 11, 538, 7576, 11, 309, 1177, 380, 13], "temperature": 0.0, "avg_logprob": -0.1522030556338957, "compression_ratio": 1.436842105263158, "no_speech_prob": 2.014511301240418e-05}, {"id": 32, "seek": 18816, "start": 210.16, "end": 216.16, "text": " a.f is just a, it's just an attribute of this class.", "tokens": [257, 13, 69, 307, 445, 257, 11, 309, 311, 445, 364, 19667, 295, 341, 1508, 13], "temperature": 0.0, "avg_logprob": -0.1522030556338957, "compression_ratio": 1.436842105263158, "no_speech_prob": 2.014511301240418e-05}, {"id": 33, "seek": 21616, "start": 216.16, "end": 222.16, "text": " There's nothing particularly to say that it should be passed as self.", "tokens": [821, 311, 1825, 4098, 281, 584, 300, 309, 820, 312, 4678, 382, 2698, 13], "temperature": 0.0, "avg_logprob": -0.1779766794460923, "compression_ratio": 1.4968944099378882, "no_speech_prob": 4.469206396606751e-05}, {"id": 34, "seek": 21616, "start": 222.16, "end": 225.16, "text": " So how did it do that?", "tokens": [407, 577, 630, 309, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.1779766794460923, "compression_ratio": 1.4968944099378882, "no_speech_prob": 4.469206396606751e-05}, {"id": 35, "seek": 21616, "start": 225.16, "end": 229.16, "text": " And actually, it would be good to do another test, make sure it's getting a real self.", "tokens": [400, 767, 11, 309, 576, 312, 665, 281, 360, 1071, 1500, 11, 652, 988, 309, 311, 1242, 257, 957, 2698, 13], "temperature": 0.0, "avg_logprob": -0.1779766794460923, "compression_ratio": 1.4968944099378882, "no_speech_prob": 4.469206396606751e-05}, {"id": 36, "seek": 21616, "start": 229.16, "end": 244.16, "text": " So maybe we should like, what if we did something like def m.", "tokens": [407, 1310, 321, 820, 411, 11, 437, 498, 321, 630, 746, 411, 1060, 275, 13], "temperature": 0.0, "avg_logprob": -0.1779766794460923, "compression_ratio": 1.4968944099378882, "no_speech_prob": 4.469206396606751e-05}, {"id": 37, "seek": 24416, "start": 244.16, "end": 248.16, "text": " Actually, I don't know, it would be kind of interesting.", "tokens": [5135, 11, 286, 500, 380, 458, 11, 309, 576, 312, 733, 295, 1880, 13], "temperature": 0.0, "avg_logprob": -0.16414116524361275, "compression_ratio": 1.4131736526946108, "no_speech_prob": 2.2125186660559848e-05}, {"id": 38, "seek": 24416, "start": 248.16, "end": 259.15999999999997, "text": " Which would be, let's take the bool one, and instead of just return x, why don't we go self.foo equals a.", "tokens": [3013, 576, 312, 11, 718, 311, 747, 264, 748, 401, 472, 11, 293, 2602, 295, 445, 2736, 2031, 11, 983, 500, 380, 321, 352, 2698, 13, 69, 1986, 6915, 257, 13], "temperature": 0.0, "avg_logprob": -0.16414116524361275, "compression_ratio": 1.4131736526946108, "no_speech_prob": 2.2125186660559848e-05}, {"id": 39, "seek": 24416, "start": 259.15999999999997, "end": 272.15999999999997, "text": " So in that case, we would expect to be able to go a.f false, for example.", "tokens": [407, 294, 300, 1389, 11, 321, 576, 2066, 281, 312, 1075, 281, 352, 257, 13, 69, 7908, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.16414116524361275, "compression_ratio": 1.4131736526946108, "no_speech_prob": 2.2125186660559848e-05}, {"id": 40, "seek": 27216, "start": 272.16, "end": 277.16, "text": " So that's going to call it with a boolean, which should call this version.", "tokens": [407, 300, 311, 516, 281, 818, 309, 365, 257, 748, 4812, 282, 11, 597, 820, 818, 341, 3037, 13], "temperature": 0.0, "avg_logprob": -0.10414470208657754, "compression_ratio": 1.4675324675324675, "no_speech_prob": 3.373626896063797e-05}, {"id": 41, "seek": 27216, "start": 277.16, "end": 286.16, "text": " So after that, we should find that a.foo is a.", "tokens": [407, 934, 300, 11, 321, 820, 915, 300, 257, 13, 69, 1986, 307, 257, 13], "temperature": 0.0, "avg_logprob": -0.10414470208657754, "compression_ratio": 1.4675324675324675, "no_speech_prob": 3.373626896063797e-05}, {"id": 42, "seek": 27216, "start": 286.16, "end": 288.16, "text": " Let's run that.", "tokens": [961, 311, 1190, 300, 13], "temperature": 0.0, "avg_logprob": -0.10414470208657754, "compression_ratio": 1.4675324675324675, "no_speech_prob": 3.373626896063797e-05}, {"id": 43, "seek": 27216, "start": 288.16, "end": 290.16, "text": " And it is, and it worked.", "tokens": [400, 309, 307, 11, 293, 309, 2732, 13], "temperature": 0.0, "avg_logprob": -0.10414470208657754, "compression_ratio": 1.4675324675324675, "no_speech_prob": 3.373626896063797e-05}, {"id": 44, "seek": 27216, "start": 290.16, "end": 300.16, "text": " So it is correctly binding, somehow, self to the, this object.", "tokens": [407, 309, 307, 8944, 17359, 11, 6063, 11, 2698, 281, 264, 11, 341, 2657, 13], "temperature": 0.0, "avg_logprob": -0.10414470208657754, "compression_ratio": 1.4675324675324675, "no_speech_prob": 3.373626896063797e-05}, {"id": 45, "seek": 30016, "start": 300.16, "end": 311.16, "text": " So the way that happens is a bit of magic, where when we call the back over in typeless batch, in dunder call,", "tokens": [407, 264, 636, 300, 2314, 307, 257, 857, 295, 5585, 11, 689, 562, 321, 818, 264, 646, 670, 294, 2125, 4272, 15245, 11, 294, 274, 6617, 818, 11], "temperature": 0.0, "avg_logprob": -0.15073689292458928, "compression_ratio": 1.7476635514018692, "no_speech_prob": 1.8342230760026723e-05}, {"id": 46, "seek": 30016, "start": 311.16, "end": 316.16, "text": " it checks for a special thing called self.instance, it stands for self.instance.", "tokens": [309, 13834, 337, 257, 2121, 551, 1219, 2698, 13, 13911, 719, 11, 309, 7382, 337, 2698, 13, 13911, 719, 13], "temperature": 0.0, "avg_logprob": -0.15073689292458928, "compression_ratio": 1.7476635514018692, "no_speech_prob": 1.8342230760026723e-05}, {"id": 47, "seek": 30016, "start": 316.16, "end": 321.16, "text": " It finds out whether this is an instance, in an instance of something.", "tokens": [467, 10704, 484, 1968, 341, 307, 364, 5197, 11, 294, 364, 5197, 295, 746, 13], "temperature": 0.0, "avg_logprob": -0.15073689292458928, "compression_ratio": 1.7476635514018692, "no_speech_prob": 1.8342230760026723e-05}, {"id": 48, "seek": 30016, "start": 321.16, "end": 328.16, "text": " And if it is, then self.instance is not none, in which case, instead of using the function that it's looked up,", "tokens": [400, 498, 309, 307, 11, 550, 2698, 13, 13911, 719, 307, 406, 6022, 11, 294, 597, 1389, 11, 2602, 295, 1228, 264, 2445, 300, 309, 311, 2956, 493, 11], "temperature": 0.0, "avg_logprob": -0.15073689292458928, "compression_ratio": 1.7476635514018692, "no_speech_prob": 1.8342230760026723e-05}, {"id": 49, "seek": 32816, "start": 328.16, "end": 334.16, "text": " it wraps it as a method.", "tokens": [309, 25831, 309, 382, 257, 3170, 13], "temperature": 0.0, "avg_logprob": -0.07878082613401775, "compression_ratio": 1.7096774193548387, "no_speech_prob": 1.8342545445193537e-05}, {"id": 50, "seek": 32816, "start": 334.16, "end": 343.16, "text": " So it's a method where the method is this function and the instance it's bound to is this instance.", "tokens": [407, 309, 311, 257, 3170, 689, 264, 3170, 307, 341, 2445, 293, 264, 5197, 309, 311, 5472, 281, 307, 341, 5197, 13], "temperature": 0.0, "avg_logprob": -0.07878082613401775, "compression_ratio": 1.7096774193548387, "no_speech_prob": 1.8342545445193537e-05}, {"id": 51, "seek": 32816, "start": 343.16, "end": 348.16, "text": " So this is how you turn, this is how you turn a function into a method.", "tokens": [407, 341, 307, 577, 291, 1261, 11, 341, 307, 577, 291, 1261, 257, 2445, 666, 257, 3170, 13], "temperature": 0.0, "avg_logprob": -0.07878082613401775, "compression_ratio": 1.7096774193548387, "no_speech_prob": 1.8342545445193537e-05}, {"id": 52, "seek": 32816, "start": 348.16, "end": 352.16, "text": " OK, so that's fine.", "tokens": [2264, 11, 370, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.07878082613401775, "compression_ratio": 1.7096774193548387, "no_speech_prob": 1.8342545445193537e-05}, {"id": 53, "seek": 32816, "start": 352.16, "end": 355.16, "text": " But how on earth does it know what self.inst is?", "tokens": [583, 577, 322, 4120, 775, 309, 458, 437, 2698, 13, 13911, 307, 30], "temperature": 0.0, "avg_logprob": -0.07878082613401775, "compression_ratio": 1.7096774193548387, "no_speech_prob": 1.8342545445193537e-05}, {"id": 54, "seek": 35516, "start": 355.16, "end": 360.16, "text": " Somehow self.inst has to be set to, in this case, a.", "tokens": [28357, 2698, 13, 13911, 575, 281, 312, 992, 281, 11, 294, 341, 1389, 11, 257, 13], "temperature": 0.0, "avg_logprob": -0.0972373514999578, "compression_ratio": 1.4887640449438202, "no_speech_prob": 8.480709948344156e-05}, {"id": 55, "seek": 35516, "start": 360.16, "end": 367.16, "text": " And the answer is that in Python, when you go a.f, like this,", "tokens": [400, 264, 1867, 307, 300, 294, 15329, 11, 562, 291, 352, 257, 13, 69, 11, 411, 341, 11], "temperature": 0.0, "avg_logprob": -0.0972373514999578, "compression_ratio": 1.4887640449438202, "no_speech_prob": 8.480709948344156e-05}, {"id": 56, "seek": 35516, "start": 367.16, "end": 372.16, "text": " it's actually going to call a special method of whatever class f is in.", "tokens": [309, 311, 767, 516, 281, 818, 257, 2121, 3170, 295, 2035, 1508, 283, 307, 294, 13], "temperature": 0.0, "avg_logprob": -0.0972373514999578, "compression_ratio": 1.4887640449438202, "no_speech_prob": 8.480709948344156e-05}, {"id": 57, "seek": 35516, "start": 372.16, "end": 376.16, "text": " And the method it calls is called dunder get.", "tokens": [400, 264, 3170, 309, 5498, 307, 1219, 274, 6617, 483, 13], "temperature": 0.0, "avg_logprob": -0.0972373514999578, "compression_ratio": 1.4887640449438202, "no_speech_prob": 8.480709948344156e-05}, {"id": 58, "seek": 35516, "start": 376.16, "end": 378.16, "text": " So we've never seen this before.", "tokens": [407, 321, 600, 1128, 1612, 341, 949, 13], "temperature": 0.0, "avg_logprob": -0.0972373514999578, "compression_ratio": 1.4887640449438202, "no_speech_prob": 8.480709948344156e-05}, {"id": 59, "seek": 37816, "start": 378.16, "end": 392.16, "text": " Dunder get, so this is again, remember the place to learn about all this stuff is the Python data model documentation.", "tokens": [413, 6617, 483, 11, 370, 341, 307, 797, 11, 1604, 264, 1081, 281, 1466, 466, 439, 341, 1507, 307, 264, 15329, 1412, 2316, 14333, 13], "temperature": 0.0, "avg_logprob": -0.0962174401354434, "compression_ratio": 1.4619883040935673, "no_speech_prob": 1.3006852896069176e-05}, {"id": 60, "seek": 37816, "start": 392.16, "end": 398.16, "text": " So we could look for dunder get.", "tokens": [407, 321, 727, 574, 337, 274, 6617, 483, 13], "temperature": 0.0, "avg_logprob": -0.0962174401354434, "compression_ratio": 1.4619883040935673, "no_speech_prob": 1.3006852896069176e-05}, {"id": 61, "seek": 37816, "start": 398.16, "end": 399.16, "text": " And here we are.", "tokens": [400, 510, 321, 366, 13], "temperature": 0.0, "avg_logprob": -0.0962174401354434, "compression_ratio": 1.4619883040935673, "no_speech_prob": 1.3006852896069176e-05}, {"id": 62, "seek": 37816, "start": 399.16, "end": 406.16, "text": " It's called to get the attribute of the owner class or an instance of that class.", "tokens": [467, 311, 1219, 281, 483, 264, 19667, 295, 264, 7289, 1508, 420, 364, 5197, 295, 300, 1508, 13], "temperature": 0.0, "avg_logprob": -0.0962174401354434, "compression_ratio": 1.4619883040935673, "no_speech_prob": 1.3006852896069176e-05}, {"id": 63, "seek": 40616, "start": 406.16, "end": 412.16, "text": " The instance is the instance that the attribute was accessed through.", "tokens": [440, 5197, 307, 264, 5197, 300, 264, 19667, 390, 34211, 807, 13], "temperature": 0.0, "avg_logprob": -0.09435674723456888, "compression_ratio": 1.6733333333333333, "no_speech_prob": 1.9222790797357447e-05}, {"id": 64, "seek": 40616, "start": 412.16, "end": 423.16, "text": " So in this case, dunder get is going to be called and it's going to be passed in as self,", "tokens": [407, 294, 341, 1389, 11, 274, 6617, 483, 307, 516, 281, 312, 1219, 293, 309, 311, 516, 281, 312, 4678, 294, 382, 2698, 11], "temperature": 0.0, "avg_logprob": -0.09435674723456888, "compression_ratio": 1.6733333333333333, "no_speech_prob": 1.9222790797357447e-05}, {"id": 65, "seek": 40616, "start": 423.16, "end": 429.16, "text": " the value of this f thing.", "tokens": [264, 2158, 295, 341, 283, 551, 13], "temperature": 0.0, "avg_logprob": -0.09435674723456888, "compression_ratio": 1.6733333333333333, "no_speech_prob": 1.9222790797357447e-05}, {"id": 66, "seek": 40616, "start": 429.16, "end": 433.16, "text": " But more interestingly, it's going to be also passed in as inst,", "tokens": [583, 544, 25873, 11, 309, 311, 516, 281, 312, 611, 4678, 294, 382, 1058, 11], "temperature": 0.0, "avg_logprob": -0.09435674723456888, "compression_ratio": 1.6733333333333333, "no_speech_prob": 1.9222790797357447e-05}, {"id": 67, "seek": 43316, "start": 433.16, "end": 436.16, "text": " the value of the thing before the dot a.", "tokens": [264, 2158, 295, 264, 551, 949, 264, 5893, 257, 13], "temperature": 0.0, "avg_logprob": -0.08037467491932404, "compression_ratio": 1.68944099378882, "no_speech_prob": 4.069332135259174e-05}, {"id": 68, "seek": 43316, "start": 436.16, "end": 440.16, "text": " And so that means we can just go self.inst equals inst.", "tokens": [400, 370, 300, 1355, 321, 393, 445, 352, 2698, 13, 13911, 6915, 1058, 13], "temperature": 0.0, "avg_logprob": -0.08037467491932404, "compression_ratio": 1.68944099378882, "no_speech_prob": 4.069332135259174e-05}, {"id": 69, "seek": 43316, "start": 440.16, "end": 448.16, "text": " And so now from now on, the type dispatch object knows what instance it's been called on.", "tokens": [400, 370, 586, 490, 586, 322, 11, 264, 2010, 36729, 2657, 3255, 437, 5197, 309, 311, 668, 1219, 322, 13], "temperature": 0.0, "avg_logprob": -0.08037467491932404, "compression_ratio": 1.68944099378882, "no_speech_prob": 4.069332135259174e-05}, {"id": 70, "seek": 43316, "start": 448.16, "end": 451.16, "text": " So we just go self.inst equals inst.", "tokens": [407, 321, 445, 352, 2698, 13, 13911, 6915, 1058, 13], "temperature": 0.0, "avg_logprob": -0.08037467491932404, "compression_ratio": 1.68944099378882, "no_speech_prob": 4.069332135259174e-05}, {"id": 71, "seek": 43316, "start": 451.16, "end": 458.16, "text": " And so then later on, when we call the function,", "tokens": [400, 370, 550, 1780, 322, 11, 562, 321, 818, 264, 2445, 11], "temperature": 0.0, "avg_logprob": -0.08037467491932404, "compression_ratio": 1.68944099378882, "no_speech_prob": 4.069332135259174e-05}, {"id": 72, "seek": 45816, "start": 458.16, "end": 463.16, "text": " we check if it's not none and indeed it's not none.", "tokens": [321, 1520, 498, 309, 311, 406, 6022, 293, 6451, 309, 311, 406, 6022, 13], "temperature": 0.0, "avg_logprob": -0.08257232863327553, "compression_ratio": 1.5497630331753554, "no_speech_prob": 7.071716936479788e-06}, {"id": 73, "seek": 45816, "start": 463.16, "end": 466.16, "text": " And so then we wrap it as a method.", "tokens": [400, 370, 550, 321, 7019, 309, 382, 257, 3170, 13], "temperature": 0.0, "avg_logprob": -0.08257232863327553, "compression_ratio": 1.5497630331753554, "no_speech_prob": 7.071716936479788e-06}, {"id": 74, "seek": 45816, "start": 466.16, "end": 476.16, "text": " So that's again, like just super nice Python extensible data model that lets us do anything we want to.", "tokens": [407, 300, 311, 797, 11, 411, 445, 1687, 1481, 15329, 1279, 30633, 1412, 2316, 300, 6653, 505, 360, 1340, 321, 528, 281, 13], "temperature": 0.0, "avg_logprob": -0.08257232863327553, "compression_ratio": 1.5497630331753554, "no_speech_prob": 7.071716936479788e-06}, {"id": 75, "seek": 45816, "start": 476.16, "end": 486.16, "text": " And so in this case, this is kind of wonderful magic where, you know, I was really surprised this was possible when I learned about it.", "tokens": [400, 370, 294, 341, 1389, 11, 341, 307, 733, 295, 3715, 5585, 689, 11, 291, 458, 11, 286, 390, 534, 6100, 341, 390, 1944, 562, 286, 3264, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.08257232863327553, "compression_ratio": 1.5497630331753554, "no_speech_prob": 7.071716936479788e-06}, {"id": 76, "seek": 48616, "start": 486.16, "end": 495.16, "text": " I really wanted it to work, which I thought it would be able to have both functions and methods and have my new dispatch automatically handle both.", "tokens": [286, 534, 1415, 309, 281, 589, 11, 597, 286, 1194, 309, 576, 312, 1075, 281, 362, 1293, 6828, 293, 7150, 293, 362, 452, 777, 36729, 6772, 4813, 1293, 13], "temperature": 0.0, "avg_logprob": -0.12789534032344818, "compression_ratio": 1.4759036144578312, "no_speech_prob": 8.397671081183944e-06}, {"id": 77, "seek": 48616, "start": 495.16, "end": 500.16, "text": " And then it does. This is how this is how it does.", "tokens": [400, 550, 309, 775, 13, 639, 307, 577, 341, 307, 577, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.12789534032344818, "compression_ratio": 1.4759036144578312, "no_speech_prob": 8.397671081183944e-06}, {"id": 78, "seek": 48616, "start": 500.16, "end": 506.16, "text": " So that is, yeah, I think that's pretty great.", "tokens": [407, 300, 307, 11, 1338, 11, 286, 519, 300, 311, 1238, 869, 13], "temperature": 0.0, "avg_logprob": -0.12789534032344818, "compression_ratio": 1.4759036144578312, "no_speech_prob": 8.397671081183944e-06}, {"id": 79, "seek": 50616, "start": 506.16, "end": 521.1600000000001, "text": " OK, so something that I added with Sylvia this morning actually was we added one more thing to our transform class, which is as well as encodes and decodes.", "tokens": [2264, 11, 370, 746, 300, 286, 3869, 365, 33349, 11617, 341, 2446, 767, 390, 321, 3869, 472, 544, 551, 281, 527, 4088, 1508, 11, 597, 307, 382, 731, 382, 2058, 4789, 293, 979, 4789, 13], "temperature": 0.0, "avg_logprob": -0.13217433761147893, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.5935947885736823e-05}, {"id": 80, "seek": 50616, "start": 521.1600000000001, "end": 528.1600000000001, "text": " We've also added setups. So setups will be called by setup as before.", "tokens": [492, 600, 611, 3869, 46832, 13, 407, 46832, 486, 312, 1219, 538, 8657, 382, 949, 13], "temperature": 0.0, "avg_logprob": -0.13217433761147893, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.5935947885736823e-05}, {"id": 81, "seek": 50616, "start": 528.1600000000001, "end": 534.1600000000001, "text": " But now setups is a type dispatch object.", "tokens": [583, 586, 46832, 307, 257, 2010, 36729, 2657, 13], "temperature": 0.0, "avg_logprob": -0.13217433761147893, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.5935947885736823e-05}, {"id": 82, "seek": 53416, "start": 534.16, "end": 542.16, "text": " So the codes changed a tiny bit. I've put encodes, decodes and setups into this couple.", "tokens": [407, 264, 14211, 3105, 257, 5870, 857, 13, 286, 600, 829, 2058, 4789, 11, 979, 4789, 293, 46832, 666, 341, 1916, 13], "temperature": 0.0, "avg_logprob": -0.11080310151383684, "compression_ratio": 1.518918918918919, "no_speech_prob": 5.337896709534107e-06}, {"id": 83, "seek": 53416, "start": 542.16, "end": 549.16, "text": " And so now we go through for name in those three methods and we create our type dispatch objects.", "tokens": [400, 370, 586, 321, 352, 807, 337, 1315, 294, 729, 1045, 7150, 293, 321, 1884, 527, 2010, 36729, 6565, 13], "temperature": 0.0, "avg_logprob": -0.11080310151383684, "compression_ratio": 1.518918918918919, "no_speech_prob": 5.337896709534107e-06}, {"id": 84, "seek": 53416, "start": 549.16, "end": 559.16, "text": " That's all in the meta class. And the reason for that is that we're starting to work on rapids.", "tokens": [663, 311, 439, 294, 264, 19616, 1508, 13, 400, 264, 1778, 337, 300, 307, 300, 321, 434, 2891, 281, 589, 322, 5099, 3742, 13], "temperature": 0.0, "avg_logprob": -0.11080310151383684, "compression_ratio": 1.518918918918919, "no_speech_prob": 5.337896709534107e-06}, {"id": 85, "seek": 55916, "start": 559.16, "end": 572.16, "text": " Rapids, if you haven't seen it, is a very nice project from Nvidia, which provides something a bit like pandas, but that runs on the GPU.", "tokens": [16184, 3742, 11, 498, 291, 2378, 380, 1612, 309, 11, 307, 257, 588, 1481, 1716, 490, 46284, 11, 597, 6417, 746, 257, 857, 411, 4565, 296, 11, 457, 300, 6676, 322, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.12091926906419836, "compression_ratio": 1.4636871508379887, "no_speech_prob": 9.972668522095773e-06}, {"id": 86, "seek": 55916, "start": 572.16, "end": 584.16, "text": " And it's only a bit like pandas. It's not pandas. So we basically want to create tabular transforms that work automatically,", "tokens": [400, 309, 311, 787, 257, 857, 411, 4565, 296, 13, 467, 311, 406, 4565, 296, 13, 407, 321, 1936, 528, 281, 1884, 4421, 1040, 35592, 300, 589, 6772, 11], "temperature": 0.0, "avg_logprob": -0.12091926906419836, "compression_ratio": 1.4636871508379887, "no_speech_prob": 9.972668522095773e-06}, {"id": 87, "seek": 58416, "start": 584.16, "end": 592.16, "text": " correctly on rapids data frames and on pandas data frames. And that includes we want the setup to work appropriately.", "tokens": [8944, 322, 5099, 3742, 1412, 12083, 293, 322, 4565, 296, 1412, 12083, 13, 400, 300, 5974, 321, 528, 264, 8657, 281, 589, 23505, 13], "temperature": 0.0, "avg_logprob": -0.13266684557940508, "compression_ratio": 1.5245901639344261, "no_speech_prob": 6.240670245460933e-06}, {"id": 88, "seek": 58416, "start": 592.16, "end": 599.16, "text": " And so now thanks to this, we can now do that.", "tokens": [400, 370, 586, 3231, 281, 341, 11, 321, 393, 586, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.13266684557940508, "compression_ratio": 1.5245901639344261, "no_speech_prob": 6.240670245460933e-06}, {"id": 89, "seek": 58416, "start": 599.16, "end": 611.16, "text": " So. Yeah, so that's why we just added that. So some slight changes to the code from last time. They're very small.", "tokens": [407, 13, 865, 11, 370, 300, 311, 983, 321, 445, 3869, 300, 13, 407, 512, 4036, 2962, 281, 264, 3089, 490, 1036, 565, 13, 814, 434, 588, 1359, 13], "temperature": 0.0, "avg_logprob": -0.13266684557940508, "compression_ratio": 1.5245901639344261, "no_speech_prob": 6.240670245460933e-06}, {"id": 90, "seek": 61116, "start": 611.16, "end": 619.16, "text": " All right. Well, let's keep working back through the details of these things that use this then, shall we?", "tokens": [1057, 558, 13, 1042, 11, 718, 311, 1066, 1364, 646, 807, 264, 4365, 295, 613, 721, 300, 764, 341, 550, 11, 4393, 321, 30], "temperature": 0.0, "avg_logprob": -0.2019062445197307, "compression_ratio": 1.4855491329479769, "no_speech_prob": 2.318643055332359e-05}, {"id": 91, "seek": 61116, "start": 619.16, "end": 629.16, "text": " So we've done zero two. Oops. And so let's now look at zero.", "tokens": [407, 321, 600, 1096, 4018, 732, 13, 21726, 13, 400, 370, 718, 311, 586, 574, 412, 4018, 13], "temperature": 0.0, "avg_logprob": -0.2019062445197307, "compression_ratio": 1.4855491329479769, "no_speech_prob": 2.318643055332359e-05}, {"id": 92, "seek": 61116, "start": 629.16, "end": 640.16, "text": " So in zero three, we can import that thing we just made, the code dot data dot transform.", "tokens": [407, 294, 4018, 1045, 11, 321, 393, 974, 300, 551, 321, 445, 1027, 11, 264, 3089, 5893, 1412, 5893, 4088, 13], "temperature": 0.0, "avg_logprob": -0.2019062445197307, "compression_ratio": 1.4855491329479769, "no_speech_prob": 2.318643055332359e-05}, {"id": 93, "seek": 64016, "start": 640.16, "end": 650.16, "text": " And what we're going to do is we're going to create pipeline. So pipeline.", "tokens": [400, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 1884, 15517, 13, 407, 15517, 13], "temperature": 0.0, "avg_logprob": -0.1921499945900657, "compression_ratio": 1.5514705882352942, "no_speech_prob": 1.3210923498263583e-05}, {"id": 94, "seek": 64016, "start": 650.16, "end": 664.16, "text": " As usual, it's probably easiest just to look at the tests. So a pipeline is an object which is so we just create a pipeline called pipe.", "tokens": [1018, 7713, 11, 309, 311, 1391, 12889, 445, 281, 574, 412, 264, 6921, 13, 407, 257, 15517, 307, 364, 2657, 597, 307, 370, 321, 445, 1884, 257, 15517, 1219, 11240, 13], "temperature": 0.0, "avg_logprob": -0.1921499945900657, "compression_ratio": 1.5514705882352942, "no_speech_prob": 1.3210923498263583e-05}, {"id": 95, "seek": 66416, "start": 664.16, "end": 678.16, "text": " And it's an object which is callable. So this is an empty pipeline. So an empty pipeline always returns whatever it's given.", "tokens": [400, 309, 311, 364, 2657, 597, 307, 818, 712, 13, 407, 341, 307, 364, 6707, 15517, 13, 407, 364, 6707, 15517, 1009, 11247, 2035, 309, 311, 2212, 13], "temperature": 0.0, "avg_logprob": -0.10752732306718826, "compression_ratio": 1.305263157894737, "no_speech_prob": 2.2602871467825025e-06}, {"id": 96, "seek": 67816, "start": 678.16, "end": 695.16, "text": " It has the same as item behavior as transforms do. And so if you say set as item on a pipeline, it will set the as item Boolean in all of the transforms in that pipeline to that value.", "tokens": [467, 575, 264, 912, 382, 3174, 5223, 382, 35592, 360, 13, 400, 370, 498, 291, 584, 992, 382, 3174, 322, 257, 15517, 11, 309, 486, 992, 264, 382, 3174, 23351, 28499, 294, 439, 295, 264, 35592, 294, 300, 15517, 281, 300, 2158, 13], "temperature": 0.0, "avg_logprob": -0.08679077499791195, "compression_ratio": 1.6727272727272726, "no_speech_prob": 6.144013241282664e-06}, {"id": 97, "seek": 67816, "start": 695.16, "end": 702.16, "text": " So in this case, we're going to say false. And so if we set it to false, then we pass in a.", "tokens": [407, 294, 341, 1389, 11, 321, 434, 516, 281, 584, 7908, 13, 400, 370, 498, 321, 992, 309, 281, 7908, 11, 550, 321, 1320, 294, 257, 13], "temperature": 0.0, "avg_logprob": -0.08679077499791195, "compression_ratio": 1.6727272727272726, "no_speech_prob": 6.144013241282664e-06}, {"id": 98, "seek": 70216, "start": 702.16, "end": 715.16, "text": " Topple confirm back a couple. So where it gets more interesting is if we create a pipeline.", "tokens": [8840, 781, 9064, 646, 257, 1916, 13, 407, 689, 309, 2170, 544, 1880, 307, 498, 321, 1884, 257, 15517, 13], "temperature": 0.0, "avg_logprob": -0.26345683253088664, "compression_ratio": 1.3596491228070176, "no_speech_prob": 5.682399660145165e-06}, {"id": 99, "seek": 70216, "start": 715.16, "end": 721.16, "text": " That does something. So here's a pipeline with two.", "tokens": [663, 775, 746, 13, 407, 510, 311, 257, 15517, 365, 732, 13], "temperature": 0.0, "avg_logprob": -0.26345683253088664, "compression_ratio": 1.3596491228070176, "no_speech_prob": 5.682399660145165e-06}, {"id": 100, "seek": 70216, "start": 721.16, "end": 724.16, "text": " Transforms.", "tokens": [27938, 82, 13], "temperature": 0.0, "avg_logprob": -0.26345683253088664, "compression_ratio": 1.3596491228070176, "no_speech_prob": 5.682399660145165e-06}, {"id": 101, "seek": 72416, "start": 724.16, "end": 733.16, "text": " The first transform is something which encoding turns something into an int decoding turns its back into a float.", "tokens": [440, 700, 4088, 307, 746, 597, 43430, 4523, 746, 666, 364, 560, 979, 8616, 4523, 1080, 646, 666, 257, 15706, 13], "temperature": 0.0, "avg_logprob": -0.10215068507838894, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.7502272385172546e-05}, {"id": 102, "seek": 72416, "start": 733.16, "end": 740.16, "text": " And these are the capital versions, capitalized versions, which are the fast AI versions that know how to show themselves.", "tokens": [400, 613, 366, 264, 4238, 9606, 11, 4238, 1602, 9606, 11, 597, 366, 264, 2370, 7318, 9606, 300, 458, 577, 281, 855, 2969, 13], "temperature": 0.0, "avg_logprob": -0.10215068507838894, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.7502272385172546e-05}, {"id": 103, "seek": 72416, "start": 740.16, "end": 747.16, "text": " One of the main reasons we use it in tests is to make sure that the retaining types works properly.", "tokens": [1485, 295, 264, 2135, 4112, 321, 764, 309, 294, 6921, 307, 281, 652, 988, 300, 264, 34936, 3467, 1985, 6108, 13], "temperature": 0.0, "avg_logprob": -0.10215068507838894, "compression_ratio": 1.6633663366336633, "no_speech_prob": 1.7502272385172546e-05}, {"id": 104, "seek": 74716, "start": 747.16, "end": 757.16, "text": " And then here's a transform, which simply remember you can create a transform either by subclassing or by.", "tokens": [400, 550, 510, 311, 257, 4088, 11, 597, 2935, 1604, 291, 393, 1884, 257, 4088, 2139, 538, 1422, 11665, 278, 420, 538, 13], "temperature": 0.0, "avg_logprob": -0.17593635656894782, "compression_ratio": 1.8066298342541436, "no_speech_prob": 8.013335900614038e-06}, {"id": 105, "seek": 74716, "start": 757.16, "end": 767.16, "text": " That's getting so here's a transform, which is going to set encodes to this negative function and the decodes to the same negative function.", "tokens": [663, 311, 1242, 370, 510, 311, 257, 4088, 11, 597, 307, 516, 281, 992, 2058, 4789, 281, 341, 3671, 2445, 293, 264, 979, 4789, 281, 264, 912, 3671, 2445, 13], "temperature": 0.0, "avg_logprob": -0.17593635656894782, "compression_ratio": 1.8066298342541436, "no_speech_prob": 8.013335900614038e-06}, {"id": 106, "seek": 74716, "start": 767.16, "end": 774.16, "text": " So there's two transforms. And so those are the two transforms in our pipeline.", "tokens": [407, 456, 311, 732, 35592, 13, 400, 370, 729, 366, 264, 732, 35592, 294, 527, 15517, 13], "temperature": 0.0, "avg_logprob": -0.17593635656894782, "compression_ratio": 1.8066298342541436, "no_speech_prob": 8.013335900614038e-06}, {"id": 107, "seek": 77416, "start": 774.16, "end": 777.16, "text": " So if we start with the value two point zero.", "tokens": [407, 498, 321, 722, 365, 264, 2158, 732, 935, 4018, 13], "temperature": 0.0, "avg_logprob": -0.13847208571159977, "compression_ratio": 1.8275862068965518, "no_speech_prob": 1.4738822756044101e-05}, {"id": 108, "seek": 77416, "start": 777.16, "end": 781.16, "text": " And then we.", "tokens": [400, 550, 321, 13], "temperature": 0.0, "avg_logprob": -0.13847208571159977, "compression_ratio": 1.8275862068965518, "no_speech_prob": 1.4738822756044101e-05}, {"id": 109, "seek": 77416, "start": 781.16, "end": 786.16, "text": " Pop that into our pipeline.", "tokens": [10215, 300, 666, 527, 15517, 13], "temperature": 0.0, "avg_logprob": -0.13847208571159977, "compression_ratio": 1.8275862068965518, "no_speech_prob": 1.4738822756044101e-05}, {"id": 110, "seek": 77416, "start": 786.16, "end": 795.16, "text": " Then the first thing it's going to do is make it a negative because that's the first thing in a pipeline that's going to become negative two.", "tokens": [1396, 264, 700, 551, 309, 311, 516, 281, 360, 307, 652, 309, 257, 3671, 570, 300, 311, 264, 700, 551, 294, 257, 15517, 300, 311, 516, 281, 1813, 3671, 732, 13], "temperature": 0.0, "avg_logprob": -0.13847208571159977, "compression_ratio": 1.8275862068965518, "no_speech_prob": 1.4738822756044101e-05}, {"id": 111, "seek": 77416, "start": 795.16, "end": 800.16, "text": " And then the second thing it's going to do is it's going to turn it into a capital I int.", "tokens": [400, 550, 264, 1150, 551, 309, 311, 516, 281, 360, 307, 309, 311, 516, 281, 1261, 309, 666, 257, 4238, 286, 560, 13], "temperature": 0.0, "avg_logprob": -0.13847208571159977, "compression_ratio": 1.8275862068965518, "no_speech_prob": 1.4738822756044101e-05}, {"id": 112, "seek": 80016, "start": 800.16, "end": 807.16, "text": " So test equals type checks that this is equal to this and not only is it equal, but exactly the same type.", "tokens": [407, 1500, 6915, 2010, 13834, 300, 341, 307, 2681, 281, 341, 293, 406, 787, 307, 309, 2681, 11, 457, 2293, 264, 912, 2010, 13], "temperature": 0.0, "avg_logprob": -0.13341926775480573, "compression_ratio": 1.7117117117117118, "no_speech_prob": 9.080325071408879e-06}, {"id": 113, "seek": 80016, "start": 807.16, "end": 810.16, "text": " So this is now into minus two as expected.", "tokens": [407, 341, 307, 586, 666, 3175, 732, 382, 5176, 13], "temperature": 0.0, "avg_logprob": -0.13341926775480573, "compression_ratio": 1.7117117117117118, "no_speech_prob": 9.080325071408879e-06}, {"id": 114, "seek": 80016, "start": 810.16, "end": 815.16, "text": " And so you can see what the pipeline is doing is it's calling.", "tokens": [400, 370, 291, 393, 536, 437, 264, 15517, 307, 884, 307, 309, 311, 5141, 13], "temperature": 0.0, "avg_logprob": -0.13341926775480573, "compression_ratio": 1.7117117117117118, "no_speech_prob": 9.080325071408879e-06}, {"id": 115, "seek": 80016, "start": 815.16, "end": 818.16, "text": " Taking this value and it calls this function first.", "tokens": [17837, 341, 2158, 293, 309, 5498, 341, 2445, 700, 13], "temperature": 0.0, "avg_logprob": -0.13341926775480573, "compression_ratio": 1.7117117117117118, "no_speech_prob": 9.080325071408879e-06}, {"id": 116, "seek": 80016, "start": 818.16, "end": 826.16, "text": " So that makes it negative two point oh and then this function second, which makes it capital I int of negative two.", "tokens": [407, 300, 1669, 309, 3671, 732, 935, 1954, 293, 550, 341, 2445, 1150, 11, 597, 1669, 309, 4238, 286, 560, 295, 3671, 732, 13], "temperature": 0.0, "avg_logprob": -0.13341926775480573, "compression_ratio": 1.7117117117117118, "no_speech_prob": 9.080325071408879e-06}, {"id": 117, "seek": 82616, "start": 826.16, "end": 831.16, "text": " And that's all it's doing. So that is function composition.", "tokens": [400, 300, 311, 439, 309, 311, 884, 13, 407, 300, 307, 2445, 12686, 13], "temperature": 0.0, "avg_logprob": -0.13950854760629158, "compression_ratio": 1.6919642857142858, "no_speech_prob": 1.952552338480018e-05}, {"id": 118, "seek": 82616, "start": 831.16, "end": 837.16, "text": " When we call pipe decode, it will simply call the decodes of each thing in the reverse order.", "tokens": [1133, 321, 818, 11240, 979, 1429, 11, 309, 486, 2935, 818, 264, 979, 4789, 295, 1184, 551, 294, 264, 9943, 1668, 13], "temperature": 0.0, "avg_logprob": -0.13950854760629158, "compression_ratio": 1.6919642857142858, "no_speech_prob": 1.952552338480018e-05}, {"id": 119, "seek": 82616, "start": 837.16, "end": 843.16, "text": " So if we start with T, which we know is int negative two and we call decode on the pipe.", "tokens": [407, 498, 321, 722, 365, 314, 11, 597, 321, 458, 307, 560, 3671, 732, 293, 321, 818, 979, 1429, 322, 264, 11240, 13], "temperature": 0.0, "avg_logprob": -0.13950854760629158, "compression_ratio": 1.6919642857142858, "no_speech_prob": 1.952552338480018e-05}, {"id": 120, "seek": 82616, "start": 843.16, "end": 848.16, "text": " The first thing I'll do, we go in transform to this one decodes.", "tokens": [440, 700, 551, 286, 603, 360, 11, 321, 352, 294, 4088, 281, 341, 472, 979, 4789, 13], "temperature": 0.0, "avg_logprob": -0.13950854760629158, "compression_ratio": 1.6919642857142858, "no_speech_prob": 1.952552338480018e-05}, {"id": 121, "seek": 82616, "start": 848.16, "end": 850.16, "text": " So it'll turn it back into a float.", "tokens": [407, 309, 603, 1261, 309, 646, 666, 257, 15706, 13], "temperature": 0.0, "avg_logprob": -0.13950854760629158, "compression_ratio": 1.6919642857142858, "no_speech_prob": 1.952552338480018e-05}, {"id": 122, "seek": 82616, "start": 850.16, "end": 855.16, "text": " That's now negative two point zero.", "tokens": [663, 311, 586, 3671, 732, 935, 4018, 13], "temperature": 0.0, "avg_logprob": -0.13950854760629158, "compression_ratio": 1.6919642857142858, "no_speech_prob": 1.952552338480018e-05}, {"id": 123, "seek": 85516, "start": 855.16, "end": 864.16, "text": " And then the second thing it will do is to go to decodes of negative transform, which is just again negative.", "tokens": [400, 550, 264, 1150, 551, 309, 486, 360, 307, 281, 352, 281, 979, 4789, 295, 3671, 4088, 11, 597, 307, 445, 797, 3671, 13], "temperature": 0.0, "avg_logprob": -0.15785105816729658, "compression_ratio": 1.5574712643678161, "no_speech_prob": 7.4111267167609185e-06}, {"id": 124, "seek": 85516, "start": 864.16, "end": 869.16, "text": " And so that's going to be a capital F float two point oh.", "tokens": [400, 370, 300, 311, 516, 281, 312, 257, 4238, 479, 15706, 732, 935, 1954, 13], "temperature": 0.0, "avg_logprob": -0.15785105816729658, "compression_ratio": 1.5574712643678161, "no_speech_prob": 7.4111267167609185e-06}, {"id": 125, "seek": 85516, "start": 869.16, "end": 874.16, "text": " Confirm. Yes, it is capital F float two point oh.", "tokens": [11701, 3692, 13, 1079, 11, 309, 307, 4238, 479, 15706, 732, 935, 1954, 13], "temperature": 0.0, "avg_logprob": -0.15785105816729658, "compression_ratio": 1.5574712643678161, "no_speech_prob": 7.4111267167609185e-06}, {"id": 126, "seek": 85516, "start": 874.16, "end": 879.16, "text": " So how does that work? Let's take a look at pipeline.", "tokens": [407, 577, 775, 300, 589, 30, 961, 311, 747, 257, 574, 412, 15517, 13], "temperature": 0.0, "avg_logprob": -0.15785105816729658, "compression_ratio": 1.5574712643678161, "no_speech_prob": 7.4111267167609185e-06}, {"id": 127, "seek": 87916, "start": 879.16, "end": 889.16, "text": " The key thing that pipeline does when we call dunder call is it calls a function called compose transforms.", "tokens": [440, 2141, 551, 300, 15517, 775, 562, 321, 818, 274, 6617, 818, 307, 309, 5498, 257, 2445, 1219, 35925, 35592, 13], "temperature": 0.0, "avg_logprob": -0.09563178893847343, "compression_ratio": 1.7027027027027026, "no_speech_prob": 8.139591045619454e-06}, {"id": 128, "seek": 87916, "start": 889.16, "end": 897.16, "text": " Passing in the value, which in this case was the value two point oh.", "tokens": [10319, 278, 294, 264, 2158, 11, 597, 294, 341, 1389, 390, 264, 2158, 732, 935, 1954, 13], "temperature": 0.0, "avg_logprob": -0.09563178893847343, "compression_ratio": 1.7027027027027026, "no_speech_prob": 8.139591045619454e-06}, {"id": 129, "seek": 87916, "start": 897.16, "end": 901.16, "text": " And it's going to pass in the list of functions.", "tokens": [400, 309, 311, 516, 281, 1320, 294, 264, 1329, 295, 6828, 13], "temperature": 0.0, "avg_logprob": -0.09563178893847343, "compression_ratio": 1.7027027027027026, "no_speech_prob": 8.139591045619454e-06}, {"id": 130, "seek": 87916, "start": 901.16, "end": 907.16, "text": " And so that list of functions is just the thing that we pass to the pipeline constructor.", "tokens": [400, 370, 300, 1329, 295, 6828, 307, 445, 264, 551, 300, 321, 1320, 281, 264, 15517, 47479, 13], "temperature": 0.0, "avg_logprob": -0.09563178893847343, "compression_ratio": 1.7027027027027026, "no_speech_prob": 8.139591045619454e-06}, {"id": 131, "seek": 90716, "start": 907.16, "end": 916.16, "text": " So we just set self dot F's to a list of those functions.", "tokens": [407, 321, 445, 992, 2698, 5893, 479, 311, 281, 257, 1329, 295, 729, 6828, 13], "temperature": 0.0, "avg_logprob": -0.14946770969825454, "compression_ratio": 1.5722543352601157, "no_speech_prob": 1.777829311322421e-05}, {"id": 132, "seek": 90716, "start": 916.16, "end": 920.16, "text": " We will turn them into transforms for those that aren't transforms.", "tokens": [492, 486, 1261, 552, 666, 35592, 337, 729, 300, 3212, 380, 35592, 13], "temperature": 0.0, "avg_logprob": -0.14946770969825454, "compression_ratio": 1.5722543352601157, "no_speech_prob": 1.777829311322421e-05}, {"id": 133, "seek": 90716, "start": 920.16, "end": 924.16, "text": " And we will sort them by order.", "tokens": [400, 321, 486, 1333, 552, 538, 1668, 13], "temperature": 0.0, "avg_logprob": -0.14946770969825454, "compression_ratio": 1.5722543352601157, "no_speech_prob": 1.777829311322421e-05}, {"id": 134, "seek": 90716, "start": 924.16, "end": 926.16, "text": " If they have an order.", "tokens": [759, 436, 362, 364, 1668, 13], "temperature": 0.0, "avg_logprob": -0.14946770969825454, "compression_ratio": 1.5722543352601157, "no_speech_prob": 1.777829311322421e-05}, {"id": 135, "seek": 90716, "start": 926.16, "end": 931.16, "text": " So compose transforms is the key thing that's actually doing the work.", "tokens": [407, 35925, 35592, 307, 264, 2141, 551, 300, 311, 767, 884, 264, 589, 13], "temperature": 0.0, "avg_logprob": -0.14946770969825454, "compression_ratio": 1.5722543352601157, "no_speech_prob": 1.777829311322421e-05}, {"id": 136, "seek": 90716, "start": 931.16, "end": 933.16, "text": " And so that's.", "tokens": [400, 370, 300, 311, 13], "temperature": 0.0, "avg_logprob": -0.14946770969825454, "compression_ratio": 1.5722543352601157, "no_speech_prob": 1.777829311322421e-05}, {"id": 137, "seek": 90716, "start": 933.16, "end": 934.16, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.14946770969825454, "compression_ratio": 1.5722543352601157, "no_speech_prob": 1.777829311322421e-05}, {"id": 138, "seek": 93416, "start": 934.16, "end": 942.16, "text": " Compose transforms that's going to take some value to calculate the composed functions on and some list of transforms.", "tokens": [6620, 541, 35592, 300, 311, 516, 281, 747, 512, 2158, 281, 8873, 264, 18204, 6828, 322, 293, 512, 1329, 295, 35592, 13], "temperature": 0.0, "avg_logprob": -0.11289866765340169, "compression_ratio": 1.6032608695652173, "no_speech_prob": 2.0784968000953086e-05}, {"id": 139, "seek": 93416, "start": 942.16, "end": 947.16, "text": " And are we encoding or decoding?", "tokens": [400, 366, 321, 43430, 420, 979, 8616, 30], "temperature": 0.0, "avg_logprob": -0.11289866765340169, "compression_ratio": 1.6032608695652173, "no_speech_prob": 2.0784968000953086e-05}, {"id": 140, "seek": 93416, "start": 947.16, "end": 951.16, "text": " Are we going in forward order or reverse order?", "tokens": [2014, 321, 516, 294, 2128, 1668, 420, 9943, 1668, 30], "temperature": 0.0, "avg_logprob": -0.11289866765340169, "compression_ratio": 1.6032608695652173, "no_speech_prob": 2.0784968000953086e-05}, {"id": 141, "seek": 93416, "start": 951.16, "end": 957.16, "text": " And this is basically a pretty classic function composition loop.", "tokens": [400, 341, 307, 1936, 257, 1238, 7230, 2445, 12686, 6367, 13], "temperature": 0.0, "avg_logprob": -0.11289866765340169, "compression_ratio": 1.6032608695652173, "no_speech_prob": 2.0784968000953086e-05}, {"id": 142, "seek": 93416, "start": 957.16, "end": 960.16, "text": " You go through each function.", "tokens": [509, 352, 807, 1184, 2445, 13], "temperature": 0.0, "avg_logprob": -0.11289866765340169, "compression_ratio": 1.6032608695652173, "no_speech_prob": 2.0784968000953086e-05}, {"id": 143, "seek": 96016, "start": 960.16, "end": 965.16, "text": " You call it and you replace your current value with the result.", "tokens": [509, 818, 309, 293, 291, 7406, 428, 2190, 2158, 365, 264, 1874, 13], "temperature": 0.0, "avg_logprob": -0.12010233086275768, "compression_ratio": 1.5816326530612246, "no_speech_prob": 5.093646450404776e-06}, {"id": 144, "seek": 96016, "start": 965.16, "end": 968.16, "text": " And then you go back and do that again.", "tokens": [400, 550, 291, 352, 646, 293, 360, 300, 797, 13], "temperature": 0.0, "avg_logprob": -0.12010233086275768, "compression_ratio": 1.5816326530612246, "no_speech_prob": 5.093646450404776e-06}, {"id": 145, "seek": 96016, "start": 968.16, "end": 971.16, "text": " Keep doing that for everything in the.", "tokens": [5527, 884, 300, 337, 1203, 294, 264, 13], "temperature": 0.0, "avg_logprob": -0.12010233086275768, "compression_ratio": 1.5816326530612246, "no_speech_prob": 5.093646450404776e-06}, {"id": 146, "seek": 96016, "start": 971.16, "end": 975.16, "text": " In the list of functions.", "tokens": [682, 264, 1329, 295, 6828, 13], "temperature": 0.0, "avg_logprob": -0.12010233086275768, "compression_ratio": 1.5816326530612246, "no_speech_prob": 5.093646450404776e-06}, {"id": 147, "seek": 96016, "start": 975.16, "end": 978.16, "text": " And so you can see you can use compose transforms.", "tokens": [400, 370, 291, 393, 536, 291, 393, 764, 35925, 35592, 13], "temperature": 0.0, "avg_logprob": -0.12010233086275768, "compression_ratio": 1.5816326530612246, "no_speech_prob": 5.093646450404776e-06}, {"id": 148, "seek": 96016, "start": 978.16, "end": 980.16, "text": " So here's some examples of some functions.", "tokens": [407, 510, 311, 512, 5110, 295, 512, 6828, 13], "temperature": 0.0, "avg_logprob": -0.12010233086275768, "compression_ratio": 1.5816326530612246, "no_speech_prob": 5.093646450404776e-06}, {"id": 149, "seek": 96016, "start": 980.16, "end": 982.16, "text": " So anytime you want to know how something like.", "tokens": [407, 13038, 291, 528, 281, 458, 577, 746, 411, 13], "temperature": 0.0, "avg_logprob": -0.12010233086275768, "compression_ratio": 1.5816326530612246, "no_speech_prob": 5.093646450404776e-06}, {"id": 150, "seek": 98216, "start": 982.16, "end": 993.16, "text": " It's used internally like this works you can see the tests for the thing that's used internally before you worry about how it's being used in for example pipeline.", "tokens": [467, 311, 1143, 19501, 411, 341, 1985, 291, 393, 536, 264, 6921, 337, 264, 551, 300, 311, 1143, 19501, 949, 291, 3292, 466, 577, 309, 311, 885, 1143, 294, 337, 1365, 15517, 13], "temperature": 0.0, "avg_logprob": -0.12403141902043269, "compression_ratio": 1.7197452229299364, "no_speech_prob": 9.665944162406959e-06}, {"id": 151, "seek": 98216, "start": 993.16, "end": 1000.16, "text": " So here's the test of composing some plain functions.", "tokens": [407, 510, 311, 264, 1500, 295, 715, 6110, 512, 11121, 6828, 13], "temperature": 0.0, "avg_logprob": -0.12403141902043269, "compression_ratio": 1.7197452229299364, "no_speech_prob": 9.665944162406959e-06}, {"id": 152, "seek": 98216, "start": 1000.16, "end": 1006.16, "text": " And then here's a test of composing some transforms.", "tokens": [400, 550, 510, 311, 257, 1500, 295, 715, 6110, 512, 35592, 13], "temperature": 0.0, "avg_logprob": -0.12403141902043269, "compression_ratio": 1.7197452229299364, "no_speech_prob": 9.665944162406959e-06}, {"id": 153, "seek": 100616, "start": 1006.16, "end": 1012.16, "text": " Because you can always use functions as transforms.", "tokens": [1436, 291, 393, 1009, 764, 6828, 382, 35592, 13], "temperature": 0.0, "avg_logprob": -0.14834202109993277, "compression_ratio": 1.6337209302325582, "no_speech_prob": 1.1842793355754111e-05}, {"id": 154, "seek": 100616, "start": 1012.16, "end": 1018.16, "text": " And in this case as long as we're not going to pass in is an equals false.", "tokens": [400, 294, 341, 1389, 382, 938, 382, 321, 434, 406, 516, 281, 1320, 294, 307, 364, 6915, 7908, 13], "temperature": 0.0, "avg_logprob": -0.14834202109993277, "compression_ratio": 1.6337209302325582, "no_speech_prob": 1.1842793355754111e-05}, {"id": 155, "seek": 100616, "start": 1018.16, "end": 1024.1599999999999, "text": " It's not going to try and do anything other than just call the callable.", "tokens": [467, 311, 406, 516, 281, 853, 293, 360, 1340, 661, 813, 445, 818, 264, 818, 712, 13], "temperature": 0.0, "avg_logprob": -0.14834202109993277, "compression_ratio": 1.6337209302325582, "no_speech_prob": 1.1842793355754111e-05}, {"id": 156, "seek": 100616, "start": 1024.1599999999999, "end": 1029.1599999999999, "text": " So that's how the pipeline does call.", "tokens": [407, 300, 311, 577, 264, 15517, 775, 818, 13], "temperature": 0.0, "avg_logprob": -0.14834202109993277, "compression_ratio": 1.6337209302325582, "no_speech_prob": 1.1842793355754111e-05}, {"id": 157, "seek": 100616, "start": 1029.1599999999999, "end": 1032.1599999999999, "text": " And it's also how the pipeline does decode.", "tokens": [400, 309, 311, 611, 577, 264, 15517, 775, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.14834202109993277, "compression_ratio": 1.6337209302325582, "no_speech_prob": 1.1842793355754111e-05}, {"id": 158, "seek": 103216, "start": 1032.16, "end": 1041.16, "text": " It's just going to call compose transforms and say is encode is false and reverse equals true.", "tokens": [467, 311, 445, 516, 281, 818, 35925, 35592, 293, 584, 307, 2058, 1429, 307, 7908, 293, 9943, 6915, 2074, 13], "temperature": 0.0, "avg_logprob": -0.21512801719434332, "compression_ratio": 1.5636363636363637, "no_speech_prob": 1.1659355550364126e-05}, {"id": 159, "seek": 103216, "start": 1041.16, "end": 1046.16, "text": " So that's that's the simple bit there.", "tokens": [407, 300, 311, 300, 311, 264, 2199, 857, 456, 13], "temperature": 0.0, "avg_logprob": -0.21512801719434332, "compression_ratio": 1.5636363636363637, "no_speech_prob": 1.1659355550364126e-05}, {"id": 160, "seek": 103216, "start": 1046.16, "end": 1052.16, "text": " Where it gets interesting is when we call pipeline show.", "tokens": [2305, 309, 2170, 1880, 307, 562, 321, 818, 15517, 855, 13], "temperature": 0.0, "avg_logprob": -0.21512801719434332, "compression_ratio": 1.5636363636363637, "no_speech_prob": 1.1659355550364126e-05}, {"id": 161, "seek": 103216, "start": 1052.16, "end": 1058.16, "text": " What is pipeline show do so intuitively what it does is it takes T.", "tokens": [708, 307, 15517, 855, 360, 370, 46506, 437, 309, 775, 307, 309, 2516, 314, 13], "temperature": 0.0, "avg_logprob": -0.21512801719434332, "compression_ratio": 1.5636363636363637, "no_speech_prob": 1.1659355550364126e-05}, {"id": 162, "seek": 105816, "start": 1058.16, "end": 1064.16, "text": " And remember T is a capital I int minus two.", "tokens": [400, 1604, 314, 307, 257, 4238, 286, 560, 3175, 732, 13], "temperature": 0.0, "avg_logprob": -0.15130669730050222, "compression_ratio": 1.4829931972789117, "no_speech_prob": 4.56593534181593e-06}, {"id": 163, "seek": 105816, "start": 1064.16, "end": 1076.16, "text": " And it decodes it one transform at a time in reverse order until it gets to a data type that has a show method.", "tokens": [400, 309, 979, 4789, 309, 472, 4088, 412, 257, 565, 294, 9943, 1668, 1826, 309, 2170, 281, 257, 1412, 2010, 300, 575, 257, 855, 3170, 13], "temperature": 0.0, "avg_logprob": -0.15130669730050222, "compression_ratio": 1.4829931972789117, "no_speech_prob": 4.56593534181593e-06}, {"id": 164, "seek": 105816, "start": 1076.16, "end": 1078.16, "text": " Data type that is showable.", "tokens": [11888, 2010, 300, 307, 855, 712, 13], "temperature": 0.0, "avg_logprob": -0.15130669730050222, "compression_ratio": 1.4829931972789117, "no_speech_prob": 4.56593534181593e-06}, {"id": 165, "seek": 105816, "start": 1078.16, "end": 1083.16, "text": " Now in this case a capital I int.", "tokens": [823, 294, 341, 1389, 257, 4238, 286, 560, 13], "temperature": 0.0, "avg_logprob": -0.15130669730050222, "compression_ratio": 1.4829931972789117, "no_speech_prob": 4.56593534181593e-06}, {"id": 166, "seek": 108316, "start": 1083.16, "end": 1090.16, "text": " Is already showable a capital I int.", "tokens": [1119, 1217, 855, 712, 257, 4238, 286, 560, 13], "temperature": 0.0, "avg_logprob": -0.16796344757080078, "compression_ratio": 1.6217948717948718, "no_speech_prob": 2.8409200240275823e-05}, {"id": 167, "seek": 108316, "start": 1090.16, "end": 1091.16, "text": " Int.", "tokens": [5681, 13], "temperature": 0.0, "avg_logprob": -0.16796344757080078, "compression_ratio": 1.6217948717948718, "no_speech_prob": 2.8409200240275823e-05}, {"id": 168, "seek": 108316, "start": 1091.16, "end": 1093.16, "text": " It's sort of a definition.", "tokens": [467, 311, 1333, 295, 257, 7123, 13], "temperature": 0.0, "avg_logprob": -0.16796344757080078, "compression_ratio": 1.6217948717948718, "no_speech_prob": 2.8409200240275823e-05}, {"id": 169, "seek": 108316, "start": 1093.16, "end": 1101.16, "text": " Capital I int is just an int that inherits from both small int and show title.", "tokens": [21502, 286, 560, 307, 445, 364, 560, 300, 9484, 1208, 490, 1293, 1359, 560, 293, 855, 4876, 13], "temperature": 0.0, "avg_logprob": -0.16796344757080078, "compression_ratio": 1.6217948717948718, "no_speech_prob": 2.8409200240275823e-05}, {"id": 170, "seek": 108316, "start": 1101.16, "end": 1104.16, "text": " And show and it has no other code in it.", "tokens": [400, 855, 293, 309, 575, 572, 661, 3089, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.16796344757080078, "compression_ratio": 1.6217948717948718, "no_speech_prob": 2.8409200240275823e-05}, {"id": 171, "seek": 108316, "start": 1104.16, "end": 1110.16, "text": " And show title remember is just a class which has a show method.", "tokens": [400, 855, 4876, 1604, 307, 445, 257, 1508, 597, 575, 257, 855, 3170, 13], "temperature": 0.0, "avg_logprob": -0.16796344757080078, "compression_ratio": 1.6217948717948718, "no_speech_prob": 2.8409200240275823e-05}, {"id": 172, "seek": 111016, "start": 1110.16, "end": 1114.16, "text": " And shows it by calling show title.", "tokens": [400, 3110, 309, 538, 5141, 855, 4876, 13], "temperature": 0.0, "avg_logprob": -0.09134310382907673, "compression_ratio": 1.5488721804511278, "no_speech_prob": 1.9524699382600375e-05}, {"id": 173, "seek": 111016, "start": 1114.16, "end": 1122.16, "text": " And show title by the way if you're passing in a no context at all it just prints whatever it's passed in.", "tokens": [400, 855, 4876, 538, 264, 636, 498, 291, 434, 8437, 294, 257, 572, 4319, 412, 439, 309, 445, 22305, 2035, 309, 311, 4678, 294, 13], "temperature": 0.0, "avg_logprob": -0.09134310382907673, "compression_ratio": 1.5488721804511278, "no_speech_prob": 1.9524699382600375e-05}, {"id": 174, "seek": 111016, "start": 1122.16, "end": 1130.16, "text": " And if you pass in a plot it'll show it as a title on the plot.", "tokens": [400, 498, 291, 1320, 294, 257, 7542, 309, 603, 855, 309, 382, 257, 4876, 322, 264, 7542, 13], "temperature": 0.0, "avg_logprob": -0.09134310382907673, "compression_ratio": 1.5488721804511278, "no_speech_prob": 1.9524699382600375e-05}, {"id": 175, "seek": 113016, "start": 1130.16, "end": 1142.16, "text": " So show title three as you can see.", "tokens": [407, 855, 4876, 1045, 382, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.15309129263225355, "compression_ratio": 1.2474226804123711, "no_speech_prob": 4.157145667704754e-06}, {"id": 176, "seek": 113016, "start": 1142.16, "end": 1146.16, "text": " So in this case pipe.show T.", "tokens": [407, 294, 341, 1389, 11240, 13, 34436, 314, 13], "temperature": 0.0, "avg_logprob": -0.15309129263225355, "compression_ratio": 1.2474226804123711, "no_speech_prob": 4.157145667704754e-06}, {"id": 177, "seek": 113016, "start": 1146.16, "end": 1153.16, "text": " And remember T is minus two simply prints out minus two.", "tokens": [400, 1604, 314, 307, 3175, 732, 2935, 22305, 484, 3175, 732, 13], "temperature": 0.0, "avg_logprob": -0.15309129263225355, "compression_ratio": 1.2474226804123711, "no_speech_prob": 4.157145667704754e-06}, {"id": 178, "seek": 115316, "start": 1153.16, "end": 1161.16, "text": " And the reason for that is that because this is already something that's showable so there's no decoding that needs to be done.", "tokens": [400, 264, 1778, 337, 300, 307, 300, 570, 341, 307, 1217, 746, 300, 311, 855, 712, 370, 456, 311, 572, 979, 8616, 300, 2203, 281, 312, 1096, 13], "temperature": 0.0, "avg_logprob": -0.11292901532403354, "compression_ratio": 1.674641148325359, "no_speech_prob": 1.1659156371024437e-05}, {"id": 179, "seek": 115316, "start": 1161.16, "end": 1169.16, "text": " For those of you didn't see it earlier notice that the way I test that this prints something out is I make that a lambda.", "tokens": [1171, 729, 295, 291, 994, 380, 536, 309, 3071, 3449, 300, 264, 636, 286, 1500, 300, 341, 22305, 746, 484, 307, 286, 652, 300, 257, 13607, 13], "temperature": 0.0, "avg_logprob": -0.11292901532403354, "compression_ratio": 1.674641148325359, "no_speech_prob": 1.1659156371024437e-05}, {"id": 180, "seek": 115316, "start": 1169.16, "end": 1171.16, "text": " Which takes no arguments.", "tokens": [3013, 2516, 572, 12869, 13], "temperature": 0.0, "avg_logprob": -0.11292901532403354, "compression_ratio": 1.674641148325359, "no_speech_prob": 1.1659156371024437e-05}, {"id": 181, "seek": 115316, "start": 1171.16, "end": 1177.16, "text": " And that's the first thing that you pass to this test stood it out method.", "tokens": [400, 300, 311, 264, 700, 551, 300, 291, 1320, 281, 341, 1500, 9371, 309, 484, 3170, 13], "temperature": 0.0, "avg_logprob": -0.11292901532403354, "compression_ratio": 1.674641148325359, "no_speech_prob": 1.1659156371024437e-05}, {"id": 182, "seek": 117716, "start": 1177.16, "end": 1184.16, "text": " And that tests that this function when run prints that to stood it out.", "tokens": [400, 300, 6921, 300, 341, 2445, 562, 1190, 22305, 300, 281, 9371, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.07193754753976497, "compression_ratio": 1.4316546762589928, "no_speech_prob": 3.785214630624978e-06}, {"id": 183, "seek": 117716, "start": 1184.16, "end": 1194.16, "text": " That's a nice way to check what's happening with our show methods.", "tokens": [663, 311, 257, 1481, 636, 281, 1520, 437, 311, 2737, 365, 527, 855, 7150, 13], "temperature": 0.0, "avg_logprob": -0.07193754753976497, "compression_ratio": 1.4316546762589928, "no_speech_prob": 3.785214630624978e-06}, {"id": 184, "seek": 117716, "start": 1194.16, "end": 1202.16, "text": " When as item is false in our pipeline and we call pipe.show.", "tokens": [1133, 382, 3174, 307, 7908, 294, 527, 15517, 293, 321, 818, 11240, 13, 34436, 13], "temperature": 0.0, "avg_logprob": -0.07193754753976497, "compression_ratio": 1.4316546762589928, "no_speech_prob": 3.785214630624978e-06}, {"id": 185, "seek": 120216, "start": 1202.16, "end": 1211.16, "text": " Pipe.show will call show on each element of the tuple that's passed in.", "tokens": [430, 6527, 13, 34436, 486, 818, 855, 322, 1184, 4478, 295, 264, 2604, 781, 300, 311, 4678, 294, 13], "temperature": 0.0, "avg_logprob": -0.09625524740952712, "compression_ratio": 1.95625, "no_speech_prob": 6.747829047526466e-06}, {"id": 186, "seek": 120216, "start": 1211.16, "end": 1221.16, "text": " Because remember when as item equals false in transforms it's basically saying you should apply the transform to each element of a tuple that's passed in.", "tokens": [1436, 1604, 562, 382, 3174, 6915, 7908, 294, 35592, 309, 311, 1936, 1566, 291, 820, 3079, 264, 4088, 281, 1184, 4478, 295, 257, 2604, 781, 300, 311, 4678, 294, 13], "temperature": 0.0, "avg_logprob": -0.09625524740952712, "compression_ratio": 1.95625, "no_speech_prob": 6.747829047526466e-06}, {"id": 187, "seek": 120216, "start": 1221.16, "end": 1226.16, "text": " And so when you show it you should show on each element of the tuple that's passed in.", "tokens": [400, 370, 562, 291, 855, 309, 291, 820, 855, 322, 1184, 4478, 295, 264, 2604, 781, 300, 311, 4678, 294, 13], "temperature": 0.0, "avg_logprob": -0.09625524740952712, "compression_ratio": 1.95625, "no_speech_prob": 6.747829047526466e-06}, {"id": 188, "seek": 122616, "start": 1226.16, "end": 1232.16, "text": " And the reason for that is for stuff like when you're doing show batch.", "tokens": [400, 264, 1778, 337, 300, 307, 337, 1507, 411, 562, 291, 434, 884, 855, 15245, 13], "temperature": 0.0, "avg_logprob": -0.13597891223964406, "compression_ratio": 1.6845637583892616, "no_speech_prob": 8.800673640507739e-06}, {"id": 189, "seek": 122616, "start": 1232.16, "end": 1240.16, "text": " Unlike the pets data set you've got two things in the tuple of the batch you've got the images and you've got the labels.", "tokens": [17657, 264, 19897, 1412, 992, 291, 600, 658, 732, 721, 294, 264, 2604, 781, 295, 264, 15245, 291, 600, 658, 264, 5267, 293, 291, 600, 658, 264, 16949, 13], "temperature": 0.0, "avg_logprob": -0.13597891223964406, "compression_ratio": 1.6845637583892616, "no_speech_prob": 8.800673640507739e-06}, {"id": 190, "seek": 122616, "start": 1240.16, "end": 1245.16, "text": " And so we want to show the image and then show the label.", "tokens": [400, 370, 321, 528, 281, 855, 264, 3256, 293, 550, 855, 264, 7645, 13], "temperature": 0.0, "avg_logprob": -0.13597891223964406, "compression_ratio": 1.6845637583892616, "no_speech_prob": 8.800673640507739e-06}, {"id": 191, "seek": 124516, "start": 1245.16, "end": 1256.16, "text": " So in this case when I say pipe.show and pass in 1 comma 2.", "tokens": [407, 294, 341, 1389, 562, 286, 584, 11240, 13, 34436, 293, 1320, 294, 502, 22117, 568, 13], "temperature": 0.0, "avg_logprob": -0.12014412534409676, "compression_ratio": 1.6369863013698631, "no_speech_prob": 6.43893417873187e-06}, {"id": 192, "seek": 124516, "start": 1256.16, "end": 1261.16, "text": " And that's going to print minus 1 and then print minus 2.", "tokens": [400, 300, 311, 516, 281, 4482, 3175, 502, 293, 550, 4482, 3175, 568, 13], "temperature": 0.0, "avg_logprob": -0.12014412534409676, "compression_ratio": 1.6369863013698631, "no_speech_prob": 6.43893417873187e-06}, {"id": 193, "seek": 124516, "start": 1261.16, "end": 1266.16, "text": " It's calling show on each element of that tuple.", "tokens": [467, 311, 5141, 855, 322, 1184, 4478, 295, 300, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.12014412534409676, "compression_ratio": 1.6369863013698631, "no_speech_prob": 6.43893417873187e-06}, {"id": 194, "seek": 124516, "start": 1266.16, "end": 1271.16, "text": " And notice it's also applied the pipeline to each element of that tuple.", "tokens": [400, 3449, 309, 311, 611, 6456, 264, 15517, 281, 1184, 4478, 295, 300, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.12014412534409676, "compression_ratio": 1.6369863013698631, "no_speech_prob": 6.43893417873187e-06}, {"id": 195, "seek": 127116, "start": 1271.16, "end": 1278.16, "text": " So each one has been negated and turned into an int.", "tokens": [407, 1184, 472, 575, 668, 2485, 770, 293, 3574, 666, 364, 560, 13], "temperature": 0.0, "avg_logprob": -0.11414825505223768, "compression_ratio": 1.3819444444444444, "no_speech_prob": 1.6280409909086302e-06}, {"id": 196, "seek": 127116, "start": 1278.16, "end": 1285.16, "text": " OK. So that's pipeline and so show.", "tokens": [2264, 13, 407, 300, 311, 15517, 293, 370, 855, 13], "temperature": 0.0, "avg_logprob": -0.11414825505223768, "compression_ratio": 1.3819444444444444, "no_speech_prob": 1.6280409909086302e-06}, {"id": 197, "seek": 127116, "start": 1285.16, "end": 1291.16, "text": " Is going to go through our functions in reverse order.", "tokens": [1119, 516, 281, 352, 807, 527, 6828, 294, 9943, 1668, 13], "temperature": 0.0, "avg_logprob": -0.11414825505223768, "compression_ratio": 1.3819444444444444, "no_speech_prob": 1.6280409909086302e-06}, {"id": 198, "seek": 127116, "start": 1291.16, "end": 1298.16, "text": " It'll see if it can show it without doing any decoding.", "tokens": [467, 603, 536, 498, 309, 393, 855, 309, 1553, 884, 604, 979, 8616, 13], "temperature": 0.0, "avg_logprob": -0.11414825505223768, "compression_ratio": 1.3819444444444444, "no_speech_prob": 1.6280409909086302e-06}, {"id": 199, "seek": 129816, "start": 1298.16, "end": 1301.16, "text": " And if it can then I'm done.", "tokens": [400, 498, 309, 393, 550, 286, 478, 1096, 13], "temperature": 0.0, "avg_logprob": -0.17617534455798922, "compression_ratio": 1.6524390243902438, "no_speech_prob": 6.853992999822367e-06}, {"id": 200, "seek": 129816, "start": 1301.16, "end": 1307.16, "text": " If it can't it will try to decode it with this function and then it will go back and try again.", "tokens": [759, 309, 393, 380, 309, 486, 853, 281, 979, 1429, 309, 365, 341, 2445, 293, 550, 309, 486, 352, 646, 293, 853, 797, 13], "temperature": 0.0, "avg_logprob": -0.17617534455798922, "compression_ratio": 1.6524390243902438, "no_speech_prob": 6.853992999822367e-06}, {"id": 201, "seek": 129816, "start": 1307.16, "end": 1309.16, "text": " See if we can show it now.", "tokens": [3008, 498, 321, 393, 855, 309, 586, 13], "temperature": 0.0, "avg_logprob": -0.17617534455798922, "compression_ratio": 1.6524390243902438, "no_speech_prob": 6.853992999822367e-06}, {"id": 202, "seek": 129816, "start": 1309.16, "end": 1314.16, "text": " And if it can't go to the next part the next earlier function in the pipeline.", "tokens": [400, 498, 309, 393, 380, 352, 281, 264, 958, 644, 264, 958, 3071, 2445, 294, 264, 15517, 13], "temperature": 0.0, "avg_logprob": -0.17617534455798922, "compression_ratio": 1.6524390243902438, "no_speech_prob": 6.853992999822367e-06}, {"id": 203, "seek": 129816, "start": 1314.16, "end": 1318.16, "text": " Decode. Can I show it now? And so forth.", "tokens": [12427, 1429, 13, 1664, 286, 855, 309, 586, 30, 400, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.17617534455798922, "compression_ratio": 1.6524390243902438, "no_speech_prob": 6.853992999822367e-06}, {"id": 204, "seek": 131816, "start": 1318.16, "end": 1331.16, "text": " And so all underscore show is doing is it's just checking whether as item is true or not.", "tokens": [400, 370, 439, 37556, 855, 307, 884, 307, 309, 311, 445, 8568, 1968, 382, 3174, 307, 2074, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.1008375397434941, "compression_ratio": 1.5968992248062015, "no_speech_prob": 3.5007465157832485e-06}, {"id": 205, "seek": 131816, "start": 1331.16, "end": 1341.16, "text": " And then it's checking that whether there is a show method for this type or not.", "tokens": [400, 550, 309, 311, 8568, 300, 1968, 456, 307, 257, 855, 3170, 337, 341, 2010, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.1008375397434941, "compression_ratio": 1.5968992248062015, "no_speech_prob": 3.5007465157832485e-06}, {"id": 206, "seek": 131816, "start": 1341.16, "end": 1343.16, "text": " For everything in that type or not.", "tokens": [1171, 1203, 294, 300, 2010, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.1008375397434941, "compression_ratio": 1.5968992248062015, "no_speech_prob": 3.5007465157832485e-06}, {"id": 207, "seek": 134316, "start": 1343.16, "end": 1351.16, "text": " And then if there is then it's going to show them.", "tokens": [400, 550, 498, 456, 307, 550, 309, 311, 516, 281, 855, 552, 13], "temperature": 0.0, "avg_logprob": -0.08228407654107786, "compression_ratio": 1.391304347826087, "no_speech_prob": 1.5779105524416082e-06}, {"id": 208, "seek": 134316, "start": 1351.16, "end": 1355.16, "text": " OK. So not super exciting code.", "tokens": [2264, 13, 407, 406, 1687, 4670, 3089, 13], "temperature": 0.0, "avg_logprob": -0.08228407654107786, "compression_ratio": 1.391304347826087, "no_speech_prob": 1.5779105524416082e-06}, {"id": 209, "seek": 134316, "start": 1355.16, "end": 1370.16, "text": " But conceptually interesting this idea of being able to decode and show things turns out to be super helpful.", "tokens": [583, 3410, 671, 1880, 341, 1558, 295, 885, 1075, 281, 979, 1429, 293, 855, 721, 4523, 484, 281, 312, 1687, 4961, 13], "temperature": 0.0, "avg_logprob": -0.08228407654107786, "compression_ratio": 1.391304347826087, "no_speech_prob": 1.5779105524416082e-06}, {"id": 210, "seek": 137016, "start": 1370.16, "end": 1379.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.13715584189803512, "compression_ratio": 1.4928571428571429, "no_speech_prob": 2.885107278416399e-05}, {"id": 211, "seek": 137016, "start": 1379.16, "end": 1383.16, "text": " So here you can see where.", "tokens": [407, 510, 291, 393, 536, 689, 13], "temperature": 0.0, "avg_logprob": -0.13715584189803512, "compression_ratio": 1.4928571428571429, "no_speech_prob": 2.885107278416399e-05}, {"id": 212, "seek": 137016, "start": 1383.16, "end": 1390.16, "text": " Creating some. Functions some of which only operate on certain types.", "tokens": [40002, 512, 13, 11166, 3916, 512, 295, 597, 787, 9651, 322, 1629, 3467, 13], "temperature": 0.0, "avg_logprob": -0.13715584189803512, "compression_ratio": 1.4928571428571429, "no_speech_prob": 2.885107278416399e-05}, {"id": 213, "seek": 137016, "start": 1390.16, "end": 1396.16, "text": " And so here we've got a function one function that operates on tensor image one that operates on everything.", "tokens": [400, 370, 510, 321, 600, 658, 257, 2445, 472, 2445, 300, 22577, 322, 40863, 3256, 472, 300, 22577, 322, 1203, 13], "temperature": 0.0, "avg_logprob": -0.13715584189803512, "compression_ratio": 1.4928571428571429, "no_speech_prob": 2.885107278416399e-05}, {"id": 214, "seek": 139616, "start": 1396.16, "end": 1400.16, "text": " One that operates on PIO images.", "tokens": [1485, 300, 22577, 322, 430, 15167, 5267, 13], "temperature": 0.0, "avg_logprob": -0.1936487511022767, "compression_ratio": 1.5389610389610389, "no_speech_prob": 1.0129661859537009e-05}, {"id": 215, "seek": 139616, "start": 1400.16, "end": 1408.16, "text": " And so here's something which is going to call image open resize.", "tokens": [400, 370, 510, 311, 746, 597, 307, 516, 281, 818, 3256, 1269, 50069, 13], "temperature": 0.0, "avg_logprob": -0.1936487511022767, "compression_ratio": 1.5389610389610389, "no_speech_prob": 1.0129661859537009e-05}, {"id": 216, "seek": 139616, "start": 1408.16, "end": 1414.16, "text": " And then turn that into a tensor image and then.", "tokens": [400, 550, 1261, 300, 666, 257, 40863, 3256, 293, 550, 13], "temperature": 0.0, "avg_logprob": -0.1936487511022767, "compression_ratio": 1.5389610389610389, "no_speech_prob": 1.0129661859537009e-05}, {"id": 217, "seek": 139616, "start": 1414.16, "end": 1418.16, "text": " Take it's negative.", "tokens": [3664, 309, 311, 3671, 13], "temperature": 0.0, "avg_logprob": -0.1936487511022767, "compression_ratio": 1.5389610389610389, "no_speech_prob": 1.0129661859537009e-05}, {"id": 218, "seek": 139616, "start": 1418.16, "end": 1424.16, "text": " So we should find at the end of all that that we have a tensor image.", "tokens": [407, 321, 820, 915, 412, 264, 917, 295, 439, 300, 300, 321, 362, 257, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1936487511022767, "compression_ratio": 1.5389610389610389, "no_speech_prob": 1.0129661859537009e-05}, {"id": 219, "seek": 142416, "start": 1424.16, "end": 1426.16, "text": " Which we do.", "tokens": [3013, 321, 360, 13], "temperature": 0.0, "avg_logprob": -0.0896516394341129, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.5070943593163975e-05}, {"id": 220, "seek": 142416, "start": 1426.16, "end": 1429.16, "text": " And we check that we have the right values.", "tokens": [400, 321, 1520, 300, 321, 362, 264, 558, 4190, 13], "temperature": 0.0, "avg_logprob": -0.0896516394341129, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.5070943593163975e-05}, {"id": 221, "seek": 142416, "start": 1429.16, "end": 1433.16, "text": " If we get rid of the F1 piece.", "tokens": [759, 321, 483, 3973, 295, 264, 479, 16, 2522, 13], "temperature": 0.0, "avg_logprob": -0.0896516394341129, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.5070943593163975e-05}, {"id": 222, "seek": 142416, "start": 1433.16, "end": 1437.16, "text": " So we just open the image and then turn it into a tensor image.", "tokens": [407, 321, 445, 1269, 264, 3256, 293, 550, 1261, 309, 666, 257, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.0896516394341129, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.5070943593163975e-05}, {"id": 223, "seek": 142416, "start": 1437.16, "end": 1439.16, "text": " We should be able to show it.", "tokens": [492, 820, 312, 1075, 281, 855, 309, 13], "temperature": 0.0, "avg_logprob": -0.0896516394341129, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.5070943593163975e-05}, {"id": 224, "seek": 142416, "start": 1439.16, "end": 1444.16, "text": " So that's making sure that we can.", "tokens": [407, 300, 311, 1455, 988, 300, 321, 393, 13], "temperature": 0.0, "avg_logprob": -0.0896516394341129, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.5070943593163975e-05}, {"id": 225, "seek": 142416, "start": 1444.16, "end": 1446.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.0896516394341129, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.5070943593163975e-05}, {"id": 226, "seek": 142416, "start": 1446.16, "end": 1450.16, "text": " So now's a good time to talk about filtering.", "tokens": [407, 586, 311, 257, 665, 565, 281, 751, 466, 30822, 13], "temperature": 0.0, "avg_logprob": -0.0896516394341129, "compression_ratio": 1.4696132596685083, "no_speech_prob": 2.5070943593163975e-05}, {"id": 227, "seek": 145016, "start": 1450.16, "end": 1462.16, "text": " Actually not. Let's talk about filtering after we talk about the data source class.", "tokens": [5135, 406, 13, 961, 311, 751, 466, 30822, 934, 321, 751, 466, 264, 1412, 4009, 1508, 13], "temperature": 0.0, "avg_logprob": -0.14843222901627823, "compression_ratio": 1.212962962962963, "no_speech_prob": 3.943732735933736e-05}, {"id": 228, "seek": 145016, "start": 1462.16, "end": 1471.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.14843222901627823, "compression_ratio": 1.212962962962963, "no_speech_prob": 3.943732735933736e-05}, {"id": 229, "seek": 145016, "start": 1471.16, "end": 1474.16, "text": " So we've kind of covered these ones before.", "tokens": [407, 321, 600, 733, 295, 5343, 613, 2306, 949, 13], "temperature": 0.0, "avg_logprob": -0.14843222901627823, "compression_ratio": 1.212962962962963, "no_speech_prob": 3.943732735933736e-05}, {"id": 230, "seek": 147416, "start": 1474.16, "end": 1484.16, "text": " So then a transformed list is something where we're going to pass in a list of items.", "tokens": [407, 550, 257, 16894, 1329, 307, 746, 689, 321, 434, 516, 281, 1320, 294, 257, 1329, 295, 4754, 13], "temperature": 0.0, "avg_logprob": -0.07711346644275593, "compression_ratio": 1.6434782608695653, "no_speech_prob": 6.339078481687466e-06}, {"id": 231, "seek": 147416, "start": 1484.16, "end": 1488.16, "text": " And a list of transforms.", "tokens": [400, 257, 1329, 295, 35592, 13], "temperature": 0.0, "avg_logprob": -0.07711346644275593, "compression_ratio": 1.6434782608695653, "no_speech_prob": 6.339078481687466e-06}, {"id": 232, "seek": 147416, "start": 1488.16, "end": 1496.16, "text": " And it's going to create a pipeline with those transforms.", "tokens": [400, 309, 311, 516, 281, 1884, 257, 15517, 365, 729, 35592, 13], "temperature": 0.0, "avg_logprob": -0.07711346644275593, "compression_ratio": 1.6434782608695653, "no_speech_prob": 6.339078481687466e-06}, {"id": 233, "seek": 147416, "start": 1496.16, "end": 1502.16, "text": " And it's going to.", "tokens": [400, 309, 311, 516, 281, 13], "temperature": 0.0, "avg_logprob": -0.07711346644275593, "compression_ratio": 1.6434782608695653, "no_speech_prob": 6.339078481687466e-06}, {"id": 234, "seek": 150216, "start": 1502.16, "end": 1506.16, "text": " So it's a subclass of triphoned base which is a subclass of L.", "tokens": [407, 309, 311, 257, 1422, 11665, 295, 1376, 950, 19009, 3096, 597, 307, 257, 1422, 11665, 295, 441, 13], "temperature": 0.0, "avg_logprob": -0.0930468919800549, "compression_ratio": 1.5649717514124293, "no_speech_prob": 7.646262929483783e-06}, {"id": 235, "seek": 150216, "start": 1506.16, "end": 1510.16, "text": " So it's just passing the items back up to the L constructor.", "tokens": [407, 309, 311, 445, 8437, 264, 4754, 646, 493, 281, 264, 441, 47479, 13], "temperature": 0.0, "avg_logprob": -0.0930468919800549, "compression_ratio": 1.5649717514124293, "no_speech_prob": 7.646262929483783e-06}, {"id": 236, "seek": 150216, "start": 1510.16, "end": 1515.16, "text": " So it's going to basically be a list of items.", "tokens": [407, 309, 311, 516, 281, 1936, 312, 257, 1329, 295, 4754, 13], "temperature": 0.0, "avg_logprob": -0.0930468919800549, "compression_ratio": 1.5649717514124293, "no_speech_prob": 7.646262929483783e-06}, {"id": 237, "seek": 150216, "start": 1515.16, "end": 1520.16, "text": " But it's also got this pipeline in it.", "tokens": [583, 309, 311, 611, 658, 341, 15517, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.0930468919800549, "compression_ratio": 1.5649717514124293, "no_speech_prob": 7.646262929483783e-06}, {"id": 238, "seek": 150216, "start": 1520.16, "end": 1526.16, "text": " And so this is where you can learn some new interesting stuff in L.", "tokens": [400, 370, 341, 307, 689, 291, 393, 1466, 512, 777, 1880, 1507, 294, 441, 13], "temperature": 0.0, "avg_logprob": -0.0930468919800549, "compression_ratio": 1.5649717514124293, "no_speech_prob": 7.646262929483783e-06}, {"id": 239, "seek": 152616, "start": 1526.16, "end": 1537.16, "text": " Because L actually lets us create, it's kind of designed to let us create some more interesting types of collections.", "tokens": [1436, 441, 767, 6653, 505, 1884, 11, 309, 311, 733, 295, 4761, 281, 718, 505, 1884, 512, 544, 1880, 3467, 295, 16641, 13], "temperature": 0.0, "avg_logprob": -0.14497320702735414, "compression_ratio": 1.3576642335766422, "no_speech_prob": 4.3568434193730354e-06}, {"id": 240, "seek": 152616, "start": 1537.16, "end": 1548.16, "text": " So in this case, you can see what happens in L when I call get item.", "tokens": [407, 294, 341, 1389, 11, 291, 393, 536, 437, 2314, 294, 441, 562, 286, 818, 483, 3174, 13], "temperature": 0.0, "avg_logprob": -0.14497320702735414, "compression_ratio": 1.3576642335766422, "no_speech_prob": 4.3568434193730354e-06}, {"id": 241, "seek": 154816, "start": 1548.16, "end": 1556.16, "text": " It actually calls self dot underscore gets if you have an iterator of indexes.", "tokens": [467, 767, 5498, 2698, 5893, 37556, 2170, 498, 291, 362, 364, 17138, 1639, 295, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.13885552353329128, "compression_ratio": 1.6011904761904763, "no_speech_prob": 1.1189313227077946e-06}, {"id": 242, "seek": 154816, "start": 1556.16, "end": 1560.16, "text": " Otherwise it calls self dot underscore get.", "tokens": [10328, 309, 5498, 2698, 5893, 37556, 483, 13], "temperature": 0.0, "avg_logprob": -0.13885552353329128, "compression_ratio": 1.6011904761904763, "no_speech_prob": 1.1189313227077946e-06}, {"id": 243, "seek": 154816, "start": 1560.16, "end": 1565.16, "text": " And self dot underscore get by default, assuming there's no ILOCK.", "tokens": [400, 2698, 5893, 37556, 483, 538, 7576, 11, 11926, 456, 311, 572, 286, 20184, 9419, 13], "temperature": 0.0, "avg_logprob": -0.13885552353329128, "compression_ratio": 1.6011904761904763, "no_speech_prob": 1.1189313227077946e-06}, {"id": 244, "seek": 154816, "start": 1565.16, "end": 1571.16, "text": " So as long as this is not a pandas data frame, it just returns the Ith element.", "tokens": [407, 382, 938, 382, 341, 307, 406, 257, 4565, 296, 1412, 3920, 11, 309, 445, 11247, 264, 286, 392, 4478, 13], "temperature": 0.0, "avg_logprob": -0.13885552353329128, "compression_ratio": 1.6011904761904763, "no_speech_prob": 1.1189313227077946e-06}, {"id": 245, "seek": 157116, "start": 1571.16, "end": 1579.16, "text": " But what we can do in to firm list is we can override underscore get.", "tokens": [583, 437, 321, 393, 360, 294, 281, 6174, 1329, 307, 321, 393, 42321, 37556, 483, 13], "temperature": 0.0, "avg_logprob": -0.1836607073560173, "compression_ratio": 1.5888888888888888, "no_speech_prob": 3.668839326564921e-06}, {"id": 246, "seek": 157116, "start": 1579.16, "end": 1585.16, "text": " And we will continue to call capital L's underscore get.", "tokens": [400, 321, 486, 2354, 281, 818, 4238, 441, 311, 37556, 483, 13], "temperature": 0.0, "avg_logprob": -0.1836607073560173, "compression_ratio": 1.5888888888888888, "no_speech_prob": 3.668839326564921e-06}, {"id": 247, "seek": 157116, "start": 1585.16, "end": 1589.16, "text": " But then we will call our pipeline.", "tokens": [583, 550, 321, 486, 818, 527, 15517, 13], "temperature": 0.0, "avg_logprob": -0.1836607073560173, "compression_ratio": 1.5888888888888888, "no_speech_prob": 3.668839326564921e-06}, {"id": 248, "seek": 157116, "start": 1589.16, "end": 1595.16, "text": " Right. So this is how we end up with something that we can say.", "tokens": [1779, 13, 407, 341, 307, 577, 321, 917, 493, 365, 746, 300, 321, 393, 584, 13], "temperature": 0.0, "avg_logprob": -0.1836607073560173, "compression_ratio": 1.5888888888888888, "no_speech_prob": 3.668839326564921e-06}, {"id": 249, "seek": 157116, "start": 1595.16, "end": 1599.16, "text": " Let's create a to firm list. The items are one, two, three.", "tokens": [961, 311, 1884, 257, 281, 6174, 1329, 13, 440, 4754, 366, 472, 11, 732, 11, 1045, 13], "temperature": 0.0, "avg_logprob": -0.1836607073560173, "compression_ratio": 1.5888888888888888, "no_speech_prob": 3.668839326564921e-06}, {"id": 250, "seek": 159916, "start": 1599.16, "end": 1604.16, "text": " Our pipeline is going to be negative and then our int to firm transform.", "tokens": [2621, 15517, 307, 516, 281, 312, 3671, 293, 550, 527, 560, 281, 6174, 4088, 13], "temperature": 0.0, "avg_logprob": -0.11036732196807861, "compression_ratio": 1.5869565217391304, "no_speech_prob": 1.0451400157762691e-05}, {"id": 251, "seek": 159916, "start": 1604.16, "end": 1609.16, "text": " And then we now have something that we can treat like a list.", "tokens": [400, 550, 321, 586, 362, 746, 300, 321, 393, 2387, 411, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.11036732196807861, "compression_ratio": 1.5869565217391304, "no_speech_prob": 1.0451400157762691e-05}, {"id": 252, "seek": 159916, "start": 1609.16, "end": 1617.16, "text": " We can subscript into it and it's going to grab the first thing, which is in this case 2.0,", "tokens": [492, 393, 2325, 662, 666, 309, 293, 309, 311, 516, 281, 4444, 264, 700, 551, 11, 597, 307, 294, 341, 1389, 568, 13, 15, 11], "temperature": 0.0, "avg_logprob": -0.11036732196807861, "compression_ratio": 1.5869565217391304, "no_speech_prob": 1.0451400157762691e-05}, {"id": 253, "seek": 159916, "start": 1617.16, "end": 1622.16, "text": " and apply the pipeline to it. So we end up with int negative two.", "tokens": [293, 3079, 264, 15517, 281, 309, 13, 407, 321, 917, 493, 365, 560, 3671, 732, 13], "temperature": 0.0, "avg_logprob": -0.11036732196807861, "compression_ratio": 1.5869565217391304, "no_speech_prob": 1.0451400157762691e-05}, {"id": 254, "seek": 162216, "start": 1622.16, "end": 1630.16, "text": " So this is starting to really look like something that has nice PyTorch data set behavior.", "tokens": [407, 341, 307, 2891, 281, 534, 574, 411, 746, 300, 575, 1481, 9953, 51, 284, 339, 1412, 992, 5223, 13], "temperature": 0.0, "avg_logprob": -0.11416105364189773, "compression_ratio": 1.4493670886075949, "no_speech_prob": 2.4060764189925976e-06}, {"id": 255, "seek": 162216, "start": 1630.16, "end": 1636.16, "text": " So you could absolutely use this as a PyTorch data set,", "tokens": [407, 291, 727, 3122, 764, 341, 382, 257, 9953, 51, 284, 339, 1412, 992, 11], "temperature": 0.0, "avg_logprob": -0.11416105364189773, "compression_ratio": 1.4493670886075949, "no_speech_prob": 2.4060764189925976e-06}, {"id": 256, "seek": 163616, "start": 1636.16, "end": 1656.16, "text": " which indeed we did that pretty close to when we started these walkthroughs in 08.", "tokens": [597, 6451, 321, 630, 300, 1238, 1998, 281, 562, 321, 1409, 613, 1792, 11529, 82, 294, 1958, 23, 13], "temperature": 0.0, "avg_logprob": -0.21634307437472874, "compression_ratio": 1.310077519379845, "no_speech_prob": 7.183165507740341e-06}, {"id": 257, "seek": 163616, "start": 1656.16, "end": 1662.16, "text": " Here is to firm DS. So going right back to it, we created an imagery size of transform", "tokens": [1692, 307, 281, 6174, 15816, 13, 407, 516, 558, 646, 281, 309, 11, 321, 2942, 364, 24340, 2744, 295, 4088], "temperature": 0.0, "avg_logprob": -0.21634307437472874, "compression_ratio": 1.310077519379845, "no_speech_prob": 7.183165507740341e-06}, {"id": 258, "seek": 166216, "start": 1662.16, "end": 1668.16, "text": " that can encode an image by resizing it.", "tokens": [300, 393, 2058, 1429, 364, 3256, 538, 725, 3319, 309, 13], "temperature": 0.0, "avg_logprob": -0.13887953379797557, "compression_ratio": 1.4054054054054055, "no_speech_prob": 1.6442152627860196e-05}, {"id": 259, "seek": 166216, "start": 1668.16, "end": 1676.16, "text": " We then created a pipeline.", "tokens": [492, 550, 2942, 257, 15517, 13], "temperature": 0.0, "avg_logprob": -0.13887953379797557, "compression_ratio": 1.4054054054054055, "no_speech_prob": 1.6442152627860196e-05}, {"id": 260, "seek": 166216, "start": 1676.16, "end": 1681.16, "text": " And then we actually do something a bit more complex.", "tokens": [400, 550, 321, 767, 360, 746, 257, 857, 544, 3997, 13], "temperature": 0.0, "avg_logprob": -0.13887953379797557, "compression_ratio": 1.4054054054054055, "no_speech_prob": 1.6442152627860196e-05}, {"id": 261, "seek": 166216, "start": 1681.16, "end": 1688.16, "text": " So we have to come back to this in a moment. We use a to firm DS, not a to firm list.", "tokens": [407, 321, 362, 281, 808, 646, 281, 341, 294, 257, 1623, 13, 492, 764, 257, 281, 6174, 15816, 11, 406, 257, 281, 6174, 1329, 13], "temperature": 0.0, "avg_logprob": -0.13887953379797557, "compression_ratio": 1.4054054054054055, "no_speech_prob": 1.6442152627860196e-05}, {"id": 262, "seek": 168816, "start": 1688.16, "end": 1693.16, "text": " OK, so let's get going to to firm DS so we can see how to make a that the reason the reason that to firm list", "tokens": [2264, 11, 370, 718, 311, 483, 516, 281, 281, 6174, 15816, 370, 321, 393, 536, 577, 281, 652, 257, 300, 264, 1778, 264, 1778, 300, 281, 6174, 1329], "temperature": 0.0, "avg_logprob": -0.18710638744996325, "compression_ratio": 1.7530864197530864, "no_speech_prob": 2.1781625036965124e-05}, {"id": 263, "seek": 168816, "start": 1693.16, "end": 1700.16, "text": " isn't quite everything we want for a data set is normally a data set when you index into it should return two things,", "tokens": [1943, 380, 1596, 1203, 321, 528, 337, 257, 1412, 992, 307, 5646, 257, 1412, 992, 562, 291, 8186, 666, 309, 820, 2736, 732, 721, 11], "temperature": 0.0, "avg_logprob": -0.18710638744996325, "compression_ratio": 1.7530864197530864, "no_speech_prob": 2.1781625036965124e-05}, {"id": 264, "seek": 168816, "start": 1700.16, "end": 1709.16, "text": " independent variable and dependent variable. And so far we only have something that kind of returns one thing.", "tokens": [6695, 7006, 293, 12334, 7006, 13, 400, 370, 1400, 321, 787, 362, 746, 300, 733, 295, 11247, 472, 551, 13], "temperature": 0.0, "avg_logprob": -0.18710638744996325, "compression_ratio": 1.7530864197530864, "no_speech_prob": 2.1781625036965124e-05}, {"id": 265, "seek": 168816, "start": 1709.16, "end": 1715.16, "text": " So what we can do is we can make something slightly more interesting called to firm DS,", "tokens": [407, 437, 321, 393, 360, 307, 321, 393, 652, 746, 4748, 544, 1880, 1219, 281, 6174, 15816, 11], "temperature": 0.0, "avg_logprob": -0.18710638744996325, "compression_ratio": 1.7530864197530864, "no_speech_prob": 2.1781625036965124e-05}, {"id": 266, "seek": 171516, "start": 1715.16, "end": 1720.16, "text": " which now it's very, very, very similar to to firm list.", "tokens": [597, 586, 309, 311, 588, 11, 588, 11, 588, 2531, 281, 281, 6174, 1329, 13], "temperature": 0.0, "avg_logprob": -0.11438532511393229, "compression_ratio": 1.6457142857142857, "no_speech_prob": 4.539328074315563e-05}, {"id": 267, "seek": 171516, "start": 1720.16, "end": 1727.16, "text": " Right. So it's still inheriting from to firm base, which in turn inherits from L, still passes the items into it.", "tokens": [1779, 13, 407, 309, 311, 920, 9484, 1748, 490, 281, 6174, 3096, 11, 597, 294, 1261, 9484, 1208, 490, 441, 11, 920, 11335, 264, 4754, 666, 309, 13], "temperature": 0.0, "avg_logprob": -0.11438532511393229, "compression_ratio": 1.6457142857142857, "no_speech_prob": 4.539328074315563e-05}, {"id": 268, "seek": 171516, "start": 1727.16, "end": 1740.16, "text": " But this time it creates a few to firm lists and specifically it creates one for each list of transforms you pass in.", "tokens": [583, 341, 565, 309, 7829, 257, 1326, 281, 6174, 14511, 293, 4682, 309, 7829, 472, 337, 1184, 1329, 295, 35592, 291, 1320, 294, 13], "temperature": 0.0, "avg_logprob": -0.11438532511393229, "compression_ratio": 1.6457142857142857, "no_speech_prob": 4.539328074315563e-05}, {"id": 269, "seek": 174016, "start": 1740.16, "end": 1747.16, "text": " So now we don't just pass in white one pipeline, but we pass in N pipelines where N usually is two.", "tokens": [407, 586, 321, 500, 380, 445, 1320, 294, 2418, 472, 15517, 11, 457, 321, 1320, 294, 426, 40168, 689, 426, 2673, 307, 732, 13], "temperature": 0.0, "avg_logprob": -0.12133077295815073, "compression_ratio": 1.803030303030303, "no_speech_prob": 9.817869795369916e-06}, {"id": 270, "seek": 174016, "start": 1747.16, "end": 1755.16, "text": " We usually want to set up an X pipeline and a Y pipeline, an independent variable pipeline and a dependent variable pipeline.", "tokens": [492, 2673, 528, 281, 992, 493, 364, 1783, 15517, 293, 257, 398, 15517, 11, 364, 6695, 7006, 15517, 293, 257, 12334, 7006, 15517, 13], "temperature": 0.0, "avg_logprob": -0.12133077295815073, "compression_ratio": 1.803030303030303, "no_speech_prob": 9.817869795369916e-06}, {"id": 271, "seek": 174016, "start": 1755.16, "end": 1768.16, "text": " So we go through each of those pipelines and we create a transformed list with the same items, but the different set of transforms.", "tokens": [407, 321, 352, 807, 1184, 295, 729, 40168, 293, 321, 1884, 257, 16894, 1329, 365, 264, 912, 4754, 11, 457, 264, 819, 992, 295, 35592, 13], "temperature": 0.0, "avg_logprob": -0.12133077295815073, "compression_ratio": 1.803030303030303, "no_speech_prob": 9.817869795369916e-06}, {"id": 272, "seek": 176816, "start": 1768.16, "end": 1779.16, "text": " And so this is actually the thing that we used in the pets tutorial because we said, oh, let's have we're going to start with a list of items is a list of file names.", "tokens": [400, 370, 341, 307, 767, 264, 551, 300, 321, 1143, 294, 264, 19897, 7073, 570, 321, 848, 11, 1954, 11, 718, 311, 362, 321, 434, 516, 281, 722, 365, 257, 1329, 295, 4754, 307, 257, 1329, 295, 3991, 5288, 13], "temperature": 0.0, "avg_logprob": -0.12353938607608571, "compression_ratio": 1.6205128205128205, "no_speech_prob": 6.643341293965932e-06}, {"id": 273, "seek": 176816, "start": 1779.16, "end": 1784.16, "text": " And the first pipeline will treat it as an image, the path to an image.", "tokens": [400, 264, 700, 15517, 486, 2387, 309, 382, 364, 3256, 11, 264, 3100, 281, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.12353938607608571, "compression_ratio": 1.6205128205128205, "no_speech_prob": 6.643341293965932e-06}, {"id": 274, "seek": 176816, "start": 1784.16, "end": 1789.16, "text": " It will open the image, resize it, turn it into a tensor and make it a float.", "tokens": [467, 486, 1269, 264, 3256, 11, 50069, 309, 11, 1261, 309, 666, 257, 40863, 293, 652, 309, 257, 15706, 13], "temperature": 0.0, "avg_logprob": -0.12353938607608571, "compression_ratio": 1.6205128205128205, "no_speech_prob": 6.643341293965932e-06}, {"id": 275, "seek": 178916, "start": 1789.16, "end": 1798.16, "text": " And the second pipeline will treat it as a source of a label and it will label it and categorize it.", "tokens": [400, 264, 1150, 15517, 486, 2387, 309, 382, 257, 4009, 295, 257, 7645, 293, 309, 486, 7645, 309, 293, 19250, 1125, 309, 13], "temperature": 0.0, "avg_logprob": -0.16342649580557136, "compression_ratio": 1.5520833333333333, "no_speech_prob": 3.2886928238440305e-06}, {"id": 276, "seek": 178916, "start": 1798.16, "end": 1805.16, "text": " And so inside, in fact, let's look at it.", "tokens": [400, 370, 1854, 11, 294, 1186, 11, 718, 311, 574, 412, 309, 13], "temperature": 0.0, "avg_logprob": -0.16342649580557136, "compression_ratio": 1.5520833333333333, "no_speech_prob": 3.2886928238440305e-06}, {"id": 277, "seek": 178916, "start": 1805.16, "end": 1817.16, "text": " We run this. We should be able to look inside TDS and we should find this self dot TLS and that should contain two transfer from lists with the same items.", "tokens": [492, 1190, 341, 13, 492, 820, 312, 1075, 281, 574, 1854, 314, 11844, 293, 321, 820, 915, 341, 2698, 5893, 314, 19198, 293, 300, 820, 5304, 732, 5003, 490, 14511, 365, 264, 912, 4754, 13], "temperature": 0.0, "avg_logprob": -0.16342649580557136, "compression_ratio": 1.5520833333333333, "no_speech_prob": 3.2886928238440305e-06}, {"id": 278, "seek": 181716, "start": 1817.16, "end": 1824.16, "text": " So let's take a look. TDS dot TLS. Yep.", "tokens": [407, 718, 311, 747, 257, 574, 13, 314, 11844, 5893, 314, 19198, 13, 7010, 13], "temperature": 0.0, "avg_logprob": -0.23285450851708128, "compression_ratio": 1.2781954887218046, "no_speech_prob": 2.7535234039532952e-05}, {"id": 279, "seek": 181716, "start": 1824.16, "end": 1827.16, "text": " So there are is our transformed lists.", "tokens": [407, 456, 366, 307, 527, 16894, 14511, 13], "temperature": 0.0, "avg_logprob": -0.23285450851708128, "compression_ratio": 1.2781954887218046, "no_speech_prob": 2.7535234039532952e-05}, {"id": 280, "seek": 181716, "start": 1827.16, "end": 1834.16, "text": " So the zero one. They have items.", "tokens": [407, 264, 4018, 472, 13, 814, 362, 4754, 13], "temperature": 0.0, "avg_logprob": -0.23285450851708128, "compression_ratio": 1.2781954887218046, "no_speech_prob": 2.7535234039532952e-05}, {"id": 281, "seek": 181716, "start": 1834.16, "end": 1842.16, "text": " As you can see, and it should have also a pipeline in it.", "tokens": [1018, 291, 393, 536, 11, 293, 309, 820, 362, 611, 257, 15517, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.23285450851708128, "compression_ratio": 1.2781954887218046, "no_speech_prob": 2.7535234039532952e-05}, {"id": 282, "seek": 184216, "start": 1842.16, "end": 1851.16, "text": " Let's go back and check to from list that pipeline will be called.", "tokens": [961, 311, 352, 646, 293, 1520, 281, 490, 1329, 300, 15517, 486, 312, 1219, 13], "temperature": 0.0, "avg_logprob": -0.49597049581593483, "compression_ratio": 1.0595238095238095, "no_speech_prob": 1.952533784788102e-05}, {"id": 283, "seek": 184216, "start": 1851.16, "end": 1854.16, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.49597049581593483, "compression_ratio": 1.0595238095238095, "no_speech_prob": 1.952533784788102e-05}, {"id": 284, "seek": 184216, "start": 1854.16, "end": 1858.16, "text": " Called to firms.", "tokens": [45001, 281, 18055, 13], "temperature": 0.0, "avg_logprob": -0.49597049581593483, "compression_ratio": 1.0595238095238095, "no_speech_prob": 1.952533784788102e-05}, {"id": 285, "seek": 185816, "start": 1858.16, "end": 1875.16, "text": " It does. So there's one zero one. OK, so there's our two transforms. So it's going to be applying these different pipelines to exactly the same items.", "tokens": [467, 775, 13, 407, 456, 311, 472, 4018, 472, 13, 2264, 11, 370, 456, 311, 527, 732, 35592, 13, 407, 309, 311, 516, 281, 312, 9275, 613, 819, 40168, 281, 2293, 264, 912, 4754, 13], "temperature": 0.0, "avg_logprob": -0.1704542496625115, "compression_ratio": 1.3880597014925373, "no_speech_prob": 6.438944183173589e-06}, {"id": 286, "seek": 185816, "start": 1875.16, "end": 1883.16, "text": " And so that's why then when we say.", "tokens": [400, 370, 300, 311, 983, 550, 562, 321, 584, 13], "temperature": 0.0, "avg_logprob": -0.1704542496625115, "compression_ratio": 1.3880597014925373, "no_speech_prob": 6.438944183173589e-06}, {"id": 287, "seek": 188316, "start": 1883.16, "end": 1888.16, "text": " T equals TDS zero, we're getting back an image.", "tokens": [314, 6915, 314, 11844, 4018, 11, 321, 434, 1242, 646, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.22240318101027917, "compression_ratio": 1.3304347826086957, "no_speech_prob": 1.7502570699434727e-05}, {"id": 288, "seek": 188316, "start": 1888.16, "end": 1890.16, "text": " And category.", "tokens": [400, 7719, 13], "temperature": 0.0, "avg_logprob": -0.22240318101027917, "compression_ratio": 1.3304347826086957, "no_speech_prob": 1.7502570699434727e-05}, {"id": 289, "seek": 188316, "start": 1890.16, "end": 1896.16, "text": " And you can see the types here.", "tokens": [400, 291, 393, 536, 264, 3467, 510, 13], "temperature": 0.0, "avg_logprob": -0.22240318101027917, "compression_ratio": 1.3304347826086957, "no_speech_prob": 1.7502570699434727e-05}, {"id": 290, "seek": 188316, "start": 1896.16, "end": 1901.16, "text": " And so when we say TDS decode.", "tokens": [400, 370, 562, 321, 584, 314, 11844, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.22240318101027917, "compression_ratio": 1.3304347826086957, "no_speech_prob": 1.7502570699434727e-05}, {"id": 291, "seek": 188316, "start": 1901.16, "end": 1907.16, "text": " Here is.", "tokens": [1692, 307, 13], "temperature": 0.0, "avg_logprob": -0.22240318101027917, "compression_ratio": 1.3304347826086957, "no_speech_prob": 1.7502570699434727e-05}, {"id": 292, "seek": 188316, "start": 1907.16, "end": 1911.16, "text": " Here is TDS decode.", "tokens": [1692, 307, 314, 11844, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.22240318101027917, "compression_ratio": 1.3304347826086957, "no_speech_prob": 1.7502570699434727e-05}, {"id": 293, "seek": 191116, "start": 1911.16, "end": 1918.16, "text": " It's going to go through each of those transform lists.", "tokens": [467, 311, 516, 281, 352, 807, 1184, 295, 729, 4088, 14511, 13], "temperature": 0.0, "avg_logprob": -0.13844141364097595, "compression_ratio": 1.5060975609756098, "no_speech_prob": 2.368743707847898e-06}, {"id": 294, "seek": 191116, "start": 1918.16, "end": 1923.16, "text": " And decode each one.", "tokens": [400, 979, 1429, 1184, 472, 13], "temperature": 0.0, "avg_logprob": -0.13844141364097595, "compression_ratio": 1.5060975609756098, "no_speech_prob": 2.368743707847898e-06}, {"id": 295, "seek": 191116, "start": 1923.16, "end": 1936.16, "text": " So, yeah, so Max, yes, both pipelines are going to start with the same thing because the two firm lists I'm creating are both being passed exactly the same list of items.", "tokens": [407, 11, 1338, 11, 370, 7402, 11, 2086, 11, 1293, 40168, 366, 516, 281, 722, 365, 264, 912, 551, 570, 264, 732, 6174, 14511, 286, 478, 4084, 366, 1293, 885, 4678, 2293, 264, 912, 1329, 295, 4754, 13], "temperature": 0.0, "avg_logprob": -0.13844141364097595, "compression_ratio": 1.5060975609756098, "no_speech_prob": 2.368743707847898e-06}, {"id": 296, "seek": 193616, "start": 1936.16, "end": 1947.16, "text": " And so when you think about it, this is like how exactly the one for X opens the path as images and the second creates labels from the paths.", "tokens": [400, 370, 562, 291, 519, 466, 309, 11, 341, 307, 411, 577, 2293, 264, 472, 337, 1783, 9870, 264, 3100, 382, 5267, 293, 264, 1150, 7829, 16949, 490, 264, 14518, 13], "temperature": 0.0, "avg_logprob": -0.19697945206253617, "compression_ratio": 1.5179487179487179, "no_speech_prob": 1.349655235571845e-06}, {"id": 297, "seek": 193616, "start": 1947.16, "end": 1952.16, "text": " Well done. So, yeah, so here is pipeline one.", "tokens": [1042, 1096, 13, 407, 11, 1338, 11, 370, 510, 307, 15517, 472, 13], "temperature": 0.0, "avg_logprob": -0.19697945206253617, "compression_ratio": 1.5179487179487179, "no_speech_prob": 1.349655235571845e-06}, {"id": 298, "seek": 193616, "start": 1952.16, "end": 1959.16, "text": " Let's see if we can use it right. So let's grab items. So here's items that we passed into a different. Yes.", "tokens": [961, 311, 536, 498, 321, 393, 764, 309, 558, 13, 407, 718, 311, 4444, 4754, 13, 407, 510, 311, 4754, 300, 321, 4678, 666, 257, 819, 13, 1079, 13], "temperature": 0.0, "avg_logprob": -0.19697945206253617, "compression_ratio": 1.5179487179487179, "no_speech_prob": 1.349655235571845e-06}, {"id": 299, "seek": 195916, "start": 1959.16, "end": 1972.16, "text": " So here's items zero. There's a path. And so when you think about it, like whatever your independent independent variables are, they they're kind of being somehow derived from the same place.", "tokens": [407, 510, 311, 4754, 4018, 13, 821, 311, 257, 3100, 13, 400, 370, 562, 291, 519, 466, 309, 11, 411, 2035, 428, 6695, 6695, 9102, 366, 11, 436, 436, 434, 733, 295, 885, 6063, 18949, 490, 264, 912, 1081, 13], "temperature": 0.0, "avg_logprob": -0.13677489293086065, "compression_ratio": 1.5706806282722514, "no_speech_prob": 2.123329295500298e-06}, {"id": 300, "seek": 195916, "start": 1972.16, "end": 1976.16, "text": " That's kind of like what a labeling function is.", "tokens": [663, 311, 733, 295, 411, 437, 257, 40244, 2445, 307, 13], "temperature": 0.0, "avg_logprob": -0.13677489293086065, "compression_ratio": 1.5706806282722514, "no_speech_prob": 2.123329295500298e-06}, {"id": 301, "seek": 195916, "start": 1976.16, "end": 1980.16, "text": " So let's create an item called like so.", "tokens": [407, 718, 311, 1884, 364, 3174, 1219, 411, 370, 13], "temperature": 0.0, "avg_logprob": -0.13677489293086065, "compression_ratio": 1.5706806282722514, "no_speech_prob": 2.123329295500298e-06}, {"id": 302, "seek": 195916, "start": 1980.16, "end": 1982.16, "text": " So here's the item.", "tokens": [407, 510, 311, 264, 3174, 13], "temperature": 0.0, "avg_logprob": -0.13677489293086065, "compression_ratio": 1.5706806282722514, "no_speech_prob": 2.123329295500298e-06}, {"id": 303, "seek": 198216, "start": 1982.16, "end": 1990.16, "text": " And so let's create our function for X would be TDS.", "tokens": [400, 370, 718, 311, 1884, 527, 2445, 337, 1783, 576, 312, 314, 11844, 13], "temperature": 0.0, "avg_logprob": -0.3796713870504628, "compression_ratio": 1.1261261261261262, "no_speech_prob": 1.3925254052082892e-06}, {"id": 304, "seek": 198216, "start": 1990.16, "end": 1994.16, "text": " Dot two firms.", "tokens": [38753, 732, 18055, 13], "temperature": 0.0, "avg_logprob": -0.3796713870504628, "compression_ratio": 1.1261261261261262, "no_speech_prob": 1.3925254052082892e-06}, {"id": 305, "seek": 198216, "start": 1994.16, "end": 1997.16, "text": " TLS zero.", "tokens": [314, 19198, 4018, 13], "temperature": 0.0, "avg_logprob": -0.3796713870504628, "compression_ratio": 1.1261261261261262, "no_speech_prob": 1.3925254052082892e-06}, {"id": 306, "seek": 198216, "start": 1997.16, "end": 2001.16, "text": " So here's our that's our first pipeline.", "tokens": [407, 510, 311, 527, 300, 311, 527, 700, 15517, 13], "temperature": 0.0, "avg_logprob": -0.3796713870504628, "compression_ratio": 1.1261261261261262, "no_speech_prob": 1.3925254052082892e-06}, {"id": 307, "seek": 198216, "start": 2001.16, "end": 2004.16, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.3796713870504628, "compression_ratio": 1.1261261261261262, "no_speech_prob": 1.3925254052082892e-06}, {"id": 308, "seek": 200416, "start": 2004.16, "end": 2012.16, "text": " And then our second pipeline is tedious.", "tokens": [400, 550, 527, 1150, 15517, 307, 38284, 13], "temperature": 0.0, "avg_logprob": -0.2490107536315918, "compression_ratio": 1.4049586776859504, "no_speech_prob": 4.3567229113250505e-06}, {"id": 309, "seek": 200416, "start": 2012.16, "end": 2015.16, "text": " And so there's both our pipelines.", "tokens": [400, 370, 456, 311, 1293, 527, 40168, 13], "temperature": 0.0, "avg_logprob": -0.2490107536315918, "compression_ratio": 1.4049586776859504, "no_speech_prob": 4.3567229113250505e-06}, {"id": 310, "seek": 200416, "start": 2015.16, "end": 2018.16, "text": " So if we then apply effects.", "tokens": [407, 498, 321, 550, 3079, 5065, 13], "temperature": 0.0, "avg_logprob": -0.2490107536315918, "compression_ratio": 1.4049586776859504, "no_speech_prob": 4.3567229113250505e-06}, {"id": 311, "seek": 200416, "start": 2018.16, "end": 2020.16, "text": " To our item.", "tokens": [1407, 527, 3174, 13], "temperature": 0.0, "avg_logprob": -0.2490107536315918, "compression_ratio": 1.4049586776859504, "no_speech_prob": 4.3567229113250505e-06}, {"id": 312, "seek": 200416, "start": 2020.16, "end": 2023.16, "text": " We get out image.", "tokens": [492, 483, 484, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2490107536315918, "compression_ratio": 1.4049586776859504, "no_speech_prob": 4.3567229113250505e-06}, {"id": 313, "seek": 200416, "start": 2023.16, "end": 2026.16, "text": " And if you apply F.Y.", "tokens": [400, 498, 291, 3079, 479, 13, 56, 13], "temperature": 0.0, "avg_logprob": -0.2490107536315918, "compression_ratio": 1.4049586776859504, "no_speech_prob": 4.3567229113250505e-06}, {"id": 314, "seek": 200416, "start": 2026.16, "end": 2028.16, "text": " To our item.", "tokens": [1407, 527, 3174, 13], "temperature": 0.0, "avg_logprob": -0.2490107536315918, "compression_ratio": 1.4049586776859504, "no_speech_prob": 4.3567229113250505e-06}, {"id": 315, "seek": 202816, "start": 2028.16, "end": 2038.16, "text": " We get back our category.", "tokens": [492, 483, 646, 527, 7719, 13], "temperature": 0.0, "avg_logprob": -0.22148907859370393, "compression_ratio": 1.3357664233576643, "no_speech_prob": 3.2884095162444282e-06}, {"id": 316, "seek": 202816, "start": 2038.16, "end": 2047.16, "text": " So, yeah, so that's kind of a useful thing to try doing is to like just see what's going on inside.", "tokens": [407, 11, 1338, 11, 370, 300, 311, 733, 295, 257, 4420, 551, 281, 853, 884, 307, 281, 411, 445, 536, 437, 311, 516, 322, 1854, 13], "temperature": 0.0, "avg_logprob": -0.22148907859370393, "compression_ratio": 1.3357664233576643, "no_speech_prob": 3.2884095162444282e-06}, {"id": 317, "seek": 202816, "start": 2047.16, "end": 2051.16, "text": " So could two firms. Yes. Except couples instead of items.", "tokens": [407, 727, 732, 18055, 13, 1079, 13, 16192, 20368, 2602, 295, 4754, 13], "temperature": 0.0, "avg_logprob": -0.22148907859370393, "compression_ratio": 1.3357664233576643, "no_speech_prob": 3.2884095162444282e-06}, {"id": 318, "seek": 205116, "start": 2051.16, "end": 2058.16, "text": " Well, I mean, it's not as dead off like the items can be couples. So, yes, absolutely.", "tokens": [1042, 11, 286, 914, 11, 309, 311, 406, 382, 3116, 766, 411, 264, 4754, 393, 312, 20368, 13, 407, 11, 2086, 11, 3122, 13], "temperature": 0.0, "avg_logprob": -0.1595407768532082, "compression_ratio": 1.296875, "no_speech_prob": 8.011884347070009e-06}, {"id": 319, "seek": 205116, "start": 2058.16, "end": 2063.16, "text": " Because it's just calling a pipeline.", "tokens": [1436, 309, 311, 445, 5141, 257, 15517, 13], "temperature": 0.0, "avg_logprob": -0.1595407768532082, "compression_ratio": 1.296875, "no_speech_prob": 8.011884347070009e-06}, {"id": 320, "seek": 205116, "start": 2063.16, "end": 2069.16, "text": " And so let's try it. Right. So let's try.", "tokens": [400, 370, 718, 311, 853, 309, 13, 1779, 13, 407, 718, 311, 853, 13], "temperature": 0.0, "avg_logprob": -0.1595407768532082, "compression_ratio": 1.296875, "no_speech_prob": 8.011884347070009e-06}, {"id": 321, "seek": 206916, "start": 2069.16, "end": 2081.16, "text": " I think so. Let's create some items. Equals. Zero comma one comma.", "tokens": [286, 519, 370, 13, 961, 311, 1884, 512, 4754, 13, 15624, 1124, 13, 17182, 22117, 472, 22117, 13], "temperature": 0.0, "avg_logprob": -0.21202041853719683, "compression_ratio": 1.4068965517241379, "no_speech_prob": 1.4738268873770721e-05}, {"id": 322, "seek": 206916, "start": 2081.16, "end": 2083.16, "text": " One comma two.", "tokens": [1485, 22117, 732, 13], "temperature": 0.0, "avg_logprob": -0.21202041853719683, "compression_ratio": 1.4068965517241379, "no_speech_prob": 1.4738268873770721e-05}, {"id": 323, "seek": 206916, "start": 2083.16, "end": 2085.16, "text": " Comma.", "tokens": [3046, 64, 13], "temperature": 0.0, "avg_logprob": -0.21202041853719683, "compression_ratio": 1.4068965517241379, "no_speech_prob": 1.4738268873770721e-05}, {"id": 324, "seek": 206916, "start": 2085.16, "end": 2087.16, "text": " Three comma four.", "tokens": [6244, 22117, 1451, 13], "temperature": 0.0, "avg_logprob": -0.21202041853719683, "compression_ratio": 1.4068965517241379, "no_speech_prob": 1.4738268873770721e-05}, {"id": 325, "seek": 206916, "start": 2087.16, "end": 2092.16, "text": " Right. So there's some items, which is a list of couples.", "tokens": [1779, 13, 407, 456, 311, 512, 4754, 11, 597, 307, 257, 1329, 295, 20368, 13], "temperature": 0.0, "avg_logprob": -0.21202041853719683, "compression_ratio": 1.4068965517241379, "no_speech_prob": 1.4738268873770721e-05}, {"id": 326, "seek": 206916, "start": 2092.16, "end": 2096.16, "text": " And so we could create like a function.", "tokens": [400, 370, 321, 727, 1884, 411, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.21202041853719683, "compression_ratio": 1.4068965517241379, "no_speech_prob": 1.4738268873770721e-05}, {"id": 327, "seek": 209616, "start": 2096.16, "end": 2099.16, "text": " So there's a function.", "tokens": [407, 456, 311, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.15504179734450121, "compression_ratio": 1.4097222222222223, "no_speech_prob": 1.184294706035871e-05}, {"id": 328, "seek": 209616, "start": 2099.16, "end": 2103.16, "text": " In Python called item getter.", "tokens": [682, 15329, 1219, 3174, 483, 391, 13], "temperature": 0.0, "avg_logprob": -0.15504179734450121, "compression_ratio": 1.4097222222222223, "no_speech_prob": 1.184294706035871e-05}, {"id": 329, "seek": 209616, "start": 2103.16, "end": 2107.16, "text": " So if I call effects is item get a zero.", "tokens": [407, 498, 286, 818, 5065, 307, 3174, 483, 257, 4018, 13], "temperature": 0.0, "avg_logprob": -0.15504179734450121, "compression_ratio": 1.4097222222222223, "no_speech_prob": 1.184294706035871e-05}, {"id": 330, "seek": 209616, "start": 2107.16, "end": 2111.16, "text": " The way that works is that.", "tokens": [440, 636, 300, 1985, 307, 300, 13], "temperature": 0.0, "avg_logprob": -0.15504179734450121, "compression_ratio": 1.4097222222222223, "no_speech_prob": 1.184294706035871e-05}, {"id": 331, "seek": 209616, "start": 2111.16, "end": 2117.16, "text": " She does try to make this more helpful by making this a capital L.", "tokens": [1240, 775, 853, 281, 652, 341, 544, 4961, 538, 1455, 341, 257, 4238, 441, 13], "temperature": 0.0, "avg_logprob": -0.15504179734450121, "compression_ratio": 1.4097222222222223, "no_speech_prob": 1.184294706035871e-05}, {"id": 332, "seek": 209616, "start": 2117.16, "end": 2123.16, "text": " So if I apply.", "tokens": [407, 498, 286, 3079, 13], "temperature": 0.0, "avg_logprob": -0.15504179734450121, "compression_ratio": 1.4097222222222223, "no_speech_prob": 1.184294706035871e-05}, {"id": 333, "seek": 212316, "start": 2123.16, "end": 2126.16, "text": " Fx to every element of that I get back.", "tokens": [479, 87, 281, 633, 4478, 295, 300, 286, 483, 646, 13], "temperature": 0.0, "avg_logprob": -0.20369875235635726, "compression_ratio": 1.4696969696969697, "no_speech_prob": 1.4509713764709886e-05}, {"id": 334, "seek": 212316, "start": 2126.16, "end": 2129.16, "text": " As you can see.", "tokens": [1018, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.20369875235635726, "compression_ratio": 1.4696969696969697, "no_speech_prob": 1.4509713764709886e-05}, {"id": 335, "seek": 212316, "start": 2129.16, "end": 2133.16, "text": " The first element of each couple.", "tokens": [440, 700, 4478, 295, 1184, 1916, 13], "temperature": 0.0, "avg_logprob": -0.20369875235635726, "compression_ratio": 1.4696969696969697, "no_speech_prob": 1.4509713764709886e-05}, {"id": 336, "seek": 212316, "start": 2133.16, "end": 2141.16, "text": " So let's create effects and if why.", "tokens": [407, 718, 311, 1884, 5065, 293, 498, 983, 13], "temperature": 0.0, "avg_logprob": -0.20369875235635726, "compression_ratio": 1.4696969696969697, "no_speech_prob": 1.4509713764709886e-05}, {"id": 337, "seek": 212316, "start": 2141.16, "end": 2146.16, "text": " And so now we do it. Why will get the second element of each couple.", "tokens": [400, 370, 586, 321, 360, 309, 13, 1545, 486, 483, 264, 1150, 4478, 295, 1184, 1916, 13], "temperature": 0.0, "avg_logprob": -0.20369875235635726, "compression_ratio": 1.4696969696969697, "no_speech_prob": 1.4509713764709886e-05}, {"id": 338, "seek": 214616, "start": 2146.16, "end": 2154.16, "text": " And so we could create a.", "tokens": [400, 370, 321, 727, 1884, 257, 13], "temperature": 0.0, "avg_logprob": -0.21722877436670765, "compression_ratio": 1.4651162790697674, "no_speech_prob": 2.282628156535793e-05}, {"id": 339, "seek": 214616, "start": 2154.16, "end": 2159.16, "text": " Fmds.", "tokens": [479, 76, 16063, 13], "temperature": 0.0, "avg_logprob": -0.21722877436670765, "compression_ratio": 1.4651162790697674, "no_speech_prob": 2.282628156535793e-05}, {"id": 340, "seek": 214616, "start": 2159.16, "end": 2163.16, "text": " Which the items of it are it's.", "tokens": [3013, 264, 4754, 295, 309, 366, 309, 311, 13], "temperature": 0.0, "avg_logprob": -0.21722877436670765, "compression_ratio": 1.4651162790697674, "no_speech_prob": 2.282628156535793e-05}, {"id": 341, "seek": 214616, "start": 2163.16, "end": 2169.16, "text": " And we're going to pass in two pipelines. The first pipeline just contains effects.", "tokens": [400, 321, 434, 516, 281, 1320, 294, 732, 40168, 13, 440, 700, 15517, 445, 8306, 5065, 13], "temperature": 0.0, "avg_logprob": -0.21722877436670765, "compression_ratio": 1.4651162790697674, "no_speech_prob": 2.282628156535793e-05}, {"id": 342, "seek": 214616, "start": 2169.16, "end": 2174.16, "text": " And the second pipeline just contains Fy.", "tokens": [400, 264, 1150, 15517, 445, 8306, 479, 88, 13], "temperature": 0.0, "avg_logprob": -0.21722877436670765, "compression_ratio": 1.4651162790697674, "no_speech_prob": 2.282628156535793e-05}, {"id": 343, "seek": 217416, "start": 2174.16, "end": 2177.16, "text": " OK. So now if we look at TDS.", "tokens": [2264, 13, 407, 586, 498, 321, 574, 412, 314, 11844, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 344, "seek": 217416, "start": 2177.16, "end": 2179.16, "text": " Zero.", "tokens": [17182, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 345, "seek": 217416, "start": 2179.16, "end": 2182.16, "text": " There you go. OK. So it's going to take the.", "tokens": [821, 291, 352, 13, 2264, 13, 407, 309, 311, 516, 281, 747, 264, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 346, "seek": 217416, "start": 2182.16, "end": 2184.16, "text": " Zero element.", "tokens": [17182, 4478, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 347, "seek": 217416, "start": 2184.16, "end": 2186.16, "text": " Which is the couple zero one.", "tokens": [3013, 307, 264, 1916, 4018, 472, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 348, "seek": 217416, "start": 2186.16, "end": 2189.16, "text": " And then it was going to pass it through through two functions.", "tokens": [400, 550, 309, 390, 516, 281, 1320, 309, 807, 807, 732, 6828, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 349, "seek": 217416, "start": 2189.16, "end": 2192.16, "text": " The first function is I didn't get a zero.", "tokens": [440, 700, 2445, 307, 286, 994, 380, 483, 257, 4018, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 350, "seek": 217416, "start": 2192.16, "end": 2195.16, "text": " It turns zero thing. The second function is.", "tokens": [467, 4523, 4018, 551, 13, 440, 1150, 2445, 307, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 351, "seek": 217416, "start": 2195.16, "end": 2198.16, "text": " I didn't get a one which returns the index one thing.", "tokens": [286, 994, 380, 483, 257, 472, 597, 11247, 264, 8186, 472, 551, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 352, "seek": 217416, "start": 2198.16, "end": 2202.16, "text": " And then it's going to put them back into a couple.", "tokens": [400, 550, 309, 311, 516, 281, 829, 552, 646, 666, 257, 1916, 13], "temperature": 0.0, "avg_logprob": -0.19608096916134618, "compression_ratio": 1.7442922374429224, "no_speech_prob": 1.8631408238434233e-05}, {"id": 353, "seek": 220216, "start": 2202.16, "end": 2205.16, "text": " So hopefully that answers your question as well.", "tokens": [407, 4696, 300, 6338, 428, 1168, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.15040039247082126, "compression_ratio": 1.5595238095238095, "no_speech_prob": 2.5463452402618714e-05}, {"id": 354, "seek": 220216, "start": 2205.16, "end": 2212.16, "text": " David you just have to make sure that your items contain whatever information is necessary.", "tokens": [4389, 291, 445, 362, 281, 652, 988, 300, 428, 4754, 5304, 2035, 1589, 307, 4818, 13], "temperature": 0.0, "avg_logprob": -0.15040039247082126, "compression_ratio": 1.5595238095238095, "no_speech_prob": 2.5463452402618714e-05}, {"id": 355, "seek": 220216, "start": 2212.16, "end": 2221.16, "text": " To construct your data that you end up want to end up in your mini batches.", "tokens": [1407, 7690, 428, 1412, 300, 291, 917, 493, 528, 281, 917, 493, 294, 428, 8382, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.15040039247082126, "compression_ratio": 1.5595238095238095, "no_speech_prob": 2.5463452402618714e-05}, {"id": 356, "seek": 220216, "start": 2221.16, "end": 2228.16, "text": " Thanks to all those very very good questions.", "tokens": [2561, 281, 439, 729, 588, 588, 665, 1651, 13], "temperature": 0.0, "avg_logprob": -0.15040039247082126, "compression_ratio": 1.5595238095238095, "no_speech_prob": 2.5463452402618714e-05}, {"id": 357, "seek": 222816, "start": 2228.16, "end": 2234.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.15890741348266602, "compression_ratio": 1.391304347826087, "no_speech_prob": 1.7496040527475998e-05}, {"id": 358, "seek": 222816, "start": 2234.16, "end": 2240.16, "text": " So you know and to be clear like remember.", "tokens": [407, 291, 458, 293, 281, 312, 1850, 411, 1604, 13], "temperature": 0.0, "avg_logprob": -0.15890741348266602, "compression_ratio": 1.391304347826087, "no_speech_prob": 1.7496040527475998e-05}, {"id": 359, "seek": 222816, "start": 2240.16, "end": 2242.16, "text": " This you know.", "tokens": [639, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.15890741348266602, "compression_ratio": 1.391304347826087, "no_speech_prob": 1.7496040527475998e-05}, {"id": 360, "seek": 222816, "start": 2242.16, "end": 2252.16, "text": " So when I got to this over a period of about 25 iterations and pretty much rewrites over a period of many weeks.", "tokens": [407, 562, 286, 658, 281, 341, 670, 257, 2896, 295, 466, 3552, 36540, 293, 1238, 709, 319, 86, 30931, 670, 257, 2896, 295, 867, 3259, 13], "temperature": 0.0, "avg_logprob": -0.15890741348266602, "compression_ratio": 1.391304347826087, "no_speech_prob": 1.7496040527475998e-05}, {"id": 361, "seek": 222816, "start": 2252.16, "end": 2255.16, "text": " And so like it's.", "tokens": [400, 370, 411, 309, 311, 13], "temperature": 0.0, "avg_logprob": -0.15890741348266602, "compression_ratio": 1.391304347826087, "no_speech_prob": 1.7496040527475998e-05}, {"id": 362, "seek": 225516, "start": 2255.16, "end": 2259.16, "text": " This is very simple but the.", "tokens": [639, 307, 588, 2199, 457, 264, 13], "temperature": 0.0, "avg_logprob": -0.1766226368565713, "compression_ratio": 1.6699029126213591, "no_speech_prob": 2.8402013413142413e-05}, {"id": 363, "seek": 225516, "start": 2259.16, "end": 2267.16, "text": " They go together in very neat ways which you know most people don't have to understand all these details.", "tokens": [814, 352, 1214, 294, 588, 10654, 2098, 597, 291, 458, 881, 561, 500, 380, 362, 281, 1223, 439, 613, 4365, 13], "temperature": 0.0, "avg_logprob": -0.1766226368565713, "compression_ratio": 1.6699029126213591, "no_speech_prob": 2.8402013413142413e-05}, {"id": 364, "seek": 225516, "start": 2267.16, "end": 2271.16, "text": " But you folks you're here because you do want to understand all these details.", "tokens": [583, 291, 4024, 291, 434, 510, 570, 291, 360, 528, 281, 1223, 439, 613, 4365, 13], "temperature": 0.0, "avg_logprob": -0.1766226368565713, "compression_ratio": 1.6699029126213591, "no_speech_prob": 2.8402013413142413e-05}, {"id": 365, "seek": 225516, "start": 2271.16, "end": 2273.16, "text": " It's it's it's it.", "tokens": [467, 311, 309, 311, 309, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.1766226368565713, "compression_ratio": 1.6699029126213591, "no_speech_prob": 2.8402013413142413e-05}, {"id": 366, "seek": 225516, "start": 2273.16, "end": 2275.16, "text": " Don't be.", "tokens": [1468, 380, 312, 13], "temperature": 0.0, "avg_logprob": -0.1766226368565713, "compression_ratio": 1.6699029126213591, "no_speech_prob": 2.8402013413142413e-05}, {"id": 367, "seek": 225516, "start": 2275.16, "end": 2281.16, "text": " But don't let it bother you that it's going to take a while probably before it all clicks into place.", "tokens": [583, 500, 380, 718, 309, 8677, 291, 300, 309, 311, 516, 281, 747, 257, 1339, 1391, 949, 309, 439, 18521, 666, 1081, 13], "temperature": 0.0, "avg_logprob": -0.1766226368565713, "compression_ratio": 1.6699029126213591, "no_speech_prob": 2.8402013413142413e-05}, {"id": 368, "seek": 228116, "start": 2281.16, "end": 2285.16, "text": " But hopefully these notebooks can help it click into place.", "tokens": [583, 4696, 613, 43782, 393, 854, 309, 2052, 666, 1081, 13], "temperature": 0.0, "avg_logprob": -0.19563755807997305, "compression_ratio": 1.5159574468085106, "no_speech_prob": 9.515069905319251e-06}, {"id": 369, "seek": 228116, "start": 2285.16, "end": 2286.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.19563755807997305, "compression_ratio": 1.5159574468085106, "no_speech_prob": 9.515069905319251e-06}, {"id": 370, "seek": 228116, "start": 2286.16, "end": 2287.16, "text": " So yeah.", "tokens": [407, 1338, 13], "temperature": 0.0, "avg_logprob": -0.19563755807997305, "compression_ratio": 1.5159574468085106, "no_speech_prob": 9.515069905319251e-06}, {"id": 371, "seek": 228116, "start": 2287.16, "end": 2290.16, "text": " So like going back to to notebook.", "tokens": [407, 411, 516, 646, 281, 281, 21060, 13], "temperature": 0.0, "avg_logprob": -0.19563755807997305, "compression_ratio": 1.5159574468085106, "no_speech_prob": 9.515069905319251e-06}, {"id": 372, "seek": 228116, "start": 2290.16, "end": 2294.16, "text": " Oh wait would be a really great thing to do.", "tokens": [876, 1699, 576, 312, 257, 534, 869, 551, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.19563755807997305, "compression_ratio": 1.5159574468085106, "no_speech_prob": 9.515069905319251e-06}, {"id": 373, "seek": 228116, "start": 2294.16, "end": 2299.16, "text": " You know kind of as as as homework if you want to do some homework before tomorrow.", "tokens": [509, 458, 733, 295, 382, 382, 382, 14578, 498, 291, 528, 281, 360, 512, 14578, 949, 4153, 13], "temperature": 0.0, "avg_logprob": -0.19563755807997305, "compression_ratio": 1.5159574468085106, "no_speech_prob": 9.515069905319251e-06}, {"id": 374, "seek": 228116, "start": 2299.16, "end": 2304.16, "text": " Because you'll understand all the pieces I know.", "tokens": [1436, 291, 603, 1223, 439, 264, 3755, 286, 458, 13], "temperature": 0.0, "avg_logprob": -0.19563755807997305, "compression_ratio": 1.5159574468085106, "no_speech_prob": 9.515069905319251e-06}, {"id": 375, "seek": 230416, "start": 2304.16, "end": 2311.16, "text": " All right. So that is to find the S and to find a different list.", "tokens": [1057, 558, 13, 407, 300, 307, 281, 915, 264, 318, 293, 281, 915, 257, 819, 1329, 13], "temperature": 0.0, "avg_logprob": -0.26205510913201097, "compression_ratio": 1.8773584905660377, "no_speech_prob": 2.3919850718812086e-05}, {"id": 376, "seek": 230416, "start": 2311.16, "end": 2322.16, "text": " In practice you probably won't use to find list much because most of the time you want multiple sets of transforms because you want to create a data loader which is going to have a mini batch with couples of things.", "tokens": [682, 3124, 291, 1391, 1582, 380, 764, 281, 915, 1329, 709, 570, 881, 295, 264, 565, 291, 528, 3866, 6352, 295, 35592, 570, 291, 528, 281, 1884, 257, 1412, 3677, 260, 597, 307, 516, 281, 362, 257, 8382, 15245, 365, 20368, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.26205510913201097, "compression_ratio": 1.8773584905660377, "no_speech_prob": 2.3919850718812086e-05}, {"id": 377, "seek": 230416, "start": 2322.16, "end": 2325.16, "text": " So you want to find the S most of the time.", "tokens": [407, 291, 528, 281, 915, 264, 318, 881, 295, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.26205510913201097, "compression_ratio": 1.8773584905660377, "no_speech_prob": 2.3919850718812086e-05}, {"id": 378, "seek": 230416, "start": 2325.16, "end": 2329.16, "text": " But to fit to fit to find the S users to find list.", "tokens": [583, 281, 3318, 281, 3318, 281, 915, 264, 318, 5022, 281, 915, 1329, 13], "temperature": 0.0, "avg_logprob": -0.26205510913201097, "compression_ratio": 1.8773584905660377, "no_speech_prob": 2.3919850718812086e-05}, {"id": 379, "seek": 230416, "start": 2329.16, "end": 2331.16, "text": " So it's a very very.", "tokens": [407, 309, 311, 257, 588, 588, 13], "temperature": 0.0, "avg_logprob": -0.26205510913201097, "compression_ratio": 1.8773584905660377, "no_speech_prob": 2.3919850718812086e-05}, {"id": 380, "seek": 233116, "start": 2331.16, "end": 2334.16, "text": " Yeah. Remember these things are very very small.", "tokens": [865, 13, 5459, 613, 721, 366, 588, 588, 1359, 13], "temperature": 0.0, "avg_logprob": -0.07264646239902663, "compression_ratio": 1.6939655172413792, "no_speech_prob": 3.8447274164354894e-06}, {"id": 381, "seek": 233116, "start": 2334.16, "end": 2335.16, "text": " Each one's very very small.", "tokens": [6947, 472, 311, 588, 588, 1359, 13], "temperature": 0.0, "avg_logprob": -0.07264646239902663, "compression_ratio": 1.6939655172413792, "no_speech_prob": 3.8447274164354894e-06}, {"id": 382, "seek": 233116, "start": 2335.16, "end": 2344.16, "text": " So try to make sure you get a good intuitive understanding of what each thing does and read through the tests and understand like why did we add that test.", "tokens": [407, 853, 281, 652, 988, 291, 483, 257, 665, 21769, 3701, 295, 437, 1184, 551, 775, 293, 1401, 807, 264, 6921, 293, 1223, 411, 983, 630, 321, 909, 300, 1500, 13], "temperature": 0.0, "avg_logprob": -0.07264646239902663, "compression_ratio": 1.6939655172413792, "no_speech_prob": 3.8447274164354894e-06}, {"id": 383, "seek": 233116, "start": 2344.16, "end": 2346.16, "text": " You know because these tests are not arbitrary.", "tokens": [509, 458, 570, 613, 6921, 366, 406, 23211, 13], "temperature": 0.0, "avg_logprob": -0.07264646239902663, "compression_ratio": 1.6939655172413792, "no_speech_prob": 3.8447274164354894e-06}, {"id": 384, "seek": 233116, "start": 2346.16, "end": 2353.16, "text": " They're the set of things we think provides kind of the best clarity around the details of what this thing does.", "tokens": [814, 434, 264, 992, 295, 721, 321, 519, 6417, 733, 295, 264, 1151, 16992, 926, 264, 4365, 295, 437, 341, 551, 775, 13], "temperature": 0.0, "avg_logprob": -0.07264646239902663, "compression_ratio": 1.6939655172413792, "no_speech_prob": 3.8447274164354894e-06}, {"id": 385, "seek": 235316, "start": 2353.16, "end": 2361.16, "text": " And remember that the methods section has tests as well so that you can learn more information about what all these different methods do.", "tokens": [400, 1604, 300, 264, 7150, 3541, 575, 6921, 382, 731, 370, 300, 291, 393, 1466, 544, 1589, 466, 437, 439, 613, 819, 7150, 360, 13], "temperature": 0.0, "avg_logprob": -0.15830473466352982, "compression_ratio": 1.575, "no_speech_prob": 2.078242141578812e-05}, {"id": 386, "seek": 235316, "start": 2361.16, "end": 2367.16, "text": " OK. So now something new.", "tokens": [2264, 13, 407, 586, 746, 777, 13], "temperature": 0.0, "avg_logprob": -0.15830473466352982, "compression_ratio": 1.575, "no_speech_prob": 2.078242141578812e-05}, {"id": 387, "seek": 235316, "start": 2367.16, "end": 2369.16, "text": " Oh no this is not user 0 5.", "tokens": [876, 572, 341, 307, 406, 4195, 1958, 1025, 13], "temperature": 0.0, "avg_logprob": -0.15830473466352982, "compression_ratio": 1.575, "no_speech_prob": 2.078242141578812e-05}, {"id": 388, "seek": 235316, "start": 2369.16, "end": 2372.16, "text": " So I think we've done all this before.", "tokens": [407, 286, 519, 321, 600, 1096, 439, 341, 949, 13], "temperature": 0.0, "avg_logprob": -0.15830473466352982, "compression_ratio": 1.575, "no_speech_prob": 2.078242141578812e-05}, {"id": 389, "seek": 235316, "start": 2372.16, "end": 2374.16, "text": " So get split and label.", "tokens": [407, 483, 7472, 293, 7645, 13], "temperature": 0.0, "avg_logprob": -0.15830473466352982, "compression_ratio": 1.575, "no_speech_prob": 2.078242141578812e-05}, {"id": 390, "seek": 235316, "start": 2374.16, "end": 2378.16, "text": " We've seen all that before.", "tokens": [492, 600, 1612, 439, 300, 949, 13], "temperature": 0.0, "avg_logprob": -0.15830473466352982, "compression_ratio": 1.575, "no_speech_prob": 2.078242141578812e-05}, {"id": 391, "seek": 235316, "start": 2378.16, "end": 2380.16, "text": " Category that we've seen before.", "tokens": [383, 48701, 300, 321, 600, 1612, 949, 13], "temperature": 0.0, "avg_logprob": -0.15830473466352982, "compression_ratio": 1.575, "no_speech_prob": 2.078242141578812e-05}, {"id": 392, "seek": 238016, "start": 2380.16, "end": 2386.16, "text": " Oh we didn't look at pipeline setup.", "tokens": [876, 321, 994, 380, 574, 412, 15517, 8657, 13], "temperature": 0.0, "avg_logprob": -0.14904161861964635, "compression_ratio": 1.5034482758620689, "no_speech_prob": 3.237673581679701e-06}, {"id": 393, "seek": 238016, "start": 2386.16, "end": 2389.16, "text": " OK. So we've talked briefly about pipeline setup before.", "tokens": [2264, 13, 407, 321, 600, 2825, 10515, 466, 15517, 8657, 949, 13], "temperature": 0.0, "avg_logprob": -0.14904161861964635, "compression_ratio": 1.5034482758620689, "no_speech_prob": 3.237673581679701e-06}, {"id": 394, "seek": 238016, "start": 2389.16, "end": 2402.16, "text": " So in something like categorize if you don't pass a vocab in to categorize it uses setup to automatically create a category.", "tokens": [407, 294, 746, 411, 19250, 1125, 498, 291, 500, 380, 1320, 257, 2329, 455, 294, 281, 19250, 1125, 309, 4960, 8657, 281, 6772, 1884, 257, 7719, 13], "temperature": 0.0, "avg_logprob": -0.14904161861964635, "compression_ratio": 1.5034482758620689, "no_speech_prob": 3.237673581679701e-06}, {"id": 395, "seek": 240216, "start": 2402.16, "end": 2423.16, "text": " So a vocab and a vocab is a category map class which is this very small little thing which simply will call dot unique on the list of items to find out the vocab unless it's a pandas data frame in the categorical series in which case the pandas already has that done for us.", "tokens": [407, 257, 2329, 455, 293, 257, 2329, 455, 307, 257, 7719, 4471, 1508, 597, 307, 341, 588, 1359, 707, 551, 597, 2935, 486, 818, 5893, 3845, 322, 264, 1329, 295, 4754, 281, 915, 484, 264, 2329, 455, 5969, 309, 311, 257, 4565, 296, 1412, 3920, 294, 264, 19250, 804, 2638, 294, 597, 1389, 264, 4565, 296, 1217, 575, 300, 1096, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.19877803859426013, "compression_ratio": 1.611764705882353, "no_speech_prob": 2.902236474255915e-06}, {"id": 396, "seek": 242316, "start": 2423.16, "end": 2432.16, "text": " So the key thing here is calling setup or setups because it's a transform.", "tokens": [407, 264, 2141, 551, 510, 307, 5141, 8657, 420, 46832, 570, 309, 311, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.2219975866922518, "compression_ratio": 1.3539823008849559, "no_speech_prob": 1.1910744888155023e-06}, {"id": 397, "seek": 242316, "start": 2432.16, "end": 2436.16, "text": " The transform method that's a type dispatch method.", "tokens": [440, 4088, 3170, 300, 311, 257, 2010, 36729, 3170, 13], "temperature": 0.0, "avg_logprob": -0.2219975866922518, "compression_ratio": 1.3539823008849559, "no_speech_prob": 1.1910744888155023e-06}, {"id": 398, "seek": 242316, "start": 2436.16, "end": 2443.16, "text": " So if we look at pipeline.", "tokens": [407, 498, 321, 574, 412, 15517, 13], "temperature": 0.0, "avg_logprob": -0.2219975866922518, "compression_ratio": 1.3539823008849559, "no_speech_prob": 1.1910744888155023e-06}, {"id": 399, "seek": 244316, "start": 2443.16, "end": 2457.16, "text": " So if we can find some setup examples.", "tokens": [407, 498, 321, 393, 915, 512, 8657, 5110, 13], "temperature": 0.0, "avg_logprob": -0.19282657869400516, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.2805170626961626e-05}, {"id": 400, "seek": 244316, "start": 2457.16, "end": 2459.16, "text": " You know have good setup examples.", "tokens": [509, 458, 362, 665, 8657, 5110, 13], "temperature": 0.0, "avg_logprob": -0.19282657869400516, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.2805170626961626e-05}, {"id": 401, "seek": 244316, "start": 2459.16, "end": 2461.16, "text": " That sounds like an oversight.", "tokens": [663, 3263, 411, 364, 29146, 13], "temperature": 0.0, "avg_logprob": -0.19282657869400516, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.2805170626961626e-05}, {"id": 402, "seek": 244316, "start": 2461.16, "end": 2469.16, "text": " I guess the setup examples probably won't come to all we look at data source.", "tokens": [286, 2041, 264, 8657, 5110, 1391, 1582, 380, 808, 281, 439, 321, 574, 412, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.19282657869400516, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.2805170626961626e-05}, {"id": 403, "seek": 244316, "start": 2469.16, "end": 2470.16, "text": " Well here's a good place to look at them.", "tokens": [1042, 510, 311, 257, 665, 1081, 281, 574, 412, 552, 13], "temperature": 0.0, "avg_logprob": -0.19282657869400516, "compression_ratio": 1.5135135135135136, "no_speech_prob": 1.2805170626961626e-05}, {"id": 404, "seek": 247016, "start": 2470.16, "end": 2477.16, "text": " So let's learn about setups by looking at categorize. So categorize I've already taken you through this code.", "tokens": [407, 718, 311, 1466, 466, 46832, 538, 1237, 412, 19250, 1125, 13, 407, 19250, 1125, 286, 600, 1217, 2726, 291, 807, 341, 3089, 13], "temperature": 0.0, "avg_logprob": -0.12054671770260658, "compression_ratio": 1.6043956043956045, "no_speech_prob": 7.453525654455007e-07}, {"id": 405, "seek": 247016, "start": 2477.16, "end": 2488.16, "text": " The key thing is that we we need to make sure we call setup at exactly the right time.", "tokens": [440, 2141, 551, 307, 300, 321, 321, 643, 281, 652, 988, 321, 818, 8657, 412, 2293, 264, 558, 565, 13], "temperature": 0.0, "avg_logprob": -0.12054671770260658, "compression_ratio": 1.6043956043956045, "no_speech_prob": 7.453525654455007e-07}, {"id": 406, "seek": 247016, "start": 2488.16, "end": 2492.16, "text": " If you look at here in pets.", "tokens": [759, 291, 574, 412, 510, 294, 19897, 13], "temperature": 0.0, "avg_logprob": -0.12054671770260658, "compression_ratio": 1.6043956043956045, "no_speech_prob": 7.453525654455007e-07}, {"id": 407, "seek": 247016, "start": 2492.16, "end": 2495.16, "text": " We need to first we need to label.", "tokens": [492, 643, 281, 700, 321, 643, 281, 7645, 13], "temperature": 0.0, "avg_logprob": -0.12054671770260658, "compression_ratio": 1.6043956043956045, "no_speech_prob": 7.453525654455007e-07}, {"id": 408, "seek": 247016, "start": 2495.16, "end": 2497.16, "text": " And then we need to categorize.", "tokens": [400, 550, 321, 643, 281, 19250, 1125, 13], "temperature": 0.0, "avg_logprob": -0.12054671770260658, "compression_ratio": 1.6043956043956045, "no_speech_prob": 7.453525654455007e-07}, {"id": 409, "seek": 249716, "start": 2497.16, "end": 2508.16, "text": " And more importantly when we create a vocab we need to create a vocab on the after calling the label.", "tokens": [400, 544, 8906, 562, 321, 1884, 257, 2329, 455, 321, 643, 281, 1884, 257, 2329, 455, 322, 264, 934, 5141, 264, 7645, 13], "temperature": 0.0, "avg_logprob": -0.11911042286799504, "compression_ratio": 1.5906040268456376, "no_speech_prob": 1.7603089190743049e-06}, {"id": 410, "seek": 249716, "start": 2508.16, "end": 2515.16, "text": " So what happens is that setup is going to be called also as part of the pipeline.", "tokens": [407, 437, 2314, 307, 300, 8657, 307, 516, 281, 312, 1219, 611, 382, 644, 295, 264, 15517, 13], "temperature": 0.0, "avg_logprob": -0.11911042286799504, "compression_ratio": 1.5906040268456376, "no_speech_prob": 1.7603089190743049e-06}, {"id": 411, "seek": 249716, "start": 2515.16, "end": 2520.16, "text": " So if you look at the pipeline.", "tokens": [407, 498, 291, 574, 412, 264, 15517, 13], "temperature": 0.0, "avg_logprob": -0.11911042286799504, "compression_ratio": 1.5906040268456376, "no_speech_prob": 1.7603089190743049e-06}, {"id": 412, "seek": 249716, "start": 2520.16, "end": 2525.16, "text": " Here it is his setup.", "tokens": [1692, 309, 307, 702, 8657, 13], "temperature": 0.0, "avg_logprob": -0.11911042286799504, "compression_ratio": 1.5906040268456376, "no_speech_prob": 1.7603089190743049e-06}, {"id": 413, "seek": 252516, "start": 2525.16, "end": 2532.16, "text": " We what we actually do is we set self dot functions to an empty list.", "tokens": [492, 437, 321, 767, 360, 307, 321, 992, 2698, 5893, 6828, 281, 364, 6707, 1329, 13], "temperature": 0.0, "avg_logprob": -0.16311421555079772, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.766399903630372e-06}, {"id": 414, "seek": 252516, "start": 2532.16, "end": 2535.16, "text": " So we say we actually don't know what our transforms are.", "tokens": [407, 321, 584, 321, 767, 500, 380, 458, 437, 527, 35592, 366, 13], "temperature": 0.0, "avg_logprob": -0.16311421555079772, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.766399903630372e-06}, {"id": 415, "seek": 252516, "start": 2535.16, "end": 2540.16, "text": " And then we store that list of functions in a temporary thing called to firms.", "tokens": [400, 550, 321, 3531, 300, 1329, 295, 6828, 294, 257, 13413, 551, 1219, 281, 18055, 13], "temperature": 0.0, "avg_logprob": -0.16311421555079772, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.766399903630372e-06}, {"id": 416, "seek": 252516, "start": 2540.16, "end": 2543.16, "text": " And then we go through each to firm.", "tokens": [400, 550, 321, 352, 807, 1184, 281, 6174, 13], "temperature": 0.0, "avg_logprob": -0.16311421555079772, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.766399903630372e-06}, {"id": 417, "seek": 252516, "start": 2543.16, "end": 2545.16, "text": " And add it.", "tokens": [400, 909, 309, 13], "temperature": 0.0, "avg_logprob": -0.16311421555079772, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.766399903630372e-06}, {"id": 418, "seek": 252516, "start": 2545.16, "end": 2551.16, "text": " And what ad does is add then call setup and then adds it to the list.", "tokens": [400, 437, 614, 775, 307, 909, 550, 818, 8657, 293, 550, 10860, 309, 281, 264, 1329, 13], "temperature": 0.0, "avg_logprob": -0.16311421555079772, "compression_ratio": 1.7287234042553192, "no_speech_prob": 7.766399903630372e-06}, {"id": 419, "seek": 255116, "start": 2551.16, "end": 2561.16, "text": " So the reason we do it in this rather awkward way is because this way when we call categorize.", "tokens": [407, 264, 1778, 321, 360, 309, 294, 341, 2831, 11411, 636, 307, 570, 341, 636, 562, 321, 818, 19250, 1125, 13], "temperature": 0.0, "avg_logprob": -0.15507674497716567, "compression_ratio": 1.640625, "no_speech_prob": 2.3687639441050123e-06}, {"id": 420, "seek": 255116, "start": 2561.16, "end": 2567.16, "text": " It will have already added the label to the pipeline.", "tokens": [467, 486, 362, 1217, 3869, 264, 7645, 281, 264, 15517, 13], "temperature": 0.0, "avg_logprob": -0.15507674497716567, "compression_ratio": 1.640625, "no_speech_prob": 2.3687639441050123e-06}, {"id": 421, "seek": 255116, "start": 2567.16, "end": 2571.16, "text": " So it's going to go through and it's going to say OK the first thing is sorry.", "tokens": [407, 309, 311, 516, 281, 352, 807, 293, 309, 311, 516, 281, 584, 2264, 264, 700, 551, 307, 2597, 13], "temperature": 0.0, "avg_logprob": -0.15507674497716567, "compression_ratio": 1.640625, "no_speech_prob": 2.3687639441050123e-06}, {"id": 422, "seek": 255116, "start": 2571.16, "end": 2574.16, "text": " The first thing is label.", "tokens": [440, 700, 551, 307, 7645, 13], "temperature": 0.0, "avg_logprob": -0.15507674497716567, "compression_ratio": 1.640625, "no_speech_prob": 2.3687639441050123e-06}, {"id": 423, "seek": 255116, "start": 2574.16, "end": 2577.16, "text": " So it'll self to add label which doesn't really have a setup.", "tokens": [407, 309, 603, 2698, 281, 909, 7645, 597, 1177, 380, 534, 362, 257, 8657, 13], "temperature": 0.0, "avg_logprob": -0.15507674497716567, "compression_ratio": 1.640625, "no_speech_prob": 2.3687639441050123e-06}, {"id": 424, "seek": 257716, "start": 2577.16, "end": 2583.16, "text": " So just adds it to the list and then it will add.", "tokens": [407, 445, 10860, 309, 281, 264, 1329, 293, 550, 309, 486, 909, 13], "temperature": 0.0, "avg_logprob": -0.18217353215293278, "compression_ratio": 1.5177304964539007, "no_speech_prob": 9.818187209020834e-06}, {"id": 425, "seek": 257716, "start": 2583.16, "end": 2587.16, "text": " Categorize.", "tokens": [383, 2968, 284, 1125, 13], "temperature": 0.0, "avg_logprob": -0.18217353215293278, "compression_ratio": 1.5177304964539007, "no_speech_prob": 9.818187209020834e-06}, {"id": 426, "seek": 257716, "start": 2587.16, "end": 2593.16, "text": " And notice it called setup before it adds it right because we can't append it before we call it setup.", "tokens": [400, 3449, 309, 1219, 8657, 949, 309, 10860, 309, 558, 570, 321, 393, 380, 34116, 309, 949, 321, 818, 309, 8657, 13], "temperature": 0.0, "avg_logprob": -0.18217353215293278, "compression_ratio": 1.5177304964539007, "no_speech_prob": 9.818187209020834e-06}, {"id": 427, "seek": 257716, "start": 2593.16, "end": 2600.16, "text": " And so that's why the setups is going to get the.", "tokens": [400, 370, 300, 311, 983, 264, 46832, 307, 516, 281, 483, 264, 13], "temperature": 0.0, "avg_logprob": -0.18217353215293278, "compression_ratio": 1.5177304964539007, "no_speech_prob": 9.818187209020834e-06}, {"id": 428, "seek": 260016, "start": 2600.16, "end": 2607.16, "text": " It's not going to get the raw paths it's going to get the paths after the labels have been extracted from them.", "tokens": [467, 311, 406, 516, 281, 483, 264, 8936, 14518, 309, 311, 516, 281, 483, 264, 14518, 934, 264, 16949, 362, 668, 34086, 490, 552, 13], "temperature": 0.0, "avg_logprob": -0.11194308407335396, "compression_ratio": 1.6523809523809523, "no_speech_prob": 2.9021859972999664e-06}, {"id": 429, "seek": 260016, "start": 2607.16, "end": 2610.16, "text": " So this is kind of like a.", "tokens": [407, 341, 307, 733, 295, 411, 257, 13], "temperature": 0.0, "avg_logprob": -0.11194308407335396, "compression_ratio": 1.6523809523809523, "no_speech_prob": 2.9021859972999664e-06}, {"id": 430, "seek": 260016, "start": 2610.16, "end": 2618.16, "text": " Yes it's really important detail that we found pretty tricky to get right.", "tokens": [1079, 309, 311, 534, 1021, 2607, 300, 321, 1352, 1238, 12414, 281, 483, 558, 13], "temperature": 0.0, "avg_logprob": -0.11194308407335396, "compression_ratio": 1.6523809523809523, "no_speech_prob": 2.9021859972999664e-06}, {"id": 431, "seek": 260016, "start": 2618.16, "end": 2627.16, "text": " But now that it's there we find just super handy because the right information goes automatically to the right parts of the pipeline.", "tokens": [583, 586, 300, 309, 311, 456, 321, 915, 445, 1687, 13239, 570, 264, 558, 1589, 1709, 6772, 281, 264, 558, 3166, 295, 264, 15517, 13], "temperature": 0.0, "avg_logprob": -0.11194308407335396, "compression_ratio": 1.6523809523809523, "no_speech_prob": 2.9021859972999664e-06}, {"id": 432, "seek": 262716, "start": 2627.16, "end": 2630.16, "text": " And so things can set themselves up automatically.", "tokens": [400, 370, 721, 393, 992, 2969, 493, 6772, 13], "temperature": 0.0, "avg_logprob": -0.14065569005113968, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.255288670014124e-06}, {"id": 433, "seek": 262716, "start": 2630.16, "end": 2633.16, "text": " So that's really handy.", "tokens": [407, 300, 311, 534, 13239, 13], "temperature": 0.0, "avg_logprob": -0.14065569005113968, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.255288670014124e-06}, {"id": 434, "seek": 262716, "start": 2633.16, "end": 2637.16, "text": " So that's the key thing to kind of understand in categorize is that setup.", "tokens": [407, 300, 311, 264, 2141, 551, 281, 733, 295, 1223, 294, 19250, 1125, 307, 300, 8657, 13], "temperature": 0.0, "avg_logprob": -0.14065569005113968, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.255288670014124e-06}, {"id": 435, "seek": 262716, "start": 2637.16, "end": 2641.16, "text": " Yes it's really the first time we properly test and display how setup works.", "tokens": [1079, 309, 311, 534, 264, 700, 565, 321, 6108, 1500, 293, 4674, 577, 8657, 1985, 13], "temperature": 0.0, "avg_logprob": -0.14065569005113968, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.255288670014124e-06}, {"id": 436, "seek": 262716, "start": 2641.16, "end": 2652.16, "text": " And so you can see here we create a TFMDS with cat dog cat as our items and our pipeline is just a.", "tokens": [400, 370, 291, 393, 536, 510, 321, 1884, 257, 40964, 44, 11844, 365, 3857, 3000, 3857, 382, 527, 4754, 293, 527, 15517, 307, 445, 257, 13], "temperature": 0.0, "avg_logprob": -0.14065569005113968, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.255288670014124e-06}, {"id": 437, "seek": 262716, "start": 2652.16, "end": 2656.16, "text": " Categorize transform.", "tokens": [383, 2968, 284, 1125, 4088, 13], "temperature": 0.0, "avg_logprob": -0.14065569005113968, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.255288670014124e-06}, {"id": 438, "seek": 265616, "start": 2656.16, "end": 2660.16, "text": " And so at the end of that the vocab should be cat dog.", "tokens": [400, 370, 412, 264, 917, 295, 300, 264, 2329, 455, 820, 312, 3857, 3000, 13], "temperature": 0.0, "avg_logprob": -0.15526254126366149, "compression_ratio": 1.6080402010050252, "no_speech_prob": 1.1842636922665406e-05}, {"id": 439, "seek": 265616, "start": 2660.16, "end": 2664.16, "text": " It is.", "tokens": [467, 307, 13], "temperature": 0.0, "avg_logprob": -0.15526254126366149, "compression_ratio": 1.6080402010050252, "no_speech_prob": 1.1842636922665406e-05}, {"id": 440, "seek": 265616, "start": 2664.16, "end": 2667.16, "text": " So body categorized doesn't have any new information.", "tokens": [407, 1772, 19250, 1602, 1177, 380, 362, 604, 777, 1589, 13], "temperature": 0.0, "avg_logprob": -0.15526254126366149, "compression_ratio": 1.6080402010050252, "no_speech_prob": 1.1842636922665406e-05}, {"id": 441, "seek": 265616, "start": 2667.16, "end": 2668.16, "text": " It's the same stuff.", "tokens": [467, 311, 264, 912, 1507, 13], "temperature": 0.0, "avg_logprob": -0.15526254126366149, "compression_ratio": 1.6080402010050252, "no_speech_prob": 1.1842636922665406e-05}, {"id": 442, "seek": 265616, "start": 2668.16, "end": 2681.16, "text": " It's a good way that you can check it out to get a second kind of angle on how setup works.", "tokens": [467, 311, 257, 665, 636, 300, 291, 393, 1520, 309, 484, 281, 483, 257, 1150, 733, 295, 5802, 322, 577, 8657, 1985, 13], "temperature": 0.0, "avg_logprob": -0.15526254126366149, "compression_ratio": 1.6080402010050252, "no_speech_prob": 1.1842636922665406e-05}, {"id": 443, "seek": 265616, "start": 2681.16, "end": 2685.16, "text": " So now that we've got all that we have all the information we need to create to from the L.", "tokens": [407, 586, 300, 321, 600, 658, 439, 300, 321, 362, 439, 264, 1589, 321, 643, 281, 1884, 281, 490, 264, 441, 13], "temperature": 0.0, "avg_logprob": -0.15526254126366149, "compression_ratio": 1.6080402010050252, "no_speech_prob": 1.1842636922665406e-05}, {"id": 444, "seek": 268516, "start": 2685.16, "end": 2691.16, "text": " So now if you go back and look at TFMDL again it'll be more straightforward.", "tokens": [407, 586, 498, 291, 352, 646, 293, 574, 412, 40964, 44, 35, 43, 797, 309, 603, 312, 544, 15325, 13], "temperature": 0.0, "avg_logprob": -0.13268881752377465, "compression_ratio": 1.5933014354066986, "no_speech_prob": 6.6432189669285435e-06}, {"id": 445, "seek": 268516, "start": 2691.16, "end": 2698.16, "text": " So you can see that we go through each of after item before batch after batch.", "tokens": [407, 291, 393, 536, 300, 321, 352, 807, 1184, 295, 934, 3174, 949, 15245, 934, 15245, 13], "temperature": 0.0, "avg_logprob": -0.13268881752377465, "compression_ratio": 1.5933014354066986, "no_speech_prob": 6.6432189669285435e-06}, {"id": 446, "seek": 268516, "start": 2698.16, "end": 2704.16, "text": " So these are all things in the data loaders kind of list of methods that goes through.", "tokens": [407, 613, 366, 439, 721, 294, 264, 1412, 3677, 433, 733, 295, 1329, 295, 7150, 300, 1709, 807, 13], "temperature": 0.0, "avg_logprob": -0.13268881752377465, "compression_ratio": 1.5933014354066986, "no_speech_prob": 6.6432189669285435e-06}, {"id": 447, "seek": 268516, "start": 2704.16, "end": 2713.16, "text": " And if you pass in any of those keyword arguments then it will grab that keyword argument.", "tokens": [400, 498, 291, 1320, 294, 604, 295, 729, 20428, 12869, 550, 309, 486, 4444, 300, 20428, 6770, 13], "temperature": 0.0, "avg_logprob": -0.13268881752377465, "compression_ratio": 1.5933014354066986, "no_speech_prob": 6.6432189669285435e-06}, {"id": 448, "seek": 271316, "start": 2713.16, "end": 2721.16, "text": " And turn it into a pipeline.", "tokens": [400, 1261, 309, 666, 257, 15517, 13], "temperature": 0.0, "avg_logprob": -0.1773700543812343, "compression_ratio": 1.4014598540145986, "no_speech_prob": 2.6274048650520854e-05}, {"id": 449, "seek": 271316, "start": 2721.16, "end": 2723.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1773700543812343, "compression_ratio": 1.4014598540145986, "no_speech_prob": 2.6274048650520854e-05}, {"id": 450, "seek": 271316, "start": 2723.16, "end": 2724.16, "text": " And.", "tokens": [400, 13], "temperature": 0.0, "avg_logprob": -0.1773700543812343, "compression_ratio": 1.4014598540145986, "no_speech_prob": 2.6274048650520854e-05}, {"id": 451, "seek": 271316, "start": 2724.16, "end": 2729.16, "text": " We'll then set it up.", "tokens": [492, 603, 550, 992, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.1773700543812343, "compression_ratio": 1.4014598540145986, "no_speech_prob": 2.6274048650520854e-05}, {"id": 452, "seek": 271316, "start": 2729.16, "end": 2739.16, "text": " And notice here it passes in self because the pipeline setup you know generally speaking it needs to know what items to set up with.", "tokens": [400, 3449, 510, 309, 11335, 294, 2698, 570, 264, 15517, 8657, 291, 458, 5101, 4124, 309, 2203, 281, 458, 437, 4754, 281, 992, 493, 365, 13], "temperature": 0.0, "avg_logprob": -0.1773700543812343, "compression_ratio": 1.4014598540145986, "no_speech_prob": 2.6274048650520854e-05}, {"id": 453, "seek": 273916, "start": 2739.16, "end": 2744.16, "text": " So for example in categorize.", "tokens": [407, 337, 1365, 294, 19250, 1125, 13], "temperature": 0.0, "avg_logprob": -0.14836663213269463, "compression_ratio": 1.3309859154929577, "no_speech_prob": 3.966769781982293e-06}, {"id": 454, "seek": 273916, "start": 2744.16, "end": 2751.16, "text": " It's the setup is receiving the actual list of.", "tokens": [467, 311, 264, 8657, 307, 10040, 264, 3539, 1329, 295, 13], "temperature": 0.0, "avg_logprob": -0.14836663213269463, "compression_ratio": 1.3309859154929577, "no_speech_prob": 3.966769781982293e-06}, {"id": 455, "seek": 273916, "start": 2751.16, "end": 2761.16, "text": " Labeled items to create a vocab with.", "tokens": [10137, 31689, 4754, 281, 1884, 257, 2329, 455, 365, 13], "temperature": 0.0, "avg_logprob": -0.14836663213269463, "compression_ratio": 1.3309859154929577, "no_speech_prob": 3.966769781982293e-06}, {"id": 456, "seek": 273916, "start": 2761.16, "end": 2763.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.14836663213269463, "compression_ratio": 1.3309859154929577, "no_speech_prob": 3.966769781982293e-06}, {"id": 457, "seek": 273916, "start": 2763.16, "end": 2768.16, "text": " So that's the key thing here is we now know what these pipelines are.", "tokens": [407, 300, 311, 264, 2141, 551, 510, 307, 321, 586, 458, 437, 613, 40168, 366, 13], "temperature": 0.0, "avg_logprob": -0.14836663213269463, "compression_ratio": 1.3309859154929577, "no_speech_prob": 3.966769781982293e-06}, {"id": 458, "seek": 276816, "start": 2768.16, "end": 2774.16, "text": " And so you can now also look and see how the code is actually working.", "tokens": [400, 370, 291, 393, 586, 611, 574, 293, 536, 577, 264, 3089, 307, 767, 1364, 13], "temperature": 0.0, "avg_logprob": -0.11769116492498488, "compression_ratio": 1.2920353982300885, "no_speech_prob": 1.8340586393605918e-05}, {"id": 459, "seek": 276816, "start": 2774.16, "end": 2787.16, "text": " And it's called calling decode on each of those things in the pipeline.", "tokens": [400, 309, 311, 1219, 5141, 979, 1429, 322, 1184, 295, 729, 721, 294, 264, 15517, 13], "temperature": 0.0, "avg_logprob": -0.11769116492498488, "compression_ratio": 1.2920353982300885, "no_speech_prob": 1.8340586393605918e-05}, {"id": 460, "seek": 276816, "start": 2787.16, "end": 2793.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.11769116492498488, "compression_ratio": 1.2920353982300885, "no_speech_prob": 1.8340586393605918e-05}, {"id": 461, "seek": 279316, "start": 2793.16, "end": 2798.16, "text": " So now we can look at some more examples.", "tokens": [407, 586, 321, 393, 574, 412, 512, 544, 5110, 13], "temperature": 0.0, "avg_logprob": -0.13207616391389265, "compression_ratio": 1.6704980842911878, "no_speech_prob": 2.9021937280049315e-06}, {"id": 462, "seek": 279316, "start": 2798.16, "end": 2806.16, "text": " So we now can see CUDA is just a transform that has an encodes and decodes and encodes.", "tokens": [407, 321, 586, 393, 536, 29777, 7509, 307, 445, 257, 4088, 300, 575, 364, 2058, 4789, 293, 979, 4789, 293, 2058, 4789, 13], "temperature": 0.0, "avg_logprob": -0.13207616391389265, "compression_ratio": 1.6704980842911878, "no_speech_prob": 2.9021937280049315e-06}, {"id": 463, "seek": 279316, "start": 2806.16, "end": 2807.16, "text": " We've seen this one before.", "tokens": [492, 600, 1612, 341, 472, 949, 13], "temperature": 0.0, "avg_logprob": -0.13207616391389265, "compression_ratio": 1.6704980842911878, "no_speech_prob": 2.9021937280049315e-06}, {"id": 464, "seek": 279316, "start": 2807.16, "end": 2811.16, "text": " Puts it on the device and decodes puts on the CPU.", "tokens": [430, 3648, 309, 322, 264, 4302, 293, 979, 4789, 8137, 322, 264, 13199, 13], "temperature": 0.0, "avg_logprob": -0.13207616391389265, "compression_ratio": 1.6704980842911878, "no_speech_prob": 2.9021937280049315e-06}, {"id": 465, "seek": 279316, "start": 2811.16, "end": 2815.16, "text": " And this is pretty cool because I don't think there are any other.", "tokens": [400, 341, 307, 1238, 1627, 570, 286, 500, 380, 519, 456, 366, 604, 661, 13], "temperature": 0.0, "avg_logprob": -0.13207616391389265, "compression_ratio": 1.6704980842911878, "no_speech_prob": 2.9021937280049315e-06}, {"id": 466, "seek": 279316, "start": 2815.16, "end": 2822.16, "text": " Frameworks that will like automatically put things on the back on the CPU for you when you're all done with them for the purpose of displaying them or whatever.", "tokens": [31628, 18357, 300, 486, 411, 6772, 829, 721, 322, 264, 646, 322, 264, 13199, 337, 291, 562, 291, 434, 439, 1096, 365, 552, 337, 264, 4334, 295, 36834, 552, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.13207616391389265, "compression_ratio": 1.6704980842911878, "no_speech_prob": 2.9021937280049315e-06}, {"id": 467, "seek": 282216, "start": 2822.16, "end": 2828.16, "text": " You don't have any memory links.", "tokens": [509, 500, 380, 362, 604, 4675, 6123, 13], "temperature": 0.0, "avg_logprob": -0.22670292573816636, "compression_ratio": 1.4555555555555555, "no_speech_prob": 3.705124618136324e-05}, {"id": 468, "seek": 282216, "start": 2828.16, "end": 2831.16, "text": " But to float tensor we've seen.", "tokens": [583, 281, 15706, 40863, 321, 600, 1612, 13], "temperature": 0.0, "avg_logprob": -0.22670292573816636, "compression_ratio": 1.4555555555555555, "no_speech_prob": 3.705124618136324e-05}, {"id": 469, "seek": 282216, "start": 2831.16, "end": 2835.16, "text": " Normalization we've seen.", "tokens": [21277, 2144, 321, 600, 1612, 13], "temperature": 0.0, "avg_logprob": -0.22670292573816636, "compression_ratio": 1.4555555555555555, "no_speech_prob": 3.705124618136324e-05}, {"id": 470, "seek": 282216, "start": 2835.16, "end": 2838.16, "text": " And data bunch we've seen.", "tokens": [400, 1412, 3840, 321, 600, 1612, 13], "temperature": 0.0, "avg_logprob": -0.22670292573816636, "compression_ratio": 1.4555555555555555, "no_speech_prob": 3.705124618136324e-05}, {"id": 471, "seek": 282216, "start": 2838.16, "end": 2840.16, "text": " OK. So we're kind of gradually working back up here.", "tokens": [2264, 13, 407, 321, 434, 733, 295, 13145, 1364, 646, 493, 510, 13], "temperature": 0.0, "avg_logprob": -0.22670292573816636, "compression_ratio": 1.4555555555555555, "no_speech_prob": 3.705124618136324e-05}, {"id": 472, "seek": 282216, "start": 2840.16, "end": 2842.16, "text": " Nice.", "tokens": [5490, 13], "temperature": 0.0, "avg_logprob": -0.22670292573816636, "compression_ratio": 1.4555555555555555, "no_speech_prob": 3.705124618136324e-05}, {"id": 473, "seek": 282216, "start": 2842.16, "end": 2844.16, "text": " And hopefully.", "tokens": [400, 4696, 13], "temperature": 0.0, "avg_logprob": -0.22670292573816636, "compression_ratio": 1.4555555555555555, "no_speech_prob": 3.705124618136324e-05}, {"id": 474, "seek": 282216, "start": 2844.16, "end": 2850.16, "text": " Yes. We're now up to 06 which is really what I wanted to get to today.", "tokens": [1079, 13, 492, 434, 586, 493, 281, 1958, 21, 597, 307, 534, 437, 286, 1415, 281, 483, 281, 965, 13], "temperature": 0.0, "avg_logprob": -0.22670292573816636, "compression_ratio": 1.4555555555555555, "no_speech_prob": 3.705124618136324e-05}, {"id": 475, "seek": 285016, "start": 2850.16, "end": 2853.16, "text": " And so 06 introduces data source.", "tokens": [400, 370, 1958, 21, 31472, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.17719310909122615, "compression_ratio": 1.4790419161676647, "no_speech_prob": 7.3677183536347e-05}, {"id": 476, "seek": 285016, "start": 2853.16, "end": 2859.16, "text": " And to remember what data source does we look at the 08 pets tutorial.", "tokens": [400, 281, 1604, 437, 1412, 4009, 775, 321, 574, 412, 264, 1958, 23, 19897, 7073, 13], "temperature": 0.0, "avg_logprob": -0.17719310909122615, "compression_ratio": 1.4790419161676647, "no_speech_prob": 7.3677183536347e-05}, {"id": 477, "seek": 285016, "start": 2859.16, "end": 2867.16, "text": " Data source is something which is almost identical to TFMDS.", "tokens": [11888, 4009, 307, 746, 597, 307, 1920, 14800, 281, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.17719310909122615, "compression_ratio": 1.4790419161676647, "no_speech_prob": 7.3677183536347e-05}, {"id": 478, "seek": 285016, "start": 2867.16, "end": 2870.16, "text": " In fact, TFMDS.", "tokens": [682, 1186, 11, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.17719310909122615, "compression_ratio": 1.4790419161676647, "no_speech_prob": 7.3677183536347e-05}, {"id": 479, "seek": 285016, "start": 2870.16, "end": 2875.16, "text": " Let's go back and have a look at our.", "tokens": [961, 311, 352, 646, 293, 362, 257, 574, 412, 527, 13], "temperature": 0.0, "avg_logprob": -0.17719310909122615, "compression_ratio": 1.4790419161676647, "no_speech_prob": 7.3677183536347e-05}, {"id": 480, "seek": 285016, "start": 2875.16, "end": 2877.16, "text": " Version of pets with TFMDS.", "tokens": [35965, 295, 19897, 365, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.17719310909122615, "compression_ratio": 1.4790419161676647, "no_speech_prob": 7.3677183536347e-05}, {"id": 481, "seek": 287716, "start": 2877.16, "end": 2880.16, "text": " This is the TFMDS version of pets.", "tokens": [639, 307, 264, 40964, 44, 11844, 3037, 295, 19897, 13], "temperature": 0.0, "avg_logprob": -0.16481747204744363, "compression_ratio": 1.6243093922651934, "no_speech_prob": 1.723045170365367e-05}, {"id": 482, "seek": 287716, "start": 2880.16, "end": 2886.16, "text": " We had two sets of transforms one which is PO image create one which was labeled and categorized.", "tokens": [492, 632, 732, 6352, 295, 35592, 472, 597, 307, 22299, 3256, 1884, 472, 597, 390, 21335, 293, 19250, 1602, 13], "temperature": 0.0, "avg_logprob": -0.16481747204744363, "compression_ratio": 1.6243093922651934, "no_speech_prob": 1.723045170365367e-05}, {"id": 483, "seek": 287716, "start": 2886.16, "end": 2890.16, "text": " Then we created a TFMDS passing in the items and the transforms.", "tokens": [1396, 321, 2942, 257, 40964, 44, 11844, 8437, 294, 264, 4754, 293, 264, 35592, 13], "temperature": 0.0, "avg_logprob": -0.16481747204744363, "compression_ratio": 1.6243093922651934, "no_speech_prob": 1.723045170365367e-05}, {"id": 484, "seek": 287716, "start": 2890.16, "end": 2897.16, "text": " And then we made that into a data loader passing in some after item.", "tokens": [400, 550, 321, 1027, 300, 666, 257, 1412, 3677, 260, 8437, 294, 512, 934, 3174, 13], "temperature": 0.0, "avg_logprob": -0.16481747204744363, "compression_ratio": 1.6243093922651934, "no_speech_prob": 1.723045170365367e-05}, {"id": 485, "seek": 287716, "start": 2897.16, "end": 2901.16, "text": " Transforms to happen there.", "tokens": [27938, 82, 281, 1051, 456, 13], "temperature": 0.0, "avg_logprob": -0.16481747204744363, "compression_ratio": 1.6243093922651934, "no_speech_prob": 1.723045170365367e-05}, {"id": 486, "seek": 290116, "start": 2901.16, "end": 2908.16, "text": " Notice that if I copy just the TDS get out and paste it here.", "tokens": [13428, 300, 498, 286, 5055, 445, 264, 314, 11844, 483, 484, 293, 9163, 309, 510, 13], "temperature": 0.0, "avg_logprob": -0.14466027246005292, "compression_ratio": 1.4933333333333334, "no_speech_prob": 5.093514118925668e-06}, {"id": 487, "seek": 290116, "start": 2908.16, "end": 2911.16, "text": " The TDS.", "tokens": [440, 314, 11844, 13], "temperature": 0.0, "avg_logprob": -0.14466027246005292, "compression_ratio": 1.4933333333333334, "no_speech_prob": 5.093514118925668e-06}, {"id": 488, "seek": 290116, "start": 2911.16, "end": 2918.16, "text": " Let's find them up so you can see.", "tokens": [961, 311, 915, 552, 493, 370, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.14466027246005292, "compression_ratio": 1.4933333333333334, "no_speech_prob": 5.093514118925668e-06}, {"id": 489, "seek": 290116, "start": 2918.16, "end": 2923.16, "text": " As you can see, TFMDS and the data source versions are almost identical.", "tokens": [1018, 291, 393, 536, 11, 40964, 44, 11844, 293, 264, 1412, 4009, 9606, 366, 1920, 14800, 13], "temperature": 0.0, "avg_logprob": -0.14466027246005292, "compression_ratio": 1.4933333333333334, "no_speech_prob": 5.093514118925668e-06}, {"id": 490, "seek": 290116, "start": 2923.16, "end": 2926.16, "text": " And the way you use them is almost identical.", "tokens": [400, 264, 636, 291, 764, 552, 307, 1920, 14800, 13], "temperature": 0.0, "avg_logprob": -0.14466027246005292, "compression_ratio": 1.4933333333333334, "no_speech_prob": 5.093514118925668e-06}, {"id": 491, "seek": 292616, "start": 2926.16, "end": 2933.16, "text": " The difference is one extra argument, which is the filters.", "tokens": [440, 2649, 307, 472, 2857, 6770, 11, 597, 307, 264, 15995, 13], "temperature": 0.0, "avg_logprob": -0.14666289203571822, "compression_ratio": 1.4274193548387097, "no_speech_prob": 2.8407624995452352e-05}, {"id": 492, "seek": 292616, "start": 2933.16, "end": 2937.16, "text": " The filters tell the data source.", "tokens": [440, 15995, 980, 264, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.14666289203571822, "compression_ratio": 1.4274193548387097, "no_speech_prob": 2.8407624995452352e-05}, {"id": 493, "seek": 292616, "start": 2937.16, "end": 2940.16, "text": " How to do.", "tokens": [1012, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.14666289203571822, "compression_ratio": 1.4274193548387097, "no_speech_prob": 2.8407624995452352e-05}, {"id": 494, "seek": 292616, "start": 2940.16, "end": 2947.16, "text": " This, which is to get a subset and all it does literally is subset.", "tokens": [639, 11, 597, 307, 281, 483, 257, 25993, 293, 439, 309, 775, 3736, 307, 25993, 13], "temperature": 0.0, "avg_logprob": -0.14666289203571822, "compression_ratio": 1.4274193548387097, "no_speech_prob": 2.8407624995452352e-05}, {"id": 495, "seek": 292616, "start": 2947.16, "end": 2949.16, "text": " One.", "tokens": [1485, 13], "temperature": 0.0, "avg_logprob": -0.14666289203571822, "compression_ratio": 1.4274193548387097, "no_speech_prob": 2.8407624995452352e-05}, {"id": 496, "seek": 294916, "start": 2949.16, "end": 2957.16, "text": " Simply returns a new TFMDS which contains not items, but items.", "tokens": [19596, 11247, 257, 777, 40964, 44, 11844, 597, 8306, 406, 4754, 11, 457, 4754, 13], "temperature": 0.0, "avg_logprob": -0.14455771172183685, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.468024831614457e-05}, {"id": 497, "seek": 294916, "start": 2957.16, "end": 2960.16, "text": " For split IDX one.", "tokens": [1171, 7472, 7348, 55, 472, 13], "temperature": 0.0, "avg_logprob": -0.14455771172183685, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.468024831614457e-05}, {"id": 498, "seek": 294916, "start": 2960.16, "end": 2961.16, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.14455771172183685, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.468024831614457e-05}, {"id": 499, "seek": 294916, "start": 2961.16, "end": 2965.16, "text": " To remind you, this is a while ago.", "tokens": [1407, 4160, 291, 11, 341, 307, 257, 1339, 2057, 13], "temperature": 0.0, "avg_logprob": -0.14455771172183685, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.468024831614457e-05}, {"id": 500, "seek": 294916, "start": 2965.16, "end": 2968.16, "text": " Split IDX.", "tokens": [45111, 7348, 55, 13], "temperature": 0.0, "avg_logprob": -0.14455771172183685, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.468024831614457e-05}, {"id": 501, "seek": 294916, "start": 2968.16, "end": 2978.16, "text": " Was just our just a couple with two things in it, which is the list of indexes that are in the training set and the list of indexes in the validation set.", "tokens": [3027, 445, 527, 445, 257, 1916, 365, 732, 721, 294, 309, 11, 597, 307, 264, 1329, 295, 8186, 279, 300, 366, 294, 264, 3097, 992, 293, 264, 1329, 295, 8186, 279, 294, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.14455771172183685, "compression_ratio": 1.5483870967741935, "no_speech_prob": 2.468024831614457e-05}, {"id": 502, "seek": 297816, "start": 2978.16, "end": 2981.16, "text": " So this.", "tokens": [407, 341, 13], "temperature": 0.0, "avg_logprob": -0.2086409085417447, "compression_ratio": 1.4764705882352942, "no_speech_prob": 4.495020675676642e-06}, {"id": 503, "seek": 297816, "start": 2981.16, "end": 2988.16, "text": " And pets.subset one has another name, which is.", "tokens": [400, 19897, 13, 30131, 3854, 472, 575, 1071, 1315, 11, 597, 307, 13], "temperature": 0.0, "avg_logprob": -0.2086409085417447, "compression_ratio": 1.4764705882352942, "no_speech_prob": 4.495020675676642e-06}, {"id": 504, "seek": 297816, "start": 2988.16, "end": 2989.16, "text": " That valid.", "tokens": [663, 7363, 13], "temperature": 0.0, "avg_logprob": -0.2086409085417447, "compression_ratio": 1.4764705882352942, "no_speech_prob": 4.495020675676642e-06}, {"id": 505, "seek": 297816, "start": 2989.16, "end": 2995.16, "text": " That's exactly the same thing. And pets.subset zero is called also called dot train.", "tokens": [663, 311, 2293, 264, 912, 551, 13, 400, 19897, 13, 30131, 3854, 4018, 307, 1219, 611, 1219, 5893, 3847, 13], "temperature": 0.0, "avg_logprob": -0.2086409085417447, "compression_ratio": 1.4764705882352942, "no_speech_prob": 4.495020675676642e-06}, {"id": 506, "seek": 297816, "start": 2995.16, "end": 3004.16, "text": " So all this data source is doing is it's giving us something that looks like two different TFMDS.", "tokens": [407, 439, 341, 1412, 4009, 307, 884, 307, 309, 311, 2902, 505, 746, 300, 1542, 411, 732, 819, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.2086409085417447, "compression_ratio": 1.4764705882352942, "no_speech_prob": 4.495020675676642e-06}, {"id": 507, "seek": 300416, "start": 3004.16, "end": 3013.16, "text": " One which is going to give us back things from the validation set and one that's going to give us back things from the training set.", "tokens": [1485, 597, 307, 516, 281, 976, 505, 646, 721, 490, 264, 24071, 992, 293, 472, 300, 311, 516, 281, 976, 505, 646, 721, 490, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.09367475980593834, "compression_ratio": 1.6592178770949721, "no_speech_prob": 5.5941618484212086e-06}, {"id": 508, "seek": 300416, "start": 3013.16, "end": 3016.16, "text": " And the way it does that is by passing in.", "tokens": [400, 264, 636, 309, 775, 300, 307, 538, 8437, 294, 13], "temperature": 0.0, "avg_logprob": -0.09367475980593834, "compression_ratio": 1.6592178770949721, "no_speech_prob": 5.5941618484212086e-06}, {"id": 509, "seek": 300416, "start": 3016.16, "end": 3018.16, "text": " Filters.", "tokens": [7905, 1559, 13], "temperature": 0.0, "avg_logprob": -0.09367475980593834, "compression_ratio": 1.6592178770949721, "no_speech_prob": 5.5941618484212086e-06}, {"id": 510, "seek": 300416, "start": 3018.16, "end": 3025.16, "text": " So the way that works is actually.", "tokens": [407, 264, 636, 300, 1985, 307, 767, 13], "temperature": 0.0, "avg_logprob": -0.09367475980593834, "compression_ratio": 1.6592178770949721, "no_speech_prob": 5.5941618484212086e-06}, {"id": 511, "seek": 300416, "start": 3025.16, "end": 3032.16, "text": " Nice and easy. As you can see data source is much less than a screen of code.", "tokens": [5490, 293, 1858, 13, 1018, 291, 393, 536, 1412, 4009, 307, 709, 1570, 813, 257, 2568, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.09367475980593834, "compression_ratio": 1.6592178770949721, "no_speech_prob": 5.5941618484212086e-06}, {"id": 512, "seek": 303216, "start": 3032.16, "end": 3035.16, "text": " And quite a lot of that is actually the thing to create a data bunch.", "tokens": [400, 1596, 257, 688, 295, 300, 307, 767, 264, 551, 281, 1884, 257, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.1271717627843221, "compression_ratio": 1.705607476635514, "no_speech_prob": 1.922210503835231e-05}, {"id": 513, "seek": 303216, "start": 3035.16, "end": 3037.16, "text": " But the actual thing.", "tokens": [583, 264, 3539, 551, 13], "temperature": 0.0, "avg_logprob": -0.1271717627843221, "compression_ratio": 1.705607476635514, "no_speech_prob": 1.922210503835231e-05}, {"id": 514, "seek": 303216, "start": 3037.16, "end": 3042.16, "text": " You know, so as you can see it, it's a subclass of TFMDS.", "tokens": [509, 458, 11, 370, 382, 291, 393, 536, 309, 11, 309, 311, 257, 1422, 11665, 295, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.1271717627843221, "compression_ratio": 1.705607476635514, "no_speech_prob": 1.922210503835231e-05}, {"id": 515, "seek": 303216, "start": 3042.16, "end": 3046.16, "text": " Right. So it behaves a lot like TFMDS because it is a TFMDS.", "tokens": [1779, 13, 407, 309, 36896, 257, 688, 411, 40964, 44, 11844, 570, 309, 307, 257, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.1271717627843221, "compression_ratio": 1.705607476635514, "no_speech_prob": 1.922210503835231e-05}, {"id": 516, "seek": 303216, "start": 3046.16, "end": 3049.16, "text": " But it's a TFMDS that also has.", "tokens": [583, 309, 311, 257, 40964, 44, 11844, 300, 611, 575, 13], "temperature": 0.0, "avg_logprob": -0.1271717627843221, "compression_ratio": 1.705607476635514, "no_speech_prob": 1.922210503835231e-05}, {"id": 517, "seek": 303216, "start": 3049.16, "end": 3051.16, "text": " Subset.", "tokens": [8511, 3854, 13], "temperature": 0.0, "avg_logprob": -0.1271717627843221, "compression_ratio": 1.705607476635514, "no_speech_prob": 1.922210503835231e-05}, {"id": 518, "seek": 303216, "start": 3051.16, "end": 3055.16, "text": " And so subset is something that's going to pass.", "tokens": [400, 370, 25993, 307, 746, 300, 311, 516, 281, 1320, 13], "temperature": 0.0, "avg_logprob": -0.1271717627843221, "compression_ratio": 1.705607476635514, "no_speech_prob": 1.922210503835231e-05}, {"id": 519, "seek": 303216, "start": 3055.16, "end": 3058.16, "text": " This TFMDS into something called make subset.", "tokens": [639, 40964, 44, 11844, 666, 746, 1219, 652, 25993, 13], "temperature": 0.0, "avg_logprob": -0.1271717627843221, "compression_ratio": 1.705607476635514, "no_speech_prob": 1.922210503835231e-05}, {"id": 520, "seek": 303216, "start": 3058.16, "end": 3061.16, "text": " And so make subset.", "tokens": [400, 370, 652, 25993, 13], "temperature": 0.0, "avg_logprob": -0.1271717627843221, "compression_ratio": 1.705607476635514, "no_speech_prob": 1.922210503835231e-05}, {"id": 521, "seek": 306116, "start": 3061.16, "end": 3066.16, "text": " Is something that's going to grab all of our transforms.", "tokens": [1119, 746, 300, 311, 516, 281, 4444, 439, 295, 527, 35592, 13], "temperature": 0.0, "avg_logprob": -0.16722030404173296, "compression_ratio": 1.5731707317073171, "no_speech_prob": 2.840803972503636e-05}, {"id": 522, "seek": 306116, "start": 3066.16, "end": 3072.16, "text": " And it's going to create, as we discussed, a new TFMDS.", "tokens": [400, 309, 311, 516, 281, 1884, 11, 382, 321, 7152, 11, 257, 777, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.16722030404173296, "compression_ratio": 1.5731707317073171, "no_speech_prob": 2.840803972503636e-05}, {"id": 523, "seek": 306116, "start": 3072.16, "end": 3076.16, "text": " Containing just the subset.", "tokens": [4839, 3686, 445, 264, 25993, 13], "temperature": 0.0, "avg_logprob": -0.16722030404173296, "compression_ratio": 1.5731707317073171, "no_speech_prob": 2.840803972503636e-05}, {"id": 524, "seek": 306116, "start": 3076.16, "end": 3082.16, "text": " Of the items that are in filts I.", "tokens": [2720, 264, 4754, 300, 366, 294, 1387, 1373, 286, 13], "temperature": 0.0, "avg_logprob": -0.16722030404173296, "compression_ratio": 1.5731707317073171, "no_speech_prob": 2.840803972503636e-05}, {"id": 525, "seek": 306116, "start": 3082.16, "end": 3086.16, "text": " So that's the split index is zero or split index is one.", "tokens": [407, 300, 311, 264, 7472, 8186, 307, 4018, 420, 7472, 8186, 307, 472, 13], "temperature": 0.0, "avg_logprob": -0.16722030404173296, "compression_ratio": 1.5731707317073171, "no_speech_prob": 2.840803972503636e-05}, {"id": 526, "seek": 306116, "start": 3086.16, "end": 3089.16, "text": " And it's going to pass in.", "tokens": [400, 309, 311, 516, 281, 1320, 294, 13], "temperature": 0.0, "avg_logprob": -0.16722030404173296, "compression_ratio": 1.5731707317073171, "no_speech_prob": 2.840803972503636e-05}, {"id": 527, "seek": 308916, "start": 3089.16, "end": 3091.16, "text": " The transforms.", "tokens": [440, 35592, 13], "temperature": 0.0, "avg_logprob": -0.15810697624482303, "compression_ratio": 1.5191256830601092, "no_speech_prob": 3.5007428778044414e-06}, {"id": 528, "seek": 308916, "start": 3091.16, "end": 3094.16, "text": " And a key thing is going to also pass in is do setup equals false.", "tokens": [400, 257, 2141, 551, 307, 516, 281, 611, 1320, 294, 307, 360, 8657, 6915, 7908, 13], "temperature": 0.0, "avg_logprob": -0.15810697624482303, "compression_ratio": 1.5191256830601092, "no_speech_prob": 3.5007428778044414e-06}, {"id": 529, "seek": 308916, "start": 3094.16, "end": 3096.16, "text": " Because I don't need to recreate the vocab.", "tokens": [1436, 286, 500, 380, 643, 281, 25833, 264, 2329, 455, 13], "temperature": 0.0, "avg_logprob": -0.15810697624482303, "compression_ratio": 1.5191256830601092, "no_speech_prob": 3.5007428778044414e-06}, {"id": 530, "seek": 308916, "start": 3096.16, "end": 3099.16, "text": " We already have one. For instance.", "tokens": [492, 1217, 362, 472, 13, 1171, 5197, 13], "temperature": 0.0, "avg_logprob": -0.15810697624482303, "compression_ratio": 1.5191256830601092, "no_speech_prob": 3.5007428778044414e-06}, {"id": 531, "seek": 308916, "start": 3099.16, "end": 3106.16, "text": " So this is just a TFMDS for a subset of items.", "tokens": [407, 341, 307, 445, 257, 40964, 44, 11844, 337, 257, 25993, 295, 4754, 13], "temperature": 0.0, "avg_logprob": -0.15810697624482303, "compression_ratio": 1.5191256830601092, "no_speech_prob": 3.5007428778044414e-06}, {"id": 532, "seek": 308916, "start": 3106.16, "end": 3107.16, "text": " That's basically all the data.", "tokens": [663, 311, 1936, 439, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.15810697624482303, "compression_ratio": 1.5191256830601092, "no_speech_prob": 3.5007428778044414e-06}, {"id": 533, "seek": 308916, "start": 3107.16, "end": 3117.16, "text": " That's basically all the data sources.", "tokens": [663, 311, 1936, 439, 264, 1412, 7139, 13], "temperature": 0.0, "avg_logprob": -0.15810697624482303, "compression_ratio": 1.5191256830601092, "no_speech_prob": 3.5007428778044414e-06}, {"id": 534, "seek": 311716, "start": 3117.16, "end": 3119.16, "text": " So like in terms of the other code here.", "tokens": [407, 411, 294, 2115, 295, 264, 661, 3089, 510, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 535, "seek": 311716, "start": 3119.16, "end": 3123.16, "text": " It's just to do a bit of kind of bookkeeping and checking and stuff.", "tokens": [467, 311, 445, 281, 360, 257, 857, 295, 733, 295, 1446, 25769, 293, 8568, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 536, "seek": 311716, "start": 3123.16, "end": 3126.16, "text": " So for example.", "tokens": [407, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 537, "seek": 311716, "start": 3126.16, "end": 3130.16, "text": " These filters IDs that we pass in.", "tokens": [1981, 15995, 48212, 300, 321, 1320, 294, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 538, "seek": 311716, "start": 3130.16, "end": 3132.16, "text": " You can pass in as many as you like.", "tokens": [509, 393, 1320, 294, 382, 867, 382, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 539, "seek": 311716, "start": 3132.16, "end": 3133.16, "text": " Normally it will be two.", "tokens": [17424, 309, 486, 312, 732, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 540, "seek": 311716, "start": 3133.16, "end": 3135.16, "text": " A list of indexes for the training set.", "tokens": [316, 1329, 295, 8186, 279, 337, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 541, "seek": 311716, "start": 3135.16, "end": 3137.16, "text": " Not listed for the validation set.", "tokens": [1726, 10052, 337, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 542, "seek": 311716, "start": 3137.16, "end": 3139.16, "text": " You can do more.", "tokens": [509, 393, 360, 544, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 543, "seek": 311716, "start": 3139.16, "end": 3143.16, "text": " And so like I just check here to make sure that there's no indexes in the training set.", "tokens": [400, 370, 411, 286, 445, 1520, 510, 281, 652, 988, 300, 456, 311, 572, 8186, 279, 294, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 544, "seek": 311716, "start": 3143.16, "end": 3145.16, "text": " That are also in the validation set.", "tokens": [663, 366, 611, 294, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.12180253542386568, "compression_ratio": 1.7630522088353413, "no_speech_prob": 1.2410551789798774e-05}, {"id": 545, "seek": 314516, "start": 3145.16, "end": 3149.16, "text": " So we kind of try to make sure that good data science practices are followed.", "tokens": [407, 321, 733, 295, 853, 281, 652, 988, 300, 665, 1412, 3497, 7525, 366, 6263, 13], "temperature": 0.0, "avg_logprob": -0.1351268688837687, "compression_ratio": 1.1568627450980393, "no_speech_prob": 3.882255623466335e-05}, {"id": 546, "seek": 314516, "start": 3149.16, "end": 3159.16, "text": " It will let you know if they're not.", "tokens": [467, 486, 718, 291, 458, 498, 436, 434, 406, 13], "temperature": 0.0, "avg_logprob": -0.1351268688837687, "compression_ratio": 1.1568627450980393, "no_speech_prob": 3.882255623466335e-05}, {"id": 547, "seek": 314516, "start": 3159.16, "end": 3174.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1351268688837687, "compression_ratio": 1.1568627450980393, "no_speech_prob": 3.882255623466335e-05}, {"id": 548, "seek": 317416, "start": 3174.16, "end": 3179.16, "text": " So there's something else though interesting about our filters.", "tokens": [407, 456, 311, 746, 1646, 1673, 1880, 466, 527, 15995, 13], "temperature": 0.0, "avg_logprob": -0.1853873896044354, "compression_ratio": 1.2682926829268293, "no_speech_prob": 2.627025605761446e-05}, {"id": 549, "seek": 317416, "start": 3179.16, "end": 3184.16, "text": " And that is that when we create the subset.", "tokens": [400, 300, 307, 300, 562, 321, 1884, 264, 25993, 13], "temperature": 0.0, "avg_logprob": -0.1853873896044354, "compression_ratio": 1.2682926829268293, "no_speech_prob": 2.627025605761446e-05}, {"id": 550, "seek": 317416, "start": 3184.16, "end": 3188.16, "text": " We actually pass into TFMDS.", "tokens": [492, 767, 1320, 666, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.1853873896044354, "compression_ratio": 1.2682926829268293, "no_speech_prob": 2.627025605761446e-05}, {"id": 551, "seek": 317416, "start": 3188.16, "end": 3193.16, "text": " A filter parameter.", "tokens": [316, 6608, 13075, 13], "temperature": 0.0, "avg_logprob": -0.1853873896044354, "compression_ratio": 1.2682926829268293, "no_speech_prob": 2.627025605761446e-05}, {"id": 552, "seek": 319316, "start": 3193.16, "end": 3215.16, "text": " So what does that do?", "tokens": [407, 437, 775, 300, 360, 30], "temperature": 0.0, "avg_logprob": -0.38352084159851074, "compression_ratio": 0.875, "no_speech_prob": 3.6452569474931806e-05}, {"id": 553, "seek": 321516, "start": 3215.16, "end": 3228.16, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.20146618249281398, "compression_ratio": 1.272, "no_speech_prob": 4.003743015346117e-05}, {"id": 554, "seek": 321516, "start": 3228.16, "end": 3231.16, "text": " So as you can see TFMDS.", "tokens": [407, 382, 291, 393, 536, 40964, 44, 11844, 13], "temperature": 0.0, "avg_logprob": -0.20146618249281398, "compression_ratio": 1.272, "no_speech_prob": 4.003743015346117e-05}, {"id": 555, "seek": 321516, "start": 3231.16, "end": 3235.16, "text": " Takes a filter argument.", "tokens": [44347, 257, 6608, 6770, 13], "temperature": 0.0, "avg_logprob": -0.20146618249281398, "compression_ratio": 1.272, "no_speech_prob": 4.003743015346117e-05}, {"id": 556, "seek": 321516, "start": 3235.16, "end": 3241.16, "text": " And it doesn't really do anything with it other than it passes it onto the TFM lists it creates.", "tokens": [400, 309, 1177, 380, 534, 360, 1340, 365, 309, 661, 813, 309, 11335, 309, 3911, 264, 40964, 44, 14511, 309, 7829, 13], "temperature": 0.0, "avg_logprob": -0.20146618249281398, "compression_ratio": 1.272, "no_speech_prob": 4.003743015346117e-05}, {"id": 557, "seek": 321516, "start": 3241.16, "end": 3244.16, "text": " So fine.", "tokens": [407, 2489, 13], "temperature": 0.0, "avg_logprob": -0.20146618249281398, "compression_ratio": 1.272, "no_speech_prob": 4.003743015346117e-05}, {"id": 558, "seek": 324416, "start": 3244.16, "end": 3246.16, "text": " Let's look at that.", "tokens": [961, 311, 574, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 559, "seek": 324416, "start": 3246.16, "end": 3248.16, "text": " So TFM list.", "tokens": [407, 40964, 44, 1329, 13], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 560, "seek": 324416, "start": 3248.16, "end": 3249.16, "text": " Gets a filter argument.", "tokens": [460, 1385, 257, 6608, 6770, 13], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 561, "seek": 324416, "start": 3249.16, "end": 3252.16, "text": " And what does it do with it?", "tokens": [400, 437, 775, 309, 360, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 562, "seek": 324416, "start": 3252.16, "end": 3254.16, "text": " And the answer is nothing much.", "tokens": [400, 264, 1867, 307, 1825, 709, 13], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 563, "seek": 324416, "start": 3254.16, "end": 3258.16, "text": " Just passes it onto the pipeline that it creates.", "tokens": [1449, 11335, 309, 3911, 264, 15517, 300, 309, 7829, 13], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 564, "seek": 324416, "start": 3258.16, "end": 3263.16, "text": " OK. So what does the pipeline do with it?", "tokens": [2264, 13, 407, 437, 775, 264, 15517, 360, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 565, "seek": 324416, "start": 3263.16, "end": 3267.16, "text": " The pipeline grabs the filter.", "tokens": [440, 15517, 30028, 264, 6608, 13], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 566, "seek": 324416, "start": 3267.16, "end": 3270.16, "text": " And what does it do with it?", "tokens": [400, 437, 775, 309, 360, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 567, "seek": 324416, "start": 3270.16, "end": 3273.16, "text": " It stores it.", "tokens": [467, 9512, 309, 13], "temperature": 0.0, "avg_logprob": -0.12189817941316994, "compression_ratio": 1.7469135802469136, "no_speech_prob": 6.204431701917201e-05}, {"id": 568, "seek": 327316, "start": 3273.16, "end": 3278.16, "text": " Because when we call call or decode.", "tokens": [1436, 562, 321, 818, 818, 420, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.16435172592384228, "compression_ratio": 1.4230769230769231, "no_speech_prob": 4.222694315103581e-06}, {"id": 569, "seek": 327316, "start": 3278.16, "end": 3283.16, "text": " It passes it as a parameter to call or decode.", "tokens": [467, 11335, 309, 382, 257, 13075, 281, 818, 420, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.16435172592384228, "compression_ratio": 1.4230769230769231, "no_speech_prob": 4.222694315103581e-06}, {"id": 570, "seek": 327316, "start": 3283.16, "end": 3289.16, "text": " So what does compose to films do with it?", "tokens": [407, 437, 775, 35925, 281, 7796, 360, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.16435172592384228, "compression_ratio": 1.4230769230769231, "no_speech_prob": 4.222694315103581e-06}, {"id": 571, "seek": 327316, "start": 3289.16, "end": 3292.16, "text": " And the answer is.", "tokens": [400, 264, 1867, 307, 13], "temperature": 0.0, "avg_logprob": -0.16435172592384228, "compression_ratio": 1.4230769230769231, "no_speech_prob": 4.222694315103581e-06}, {"id": 572, "seek": 327316, "start": 3292.16, "end": 3294.16, "text": " Nothing really.", "tokens": [6693, 534, 13], "temperature": 0.0, "avg_logprob": -0.16435172592384228, "compression_ratio": 1.4230769230769231, "no_speech_prob": 4.222694315103581e-06}, {"id": 573, "seek": 327316, "start": 3294.16, "end": 3297.16, "text": " It's just a keyword argument.", "tokens": [467, 311, 445, 257, 20428, 6770, 13], "temperature": 0.0, "avg_logprob": -0.16435172592384228, "compression_ratio": 1.4230769230769231, "no_speech_prob": 4.222694315103581e-06}, {"id": 574, "seek": 327316, "start": 3297.16, "end": 3301.16, "text": " That it passes to our function.", "tokens": [663, 309, 11335, 281, 527, 2445, 13], "temperature": 0.0, "avg_logprob": -0.16435172592384228, "compression_ratio": 1.4230769230769231, "no_speech_prob": 4.222694315103581e-06}, {"id": 575, "seek": 330116, "start": 3301.16, "end": 3303.16, "text": " What does our function do with it?", "tokens": [708, 775, 527, 2445, 360, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.14322442424540616, "compression_ratio": 1.7932692307692308, "no_speech_prob": 4.029197498311987e-06}, {"id": 576, "seek": 330116, "start": 3303.16, "end": 3305.16, "text": " What does our transform do with it?", "tokens": [708, 775, 527, 4088, 360, 365, 309, 30], "temperature": 0.0, "avg_logprob": -0.14322442424540616, "compression_ratio": 1.7932692307692308, "no_speech_prob": 4.029197498311987e-06}, {"id": 577, "seek": 330116, "start": 3305.16, "end": 3307.16, "text": " And the answer is.", "tokens": [400, 264, 1867, 307, 13], "temperature": 0.0, "avg_logprob": -0.14322442424540616, "compression_ratio": 1.7932692307692308, "no_speech_prob": 4.029197498311987e-06}, {"id": 578, "seek": 330116, "start": 3307.16, "end": 3309.16, "text": " Whatever you like.", "tokens": [8541, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.14322442424540616, "compression_ratio": 1.7932692307692308, "no_speech_prob": 4.029197498311987e-06}, {"id": 579, "seek": 330116, "start": 3309.16, "end": 3315.16, "text": " So the key insight here is that our transforms actually have the ability to know.", "tokens": [407, 264, 2141, 11269, 510, 307, 300, 527, 35592, 767, 362, 264, 3485, 281, 458, 13], "temperature": 0.0, "avg_logprob": -0.14322442424540616, "compression_ratio": 1.7932692307692308, "no_speech_prob": 4.029197498311987e-06}, {"id": 580, "seek": 330116, "start": 3315.16, "end": 3321.16, "text": " Whether they're being called on the training set or the validation set.", "tokens": [8503, 436, 434, 885, 1219, 322, 264, 3097, 992, 420, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.14322442424540616, "compression_ratio": 1.7932692307692308, "no_speech_prob": 4.029197498311987e-06}, {"id": 581, "seek": 330116, "start": 3321.16, "end": 3325.16, "text": " And actually by default is something that it does with that.", "tokens": [400, 767, 538, 7576, 307, 746, 300, 309, 775, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.14322442424540616, "compression_ratio": 1.7932692307692308, "no_speech_prob": 4.029197498311987e-06}, {"id": 582, "seek": 330116, "start": 3325.16, "end": 3328.16, "text": " Which is when you create a function.", "tokens": [3013, 307, 562, 291, 1884, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.14322442424540616, "compression_ratio": 1.7932692307692308, "no_speech_prob": 4.029197498311987e-06}, {"id": 583, "seek": 330116, "start": 3328.16, "end": 3330.16, "text": " A transform.", "tokens": [316, 4088, 13], "temperature": 0.0, "avg_logprob": -0.14322442424540616, "compression_ratio": 1.7932692307692308, "no_speech_prob": 4.029197498311987e-06}, {"id": 584, "seek": 333016, "start": 3330.16, "end": 3332.16, "text": " You can actually pass in a filter.", "tokens": [509, 393, 767, 1320, 294, 257, 6608, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 585, "seek": 333016, "start": 3332.16, "end": 3335.16, "text": " And if you pass in a filter when you create the transform.", "tokens": [400, 498, 291, 1320, 294, 257, 6608, 562, 291, 1884, 264, 4088, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 586, "seek": 333016, "start": 3335.16, "end": 3340.16, "text": " That says this transform should only be applied.", "tokens": [663, 1619, 341, 4088, 820, 787, 312, 6456, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 587, "seek": 333016, "start": 3340.16, "end": 3343.16, "text": " On that particular subset.", "tokens": [1282, 300, 1729, 25993, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 588, "seek": 333016, "start": 3343.16, "end": 3345.16, "text": " So for example.", "tokens": [407, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 589, "seek": 333016, "start": 3345.16, "end": 3348.16, "text": " Data augmentation.", "tokens": [11888, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 590, "seek": 333016, "start": 3348.16, "end": 3352.16, "text": " The data augmentation.", "tokens": [440, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 591, "seek": 333016, "start": 3352.16, "end": 3355.16, "text": " Transforms I think by default always set filter to zero.", "tokens": [27938, 82, 286, 519, 538, 7576, 1009, 992, 6608, 281, 4018, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 592, "seek": 333016, "start": 3355.16, "end": 3357.16, "text": " Because a filter equals none.", "tokens": [1436, 257, 6608, 6915, 6022, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 593, "seek": 333016, "start": 3357.16, "end": 3359.16, "text": " It means you should apply it all the time.", "tokens": [467, 1355, 291, 820, 3079, 309, 439, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.10246752719489896, "compression_ratio": 1.6604651162790698, "no_speech_prob": 1.3845605280948803e-05}, {"id": 594, "seek": 335916, "start": 3359.16, "end": 3361.16, "text": " But a filter equals zero.", "tokens": [583, 257, 6608, 6915, 4018, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 595, "seek": 335916, "start": 3361.16, "end": 3365.16, "text": " It means you should only apply this to the training set.", "tokens": [467, 1355, 291, 820, 787, 3079, 341, 281, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 596, "seek": 335916, "start": 3365.16, "end": 3367.16, "text": " Which is what we want right.", "tokens": [3013, 307, 437, 321, 528, 558, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 597, "seek": 335916, "start": 3367.16, "end": 3371.16, "text": " We want our data augmentation only applied to the training set.", "tokens": [492, 528, 527, 1412, 14501, 19631, 787, 6456, 281, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 598, "seek": 335916, "start": 3371.16, "end": 3376.16, "text": " So when we call this transform.", "tokens": [407, 562, 321, 818, 341, 4088, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 599, "seek": 335916, "start": 3376.16, "end": 3379.16, "text": " It's going to be passed.", "tokens": [467, 311, 516, 281, 312, 4678, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 600, "seek": 335916, "start": 3379.16, "end": 3381.16, "text": " The filter.", "tokens": [440, 6608, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 601, "seek": 335916, "start": 3381.16, "end": 3384.16, "text": " Because remember the pipeline passed it along.", "tokens": [1436, 1604, 264, 15517, 4678, 309, 2051, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 602, "seek": 335916, "start": 3384.16, "end": 3386.16, "text": " And you can see here.", "tokens": [400, 291, 393, 536, 510, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 603, "seek": 335916, "start": 3386.16, "end": 3388.16, "text": " If our filter is not none.", "tokens": [759, 527, 6608, 307, 406, 6022, 13], "temperature": 0.0, "avg_logprob": -0.09522150000747369, "compression_ratio": 1.6037735849056605, "no_speech_prob": 1.3630989997182041e-05}, {"id": 604, "seek": 338816, "start": 3388.16, "end": 3392.16, "text": " And the filter for this function is not this transforms filter.", "tokens": [400, 264, 6608, 337, 341, 2445, 307, 406, 341, 35592, 6608, 13], "temperature": 0.0, "avg_logprob": -0.14197231972054258, "compression_ratio": 1.6582278481012658, "no_speech_prob": 8.800700925348792e-06}, {"id": 605, "seek": 338816, "start": 3392.16, "end": 3394.16, "text": " It does nothing at all.", "tokens": [467, 775, 1825, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.14197231972054258, "compression_ratio": 1.6582278481012658, "no_speech_prob": 8.800700925348792e-06}, {"id": 606, "seek": 338816, "start": 3394.16, "end": 3399.16, "text": " Ok so that's the default behavior for a transform.", "tokens": [3477, 370, 300, 311, 264, 7576, 5223, 337, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.14197231972054258, "compression_ratio": 1.6582278481012658, "no_speech_prob": 8.800700925348792e-06}, {"id": 607, "seek": 338816, "start": 3399.16, "end": 3402.16, "text": " Is that it will be disabled.", "tokens": [1119, 300, 309, 486, 312, 15191, 13], "temperature": 0.0, "avg_logprob": -0.14197231972054258, "compression_ratio": 1.6582278481012658, "no_speech_prob": 8.800700925348792e-06}, {"id": 608, "seek": 338816, "start": 3402.16, "end": 3407.16, "text": " If you set the transforms filter.", "tokens": [759, 291, 992, 264, 35592, 6608, 13], "temperature": 0.0, "avg_logprob": -0.14197231972054258, "compression_ratio": 1.6582278481012658, "no_speech_prob": 8.800700925348792e-06}, {"id": 609, "seek": 338816, "start": 3407.16, "end": 3411.16, "text": " And then you call it with some different filter.", "tokens": [400, 550, 291, 818, 309, 365, 512, 819, 6608, 13], "temperature": 0.0, "avg_logprob": -0.14197231972054258, "compression_ratio": 1.6582278481012658, "no_speech_prob": 8.800700925348792e-06}, {"id": 610, "seek": 338816, "start": 3411.16, "end": 3416.16, "text": " So this is.", "tokens": [407, 341, 307, 13], "temperature": 0.0, "avg_logprob": -0.14197231972054258, "compression_ratio": 1.6582278481012658, "no_speech_prob": 8.800700925348792e-06}, {"id": 611, "seek": 341616, "start": 3416.16, "end": 3423.16, "text": " Yeah this is like just another of these nice things to make sure that you don't accidentally do things that you wouldn't want to do.", "tokens": [865, 341, 307, 411, 445, 1071, 295, 613, 1481, 721, 281, 652, 988, 300, 291, 500, 380, 15715, 360, 721, 300, 291, 2759, 380, 528, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.1120498326359963, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.5350050893612206e-05}, {"id": 612, "seek": 341616, "start": 3423.16, "end": 3430.16, "text": " Where we make sure that it's only being called on the training set.", "tokens": [2305, 321, 652, 988, 300, 309, 311, 787, 885, 1219, 322, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.1120498326359963, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.5350050893612206e-05}, {"id": 613, "seek": 341616, "start": 3430.16, "end": 3432.16, "text": " That's appropriate.", "tokens": [663, 311, 6854, 13], "temperature": 0.0, "avg_logprob": -0.1120498326359963, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.5350050893612206e-05}, {"id": 614, "seek": 341616, "start": 3432.16, "end": 3434.16, "text": " So most of the time you don't have to worry about it right.", "tokens": [407, 881, 295, 264, 565, 291, 500, 380, 362, 281, 3292, 466, 309, 558, 13], "temperature": 0.0, "avg_logprob": -0.1120498326359963, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.5350050893612206e-05}, {"id": 615, "seek": 341616, "start": 3434.16, "end": 3436.16, "text": " Because most of the time.", "tokens": [1436, 881, 295, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.1120498326359963, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.5350050893612206e-05}, {"id": 616, "seek": 341616, "start": 3436.16, "end": 3439.16, "text": " When you create a transform.", "tokens": [1133, 291, 1884, 257, 4088, 13], "temperature": 0.0, "avg_logprob": -0.1120498326359963, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.5350050893612206e-05}, {"id": 617, "seek": 341616, "start": 3439.16, "end": 3441.16, "text": " You're not passing in a filter.", "tokens": [509, 434, 406, 8437, 294, 257, 6608, 13], "temperature": 0.0, "avg_logprob": -0.1120498326359963, "compression_ratio": 1.6757990867579908, "no_speech_prob": 3.5350050893612206e-05}, {"id": 618, "seek": 344116, "start": 3441.16, "end": 3447.16, "text": " Right. So most of the time this just does nothing at all.", "tokens": [1779, 13, 407, 881, 295, 264, 565, 341, 445, 775, 1825, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.14098672609071475, "compression_ratio": 1.5087719298245614, "no_speech_prob": 4.3566546992224175e-06}, {"id": 619, "seek": 344116, "start": 3447.16, "end": 3449.16, "text": " But if you do.", "tokens": [583, 498, 291, 360, 13], "temperature": 0.0, "avg_logprob": -0.14098672609071475, "compression_ratio": 1.5087719298245614, "no_speech_prob": 4.3566546992224175e-06}, {"id": 620, "seek": 344116, "start": 3449.16, "end": 3452.16, "text": " Or more generally if you have some transform that's not.", "tokens": [1610, 544, 5101, 498, 291, 362, 512, 4088, 300, 311, 406, 13], "temperature": 0.0, "avg_logprob": -0.14098672609071475, "compression_ratio": 1.5087719298245614, "no_speech_prob": 4.3566546992224175e-06}, {"id": 621, "seek": 344116, "start": 3452.16, "end": 3454.16, "text": " Seems to be not doing anything.", "tokens": [22524, 281, 312, 406, 884, 1340, 13], "temperature": 0.0, "avg_logprob": -0.14098672609071475, "compression_ratio": 1.5087719298245614, "no_speech_prob": 4.3566546992224175e-06}, {"id": 622, "seek": 344116, "start": 3454.16, "end": 3458.16, "text": " And you should check maybe you created it with a filter.", "tokens": [400, 291, 820, 1520, 1310, 291, 2942, 309, 365, 257, 6608, 13], "temperature": 0.0, "avg_logprob": -0.14098672609071475, "compression_ratio": 1.5087719298245614, "no_speech_prob": 4.3566546992224175e-06}, {"id": 623, "seek": 344116, "start": 3458.16, "end": 3464.16, "text": " So yes Max a filter is just an integer.", "tokens": [407, 2086, 7402, 257, 6608, 307, 445, 364, 24922, 13], "temperature": 0.0, "avg_logprob": -0.14098672609071475, "compression_ratio": 1.5087719298245614, "no_speech_prob": 4.3566546992224175e-06}, {"id": 624, "seek": 346416, "start": 3464.16, "end": 3472.16, "text": " I think yes it's just an integer.", "tokens": [286, 519, 2086, 309, 311, 445, 364, 24922, 13], "temperature": 0.0, "avg_logprob": -0.13530492782592773, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.029184765386162e-06}, {"id": 625, "seek": 346416, "start": 3472.16, "end": 3476.16, "text": " But you know you could inherit from transform.", "tokens": [583, 291, 458, 291, 727, 21389, 490, 4088, 13], "temperature": 0.0, "avg_logprob": -0.13530492782592773, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.029184765386162e-06}, {"id": 626, "seek": 346416, "start": 3476.16, "end": 3482.16, "text": " And and replace how underscore core works and actually have things that work differently.", "tokens": [400, 293, 7406, 577, 37556, 4965, 1985, 293, 767, 362, 721, 300, 589, 7614, 13], "temperature": 0.0, "avg_logprob": -0.13530492782592773, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.029184765386162e-06}, {"id": 627, "seek": 346416, "start": 3482.16, "end": 3484.16, "text": " For training versus validation.", "tokens": [1171, 3097, 5717, 24071, 13], "temperature": 0.0, "avg_logprob": -0.13530492782592773, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.029184765386162e-06}, {"id": 628, "seek": 346416, "start": 3484.16, "end": 3489.16, "text": " So you know that the key thing here is that the infrastructure is in place.", "tokens": [407, 291, 458, 300, 264, 2141, 551, 510, 307, 300, 264, 6896, 307, 294, 1081, 13], "temperature": 0.0, "avg_logprob": -0.13530492782592773, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.029184765386162e-06}, {"id": 629, "seek": 346416, "start": 3489.16, "end": 3492.16, "text": " That functions that transforms can behave differently.", "tokens": [663, 6828, 300, 35592, 393, 15158, 7614, 13], "temperature": 0.0, "avg_logprob": -0.13530492782592773, "compression_ratio": 1.6323529411764706, "no_speech_prob": 4.029184765386162e-06}, {"id": 630, "seek": 349216, "start": 3492.16, "end": 3502.16, "text": " They actually know where they're being called from.", "tokens": [814, 767, 458, 689, 436, 434, 885, 1219, 490, 13], "temperature": 0.0, "avg_logprob": -0.19407894084979962, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.092791186849354e-06}, {"id": 631, "seek": 349216, "start": 3502.16, "end": 3507.16, "text": " So you can see in the data source tests.", "tokens": [407, 291, 393, 536, 294, 264, 1412, 4009, 6921, 13], "temperature": 0.0, "avg_logprob": -0.19407894084979962, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.092791186849354e-06}, {"id": 632, "seek": 349216, "start": 3507.16, "end": 3509.16, "text": " Let's start by looking at them right.", "tokens": [961, 311, 722, 538, 1237, 412, 552, 558, 13], "temperature": 0.0, "avg_logprob": -0.19407894084979962, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.092791186849354e-06}, {"id": 633, "seek": 349216, "start": 3509.16, "end": 3512.16, "text": " So here's some items not through for.", "tokens": [407, 510, 311, 512, 4754, 406, 807, 337, 13], "temperature": 0.0, "avg_logprob": -0.19407894084979962, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.092791186849354e-06}, {"id": 634, "seek": 349216, "start": 3512.16, "end": 3513.16, "text": " So here's a data source.", "tokens": [407, 510, 311, 257, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.19407894084979962, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.092791186849354e-06}, {"id": 635, "seek": 349216, "start": 3513.16, "end": 3519.16, "text": " The north through four and the pipeline it's going to apply is do nothing at all.", "tokens": [440, 6830, 807, 1451, 293, 264, 15517, 309, 311, 516, 281, 3079, 307, 360, 1825, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.19407894084979962, "compression_ratio": 1.608187134502924, "no_speech_prob": 4.092791186849354e-06}, {"id": 636, "seek": 351916, "start": 3519.16, "end": 3522.16, "text": " So it's an empty pipeline.", "tokens": [407, 309, 311, 364, 6707, 15517, 13], "temperature": 0.0, "avg_logprob": -0.11962360494277056, "compression_ratio": 1.4701986754966887, "no_speech_prob": 5.594241883954965e-06}, {"id": 637, "seek": 351916, "start": 3522.16, "end": 3528.16, "text": " So the data source has a list of filters.", "tokens": [407, 264, 1412, 4009, 575, 257, 1329, 295, 15995, 13], "temperature": 0.0, "avg_logprob": -0.11962360494277056, "compression_ratio": 1.4701986754966887, "no_speech_prob": 5.594241883954965e-06}, {"id": 638, "seek": 351916, "start": 3528.16, "end": 3530.16, "text": " And we didn't pass in any filters.", "tokens": [400, 321, 994, 380, 1320, 294, 604, 15995, 13], "temperature": 0.0, "avg_logprob": -0.11962360494277056, "compression_ratio": 1.4701986754966887, "no_speech_prob": 5.594241883954965e-06}, {"id": 639, "seek": 351916, "start": 3530.16, "end": 3537.16, "text": " So it's just going to by default have one filter which is everything in the list.", "tokens": [407, 309, 311, 445, 516, 281, 538, 7576, 362, 472, 6608, 597, 307, 1203, 294, 264, 1329, 13], "temperature": 0.0, "avg_logprob": -0.11962360494277056, "compression_ratio": 1.4701986754966887, "no_speech_prob": 5.594241883954965e-06}, {"id": 640, "seek": 351916, "start": 3537.16, "end": 3541.16, "text": " So if we just grab.", "tokens": [407, 498, 321, 445, 4444, 13], "temperature": 0.0, "avg_logprob": -0.11962360494277056, "compression_ratio": 1.4701986754966887, "no_speech_prob": 5.594241883954965e-06}, {"id": 641, "seek": 351916, "start": 3541.16, "end": 3543.16, "text": " Item number two.", "tokens": [31066, 1230, 732, 13], "temperature": 0.0, "avg_logprob": -0.11962360494277056, "compression_ratio": 1.4701986754966887, "no_speech_prob": 5.594241883954965e-06}, {"id": 642, "seek": 354316, "start": 3543.16, "end": 3549.16, "text": " Then here is zero one two and it should return.", "tokens": [1396, 510, 307, 4018, 472, 732, 293, 309, 820, 2736, 13], "temperature": 0.0, "avg_logprob": -0.23472870720757377, "compression_ratio": 1.4304635761589404, "no_speech_prob": 7.411100796161918e-06}, {"id": 643, "seek": 354316, "start": 3549.16, "end": 3550.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.23472870720757377, "compression_ratio": 1.4304635761589404, "no_speech_prob": 7.411100796161918e-06}, {"id": 644, "seek": 354316, "start": 3550.16, "end": 3554.16, "text": " If we grab items one and two.", "tokens": [759, 321, 4444, 4754, 472, 293, 732, 13], "temperature": 0.0, "avg_logprob": -0.23472870720757377, "compression_ratio": 1.4304635761589404, "no_speech_prob": 7.411100796161918e-06}, {"id": 645, "seek": 354316, "start": 3554.16, "end": 3559.16, "text": " You're going to get back one and two and notice they're being turned into couples.", "tokens": [509, 434, 516, 281, 483, 646, 472, 293, 732, 293, 3449, 436, 434, 885, 3574, 666, 20368, 13], "temperature": 0.0, "avg_logprob": -0.23472870720757377, "compression_ratio": 1.4304635761589404, "no_speech_prob": 7.411100796161918e-06}, {"id": 646, "seek": 354316, "start": 3559.16, "end": 3563.16, "text": " And the reason for that is that remember this is a.", "tokens": [400, 264, 1778, 337, 300, 307, 300, 1604, 341, 307, 257, 13], "temperature": 0.0, "avg_logprob": -0.23472870720757377, "compression_ratio": 1.4304635761589404, "no_speech_prob": 7.411100796161918e-06}, {"id": 647, "seek": 356316, "start": 3563.16, "end": 3574.16, "text": " To from DS and to from DS is take a list of pipelines and create a couple with an element for each pipeline.", "tokens": [1407, 490, 15816, 293, 281, 490, 15816, 307, 747, 257, 1329, 295, 40168, 293, 1884, 257, 1916, 365, 364, 4478, 337, 1184, 15517, 13], "temperature": 0.0, "avg_logprob": -0.2391836438860212, "compression_ratio": 1.5098039215686274, "no_speech_prob": 2.1567386738752248e-06}, {"id": 648, "seek": 356316, "start": 3574.16, "end": 3576.16, "text": " So we have one pipeline.", "tokens": [407, 321, 362, 472, 15517, 13], "temperature": 0.0, "avg_logprob": -0.2391836438860212, "compression_ratio": 1.5098039215686274, "no_speech_prob": 2.1567386738752248e-06}, {"id": 649, "seek": 356316, "start": 3576.16, "end": 3579.16, "text": " So we get back.", "tokens": [407, 321, 483, 646, 13], "temperature": 0.0, "avg_logprob": -0.2391836438860212, "compression_ratio": 1.5098039215686274, "no_speech_prob": 2.1567386738752248e-06}, {"id": 650, "seek": 356316, "start": 3579.16, "end": 3584.16, "text": " Couples with one thing in.", "tokens": [26180, 2622, 365, 472, 551, 294, 13], "temperature": 0.0, "avg_logprob": -0.2391836438860212, "compression_ratio": 1.5098039215686274, "no_speech_prob": 2.1567386738752248e-06}, {"id": 651, "seek": 356316, "start": 3584.16, "end": 3587.16, "text": " This is what you want in by torch.", "tokens": [639, 307, 437, 291, 528, 294, 538, 27822, 13], "temperature": 0.0, "avg_logprob": -0.2391836438860212, "compression_ratio": 1.5098039215686274, "no_speech_prob": 2.1567386738752248e-06}, {"id": 652, "seek": 356316, "start": 3587.16, "end": 3588.16, "text": " Mini batches right.", "tokens": [18239, 15245, 279, 558, 13], "temperature": 0.0, "avg_logprob": -0.2391836438860212, "compression_ratio": 1.5098039215686274, "no_speech_prob": 2.1567386738752248e-06}, {"id": 653, "seek": 358816, "start": 3588.16, "end": 3593.16, "text": " A data set and a data loader should return.", "tokens": [316, 1412, 992, 293, 257, 1412, 3677, 260, 820, 2736, 13], "temperature": 0.0, "avg_logprob": -0.24021753771551724, "compression_ratio": 1.323076923076923, "no_speech_prob": 3.446460596023826e-06}, {"id": 654, "seek": 358816, "start": 3593.16, "end": 3601.16, "text": " Doubles.", "tokens": [13200, 8806, 13], "temperature": 0.0, "avg_logprob": -0.24021753771551724, "compression_ratio": 1.323076923076923, "no_speech_prob": 3.446460596023826e-06}, {"id": 655, "seek": 358816, "start": 3601.16, "end": 3607.16, "text": " So Petro's question is should we call retain type back here.", "tokens": [407, 10472, 340, 311, 1168, 307, 820, 321, 818, 18340, 2010, 646, 510, 13], "temperature": 0.0, "avg_logprob": -0.24021753771551724, "compression_ratio": 1.323076923076923, "no_speech_prob": 3.446460596023826e-06}, {"id": 656, "seek": 358816, "start": 3607.16, "end": 3609.16, "text": " And the answer is no.", "tokens": [400, 264, 1867, 307, 572, 13], "temperature": 0.0, "avg_logprob": -0.24021753771551724, "compression_ratio": 1.323076923076923, "no_speech_prob": 3.446460596023826e-06}, {"id": 657, "seek": 358816, "start": 3609.16, "end": 3611.16, "text": " Retained type.", "tokens": [11495, 3563, 2010, 13], "temperature": 0.0, "avg_logprob": -0.24021753771551724, "compression_ratio": 1.323076923076923, "no_speech_prob": 3.446460596023826e-06}, {"id": 658, "seek": 358816, "start": 3611.16, "end": 3614.16, "text": " Gets past two things.", "tokens": [460, 1385, 1791, 732, 721, 13], "temperature": 0.0, "avg_logprob": -0.24021753771551724, "compression_ratio": 1.323076923076923, "no_speech_prob": 3.446460596023826e-06}, {"id": 659, "seek": 361416, "start": 3614.16, "end": 3621.16, "text": " The new result of whatever functions we called and the original thing we were passed in.", "tokens": [440, 777, 1874, 295, 2035, 6828, 321, 1219, 293, 264, 3380, 551, 321, 645, 4678, 294, 13], "temperature": 0.0, "avg_logprob": -0.1873908200106778, "compression_ratio": 1.641711229946524, "no_speech_prob": 1.0289095371263102e-05}, {"id": 660, "seek": 361416, "start": 3621.16, "end": 3623.16, "text": " And it makes sure that this.", "tokens": [400, 309, 1669, 988, 300, 341, 13], "temperature": 0.0, "avg_logprob": -0.1873908200106778, "compression_ratio": 1.641711229946524, "no_speech_prob": 1.0289095371263102e-05}, {"id": 661, "seek": 361416, "start": 3623.16, "end": 3626.16, "text": " Res has the same type as this.", "tokens": [5015, 575, 264, 912, 2010, 382, 341, 13], "temperature": 0.0, "avg_logprob": -0.1873908200106778, "compression_ratio": 1.641711229946524, "no_speech_prob": 1.0289095371263102e-05}, {"id": 662, "seek": 361416, "start": 3626.16, "end": 3629.16, "text": " If res ends up as a subclass of this.", "tokens": [759, 725, 5314, 493, 382, 257, 1422, 11665, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.1873908200106778, "compression_ratio": 1.641711229946524, "no_speech_prob": 1.0289095371263102e-05}, {"id": 663, "seek": 361416, "start": 3629.16, "end": 3633.16, "text": " Res ends up a tensor and X is a tensor image.", "tokens": [5015, 5314, 493, 257, 40863, 293, 1783, 307, 257, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1873908200106778, "compression_ratio": 1.641711229946524, "no_speech_prob": 1.0289095371263102e-05}, {"id": 664, "seek": 361416, "start": 3633.16, "end": 3637.16, "text": " It will turn res into a tensor image.", "tokens": [467, 486, 1261, 725, 666, 257, 40863, 3256, 13], "temperature": 0.0, "avg_logprob": -0.1873908200106778, "compression_ratio": 1.641711229946524, "no_speech_prob": 1.0289095371263102e-05}, {"id": 665, "seek": 361416, "start": 3637.16, "end": 3638.16, "text": " In this case.", "tokens": [682, 341, 1389, 13], "temperature": 0.0, "avg_logprob": -0.1873908200106778, "compression_ratio": 1.641711229946524, "no_speech_prob": 1.0289095371263102e-05}, {"id": 666, "seek": 361416, "start": 3638.16, "end": 3640.16, "text": " Nothing happened to X.", "tokens": [6693, 2011, 281, 1783, 13], "temperature": 0.0, "avg_logprob": -0.1873908200106778, "compression_ratio": 1.641711229946524, "no_speech_prob": 1.0289095371263102e-05}, {"id": 667, "seek": 364016, "start": 3640.16, "end": 3652.16, "text": " It didn't change so we we have no retained type to do it's already the same type as X because it is X.", "tokens": [467, 994, 380, 1319, 370, 321, 321, 362, 572, 33438, 2010, 281, 360, 309, 311, 1217, 264, 912, 2010, 382, 1783, 570, 309, 307, 1783, 13], "temperature": 0.0, "avg_logprob": -0.1709417196420523, "compression_ratio": 1.4619565217391304, "no_speech_prob": 3.23767062582192e-06}, {"id": 668, "seek": 364016, "start": 3652.16, "end": 3656.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1709417196420523, "compression_ratio": 1.4619565217391304, "no_speech_prob": 3.23767062582192e-06}, {"id": 669, "seek": 364016, "start": 3656.16, "end": 3660.16, "text": " You can also index into to from lists and therefore data sources with masks.", "tokens": [509, 393, 611, 8186, 666, 281, 490, 14511, 293, 4412, 1412, 7139, 365, 11830, 13], "temperature": 0.0, "avg_logprob": -0.1709417196420523, "compression_ratio": 1.4619565217391304, "no_speech_prob": 3.23767062582192e-06}, {"id": 670, "seek": 364016, "start": 3660.16, "end": 3663.16, "text": " Bullion masks instead of indexes.", "tokens": [14131, 313, 11830, 2602, 295, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.1709417196420523, "compression_ratio": 1.4619565217391304, "no_speech_prob": 3.23767062582192e-06}, {"id": 671, "seek": 364016, "start": 3663.16, "end": 3665.16, "text": " So that's just that.", "tokens": [407, 300, 311, 445, 300, 13], "temperature": 0.0, "avg_logprob": -0.1709417196420523, "compression_ratio": 1.4619565217391304, "no_speech_prob": 3.23767062582192e-06}, {"id": 672, "seek": 364016, "start": 3665.16, "end": 3668.16, "text": " They also work on data frames.", "tokens": [814, 611, 589, 322, 1412, 12083, 13], "temperature": 0.0, "avg_logprob": -0.1709417196420523, "compression_ratio": 1.4619565217391304, "no_speech_prob": 3.23767062582192e-06}, {"id": 673, "seek": 366816, "start": 3668.16, "end": 3670.16, "text": " This is important that they work on data frames.", "tokens": [639, 307, 1021, 300, 436, 589, 322, 1412, 12083, 13], "temperature": 0.0, "avg_logprob": -0.1187082629337489, "compression_ratio": 1.6652173913043478, "no_speech_prob": 8.267261364380829e-06}, {"id": 674, "seek": 366816, "start": 3670.16, "end": 3675.16, "text": " It's not just they work on data frames that they work on data frames in a optimized way.", "tokens": [467, 311, 406, 445, 436, 589, 322, 1412, 12083, 300, 436, 589, 322, 1412, 12083, 294, 257, 26941, 636, 13], "temperature": 0.0, "avg_logprob": -0.1187082629337489, "compression_ratio": 1.6652173913043478, "no_speech_prob": 8.267261364380829e-06}, {"id": 675, "seek": 366816, "start": 3675.16, "end": 3683.16, "text": " So they'll actually use the ILOC method in data frame to do things efficiently.", "tokens": [407, 436, 603, 767, 764, 264, 286, 20184, 34, 3170, 294, 1412, 3920, 281, 360, 721, 19621, 13], "temperature": 0.0, "avg_logprob": -0.1187082629337489, "compression_ratio": 1.6652173913043478, "no_speech_prob": 8.267261364380829e-06}, {"id": 676, "seek": 366816, "start": 3683.16, "end": 3684.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1187082629337489, "compression_ratio": 1.6652173913043478, "no_speech_prob": 8.267261364380829e-06}, {"id": 677, "seek": 366816, "start": 3684.16, "end": 3687.16, "text": " How do we set up a pipeline where a transform of X depends on Y.", "tokens": [1012, 360, 321, 992, 493, 257, 15517, 689, 257, 4088, 295, 1783, 5946, 322, 398, 13], "temperature": 0.0, "avg_logprob": -0.1187082629337489, "compression_ratio": 1.6652173913043478, "no_speech_prob": 8.267261364380829e-06}, {"id": 678, "seek": 366816, "start": 3687.16, "end": 3689.16, "text": " Let's look at that next time.", "tokens": [961, 311, 574, 412, 300, 958, 565, 13], "temperature": 0.0, "avg_logprob": -0.1187082629337489, "compression_ratio": 1.6652173913043478, "no_speech_prob": 8.267261364380829e-06}, {"id": 679, "seek": 366816, "start": 3689.16, "end": 3691.16, "text": " More sometime in the next couple of days.", "tokens": [5048, 15053, 294, 264, 958, 1916, 295, 1708, 13], "temperature": 0.0, "avg_logprob": -0.1187082629337489, "compression_ratio": 1.6652173913043478, "no_speech_prob": 8.267261364380829e-06}, {"id": 680, "seek": 366816, "start": 3691.16, "end": 3693.16, "text": " That's a great question.", "tokens": [663, 311, 257, 869, 1168, 13], "temperature": 0.0, "avg_logprob": -0.1187082629337489, "compression_ratio": 1.6652173913043478, "no_speech_prob": 8.267261364380829e-06}, {"id": 681, "seek": 369316, "start": 3693.16, "end": 3698.16, "text": " And do remind me in the next couple of days if I forget.", "tokens": [400, 360, 4160, 385, 294, 264, 958, 1916, 295, 1708, 498, 286, 2870, 13], "temperature": 0.0, "avg_logprob": -0.10381175625708795, "compression_ratio": 1.69377990430622, "no_speech_prob": 1.952475940925069e-05}, {"id": 682, "seek": 369316, "start": 3698.16, "end": 3699.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.10381175625708795, "compression_ratio": 1.69377990430622, "no_speech_prob": 1.952475940925069e-05}, {"id": 683, "seek": 369316, "start": 3699.16, "end": 3706.16, "text": " So then you can see here's the same thing basically passing in our range with no transforms.", "tokens": [407, 550, 291, 393, 536, 510, 311, 264, 912, 551, 1936, 8437, 294, 527, 3613, 365, 572, 35592, 13], "temperature": 0.0, "avg_logprob": -0.10381175625708795, "compression_ratio": 1.69377990430622, "no_speech_prob": 1.952475940925069e-05}, {"id": 684, "seek": 369316, "start": 3706.16, "end": 3708.16, "text": " But this time it's passing some filters.", "tokens": [583, 341, 565, 309, 311, 8437, 512, 15995, 13], "temperature": 0.0, "avg_logprob": -0.10381175625708795, "compression_ratio": 1.69377990430622, "no_speech_prob": 1.952475940925069e-05}, {"id": 685, "seek": 369316, "start": 3708.16, "end": 3714.16, "text": " So now there are two sets of filters and there's subset zero which is the same as the training set.", "tokens": [407, 586, 456, 366, 732, 6352, 295, 15995, 293, 456, 311, 25993, 4018, 597, 307, 264, 912, 382, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.10381175625708795, "compression_ratio": 1.69377990430622, "no_speech_prob": 1.952475940925069e-05}, {"id": 686, "seek": 369316, "start": 3714.16, "end": 3721.16, "text": " There's subset one which is the same as the validation set.", "tokens": [821, 311, 25993, 472, 597, 307, 264, 912, 382, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.10381175625708795, "compression_ratio": 1.69377990430622, "no_speech_prob": 1.952475940925069e-05}, {"id": 687, "seek": 372116, "start": 3721.16, "end": 3725.16, "text": " So that's that.", "tokens": [407, 300, 311, 300, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 688, "seek": 372116, "start": 3725.16, "end": 3726.16, "text": " Oh, batteries.", "tokens": [876, 11, 13070, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 689, "seek": 372116, "start": 3726.16, "end": 3728.16, "text": " That's fine.", "tokens": [663, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 690, "seek": 372116, "start": 3728.16, "end": 3730.16, "text": " And the filters could also be masks.", "tokens": [400, 264, 15995, 727, 611, 312, 11830, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 691, "seek": 372116, "start": 3730.16, "end": 3736.16, "text": " They don't have to be ints.", "tokens": [814, 500, 380, 362, 281, 312, 560, 82, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 692, "seek": 372116, "start": 3736.16, "end": 3737.16, "text": " Great.", "tokens": [3769, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 693, "seek": 372116, "start": 3737.16, "end": 3738.16, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 694, "seek": 372116, "start": 3738.16, "end": 3740.16, "text": " Well, I think that's enough for today.", "tokens": [1042, 11, 286, 519, 300, 311, 1547, 337, 965, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 695, "seek": 372116, "start": 3740.16, "end": 3745.16, "text": " So, yeah, let me know any questions you've got.", "tokens": [407, 11, 1338, 11, 718, 385, 458, 604, 1651, 291, 600, 658, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 696, "seek": 372116, "start": 3745.16, "end": 3749.16, "text": " But hopefully these things are starting to come together.", "tokens": [583, 4696, 613, 721, 366, 2891, 281, 808, 1214, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 697, "seek": 372116, "start": 3749.16, "end": 3750.16, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.1498484915875374, "compression_ratio": 1.4175257731958764, "no_speech_prob": 1.2027400771330576e-05}, {"id": 698, "seek": 375016, "start": 3750.16, "end": 3751.16, "text": " Thanks, everybody.", "tokens": [2561, 11, 2201, 13], "temperature": 0.0, "avg_logprob": -0.16823041439056396, "compression_ratio": 0.7714285714285715, "no_speech_prob": 0.00013722074800170958}, {"id": 699, "seek": 375116, "start": 3751.16, "end": 3780.16, "text": " See you next time.", "tokens": [50364, 3008, 291, 958, 565, 13, 51814], "temperature": 0.0, "avg_logprob": -0.40945470333099365, "compression_ratio": 0.6923076923076923, "no_speech_prob": 0.0013654958456754684}], "language": "en"}