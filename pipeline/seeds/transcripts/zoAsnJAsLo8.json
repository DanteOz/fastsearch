{"text": " But just a few questions that you can ask about projects you're working on, and I hope you will ask about projects you're working on. The first is, should we even be doing this? And considering that maybe there's some work that we shouldn't do. There's a paper when the implication is not to design technology. As engineers, we often tend to respond to problems with, you know, what can I make or build to address this, but sometimes the answer is to not make or build anything. One example of research that I think has a huge amount of downside and really no upside I see was kind of to identify the ethnicity, particularly for people of ethnic minorities. And so there was work done identifying the Chinese Uyghurs, which is the Muslim minority in Western China, which has since, you know, over a million people have been placed in internment camps. So I think this is a very, very harmful, harmful line of research. I think that the, you know, there have been at least two attempts of building a classifier to try to identify someone's sexuality, which is probably just picking up on kind of stylistic differences, but this is something that could also be quite dangerous, as in many countries it's illegal to be gay. Yes. So this is a question for me, which I don't know the answer to. As that title says, a Stanford scientist says he built the gay art using the lamest AI possible to prove a point. And my understanding is that point was to say, you know, I guess it's something like, hey, you could use fast AI lesson one after an hour or two, you can build this thing, anybody can do it. You know, how do you feel about this idea that there's a role to demonstrate what's readily available with the technology we have? Yeah, I mean, that's the thing that I think, so I appreciate that, and I'll talk about this a little bit later, OpenAI with GPT-2, I think was trying to raise a debate around dual use and what is responsible release of dual use technology and what's a kind of responsible way to raise awareness of what is possible. In the cases of researchers that have done this on the sexuality question, to me it hasn't seemed like they've put adequate thought into how they're conducting that and who they're collaborating with to ensure that it is something that is leading to kind of helping address the problem. But I think you're right that I think there is probably some place for letting people know what is probably widely available now. Yeah, it reminds me a bit of like pen testing in InfoSec, where it's kind of considered it, well, there's an ethical way that you can go about pointing out that it's trivially easy to break into somebody's system. Yes, yeah, I would agree with that, that there is an ethical way, but I think that's something that we as a community still have more work to do in even determining what that is. Other questions to consider are what bias is in the data? And something I should highlight is people often ask me, you know, how can I debias my data or ensure that it's bias-free? And that's not possible. All data contains bias. And the kind of most important thing is just to understand kind of how your data set was created and what its limitations are so that you're not blindsided by that bias, but you're never going to fully remove it. And some of the, I think, most promising approaches in this area are work like Timnit Gebru's Data Sheets for Data Sets, which is kind of going through and asking kind of a bunch of questions about how your data set was created and for what purposes and how it's being maintained and, you know, what are the risks in that, just to really kind of be aware of the context of your data. Can the code and data be audited? I think particularly in the United States, we have a lot of issues with when private companies are creating software that's really impacting people through the criminal justice system or hiring. And when these things are, you know, kind of their proprietary black boxes that are protected in court, this creates a lot of kind of issues of, you know, what are our rights around that. Looking at error rates for different subgroups is really important, and that's what's kind of so powerful about Joy Balanwini's work. If she had just looked at light skin versus dark skin and men versus women, she wouldn't have identified just how poorly the algorithms were doing on dark-skinned women. What is the accuracy of a simple rule-based alternative? And this is something I think Jeremy talked about last week, which is kind of good machine learning practice to have a baseline, but particularly in cases like the compass recidivism where this 130-variable black box is not doing much better than a linear classifier on three variables, that raises kind of a question of why are we using this? And then what processes are in place to handle appeals or mistakes? Because there will be errors in the data, there may be bugs in the implementation, and we need to have a process for recourse. Yes? Can you explain this for me now? Sorry, I must get my own questions. Nobody voted them up at all. What's the thinking behind this idea that a simpler model, is it kind of saying a simpler model or other things being the same, you should pick the simpler one? Is that what this baseline is for? And if so, what's the kind of thinking behind that? Well, I guess with the compass recidivism algorithm, some of this for me is linked to the proprietary black box nature. And so you're right if maybe if we had a way to introspect and what were our rights around appealing something. But I would say, yeah, like why use the more complex thing if the simpler one works the same? And then how diverse is the team that built it? And I'll talk more about team diversity later in this lesson. It says Jeremy at the start, but I'm not the teacher. So it actually says, Jeremy, do you think transfer learning makes this tougher, auditing the data that led to the initial model? I assume they mean Jeremy, please ask Rachel. No, they were asking you. That's a good question. Again, I think it's important. I would say I think it's important to have information probably on both data sets, what the initial data set used was and what the data set you used to fine tune it. Do you have thoughts on that? What she said. And then I'll say so while bias and fairness as well as accountability and transparency are important, they aren't everything. And so there's this great paper, a mulching proposal by Oz Keyes et al. And here they talk about a system for turning the elderly into high nutrient slurry. So this is something that's clearly unethical, but they propose a way to do it that is fair and accountable and transparent and meets these qualifications. And so that kind of shows some of the limitations of this framework, as well as kind of being a good technique for kind of inspecting whatever framework you are using of trying to find something that's clearly unethical that could meet the standards you've put forth. That technique, I really like it. It's my favorite technique from philosophy. It's this idea that you say, OK, given this premise, here's what it implies. And then you try and find an implied result, which intuitively is clearly insane. And it's a really, it's the number one philosophical thinking tool I got out of university. And sometimes you can have a lot of fun with it like this time too. Oh, thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.38, "text": " But just a few questions that you can ask about projects you're working on, and I hope", "tokens": [583, 445, 257, 1326, 1651, 300, 291, 393, 1029, 466, 4455, 291, 434, 1364, 322, 11, 293, 286, 1454], "temperature": 0.0, "avg_logprob": -0.15680987291997023, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.007932737469673157}, {"id": 1, "seek": 0, "start": 5.38, "end": 9.34, "text": " you will ask about projects you're working on.", "tokens": [291, 486, 1029, 466, 4455, 291, 434, 1364, 322, 13], "temperature": 0.0, "avg_logprob": -0.15680987291997023, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.007932737469673157}, {"id": 2, "seek": 0, "start": 9.34, "end": 13.34, "text": " The first is, should we even be doing this?", "tokens": [440, 700, 307, 11, 820, 321, 754, 312, 884, 341, 30], "temperature": 0.0, "avg_logprob": -0.15680987291997023, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.007932737469673157}, {"id": 3, "seek": 0, "start": 13.34, "end": 17.900000000000002, "text": " And considering that maybe there's some work that we shouldn't do.", "tokens": [400, 8079, 300, 1310, 456, 311, 512, 589, 300, 321, 4659, 380, 360, 13], "temperature": 0.0, "avg_logprob": -0.15680987291997023, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.007932737469673157}, {"id": 4, "seek": 0, "start": 17.900000000000002, "end": 22.580000000000002, "text": " There's a paper when the implication is not to design technology.", "tokens": [821, 311, 257, 3035, 562, 264, 37814, 307, 406, 281, 1715, 2899, 13], "temperature": 0.0, "avg_logprob": -0.15680987291997023, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.007932737469673157}, {"id": 5, "seek": 0, "start": 22.580000000000002, "end": 26.34, "text": " As engineers, we often tend to respond to problems with, you know, what can I make or", "tokens": [1018, 11955, 11, 321, 2049, 3928, 281, 4196, 281, 2740, 365, 11, 291, 458, 11, 437, 393, 286, 652, 420], "temperature": 0.0, "avg_logprob": -0.15680987291997023, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.007932737469673157}, {"id": 6, "seek": 2634, "start": 26.34, "end": 34.019999999999996, "text": " build to address this, but sometimes the answer is to not make or build anything.", "tokens": [1322, 281, 2985, 341, 11, 457, 2171, 264, 1867, 307, 281, 406, 652, 420, 1322, 1340, 13], "temperature": 0.0, "avg_logprob": -0.083661683715216, "compression_ratio": 1.626865671641791, "no_speech_prob": 7.138746150303632e-05}, {"id": 7, "seek": 2634, "start": 34.019999999999996, "end": 38.94, "text": " One example of research that I think has a huge amount of downside and really no upside", "tokens": [1485, 1365, 295, 2132, 300, 286, 519, 575, 257, 2603, 2372, 295, 25060, 293, 534, 572, 14119], "temperature": 0.0, "avg_logprob": -0.083661683715216, "compression_ratio": 1.626865671641791, "no_speech_prob": 7.138746150303632e-05}, {"id": 8, "seek": 2634, "start": 38.94, "end": 45.879999999999995, "text": " I see was kind of to identify the ethnicity, particularly for people of ethnic minorities.", "tokens": [286, 536, 390, 733, 295, 281, 5876, 264, 33774, 11, 4098, 337, 561, 295, 14363, 30373, 13], "temperature": 0.0, "avg_logprob": -0.083661683715216, "compression_ratio": 1.626865671641791, "no_speech_prob": 7.138746150303632e-05}, {"id": 9, "seek": 2634, "start": 45.879999999999995, "end": 50.94, "text": " And so there was work done identifying the Chinese Uyghurs, which is the Muslim minority", "tokens": [400, 370, 456, 390, 589, 1096, 16696, 264, 4649, 624, 88, 9030, 2156, 11, 597, 307, 264, 8178, 16166], "temperature": 0.0, "avg_logprob": -0.083661683715216, "compression_ratio": 1.626865671641791, "no_speech_prob": 7.138746150303632e-05}, {"id": 10, "seek": 2634, "start": 50.94, "end": 55.04, "text": " in Western China, which has since, you know, over a million people have been placed in", "tokens": [294, 8724, 3533, 11, 597, 575, 1670, 11, 291, 458, 11, 670, 257, 2459, 561, 362, 668, 7074, 294], "temperature": 0.0, "avg_logprob": -0.083661683715216, "compression_ratio": 1.626865671641791, "no_speech_prob": 7.138746150303632e-05}, {"id": 11, "seek": 5504, "start": 55.04, "end": 56.82, "text": " internment camps.", "tokens": [2154, 518, 16573, 13], "temperature": 0.0, "avg_logprob": -0.1941527140509222, "compression_ratio": 1.5819672131147542, "no_speech_prob": 4.906109825242311e-05}, {"id": 12, "seek": 5504, "start": 56.82, "end": 62.58, "text": " So I think this is a very, very harmful, harmful line of research.", "tokens": [407, 286, 519, 341, 307, 257, 588, 11, 588, 19727, 11, 19727, 1622, 295, 2132, 13], "temperature": 0.0, "avg_logprob": -0.1941527140509222, "compression_ratio": 1.5819672131147542, "no_speech_prob": 4.906109825242311e-05}, {"id": 13, "seek": 5504, "start": 62.58, "end": 69.18, "text": " I think that the, you know, there have been at least two attempts of building a classifier", "tokens": [286, 519, 300, 264, 11, 291, 458, 11, 456, 362, 668, 412, 1935, 732, 15257, 295, 2390, 257, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.1941527140509222, "compression_ratio": 1.5819672131147542, "no_speech_prob": 4.906109825242311e-05}, {"id": 14, "seek": 5504, "start": 69.18, "end": 77.3, "text": " to try to identify someone's sexuality, which is probably just picking up on kind of stylistic", "tokens": [281, 853, 281, 5876, 1580, 311, 25426, 11, 597, 307, 1391, 445, 8867, 493, 322, 733, 295, 23736, 3142], "temperature": 0.0, "avg_logprob": -0.1941527140509222, "compression_ratio": 1.5819672131147542, "no_speech_prob": 4.906109825242311e-05}, {"id": 15, "seek": 5504, "start": 77.3, "end": 82.34, "text": " differences, but this is something that could also be quite dangerous, as in many countries", "tokens": [7300, 11, 457, 341, 307, 746, 300, 727, 611, 312, 1596, 5795, 11, 382, 294, 867, 3517], "temperature": 0.0, "avg_logprob": -0.1941527140509222, "compression_ratio": 1.5819672131147542, "no_speech_prob": 4.906109825242311e-05}, {"id": 16, "seek": 5504, "start": 82.34, "end": 84.94, "text": " it's illegal to be gay.", "tokens": [309, 311, 11905, 281, 312, 9049, 13], "temperature": 0.0, "avg_logprob": -0.1941527140509222, "compression_ratio": 1.5819672131147542, "no_speech_prob": 4.906109825242311e-05}, {"id": 17, "seek": 8494, "start": 84.94, "end": 85.94, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.13603754763333303, "compression_ratio": 1.6008583690987124, "no_speech_prob": 6.484784535132349e-05}, {"id": 18, "seek": 8494, "start": 85.94, "end": 91.58, "text": " So this is a question for me, which I don't know the answer to.", "tokens": [407, 341, 307, 257, 1168, 337, 385, 11, 597, 286, 500, 380, 458, 264, 1867, 281, 13], "temperature": 0.0, "avg_logprob": -0.13603754763333303, "compression_ratio": 1.6008583690987124, "no_speech_prob": 6.484784535132349e-05}, {"id": 19, "seek": 8494, "start": 91.58, "end": 97.53999999999999, "text": " As that title says, a Stanford scientist says he built the gay art using the lamest AI possible", "tokens": [1018, 300, 4876, 1619, 11, 257, 20374, 12662, 1619, 415, 3094, 264, 9049, 1523, 1228, 264, 24688, 377, 7318, 1944], "temperature": 0.0, "avg_logprob": -0.13603754763333303, "compression_ratio": 1.6008583690987124, "no_speech_prob": 6.484784535132349e-05}, {"id": 20, "seek": 8494, "start": 97.53999999999999, "end": 98.53999999999999, "text": " to prove a point.", "tokens": [281, 7081, 257, 935, 13], "temperature": 0.0, "avg_logprob": -0.13603754763333303, "compression_ratio": 1.6008583690987124, "no_speech_prob": 6.484784535132349e-05}, {"id": 21, "seek": 8494, "start": 98.53999999999999, "end": 102.82, "text": " And my understanding is that point was to say, you know, I guess it's something like,", "tokens": [400, 452, 3701, 307, 300, 935, 390, 281, 584, 11, 291, 458, 11, 286, 2041, 309, 311, 746, 411, 11], "temperature": 0.0, "avg_logprob": -0.13603754763333303, "compression_ratio": 1.6008583690987124, "no_speech_prob": 6.484784535132349e-05}, {"id": 22, "seek": 8494, "start": 102.82, "end": 108.53999999999999, "text": " hey, you could use fast AI lesson one after an hour or two, you can build this thing,", "tokens": [4177, 11, 291, 727, 764, 2370, 7318, 6898, 472, 934, 364, 1773, 420, 732, 11, 291, 393, 1322, 341, 551, 11], "temperature": 0.0, "avg_logprob": -0.13603754763333303, "compression_ratio": 1.6008583690987124, "no_speech_prob": 6.484784535132349e-05}, {"id": 23, "seek": 8494, "start": 108.53999999999999, "end": 110.62, "text": " anybody can do it.", "tokens": [4472, 393, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.13603754763333303, "compression_ratio": 1.6008583690987124, "no_speech_prob": 6.484784535132349e-05}, {"id": 24, "seek": 11062, "start": 110.62, "end": 115.94, "text": " You know, how do you feel about this idea that there's a role to demonstrate what's", "tokens": [509, 458, 11, 577, 360, 291, 841, 466, 341, 1558, 300, 456, 311, 257, 3090, 281, 11698, 437, 311], "temperature": 0.0, "avg_logprob": -0.15512466430664062, "compression_ratio": 1.6680497925311204, "no_speech_prob": 4.397330485517159e-05}, {"id": 25, "seek": 11062, "start": 115.94, "end": 118.02000000000001, "text": " readily available with the technology we have?", "tokens": [26336, 2435, 365, 264, 2899, 321, 362, 30], "temperature": 0.0, "avg_logprob": -0.15512466430664062, "compression_ratio": 1.6680497925311204, "no_speech_prob": 4.397330485517159e-05}, {"id": 26, "seek": 11062, "start": 118.02000000000001, "end": 125.9, "text": " Yeah, I mean, that's the thing that I think, so I appreciate that, and I'll talk about", "tokens": [865, 11, 286, 914, 11, 300, 311, 264, 551, 300, 286, 519, 11, 370, 286, 4449, 300, 11, 293, 286, 603, 751, 466], "temperature": 0.0, "avg_logprob": -0.15512466430664062, "compression_ratio": 1.6680497925311204, "no_speech_prob": 4.397330485517159e-05}, {"id": 27, "seek": 11062, "start": 125.9, "end": 133.38, "text": " this a little bit later, OpenAI with GPT-2, I think was trying to raise a debate around", "tokens": [341, 257, 707, 857, 1780, 11, 7238, 48698, 365, 26039, 51, 12, 17, 11, 286, 519, 390, 1382, 281, 5300, 257, 7958, 926], "temperature": 0.0, "avg_logprob": -0.15512466430664062, "compression_ratio": 1.6680497925311204, "no_speech_prob": 4.397330485517159e-05}, {"id": 28, "seek": 11062, "start": 133.38, "end": 140.22, "text": " dual use and what is responsible release of dual use technology and what's a kind of responsible", "tokens": [11848, 764, 293, 437, 307, 6250, 4374, 295, 11848, 764, 2899, 293, 437, 311, 257, 733, 295, 6250], "temperature": 0.0, "avg_logprob": -0.15512466430664062, "compression_ratio": 1.6680497925311204, "no_speech_prob": 4.397330485517159e-05}, {"id": 29, "seek": 14022, "start": 140.22, "end": 146.66, "text": " way to raise awareness of what is possible.", "tokens": [636, 281, 5300, 8888, 295, 437, 307, 1944, 13], "temperature": 0.0, "avg_logprob": -0.10344702946512323, "compression_ratio": 1.6176470588235294, "no_speech_prob": 2.2466239897767082e-05}, {"id": 30, "seek": 14022, "start": 146.66, "end": 152.86, "text": " In the cases of researchers that have done this on the sexuality question, to me it hasn't", "tokens": [682, 264, 3331, 295, 10309, 300, 362, 1096, 341, 322, 264, 25426, 1168, 11, 281, 385, 309, 6132, 380], "temperature": 0.0, "avg_logprob": -0.10344702946512323, "compression_ratio": 1.6176470588235294, "no_speech_prob": 2.2466239897767082e-05}, {"id": 31, "seek": 14022, "start": 152.86, "end": 157.34, "text": " seemed like they've put adequate thought into how they're conducting that and who they're", "tokens": [6576, 411, 436, 600, 829, 20927, 1194, 666, 577, 436, 434, 21749, 300, 293, 567, 436, 434], "temperature": 0.0, "avg_logprob": -0.10344702946512323, "compression_ratio": 1.6176470588235294, "no_speech_prob": 2.2466239897767082e-05}, {"id": 32, "seek": 14022, "start": 157.34, "end": 165.06, "text": " collaborating with to ensure that it is something that is leading to kind of helping address", "tokens": [30188, 365, 281, 5586, 300, 309, 307, 746, 300, 307, 5775, 281, 733, 295, 4315, 2985], "temperature": 0.0, "avg_logprob": -0.10344702946512323, "compression_ratio": 1.6176470588235294, "no_speech_prob": 2.2466239897767082e-05}, {"id": 33, "seek": 14022, "start": 165.06, "end": 168.26, "text": " the problem.", "tokens": [264, 1154, 13], "temperature": 0.0, "avg_logprob": -0.10344702946512323, "compression_ratio": 1.6176470588235294, "no_speech_prob": 2.2466239897767082e-05}, {"id": 34, "seek": 16826, "start": 168.26, "end": 172.39999999999998, "text": " But I think you're right that I think there is probably some place for letting people", "tokens": [583, 286, 519, 291, 434, 558, 300, 286, 519, 456, 307, 1391, 512, 1081, 337, 8295, 561], "temperature": 0.0, "avg_logprob": -0.20324251944558663, "compression_ratio": 1.7244094488188977, "no_speech_prob": 3.479525548755191e-05}, {"id": 35, "seek": 16826, "start": 172.39999999999998, "end": 174.78, "text": " know what is probably widely available now.", "tokens": [458, 437, 307, 1391, 13371, 2435, 586, 13], "temperature": 0.0, "avg_logprob": -0.20324251944558663, "compression_ratio": 1.7244094488188977, "no_speech_prob": 3.479525548755191e-05}, {"id": 36, "seek": 16826, "start": 174.78, "end": 181.34, "text": " Yeah, it reminds me a bit of like pen testing in InfoSec, where it's kind of considered", "tokens": [865, 11, 309, 12025, 385, 257, 857, 295, 411, 3435, 4997, 294, 11537, 78, 29511, 11, 689, 309, 311, 733, 295, 4888], "temperature": 0.0, "avg_logprob": -0.20324251944558663, "compression_ratio": 1.7244094488188977, "no_speech_prob": 3.479525548755191e-05}, {"id": 37, "seek": 16826, "start": 181.34, "end": 185.34, "text": " it, well, there's an ethical way that you can go about pointing out that it's trivially", "tokens": [309, 11, 731, 11, 456, 311, 364, 18890, 636, 300, 291, 393, 352, 466, 12166, 484, 300, 309, 311, 1376, 85, 2270], "temperature": 0.0, "avg_logprob": -0.20324251944558663, "compression_ratio": 1.7244094488188977, "no_speech_prob": 3.479525548755191e-05}, {"id": 38, "seek": 16826, "start": 185.34, "end": 187.85999999999999, "text": " easy to break into somebody's system.", "tokens": [1858, 281, 1821, 666, 2618, 311, 1185, 13], "temperature": 0.0, "avg_logprob": -0.20324251944558663, "compression_ratio": 1.7244094488188977, "no_speech_prob": 3.479525548755191e-05}, {"id": 39, "seek": 16826, "start": 187.85999999999999, "end": 192.5, "text": " Yes, yeah, I would agree with that, that there is an ethical way, but I think that's something", "tokens": [1079, 11, 1338, 11, 286, 576, 3986, 365, 300, 11, 300, 456, 307, 364, 18890, 636, 11, 457, 286, 519, 300, 311, 746], "temperature": 0.0, "avg_logprob": -0.20324251944558663, "compression_ratio": 1.7244094488188977, "no_speech_prob": 3.479525548755191e-05}, {"id": 40, "seek": 19250, "start": 192.5, "end": 200.86, "text": " that we as a community still have more work to do in even determining what that is.", "tokens": [300, 321, 382, 257, 1768, 920, 362, 544, 589, 281, 360, 294, 754, 23751, 437, 300, 307, 13], "temperature": 0.0, "avg_logprob": -0.1415402548653739, "compression_ratio": 1.608, "no_speech_prob": 9.972401130653452e-06}, {"id": 41, "seek": 19250, "start": 200.86, "end": 204.22, "text": " Other questions to consider are what bias is in the data?", "tokens": [5358, 1651, 281, 1949, 366, 437, 12577, 307, 294, 264, 1412, 30], "temperature": 0.0, "avg_logprob": -0.1415402548653739, "compression_ratio": 1.608, "no_speech_prob": 9.972401130653452e-06}, {"id": 42, "seek": 19250, "start": 204.22, "end": 209.12, "text": " And something I should highlight is people often ask me, you know, how can I debias my", "tokens": [400, 746, 286, 820, 5078, 307, 561, 2049, 1029, 385, 11, 291, 458, 11, 577, 393, 286, 3001, 4609, 452], "temperature": 0.0, "avg_logprob": -0.1415402548653739, "compression_ratio": 1.608, "no_speech_prob": 9.972401130653452e-06}, {"id": 43, "seek": 19250, "start": 209.12, "end": 211.98, "text": " data or ensure that it's bias-free?", "tokens": [1412, 420, 5586, 300, 309, 311, 12577, 12, 10792, 30], "temperature": 0.0, "avg_logprob": -0.1415402548653739, "compression_ratio": 1.608, "no_speech_prob": 9.972401130653452e-06}, {"id": 44, "seek": 19250, "start": 211.98, "end": 213.06, "text": " And that's not possible.", "tokens": [400, 300, 311, 406, 1944, 13], "temperature": 0.0, "avg_logprob": -0.1415402548653739, "compression_ratio": 1.608, "no_speech_prob": 9.972401130653452e-06}, {"id": 45, "seek": 19250, "start": 213.06, "end": 214.82, "text": " All data contains bias.", "tokens": [1057, 1412, 8306, 12577, 13], "temperature": 0.0, "avg_logprob": -0.1415402548653739, "compression_ratio": 1.608, "no_speech_prob": 9.972401130653452e-06}, {"id": 46, "seek": 19250, "start": 214.82, "end": 220.82, "text": " And the kind of most important thing is just to understand kind of how your data set was", "tokens": [400, 264, 733, 295, 881, 1021, 551, 307, 445, 281, 1223, 733, 295, 577, 428, 1412, 992, 390], "temperature": 0.0, "avg_logprob": -0.1415402548653739, "compression_ratio": 1.608, "no_speech_prob": 9.972401130653452e-06}, {"id": 47, "seek": 22082, "start": 220.82, "end": 224.78, "text": " created and what its limitations are so that you're not blindsided by that bias, but you're", "tokens": [2942, 293, 437, 1080, 15705, 366, 370, 300, 291, 434, 406, 6865, 30941, 538, 300, 12577, 11, 457, 291, 434], "temperature": 0.0, "avg_logprob": -0.12338973183668296, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.5934090697555803e-05}, {"id": 48, "seek": 22082, "start": 224.78, "end": 227.0, "text": " never going to fully remove it.", "tokens": [1128, 516, 281, 4498, 4159, 309, 13], "temperature": 0.0, "avg_logprob": -0.12338973183668296, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.5934090697555803e-05}, {"id": 49, "seek": 22082, "start": 227.0, "end": 234.06, "text": " And some of the, I think, most promising approaches in this area are work like Timnit Gebru's", "tokens": [400, 512, 295, 264, 11, 286, 519, 11, 881, 20257, 11587, 294, 341, 1859, 366, 589, 411, 7172, 77, 270, 2876, 7294, 311], "temperature": 0.0, "avg_logprob": -0.12338973183668296, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.5934090697555803e-05}, {"id": 50, "seek": 22082, "start": 234.06, "end": 238.26, "text": " Data Sheets for Data Sets, which is kind of going through and asking kind of a bunch of", "tokens": [11888, 1240, 1385, 337, 11888, 318, 1385, 11, 597, 307, 733, 295, 516, 807, 293, 3365, 733, 295, 257, 3840, 295], "temperature": 0.0, "avg_logprob": -0.12338973183668296, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.5934090697555803e-05}, {"id": 51, "seek": 22082, "start": 238.26, "end": 242.78, "text": " questions about how your data set was created and for what purposes and how it's being maintained", "tokens": [1651, 466, 577, 428, 1412, 992, 390, 2942, 293, 337, 437, 9932, 293, 577, 309, 311, 885, 17578], "temperature": 0.0, "avg_logprob": -0.12338973183668296, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.5934090697555803e-05}, {"id": 52, "seek": 22082, "start": 242.78, "end": 248.42, "text": " and, you know, what are the risks in that, just to really kind of be aware of the context", "tokens": [293, 11, 291, 458, 11, 437, 366, 264, 10888, 294, 300, 11, 445, 281, 534, 733, 295, 312, 3650, 295, 264, 4319], "temperature": 0.0, "avg_logprob": -0.12338973183668296, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.5934090697555803e-05}, {"id": 53, "seek": 22082, "start": 248.42, "end": 249.42, "text": " of your data.", "tokens": [295, 428, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12338973183668296, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.5934090697555803e-05}, {"id": 54, "seek": 24942, "start": 249.42, "end": 253.1, "text": " Can the code and data be audited?", "tokens": [1664, 264, 3089, 293, 1412, 312, 2379, 1226, 30], "temperature": 0.0, "avg_logprob": -0.1303975772857666, "compression_ratio": 1.6377952755905512, "no_speech_prob": 1.5204748706310056e-05}, {"id": 55, "seek": 24942, "start": 253.1, "end": 257.32, "text": " I think particularly in the United States, we have a lot of issues with when private", "tokens": [286, 519, 4098, 294, 264, 2824, 3040, 11, 321, 362, 257, 688, 295, 2663, 365, 562, 4551], "temperature": 0.0, "avg_logprob": -0.1303975772857666, "compression_ratio": 1.6377952755905512, "no_speech_prob": 1.5204748706310056e-05}, {"id": 56, "seek": 24942, "start": 257.32, "end": 263.08, "text": " companies are creating software that's really impacting people through the criminal justice", "tokens": [3431, 366, 4084, 4722, 300, 311, 534, 29963, 561, 807, 264, 8628, 6118], "temperature": 0.0, "avg_logprob": -0.1303975772857666, "compression_ratio": 1.6377952755905512, "no_speech_prob": 1.5204748706310056e-05}, {"id": 57, "seek": 24942, "start": 263.08, "end": 265.06, "text": " system or hiring.", "tokens": [1185, 420, 15335, 13], "temperature": 0.0, "avg_logprob": -0.1303975772857666, "compression_ratio": 1.6377952755905512, "no_speech_prob": 1.5204748706310056e-05}, {"id": 58, "seek": 24942, "start": 265.06, "end": 268.26, "text": " And when these things are, you know, kind of their proprietary black boxes that are", "tokens": [400, 562, 613, 721, 366, 11, 291, 458, 11, 733, 295, 641, 38992, 2211, 9002, 300, 366], "temperature": 0.0, "avg_logprob": -0.1303975772857666, "compression_ratio": 1.6377952755905512, "no_speech_prob": 1.5204748706310056e-05}, {"id": 59, "seek": 24942, "start": 268.26, "end": 273.41999999999996, "text": " protected in court, this creates a lot of kind of issues of, you know, what are our", "tokens": [10594, 294, 4753, 11, 341, 7829, 257, 688, 295, 733, 295, 2663, 295, 11, 291, 458, 11, 437, 366, 527], "temperature": 0.0, "avg_logprob": -0.1303975772857666, "compression_ratio": 1.6377952755905512, "no_speech_prob": 1.5204748706310056e-05}, {"id": 60, "seek": 24942, "start": 273.41999999999996, "end": 276.94, "text": " rights around that.", "tokens": [4601, 926, 300, 13], "temperature": 0.0, "avg_logprob": -0.1303975772857666, "compression_ratio": 1.6377952755905512, "no_speech_prob": 1.5204748706310056e-05}, {"id": 61, "seek": 27694, "start": 276.94, "end": 280.82, "text": " Looking at error rates for different subgroups is really important, and that's what's kind", "tokens": [11053, 412, 6713, 6846, 337, 819, 1422, 17377, 82, 307, 534, 1021, 11, 293, 300, 311, 437, 311, 733], "temperature": 0.0, "avg_logprob": -0.13892019445245915, "compression_ratio": 1.6164874551971327, "no_speech_prob": 1.2606077689270023e-05}, {"id": 62, "seek": 27694, "start": 280.82, "end": 283.42, "text": " of so powerful about Joy Balanwini's work.", "tokens": [295, 370, 4005, 466, 15571, 13140, 282, 86, 3812, 311, 589, 13], "temperature": 0.0, "avg_logprob": -0.13892019445245915, "compression_ratio": 1.6164874551971327, "no_speech_prob": 1.2606077689270023e-05}, {"id": 63, "seek": 27694, "start": 283.42, "end": 289.18, "text": " If she had just looked at light skin versus dark skin and men versus women, she wouldn't", "tokens": [759, 750, 632, 445, 2956, 412, 1442, 3178, 5717, 2877, 3178, 293, 1706, 5717, 2266, 11, 750, 2759, 380], "temperature": 0.0, "avg_logprob": -0.13892019445245915, "compression_ratio": 1.6164874551971327, "no_speech_prob": 1.2606077689270023e-05}, {"id": 64, "seek": 27694, "start": 289.18, "end": 296.15999999999997, "text": " have identified just how poorly the algorithms were doing on dark-skinned women.", "tokens": [362, 9234, 445, 577, 22271, 264, 14642, 645, 884, 322, 2877, 12, 5161, 45508, 2266, 13], "temperature": 0.0, "avg_logprob": -0.13892019445245915, "compression_ratio": 1.6164874551971327, "no_speech_prob": 1.2606077689270023e-05}, {"id": 65, "seek": 27694, "start": 296.15999999999997, "end": 298.42, "text": " What is the accuracy of a simple rule-based alternative?", "tokens": [708, 307, 264, 14170, 295, 257, 2199, 4978, 12, 6032, 8535, 30], "temperature": 0.0, "avg_logprob": -0.13892019445245915, "compression_ratio": 1.6164874551971327, "no_speech_prob": 1.2606077689270023e-05}, {"id": 66, "seek": 27694, "start": 298.42, "end": 303.3, "text": " And this is something I think Jeremy talked about last week, which is kind of good machine", "tokens": [400, 341, 307, 746, 286, 519, 17809, 2825, 466, 1036, 1243, 11, 597, 307, 733, 295, 665, 3479], "temperature": 0.0, "avg_logprob": -0.13892019445245915, "compression_ratio": 1.6164874551971327, "no_speech_prob": 1.2606077689270023e-05}, {"id": 67, "seek": 30330, "start": 303.3, "end": 309.06, "text": " learning practice to have a baseline, but particularly in cases like the compass recidivism", "tokens": [2539, 3124, 281, 362, 257, 20518, 11, 457, 4098, 294, 3331, 411, 264, 10707, 850, 327, 592, 1434], "temperature": 0.0, "avg_logprob": -0.13808294578834815, "compression_ratio": 1.6555555555555554, "no_speech_prob": 6.240783932298655e-06}, {"id": 68, "seek": 30330, "start": 309.06, "end": 316.3, "text": " where this 130-variable black box is not doing much better than a linear classifier on three", "tokens": [689, 341, 19966, 12, 34033, 712, 2211, 2424, 307, 406, 884, 709, 1101, 813, 257, 8213, 1508, 9902, 322, 1045], "temperature": 0.0, "avg_logprob": -0.13808294578834815, "compression_ratio": 1.6555555555555554, "no_speech_prob": 6.240783932298655e-06}, {"id": 69, "seek": 30330, "start": 316.3, "end": 321.54, "text": " variables, that raises kind of a question of why are we using this?", "tokens": [9102, 11, 300, 19658, 733, 295, 257, 1168, 295, 983, 366, 321, 1228, 341, 30], "temperature": 0.0, "avg_logprob": -0.13808294578834815, "compression_ratio": 1.6555555555555554, "no_speech_prob": 6.240783932298655e-06}, {"id": 70, "seek": 30330, "start": 321.54, "end": 325.1, "text": " And then what processes are in place to handle appeals or mistakes?", "tokens": [400, 550, 437, 7555, 366, 294, 1081, 281, 4813, 32603, 420, 8038, 30], "temperature": 0.0, "avg_logprob": -0.13808294578834815, "compression_ratio": 1.6555555555555554, "no_speech_prob": 6.240783932298655e-06}, {"id": 71, "seek": 30330, "start": 325.1, "end": 329.5, "text": " Because there will be errors in the data, there may be bugs in the implementation, and", "tokens": [1436, 456, 486, 312, 13603, 294, 264, 1412, 11, 456, 815, 312, 15120, 294, 264, 11420, 11, 293], "temperature": 0.0, "avg_logprob": -0.13808294578834815, "compression_ratio": 1.6555555555555554, "no_speech_prob": 6.240783932298655e-06}, {"id": 72, "seek": 30330, "start": 329.5, "end": 332.02, "text": " we need to have a process for recourse.", "tokens": [321, 643, 281, 362, 257, 1399, 337, 850, 13656, 13], "temperature": 0.0, "avg_logprob": -0.13808294578834815, "compression_ratio": 1.6555555555555554, "no_speech_prob": 6.240783932298655e-06}, {"id": 73, "seek": 33202, "start": 332.02, "end": 334.85999999999996, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.32002749587550305, "compression_ratio": 1.627906976744186, "no_speech_prob": 7.962983363540843e-05}, {"id": 74, "seek": 33202, "start": 334.85999999999996, "end": 335.85999999999996, "text": " Can you explain this for me now?", "tokens": [1664, 291, 2903, 341, 337, 385, 586, 30], "temperature": 0.0, "avg_logprob": -0.32002749587550305, "compression_ratio": 1.627906976744186, "no_speech_prob": 7.962983363540843e-05}, {"id": 75, "seek": 33202, "start": 335.85999999999996, "end": 336.85999999999996, "text": " Sorry, I must get my own questions.", "tokens": [4919, 11, 286, 1633, 483, 452, 1065, 1651, 13], "temperature": 0.0, "avg_logprob": -0.32002749587550305, "compression_ratio": 1.627906976744186, "no_speech_prob": 7.962983363540843e-05}, {"id": 76, "seek": 33202, "start": 336.85999999999996, "end": 342.26, "text": " Nobody voted them up at all.", "tokens": [9297, 13415, 552, 493, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.32002749587550305, "compression_ratio": 1.627906976744186, "no_speech_prob": 7.962983363540843e-05}, {"id": 77, "seek": 33202, "start": 342.26, "end": 347.14, "text": " What's the thinking behind this idea that a simpler model, is it kind of saying a simpler", "tokens": [708, 311, 264, 1953, 2261, 341, 1558, 300, 257, 18587, 2316, 11, 307, 309, 733, 295, 1566, 257, 18587], "temperature": 0.0, "avg_logprob": -0.32002749587550305, "compression_ratio": 1.627906976744186, "no_speech_prob": 7.962983363540843e-05}, {"id": 78, "seek": 33202, "start": 347.14, "end": 350.59999999999997, "text": " model or other things being the same, you should pick the simpler one?", "tokens": [2316, 420, 661, 721, 885, 264, 912, 11, 291, 820, 1888, 264, 18587, 472, 30], "temperature": 0.0, "avg_logprob": -0.32002749587550305, "compression_ratio": 1.627906976744186, "no_speech_prob": 7.962983363540843e-05}, {"id": 79, "seek": 33202, "start": 350.59999999999997, "end": 352.21999999999997, "text": " Is that what this baseline is for?", "tokens": [1119, 300, 437, 341, 20518, 307, 337, 30], "temperature": 0.0, "avg_logprob": -0.32002749587550305, "compression_ratio": 1.627906976744186, "no_speech_prob": 7.962983363540843e-05}, {"id": 80, "seek": 33202, "start": 352.21999999999997, "end": 355.09999999999997, "text": " And if so, what's the kind of thinking behind that?", "tokens": [400, 498, 370, 11, 437, 311, 264, 733, 295, 1953, 2261, 300, 30], "temperature": 0.0, "avg_logprob": -0.32002749587550305, "compression_ratio": 1.627906976744186, "no_speech_prob": 7.962983363540843e-05}, {"id": 81, "seek": 35510, "start": 355.1, "end": 363.5, "text": " Well, I guess with the compass recidivism algorithm, some of this for me is linked to", "tokens": [1042, 11, 286, 2041, 365, 264, 10707, 850, 327, 592, 1434, 9284, 11, 512, 295, 341, 337, 385, 307, 9408, 281], "temperature": 0.0, "avg_logprob": -0.19099197387695313, "compression_ratio": 1.5541666666666667, "no_speech_prob": 1.9221257389290258e-05}, {"id": 82, "seek": 35510, "start": 363.5, "end": 365.98, "text": " the proprietary black box nature.", "tokens": [264, 38992, 2211, 2424, 3687, 13], "temperature": 0.0, "avg_logprob": -0.19099197387695313, "compression_ratio": 1.5541666666666667, "no_speech_prob": 1.9221257389290258e-05}, {"id": 83, "seek": 35510, "start": 365.98, "end": 369.54, "text": " And so you're right if maybe if we had a way to introspect and what were our rights around", "tokens": [400, 370, 291, 434, 558, 498, 1310, 498, 321, 632, 257, 636, 281, 560, 28713, 293, 437, 645, 527, 4601, 926], "temperature": 0.0, "avg_logprob": -0.19099197387695313, "compression_ratio": 1.5541666666666667, "no_speech_prob": 1.9221257389290258e-05}, {"id": 84, "seek": 35510, "start": 369.54, "end": 370.54, "text": " appealing something.", "tokens": [23842, 746, 13], "temperature": 0.0, "avg_logprob": -0.19099197387695313, "compression_ratio": 1.5541666666666667, "no_speech_prob": 1.9221257389290258e-05}, {"id": 85, "seek": 35510, "start": 370.54, "end": 375.62, "text": " But I would say, yeah, like why use the more complex thing if the simpler one works the", "tokens": [583, 286, 576, 584, 11, 1338, 11, 411, 983, 764, 264, 544, 3997, 551, 498, 264, 18587, 472, 1985, 264], "temperature": 0.0, "avg_logprob": -0.19099197387695313, "compression_ratio": 1.5541666666666667, "no_speech_prob": 1.9221257389290258e-05}, {"id": 86, "seek": 35510, "start": 375.62, "end": 379.1, "text": " same?", "tokens": [912, 30], "temperature": 0.0, "avg_logprob": -0.19099197387695313, "compression_ratio": 1.5541666666666667, "no_speech_prob": 1.9221257389290258e-05}, {"id": 87, "seek": 35510, "start": 379.1, "end": 380.78000000000003, "text": " And then how diverse is the team that built it?", "tokens": [400, 550, 577, 9521, 307, 264, 1469, 300, 3094, 309, 30], "temperature": 0.0, "avg_logprob": -0.19099197387695313, "compression_ratio": 1.5541666666666667, "no_speech_prob": 1.9221257389290258e-05}, {"id": 88, "seek": 38078, "start": 380.78, "end": 385.78, "text": " And I'll talk more about team diversity later in this lesson.", "tokens": [400, 286, 603, 751, 544, 466, 1469, 8811, 1780, 294, 341, 6898, 13], "temperature": 0.0, "avg_logprob": -0.28860194708711356, "compression_ratio": 1.5246636771300448, "no_speech_prob": 1.130002328864066e-05}, {"id": 89, "seek": 38078, "start": 385.78, "end": 389.97999999999996, "text": " It says Jeremy at the start, but I'm not the teacher.", "tokens": [467, 1619, 17809, 412, 264, 722, 11, 457, 286, 478, 406, 264, 5027, 13], "temperature": 0.0, "avg_logprob": -0.28860194708711356, "compression_ratio": 1.5246636771300448, "no_speech_prob": 1.130002328864066e-05}, {"id": 90, "seek": 38078, "start": 389.97999999999996, "end": 395.26, "text": " So it actually says, Jeremy, do you think transfer learning makes this tougher, auditing", "tokens": [407, 309, 767, 1619, 11, 17809, 11, 360, 291, 519, 5003, 2539, 1669, 341, 30298, 11, 2379, 1748], "temperature": 0.0, "avg_logprob": -0.28860194708711356, "compression_ratio": 1.5246636771300448, "no_speech_prob": 1.130002328864066e-05}, {"id": 91, "seek": 38078, "start": 395.26, "end": 397.61999999999995, "text": " the data that led to the initial model?", "tokens": [264, 1412, 300, 4684, 281, 264, 5883, 2316, 30], "temperature": 0.0, "avg_logprob": -0.28860194708711356, "compression_ratio": 1.5246636771300448, "no_speech_prob": 1.130002328864066e-05}, {"id": 92, "seek": 38078, "start": 397.61999999999995, "end": 400.41999999999996, "text": " I assume they mean Jeremy, please ask Rachel.", "tokens": [286, 6552, 436, 914, 17809, 11, 1767, 1029, 14246, 13], "temperature": 0.0, "avg_logprob": -0.28860194708711356, "compression_ratio": 1.5246636771300448, "no_speech_prob": 1.130002328864066e-05}, {"id": 93, "seek": 38078, "start": 400.41999999999996, "end": 403.21999999999997, "text": " No, they were asking you.", "tokens": [883, 11, 436, 645, 3365, 291, 13], "temperature": 0.0, "avg_logprob": -0.28860194708711356, "compression_ratio": 1.5246636771300448, "no_speech_prob": 1.130002328864066e-05}, {"id": 94, "seek": 38078, "start": 403.21999999999997, "end": 407.61999999999995, "text": " That's a good question.", "tokens": [663, 311, 257, 665, 1168, 13], "temperature": 0.0, "avg_logprob": -0.28860194708711356, "compression_ratio": 1.5246636771300448, "no_speech_prob": 1.130002328864066e-05}, {"id": 95, "seek": 40762, "start": 407.62, "end": 411.98, "text": " Again, I think it's important.", "tokens": [3764, 11, 286, 519, 309, 311, 1021, 13], "temperature": 0.0, "avg_logprob": -0.21908037286055715, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.585947913757991e-05}, {"id": 96, "seek": 40762, "start": 411.98, "end": 415.66, "text": " I would say I think it's important to have information probably on both data sets, what", "tokens": [286, 576, 584, 286, 519, 309, 311, 1021, 281, 362, 1589, 1391, 322, 1293, 1412, 6352, 11, 437], "temperature": 0.0, "avg_logprob": -0.21908037286055715, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.585947913757991e-05}, {"id": 97, "seek": 40762, "start": 415.66, "end": 421.94, "text": " the initial data set used was and what the data set you used to fine tune it.", "tokens": [264, 5883, 1412, 992, 1143, 390, 293, 437, 264, 1412, 992, 291, 1143, 281, 2489, 10864, 309, 13], "temperature": 0.0, "avg_logprob": -0.21908037286055715, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.585947913757991e-05}, {"id": 98, "seek": 40762, "start": 421.94, "end": 425.06, "text": " Do you have thoughts on that?", "tokens": [1144, 291, 362, 4598, 322, 300, 30], "temperature": 0.0, "avg_logprob": -0.21908037286055715, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.585947913757991e-05}, {"id": 99, "seek": 40762, "start": 425.06, "end": 428.06, "text": " What she said.", "tokens": [708, 750, 848, 13], "temperature": 0.0, "avg_logprob": -0.21908037286055715, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.585947913757991e-05}, {"id": 100, "seek": 40762, "start": 428.06, "end": 434.78000000000003, "text": " And then I'll say so while bias and fairness as well as accountability and transparency", "tokens": [400, 550, 286, 603, 584, 370, 1339, 12577, 293, 29765, 382, 731, 382, 19380, 293, 17131], "temperature": 0.0, "avg_logprob": -0.21908037286055715, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.585947913757991e-05}, {"id": 101, "seek": 40762, "start": 434.78000000000003, "end": 437.5, "text": " are important, they aren't everything.", "tokens": [366, 1021, 11, 436, 3212, 380, 1203, 13], "temperature": 0.0, "avg_logprob": -0.21908037286055715, "compression_ratio": 1.6803652968036529, "no_speech_prob": 2.585947913757991e-05}, {"id": 102, "seek": 43750, "start": 437.5, "end": 443.22, "text": " And so there's this great paper, a mulching proposal by Oz Keyes et al.", "tokens": [400, 370, 456, 311, 341, 869, 3035, 11, 257, 14077, 17354, 11494, 538, 29843, 12759, 279, 1030, 419, 13], "temperature": 0.0, "avg_logprob": -0.11321601482352825, "compression_ratio": 1.624, "no_speech_prob": 1.6961837900453247e-05}, {"id": 103, "seek": 43750, "start": 443.22, "end": 449.26, "text": " And here they talk about a system for turning the elderly into high nutrient slurry.", "tokens": [400, 510, 436, 751, 466, 257, 1185, 337, 6246, 264, 19682, 666, 1090, 32694, 1061, 30614, 13], "temperature": 0.0, "avg_logprob": -0.11321601482352825, "compression_ratio": 1.624, "no_speech_prob": 1.6961837900453247e-05}, {"id": 104, "seek": 43750, "start": 449.26, "end": 454.22, "text": " So this is something that's clearly unethical, but they propose a way to do it that is fair", "tokens": [407, 341, 307, 746, 300, 311, 4448, 517, 3293, 804, 11, 457, 436, 17421, 257, 636, 281, 360, 309, 300, 307, 3143], "temperature": 0.0, "avg_logprob": -0.11321601482352825, "compression_ratio": 1.624, "no_speech_prob": 1.6961837900453247e-05}, {"id": 105, "seek": 43750, "start": 454.22, "end": 458.38, "text": " and accountable and transparent and meets these qualifications.", "tokens": [293, 18024, 293, 12737, 293, 13961, 613, 33223, 13], "temperature": 0.0, "avg_logprob": -0.11321601482352825, "compression_ratio": 1.624, "no_speech_prob": 1.6961837900453247e-05}, {"id": 106, "seek": 43750, "start": 458.38, "end": 462.98, "text": " And so that kind of shows some of the limitations of this framework, as well as kind of being", "tokens": [400, 370, 300, 733, 295, 3110, 512, 295, 264, 15705, 295, 341, 8388, 11, 382, 731, 382, 733, 295, 885], "temperature": 0.0, "avg_logprob": -0.11321601482352825, "compression_ratio": 1.624, "no_speech_prob": 1.6961837900453247e-05}, {"id": 107, "seek": 46298, "start": 462.98, "end": 471.46000000000004, "text": " a good technique for kind of inspecting whatever framework you are using of trying to find", "tokens": [257, 665, 6532, 337, 733, 295, 15018, 278, 2035, 8388, 291, 366, 1228, 295, 1382, 281, 915], "temperature": 0.0, "avg_logprob": -0.13491204889809214, "compression_ratio": 1.5471698113207548, "no_speech_prob": 2.840530578396283e-05}, {"id": 108, "seek": 46298, "start": 471.46000000000004, "end": 478.26, "text": " something that's clearly unethical that could meet the standards you've put forth.", "tokens": [746, 300, 311, 4448, 517, 3293, 804, 300, 727, 1677, 264, 7787, 291, 600, 829, 5220, 13], "temperature": 0.0, "avg_logprob": -0.13491204889809214, "compression_ratio": 1.5471698113207548, "no_speech_prob": 2.840530578396283e-05}, {"id": 109, "seek": 46298, "start": 478.26, "end": 480.86, "text": " That technique, I really like it.", "tokens": [663, 6532, 11, 286, 534, 411, 309, 13], "temperature": 0.0, "avg_logprob": -0.13491204889809214, "compression_ratio": 1.5471698113207548, "no_speech_prob": 2.840530578396283e-05}, {"id": 110, "seek": 46298, "start": 480.86, "end": 483.58000000000004, "text": " It's my favorite technique from philosophy.", "tokens": [467, 311, 452, 2954, 6532, 490, 10675, 13], "temperature": 0.0, "avg_logprob": -0.13491204889809214, "compression_ratio": 1.5471698113207548, "no_speech_prob": 2.840530578396283e-05}, {"id": 111, "seek": 46298, "start": 483.58000000000004, "end": 490.94, "text": " It's this idea that you say, OK, given this premise, here's what it implies.", "tokens": [467, 311, 341, 1558, 300, 291, 584, 11, 2264, 11, 2212, 341, 22045, 11, 510, 311, 437, 309, 18779, 13], "temperature": 0.0, "avg_logprob": -0.13491204889809214, "compression_ratio": 1.5471698113207548, "no_speech_prob": 2.840530578396283e-05}, {"id": 112, "seek": 49094, "start": 490.94, "end": 496.74, "text": " And then you try and find an implied result, which intuitively is clearly insane.", "tokens": [400, 550, 291, 853, 293, 915, 364, 32614, 1874, 11, 597, 46506, 307, 4448, 10838, 13], "temperature": 0.0, "avg_logprob": -0.2757634538592714, "compression_ratio": 1.4797687861271676, "no_speech_prob": 6.142478468973422e-06}, {"id": 113, "seek": 49094, "start": 496.74, "end": 503.54, "text": " And it's a really, it's the number one philosophical thinking tool I got out of university.", "tokens": [400, 309, 311, 257, 534, 11, 309, 311, 264, 1230, 472, 25066, 1953, 2290, 286, 658, 484, 295, 5454, 13], "temperature": 0.0, "avg_logprob": -0.2757634538592714, "compression_ratio": 1.4797687861271676, "no_speech_prob": 6.142478468973422e-06}, {"id": 114, "seek": 49094, "start": 503.54, "end": 507.06, "text": " And sometimes you can have a lot of fun with it like this time too.", "tokens": [400, 2171, 291, 393, 362, 257, 688, 295, 1019, 365, 309, 411, 341, 565, 886, 13], "temperature": 0.0, "avg_logprob": -0.2757634538592714, "compression_ratio": 1.4797687861271676, "no_speech_prob": 6.142478468973422e-06}, {"id": 115, "seek": 50706, "start": 507.06, "end": 521.42, "text": " Oh, thank you.", "tokens": [50364, 876, 11, 1309, 291, 13, 51082], "temperature": 0.0, "avg_logprob": -0.6372485756874084, "compression_ratio": 0.6363636363636364, "no_speech_prob": 0.0004706177278421819}], "language": "en"}