{"text": " Hi, can you see me and hear me okay? Test test one two. Okay. Sorry for the slight delay. Where did we get to last time we looked at data source. Did we finish looking at data source. And also did anybody have any questions about yesterday. No, it doesn't look like we quite finished a source. Okay, so we've done some. Okay, we looked at filter. Okay, so. Alright, so we're looking at data source. Yes, that's right. We looked at subsets. So I think the only bit we haven't looked at was data bunch. So if we look at the tests. Yes, I remember doing that test. Yeah, okay, so I don't think we did this one. So, one of the interesting things. Oh, my video is not on. No, it's not. Why is that? Thanks, Michael. That's because it's trying to use a device that's not there. And then my computer is going really slowly. Okay. Can you see me now? Alright, so one of the interesting things about data source is that the input could be, instead of being a list or an L or whatever, it can be a data frame or a numpy array. And one of the nice things is that it will use the pandas or numpy or whatever kind of accelerated indexing methods to index into that to grab the training set and the test set. So this is kind of a test that that's working correctly. And so here's an example of a transform, which should grab the first column. And then this subset is going to be the training set. And in this case, the data source, we haven't passed any filters into it. So this is going to be exactly the same as the unsubstated version. So that's all that tests doing. So here's how tensors work. They don't, sorry, how filters work. They don't have to be tensors, but here's an example with a tensor in a list just to show you. So here we've got two filters. And we can check the zero subset and the first subset. Yeah, so that 15 second lag, I think is that's just what YouTube does. It has a super low latency version. But if you choose a super low latency version, I think that significantly impacts the quality. So I think the 15 second lag is probably the best compromise. Just a reminder that the reason that we get things back as tuples is because that's what we expect to see for a data set or a data loader mini batch is that we do get tuples of X and Y or even if it's just an X, it'll be a tuple of an X. So it keeps things more consistent that way. Okay. Then we've got, yeah, so here's a test of adding a filter to a transform, which we talked about last time. So this transform will only be applied to subset one, which in this case will be these ones. So encode is X times two. So if we start with range, not through four, then the training set still going to be one comma two, but the validation set will be doubled because it's the filter number one. So that's the example of the thing we're talking about of using filters. Okay. So then data bunch is, as the name suggests, just something that creates a data bunch. So a data bunch to remind you is data bunch is this tiny, tiny, tiny thing. So it's just something which basically has a trained DL and a valid DL. So to create one, we just need to pass some data loaders into init for data bunch. That's how we create it. So here you can see here is the data bunch constructor and we have to pass in a bunch of data loaders. And this is something Silvran just added today, which is it won't necessarily be of type data loader. It could be some subclass of data loader. So DL class by default is transformed DL. So this is going to create a transformed DL with subset I because we're looping through all the I's of all of the subsets. And then for each one, there's going to be some batch size and some shuffle and some drop blast. And they all just depend on whether or not it's the training or validation set as to what's the appropriate value there. OK, so that's that. That is data source. So now let's put that all together again. Look back at data source in 08. So, OK, so the delegates is something that we're kind of working on at the moment. It's not quite working the way we want. But basically, normally we just put delegates at the very top of a class like this. And that means that the any star star quarks in the init of that class will be documented in the signature as being the super classes in it method. But we don't have to delegate to the super class in it. We can specifically say what we're delegating to. So in this case, the quarks that are being passed through here ended up being passed to the data loader constructor. So this says this is delegating to the data loader constructor. So if we look at the documentation. So let's run some of these to see this in action. So if we go data source data bunch. And you can see here's quarks. If I hit shift tab. Then I don't see quarks. I see all of the keyword arguments for data loader. And that's because that's what at delegates did. It said use the quarks from this method for the signature. OK, thanks for the question. So if we now look at the data source version here. Just to remind you of what we have. We're looking at the pets data set. And so the items are lists of paths. Two pictures of pets and two firms are these lists of PIO based on create. Or actually PIO image to create. And there's a regex label in the second pipeline and categorized in the second pipeline. So when we pass those to data source, we can also pass in our splits and we can go pets subset one to grab the validation set. And so this is the zero thing in that data set, which is, of course, an image. That's the shape and some label categorized label. So we can also use valid. And we can use decode. And we can use show. And so you can see show is decoding the int label to create an actual proper label. So in order to create many batches, we need to create a data loader. That's here. And to do that, we also need to resize all the images to the same size and turn them into tensors. And we need to put everything onto CUDA and convert byte to float tensors for the images. So when we create the transform data loader, we do the training set, some batch size. And then here the data loader transforms. And so then we can grab a batch and we can make sure that the lengths and shapes are right and that it's actually on CUDA if we asked it to be. And that now gives us something we can do a dot show batch done. We could have also done this by using data batch. Data bunch, rather. The source data bunch. Pets train. Pets data bunch. So that's going to want batch size. Oh, there's two batch sizes. That's a mistake. And let's grab all that. OK, so that's let's see what that's given us data bunch. So that should have a train DL. Train DL. Oopsie daisy. So it is. And so we could then grab a batch of that. Same idea. OK, so I guess we could even say show batch. There we are. OK, so questions. Maybe do image resizer as preprocessing. So generally you don't. Well, let's try and give you a complete answer to that, Harami. Generally speaking, in the fast data courses, we don't do it that way because normally part of the resizing is data augmentation. So the default data augmentation for ImageNet, for example, is we kind of pick some. We pick some random cropped sub area of the image and we kind of like zoom into that. So that's like what we that's kind of what that's normally how we resize. So for the training, the resizing is kind of cropping at the same time. So that's why we don't generally resize as preprocessing. Having said that, if your initial images are really, really big and you never want to use the full size of them, then you may want to do some preprocessing resizing. OK, so after batch and after item, I'm glad you asked. There's a thing I was going to look at in more detail now, which is to take a deeper dive into how transform data loader works. We've already kind of seen it a little bit, but we're probably in a good position to look at it more closely. And yeah, you can think of them as callbacks. Looking at O1C data loader is actually a fun place to study because it's a super interesting notebook. It's got this really annoying fake loader thing, which you shouldn't worry about too much because it's just working around some problems with the design of PyTorch's data loader. But once you get past that, to get to the data loader itself, we're doing a lot of stuff in a very nice way. So basically what happens is, let's see what happens when we iterate. So what's going to happen when we iterate is it's going to create some kind of loader. And so underscore loaders specifically is a list of the multiprocessing data loader and the single process data loader from PyTorch. So we'll generally be using the multiprocessing data loader. So it's going to grab a multiprocessing data loader and it's going to yield a batch from that. And what that does actually is when it iterates, it actually calls sampler on our data loader class to grab a sample of IDs and then batches to create batches from those IDs. So the key thing to look at is create batches. This is actually what the data loader is using, is create batches. So create batches, most of the time there's going to be a data set that we're creating a data loader over. So we create an iterator over the data set and we pop that into self.it. And then we grab each of the indexes that we are interested in. So this is the indexes of our sample and we map do item over that. Do item calls create item and then after item. Create item, assuming that the sample is not none, simply grabs the appropriate indexed item from a data set. So that's all create item does. And then after item, by default, after item equals no op. It does nothing at all. But we have this funcs quags thing, which is a thing where it looks for methods. And you'll see that after item is one of the things listed here in funcs quags. And what that means is that when we pass in quags, it's going to see if you've passed in something called after item. And it's going to replace our after item method with the thing you passed in. So in other words, we can pass in after item and it will then be called, the thing we passed in will be called at this point. So, yeah, it is basically a callback. But actually, notice that all of these things, all these things that are listed are all replaceable. So it's kind of like a bit more powerful than normal callbacks because you can easily replace anything inside the data loader with whatever you like. But these things with after or before in their name, the things which actually default to no op, are very easy to replace because there's no functionality currently there. So it doesn't matter. Like you can do anything you like. So after item, then, is the thing that is going to get called immediately after we grab one thing from the data set. And so that's what happens here. So we map that over each sample index. And then assuming that you have so that if you if you haven't got a batch size set, so batch size is none, then we're done. There's nothing to do. You haven't asked for batches. But if you have asked for batches, which you normally have, then we're going to map. Do batch over the result we just got. And first, we chunk it into batches. And one of the nice things about this code is the whole thing's done using kind of generators and maps and lazy. So it's a nice example of code to learn how to do that in Python. Anyway, so do batch is going to call before batch and then create batch and then retain. This is just the thing that keeps the same type. And then finally, eventually, after batch. So, again, before batch by default does nothing at all. After batch by default does nothing at all. And create batch by default simply calls collate. So that's the thing that just concatenates everything into a single tensor. OK, so it's amazing how little code there is here and how little it does that we end up with something that's like super extensible because we can hook into any of these points to change or add behavior. One of the things we're talking about is that we it's possible we might change the names of these things like after item and before batch and stuff. They're they're technically accurate. You know, they're kind of like once you understand how the data loader works. They make perfect sense. But we may change them to be names, which makes sense even if you don't know how the data loader works. So anyway, so that's something we're thinking about. So then to firm DL, which is in 05. Now I think about it. It is a pretty thin subclass of data loader. And as the name suggests, so here it is. As the name suggests, it is a data loader. But the key thing we do is that for each of these three callbacks, we look through those and we replace them with pipelines, transform pipelines. So that means that a different data loader also has decode, decode batch and show batch. So that's the key difference there. OK, the other thing it needs to know how to do is that if you when you call decode, you're going to be passing in just a plain pie torch tensor. Probably it's not going to have any type like a tensor image or tensor bounding box or whatever. So the data loader has to know what data types to convert it into. And what it actually does is it has this method called retain DL, which is the first thing that it does here. And that's the method that adds the types that it needs. So the what we do is we basically just run one mini batch, a small mini batch, to find out what types it creates. And we save those types. And this this little bit of code is actually super cute. If you want to look at some cute code, check this out and see if you can figure out how it's working, because it's I think it's very nice. OK, so that's that. So now you can see why we have these data set image transforms and these data loader transforms and what they go here. So these data set image transforms, image resizer, that's something that operates on. Let's go back and have a look at it because we created it just up here. It's something that operates on a pillow image. Right. So that has to be run before it's been collated into a mini batch. But after it's been grabbed from the data set. So that's why it's that is in the after item transforms because it's before it's been collated into a mini batch. On the other hand, CUDA and byte to float tensor are going to run much faster if it's run in a whole mini batch at a time. So after batch is the thing that happens after it's all been collated. And so that's why those ones are here. OK, so. Let's now look at data blocks. OK, so data blocks is down in 50. Because we. Because it has to use stuff from vision and text and so forth in order to create all those different types of data blocks. And let's take a look at an example first. So here's an example of MNIST. So if you remember what data blocks basically have to do, there has to be some way to say which files, for example, you're working with. Some way to say how to split it from validation set and trading set. And some way to label. So. Here are each of those things. We kind of need something else, though, as well, which is we need to know. For your exes, what types are you going to be creating for your exes? And for your wise, what types are you going to be creating for your wise? Why is that? Well, it wants to create. Those types, because these types, as we'll see, have information about what are all the transforms that you would generally expect to have to use to create and use that type. So you can see there isn't actually anything here. That says open an image, right? This is just list the images. On the disk, this the file names. But this tuple of types is the thing where it's going to call PIL image black and white dot create on the file name to create my exes. And it's going to call category to create my wise. And in the Y case, because there's a get Y defined, first of all, it will label it with apparent label. So if we have a look. So here's our category class. Let me try to remember how this works. Image P.W. I just try to remember how to find my way around this bit. So PIL image P.W. Right. So these types are defined in our seven vision core. Yeah, so you can see PIL image P.W. Is a PIL image. It's got no other methods, so it's going to be calling the create method for us. But when it calls the create method, it's going to use open args to figure out what arguments to pass to the create method, which in the case of PIL image P.W. is mode L. That's the black and white mode for pillow. But there's another thing in here that's interesting, which is that PIL base, which this inherits from, has a thing called default default DL transforms. And this says if you in the data blocks API, when you use this type, it's going to automatically add this transform to our pipeline. So here's another example. If you're working with point data. It adds this to your DS transform pipeline bounding boxes. There are different transforms that are added to those. So the key thing here is that these these types do two things, at least two things. The first is they say how to actually create the how to actually create the objects that we're trying to build. But they also say what default transforms to add to our pipeline. And so that's why when we then say so we can take a data block object and we can create it and then we can call data source passing in the thing that will eventually make its way to get item source. So this is the path to MNIST. And this then allows us, as you can see, to use it in the usual way. And because the data block API, as we'll see, users, funcs, quags. That means that we can instead of inheriting from data block, we can equally well just construct a data block. And if you construct a data block, then you have to pass in the types like this. And then here are the three things again that we're we were overriding before. So it's doing exactly the same thing as this one. So a lot of the time this one's going to be a bit shorter and easier version if you don't kind of need state. So let's look at the data block class. As you can see, it's very short. So as we discussed, it has a funcs, quags decorator. And that means it needs to look to see what the underscore methods are. So here's the list of methods that you can pass in to have replaced by your code. Then the other thing that you're going to pass in other types. So then what we're going to do is we're going to be creating three different sets of transforms. And in data block, we're giving them different names to what we've called them elsewhere. So again, I don't know if this is what the names are going to end up being. But basically what's going to happen is, as you can see, after item is DS transforms, which kind of makes sense, right? Because the things that happen after you pull something out of a data set is after items. So they're kind of the data set transforms. Where else the things that happen after you collate. So after batch, they're the DL transforms. So they're those two. And so we have for a particular data block subclass, there's going to be some default data set transforms and some default data loader transforms. The data set transforms, you're pretty much always going to want to tensor. Data loader transforms, pretty much always going to want CUDA. And then we're going to grab from our types that we passed in that default DS transforms and default DL transforms. Attributes that we saw. OK. So. There's something kind of interesting, though, which is then later on when you try to create your data bunch. You know, you might pass in your own data set transforms and data loader transforms. And so we have to merge them together with the defaults. And so that means if you pass in a transform that's already there, we don't want it to be there twice in particular. So there's a little function here called merge transforms, which, as you can see, basically removes duplicate transforms. So transforms of the same type. Which is a little bit awkward, but it works OK. So. This is why things like order is important. Remember, there's that order attribute in pipeline. We use the order attribute to sort the transforms. So like you can have transforms defined in different places. They can be defined in the types in the defaults and the types, or you could be passing them in directly when you call data source. Sorry, a data bunch or data source. And so we need to bring them all together in a list and make sure that list is in an order that makes sense. So, yes, so data augmentation we haven't looked at yet, but they are just other transforms. So generally you would pass them into the data bunch method and we don't have any. There's no augmentations that are done by default, so you have to pass them in. So if you ask for a data bunch, then first of all, it's going to create a data source. So self dot source in this case will be like the path to amnest, for example. So we would then call that get items function that you defined. And if you didn't define one, then just do nothing to turn the source into a list of items. And then if you have a splitter, then we create the splits from it. And if there's a get X and a get Y, then call those. We actually don't call those, just store those, I should say, as functions. So they're going to be a labeling functions. OK, if you didn't pass in any type transforms, then use the defaults. And so then we can create a data source passing in our items and our transforms. And so that gives us our data source. And then we'll create our data set transforms and data loader transforms and turn our data source into a data bunch using the method we just saw. OK, so that's data blocks. So the best way to understand it is through the examples. So yeah, have a look at the subclassing example. Have a look at the function version example. And so pets. So the types of pets are going to be image and a category. Same get items, random splitter, a regex label, forget Y. And there we go. In this case, you can see here we are actually doing some data augmentation. So aug transforms as a function or simply later, which gives us it's basically the same as get transforms was in version one. But now transforms is a much more general concept in version two. So these are specifically augmentation transforms. OK, then multi-label classification. So multi-label classification is interesting because this time we this is Planet. It uses a CSV. So, yeah, Kevin, hopefully that's answered your question on augmentations. Let me know if it didn't. So Planet, we create a data frame from the CSV. And so when we call Planet.Beta bunch, we're going to be passing in the numpy array version of that data frame. So Df.values in this case. And our augmentation here, as you can see, has some standard Planet appropriate augmentations, including flipvert equals true. And so what happens here? We passed in this. This is a numpy array when we called.values. And so getX is going to grab just X0. And this will just grab X1 and split it because this is a numpy array. So each row of this will contain the first the first item will be the file name and the second item will be the value. So that's one way of doing Planet, which is mildly clunky. It works. Here's another way of doing and the other thing about this way is it's kind of I don't know. It's like doing this numpy array thing is kind of weird. This is a more elegant way, I think, where we're actually passing in the data frame rather than converting it rather than converting it into a numpy array first. So this time we're doing something a little bit different, which is in get items. So before, for get items, there was nothing at all. Right. So we just used the numpy array directly. This time for get items, we're using this function, which returns a tuple. And the first thing in the tuple is a pandas expression that works in an entire pandas column to turn that column into a list of file names. And then this is another pandas expression that works on a complete column, the tags column to create the labels. So one of the things that we skipped over when we looked at data blocks is that when we call get items, if it returns a tuple, then what we do is we zip together all of the items in that tuple. So in this case, we've returned a column of file names and a column of labels. And data sets are meant to return a single file name label pair. So that's why this zips them together. And so then the labelers will just grab the appropriate thing from each of those lists. So this is kind of a nice, as you can see, you end up with very nice, neat code. It's also super fast because it's all operating, you know, in the kind of the pandas fast C code version of things. So this is a handy trick. And then here's the same thing again, but using inheritance instead. Here's a neat trick. You've probably only ever seen static method use as a decorator before, but you can actually just use it like all like everything. You can use it as a function to turn this into a static method. Lots and lots of versions of this, as you can see. Here's another one where we're pissing in the data frame and we can just have get X, grab the this column, grab get Y, this column. Maybe this is kind of actually the maybe this is the best version. It's kind of both fast and fairly obvious what's going on. So there's lots of ways of doing things. So Kevin mapped is simply the the version of map as a method inside L. And then map is just the standard map function in Python, which you should Google if you don't know about it. It's got nothing to do with parallelization. It's just a way of creating a lazy generator in Python. And it's it's very fundamental to how we do things in version two. So I mean, end users don't really need to understand it, but if you want to understand the version two code, then you should definitely do a deep dive into into map. And looking at how the version two data loader works would be a good place to get a very deep dive into that because it's all it's all doing lazy mapping. It's basically a functional style. So map is something that comes up in functional programming a lot. It's a lot of the code in version two is of a more functional style. I mean, here's a short version. If I create something like that and then I say map some function. Like negative. So that's just the negative function over that. It returns something weird. It returns a map. And basically that says this is a lazy generator, which won't be calculated until like I print it or turn it into a list or something. So I can just say list. And there you go. OK, so you can see it's mapped this function over my list. But it won't do it until you actually kind of finally need it. So if we go to two equals that and then we say T three equals map. Maybe lambda plus 100 over T two. So now T three is again some map that I could force it to get calculated like so. And as you can see, it's doing each of those functions in turn. So this is a really nice way to work with, you know, data sets and data loaders and stuff like that. You can just add more and more processing to them lazily in this way. OK. So then segmentation. I don't think there's anything interesting there that's any different. I'm not going to go into the details of how points and bounding boxes work. But for those of you that are interested in segment in object detection, for example, please do check it out in the code and ask us any questions you have. Because like although there's no new concepts in it, the way that this works so neatly, I think is super, super nice. And if you have questions or suggestions, I would love to hear about them. OK. And then I think what we might do next time is we will look at tabular data. So let's do that tomorrow. OK. Thanks, everybody. Hopefully that was useful. See you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 19.0, "text": " Hi, can you see me and hear me okay?", "tokens": [2421, 11, 393, 291, 536, 385, 293, 1568, 385, 1392, 30], "temperature": 0.0, "avg_logprob": -0.6603841145833333, "compression_ratio": 0.8780487804878049, "no_speech_prob": 0.2710569500923157}, {"id": 1, "seek": 1900, "start": 19.0, "end": 45.0, "text": " Test test one two.", "tokens": [9279, 1500, 472, 732, 13], "temperature": 0.0, "avg_logprob": -0.507499270968967, "compression_ratio": 0.782608695652174, "no_speech_prob": 0.003544586943462491}, {"id": 2, "seek": 4500, "start": 45.0, "end": 52.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.17868259035307785, "compression_ratio": 1.0853658536585367, "no_speech_prob": 2.7957363272435032e-05}, {"id": 3, "seek": 4500, "start": 52.0, "end": 59.0, "text": " Sorry for the slight delay.", "tokens": [4919, 337, 264, 4036, 8577, 13], "temperature": 0.0, "avg_logprob": -0.17868259035307785, "compression_ratio": 1.0853658536585367, "no_speech_prob": 2.7957363272435032e-05}, {"id": 4, "seek": 4500, "start": 59.0, "end": 68.0, "text": " Where did we get to last time we looked at data source.", "tokens": [2305, 630, 321, 483, 281, 1036, 565, 321, 2956, 412, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.17868259035307785, "compression_ratio": 1.0853658536585367, "no_speech_prob": 2.7957363272435032e-05}, {"id": 5, "seek": 6800, "start": 68.0, "end": 76.0, "text": " Did we finish looking at data source. And also did anybody have any questions about yesterday.", "tokens": [2589, 321, 2413, 1237, 412, 1412, 4009, 13, 400, 611, 630, 4472, 362, 604, 1651, 466, 5186, 13], "temperature": 0.0, "avg_logprob": -0.20165218006480823, "compression_ratio": 1.119047619047619, "no_speech_prob": 1.3416935871646274e-05}, {"id": 6, "seek": 7600, "start": 76.0, "end": 104.0, "text": " No, it doesn't look like we quite finished a source.", "tokens": [883, 11, 309, 1177, 380, 574, 411, 321, 1596, 4335, 257, 4009, 13], "temperature": 0.0, "avg_logprob": -0.21039321843315573, "compression_ratio": 0.8666666666666667, "no_speech_prob": 6.496356945717707e-05}, {"id": 7, "seek": 10400, "start": 104.0, "end": 108.0, "text": " Okay, so we've done some. Okay, we looked at filter.", "tokens": [1033, 11, 370, 321, 600, 1096, 512, 13, 1033, 11, 321, 2956, 412, 6608, 13], "temperature": 0.0, "avg_logprob": -0.150087646409577, "compression_ratio": 1.3302752293577982, "no_speech_prob": 2.077538738376461e-05}, {"id": 8, "seek": 10400, "start": 108.0, "end": 112.0, "text": " Okay, so.", "tokens": [1033, 11, 370, 13], "temperature": 0.0, "avg_logprob": -0.150087646409577, "compression_ratio": 1.3302752293577982, "no_speech_prob": 2.077538738376461e-05}, {"id": 9, "seek": 10400, "start": 112.0, "end": 117.0, "text": " Alright, so we're looking at data source.", "tokens": [2798, 11, 370, 321, 434, 1237, 412, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.150087646409577, "compression_ratio": 1.3302752293577982, "no_speech_prob": 2.077538738376461e-05}, {"id": 10, "seek": 10400, "start": 117.0, "end": 121.0, "text": " Yes, that's right. We looked at subsets.", "tokens": [1079, 11, 300, 311, 558, 13, 492, 2956, 412, 2090, 1385, 13], "temperature": 0.0, "avg_logprob": -0.150087646409577, "compression_ratio": 1.3302752293577982, "no_speech_prob": 2.077538738376461e-05}, {"id": 11, "seek": 12100, "start": 121.0, "end": 135.0, "text": " So I think the only bit we haven't looked at was data bunch.", "tokens": [407, 286, 519, 264, 787, 857, 321, 2378, 380, 2956, 412, 390, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.06685835275894557, "compression_ratio": 1.1862745098039216, "no_speech_prob": 1.384427559969481e-05}, {"id": 12, "seek": 12100, "start": 135.0, "end": 140.0, "text": " So if we look at the tests.", "tokens": [407, 498, 321, 574, 412, 264, 6921, 13], "temperature": 0.0, "avg_logprob": -0.06685835275894557, "compression_ratio": 1.1862745098039216, "no_speech_prob": 1.384427559969481e-05}, {"id": 13, "seek": 12100, "start": 140.0, "end": 146.0, "text": " Yes, I remember doing that test.", "tokens": [1079, 11, 286, 1604, 884, 300, 1500, 13], "temperature": 0.0, "avg_logprob": -0.06685835275894557, "compression_ratio": 1.1862745098039216, "no_speech_prob": 1.384427559969481e-05}, {"id": 14, "seek": 14600, "start": 146.0, "end": 152.0, "text": " Yeah, okay, so I don't think we did this one. So,", "tokens": [865, 11, 1392, 11, 370, 286, 500, 380, 519, 321, 630, 341, 472, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.1708089624132429, "compression_ratio": 1.2231404958677685, "no_speech_prob": 5.223878542892635e-05}, {"id": 15, "seek": 14600, "start": 152.0, "end": 158.0, "text": " one of the interesting things.", "tokens": [472, 295, 264, 1880, 721, 13], "temperature": 0.0, "avg_logprob": -0.1708089624132429, "compression_ratio": 1.2231404958677685, "no_speech_prob": 5.223878542892635e-05}, {"id": 16, "seek": 14600, "start": 158.0, "end": 162.0, "text": " Oh, my video is not on.", "tokens": [876, 11, 452, 960, 307, 406, 322, 13], "temperature": 0.0, "avg_logprob": -0.1708089624132429, "compression_ratio": 1.2231404958677685, "no_speech_prob": 5.223878542892635e-05}, {"id": 17, "seek": 14600, "start": 162.0, "end": 166.0, "text": " No, it's not. Why is that?", "tokens": [883, 11, 309, 311, 406, 13, 1545, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.1708089624132429, "compression_ratio": 1.2231404958677685, "no_speech_prob": 5.223878542892635e-05}, {"id": 18, "seek": 14600, "start": 166.0, "end": 172.0, "text": " Thanks, Michael.", "tokens": [2561, 11, 5116, 13], "temperature": 0.0, "avg_logprob": -0.1708089624132429, "compression_ratio": 1.2231404958677685, "no_speech_prob": 5.223878542892635e-05}, {"id": 19, "seek": 17200, "start": 172.0, "end": 201.0, "text": " That's because it's trying to use a device that's not there.", "tokens": [663, 311, 570, 309, 311, 1382, 281, 764, 257, 4302, 300, 311, 406, 456, 13], "temperature": 0.0, "avg_logprob": -0.24029681557103208, "compression_ratio": 1.0344827586206897, "no_speech_prob": 0.0006530821556225419}, {"id": 20, "seek": 20100, "start": 201.0, "end": 230.0, "text": " And then my computer is going really slowly.", "tokens": [400, 550, 452, 3820, 307, 516, 534, 5692, 13], "temperature": 0.0, "avg_logprob": -0.2996385097503662, "compression_ratio": 0.8461538461538461, "no_speech_prob": 0.0003905260527972132}, {"id": 21, "seek": 23000, "start": 230.0, "end": 253.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.21553385257720947, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.00044210240594111383}, {"id": 22, "seek": 25300, "start": 253.0, "end": 266.0, "text": " Can you see me now?", "tokens": [1664, 291, 536, 385, 586, 30], "temperature": 0.0, "avg_logprob": -0.1684321457484983, "compression_ratio": 1.3785714285714286, "no_speech_prob": 8.01239821157651e-06}, {"id": 23, "seek": 25300, "start": 266.0, "end": 281.0, "text": " Alright, so one of the interesting things about data source is that the input could be, instead of being a list or an L or whatever, it can be a data frame or a numpy array.", "tokens": [2798, 11, 370, 472, 295, 264, 1880, 721, 466, 1412, 4009, 307, 300, 264, 4846, 727, 312, 11, 2602, 295, 885, 257, 1329, 420, 364, 441, 420, 2035, 11, 309, 393, 312, 257, 1412, 3920, 420, 257, 1031, 8200, 10225, 13], "temperature": 0.0, "avg_logprob": -0.1684321457484983, "compression_ratio": 1.3785714285714286, "no_speech_prob": 8.01239821157651e-06}, {"id": 24, "seek": 28100, "start": 281.0, "end": 295.0, "text": " And one of the nice things is that it will use the pandas or numpy or whatever kind of accelerated indexing methods to index into that to grab the training set and the test set.", "tokens": [400, 472, 295, 264, 1481, 721, 307, 300, 309, 486, 764, 264, 4565, 296, 420, 1031, 8200, 420, 2035, 733, 295, 29763, 8186, 278, 7150, 281, 8186, 666, 300, 281, 4444, 264, 3097, 992, 293, 264, 1500, 992, 13], "temperature": 0.0, "avg_logprob": -0.0635808829603524, "compression_ratio": 1.5496688741721854, "no_speech_prob": 6.539919013448525e-06}, {"id": 25, "seek": 28100, "start": 295.0, "end": 302.0, "text": " So this is kind of a test that that's working correctly.", "tokens": [407, 341, 307, 733, 295, 257, 1500, 300, 300, 311, 1364, 8944, 13], "temperature": 0.0, "avg_logprob": -0.0635808829603524, "compression_ratio": 1.5496688741721854, "no_speech_prob": 6.539919013448525e-06}, {"id": 26, "seek": 30200, "start": 302.0, "end": 311.0, "text": " And so here's an example of a transform, which should grab the first column.", "tokens": [400, 370, 510, 311, 364, 1365, 295, 257, 4088, 11, 597, 820, 4444, 264, 700, 7738, 13], "temperature": 0.0, "avg_logprob": -0.07673416137695313, "compression_ratio": 1.2149532710280373, "no_speech_prob": 2.332035819563316e-06}, {"id": 27, "seek": 30200, "start": 311.0, "end": 320.0, "text": " And then this subset is going to be the training set.", "tokens": [400, 550, 341, 25993, 307, 516, 281, 312, 264, 3097, 992, 13], "temperature": 0.0, "avg_logprob": -0.07673416137695313, "compression_ratio": 1.2149532710280373, "no_speech_prob": 2.332035819563316e-06}, {"id": 28, "seek": 32000, "start": 320.0, "end": 332.0, "text": " And in this case, the data source, we haven't passed any filters into it. So this is going to be exactly the same as the unsubstated version. So that's all that tests doing.", "tokens": [400, 294, 341, 1389, 11, 264, 1412, 4009, 11, 321, 2378, 380, 4678, 604, 15995, 666, 309, 13, 407, 341, 307, 516, 281, 312, 2293, 264, 912, 382, 264, 2693, 836, 372, 770, 3037, 13, 407, 300, 311, 439, 300, 6921, 884, 13], "temperature": 0.0, "avg_logprob": -0.12943258492842966, "compression_ratio": 1.6567164179104477, "no_speech_prob": 2.769293587334687e-06}, {"id": 29, "seek": 32000, "start": 332.0, "end": 349.0, "text": " So here's how tensors work. They don't, sorry, how filters work. They don't have to be tensors, but here's an example with a tensor in a list just to show you.", "tokens": [407, 510, 311, 577, 10688, 830, 589, 13, 814, 500, 380, 11, 2597, 11, 577, 15995, 589, 13, 814, 500, 380, 362, 281, 312, 10688, 830, 11, 457, 510, 311, 364, 1365, 365, 257, 40863, 294, 257, 1329, 445, 281, 855, 291, 13], "temperature": 0.0, "avg_logprob": -0.12943258492842966, "compression_ratio": 1.6567164179104477, "no_speech_prob": 2.769293587334687e-06}, {"id": 30, "seek": 34900, "start": 349.0, "end": 355.0, "text": " So here we've got two filters.", "tokens": [407, 510, 321, 600, 658, 732, 15995, 13], "temperature": 0.0, "avg_logprob": -0.12118536896175808, "compression_ratio": 1.5185185185185186, "no_speech_prob": 2.8408174330252223e-05}, {"id": 31, "seek": 34900, "start": 355.0, "end": 361.0, "text": " And we can check the zero subset and the first subset.", "tokens": [400, 321, 393, 1520, 264, 4018, 25993, 293, 264, 700, 25993, 13], "temperature": 0.0, "avg_logprob": -0.12118536896175808, "compression_ratio": 1.5185185185185186, "no_speech_prob": 2.8408174330252223e-05}, {"id": 32, "seek": 34900, "start": 361.0, "end": 375.0, "text": " Yeah, so that 15 second lag, I think is that's just what YouTube does. It has a super low latency version. But if you choose a super low latency version, I think that significantly impacts the quality.", "tokens": [865, 11, 370, 300, 2119, 1150, 8953, 11, 286, 519, 307, 300, 311, 445, 437, 3088, 775, 13, 467, 575, 257, 1687, 2295, 27043, 3037, 13, 583, 498, 291, 2826, 257, 1687, 2295, 27043, 3037, 11, 286, 519, 300, 10591, 11606, 264, 3125, 13], "temperature": 0.0, "avg_logprob": -0.12118536896175808, "compression_ratio": 1.5185185185185186, "no_speech_prob": 2.8408174330252223e-05}, {"id": 33, "seek": 37500, "start": 375.0, "end": 383.0, "text": " So I think the 15 second lag is probably the best compromise.", "tokens": [407, 286, 519, 264, 2119, 1150, 8953, 307, 1391, 264, 1151, 18577, 13], "temperature": 0.0, "avg_logprob": -0.0765834555906408, "compression_ratio": 0.9682539682539683, "no_speech_prob": 4.936862296744948e-06}, {"id": 34, "seek": 38300, "start": 383.0, "end": 406.0, "text": " Just a reminder that the reason that we get things back as tuples is because that's what we expect to see for a data set or a data loader mini batch is that we do get tuples of X and Y or even if it's just an X, it'll be a tuple of an X. So it keeps things more consistent that way.", "tokens": [1449, 257, 13548, 300, 264, 1778, 300, 321, 483, 721, 646, 382, 2604, 2622, 307, 570, 300, 311, 437, 321, 2066, 281, 536, 337, 257, 1412, 992, 420, 257, 1412, 3677, 260, 8382, 15245, 307, 300, 321, 360, 483, 2604, 2622, 295, 1783, 293, 398, 420, 754, 498, 309, 311, 445, 364, 1783, 11, 309, 603, 312, 257, 2604, 781, 295, 364, 1783, 13, 407, 309, 5965, 721, 544, 8398, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.11567505923184482, "compression_ratio": 1.630057803468208, "no_speech_prob": 1.1478054148028605e-05}, {"id": 35, "seek": 40600, "start": 406.0, "end": 422.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.30758245786031085, "compression_ratio": 0.38461538461538464, "no_speech_prob": 3.6687995361717185e-06}, {"id": 36, "seek": 42200, "start": 422.0, "end": 441.0, "text": " Then we've got, yeah, so here's a test of adding a filter to a transform, which we talked about last time. So this transform will only be applied to subset one, which in this case will be these ones.", "tokens": [1396, 321, 600, 658, 11, 1338, 11, 370, 510, 311, 257, 1500, 295, 5127, 257, 6608, 281, 257, 4088, 11, 597, 321, 2825, 466, 1036, 565, 13, 407, 341, 4088, 486, 787, 312, 6456, 281, 25993, 472, 11, 597, 294, 341, 1389, 486, 312, 613, 2306, 13], "temperature": 0.0, "avg_logprob": -0.10783738777285716, "compression_ratio": 1.480263157894737, "no_speech_prob": 9.276306514038879e-07}, {"id": 37, "seek": 42200, "start": 441.0, "end": 445.0, "text": " So encode is X times two.", "tokens": [407, 2058, 1429, 307, 1783, 1413, 732, 13], "temperature": 0.0, "avg_logprob": -0.10783738777285716, "compression_ratio": 1.480263157894737, "no_speech_prob": 9.276306514038879e-07}, {"id": 38, "seek": 44500, "start": 445.0, "end": 458.0, "text": " So if we start with range, not through four, then the training set still going to be one comma two, but the validation set will be doubled because it's the filter number one.", "tokens": [407, 498, 321, 722, 365, 3613, 11, 406, 807, 1451, 11, 550, 264, 3097, 992, 920, 516, 281, 312, 472, 22117, 732, 11, 457, 264, 24071, 992, 486, 312, 24405, 570, 309, 311, 264, 6608, 1230, 472, 13], "temperature": 0.0, "avg_logprob": -0.11536374688148499, "compression_ratio": 1.505952380952381, "no_speech_prob": 3.966902568208752e-06}, {"id": 39, "seek": 44500, "start": 458.0, "end": 466.0, "text": " So that's the example of the thing we're talking about of using filters.", "tokens": [407, 300, 311, 264, 1365, 295, 264, 551, 321, 434, 1417, 466, 295, 1228, 15995, 13], "temperature": 0.0, "avg_logprob": -0.11536374688148499, "compression_ratio": 1.505952380952381, "no_speech_prob": 3.966902568208752e-06}, {"id": 40, "seek": 44500, "start": 466.0, "end": 472.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.11536374688148499, "compression_ratio": 1.505952380952381, "no_speech_prob": 3.966902568208752e-06}, {"id": 41, "seek": 47200, "start": 472.0, "end": 482.0, "text": " So then data bunch is, as the name suggests, just something that creates a data bunch.", "tokens": [407, 550, 1412, 3840, 307, 11, 382, 264, 1315, 13409, 11, 445, 746, 300, 7829, 257, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.1521271886052312, "compression_ratio": 1.4285714285714286, "no_speech_prob": 7.18278033673414e-06}, {"id": 42, "seek": 47200, "start": 482.0, "end": 489.0, "text": " So a data bunch to remind you is", "tokens": [407, 257, 1412, 3840, 281, 4160, 291, 307], "temperature": 0.0, "avg_logprob": -0.1521271886052312, "compression_ratio": 1.4285714285714286, "no_speech_prob": 7.18278033673414e-06}, {"id": 43, "seek": 47200, "start": 489.0, "end": 494.0, "text": " data bunch", "tokens": [1412, 3840], "temperature": 0.0, "avg_logprob": -0.1521271886052312, "compression_ratio": 1.4285714285714286, "no_speech_prob": 7.18278033673414e-06}, {"id": 44, "seek": 49400, "start": 494.0, "end": 502.0, "text": " is this tiny, tiny, tiny thing. So it's just something which basically has a trained DL and a valid DL.", "tokens": [307, 341, 5870, 11, 5870, 11, 5870, 551, 13, 407, 309, 311, 445, 746, 597, 1936, 575, 257, 8895, 413, 43, 293, 257, 7363, 413, 43, 13], "temperature": 0.0, "avg_logprob": -0.1186864145340458, "compression_ratio": 1.4652777777777777, "no_speech_prob": 1.544523547636345e-05}, {"id": 45, "seek": 49400, "start": 502.0, "end": 507.0, "text": " So to create one,", "tokens": [407, 281, 1884, 472, 11], "temperature": 0.0, "avg_logprob": -0.1186864145340458, "compression_ratio": 1.4652777777777777, "no_speech_prob": 1.544523547636345e-05}, {"id": 46, "seek": 49400, "start": 507.0, "end": 514.0, "text": " we just need to pass some data loaders into init for data bunch. That's how we create it.", "tokens": [321, 445, 643, 281, 1320, 512, 1412, 3677, 433, 666, 3157, 337, 1412, 3840, 13, 663, 311, 577, 321, 1884, 309, 13], "temperature": 0.0, "avg_logprob": -0.1186864145340458, "compression_ratio": 1.4652777777777777, "no_speech_prob": 1.544523547636345e-05}, {"id": 47, "seek": 51400, "start": 514.0, "end": 526.0, "text": " So here you can see here is the data bunch constructor and we have to pass in a bunch of data loaders.", "tokens": [407, 510, 291, 393, 536, 510, 307, 264, 1412, 3840, 47479, 293, 321, 362, 281, 1320, 294, 257, 3840, 295, 1412, 3677, 433, 13], "temperature": 0.0, "avg_logprob": -0.15411749619704027, "compression_ratio": 1.5279503105590062, "no_speech_prob": 2.406078237982001e-06}, {"id": 48, "seek": 51400, "start": 526.0, "end": 534.0, "text": " And this is something Silvran just added today, which is it won't necessarily be of type data loader. It could be some subclass of data loader.", "tokens": [400, 341, 307, 746, 6943, 85, 4257, 445, 3869, 965, 11, 597, 307, 309, 1582, 380, 4725, 312, 295, 2010, 1412, 3677, 260, 13, 467, 727, 312, 512, 1422, 11665, 295, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.15411749619704027, "compression_ratio": 1.5279503105590062, "no_speech_prob": 2.406078237982001e-06}, {"id": 49, "seek": 53400, "start": 534.0, "end": 550.0, "text": " So DL class by default is transformed DL. So this is going to create a transformed DL with subset I because we're looping through all the I's of all of the subsets.", "tokens": [407, 413, 43, 1508, 538, 7576, 307, 16894, 413, 43, 13, 407, 341, 307, 516, 281, 1884, 257, 16894, 413, 43, 365, 25993, 286, 570, 321, 434, 6367, 278, 807, 439, 264, 286, 311, 295, 439, 295, 264, 2090, 1385, 13], "temperature": 0.0, "avg_logprob": -0.12703367592631906, "compression_ratio": 1.535294117647059, "no_speech_prob": 5.255307314655511e-06}, {"id": 50, "seek": 53400, "start": 550.0, "end": 555.0, "text": " And then for each one, there's going to be some batch size and some shuffle and some drop blast.", "tokens": [400, 550, 337, 1184, 472, 11, 456, 311, 516, 281, 312, 512, 15245, 2744, 293, 512, 39426, 293, 512, 3270, 12035, 13], "temperature": 0.0, "avg_logprob": -0.12703367592631906, "compression_ratio": 1.535294117647059, "no_speech_prob": 5.255307314655511e-06}, {"id": 51, "seek": 55500, "start": 555.0, "end": 566.0, "text": " And they all just depend on whether or not it's the training or validation set as to what's the appropriate value there.", "tokens": [400, 436, 439, 445, 5672, 322, 1968, 420, 406, 309, 311, 264, 3097, 420, 24071, 992, 382, 281, 437, 311, 264, 6854, 2158, 456, 13], "temperature": 0.0, "avg_logprob": -0.07758375803629557, "compression_ratio": 1.3305785123966942, "no_speech_prob": 8.059381002567534e-07}, {"id": 52, "seek": 55500, "start": 566.0, "end": 571.0, "text": " OK, so that's that. That is", "tokens": [2264, 11, 370, 300, 311, 300, 13, 663, 307], "temperature": 0.0, "avg_logprob": -0.07758375803629557, "compression_ratio": 1.3305785123966942, "no_speech_prob": 8.059381002567534e-07}, {"id": 53, "seek": 55500, "start": 571.0, "end": 577.0, "text": " data source.", "tokens": [1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.07758375803629557, "compression_ratio": 1.3305785123966942, "no_speech_prob": 8.059381002567534e-07}, {"id": 54, "seek": 57700, "start": 577.0, "end": 592.0, "text": " So now let's put that all together again. Look back at data source in 08.", "tokens": [407, 586, 718, 311, 829, 300, 439, 1214, 797, 13, 2053, 646, 412, 1412, 4009, 294, 1958, 23, 13], "temperature": 0.0, "avg_logprob": -0.1082802339033647, "compression_ratio": 1.3424657534246576, "no_speech_prob": 1.2029037861793768e-05}, {"id": 55, "seek": 57700, "start": 592.0, "end": 599.0, "text": " So, OK, so the delegates is something that we're kind of working on at the moment. It's not quite working the way we want.", "tokens": [407, 11, 2264, 11, 370, 264, 45756, 307, 746, 300, 321, 434, 733, 295, 1364, 322, 412, 264, 1623, 13, 467, 311, 406, 1596, 1364, 264, 636, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.1082802339033647, "compression_ratio": 1.3424657534246576, "no_speech_prob": 1.2029037861793768e-05}, {"id": 56, "seek": 59900, "start": 599.0, "end": 609.0, "text": " But basically, normally we just put delegates at the very top of a class like this.", "tokens": [583, 1936, 11, 5646, 321, 445, 829, 45756, 412, 264, 588, 1192, 295, 257, 1508, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.12995899373834782, "compression_ratio": 1.54, "no_speech_prob": 3.18751813210838e-06}, {"id": 57, "seek": 59900, "start": 609.0, "end": 624.0, "text": " And that means that the any star star quarks in the init of that class will be documented in the signature as being the super classes in it method.", "tokens": [400, 300, 1355, 300, 264, 604, 3543, 3543, 421, 20851, 294, 264, 3157, 295, 300, 1508, 486, 312, 23007, 294, 264, 13397, 382, 885, 264, 1687, 5359, 294, 309, 3170, 13], "temperature": 0.0, "avg_logprob": -0.12995899373834782, "compression_ratio": 1.54, "no_speech_prob": 3.18751813210838e-06}, {"id": 58, "seek": 62400, "start": 624.0, "end": 631.0, "text": " But we don't have to delegate to the super class in it. We can specifically say what we're delegating to.", "tokens": [583, 321, 500, 380, 362, 281, 40999, 281, 264, 1687, 1508, 294, 309, 13, 492, 393, 4682, 584, 437, 321, 434, 15824, 990, 281, 13], "temperature": 0.0, "avg_logprob": -0.09101167321205139, "compression_ratio": 1.7405405405405405, "no_speech_prob": 6.276619046730048e-07}, {"id": 59, "seek": 62400, "start": 631.0, "end": 641.0, "text": " So in this case, the quarks that are being passed through here ended up being passed to the data loader constructor.", "tokens": [407, 294, 341, 1389, 11, 264, 421, 20851, 300, 366, 885, 4678, 807, 510, 4590, 493, 885, 4678, 281, 264, 1412, 3677, 260, 47479, 13], "temperature": 0.0, "avg_logprob": -0.09101167321205139, "compression_ratio": 1.7405405405405405, "no_speech_prob": 6.276619046730048e-07}, {"id": 60, "seek": 62400, "start": 641.0, "end": 649.0, "text": " So this says this is delegating to the data loader constructor. So if we look at the documentation.", "tokens": [407, 341, 1619, 341, 307, 15824, 990, 281, 264, 1412, 3677, 260, 47479, 13, 407, 498, 321, 574, 412, 264, 14333, 13], "temperature": 0.0, "avg_logprob": -0.09101167321205139, "compression_ratio": 1.7405405405405405, "no_speech_prob": 6.276619046730048e-07}, {"id": 61, "seek": 64900, "start": 649.0, "end": 655.0, "text": " So let's run some of these to see this in action.", "tokens": [407, 718, 311, 1190, 512, 295, 613, 281, 536, 341, 294, 3069, 13], "temperature": 0.0, "avg_logprob": -0.1352726381216476, "compression_ratio": 1.42, "no_speech_prob": 6.854185812699143e-06}, {"id": 62, "seek": 64900, "start": 655.0, "end": 662.0, "text": " So if we go data source data bunch.", "tokens": [407, 498, 321, 352, 1412, 4009, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.1352726381216476, "compression_ratio": 1.42, "no_speech_prob": 6.854185812699143e-06}, {"id": 63, "seek": 64900, "start": 662.0, "end": 668.0, "text": " And you can see here's quarks. If I hit shift tab.", "tokens": [400, 291, 393, 536, 510, 311, 421, 20851, 13, 759, 286, 2045, 5513, 4421, 13], "temperature": 0.0, "avg_logprob": -0.1352726381216476, "compression_ratio": 1.42, "no_speech_prob": 6.854185812699143e-06}, {"id": 64, "seek": 64900, "start": 668.0, "end": 674.0, "text": " Then I don't see quarks. I see all of the keyword arguments for data loader.", "tokens": [1396, 286, 500, 380, 536, 421, 20851, 13, 286, 536, 439, 295, 264, 20428, 12869, 337, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.1352726381216476, "compression_ratio": 1.42, "no_speech_prob": 6.854185812699143e-06}, {"id": 65, "seek": 67400, "start": 674.0, "end": 686.0, "text": " And that's because that's what at delegates did. It said use the quarks from this method for the signature.", "tokens": [400, 300, 311, 570, 300, 311, 437, 412, 45756, 630, 13, 467, 848, 764, 264, 421, 20851, 490, 341, 3170, 337, 264, 13397, 13], "temperature": 0.0, "avg_logprob": -0.12128840266047297, "compression_ratio": 1.2477064220183487, "no_speech_prob": 1.2606366908585187e-05}, {"id": 66, "seek": 67400, "start": 686.0, "end": 693.0, "text": " OK, thanks for the question.", "tokens": [2264, 11, 3231, 337, 264, 1168, 13], "temperature": 0.0, "avg_logprob": -0.12128840266047297, "compression_ratio": 1.2477064220183487, "no_speech_prob": 1.2606366908585187e-05}, {"id": 67, "seek": 69300, "start": 693.0, "end": 710.0, "text": " So if we now look at the data source version here.", "tokens": [407, 498, 321, 586, 574, 412, 264, 1412, 4009, 3037, 510, 13], "temperature": 0.0, "avg_logprob": -0.16159804662068686, "compression_ratio": 1.2323232323232323, "no_speech_prob": 4.495000666793203e-06}, {"id": 68, "seek": 69300, "start": 710.0, "end": 715.0, "text": " Just to remind you of what we have. We're looking at the pets data set.", "tokens": [1449, 281, 4160, 291, 295, 437, 321, 362, 13, 492, 434, 1237, 412, 264, 19897, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.16159804662068686, "compression_ratio": 1.2323232323232323, "no_speech_prob": 4.495000666793203e-06}, {"id": 69, "seek": 71500, "start": 715.0, "end": 727.0, "text": " And so the items are lists of paths.", "tokens": [400, 370, 264, 4754, 366, 14511, 295, 14518, 13], "temperature": 0.0, "avg_logprob": -0.27066031098365784, "compression_ratio": 1.2197802197802199, "no_speech_prob": 9.222879270964768e-06}, {"id": 70, "seek": 71500, "start": 727.0, "end": 737.0, "text": " Two pictures of pets and two firms are these lists of PIO based on create.", "tokens": [4453, 5242, 295, 19897, 293, 732, 18055, 366, 613, 14511, 295, 430, 15167, 2361, 322, 1884, 13], "temperature": 0.0, "avg_logprob": -0.27066031098365784, "compression_ratio": 1.2197802197802199, "no_speech_prob": 9.222879270964768e-06}, {"id": 71, "seek": 73700, "start": 737.0, "end": 746.0, "text": " Or actually PIO image to create. And there's a regex label in the second pipeline and categorized in the second pipeline.", "tokens": [1610, 767, 430, 15167, 3256, 281, 1884, 13, 400, 456, 311, 257, 319, 432, 87, 7645, 294, 264, 1150, 15517, 293, 19250, 1602, 294, 264, 1150, 15517, 13], "temperature": 0.0, "avg_logprob": -0.15774541677430617, "compression_ratio": 1.635, "no_speech_prob": 3.6118021853326354e-06}, {"id": 72, "seek": 73700, "start": 746.0, "end": 757.0, "text": " So when we pass those to data source, we can also pass in our splits and we can go pets subset one to grab the validation set.", "tokens": [407, 562, 321, 1320, 729, 281, 1412, 4009, 11, 321, 393, 611, 1320, 294, 527, 37741, 293, 321, 393, 352, 19897, 25993, 472, 281, 4444, 264, 24071, 992, 13], "temperature": 0.0, "avg_logprob": -0.15774541677430617, "compression_ratio": 1.635, "no_speech_prob": 3.6118021853326354e-06}, {"id": 73, "seek": 73700, "start": 757.0, "end": 762.0, "text": " And so this is the zero thing in that data set, which is, of course, an image.", "tokens": [400, 370, 341, 307, 264, 4018, 551, 294, 300, 1412, 992, 11, 597, 307, 11, 295, 1164, 11, 364, 3256, 13], "temperature": 0.0, "avg_logprob": -0.15774541677430617, "compression_ratio": 1.635, "no_speech_prob": 3.6118021853326354e-06}, {"id": 74, "seek": 76200, "start": 762.0, "end": 768.0, "text": " That's the shape and some label categorized label.", "tokens": [663, 311, 264, 3909, 293, 512, 7645, 19250, 1602, 7645, 13], "temperature": 0.0, "avg_logprob": -0.10335874557495117, "compression_ratio": 1.5813953488372092, "no_speech_prob": 1.6536736211492098e-06}, {"id": 75, "seek": 76200, "start": 768.0, "end": 771.0, "text": " So we can also use valid.", "tokens": [407, 321, 393, 611, 764, 7363, 13], "temperature": 0.0, "avg_logprob": -0.10335874557495117, "compression_ratio": 1.5813953488372092, "no_speech_prob": 1.6536736211492098e-06}, {"id": 76, "seek": 76200, "start": 771.0, "end": 773.0, "text": " And we can use decode.", "tokens": [400, 321, 393, 764, 979, 1429, 13], "temperature": 0.0, "avg_logprob": -0.10335874557495117, "compression_ratio": 1.5813953488372092, "no_speech_prob": 1.6536736211492098e-06}, {"id": 77, "seek": 76200, "start": 773.0, "end": 775.0, "text": " And we can use show.", "tokens": [400, 321, 393, 764, 855, 13], "temperature": 0.0, "avg_logprob": -0.10335874557495117, "compression_ratio": 1.5813953488372092, "no_speech_prob": 1.6536736211492098e-06}, {"id": 78, "seek": 76200, "start": 775.0, "end": 784.0, "text": " And so you can see show is decoding the int label to create an actual proper label.", "tokens": [400, 370, 291, 393, 536, 855, 307, 979, 8616, 264, 560, 7645, 281, 1884, 364, 3539, 2296, 7645, 13], "temperature": 0.0, "avg_logprob": -0.10335874557495117, "compression_ratio": 1.5813953488372092, "no_speech_prob": 1.6536736211492098e-06}, {"id": 79, "seek": 78400, "start": 784.0, "end": 792.0, "text": " So in order to create many batches, we need to create a data loader.", "tokens": [407, 294, 1668, 281, 1884, 867, 15245, 279, 11, 321, 643, 281, 1884, 257, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.06943023204803467, "compression_ratio": 1.6167664670658684, "no_speech_prob": 3.041520130864228e-06}, {"id": 80, "seek": 78400, "start": 792.0, "end": 795.0, "text": " That's here.", "tokens": [663, 311, 510, 13], "temperature": 0.0, "avg_logprob": -0.06943023204803467, "compression_ratio": 1.6167664670658684, "no_speech_prob": 3.041520130864228e-06}, {"id": 81, "seek": 78400, "start": 795.0, "end": 802.0, "text": " And to do that, we also need to resize all the images to the same size and turn them into tensors.", "tokens": [400, 281, 360, 300, 11, 321, 611, 643, 281, 50069, 439, 264, 5267, 281, 264, 912, 2744, 293, 1261, 552, 666, 10688, 830, 13], "temperature": 0.0, "avg_logprob": -0.06943023204803467, "compression_ratio": 1.6167664670658684, "no_speech_prob": 3.041520130864228e-06}, {"id": 82, "seek": 78400, "start": 802.0, "end": 811.0, "text": " And we need to put everything onto CUDA and convert byte to float tensors for the images.", "tokens": [400, 321, 643, 281, 829, 1203, 3911, 29777, 7509, 293, 7620, 40846, 281, 15706, 10688, 830, 337, 264, 5267, 13], "temperature": 0.0, "avg_logprob": -0.06943023204803467, "compression_ratio": 1.6167664670658684, "no_speech_prob": 3.041520130864228e-06}, {"id": 83, "seek": 81100, "start": 811.0, "end": 819.0, "text": " So when we create the transform data loader, we do the training set, some batch size.", "tokens": [407, 562, 321, 1884, 264, 4088, 1412, 3677, 260, 11, 321, 360, 264, 3097, 992, 11, 512, 15245, 2744, 13], "temperature": 0.0, "avg_logprob": -0.1367382738325331, "compression_ratio": 1.6130952380952381, "no_speech_prob": 5.014550879423041e-06}, {"id": 84, "seek": 81100, "start": 819.0, "end": 827.0, "text": " And then here the data loader transforms.", "tokens": [400, 550, 510, 264, 1412, 3677, 260, 35592, 13], "temperature": 0.0, "avg_logprob": -0.1367382738325331, "compression_ratio": 1.6130952380952381, "no_speech_prob": 5.014550879423041e-06}, {"id": 85, "seek": 81100, "start": 827.0, "end": 839.0, "text": " And so then we can grab a batch and we can make sure that the lengths and shapes are right and that it's actually on CUDA if we asked it to be.", "tokens": [400, 370, 550, 321, 393, 4444, 257, 15245, 293, 321, 393, 652, 988, 300, 264, 26329, 293, 10854, 366, 558, 293, 300, 309, 311, 767, 322, 29777, 7509, 498, 321, 2351, 309, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.1367382738325331, "compression_ratio": 1.6130952380952381, "no_speech_prob": 5.014550879423041e-06}, {"id": 86, "seek": 83900, "start": 839.0, "end": 845.0, "text": " And that now gives us something we can do a dot show batch done.", "tokens": [400, 300, 586, 2709, 505, 746, 321, 393, 360, 257, 5893, 855, 15245, 1096, 13], "temperature": 0.0, "avg_logprob": -0.15234033878032976, "compression_ratio": 1.2523364485981308, "no_speech_prob": 4.785008513863431e-06}, {"id": 87, "seek": 83900, "start": 845.0, "end": 857.0, "text": " We could have also done this by using data batch.", "tokens": [492, 727, 362, 611, 1096, 341, 538, 1228, 1412, 15245, 13], "temperature": 0.0, "avg_logprob": -0.15234033878032976, "compression_ratio": 1.2523364485981308, "no_speech_prob": 4.785008513863431e-06}, {"id": 88, "seek": 83900, "start": 857.0, "end": 861.0, "text": " Data bunch, rather.", "tokens": [11888, 3840, 11, 2831, 13], "temperature": 0.0, "avg_logprob": -0.15234033878032976, "compression_ratio": 1.2523364485981308, "no_speech_prob": 4.785008513863431e-06}, {"id": 89, "seek": 86100, "start": 861.0, "end": 871.0, "text": " The source data bunch.", "tokens": [440, 4009, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.18427311290394177, "compression_ratio": 1.144736842105263, "no_speech_prob": 3.5007608403248014e-06}, {"id": 90, "seek": 86100, "start": 871.0, "end": 875.0, "text": " Pets train.", "tokens": [430, 1385, 3847, 13], "temperature": 0.0, "avg_logprob": -0.18427311290394177, "compression_ratio": 1.144736842105263, "no_speech_prob": 3.5007608403248014e-06}, {"id": 91, "seek": 86100, "start": 875.0, "end": 878.0, "text": " Pets data bunch.", "tokens": [430, 1385, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.18427311290394177, "compression_ratio": 1.144736842105263, "no_speech_prob": 3.5007608403248014e-06}, {"id": 92, "seek": 86100, "start": 878.0, "end": 885.0, "text": " So that's going to want batch size.", "tokens": [407, 300, 311, 516, 281, 528, 15245, 2744, 13], "temperature": 0.0, "avg_logprob": -0.18427311290394177, "compression_ratio": 1.144736842105263, "no_speech_prob": 3.5007608403248014e-06}, {"id": 93, "seek": 88500, "start": 885.0, "end": 899.0, "text": " Oh, there's two batch sizes. That's a mistake.", "tokens": [876, 11, 456, 311, 732, 15245, 11602, 13, 663, 311, 257, 6146, 13], "temperature": 0.0, "avg_logprob": -0.205277821596931, "compression_ratio": 0.8679245283018868, "no_speech_prob": 1.2804534890165087e-05}, {"id": 94, "seek": 89900, "start": 899.0, "end": 922.0, "text": " And let's grab all that.", "tokens": [400, 718, 311, 4444, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.14321986560163827, "compression_ratio": 1.1095890410958904, "no_speech_prob": 1.4508913409372326e-05}, {"id": 95, "seek": 89900, "start": 922.0, "end": 927.0, "text": " OK, so that's let's see what that's given us data bunch.", "tokens": [2264, 11, 370, 300, 311, 718, 311, 536, 437, 300, 311, 2212, 505, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.14321986560163827, "compression_ratio": 1.1095890410958904, "no_speech_prob": 1.4508913409372326e-05}, {"id": 96, "seek": 92700, "start": 927.0, "end": 938.0, "text": " So that should have a train DL.", "tokens": [407, 300, 820, 362, 257, 3847, 413, 43, 13], "temperature": 0.0, "avg_logprob": -0.28146251879240336, "compression_ratio": 0.9761904761904762, "no_speech_prob": 3.88232474506367e-05}, {"id": 97, "seek": 92700, "start": 938.0, "end": 950.0, "text": " Train DL.", "tokens": [28029, 413, 43, 13], "temperature": 0.0, "avg_logprob": -0.28146251879240336, "compression_ratio": 0.9761904761904762, "no_speech_prob": 3.88232474506367e-05}, {"id": 98, "seek": 95000, "start": 950.0, "end": 960.0, "text": " Oopsie daisy. So it is. And so we could then grab a batch of that.", "tokens": [21726, 414, 1120, 14169, 13, 407, 309, 307, 13, 400, 370, 321, 727, 550, 4444, 257, 15245, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.10234354911966527, "compression_ratio": 1.2252252252252251, "no_speech_prob": 4.637467100110371e-06}, {"id": 99, "seek": 95000, "start": 960.0, "end": 973.0, "text": " Same idea. OK, so I guess we could even say show batch.", "tokens": [10635, 1558, 13, 2264, 11, 370, 286, 2041, 321, 727, 754, 584, 855, 15245, 13], "temperature": 0.0, "avg_logprob": -0.10234354911966527, "compression_ratio": 1.2252252252252251, "no_speech_prob": 4.637467100110371e-06}, {"id": 100, "seek": 95000, "start": 973.0, "end": 978.0, "text": " There we are.", "tokens": [821, 321, 366, 13], "temperature": 0.0, "avg_logprob": -0.10234354911966527, "compression_ratio": 1.2252252252252251, "no_speech_prob": 4.637467100110371e-06}, {"id": 101, "seek": 97800, "start": 978.0, "end": 984.0, "text": " OK, so questions. Maybe do image resizer as preprocessing.", "tokens": [2264, 11, 370, 1651, 13, 2704, 360, 3256, 725, 6545, 382, 2666, 340, 780, 278, 13], "temperature": 0.0, "avg_logprob": -0.16334842681884765, "compression_ratio": 1.4603174603174602, "no_speech_prob": 1.06156130641466e-05}, {"id": 102, "seek": 97800, "start": 984.0, "end": 992.0, "text": " So generally you don't. Well, let's try and give you a complete answer to that, Harami.", "tokens": [407, 5101, 291, 500, 380, 13, 1042, 11, 718, 311, 853, 293, 976, 291, 257, 3566, 1867, 281, 300, 11, 3653, 4526, 13], "temperature": 0.0, "avg_logprob": -0.16334842681884765, "compression_ratio": 1.4603174603174602, "no_speech_prob": 1.06156130641466e-05}, {"id": 103, "seek": 97800, "start": 992.0, "end": 1003.0, "text": " Generally speaking, in the fast data courses, we don't do it that way because normally part of the resizing is data augmentation.", "tokens": [21082, 4124, 11, 294, 264, 2370, 1412, 7712, 11, 321, 500, 380, 360, 309, 300, 636, 570, 5646, 644, 295, 264, 725, 3319, 307, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.16334842681884765, "compression_ratio": 1.4603174603174602, "no_speech_prob": 1.06156130641466e-05}, {"id": 104, "seek": 100300, "start": 1003.0, "end": 1008.0, "text": " So the default data augmentation for ImageNet, for example, is we kind of pick some.", "tokens": [407, 264, 7576, 1412, 14501, 19631, 337, 29903, 31890, 11, 337, 1365, 11, 307, 321, 733, 295, 1888, 512, 13], "temperature": 0.0, "avg_logprob": -0.06584785150927167, "compression_ratio": 1.7081081081081082, "no_speech_prob": 7.527243269578321e-06}, {"id": 105, "seek": 100300, "start": 1008.0, "end": 1016.0, "text": " We pick some random cropped sub area of the image and we kind of like zoom into that.", "tokens": [492, 1888, 512, 4974, 4848, 3320, 1422, 1859, 295, 264, 3256, 293, 321, 733, 295, 411, 8863, 666, 300, 13], "temperature": 0.0, "avg_logprob": -0.06584785150927167, "compression_ratio": 1.7081081081081082, "no_speech_prob": 7.527243269578321e-06}, {"id": 106, "seek": 100300, "start": 1016.0, "end": 1021.0, "text": " So that's like what we that's kind of what that's normally how we resize.", "tokens": [407, 300, 311, 411, 437, 321, 300, 311, 733, 295, 437, 300, 311, 5646, 577, 321, 50069, 13], "temperature": 0.0, "avg_logprob": -0.06584785150927167, "compression_ratio": 1.7081081081081082, "no_speech_prob": 7.527243269578321e-06}, {"id": 107, "seek": 100300, "start": 1021.0, "end": 1026.0, "text": " So for the training, the resizing is kind of cropping at the same time.", "tokens": [407, 337, 264, 3097, 11, 264, 725, 3319, 307, 733, 295, 4848, 3759, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.06584785150927167, "compression_ratio": 1.7081081081081082, "no_speech_prob": 7.527243269578321e-06}, {"id": 108, "seek": 102600, "start": 1026.0, "end": 1035.0, "text": " So that's why we don't generally resize as preprocessing.", "tokens": [407, 300, 311, 983, 321, 500, 380, 5101, 50069, 382, 2666, 340, 780, 278, 13], "temperature": 0.0, "avg_logprob": -0.08061337471008301, "compression_ratio": 1.5067567567567568, "no_speech_prob": 4.356493263912853e-06}, {"id": 109, "seek": 102600, "start": 1035.0, "end": 1047.0, "text": " Having said that, if your initial images are really, really big and you never want to use the full size of them, then you may want to do some preprocessing resizing.", "tokens": [10222, 848, 300, 11, 498, 428, 5883, 5267, 366, 534, 11, 534, 955, 293, 291, 1128, 528, 281, 764, 264, 1577, 2744, 295, 552, 11, 550, 291, 815, 528, 281, 360, 512, 2666, 340, 780, 278, 725, 3319, 13], "temperature": 0.0, "avg_logprob": -0.08061337471008301, "compression_ratio": 1.5067567567567568, "no_speech_prob": 4.356493263912853e-06}, {"id": 110, "seek": 104700, "start": 1047.0, "end": 1058.0, "text": " OK, so after batch and after item, I'm glad you asked. There's a thing I was going to look at in more detail now, which is to take a deeper dive into how transform data loader works.", "tokens": [2264, 11, 370, 934, 15245, 293, 934, 3174, 11, 286, 478, 5404, 291, 2351, 13, 821, 311, 257, 551, 286, 390, 516, 281, 574, 412, 294, 544, 2607, 586, 11, 597, 307, 281, 747, 257, 7731, 9192, 666, 577, 4088, 1412, 3677, 260, 1985, 13], "temperature": 0.0, "avg_logprob": -0.09167711456100662, "compression_ratio": 1.4673366834170853, "no_speech_prob": 1.147342481999658e-05}, {"id": 111, "seek": 104700, "start": 1058.0, "end": 1069.0, "text": " We've already kind of seen it a little bit, but we're probably in a good position to look at it more closely.", "tokens": [492, 600, 1217, 733, 295, 1612, 309, 257, 707, 857, 11, 457, 321, 434, 1391, 294, 257, 665, 2535, 281, 574, 412, 309, 544, 8185, 13], "temperature": 0.0, "avg_logprob": -0.09167711456100662, "compression_ratio": 1.4673366834170853, "no_speech_prob": 1.147342481999658e-05}, {"id": 112, "seek": 106900, "start": 1069.0, "end": 1077.0, "text": " And yeah, you can think of them as callbacks.", "tokens": [400, 1338, 11, 291, 393, 519, 295, 552, 382, 818, 17758, 13], "temperature": 0.0, "avg_logprob": -0.1248471708182829, "compression_ratio": 1.5069124423963134, "no_speech_prob": 7.071105756040197e-06}, {"id": 113, "seek": 106900, "start": 1077.0, "end": 1087.0, "text": " Looking at O1C data loader is actually a fun place to study because it's a super interesting notebook.", "tokens": [11053, 412, 422, 16, 34, 1412, 3677, 260, 307, 767, 257, 1019, 1081, 281, 2979, 570, 309, 311, 257, 1687, 1880, 21060, 13], "temperature": 0.0, "avg_logprob": -0.1248471708182829, "compression_ratio": 1.5069124423963134, "no_speech_prob": 7.071105756040197e-06}, {"id": 114, "seek": 106900, "start": 1087.0, "end": 1098.0, "text": " It's got this really annoying fake loader thing, which you shouldn't worry about too much because it's just working around some problems with the design of PyTorch's data loader.", "tokens": [467, 311, 658, 341, 534, 11304, 7592, 3677, 260, 551, 11, 597, 291, 4659, 380, 3292, 466, 886, 709, 570, 309, 311, 445, 1364, 926, 512, 2740, 365, 264, 1715, 295, 9953, 51, 284, 339, 311, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.1248471708182829, "compression_ratio": 1.5069124423963134, "no_speech_prob": 7.071105756040197e-06}, {"id": 115, "seek": 109800, "start": 1098.0, "end": 1106.0, "text": " But once you get past that, to get to the data loader itself, we're doing a lot of stuff in a very nice way.", "tokens": [583, 1564, 291, 483, 1791, 300, 11, 281, 483, 281, 264, 1412, 3677, 260, 2564, 11, 321, 434, 884, 257, 688, 295, 1507, 294, 257, 588, 1481, 636, 13], "temperature": 0.0, "avg_logprob": -0.0671081738929226, "compression_ratio": 1.6257668711656441, "no_speech_prob": 7.183029538282426e-06}, {"id": 116, "seek": 109800, "start": 1106.0, "end": 1115.0, "text": " So basically what happens is, let's see what happens when we iterate.", "tokens": [407, 1936, 437, 2314, 307, 11, 718, 311, 536, 437, 2314, 562, 321, 44497, 13], "temperature": 0.0, "avg_logprob": -0.0671081738929226, "compression_ratio": 1.6257668711656441, "no_speech_prob": 7.183029538282426e-06}, {"id": 117, "seek": 109800, "start": 1115.0, "end": 1121.0, "text": " So what's going to happen when we iterate is it's going to create some kind of loader.", "tokens": [407, 437, 311, 516, 281, 1051, 562, 321, 44497, 307, 309, 311, 516, 281, 1884, 512, 733, 295, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.0671081738929226, "compression_ratio": 1.6257668711656441, "no_speech_prob": 7.183029538282426e-06}, {"id": 118, "seek": 112100, "start": 1121.0, "end": 1130.0, "text": " And so underscore loaders specifically is a list of the multiprocessing data loader and the single process data loader from PyTorch.", "tokens": [400, 370, 37556, 3677, 433, 4682, 307, 257, 1329, 295, 264, 3311, 340, 780, 278, 1412, 3677, 260, 293, 264, 2167, 1399, 1412, 3677, 260, 490, 9953, 51, 284, 339, 13], "temperature": 0.0, "avg_logprob": -0.05567557298684422, "compression_ratio": 1.9072847682119205, "no_speech_prob": 2.857273557310691e-06}, {"id": 119, "seek": 112100, "start": 1130.0, "end": 1133.0, "text": " So we'll generally be using the multiprocessing data loader.", "tokens": [407, 321, 603, 5101, 312, 1228, 264, 3311, 340, 780, 278, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.05567557298684422, "compression_ratio": 1.9072847682119205, "no_speech_prob": 2.857273557310691e-06}, {"id": 120, "seek": 112100, "start": 1133.0, "end": 1143.0, "text": " So it's going to grab a multiprocessing data loader and it's going to yield a batch from that.", "tokens": [407, 309, 311, 516, 281, 4444, 257, 3311, 340, 780, 278, 1412, 3677, 260, 293, 309, 311, 516, 281, 11257, 257, 15245, 490, 300, 13], "temperature": 0.0, "avg_logprob": -0.05567557298684422, "compression_ratio": 1.9072847682119205, "no_speech_prob": 2.857273557310691e-06}, {"id": 121, "seek": 114300, "start": 1143.0, "end": 1159.0, "text": " And what that does actually is when it iterates, it actually calls sampler on our data loader class to grab a sample of IDs and then batches to create batches from those IDs.", "tokens": [400, 437, 300, 775, 767, 307, 562, 309, 17138, 1024, 11, 309, 767, 5498, 3247, 22732, 322, 527, 1412, 3677, 260, 1508, 281, 4444, 257, 6889, 295, 48212, 293, 550, 15245, 279, 281, 1884, 15245, 279, 490, 729, 48212, 13], "temperature": 0.0, "avg_logprob": -0.07038609605086477, "compression_ratio": 1.7454545454545454, "no_speech_prob": 7.112379307727679e-07}, {"id": 122, "seek": 114300, "start": 1159.0, "end": 1162.0, "text": " So the key thing to look at is create batches.", "tokens": [407, 264, 2141, 551, 281, 574, 412, 307, 1884, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.07038609605086477, "compression_ratio": 1.7454545454545454, "no_speech_prob": 7.112379307727679e-07}, {"id": 123, "seek": 114300, "start": 1162.0, "end": 1166.0, "text": " This is actually what the data loader is using, is create batches.", "tokens": [639, 307, 767, 437, 264, 1412, 3677, 260, 307, 1228, 11, 307, 1884, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.07038609605086477, "compression_ratio": 1.7454545454545454, "no_speech_prob": 7.112379307727679e-07}, {"id": 124, "seek": 116600, "start": 1166.0, "end": 1173.0, "text": " So create batches, most of the time there's going to be a data set that we're creating a data loader over.", "tokens": [407, 1884, 15245, 279, 11, 881, 295, 264, 565, 456, 311, 516, 281, 312, 257, 1412, 992, 300, 321, 434, 4084, 257, 1412, 3677, 260, 670, 13], "temperature": 0.0, "avg_logprob": -0.06745697151530873, "compression_ratio": 1.7318435754189945, "no_speech_prob": 5.043453938924358e-07}, {"id": 125, "seek": 116600, "start": 1173.0, "end": 1180.0, "text": " So we create an iterator over the data set and we pop that into self.it.", "tokens": [407, 321, 1884, 364, 17138, 1639, 670, 264, 1412, 992, 293, 321, 1665, 300, 666, 2698, 13, 270, 13], "temperature": 0.0, "avg_logprob": -0.06745697151530873, "compression_ratio": 1.7318435754189945, "no_speech_prob": 5.043453938924358e-07}, {"id": 126, "seek": 116600, "start": 1180.0, "end": 1186.0, "text": " And then we grab each of the indexes that we are interested in.", "tokens": [400, 550, 321, 4444, 1184, 295, 264, 8186, 279, 300, 321, 366, 3102, 294, 13], "temperature": 0.0, "avg_logprob": -0.06745697151530873, "compression_ratio": 1.7318435754189945, "no_speech_prob": 5.043453938924358e-07}, {"id": 127, "seek": 116600, "start": 1186.0, "end": 1192.0, "text": " So this is the indexes of our sample and we map do item over that.", "tokens": [407, 341, 307, 264, 8186, 279, 295, 527, 6889, 293, 321, 4471, 360, 3174, 670, 300, 13], "temperature": 0.0, "avg_logprob": -0.06745697151530873, "compression_ratio": 1.7318435754189945, "no_speech_prob": 5.043453938924358e-07}, {"id": 128, "seek": 119200, "start": 1192.0, "end": 1198.0, "text": " Do item calls create item and then after item.", "tokens": [1144, 3174, 5498, 1884, 3174, 293, 550, 934, 3174, 13], "temperature": 0.0, "avg_logprob": -0.13244193150446965, "compression_ratio": 1.618421052631579, "no_speech_prob": 1.3287684623719542e-06}, {"id": 129, "seek": 119200, "start": 1198.0, "end": 1210.0, "text": " Create item, assuming that the sample is not none, simply grabs the appropriate indexed item from a data set.", "tokens": [20248, 3174, 11, 11926, 300, 264, 6889, 307, 406, 6022, 11, 2935, 30028, 264, 6854, 8186, 292, 3174, 490, 257, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.13244193150446965, "compression_ratio": 1.618421052631579, "no_speech_prob": 1.3287684623719542e-06}, {"id": 130, "seek": 119200, "start": 1210.0, "end": 1212.0, "text": " So that's all create item does.", "tokens": [407, 300, 311, 439, 1884, 3174, 775, 13], "temperature": 0.0, "avg_logprob": -0.13244193150446965, "compression_ratio": 1.618421052631579, "no_speech_prob": 1.3287684623719542e-06}, {"id": 131, "seek": 119200, "start": 1212.0, "end": 1220.0, "text": " And then after item, by default, after item equals no op.", "tokens": [400, 550, 934, 3174, 11, 538, 7576, 11, 934, 3174, 6915, 572, 999, 13], "temperature": 0.0, "avg_logprob": -0.13244193150446965, "compression_ratio": 1.618421052631579, "no_speech_prob": 1.3287684623719542e-06}, {"id": 132, "seek": 122000, "start": 1220.0, "end": 1222.0, "text": " It does nothing at all.", "tokens": [467, 775, 1825, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.1320000931068703, "compression_ratio": 1.426356589147287, "no_speech_prob": 1.9832441466860473e-05}, {"id": 133, "seek": 122000, "start": 1222.0, "end": 1233.0, "text": " But we have this funcs quags thing, which is a thing where it looks for methods.", "tokens": [583, 321, 362, 341, 1019, 14368, 421, 12109, 551, 11, 597, 307, 257, 551, 689, 309, 1542, 337, 7150, 13], "temperature": 0.0, "avg_logprob": -0.1320000931068703, "compression_ratio": 1.426356589147287, "no_speech_prob": 1.9832441466860473e-05}, {"id": 134, "seek": 122000, "start": 1233.0, "end": 1248.0, "text": " And you'll see that after item is one of the things listed here in funcs quags.", "tokens": [400, 291, 603, 536, 300, 934, 3174, 307, 472, 295, 264, 721, 10052, 510, 294, 1019, 14368, 421, 12109, 13], "temperature": 0.0, "avg_logprob": -0.1320000931068703, "compression_ratio": 1.426356589147287, "no_speech_prob": 1.9832441466860473e-05}, {"id": 135, "seek": 124800, "start": 1248.0, "end": 1255.0, "text": " And what that means is that when we pass in quags, it's going to see if you've passed in something called after item.", "tokens": [400, 437, 300, 1355, 307, 300, 562, 321, 1320, 294, 421, 12109, 11, 309, 311, 516, 281, 536, 498, 291, 600, 4678, 294, 746, 1219, 934, 3174, 13], "temperature": 0.0, "avg_logprob": -0.07356567680835724, "compression_ratio": 1.8223350253807107, "no_speech_prob": 9.368473001813982e-06}, {"id": 136, "seek": 124800, "start": 1255.0, "end": 1260.0, "text": " And it's going to replace our after item method with the thing you passed in.", "tokens": [400, 309, 311, 516, 281, 7406, 527, 934, 3174, 3170, 365, 264, 551, 291, 4678, 294, 13], "temperature": 0.0, "avg_logprob": -0.07356567680835724, "compression_ratio": 1.8223350253807107, "no_speech_prob": 9.368473001813982e-06}, {"id": 137, "seek": 124800, "start": 1260.0, "end": 1271.0, "text": " So in other words, we can pass in after item and it will then be called, the thing we passed in will be called at this point.", "tokens": [407, 294, 661, 2283, 11, 321, 393, 1320, 294, 934, 3174, 293, 309, 486, 550, 312, 1219, 11, 264, 551, 321, 4678, 294, 486, 312, 1219, 412, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.07356567680835724, "compression_ratio": 1.8223350253807107, "no_speech_prob": 9.368473001813982e-06}, {"id": 138, "seek": 124800, "start": 1271.0, "end": 1274.0, "text": " So, yeah, it is basically a callback.", "tokens": [407, 11, 1338, 11, 309, 307, 1936, 257, 818, 3207, 13], "temperature": 0.0, "avg_logprob": -0.07356567680835724, "compression_ratio": 1.8223350253807107, "no_speech_prob": 9.368473001813982e-06}, {"id": 139, "seek": 127400, "start": 1274.0, "end": 1282.0, "text": " But actually, notice that all of these things, all these things that are listed are all replaceable.", "tokens": [583, 767, 11, 3449, 300, 439, 295, 613, 721, 11, 439, 613, 721, 300, 366, 10052, 366, 439, 7406, 712, 13], "temperature": 0.0, "avg_logprob": -0.07335900223773459, "compression_ratio": 1.7510373443983402, "no_speech_prob": 4.495135726756416e-06}, {"id": 140, "seek": 127400, "start": 1282.0, "end": 1291.0, "text": " So it's kind of like a bit more powerful than normal callbacks because you can easily replace anything inside the data loader with whatever you like.", "tokens": [407, 309, 311, 733, 295, 411, 257, 857, 544, 4005, 813, 2710, 818, 17758, 570, 291, 393, 3612, 7406, 1340, 1854, 264, 1412, 3677, 260, 365, 2035, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.07335900223773459, "compression_ratio": 1.7510373443983402, "no_speech_prob": 4.495135726756416e-06}, {"id": 141, "seek": 127400, "start": 1291.0, "end": 1302.0, "text": " But these things with after or before in their name, the things which actually default to no op, are very easy to replace because there's no functionality currently there.", "tokens": [583, 613, 721, 365, 934, 420, 949, 294, 641, 1315, 11, 264, 721, 597, 767, 7576, 281, 572, 999, 11, 366, 588, 1858, 281, 7406, 570, 456, 311, 572, 14980, 4362, 456, 13], "temperature": 0.0, "avg_logprob": -0.07335900223773459, "compression_ratio": 1.7510373443983402, "no_speech_prob": 4.495135726756416e-06}, {"id": 142, "seek": 130200, "start": 1302.0, "end": 1305.0, "text": " So it doesn't matter. Like you can do anything you like.", "tokens": [407, 309, 1177, 380, 1871, 13, 1743, 291, 393, 360, 1340, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.07610674638014574, "compression_ratio": 1.5030674846625767, "no_speech_prob": 2.5215133518941e-06}, {"id": 143, "seek": 130200, "start": 1305.0, "end": 1315.0, "text": " So after item, then, is the thing that is going to get called immediately after we grab one thing from the data set.", "tokens": [407, 934, 3174, 11, 550, 11, 307, 264, 551, 300, 307, 516, 281, 483, 1219, 4258, 934, 321, 4444, 472, 551, 490, 264, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.07610674638014574, "compression_ratio": 1.5030674846625767, "no_speech_prob": 2.5215133518941e-06}, {"id": 144, "seek": 130200, "start": 1315.0, "end": 1324.0, "text": " And so that's what happens here. So we map that over each sample index.", "tokens": [400, 370, 300, 311, 437, 2314, 510, 13, 407, 321, 4471, 300, 670, 1184, 6889, 8186, 13], "temperature": 0.0, "avg_logprob": -0.07610674638014574, "compression_ratio": 1.5030674846625767, "no_speech_prob": 2.5215133518941e-06}, {"id": 145, "seek": 132400, "start": 1324.0, "end": 1336.0, "text": " And then assuming that you have so that if you if you haven't got a batch size set, so batch size is none, then we're done.", "tokens": [400, 550, 11926, 300, 291, 362, 370, 300, 498, 291, 498, 291, 2378, 380, 658, 257, 15245, 2744, 992, 11, 370, 15245, 2744, 307, 6022, 11, 550, 321, 434, 1096, 13], "temperature": 0.0, "avg_logprob": -0.11515411577726666, "compression_ratio": 1.7552083333333333, "no_speech_prob": 1.5779244222358102e-06}, {"id": 146, "seek": 132400, "start": 1336.0, "end": 1343.0, "text": " There's nothing to do. You haven't asked for batches. But if you have asked for batches, which you normally have, then we're going to map.", "tokens": [821, 311, 1825, 281, 360, 13, 509, 2378, 380, 2351, 337, 15245, 279, 13, 583, 498, 291, 362, 2351, 337, 15245, 279, 11, 597, 291, 5646, 362, 11, 550, 321, 434, 516, 281, 4471, 13], "temperature": 0.0, "avg_logprob": -0.11515411577726666, "compression_ratio": 1.7552083333333333, "no_speech_prob": 1.5779244222358102e-06}, {"id": 147, "seek": 132400, "start": 1343.0, "end": 1348.0, "text": " Do batch over the result we just got.", "tokens": [1144, 15245, 670, 264, 1874, 321, 445, 658, 13], "temperature": 0.0, "avg_logprob": -0.11515411577726666, "compression_ratio": 1.7552083333333333, "no_speech_prob": 1.5779244222358102e-06}, {"id": 148, "seek": 132400, "start": 1348.0, "end": 1351.0, "text": " And first, we chunk it into batches.", "tokens": [400, 700, 11, 321, 16635, 309, 666, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.11515411577726666, "compression_ratio": 1.7552083333333333, "no_speech_prob": 1.5779244222358102e-06}, {"id": 149, "seek": 135100, "start": 1351.0, "end": 1359.0, "text": " And one of the nice things about this code is the whole thing's done using kind of generators and maps and lazy.", "tokens": [400, 472, 295, 264, 1481, 721, 466, 341, 3089, 307, 264, 1379, 551, 311, 1096, 1228, 733, 295, 38662, 293, 11317, 293, 14847, 13], "temperature": 0.0, "avg_logprob": -0.07557797961764866, "compression_ratio": 1.6775700934579438, "no_speech_prob": 9.276320156459406e-07}, {"id": 150, "seek": 135100, "start": 1359.0, "end": 1364.0, "text": " So it's a nice example of code to learn how to do that in Python.", "tokens": [407, 309, 311, 257, 1481, 1365, 295, 3089, 281, 1466, 577, 281, 360, 300, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.07557797961764866, "compression_ratio": 1.6775700934579438, "no_speech_prob": 9.276320156459406e-07}, {"id": 151, "seek": 135100, "start": 1364.0, "end": 1372.0, "text": " Anyway, so do batch is going to call before batch and then create batch and then retain.", "tokens": [5684, 11, 370, 360, 15245, 307, 516, 281, 818, 949, 15245, 293, 550, 1884, 15245, 293, 550, 18340, 13], "temperature": 0.0, "avg_logprob": -0.07557797961764866, "compression_ratio": 1.6775700934579438, "no_speech_prob": 9.276320156459406e-07}, {"id": 152, "seek": 135100, "start": 1372.0, "end": 1379.0, "text": " This is just the thing that keeps the same type. And then finally, eventually, after batch.", "tokens": [639, 307, 445, 264, 551, 300, 5965, 264, 912, 2010, 13, 400, 550, 2721, 11, 4728, 11, 934, 15245, 13], "temperature": 0.0, "avg_logprob": -0.07557797961764866, "compression_ratio": 1.6775700934579438, "no_speech_prob": 9.276320156459406e-07}, {"id": 153, "seek": 137900, "start": 1379.0, "end": 1387.0, "text": " So, again, before batch by default does nothing at all. After batch by default does nothing at all.", "tokens": [407, 11, 797, 11, 949, 15245, 538, 7576, 775, 1825, 412, 439, 13, 2381, 15245, 538, 7576, 775, 1825, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.12359941005706787, "compression_ratio": 1.6917293233082706, "no_speech_prob": 2.7264386517344974e-06}, {"id": 154, "seek": 137900, "start": 1387.0, "end": 1392.0, "text": " And create batch by default simply calls collate.", "tokens": [400, 1884, 15245, 538, 7576, 2935, 5498, 1263, 473, 13], "temperature": 0.0, "avg_logprob": -0.12359941005706787, "compression_ratio": 1.6917293233082706, "no_speech_prob": 2.7264386517344974e-06}, {"id": 155, "seek": 137900, "start": 1392.0, "end": 1401.0, "text": " So that's the thing that just concatenates everything into a single tensor.", "tokens": [407, 300, 311, 264, 551, 300, 445, 1588, 7186, 1024, 1203, 666, 257, 2167, 40863, 13], "temperature": 0.0, "avg_logprob": -0.12359941005706787, "compression_ratio": 1.6917293233082706, "no_speech_prob": 2.7264386517344974e-06}, {"id": 156, "seek": 140100, "start": 1401.0, "end": 1421.0, "text": " OK, so it's amazing how little code there is here and how little it does that we end up with something that's like super extensible because we can hook into any of these points to change or add behavior.", "tokens": [2264, 11, 370, 309, 311, 2243, 577, 707, 3089, 456, 307, 510, 293, 577, 707, 309, 775, 300, 321, 917, 493, 365, 746, 300, 311, 411, 1687, 1279, 30633, 570, 321, 393, 6328, 666, 604, 295, 613, 2793, 281, 1319, 420, 909, 5223, 13], "temperature": 0.0, "avg_logprob": -0.13311312596003214, "compression_ratio": 1.4195804195804196, "no_speech_prob": 2.521537908251048e-06}, {"id": 157, "seek": 142100, "start": 1421.0, "end": 1432.0, "text": " One of the things we're talking about is that we it's possible we might change the names of these things like after item and before batch and stuff.", "tokens": [1485, 295, 264, 721, 321, 434, 1417, 466, 307, 300, 321, 309, 311, 1944, 321, 1062, 1319, 264, 5288, 295, 613, 721, 411, 934, 3174, 293, 949, 15245, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.12387204506027867, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.933305838974775e-06}, {"id": 158, "seek": 142100, "start": 1432.0, "end": 1439.0, "text": " They're they're technically accurate.", "tokens": [814, 434, 436, 434, 12120, 8559, 13], "temperature": 0.0, "avg_logprob": -0.12387204506027867, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.933305838974775e-06}, {"id": 159, "seek": 142100, "start": 1439.0, "end": 1445.0, "text": " You know, they're kind of like once you understand how the data loader works.", "tokens": [509, 458, 11, 436, 434, 733, 295, 411, 1564, 291, 1223, 577, 264, 1412, 3677, 260, 1985, 13], "temperature": 0.0, "avg_logprob": -0.12387204506027867, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.933305838974775e-06}, {"id": 160, "seek": 142100, "start": 1445.0, "end": 1448.0, "text": " They make perfect sense.", "tokens": [814, 652, 2176, 2020, 13], "temperature": 0.0, "avg_logprob": -0.12387204506027867, "compression_ratio": 1.553763440860215, "no_speech_prob": 1.933305838974775e-06}, {"id": 161, "seek": 144800, "start": 1448.0, "end": 1457.0, "text": " But we may change them to be names, which makes sense even if you don't know how the data loader works.", "tokens": [583, 321, 815, 1319, 552, 281, 312, 5288, 11, 597, 1669, 2020, 754, 498, 291, 500, 380, 458, 577, 264, 1412, 3677, 260, 1985, 13], "temperature": 0.0, "avg_logprob": -0.18740164149891247, "compression_ratio": 1.3459119496855345, "no_speech_prob": 4.494997938309098e-06}, {"id": 162, "seek": 144800, "start": 1457.0, "end": 1462.0, "text": " So anyway, so that's something we're thinking about.", "tokens": [407, 4033, 11, 370, 300, 311, 746, 321, 434, 1953, 466, 13], "temperature": 0.0, "avg_logprob": -0.18740164149891247, "compression_ratio": 1.3459119496855345, "no_speech_prob": 4.494997938309098e-06}, {"id": 163, "seek": 144800, "start": 1462.0, "end": 1466.0, "text": " So then to firm DL,", "tokens": [407, 550, 281, 6174, 413, 43, 11], "temperature": 0.0, "avg_logprob": -0.18740164149891247, "compression_ratio": 1.3459119496855345, "no_speech_prob": 4.494997938309098e-06}, {"id": 164, "seek": 144800, "start": 1466.0, "end": 1477.0, "text": " which is in 05. Now I think about it.", "tokens": [597, 307, 294, 1958, 20, 13, 823, 286, 519, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.18740164149891247, "compression_ratio": 1.3459119496855345, "no_speech_prob": 4.494997938309098e-06}, {"id": 165, "seek": 147700, "start": 1477.0, "end": 1481.0, "text": " It is a pretty thin", "tokens": [467, 307, 257, 1238, 5862], "temperature": 0.0, "avg_logprob": -0.1561703152126736, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.3404294299543835e-06}, {"id": 166, "seek": 147700, "start": 1481.0, "end": 1484.0, "text": " subclass of data loader.", "tokens": [1422, 11665, 295, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.1561703152126736, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.3404294299543835e-06}, {"id": 167, "seek": 147700, "start": 1484.0, "end": 1490.0, "text": " And as the name suggests, so here it is.", "tokens": [400, 382, 264, 1315, 13409, 11, 370, 510, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.1561703152126736, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.3404294299543835e-06}, {"id": 168, "seek": 147700, "start": 1490.0, "end": 1493.0, "text": " As the name suggests, it is a data loader.", "tokens": [1018, 264, 1315, 13409, 11, 309, 307, 257, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.1561703152126736, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.3404294299543835e-06}, {"id": 169, "seek": 147700, "start": 1493.0, "end": 1500.0, "text": " But the key thing we do is that for each of these three callbacks,", "tokens": [583, 264, 2141, 551, 321, 360, 307, 300, 337, 1184, 295, 613, 1045, 818, 17758, 11], "temperature": 0.0, "avg_logprob": -0.1561703152126736, "compression_ratio": 1.5354330708661417, "no_speech_prob": 3.3404294299543835e-06}, {"id": 170, "seek": 150000, "start": 1500.0, "end": 1507.0, "text": " we look through those and we replace them with pipelines, transform pipelines.", "tokens": [321, 574, 807, 729, 293, 321, 7406, 552, 365, 40168, 11, 4088, 40168, 13], "temperature": 0.0, "avg_logprob": -0.15748212851730048, "compression_ratio": 1.5263157894736843, "no_speech_prob": 2.0580134787451243e-06}, {"id": 171, "seek": 150000, "start": 1507.0, "end": 1517.0, "text": " So that means that a different data loader also has decode, decode batch and show batch.", "tokens": [407, 300, 1355, 300, 257, 819, 1412, 3677, 260, 611, 575, 979, 1429, 11, 979, 1429, 15245, 293, 855, 15245, 13], "temperature": 0.0, "avg_logprob": -0.15748212851730048, "compression_ratio": 1.5263157894736843, "no_speech_prob": 2.0580134787451243e-06}, {"id": 172, "seek": 150000, "start": 1517.0, "end": 1526.0, "text": " So that's the key difference there.", "tokens": [407, 300, 311, 264, 2141, 2649, 456, 13], "temperature": 0.0, "avg_logprob": -0.15748212851730048, "compression_ratio": 1.5263157894736843, "no_speech_prob": 2.0580134787451243e-06}, {"id": 173, "seek": 152600, "start": 1526.0, "end": 1536.0, "text": " OK, the other thing it needs to know how to do is that if you when you call decode,", "tokens": [2264, 11, 264, 661, 551, 309, 2203, 281, 458, 577, 281, 360, 307, 300, 498, 291, 562, 291, 818, 979, 1429, 11], "temperature": 0.0, "avg_logprob": -0.09476545058101056, "compression_ratio": 1.5958549222797926, "no_speech_prob": 2.2602880562772043e-06}, {"id": 174, "seek": 152600, "start": 1536.0, "end": 1540.0, "text": " you're going to be passing in just a plain pie torch tensor.", "tokens": [291, 434, 516, 281, 312, 8437, 294, 445, 257, 11121, 1730, 27822, 40863, 13], "temperature": 0.0, "avg_logprob": -0.09476545058101056, "compression_ratio": 1.5958549222797926, "no_speech_prob": 2.2602880562772043e-06}, {"id": 175, "seek": 152600, "start": 1540.0, "end": 1545.0, "text": " Probably it's not going to have any type like a tensor image or tensor bounding box or whatever.", "tokens": [9210, 309, 311, 406, 516, 281, 362, 604, 2010, 411, 257, 40863, 3256, 420, 40863, 5472, 278, 2424, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.09476545058101056, "compression_ratio": 1.5958549222797926, "no_speech_prob": 2.2602880562772043e-06}, {"id": 176, "seek": 152600, "start": 1545.0, "end": 1552.0, "text": " So the data loader has to know what data types to convert it into.", "tokens": [407, 264, 1412, 3677, 260, 575, 281, 458, 437, 1412, 3467, 281, 7620, 309, 666, 13], "temperature": 0.0, "avg_logprob": -0.09476545058101056, "compression_ratio": 1.5958549222797926, "no_speech_prob": 2.2602880562772043e-06}, {"id": 177, "seek": 155200, "start": 1552.0, "end": 1559.0, "text": " And what it actually does is it has this method called retain DL,", "tokens": [400, 437, 309, 767, 775, 307, 309, 575, 341, 3170, 1219, 18340, 413, 43, 11], "temperature": 0.0, "avg_logprob": -0.07732974052429199, "compression_ratio": 1.4180327868852458, "no_speech_prob": 7.296100193343591e-06}, {"id": 178, "seek": 155200, "start": 1559.0, "end": 1564.0, "text": " which is the first thing that it does here.", "tokens": [597, 307, 264, 700, 551, 300, 309, 775, 510, 13], "temperature": 0.0, "avg_logprob": -0.07732974052429199, "compression_ratio": 1.4180327868852458, "no_speech_prob": 7.296100193343591e-06}, {"id": 179, "seek": 155200, "start": 1564.0, "end": 1568.0, "text": " And that's the method that adds the types that it needs.", "tokens": [400, 300, 311, 264, 3170, 300, 10860, 264, 3467, 300, 309, 2203, 13], "temperature": 0.0, "avg_logprob": -0.07732974052429199, "compression_ratio": 1.4180327868852458, "no_speech_prob": 7.296100193343591e-06}, {"id": 180, "seek": 155200, "start": 1568.0, "end": 1575.0, "text": " So the", "tokens": [407, 264], "temperature": 0.0, "avg_logprob": -0.07732974052429199, "compression_ratio": 1.4180327868852458, "no_speech_prob": 7.296100193343591e-06}, {"id": 181, "seek": 157500, "start": 1575.0, "end": 1582.0, "text": " what we do is we basically just run one mini batch, a small mini batch,", "tokens": [437, 321, 360, 307, 321, 1936, 445, 1190, 472, 8382, 15245, 11, 257, 1359, 8382, 15245, 11], "temperature": 0.0, "avg_logprob": -0.0925108015537262, "compression_ratio": 1.576086956521739, "no_speech_prob": 1.3630696230393369e-05}, {"id": 182, "seek": 157500, "start": 1582.0, "end": 1585.0, "text": " to find out what types it creates.", "tokens": [281, 915, 484, 437, 3467, 309, 7829, 13], "temperature": 0.0, "avg_logprob": -0.0925108015537262, "compression_ratio": 1.576086956521739, "no_speech_prob": 1.3630696230393369e-05}, {"id": 183, "seek": 157500, "start": 1585.0, "end": 1591.0, "text": " And we save those types.", "tokens": [400, 321, 3155, 729, 3467, 13], "temperature": 0.0, "avg_logprob": -0.0925108015537262, "compression_ratio": 1.576086956521739, "no_speech_prob": 1.3630696230393369e-05}, {"id": 184, "seek": 157500, "start": 1591.0, "end": 1594.0, "text": " And this this little bit of code is actually super cute.", "tokens": [400, 341, 341, 707, 857, 295, 3089, 307, 767, 1687, 4052, 13], "temperature": 0.0, "avg_logprob": -0.0925108015537262, "compression_ratio": 1.576086956521739, "no_speech_prob": 1.3630696230393369e-05}, {"id": 185, "seek": 157500, "start": 1594.0, "end": 1598.0, "text": " If you want to look at some cute code, check this out and see if you can figure out how it's working,", "tokens": [759, 291, 528, 281, 574, 412, 512, 4052, 3089, 11, 1520, 341, 484, 293, 536, 498, 291, 393, 2573, 484, 577, 309, 311, 1364, 11], "temperature": 0.0, "avg_logprob": -0.0925108015537262, "compression_ratio": 1.576086956521739, "no_speech_prob": 1.3630696230393369e-05}, {"id": 186, "seek": 159800, "start": 1598.0, "end": 1605.0, "text": " because it's I think it's very nice.", "tokens": [570, 309, 311, 286, 519, 309, 311, 588, 1481, 13], "temperature": 0.0, "avg_logprob": -0.11229969107586404, "compression_ratio": 1.037037037037037, "no_speech_prob": 2.0143996152910404e-05}, {"id": 187, "seek": 159800, "start": 1605.0, "end": 1621.0, "text": " OK, so that's that.", "tokens": [2264, 11, 370, 300, 311, 300, 13], "temperature": 0.0, "avg_logprob": -0.11229969107586404, "compression_ratio": 1.037037037037037, "no_speech_prob": 2.0143996152910404e-05}, {"id": 188, "seek": 162100, "start": 1621.0, "end": 1631.0, "text": " So now you can see why we have these data set image transforms and these data loader transforms and what they go here.", "tokens": [407, 586, 291, 393, 536, 983, 321, 362, 613, 1412, 992, 3256, 35592, 293, 613, 1412, 3677, 260, 35592, 293, 437, 436, 352, 510, 13], "temperature": 0.0, "avg_logprob": -0.11318950888551312, "compression_ratio": 1.8514285714285714, "no_speech_prob": 1.172626411971578e-06}, {"id": 189, "seek": 162100, "start": 1631.0, "end": 1638.0, "text": " So these data set image transforms, image resizer, that's something that operates on.", "tokens": [407, 613, 1412, 992, 3256, 35592, 11, 3256, 725, 6545, 11, 300, 311, 746, 300, 22577, 322, 13], "temperature": 0.0, "avg_logprob": -0.11318950888551312, "compression_ratio": 1.8514285714285714, "no_speech_prob": 1.172626411971578e-06}, {"id": 190, "seek": 162100, "start": 1638.0, "end": 1641.0, "text": " Let's go back and have a look at it because we created it just up here.", "tokens": [961, 311, 352, 646, 293, 362, 257, 574, 412, 309, 570, 321, 2942, 309, 445, 493, 510, 13], "temperature": 0.0, "avg_logprob": -0.11318950888551312, "compression_ratio": 1.8514285714285714, "no_speech_prob": 1.172626411971578e-06}, {"id": 191, "seek": 162100, "start": 1641.0, "end": 1646.0, "text": " It's something that operates on a pillow image.", "tokens": [467, 311, 746, 300, 22577, 322, 257, 18581, 3256, 13], "temperature": 0.0, "avg_logprob": -0.11318950888551312, "compression_ratio": 1.8514285714285714, "no_speech_prob": 1.172626411971578e-06}, {"id": 192, "seek": 164600, "start": 1646.0, "end": 1653.0, "text": " Right. So that has to be run before it's been collated into a mini batch.", "tokens": [1779, 13, 407, 300, 575, 281, 312, 1190, 949, 309, 311, 668, 1263, 770, 666, 257, 8382, 15245, 13], "temperature": 0.0, "avg_logprob": -0.1359536391038161, "compression_ratio": 1.7593984962406015, "no_speech_prob": 2.1233345250948332e-06}, {"id": 193, "seek": 164600, "start": 1653.0, "end": 1660.0, "text": " But after it's been grabbed from the data set.", "tokens": [583, 934, 309, 311, 668, 18607, 490, 264, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.1359536391038161, "compression_ratio": 1.7593984962406015, "no_speech_prob": 2.1233345250948332e-06}, {"id": 194, "seek": 164600, "start": 1660.0, "end": 1672.0, "text": " So that's why it's that is in the after item transforms because it's before it's been collated into a mini batch.", "tokens": [407, 300, 311, 983, 309, 311, 300, 307, 294, 264, 934, 3174, 35592, 570, 309, 311, 949, 309, 311, 668, 1263, 770, 666, 257, 8382, 15245, 13], "temperature": 0.0, "avg_logprob": -0.1359536391038161, "compression_ratio": 1.7593984962406015, "no_speech_prob": 2.1233345250948332e-06}, {"id": 195, "seek": 167200, "start": 1672.0, "end": 1679.0, "text": " On the other hand, CUDA and byte to float tensor are going to run much faster if it's run in a whole mini batch at a time.", "tokens": [1282, 264, 661, 1011, 11, 29777, 7509, 293, 40846, 281, 15706, 40863, 366, 516, 281, 1190, 709, 4663, 498, 309, 311, 1190, 294, 257, 1379, 8382, 15245, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.10753361628605769, "compression_ratio": 1.45, "no_speech_prob": 7.4536507099765e-07}, {"id": 196, "seek": 167200, "start": 1679.0, "end": 1683.0, "text": " So after batch is the thing that happens after it's all been collated.", "tokens": [407, 934, 15245, 307, 264, 551, 300, 2314, 934, 309, 311, 439, 668, 1263, 770, 13], "temperature": 0.0, "avg_logprob": -0.10753361628605769, "compression_ratio": 1.45, "no_speech_prob": 7.4536507099765e-07}, {"id": 197, "seek": 167200, "start": 1683.0, "end": 1690.0, "text": " And so that's why those ones are here.", "tokens": [400, 370, 300, 311, 983, 729, 2306, 366, 510, 13], "temperature": 0.0, "avg_logprob": -0.10753361628605769, "compression_ratio": 1.45, "no_speech_prob": 7.4536507099765e-07}, {"id": 198, "seek": 169000, "start": 1690.0, "end": 1704.0, "text": " OK, so. Let's now look at data blocks.", "tokens": [50364, 2264, 11, 370, 13, 961, 311, 586, 574, 412, 1412, 8474, 13, 51064], "temperature": 0.0, "avg_logprob": -0.29332812627156574, "compression_ratio": 0.8260869565217391, "no_speech_prob": 6.396321987267584e-05}, {"id": 199, "seek": 172000, "start": 1720.0, "end": 1726.0, "text": " OK, so data blocks is down in 50.", "tokens": [2264, 11, 370, 1412, 8474, 307, 760, 294, 2625, 13], "temperature": 0.0, "avg_logprob": -0.14807393517292722, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00806040782481432}, {"id": 200, "seek": 172000, "start": 1726.0, "end": 1730.0, "text": " Because we.", "tokens": [1436, 321, 13], "temperature": 0.0, "avg_logprob": -0.14807393517292722, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00806040782481432}, {"id": 201, "seek": 172000, "start": 1730.0, "end": 1739.0, "text": " Because it has to use stuff from vision and text and so forth in order to create all those different types of data blocks.", "tokens": [1436, 309, 575, 281, 764, 1507, 490, 5201, 293, 2487, 293, 370, 5220, 294, 1668, 281, 1884, 439, 729, 819, 3467, 295, 1412, 8474, 13], "temperature": 0.0, "avg_logprob": -0.14807393517292722, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00806040782481432}, {"id": 202, "seek": 172000, "start": 1739.0, "end": 1744.0, "text": " And let's take a look at an example first.", "tokens": [400, 718, 311, 747, 257, 574, 412, 364, 1365, 700, 13], "temperature": 0.0, "avg_logprob": -0.14807393517292722, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00806040782481432}, {"id": 203, "seek": 172000, "start": 1744.0, "end": 1748.0, "text": " So here's an example of MNIST.", "tokens": [407, 510, 311, 364, 1365, 295, 376, 45, 19756, 13], "temperature": 0.0, "avg_logprob": -0.14807393517292722, "compression_ratio": 1.4404761904761905, "no_speech_prob": 0.00806040782481432}, {"id": 204, "seek": 174800, "start": 1748.0, "end": 1757.0, "text": " So if you remember what data blocks basically have to do, there has to be some way to say which files, for example, you're working with.", "tokens": [407, 498, 291, 1604, 437, 1412, 8474, 1936, 362, 281, 360, 11, 456, 575, 281, 312, 512, 636, 281, 584, 597, 7098, 11, 337, 1365, 11, 291, 434, 1364, 365, 13], "temperature": 0.0, "avg_logprob": -0.11637682457492776, "compression_ratio": 1.4943181818181819, "no_speech_prob": 3.041518993995851e-06}, {"id": 205, "seek": 174800, "start": 1757.0, "end": 1763.0, "text": " Some way to say how to split it from validation set and trading set.", "tokens": [2188, 636, 281, 584, 577, 281, 7472, 309, 490, 24071, 992, 293, 9529, 992, 13], "temperature": 0.0, "avg_logprob": -0.11637682457492776, "compression_ratio": 1.4943181818181819, "no_speech_prob": 3.041518993995851e-06}, {"id": 206, "seek": 174800, "start": 1763.0, "end": 1767.0, "text": " And some way to label.", "tokens": [400, 512, 636, 281, 7645, 13], "temperature": 0.0, "avg_logprob": -0.11637682457492776, "compression_ratio": 1.4943181818181819, "no_speech_prob": 3.041518993995851e-06}, {"id": 207, "seek": 174800, "start": 1767.0, "end": 1769.0, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.11637682457492776, "compression_ratio": 1.4943181818181819, "no_speech_prob": 3.041518993995851e-06}, {"id": 208, "seek": 174800, "start": 1769.0, "end": 1777.0, "text": " Here are each of those things.", "tokens": [1692, 366, 1184, 295, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.11637682457492776, "compression_ratio": 1.4943181818181819, "no_speech_prob": 3.041518993995851e-06}, {"id": 209, "seek": 177700, "start": 1777.0, "end": 1785.0, "text": " We kind of need something else, though, as well, which is we need to know.", "tokens": [492, 733, 295, 643, 746, 1646, 11, 1673, 11, 382, 731, 11, 597, 307, 321, 643, 281, 458, 13], "temperature": 0.0, "avg_logprob": -0.1112213134765625, "compression_ratio": 1.7847222222222223, "no_speech_prob": 1.2218448318890296e-05}, {"id": 210, "seek": 177700, "start": 1785.0, "end": 1793.0, "text": " For your exes, what types are you going to be creating for your exes?", "tokens": [1171, 428, 454, 279, 11, 437, 3467, 366, 291, 516, 281, 312, 4084, 337, 428, 454, 279, 30], "temperature": 0.0, "avg_logprob": -0.1112213134765625, "compression_ratio": 1.7847222222222223, "no_speech_prob": 1.2218448318890296e-05}, {"id": 211, "seek": 177700, "start": 1793.0, "end": 1799.0, "text": " And for your wise, what types are you going to be creating for your wise?", "tokens": [400, 337, 428, 10829, 11, 437, 3467, 366, 291, 516, 281, 312, 4084, 337, 428, 10829, 30], "temperature": 0.0, "avg_logprob": -0.1112213134765625, "compression_ratio": 1.7847222222222223, "no_speech_prob": 1.2218448318890296e-05}, {"id": 212, "seek": 177700, "start": 1799.0, "end": 1804.0, "text": " Why is that? Well, it wants to create.", "tokens": [1545, 307, 300, 30, 1042, 11, 309, 2738, 281, 1884, 13], "temperature": 0.0, "avg_logprob": -0.1112213134765625, "compression_ratio": 1.7847222222222223, "no_speech_prob": 1.2218448318890296e-05}, {"id": 213, "seek": 180400, "start": 1804.0, "end": 1817.0, "text": " Those types, because these types, as we'll see, have information about what are all the transforms that you would generally expect to have to use to create and use that type.", "tokens": [3950, 3467, 11, 570, 613, 3467, 11, 382, 321, 603, 536, 11, 362, 1589, 466, 437, 366, 439, 264, 35592, 300, 291, 576, 5101, 2066, 281, 362, 281, 764, 281, 1884, 293, 764, 300, 2010, 13], "temperature": 0.0, "avg_logprob": -0.09681486200403285, "compression_ratio": 1.5735294117647058, "no_speech_prob": 1.4738562640559394e-05}, {"id": 214, "seek": 180400, "start": 1817.0, "end": 1821.0, "text": " So you can see there isn't actually anything here.", "tokens": [407, 291, 393, 536, 456, 1943, 380, 767, 1340, 510, 13], "temperature": 0.0, "avg_logprob": -0.09681486200403285, "compression_ratio": 1.5735294117647058, "no_speech_prob": 1.4738562640559394e-05}, {"id": 215, "seek": 180400, "start": 1821.0, "end": 1826.0, "text": " That says open an image, right? This is just list the images.", "tokens": [663, 1619, 1269, 364, 3256, 11, 558, 30, 639, 307, 445, 1329, 264, 5267, 13], "temperature": 0.0, "avg_logprob": -0.09681486200403285, "compression_ratio": 1.5735294117647058, "no_speech_prob": 1.4738562640559394e-05}, {"id": 216, "seek": 180400, "start": 1826.0, "end": 1829.0, "text": " On the disk, this the file names.", "tokens": [1282, 264, 12355, 11, 341, 264, 3991, 5288, 13], "temperature": 0.0, "avg_logprob": -0.09681486200403285, "compression_ratio": 1.5735294117647058, "no_speech_prob": 1.4738562640559394e-05}, {"id": 217, "seek": 182900, "start": 1829.0, "end": 1840.0, "text": " But this tuple of types is the thing where it's going to call PIL image black and white dot create on the file name to create my exes.", "tokens": [583, 341, 2604, 781, 295, 3467, 307, 264, 551, 689, 309, 311, 516, 281, 818, 430, 4620, 3256, 2211, 293, 2418, 5893, 1884, 322, 264, 3991, 1315, 281, 1884, 452, 454, 279, 13], "temperature": 0.0, "avg_logprob": -0.20296804210807703, "compression_ratio": 1.6055555555555556, "no_speech_prob": 2.2958959107199917e-06}, {"id": 218, "seek": 182900, "start": 1840.0, "end": 1846.0, "text": " And it's going to call category to create my wise.", "tokens": [400, 309, 311, 516, 281, 818, 7719, 281, 1884, 452, 10829, 13], "temperature": 0.0, "avg_logprob": -0.20296804210807703, "compression_ratio": 1.6055555555555556, "no_speech_prob": 2.2958959107199917e-06}, {"id": 219, "seek": 182900, "start": 1846.0, "end": 1856.0, "text": " And in the Y case, because there's a get Y defined, first of all, it will label it with apparent label.", "tokens": [400, 294, 264, 398, 1389, 11, 570, 456, 311, 257, 483, 398, 7642, 11, 700, 295, 439, 11, 309, 486, 7645, 309, 365, 18335, 7645, 13], "temperature": 0.0, "avg_logprob": -0.20296804210807703, "compression_ratio": 1.6055555555555556, "no_speech_prob": 2.2958959107199917e-06}, {"id": 220, "seek": 185600, "start": 1856.0, "end": 1873.0, "text": " So if we have a look.", "tokens": [407, 498, 321, 362, 257, 574, 13], "temperature": 0.0, "avg_logprob": -0.1906543861735951, "compression_ratio": 0.7241379310344828, "no_speech_prob": 4.356772024038946e-06}, {"id": 221, "seek": 187300, "start": 1873.0, "end": 1886.0, "text": " So here's our category class.", "tokens": [407, 510, 311, 527, 7719, 1508, 13], "temperature": 0.0, "avg_logprob": -0.14143717288970947, "compression_ratio": 0.7837837837837838, "no_speech_prob": 2.4297458367072977e-05}, {"id": 222, "seek": 188600, "start": 1886.0, "end": 1911.0, "text": " Let me try to remember how this works.", "tokens": [961, 385, 853, 281, 1604, 577, 341, 1985, 13], "temperature": 0.0, "avg_logprob": -0.2002411438868596, "compression_ratio": 0.8260869565217391, "no_speech_prob": 6.200111238285899e-05}, {"id": 223, "seek": 191100, "start": 1911.0, "end": 1935.0, "text": " Image P.W.", "tokens": [29903, 430, 13, 54, 13], "temperature": 0.0, "avg_logprob": -0.6807605955335829, "compression_ratio": 0.5555555555555556, "no_speech_prob": 2.0143026631558314e-05}, {"id": 224, "seek": 193500, "start": 1935.0, "end": 1953.0, "text": " I just try to remember how to find my way around this bit. So PIL image P.W.", "tokens": [286, 445, 853, 281, 1604, 577, 281, 915, 452, 636, 926, 341, 857, 13, 407, 430, 4620, 3256, 430, 13, 54, 13], "temperature": 0.0, "avg_logprob": -0.27569339825556827, "compression_ratio": 0.9743589743589743, "no_speech_prob": 2.429422784189228e-05}, {"id": 225, "seek": 195300, "start": 1953.0, "end": 1972.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.12736834088961282, "compression_ratio": 0.42857142857142855, "no_speech_prob": 6.048186605767114e-06}, {"id": 226, "seek": 197200, "start": 1972.0, "end": 1997.0, "text": " So these types are defined in our seven vision core.", "tokens": [407, 613, 3467, 366, 7642, 294, 527, 3407, 5201, 4965, 13], "temperature": 0.0, "avg_logprob": -0.3104163487752279, "compression_ratio": 0.896551724137931, "no_speech_prob": 3.186217099937494e-06}, {"id": 227, "seek": 199700, "start": 1997.0, "end": 2012.0, "text": " Yeah, so you can see PIL image P.W.", "tokens": [865, 11, 370, 291, 393, 536, 430, 4620, 3256, 430, 13, 54, 13], "temperature": 0.0, "avg_logprob": -0.1796378665500217, "compression_ratio": 1.2941176470588236, "no_speech_prob": 6.338568709907122e-06}, {"id": 228, "seek": 199700, "start": 2012.0, "end": 2022.0, "text": " Is a PIL image. It's got no other methods, so it's going to be calling the create method for us.", "tokens": [1119, 257, 430, 4620, 3256, 13, 467, 311, 658, 572, 661, 7150, 11, 370, 309, 311, 516, 281, 312, 5141, 264, 1884, 3170, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.1796378665500217, "compression_ratio": 1.2941176470588236, "no_speech_prob": 6.338568709907122e-06}, {"id": 229, "seek": 202200, "start": 2022.0, "end": 2033.0, "text": " But when it calls the create method, it's going to use open args to figure out what arguments to pass to the create method, which in the case of PIL image P.W. is mode L.", "tokens": [583, 562, 309, 5498, 264, 1884, 3170, 11, 309, 311, 516, 281, 764, 1269, 3882, 82, 281, 2573, 484, 437, 12869, 281, 1320, 281, 264, 1884, 3170, 11, 597, 294, 264, 1389, 295, 430, 4620, 3256, 430, 13, 54, 13, 307, 4391, 441, 13], "temperature": 0.0, "avg_logprob": -0.13461071252822876, "compression_ratio": 1.6727272727272726, "no_speech_prob": 1.6700723790563643e-05}, {"id": 230, "seek": 202200, "start": 2033.0, "end": 2041.0, "text": " That's the black and white mode for pillow.", "tokens": [663, 311, 264, 2211, 293, 2418, 4391, 337, 18581, 13], "temperature": 0.0, "avg_logprob": -0.13461071252822876, "compression_ratio": 1.6727272727272726, "no_speech_prob": 1.6700723790563643e-05}, {"id": 231, "seek": 202200, "start": 2041.0, "end": 2051.0, "text": " But there's another thing in here that's interesting, which is that PIL base, which this inherits from, has a thing called default default DL transforms.", "tokens": [583, 456, 311, 1071, 551, 294, 510, 300, 311, 1880, 11, 597, 307, 300, 430, 4620, 3096, 11, 597, 341, 9484, 1208, 490, 11, 575, 257, 551, 1219, 7576, 7576, 413, 43, 35592, 13], "temperature": 0.0, "avg_logprob": -0.13461071252822876, "compression_ratio": 1.6727272727272726, "no_speech_prob": 1.6700723790563643e-05}, {"id": 232, "seek": 205100, "start": 2051.0, "end": 2067.0, "text": " And this says if you in the data blocks API, when you use this type, it's going to automatically add this transform to our pipeline.", "tokens": [400, 341, 1619, 498, 291, 294, 264, 1412, 8474, 9362, 11, 562, 291, 764, 341, 2010, 11, 309, 311, 516, 281, 6772, 909, 341, 4088, 281, 527, 15517, 13], "temperature": 0.0, "avg_logprob": -0.10432492470254703, "compression_ratio": 1.3472222222222223, "no_speech_prob": 1.9637845980469137e-06}, {"id": 233, "seek": 205100, "start": 2067.0, "end": 2072.0, "text": " So here's another example. If you're working with point data.", "tokens": [407, 510, 311, 1071, 1365, 13, 759, 291, 434, 1364, 365, 935, 1412, 13], "temperature": 0.0, "avg_logprob": -0.10432492470254703, "compression_ratio": 1.3472222222222223, "no_speech_prob": 1.9637845980469137e-06}, {"id": 234, "seek": 207200, "start": 2072.0, "end": 2090.0, "text": " It adds this to your DS transform pipeline bounding boxes. There are different transforms that are added to those.", "tokens": [467, 10860, 341, 281, 428, 15816, 4088, 15517, 5472, 278, 9002, 13, 821, 366, 819, 35592, 300, 366, 3869, 281, 729, 13], "temperature": 0.0, "avg_logprob": -0.15919793569124663, "compression_ratio": 1.2, "no_speech_prob": 3.138100282740197e-06}, {"id": 235, "seek": 209000, "start": 2090.0, "end": 2109.0, "text": " So the key thing here is that these these types do two things, at least two things. The first is they say how to actually create the how to actually create the objects that we're trying to build.", "tokens": [407, 264, 2141, 551, 510, 307, 300, 613, 613, 3467, 360, 732, 721, 11, 412, 1935, 732, 721, 13, 440, 700, 307, 436, 584, 577, 281, 767, 1884, 264, 577, 281, 767, 1884, 264, 6565, 300, 321, 434, 1382, 281, 1322, 13], "temperature": 0.0, "avg_logprob": -0.07147435672947618, "compression_ratio": 1.6624203821656052, "no_speech_prob": 3.2376722174376482e-06}, {"id": 236, "seek": 209000, "start": 2109.0, "end": 2118.0, "text": " But they also say what default transforms to add to our pipeline.", "tokens": [583, 436, 611, 584, 437, 7576, 35592, 281, 909, 281, 527, 15517, 13], "temperature": 0.0, "avg_logprob": -0.07147435672947618, "compression_ratio": 1.6624203821656052, "no_speech_prob": 3.2376722174376482e-06}, {"id": 237, "seek": 211800, "start": 2118.0, "end": 2133.0, "text": " And so that's why when we then say so we can take a data block object and we can create it and then we can call data source passing in the thing that will eventually make its way to get item source.", "tokens": [400, 370, 300, 311, 983, 562, 321, 550, 584, 370, 321, 393, 747, 257, 1412, 3461, 2657, 293, 321, 393, 1884, 309, 293, 550, 321, 393, 818, 1412, 4009, 8437, 294, 264, 551, 300, 486, 4728, 652, 1080, 636, 281, 483, 3174, 4009, 13], "temperature": 0.0, "avg_logprob": -0.09239601794584298, "compression_ratio": 1.6054054054054054, "no_speech_prob": 4.93686320623965e-06}, {"id": 238, "seek": 211800, "start": 2133.0, "end": 2136.0, "text": " So this is the path to MNIST.", "tokens": [407, 341, 307, 264, 3100, 281, 376, 45, 19756, 13], "temperature": 0.0, "avg_logprob": -0.09239601794584298, "compression_ratio": 1.6054054054054054, "no_speech_prob": 4.93686320623965e-06}, {"id": 239, "seek": 211800, "start": 2136.0, "end": 2143.0, "text": " And this then allows us, as you can see, to use it in the usual way.", "tokens": [400, 341, 550, 4045, 505, 11, 382, 291, 393, 536, 11, 281, 764, 309, 294, 264, 7713, 636, 13], "temperature": 0.0, "avg_logprob": -0.09239601794584298, "compression_ratio": 1.6054054054054054, "no_speech_prob": 4.93686320623965e-06}, {"id": 240, "seek": 214300, "start": 2143.0, "end": 2152.0, "text": " And because the data block API, as we'll see,", "tokens": [400, 570, 264, 1412, 3461, 9362, 11, 382, 321, 603, 536, 11], "temperature": 0.0, "avg_logprob": -0.1329869959089491, "compression_ratio": 1.5449101796407185, "no_speech_prob": 9.818064427236095e-06}, {"id": 241, "seek": 214300, "start": 2152.0, "end": 2155.0, "text": " users, funcs, quags.", "tokens": [5022, 11, 1019, 14368, 11, 421, 12109, 13], "temperature": 0.0, "avg_logprob": -0.1329869959089491, "compression_ratio": 1.5449101796407185, "no_speech_prob": 9.818064427236095e-06}, {"id": 242, "seek": 214300, "start": 2155.0, "end": 2163.0, "text": " That means that we can instead of inheriting from data block, we can equally well just construct a data block.", "tokens": [663, 1355, 300, 321, 393, 2602, 295, 9484, 1748, 490, 1412, 3461, 11, 321, 393, 12309, 731, 445, 7690, 257, 1412, 3461, 13], "temperature": 0.0, "avg_logprob": -0.1329869959089491, "compression_ratio": 1.5449101796407185, "no_speech_prob": 9.818064427236095e-06}, {"id": 243, "seek": 214300, "start": 2163.0, "end": 2168.0, "text": " And if you construct a data block, then you have to pass in the types like this.", "tokens": [400, 498, 291, 7690, 257, 1412, 3461, 11, 550, 291, 362, 281, 1320, 294, 264, 3467, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1329869959089491, "compression_ratio": 1.5449101796407185, "no_speech_prob": 9.818064427236095e-06}, {"id": 244, "seek": 216800, "start": 2168.0, "end": 2173.0, "text": " And then here are the three things again that we're we were overriding before.", "tokens": [400, 550, 510, 366, 264, 1045, 721, 797, 300, 321, 434, 321, 645, 670, 81, 2819, 949, 13], "temperature": 0.0, "avg_logprob": -0.0906640523439878, "compression_ratio": 1.5919540229885059, "no_speech_prob": 4.356730642030016e-06}, {"id": 245, "seek": 216800, "start": 2173.0, "end": 2178.0, "text": " So it's doing exactly the same thing as this one.", "tokens": [407, 309, 311, 884, 2293, 264, 912, 551, 382, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.0906640523439878, "compression_ratio": 1.5919540229885059, "no_speech_prob": 4.356730642030016e-06}, {"id": 246, "seek": 216800, "start": 2178.0, "end": 2186.0, "text": " So a lot of the time this one's going to be a bit shorter and easier version if you don't kind of need state.", "tokens": [407, 257, 688, 295, 264, 565, 341, 472, 311, 516, 281, 312, 257, 857, 11639, 293, 3571, 3037, 498, 291, 500, 380, 733, 295, 643, 1785, 13], "temperature": 0.0, "avg_logprob": -0.0906640523439878, "compression_ratio": 1.5919540229885059, "no_speech_prob": 4.356730642030016e-06}, {"id": 247, "seek": 216800, "start": 2186.0, "end": 2196.0, "text": " So let's look at the data block class.", "tokens": [407, 718, 311, 574, 412, 264, 1412, 3461, 1508, 13], "temperature": 0.0, "avg_logprob": -0.0906640523439878, "compression_ratio": 1.5919540229885059, "no_speech_prob": 4.356730642030016e-06}, {"id": 248, "seek": 219600, "start": 2196.0, "end": 2200.0, "text": " As you can see, it's very short.", "tokens": [1018, 291, 393, 536, 11, 309, 311, 588, 2099, 13], "temperature": 0.0, "avg_logprob": -0.054038991246904644, "compression_ratio": 1.49375, "no_speech_prob": 1.6536695284230518e-06}, {"id": 249, "seek": 219600, "start": 2200.0, "end": 2207.0, "text": " So as we discussed, it has a funcs, quags decorator.", "tokens": [407, 382, 321, 7152, 11, 309, 575, 257, 1019, 14368, 11, 421, 12109, 7919, 1639, 13], "temperature": 0.0, "avg_logprob": -0.054038991246904644, "compression_ratio": 1.49375, "no_speech_prob": 1.6536695284230518e-06}, {"id": 250, "seek": 219600, "start": 2207.0, "end": 2211.0, "text": " And that means it needs to look to see what the underscore methods are.", "tokens": [400, 300, 1355, 309, 2203, 281, 574, 281, 536, 437, 264, 37556, 7150, 366, 13], "temperature": 0.0, "avg_logprob": -0.054038991246904644, "compression_ratio": 1.49375, "no_speech_prob": 1.6536695284230518e-06}, {"id": 251, "seek": 219600, "start": 2211.0, "end": 2218.0, "text": " So here's the list of methods that you can pass in to have replaced by your code.", "tokens": [407, 510, 311, 264, 1329, 295, 7150, 300, 291, 393, 1320, 294, 281, 362, 10772, 538, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.054038991246904644, "compression_ratio": 1.49375, "no_speech_prob": 1.6536695284230518e-06}, {"id": 252, "seek": 221800, "start": 2218.0, "end": 2227.0, "text": " Then the other thing that you're going to pass in other types.", "tokens": [1396, 264, 661, 551, 300, 291, 434, 516, 281, 1320, 294, 661, 3467, 13], "temperature": 0.0, "avg_logprob": -0.054184249469212124, "compression_ratio": 1.7287234042553192, "no_speech_prob": 2.7693513402482495e-06}, {"id": 253, "seek": 221800, "start": 2227.0, "end": 2234.0, "text": " So then what we're going to do is we're going to be creating three different sets of transforms.", "tokens": [407, 550, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 312, 4084, 1045, 819, 6352, 295, 35592, 13], "temperature": 0.0, "avg_logprob": -0.054184249469212124, "compression_ratio": 1.7287234042553192, "no_speech_prob": 2.7693513402482495e-06}, {"id": 254, "seek": 221800, "start": 2234.0, "end": 2238.0, "text": " And in data block, we're giving them different names to what we've called them elsewhere.", "tokens": [400, 294, 1412, 3461, 11, 321, 434, 2902, 552, 819, 5288, 281, 437, 321, 600, 1219, 552, 14517, 13], "temperature": 0.0, "avg_logprob": -0.054184249469212124, "compression_ratio": 1.7287234042553192, "no_speech_prob": 2.7693513402482495e-06}, {"id": 255, "seek": 221800, "start": 2238.0, "end": 2241.0, "text": " So again, I don't know if this is what the names are going to end up being.", "tokens": [407, 797, 11, 286, 500, 380, 458, 498, 341, 307, 437, 264, 5288, 366, 516, 281, 917, 493, 885, 13], "temperature": 0.0, "avg_logprob": -0.054184249469212124, "compression_ratio": 1.7287234042553192, "no_speech_prob": 2.7693513402482495e-06}, {"id": 256, "seek": 224100, "start": 2241.0, "end": 2252.0, "text": " But basically what's going to happen is, as you can see, after item is DS transforms, which kind of makes sense, right?", "tokens": [583, 1936, 437, 311, 516, 281, 1051, 307, 11, 382, 291, 393, 536, 11, 934, 3174, 307, 15816, 35592, 11, 597, 733, 295, 1669, 2020, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1602035444609973, "compression_ratio": 1.8366336633663367, "no_speech_prob": 5.422131835075561e-06}, {"id": 257, "seek": 224100, "start": 2252.0, "end": 2256.0, "text": " Because the things that happen after you pull something out of a data set is after items.", "tokens": [1436, 264, 721, 300, 1051, 934, 291, 2235, 746, 484, 295, 257, 1412, 992, 307, 934, 4754, 13], "temperature": 0.0, "avg_logprob": -0.1602035444609973, "compression_ratio": 1.8366336633663367, "no_speech_prob": 5.422131835075561e-06}, {"id": 258, "seek": 224100, "start": 2256.0, "end": 2259.0, "text": " So they're kind of the data set transforms.", "tokens": [407, 436, 434, 733, 295, 264, 1412, 992, 35592, 13], "temperature": 0.0, "avg_logprob": -0.1602035444609973, "compression_ratio": 1.8366336633663367, "no_speech_prob": 5.422131835075561e-06}, {"id": 259, "seek": 224100, "start": 2259.0, "end": 2262.0, "text": " Where else the things that happen after you collate.", "tokens": [2305, 1646, 264, 721, 300, 1051, 934, 291, 1263, 473, 13], "temperature": 0.0, "avg_logprob": -0.1602035444609973, "compression_ratio": 1.8366336633663367, "no_speech_prob": 5.422131835075561e-06}, {"id": 260, "seek": 224100, "start": 2262.0, "end": 2265.0, "text": " So after batch, they're the DL transforms.", "tokens": [407, 934, 15245, 11, 436, 434, 264, 413, 43, 35592, 13], "temperature": 0.0, "avg_logprob": -0.1602035444609973, "compression_ratio": 1.8366336633663367, "no_speech_prob": 5.422131835075561e-06}, {"id": 261, "seek": 224100, "start": 2265.0, "end": 2268.0, "text": " So they're those two.", "tokens": [407, 436, 434, 729, 732, 13], "temperature": 0.0, "avg_logprob": -0.1602035444609973, "compression_ratio": 1.8366336633663367, "no_speech_prob": 5.422131835075561e-06}, {"id": 262, "seek": 226800, "start": 2268.0, "end": 2279.0, "text": " And so we have for a particular data block subclass, there's going to be some default data set transforms and some default data loader transforms.", "tokens": [400, 370, 321, 362, 337, 257, 1729, 1412, 3461, 1422, 11665, 11, 456, 311, 516, 281, 312, 512, 7576, 1412, 992, 35592, 293, 512, 7576, 1412, 3677, 260, 35592, 13], "temperature": 0.0, "avg_logprob": -0.08559409608232214, "compression_ratio": 1.9656862745098038, "no_speech_prob": 5.594275080511579e-06}, {"id": 263, "seek": 226800, "start": 2279.0, "end": 2284.0, "text": " The data set transforms, you're pretty much always going to want to tensor.", "tokens": [440, 1412, 992, 35592, 11, 291, 434, 1238, 709, 1009, 516, 281, 528, 281, 40863, 13], "temperature": 0.0, "avg_logprob": -0.08559409608232214, "compression_ratio": 1.9656862745098038, "no_speech_prob": 5.594275080511579e-06}, {"id": 264, "seek": 226800, "start": 2284.0, "end": 2287.0, "text": " Data loader transforms, pretty much always going to want CUDA.", "tokens": [11888, 3677, 260, 35592, 11, 1238, 709, 1009, 516, 281, 528, 29777, 7509, 13], "temperature": 0.0, "avg_logprob": -0.08559409608232214, "compression_ratio": 1.9656862745098038, "no_speech_prob": 5.594275080511579e-06}, {"id": 265, "seek": 226800, "start": 2287.0, "end": 2297.0, "text": " And then we're going to grab from our types that we passed in that default DS transforms and default DL transforms.", "tokens": [400, 550, 321, 434, 516, 281, 4444, 490, 527, 3467, 300, 321, 4678, 294, 300, 7576, 15816, 35592, 293, 7576, 413, 43, 35592, 13], "temperature": 0.0, "avg_logprob": -0.08559409608232214, "compression_ratio": 1.9656862745098038, "no_speech_prob": 5.594275080511579e-06}, {"id": 266, "seek": 229700, "start": 2297.0, "end": 2306.0, "text": " Attributes that we saw.", "tokens": [7298, 2024, 1819, 300, 321, 1866, 13], "temperature": 0.0, "avg_logprob": -0.18938051570545544, "compression_ratio": 1.2155172413793103, "no_speech_prob": 1.1842796084238216e-05}, {"id": 267, "seek": 229700, "start": 2306.0, "end": 2307.0, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.18938051570545544, "compression_ratio": 1.2155172413793103, "no_speech_prob": 1.1842796084238216e-05}, {"id": 268, "seek": 229700, "start": 2307.0, "end": 2311.0, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.18938051570545544, "compression_ratio": 1.2155172413793103, "no_speech_prob": 1.1842796084238216e-05}, {"id": 269, "seek": 229700, "start": 2311.0, "end": 2320.0, "text": " There's something kind of interesting, though, which is then later on when you try to create your data bunch.", "tokens": [821, 311, 746, 733, 295, 1880, 11, 1673, 11, 597, 307, 550, 1780, 322, 562, 291, 853, 281, 1884, 428, 1412, 3840, 13], "temperature": 0.0, "avg_logprob": -0.18938051570545544, "compression_ratio": 1.2155172413793103, "no_speech_prob": 1.1842796084238216e-05}, {"id": 270, "seek": 232000, "start": 2320.0, "end": 2334.0, "text": " You know, you might pass in your own data set transforms and data loader transforms.", "tokens": [509, 458, 11, 291, 1062, 1320, 294, 428, 1065, 1412, 992, 35592, 293, 1412, 3677, 260, 35592, 13], "temperature": 0.0, "avg_logprob": -0.06734077135721843, "compression_ratio": 1.6125, "no_speech_prob": 8.446169772469148e-07}, {"id": 271, "seek": 232000, "start": 2334.0, "end": 2338.0, "text": " And so we have to merge them together with the defaults.", "tokens": [400, 370, 321, 362, 281, 22183, 552, 1214, 365, 264, 7576, 82, 13], "temperature": 0.0, "avg_logprob": -0.06734077135721843, "compression_ratio": 1.6125, "no_speech_prob": 8.446169772469148e-07}, {"id": 272, "seek": 232000, "start": 2338.0, "end": 2345.0, "text": " And so that means if you pass in a transform that's already there, we don't want it to be there twice in particular.", "tokens": [400, 370, 300, 1355, 498, 291, 1320, 294, 257, 4088, 300, 311, 1217, 456, 11, 321, 500, 380, 528, 309, 281, 312, 456, 6091, 294, 1729, 13], "temperature": 0.0, "avg_logprob": -0.06734077135721843, "compression_ratio": 1.6125, "no_speech_prob": 8.446169772469148e-07}, {"id": 273, "seek": 234500, "start": 2345.0, "end": 2356.0, "text": " So there's a little function here called merge transforms, which, as you can see, basically removes duplicate transforms.", "tokens": [407, 456, 311, 257, 707, 2445, 510, 1219, 22183, 35592, 11, 597, 11, 382, 291, 393, 536, 11, 1936, 30445, 23976, 35592, 13], "temperature": 0.0, "avg_logprob": -0.13765606173762568, "compression_ratio": 1.4855072463768115, "no_speech_prob": 6.681488571302907e-07}, {"id": 274, "seek": 234500, "start": 2356.0, "end": 2361.0, "text": " So transforms of the same type.", "tokens": [407, 35592, 295, 264, 912, 2010, 13], "temperature": 0.0, "avg_logprob": -0.13765606173762568, "compression_ratio": 1.4855072463768115, "no_speech_prob": 6.681488571302907e-07}, {"id": 275, "seek": 234500, "start": 2361.0, "end": 2365.0, "text": " Which is a little bit awkward, but it works OK.", "tokens": [3013, 307, 257, 707, 857, 11411, 11, 457, 309, 1985, 2264, 13], "temperature": 0.0, "avg_logprob": -0.13765606173762568, "compression_ratio": 1.4855072463768115, "no_speech_prob": 6.681488571302907e-07}, {"id": 276, "seek": 234500, "start": 2365.0, "end": 2368.0, "text": " So.", "tokens": [407, 13], "temperature": 0.0, "avg_logprob": -0.13765606173762568, "compression_ratio": 1.4855072463768115, "no_speech_prob": 6.681488571302907e-07}, {"id": 277, "seek": 236800, "start": 2368.0, "end": 2376.0, "text": " This is why things like order is important. Remember, there's that order attribute in pipeline. We use the order attribute to sort the transforms.", "tokens": [639, 307, 983, 721, 411, 1668, 307, 1021, 13, 5459, 11, 456, 311, 300, 1668, 19667, 294, 15517, 13, 492, 764, 264, 1668, 19667, 281, 1333, 264, 35592, 13], "temperature": 0.0, "avg_logprob": -0.15161227096210828, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.8161911157221766e-06}, {"id": 278, "seek": 236800, "start": 2376.0, "end": 2379.0, "text": " So like you can have transforms defined in different places.", "tokens": [407, 411, 291, 393, 362, 35592, 7642, 294, 819, 3190, 13], "temperature": 0.0, "avg_logprob": -0.15161227096210828, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.8161911157221766e-06}, {"id": 279, "seek": 236800, "start": 2379.0, "end": 2388.0, "text": " They can be defined in the types in the defaults and the types, or you could be passing them in directly when you call data source.", "tokens": [814, 393, 312, 7642, 294, 264, 3467, 294, 264, 7576, 82, 293, 264, 3467, 11, 420, 291, 727, 312, 8437, 552, 294, 3838, 562, 291, 818, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.15161227096210828, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.8161911157221766e-06}, {"id": 280, "seek": 236800, "start": 2388.0, "end": 2392.0, "text": " Sorry, a data bunch or data source.", "tokens": [4919, 11, 257, 1412, 3840, 420, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.15161227096210828, "compression_ratio": 1.7857142857142858, "no_speech_prob": 1.8161911157221766e-06}, {"id": 281, "seek": 239200, "start": 2392.0, "end": 2400.0, "text": " And so we need to bring them all together in a list and make sure that list is in an order that makes sense.", "tokens": [400, 370, 321, 643, 281, 1565, 552, 439, 1214, 294, 257, 1329, 293, 652, 988, 300, 1329, 307, 294, 364, 1668, 300, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.08729421331527386, "compression_ratio": 1.672811059907834, "no_speech_prob": 2.60156525655475e-06}, {"id": 282, "seek": 239200, "start": 2400.0, "end": 2406.0, "text": " So, yes, so data augmentation we haven't looked at yet, but they are just other transforms.", "tokens": [407, 11, 2086, 11, 370, 1412, 14501, 19631, 321, 2378, 380, 2956, 412, 1939, 11, 457, 436, 366, 445, 661, 35592, 13], "temperature": 0.0, "avg_logprob": -0.08729421331527386, "compression_ratio": 1.672811059907834, "no_speech_prob": 2.60156525655475e-06}, {"id": 283, "seek": 239200, "start": 2406.0, "end": 2414.0, "text": " So generally you would pass them into the data bunch method and we don't have any.", "tokens": [407, 5101, 291, 576, 1320, 552, 666, 264, 1412, 3840, 3170, 293, 321, 500, 380, 362, 604, 13], "temperature": 0.0, "avg_logprob": -0.08729421331527386, "compression_ratio": 1.672811059907834, "no_speech_prob": 2.60156525655475e-06}, {"id": 284, "seek": 239200, "start": 2414.0, "end": 2421.0, "text": " There's no augmentations that are done by default, so you have to pass them in.", "tokens": [821, 311, 572, 29919, 763, 300, 366, 1096, 538, 7576, 11, 370, 291, 362, 281, 1320, 552, 294, 13], "temperature": 0.0, "avg_logprob": -0.08729421331527386, "compression_ratio": 1.672811059907834, "no_speech_prob": 2.60156525655475e-06}, {"id": 285, "seek": 242100, "start": 2421.0, "end": 2426.0, "text": " So if you ask for a data bunch, then first of all, it's going to create a data source.", "tokens": [407, 498, 291, 1029, 337, 257, 1412, 3840, 11, 550, 700, 295, 439, 11, 309, 311, 516, 281, 1884, 257, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.08926147222518921, "compression_ratio": 1.641025641025641, "no_speech_prob": 1.0783035577333067e-05}, {"id": 286, "seek": 242100, "start": 2426.0, "end": 2431.0, "text": " So self dot source in this case will be like the path to amnest, for example.", "tokens": [407, 2698, 5893, 4009, 294, 341, 1389, 486, 312, 411, 264, 3100, 281, 669, 77, 377, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.08926147222518921, "compression_ratio": 1.641025641025641, "no_speech_prob": 1.0783035577333067e-05}, {"id": 287, "seek": 242100, "start": 2431.0, "end": 2435.0, "text": " So we would then call that get items function that you defined.", "tokens": [407, 321, 576, 550, 818, 300, 483, 4754, 2445, 300, 291, 7642, 13], "temperature": 0.0, "avg_logprob": -0.08926147222518921, "compression_ratio": 1.641025641025641, "no_speech_prob": 1.0783035577333067e-05}, {"id": 288, "seek": 242100, "start": 2435.0, "end": 2445.0, "text": " And if you didn't define one, then just do nothing to turn the source into a list of items.", "tokens": [400, 498, 291, 994, 380, 6964, 472, 11, 550, 445, 360, 1825, 281, 1261, 264, 4009, 666, 257, 1329, 295, 4754, 13], "temperature": 0.0, "avg_logprob": -0.08926147222518921, "compression_ratio": 1.641025641025641, "no_speech_prob": 1.0783035577333067e-05}, {"id": 289, "seek": 244500, "start": 2445.0, "end": 2451.0, "text": " And then if you have a splitter, then we create the splits from it.", "tokens": [400, 550, 498, 291, 362, 257, 4732, 3904, 11, 550, 321, 1884, 264, 37741, 490, 309, 13], "temperature": 0.0, "avg_logprob": -0.1278857647533148, "compression_ratio": 1.535031847133758, "no_speech_prob": 5.507556579686934e-06}, {"id": 290, "seek": 244500, "start": 2451.0, "end": 2459.0, "text": " And if there's a get X and a get Y, then call those.", "tokens": [400, 498, 456, 311, 257, 483, 1783, 293, 257, 483, 398, 11, 550, 818, 729, 13], "temperature": 0.0, "avg_logprob": -0.1278857647533148, "compression_ratio": 1.535031847133758, "no_speech_prob": 5.507556579686934e-06}, {"id": 291, "seek": 244500, "start": 2459.0, "end": 2464.0, "text": " We actually don't call those, just store those, I should say, as functions.", "tokens": [492, 767, 500, 380, 818, 729, 11, 445, 3531, 729, 11, 286, 820, 584, 11, 382, 6828, 13], "temperature": 0.0, "avg_logprob": -0.1278857647533148, "compression_ratio": 1.535031847133758, "no_speech_prob": 5.507556579686934e-06}, {"id": 292, "seek": 244500, "start": 2464.0, "end": 2473.0, "text": " So they're going to be a labeling functions.", "tokens": [407, 436, 434, 516, 281, 312, 257, 40244, 6828, 13], "temperature": 0.0, "avg_logprob": -0.1278857647533148, "compression_ratio": 1.535031847133758, "no_speech_prob": 5.507556579686934e-06}, {"id": 293, "seek": 247300, "start": 2473.0, "end": 2479.0, "text": " OK, if you didn't pass in any type transforms, then use the defaults.", "tokens": [2264, 11, 498, 291, 994, 380, 1320, 294, 604, 2010, 35592, 11, 550, 764, 264, 7576, 82, 13], "temperature": 0.0, "avg_logprob": -0.09492421851438634, "compression_ratio": 1.7876712328767124, "no_speech_prob": 6.144061444501858e-06}, {"id": 294, "seek": 247300, "start": 2479.0, "end": 2491.0, "text": " And so then we can create a data source passing in our items and our transforms.", "tokens": [400, 370, 550, 321, 393, 1884, 257, 1412, 4009, 8437, 294, 527, 4754, 293, 527, 35592, 13], "temperature": 0.0, "avg_logprob": -0.09492421851438634, "compression_ratio": 1.7876712328767124, "no_speech_prob": 6.144061444501858e-06}, {"id": 295, "seek": 247300, "start": 2491.0, "end": 2493.0, "text": " And so that gives us our data source.", "tokens": [400, 370, 300, 2709, 505, 527, 1412, 4009, 13], "temperature": 0.0, "avg_logprob": -0.09492421851438634, "compression_ratio": 1.7876712328767124, "no_speech_prob": 6.144061444501858e-06}, {"id": 296, "seek": 247300, "start": 2493.0, "end": 2497.0, "text": " And then we'll create our data set transforms and data loader transforms", "tokens": [400, 550, 321, 603, 1884, 527, 1412, 992, 35592, 293, 1412, 3677, 260, 35592], "temperature": 0.0, "avg_logprob": -0.09492421851438634, "compression_ratio": 1.7876712328767124, "no_speech_prob": 6.144061444501858e-06}, {"id": 297, "seek": 249700, "start": 2497.0, "end": 2505.0, "text": " and turn our data source into a data bunch using the method we just saw.", "tokens": [293, 1261, 527, 1412, 4009, 666, 257, 1412, 3840, 1228, 264, 3170, 321, 445, 1866, 13], "temperature": 0.0, "avg_logprob": -0.11319375442246259, "compression_ratio": 1.4206896551724137, "no_speech_prob": 6.240795755729778e-06}, {"id": 298, "seek": 249700, "start": 2505.0, "end": 2517.0, "text": " OK, so that's data blocks.", "tokens": [2264, 11, 370, 300, 311, 1412, 8474, 13], "temperature": 0.0, "avg_logprob": -0.11319375442246259, "compression_ratio": 1.4206896551724137, "no_speech_prob": 6.240795755729778e-06}, {"id": 299, "seek": 249700, "start": 2517.0, "end": 2519.0, "text": " So the best way to understand it is through the examples.", "tokens": [407, 264, 1151, 636, 281, 1223, 309, 307, 807, 264, 5110, 13], "temperature": 0.0, "avg_logprob": -0.11319375442246259, "compression_ratio": 1.4206896551724137, "no_speech_prob": 6.240795755729778e-06}, {"id": 300, "seek": 249700, "start": 2519.0, "end": 2523.0, "text": " So yeah, have a look at the subclassing example.", "tokens": [407, 1338, 11, 362, 257, 574, 412, 264, 1422, 11665, 278, 1365, 13], "temperature": 0.0, "avg_logprob": -0.11319375442246259, "compression_ratio": 1.4206896551724137, "no_speech_prob": 6.240795755729778e-06}, {"id": 301, "seek": 252300, "start": 2523.0, "end": 2527.0, "text": " Have a look at the function version example.", "tokens": [3560, 257, 574, 412, 264, 2445, 3037, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1931153749164782, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.785281933232909e-06}, {"id": 302, "seek": 252300, "start": 2527.0, "end": 2530.0, "text": " And so pets.", "tokens": [400, 370, 19897, 13], "temperature": 0.0, "avg_logprob": -0.1931153749164782, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.785281933232909e-06}, {"id": 303, "seek": 252300, "start": 2530.0, "end": 2534.0, "text": " So the types of pets are going to be image and a category.", "tokens": [407, 264, 3467, 295, 19897, 366, 516, 281, 312, 3256, 293, 257, 7719, 13], "temperature": 0.0, "avg_logprob": -0.1931153749164782, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.785281933232909e-06}, {"id": 304, "seek": 252300, "start": 2534.0, "end": 2541.0, "text": " Same get items, random splitter, a regex label, forget Y.", "tokens": [10635, 483, 4754, 11, 4974, 4732, 3904, 11, 257, 319, 432, 87, 7645, 11, 2870, 398, 13], "temperature": 0.0, "avg_logprob": -0.1931153749164782, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.785281933232909e-06}, {"id": 305, "seek": 252300, "start": 2541.0, "end": 2542.0, "text": " And there we go.", "tokens": [400, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.1931153749164782, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.785281933232909e-06}, {"id": 306, "seek": 252300, "start": 2542.0, "end": 2547.0, "text": " In this case, you can see here we are actually doing some data augmentation.", "tokens": [682, 341, 1389, 11, 291, 393, 536, 510, 321, 366, 767, 884, 512, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.1931153749164782, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.785281933232909e-06}, {"id": 307, "seek": 252300, "start": 2547.0, "end": 2551.0, "text": " So aug transforms as a function or simply later, which gives us", "tokens": [407, 14501, 35592, 382, 257, 2445, 420, 2935, 1780, 11, 597, 2709, 505], "temperature": 0.0, "avg_logprob": -0.1931153749164782, "compression_ratio": 1.544186046511628, "no_speech_prob": 3.785281933232909e-06}, {"id": 308, "seek": 255100, "start": 2551.0, "end": 2556.0, "text": " it's basically the same as get transforms was in version one.", "tokens": [309, 311, 1936, 264, 912, 382, 483, 35592, 390, 294, 3037, 472, 13], "temperature": 0.0, "avg_logprob": -0.10197527003738116, "compression_ratio": 1.4930555555555556, "no_speech_prob": 6.339104857033817e-06}, {"id": 309, "seek": 255100, "start": 2556.0, "end": 2560.0, "text": " But now transforms is a much more general concept in version two.", "tokens": [583, 586, 35592, 307, 257, 709, 544, 2674, 3410, 294, 3037, 732, 13], "temperature": 0.0, "avg_logprob": -0.10197527003738116, "compression_ratio": 1.4930555555555556, "no_speech_prob": 6.339104857033817e-06}, {"id": 310, "seek": 255100, "start": 2560.0, "end": 2572.0, "text": " So these are specifically augmentation transforms.", "tokens": [407, 613, 366, 4682, 14501, 19631, 35592, 13], "temperature": 0.0, "avg_logprob": -0.10197527003738116, "compression_ratio": 1.4930555555555556, "no_speech_prob": 6.339104857033817e-06}, {"id": 311, "seek": 255100, "start": 2572.0, "end": 2578.0, "text": " OK, then multi-label classification.", "tokens": [2264, 11, 550, 4825, 12, 75, 18657, 21538, 13], "temperature": 0.0, "avg_logprob": -0.10197527003738116, "compression_ratio": 1.4930555555555556, "no_speech_prob": 6.339104857033817e-06}, {"id": 312, "seek": 257800, "start": 2578.0, "end": 2585.0, "text": " So multi-label classification is interesting because this time we this is Planet.", "tokens": [407, 4825, 12, 75, 18657, 21538, 307, 1880, 570, 341, 565, 321, 341, 307, 22146, 13], "temperature": 0.0, "avg_logprob": -0.14136097396629443, "compression_ratio": 1.4, "no_speech_prob": 8.267512384918518e-06}, {"id": 313, "seek": 257800, "start": 2585.0, "end": 2591.0, "text": " It uses a CSV.", "tokens": [467, 4960, 257, 48814, 13], "temperature": 0.0, "avg_logprob": -0.14136097396629443, "compression_ratio": 1.4, "no_speech_prob": 8.267512384918518e-06}, {"id": 314, "seek": 257800, "start": 2591.0, "end": 2594.0, "text": " So, yeah, Kevin, hopefully that's answered your question on augmentations.", "tokens": [407, 11, 1338, 11, 9954, 11, 4696, 300, 311, 10103, 428, 1168, 322, 29919, 763, 13], "temperature": 0.0, "avg_logprob": -0.14136097396629443, "compression_ratio": 1.4, "no_speech_prob": 8.267512384918518e-06}, {"id": 315, "seek": 257800, "start": 2594.0, "end": 2597.0, "text": " Let me know if it didn't.", "tokens": [961, 385, 458, 498, 309, 994, 380, 13], "temperature": 0.0, "avg_logprob": -0.14136097396629443, "compression_ratio": 1.4, "no_speech_prob": 8.267512384918518e-06}, {"id": 316, "seek": 257800, "start": 2597.0, "end": 2602.0, "text": " So Planet, we create a data frame from the CSV.", "tokens": [407, 22146, 11, 321, 1884, 257, 1412, 3920, 490, 264, 48814, 13], "temperature": 0.0, "avg_logprob": -0.14136097396629443, "compression_ratio": 1.4, "no_speech_prob": 8.267512384918518e-06}, {"id": 317, "seek": 260200, "start": 2602.0, "end": 2613.0, "text": " And so when we call Planet.Beta bunch, we're going to be passing in the numpy array version of that data frame.", "tokens": [400, 370, 562, 321, 818, 22146, 13, 33, 7664, 3840, 11, 321, 434, 516, 281, 312, 8437, 294, 264, 1031, 8200, 10225, 3037, 295, 300, 1412, 3920, 13], "temperature": 0.0, "avg_logprob": -0.28551019624222157, "compression_ratio": 1.1794871794871795, "no_speech_prob": 7.410928446915932e-06}, {"id": 318, "seek": 260200, "start": 2613.0, "end": 2618.0, "text": " So Df.values in this case.", "tokens": [407, 413, 69, 13, 46033, 294, 341, 1389, 13], "temperature": 0.0, "avg_logprob": -0.28551019624222157, "compression_ratio": 1.1794871794871795, "no_speech_prob": 7.410928446915932e-06}, {"id": 319, "seek": 261800, "start": 2618.0, "end": 2640.0, "text": " And our augmentation here, as you can see, has some standard Planet appropriate augmentations, including flipvert equals true.", "tokens": [400, 527, 14501, 19631, 510, 11, 382, 291, 393, 536, 11, 575, 512, 3832, 22146, 6854, 29919, 763, 11, 3009, 7929, 3281, 6915, 2074, 13], "temperature": 0.0, "avg_logprob": -0.18592146280649546, "compression_ratio": 1.2991452991452992, "no_speech_prob": 3.288672132839565e-06}, {"id": 320, "seek": 261800, "start": 2640.0, "end": 2642.0, "text": " And so what happens here?", "tokens": [400, 370, 437, 2314, 510, 30], "temperature": 0.0, "avg_logprob": -0.18592146280649546, "compression_ratio": 1.2991452991452992, "no_speech_prob": 3.288672132839565e-06}, {"id": 321, "seek": 264200, "start": 2642.0, "end": 2648.0, "text": " We passed in this. This is a numpy array when we called.values.", "tokens": [492, 4678, 294, 341, 13, 639, 307, 257, 1031, 8200, 10225, 562, 321, 1219, 13, 46033, 13], "temperature": 0.0, "avg_logprob": -0.2874704360961914, "compression_ratio": 1.086021505376344, "no_speech_prob": 2.769385901046917e-06}, {"id": 322, "seek": 264200, "start": 2648.0, "end": 2663.0, "text": " And so getX is going to grab just X0.", "tokens": [400, 370, 483, 55, 307, 516, 281, 4444, 445, 1783, 15, 13], "temperature": 0.0, "avg_logprob": -0.2874704360961914, "compression_ratio": 1.086021505376344, "no_speech_prob": 2.769385901046917e-06}, {"id": 323, "seek": 266300, "start": 2663.0, "end": 2672.0, "text": " And this will just grab X1 and split it because this is a numpy array.", "tokens": [400, 341, 486, 445, 4444, 1783, 16, 293, 7472, 309, 570, 341, 307, 257, 1031, 8200, 10225, 13], "temperature": 0.0, "avg_logprob": -0.07537832652052788, "compression_ratio": 1.5266272189349113, "no_speech_prob": 1.3081670431347447e-06}, {"id": 324, "seek": 266300, "start": 2672.0, "end": 2680.0, "text": " So each row of this will contain the first the first item will be the file name and the second item will be the value.", "tokens": [407, 1184, 5386, 295, 341, 486, 5304, 264, 700, 264, 700, 3174, 486, 312, 264, 3991, 1315, 293, 264, 1150, 3174, 486, 312, 264, 2158, 13], "temperature": 0.0, "avg_logprob": -0.07537832652052788, "compression_ratio": 1.5266272189349113, "no_speech_prob": 1.3081670431347447e-06}, {"id": 325, "seek": 266300, "start": 2680.0, "end": 2685.0, "text": " So that's one way of doing Planet, which is mildly clunky.", "tokens": [407, 300, 311, 472, 636, 295, 884, 22146, 11, 597, 307, 15154, 356, 596, 25837, 13], "temperature": 0.0, "avg_logprob": -0.07537832652052788, "compression_ratio": 1.5266272189349113, "no_speech_prob": 1.3081670431347447e-06}, {"id": 326, "seek": 266300, "start": 2685.0, "end": 2689.0, "text": " It works.", "tokens": [467, 1985, 13], "temperature": 0.0, "avg_logprob": -0.07537832652052788, "compression_ratio": 1.5266272189349113, "no_speech_prob": 1.3081670431347447e-06}, {"id": 327, "seek": 268900, "start": 2689.0, "end": 2693.0, "text": " Here's another way of doing and the other thing about this way is it's kind of I don't know.", "tokens": [1692, 311, 1071, 636, 295, 884, 293, 264, 661, 551, 466, 341, 636, 307, 309, 311, 733, 295, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.08286608925348596, "compression_ratio": 1.7374301675977655, "no_speech_prob": 2.7264427444606554e-06}, {"id": 328, "seek": 268900, "start": 2693.0, "end": 2696.0, "text": " It's like doing this numpy array thing is kind of weird.", "tokens": [467, 311, 411, 884, 341, 1031, 8200, 10225, 551, 307, 733, 295, 3657, 13], "temperature": 0.0, "avg_logprob": -0.08286608925348596, "compression_ratio": 1.7374301675977655, "no_speech_prob": 2.7264427444606554e-06}, {"id": 329, "seek": 268900, "start": 2696.0, "end": 2713.0, "text": " This is a more elegant way, I think, where we're actually passing in the data frame rather than converting it rather than converting it into a numpy array first.", "tokens": [639, 307, 257, 544, 21117, 636, 11, 286, 519, 11, 689, 321, 434, 767, 8437, 294, 264, 1412, 3920, 2831, 813, 29942, 309, 2831, 813, 29942, 309, 666, 257, 1031, 8200, 10225, 700, 13], "temperature": 0.0, "avg_logprob": -0.08286608925348596, "compression_ratio": 1.7374301675977655, "no_speech_prob": 2.7264427444606554e-06}, {"id": 330, "seek": 271300, "start": 2713.0, "end": 2724.0, "text": " So this time we're doing something a little bit different, which is in get items.", "tokens": [407, 341, 565, 321, 434, 884, 746, 257, 707, 857, 819, 11, 597, 307, 294, 483, 4754, 13], "temperature": 0.0, "avg_logprob": -0.12798952720534634, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.6536799876121222e-06}, {"id": 331, "seek": 271300, "start": 2724.0, "end": 2728.0, "text": " So before, for get items, there was nothing at all. Right.", "tokens": [407, 949, 11, 337, 483, 4754, 11, 456, 390, 1825, 412, 439, 13, 1779, 13], "temperature": 0.0, "avg_logprob": -0.12798952720534634, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.6536799876121222e-06}, {"id": 332, "seek": 271300, "start": 2728.0, "end": 2730.0, "text": " So we just used the numpy array directly.", "tokens": [407, 321, 445, 1143, 264, 1031, 8200, 10225, 3838, 13], "temperature": 0.0, "avg_logprob": -0.12798952720534634, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.6536799876121222e-06}, {"id": 333, "seek": 271300, "start": 2730.0, "end": 2738.0, "text": " This time for get items, we're using this function, which returns a tuple.", "tokens": [639, 565, 337, 483, 4754, 11, 321, 434, 1228, 341, 2445, 11, 597, 11247, 257, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.12798952720534634, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.6536799876121222e-06}, {"id": 334, "seek": 273800, "start": 2738.0, "end": 2749.0, "text": " And the first thing in the tuple is a pandas expression that works in an entire pandas column to turn that column into a list of file names.", "tokens": [400, 264, 700, 551, 294, 264, 2604, 781, 307, 257, 4565, 296, 6114, 300, 1985, 294, 364, 2302, 4565, 296, 7738, 281, 1261, 300, 7738, 666, 257, 1329, 295, 3991, 5288, 13], "temperature": 0.0, "avg_logprob": -0.05065910542597536, "compression_ratio": 1.7762237762237763, "no_speech_prob": 1.3925398434366798e-06}, {"id": 335, "seek": 273800, "start": 2749.0, "end": 2758.0, "text": " And then this is another pandas expression that works on a complete column, the tags column to create the labels.", "tokens": [400, 550, 341, 307, 1071, 4565, 296, 6114, 300, 1985, 322, 257, 3566, 7738, 11, 264, 18632, 7738, 281, 1884, 264, 16949, 13], "temperature": 0.0, "avg_logprob": -0.05065910542597536, "compression_ratio": 1.7762237762237763, "no_speech_prob": 1.3925398434366798e-06}, {"id": 336, "seek": 275800, "start": 2758.0, "end": 2778.0, "text": " So one of the things that we skipped over when we looked at data blocks is that when we call get items, if it returns a tuple,", "tokens": [407, 472, 295, 264, 721, 300, 321, 30193, 670, 562, 321, 2956, 412, 1412, 8474, 307, 300, 562, 321, 818, 483, 4754, 11, 498, 309, 11247, 257, 2604, 781, 11], "temperature": 0.0, "avg_logprob": -0.05896239460639234, "compression_ratio": 1.4846153846153847, "no_speech_prob": 1.034844217429054e-06}, {"id": 337, "seek": 275800, "start": 2778.0, "end": 2783.0, "text": " then what we do is we zip together all of the items in that tuple.", "tokens": [550, 437, 321, 360, 307, 321, 20730, 1214, 439, 295, 264, 4754, 294, 300, 2604, 781, 13], "temperature": 0.0, "avg_logprob": -0.05896239460639234, "compression_ratio": 1.4846153846153847, "no_speech_prob": 1.034844217429054e-06}, {"id": 338, "seek": 278300, "start": 2783.0, "end": 2790.0, "text": " So in this case, we've returned a column of file names and a column of labels.", "tokens": [407, 294, 341, 1389, 11, 321, 600, 8752, 257, 7738, 295, 3991, 5288, 293, 257, 7738, 295, 16949, 13], "temperature": 0.0, "avg_logprob": -0.07928797777961283, "compression_ratio": 1.421875, "no_speech_prob": 1.9637859622889664e-06}, {"id": 339, "seek": 278300, "start": 2790.0, "end": 2797.0, "text": " And data sets are meant to return a single file name label pair.", "tokens": [400, 1412, 6352, 366, 4140, 281, 2736, 257, 2167, 3991, 1315, 7645, 6119, 13], "temperature": 0.0, "avg_logprob": -0.07928797777961283, "compression_ratio": 1.421875, "no_speech_prob": 1.9637859622889664e-06}, {"id": 340, "seek": 278300, "start": 2797.0, "end": 2802.0, "text": " So that's why this zips them together.", "tokens": [407, 300, 311, 983, 341, 710, 2600, 552, 1214, 13], "temperature": 0.0, "avg_logprob": -0.07928797777961283, "compression_ratio": 1.421875, "no_speech_prob": 1.9637859622889664e-06}, {"id": 341, "seek": 280200, "start": 2802.0, "end": 2813.0, "text": " And so then the labelers will just grab the appropriate thing from each of those lists.", "tokens": [400, 370, 550, 264, 7645, 433, 486, 445, 4444, 264, 6854, 551, 490, 1184, 295, 729, 14511, 13], "temperature": 0.0, "avg_logprob": -0.07079353580227146, "compression_ratio": 1.5351351351351352, "no_speech_prob": 4.784940756508149e-06}, {"id": 342, "seek": 280200, "start": 2813.0, "end": 2818.0, "text": " So this is kind of a nice, as you can see, you end up with very nice, neat code.", "tokens": [407, 341, 307, 733, 295, 257, 1481, 11, 382, 291, 393, 536, 11, 291, 917, 493, 365, 588, 1481, 11, 10654, 3089, 13], "temperature": 0.0, "avg_logprob": -0.07079353580227146, "compression_ratio": 1.5351351351351352, "no_speech_prob": 4.784940756508149e-06}, {"id": 343, "seek": 280200, "start": 2818.0, "end": 2827.0, "text": " It's also super fast because it's all operating, you know, in the kind of the pandas fast C code version of things.", "tokens": [467, 311, 611, 1687, 2370, 570, 309, 311, 439, 7447, 11, 291, 458, 11, 294, 264, 733, 295, 264, 4565, 296, 2370, 383, 3089, 3037, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.07079353580227146, "compression_ratio": 1.5351351351351352, "no_speech_prob": 4.784940756508149e-06}, {"id": 344, "seek": 282700, "start": 2827.0, "end": 2835.0, "text": " So this is a handy trick.", "tokens": [407, 341, 307, 257, 13239, 4282, 13], "temperature": 0.0, "avg_logprob": -0.139503417476531, "compression_ratio": 1.4642857142857142, "no_speech_prob": 5.507449259312125e-06}, {"id": 345, "seek": 282700, "start": 2835.0, "end": 2843.0, "text": " And then here's the same thing again, but using inheritance instead.", "tokens": [400, 550, 510, 311, 264, 912, 551, 797, 11, 457, 1228, 32122, 2602, 13], "temperature": 0.0, "avg_logprob": -0.139503417476531, "compression_ratio": 1.4642857142857142, "no_speech_prob": 5.507449259312125e-06}, {"id": 346, "seek": 282700, "start": 2843.0, "end": 2851.0, "text": " Here's a neat trick. You've probably only ever seen static method use as a decorator before, but you can actually just use it like all like everything.", "tokens": [1692, 311, 257, 10654, 4282, 13, 509, 600, 1391, 787, 1562, 1612, 13437, 3170, 764, 382, 257, 7919, 1639, 949, 11, 457, 291, 393, 767, 445, 764, 309, 411, 439, 411, 1203, 13], "temperature": 0.0, "avg_logprob": -0.139503417476531, "compression_ratio": 1.4642857142857142, "no_speech_prob": 5.507449259312125e-06}, {"id": 347, "seek": 285100, "start": 2851.0, "end": 2859.0, "text": " You can use it as a function to turn this into a static method.", "tokens": [509, 393, 764, 309, 382, 257, 2445, 281, 1261, 341, 666, 257, 13437, 3170, 13], "temperature": 0.0, "avg_logprob": -0.1415784808172696, "compression_ratio": 1.5185185185185186, "no_speech_prob": 3.089464598815539e-06}, {"id": 348, "seek": 285100, "start": 2859.0, "end": 2862.0, "text": " Lots and lots of versions of this, as you can see.", "tokens": [15908, 293, 3195, 295, 9606, 295, 341, 11, 382, 291, 393, 536, 13], "temperature": 0.0, "avg_logprob": -0.1415784808172696, "compression_ratio": 1.5185185185185186, "no_speech_prob": 3.089464598815539e-06}, {"id": 349, "seek": 285100, "start": 2862.0, "end": 2874.0, "text": " Here's another one where we're pissing in the data frame and we can just have get X, grab the this column, grab get Y, this column.", "tokens": [1692, 311, 1071, 472, 689, 321, 434, 15171, 278, 294, 264, 1412, 3920, 293, 321, 393, 445, 362, 483, 1783, 11, 4444, 264, 341, 7738, 11, 4444, 483, 398, 11, 341, 7738, 13], "temperature": 0.0, "avg_logprob": -0.1415784808172696, "compression_ratio": 1.5185185185185186, "no_speech_prob": 3.089464598815539e-06}, {"id": 350, "seek": 287400, "start": 2874.0, "end": 2884.0, "text": " Maybe this is kind of actually the maybe this is the best version. It's kind of both fast and fairly obvious what's going on.", "tokens": [2704, 341, 307, 733, 295, 767, 264, 1310, 341, 307, 264, 1151, 3037, 13, 467, 311, 733, 295, 1293, 2370, 293, 6457, 6322, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.09297516269068565, "compression_ratio": 1.5290322580645161, "no_speech_prob": 4.425424776854925e-06}, {"id": 351, "seek": 287400, "start": 2884.0, "end": 2888.0, "text": " So there's lots of ways of doing things.", "tokens": [407, 456, 311, 3195, 295, 2098, 295, 884, 721, 13], "temperature": 0.0, "avg_logprob": -0.09297516269068565, "compression_ratio": 1.5290322580645161, "no_speech_prob": 4.425424776854925e-06}, {"id": 352, "seek": 287400, "start": 2888.0, "end": 2897.0, "text": " So Kevin mapped is simply the the version of map as a method inside L.", "tokens": [407, 9954, 33318, 307, 2935, 264, 264, 3037, 295, 4471, 382, 257, 3170, 1854, 441, 13], "temperature": 0.0, "avg_logprob": -0.09297516269068565, "compression_ratio": 1.5290322580645161, "no_speech_prob": 4.425424776854925e-06}, {"id": 353, "seek": 289700, "start": 2897.0, "end": 2905.0, "text": " And then map is just the standard map function in Python, which you should Google if you don't know about it.", "tokens": [400, 550, 4471, 307, 445, 264, 3832, 4471, 2445, 294, 15329, 11, 597, 291, 820, 3329, 498, 291, 500, 380, 458, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.06228175881790788, "compression_ratio": 1.489247311827957, "no_speech_prob": 6.643236247327877e-06}, {"id": 354, "seek": 289700, "start": 2905.0, "end": 2908.0, "text": " It's got nothing to do with parallelization.", "tokens": [467, 311, 658, 1825, 281, 360, 365, 8952, 2144, 13], "temperature": 0.0, "avg_logprob": -0.06228175881790788, "compression_ratio": 1.489247311827957, "no_speech_prob": 6.643236247327877e-06}, {"id": 355, "seek": 289700, "start": 2908.0, "end": 2914.0, "text": " It's just a way of creating a lazy generator in Python.", "tokens": [467, 311, 445, 257, 636, 295, 4084, 257, 14847, 19265, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.06228175881790788, "compression_ratio": 1.489247311827957, "no_speech_prob": 6.643236247327877e-06}, {"id": 356, "seek": 289700, "start": 2914.0, "end": 2920.0, "text": " And it's it's very fundamental to how we do things in version two.", "tokens": [400, 309, 311, 309, 311, 588, 8088, 281, 577, 321, 360, 721, 294, 3037, 732, 13], "temperature": 0.0, "avg_logprob": -0.06228175881790788, "compression_ratio": 1.489247311827957, "no_speech_prob": 6.643236247327877e-06}, {"id": 357, "seek": 292000, "start": 2920.0, "end": 2930.0, "text": " So I mean, end users don't really need to understand it, but if you want to understand the version two code, then you should definitely do a deep dive into into map.", "tokens": [407, 286, 914, 11, 917, 5022, 500, 380, 534, 643, 281, 1223, 309, 11, 457, 498, 291, 528, 281, 1223, 264, 3037, 732, 3089, 11, 550, 291, 820, 2138, 360, 257, 2452, 9192, 666, 666, 4471, 13], "temperature": 0.0, "avg_logprob": -0.0909259033203125, "compression_ratio": 1.7366255144032923, "no_speech_prob": 2.406062776572071e-06}, {"id": 358, "seek": 292000, "start": 2930.0, "end": 2940.0, "text": " And looking at how the version two data loader works would be a good place to get a very deep dive into that because it's all it's all doing lazy mapping.", "tokens": [400, 1237, 412, 577, 264, 3037, 732, 1412, 3677, 260, 1985, 576, 312, 257, 665, 1081, 281, 483, 257, 588, 2452, 9192, 666, 300, 570, 309, 311, 439, 309, 311, 439, 884, 14847, 18350, 13], "temperature": 0.0, "avg_logprob": -0.0909259033203125, "compression_ratio": 1.7366255144032923, "no_speech_prob": 2.406062776572071e-06}, {"id": 359, "seek": 292000, "start": 2940.0, "end": 2946.0, "text": " It's basically a functional style. So map is something that comes up in functional programming a lot.", "tokens": [467, 311, 1936, 257, 11745, 3758, 13, 407, 4471, 307, 746, 300, 1487, 493, 294, 11745, 9410, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.0909259033203125, "compression_ratio": 1.7366255144032923, "no_speech_prob": 2.406062776572071e-06}, {"id": 360, "seek": 294600, "start": 2946.0, "end": 2955.0, "text": " It's a lot of the code in version two is of a more functional style.", "tokens": [467, 311, 257, 688, 295, 264, 3089, 294, 3037, 732, 307, 295, 257, 544, 11745, 3758, 13], "temperature": 0.0, "avg_logprob": -0.19023783310599948, "compression_ratio": 1.4067796610169492, "no_speech_prob": 9.132490959018469e-07}, {"id": 361, "seek": 294600, "start": 2955.0, "end": 2969.0, "text": " I mean, here's a short version. If I create something like that and then I say map some function.", "tokens": [286, 914, 11, 510, 311, 257, 2099, 3037, 13, 759, 286, 1884, 746, 411, 300, 293, 550, 286, 584, 4471, 512, 2445, 13], "temperature": 0.0, "avg_logprob": -0.19023783310599948, "compression_ratio": 1.4067796610169492, "no_speech_prob": 9.132490959018469e-07}, {"id": 362, "seek": 296900, "start": 2969.0, "end": 2978.0, "text": " Like negative. So that's just the negative function over that.", "tokens": [1743, 3671, 13, 407, 300, 311, 445, 264, 3671, 2445, 670, 300, 13], "temperature": 0.0, "avg_logprob": -0.13801104313618429, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.0904442408209434e-06}, {"id": 363, "seek": 296900, "start": 2978.0, "end": 2983.0, "text": " It returns something weird. It returns a map.", "tokens": [467, 11247, 746, 3657, 13, 467, 11247, 257, 4471, 13], "temperature": 0.0, "avg_logprob": -0.13801104313618429, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.0904442408209434e-06}, {"id": 364, "seek": 296900, "start": 2983.0, "end": 2991.0, "text": " And basically that says this is a lazy generator, which won't be calculated until like I print it or turn it into a list or something.", "tokens": [400, 1936, 300, 1619, 341, 307, 257, 14847, 19265, 11, 597, 1582, 380, 312, 15598, 1826, 411, 286, 4482, 309, 420, 1261, 309, 666, 257, 1329, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.13801104313618429, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.0904442408209434e-06}, {"id": 365, "seek": 296900, "start": 2991.0, "end": 2995.0, "text": " So I can just say list. And there you go.", "tokens": [407, 286, 393, 445, 584, 1329, 13, 400, 456, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.13801104313618429, "compression_ratio": 1.5405405405405406, "no_speech_prob": 2.0904442408209434e-06}, {"id": 366, "seek": 299500, "start": 2995.0, "end": 3004.0, "text": " OK, so you can see it's mapped this function over my list.", "tokens": [2264, 11, 370, 291, 393, 536, 309, 311, 33318, 341, 2445, 670, 452, 1329, 13], "temperature": 0.0, "avg_logprob": -0.16720260273326526, "compression_ratio": 1.3333333333333333, "no_speech_prob": 5.682382834493183e-06}, {"id": 367, "seek": 299500, "start": 3004.0, "end": 3008.0, "text": " But it won't do it until you actually kind of finally need it.", "tokens": [583, 309, 1582, 380, 360, 309, 1826, 291, 767, 733, 295, 2721, 643, 309, 13], "temperature": 0.0, "avg_logprob": -0.16720260273326526, "compression_ratio": 1.3333333333333333, "no_speech_prob": 5.682382834493183e-06}, {"id": 368, "seek": 299500, "start": 3008.0, "end": 3018.0, "text": " So if we go to two equals that and then we say T three equals map.", "tokens": [407, 498, 321, 352, 281, 732, 6915, 300, 293, 550, 321, 584, 314, 1045, 6915, 4471, 13], "temperature": 0.0, "avg_logprob": -0.16720260273326526, "compression_ratio": 1.3333333333333333, "no_speech_prob": 5.682382834493183e-06}, {"id": 369, "seek": 301800, "start": 3018.0, "end": 3027.0, "text": " Maybe lambda plus 100 over T two.", "tokens": [2704, 13607, 1804, 2319, 670, 314, 732, 13], "temperature": 0.0, "avg_logprob": -0.15105636303241438, "compression_ratio": 1.443298969072165, "no_speech_prob": 6.893569093335827e-07}, {"id": 370, "seek": 301800, "start": 3027.0, "end": 3036.0, "text": " So now T three is again some map that I could force it to get calculated like so.", "tokens": [407, 586, 314, 1045, 307, 797, 512, 4471, 300, 286, 727, 3464, 309, 281, 483, 15598, 411, 370, 13], "temperature": 0.0, "avg_logprob": -0.15105636303241438, "compression_ratio": 1.443298969072165, "no_speech_prob": 6.893569093335827e-07}, {"id": 371, "seek": 301800, "start": 3036.0, "end": 3040.0, "text": " And as you can see, it's doing each of those functions in turn.", "tokens": [400, 382, 291, 393, 536, 11, 309, 311, 884, 1184, 295, 729, 6828, 294, 1261, 13], "temperature": 0.0, "avg_logprob": -0.15105636303241438, "compression_ratio": 1.443298969072165, "no_speech_prob": 6.893569093335827e-07}, {"id": 372, "seek": 301800, "start": 3040.0, "end": 3046.0, "text": " So this is a really nice way to work with, you know, data sets and data loaders and stuff like that.", "tokens": [407, 341, 307, 257, 534, 1481, 636, 281, 589, 365, 11, 291, 458, 11, 1412, 6352, 293, 1412, 3677, 433, 293, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.15105636303241438, "compression_ratio": 1.443298969072165, "no_speech_prob": 6.893569093335827e-07}, {"id": 373, "seek": 304600, "start": 3046.0, "end": 3055.0, "text": " You can just add more and more processing to them lazily in this way.", "tokens": [509, 393, 445, 909, 544, 293, 544, 9007, 281, 552, 19320, 953, 294, 341, 636, 13], "temperature": 0.0, "avg_logprob": -0.078316863377889, "compression_ratio": 1.3174603174603174, "no_speech_prob": 4.22277571487939e-06}, {"id": 374, "seek": 304600, "start": 3055.0, "end": 3060.0, "text": " OK.", "tokens": [2264, 13], "temperature": 0.0, "avg_logprob": -0.078316863377889, "compression_ratio": 1.3174603174603174, "no_speech_prob": 4.22277571487939e-06}, {"id": 375, "seek": 304600, "start": 3060.0, "end": 3068.0, "text": " So then segmentation. I don't think there's anything interesting there that's any different.", "tokens": [407, 550, 9469, 399, 13, 286, 500, 380, 519, 456, 311, 1340, 1880, 456, 300, 311, 604, 819, 13], "temperature": 0.0, "avg_logprob": -0.078316863377889, "compression_ratio": 1.3174603174603174, "no_speech_prob": 4.22277571487939e-06}, {"id": 376, "seek": 306800, "start": 3068.0, "end": 3086.0, "text": " I'm not going to go into the details of how points and bounding boxes work. But for those of you that are interested in segment in object detection, for example, please do check it out in the code and ask us any questions you have.", "tokens": [286, 478, 406, 516, 281, 352, 666, 264, 4365, 295, 577, 2793, 293, 5472, 278, 9002, 589, 13, 583, 337, 729, 295, 291, 300, 366, 3102, 294, 9469, 294, 2657, 17784, 11, 337, 1365, 11, 1767, 360, 1520, 309, 484, 294, 264, 3089, 293, 1029, 505, 604, 1651, 291, 362, 13], "temperature": 0.0, "avg_logprob": -0.1279393802989613, "compression_ratio": 1.4528301886792452, "no_speech_prob": 2.8129300062573748e-06}, {"id": 377, "seek": 308600, "start": 3086.0, "end": 3099.0, "text": " Because like although there's no new concepts in it, the way that this works so neatly, I think is super, super nice. And if you have questions or suggestions, I would love to hear about them.", "tokens": [1436, 411, 4878, 456, 311, 572, 777, 10392, 294, 309, 11, 264, 636, 300, 341, 1985, 370, 36634, 11, 286, 519, 307, 1687, 11, 1687, 1481, 13, 400, 498, 291, 362, 1651, 420, 13396, 11, 286, 576, 959, 281, 1568, 466, 552, 13], "temperature": 0.0, "avg_logprob": -0.06729597381398647, "compression_ratio": 1.5, "no_speech_prob": 5.173673343961127e-06}, {"id": 378, "seek": 308600, "start": 3099.0, "end": 3108.0, "text": " OK. And then I think what we might do next time is we will look at tabular data.", "tokens": [2264, 13, 400, 550, 286, 519, 437, 321, 1062, 360, 958, 565, 307, 321, 486, 574, 412, 4421, 1040, 1412, 13], "temperature": 0.0, "avg_logprob": -0.06729597381398647, "compression_ratio": 1.5, "no_speech_prob": 5.173673343961127e-06}, {"id": 379, "seek": 308600, "start": 3108.0, "end": 3111.0, "text": " So let's do that tomorrow.", "tokens": [407, 718, 311, 360, 300, 4153, 13], "temperature": 0.0, "avg_logprob": -0.06729597381398647, "compression_ratio": 1.5, "no_speech_prob": 5.173673343961127e-06}, {"id": 380, "seek": 311100, "start": 3111.0, "end": 3119.0, "text": " OK. Thanks, everybody. Hopefully that was useful. See you.", "tokens": [50364, 2264, 13, 2561, 11, 2201, 13, 10429, 300, 390, 4420, 13, 3008, 291, 13, 50764], "temperature": 0.0, "avg_logprob": -0.23684240789974437, "compression_ratio": 0.90625, "no_speech_prob": 4.004258516943082e-05}], "language": "en"}