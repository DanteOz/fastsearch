{"text": " So welcome back everybody thanks for coming, and I hope you had a good week and had a fun time playing around with artistic style I know I did I thought I'd show you So I Tried a couple of things myself over the week with this artistic style stuff Just like I just tried a couple of simple little changes, which I thought you might be interested in Yeah Oh Actually, yeah, okay, so One thing before I talk about the artistic style is I just wanted to point out some of the really cool stuff that people have been contributing Over the over the week if you haven't come across it yet be sure to check out the the wiki so the There's a nice thing in discourse where you can basically set any post as being a wiki which means that anybody can edit it So I created this wiki post early on and by the end of the week we now have all kinds of stuff with Links to the stuff in the class a summary of the paper Examples a list of all the links Both snippets Handy list of steps that are kind of necessary when you're doing style transfer Lots of stuff about the tensorflow dead summit and so forth Wiki threads every week So look out for that and lots of other threads one I saw just this afternoon popped up, which is great from chin chin Talked about trying to summarize what they've learned from Lots of other threads across the weekend. This is really sorry across the forum. This is a great thing that we can all do is you know when you Look at lots of different things and kind of takes notes if you put them on the forum for everybody else This is super handy, and so if you haven't quite caught up on all the stuff going on the forum Looking at this curating lesson 8 experiments thread would be probably a good place to start So a couple of little changes I made in my experiments I tried thinking about like why Quite a few if you pointed out how depending on what your starting point is for your optimizer you get to a very different place and so clearly our convex optimization Is I'm not necessarily finding a local minimum, but at least saddle points is not getting out of so I tried something Which was to create a take the random image and just add a Gaussian blur to it So Gaussian filter is just a blur and so that makes a random image into this kind of thing and I just found that even the Plain style looks a lot smoother. So that was one change that I made which I thought worked quite well Another change that I made just to play around with it was I added a different weight to each of the style layers and So my my zip now has a third thing in which is the weights and I just multiply by the weight So I thought that those two things made my little bird look significantly better than my little bird look before so I was happy with that You could do a similar thing for content loss Also, maybe add more different layers of content loss and give them different weights as well, I'm not sure if anybody's tried that as yet Yes, Rachel a question I have a question regards cartoons The cartoons when we think of transferring the style what we really mean is transferring the contours of the cartoon to redraw The content in that style and this is not what style transferring is doing here. How might one implement this? Yeah, I Don't know that anybody's quite figured that out, but I'll show you a couple of directions that may be useful Yeah, I've tried selecting activations correspond with edges and such as indicated by one of the calm visualization papers and carrying outputs from typically those activation Yeah, yeah, so I'll show you some things I show you some things you could try I haven't seen anybody do a great job of This yet, but yes I mean here's one example from the from the forum is somebody pointed out that this this cartoon approach didn't work very well with dr. Seuss But then when they changed their initial image not to be random but to be the picture of the dog it actually look quite a lot Better so there's one thing you could try There's some very helpful diagrams that some somebody posted which is fantastic. They're summarizing what we learned I like this summary of what happens if you add versus remove each layer So this is what happens if you remove block 0 block 1 block 2 block 3 and block 4 to get a sense of how they Impact things so you can see for the style that the last layer is really important to making it look good At least for this image One If you had some particularly nice examples I love this like that seems like there's a certain taste They're kind of figuring out what photos go with what images I thought this Einstein was terrific. I thought this was terrific as well Brad came up with this really interesting insight that starting with this picture and adding a style to it creates this extraordinary Shape here where as he points out you can tell it's a man sitting in the corner But there's like less than 10 brushstrokes, but sometimes this style transfer does things which are surprisingly fantastic I Have no idea what this is even in the photos So I don't know what it is the painting either, but I guess I don't watch that kind of music enough So there's lots of interesting ideas you can try and I've got a link here and you might have seen it in the PowerPoint to A clear us implementation that has a whole list of things that you can try and Here are some particular examples This is something called and all of these examples you can get the details from this link There's something called chain blurring and for some things. This is this might work well for cartoons notice how the matrix Doesn't do a good job with the cat when you use the classic. This is our paper, right? But if you use this chain blurred approach it does a fantastic job, and so I wonder if that might be one secret to the cartoons Some of you I saw in the forum have already tried this which is using color preservation and luminance matching Which basically means you're still taking the style, but you're not taking the color, and I think in these particular examples This is really great results. I think it depends a lot on what what things you tried with And you can go a lot further For example you can add a mask and then say just do Color preservation for one part of the photo so here the top part of the photo has got color preservation and the bottom hasn't That's pretty cool They even show in that code how you can Use a mask to say one part of my image should not be stylized Again, I'm getting some good results Well this is really crazy use masks to decide which one of two style images to use and Then you can really generate some creative stuff, so there's a lot of stuff that you can play with and You can go beyond this to coming up with your own ideas Now some of the best stuff you're going to learn a bit more today about how to do some of these things better But just to give an idea if you go to like mode net you can literally draw something using All colors and Then choose a style image, and it will turn your drawing Into an image basically the idea being that blue is going to be water and greens going to be foliage And I guess red is going to be foreground So that's there's a lot of good examples of this kind of Neural doodle they call it online Something else we'll learn more about how to do better today is if you go to a fine layer calm There's a very recent paper called pics to pics Which is basically we're going to be learning quite a bit in this class about how to do segmentation Which is where you take a photo and turn it into a colored image basically saying the horse is here the bicycles here the persons Here this is basically doing the opposite is that by drawing something? Saying I want you to create something that has a window here and a windowsill here and a door here and column there and It generates a photo Which is fairly remarkable? So the stuff we've learned so far won't quite get you to do these two things But by the end of today, we should be able to This is a nice example that I think some folks at Adobe built showing that you could basically draw Something and it would try and generate an image that was close to your drawing where you just needed a small number of lines Again, you can find this Will link to this paper from the resources This actually shows it to you in real time. You can see that there's this There's some new way of doing art that's starting to appear where you don't necessarily need a whole lot of technique I'm not promising It's going to turn you into a van Gogh But you can at least generate images that maybe you're in your head in some style that's somewhat similar to somebody else's I think it's really interesting Okay One Thing I was thrilled to see is that at least two of you have already written blog posts on medium That was fantastic to see so I hope more of you might try to do that this week Definitely doesn't need to be something that takes a long time I Know some of you already planned also planning on turning your forum posts into blog posts So hopefully we'll see a lot more blog posts this week popping up I know the people who have done that have found that a useful experience as well, so One of the things that I suggested doing pretty high on the list of priorities for this week's Assignment was to go through the paper Knowing what it's going to say you know I think this is really helpful It's when you already know how to do something is to go back over that paper And this is a great way to learn how to read papers right because you already know what it's telling you This is like the way I Learn to read papers was totally this method so I've kind of gone through and I Have highlighted a few key things which I as I went through I thought were kind of important so in the abstract of the paper But let me ask say how many people kind of went back and re-looked at this paper again But a few of you that's great So In the abstract they basically say what is it they're introducing so it's a system based on a deep neural network that creates artistic images And high perceptual quality okay, so we're going to read this paper and hopefully at the end of it. We all know how to do that Then in the first section They tell us about the basic ideas so when CNN's are trained on object recognition. They developed a representation of an image Along the processing hierarchy of the network it's transformed into representations that increasingly care about the actual content compared to the pixel values So it describes the basic idea of content loss Then they describe the basic idea of style loss Which is looking at the correlations between the different filter responses Over the spatial extent of the feature maps and this is one of these sentences that Read on its own doesn't mean very much And now that you know how to do it you can read it and be like okay I think I see what that means and then when you get to the methods section we learn more So the idea here is that by including the feature correlations and this answers one of the questions that one of you had on the forum By including feature correlations of multiple layers we obtain a multi-scale representation of the input image This idea of a multi-scale representation is something we're going to be coming across a lot because a lot of this as we discussed last week a lot of this class is about generative models and one of the tricky things with generative models is both to get the kind of The general idea of the thing you're trying to generate Correct, but also get all the details correct and so the details generally requires you to zoom into a small scale And getting a kind of the big picture correct is about zooming out to a large scale So this was one of the key things that they did in this paper was show how to create a style representation that included Multiple resolutions, and we know now know that where they did that was to use multiple style layers And as we go through the layers of a GG they gradually become lower and lower resolution larger and larger receptive fields I'm always great to look at the figures and make sure and I was thrilled to see that some of you were trying to Recreate these figures which actually turned out to be slightly non-trivial So we can see exactly what that figure is and if you haven't tried it for yourself yet You might want to try it see if you can recreate this figure Okay It's good to try and find in a paper the key finding you know the key The key thing that they're showing in this case they found that Representations of content and style and a CNN are separable and you can manipulate both to create new images It's again. Hopefully that now you can look at that and say oh, yeah that makes sense You can see that with papers certainly with this paper. There's often quite a lot of Introduction that often says the same thing a bunch of different ways, so it's often worth You know the first time you read it one paragraph might not make sense But later on they say it in a different way, and it starts to make more sense So it's worth looking through the introductory remarks maybe two or three times They can certainly see that again talking about the different layers how they behave Right again showing The results of some experiments so again you can see if you couldn't recreate these experiments make sure that you understand how to do it And then there's a kind of a lot of stuff I didn't find that interesting until we get to the section called methods So the method section is the section that hopefully you'll learn the most about reading papers After you've implemented something by reading the section called methods now. I want to show you a few little tricks of notation You Do need to be careful of little details that fly by like here they used average Pauling yes, that's a sentence which if you weren't reading Carefully you could skip over it now. We know okay. We need to use average Pauling not max Pauling So they will often have a section which explicitly says now. I'm going to introduce the notation This paper doesn't this paper just kind of introduces the notation as part of the discussion But at some point you'll start getting Greek letters or you know things with subscripts or whatever notation starts appearing and so at this point You need to start looking very carefully and at least for me I find I have to go back and read something many times to remember. What's L? What's M? What's M? Okay, this is the annoying thing with math notation is the single letters. They generally don't have any kind of mnemonic Often though you'll find that across papers in a particular field They'll tend to reuse the same kind of English and Greek letters for the same kinds of things All right, so M will generally be the number of rows Capital M capital N will often be the number of columns K will often be the index that you're summing over so on and so forth So here we've got The first thing which is introduced is X with an arrow on top so X with an arrow on top means it's a vector, right? It's actually an input image But they're going to turn it into a vector by flattening it out So okay So our image is called X and then the CNN has a whole bunch of layers and Every time you see something with a subscript or a superscript like this you need to look at both of the two bits because they've Both got a meaning right the thing the big thing is like the main object so in this case a capital N is a filter and then the subscript or superscript is like In an array or a tensor in Python. It's like the thing in square brackets, right? so each filter has A letter L which is like which number of the filter is it and so often as I read a paper I'll actually try to write code as I go and like put little comments so that I like right Layer square bracket layer number close square bracket, and then I have a comment after they like Just to remind myself, so I'm creating the code and mapping it to the letters so there are NL filters We know from a CNN that each filter creates a feature map. So that's why there are NL feature maps I remember anytime you see the same letter it means the same thing within a paper not necessarily across papers Each feature map is of size M. And as I mentioned before M tends to be rows M tends to be columns So here it says M is the height times the width of the feature map so here we can see okay They've they've done dot flat Basically to make it all one row Okay Now this is another piece of notation You'll see all the time a layer L can be stored in a matrix called F and now the L has gone to the top Doesn't matter same basic idea. It's just an index so the matrix F is going to contain our activations and This thing here where it says are with a little superscript. This has a very special meaning It's referring to Basically what is the the shape of this so when you see this shape it says these are our means that their floats And this thing here means it's a matrix you can see the X. So it means it's rows by columns So there are n rows and m columns in this matrix and every matrix there's one matrix for each layer and There's different number of rows and different number of columns for each layer so you can basically go through and Map it to the code that you've already written So I'm not going to read through the whole thing, but there's not very much here And it'd be good to make sure that you understand all of it perhaps with the exception of the derivative because we don't care about derivatives because They get done for us. Thanks to the I know in TensorFlow, so You can always skip the bits about derivatives Okay So then they do the same thing basically describing the Gram matrix So they show here that the basic idea of the gram matrix is that they create? an inner product between the vectorized feature map I And J so vectorized here means turned into a vector so the way you turn a matrix into a vector is flattened This means the flattened inner product between the flattened feature maps so those matrices we saw Yeah, so Hopefully you'll find this helpful You'll see there'll be like small little differences so rather than Taking the mean they tend to use here the sum and then they kind of Divide back out the number of rows and columns to kind of create the mean this way in our code We actually put the division inside the sum so you see these little differences of how we implement things And sometimes you may seem see actual Meaningful differences, and that's often a suggestion of like oh, there's something you could try you know some differences you could try Okay, so that describes the Notation and the method and that's it But then very importantly is throughout this any time you come across some concept Which you're not familiar with it'll pretty much always have a reference a citation right so you'll see there's Little numbers all over the place There's lots of different ways of doing these references But anytime you come across something Which has a citation like it's a new piece of notation or a new concept you don't know what it is Generally the first time I see it in a paper I ignore it right, but if I keep reading and it turns out to be Something that actually is important, and I can't understand the basic idea at all I generally then put this paper aside I put it in my to read file and Make the new paper I'm reading the thing that it's citing because like very often a paper is entirely meaningless until you've read One or two of the key papers. It's based on Sometimes this can be like reading the dictionary if you don't yet know English it can be like layer upon layer of citations and at some point you have to stop I Generally thought you should I think you should find that the basic set of papers that things refer to is Pretty much all stuff you guys know at this point, so I don't think you're going to get stuck in an infinite loop But if you ever do You know let let us know in the forum, and we'll try and help you get unstuck Or if there's any notation you don't understand let us know Another of the horrible things about math is it's very hard to search for you know It's not like you can take that function name and search for Python in the function name instead of some weird squiggly shape So again feel free to ask If you're not sure about that There is a great Wikipedia page which lists But I think it's just called Notate out math notation or something which lists pretty much every piece of notation There are various places you can look up notation as well Okay, so that's the paper So let's let's move to the next step I Think what I might do is kind of try and Draw the basic idea of what we did before so that I can draw the idea of what we're going to do differently this time So previously and now this thing is actually calibrated. You'll be pleased to hear we had an a random image and we had a Lost function so this doesn't matter what the loss function was right we know that it happened to be a combination of style loss plus content loss right and what we did was we took our image and We're our random image, and we put it through This loss function, and we got out of it two things one was the loss and the other was the gradients and then we use the gradients with respect to the original pixels to Change the original pixels Right and so we basically repeated that loop again and again and the pixels gradually changed to make the loss Go down, so that's the basic approach that we just used It's a perfectly fine approach for what it is and in fact for if you are Wanting to do lots of different photos with lots of different styles Like if you created a web app where you said, please upload any style image and any content image Here's your artistic style version This is probably still the best Particularly with some of those tweaks I talked about But what if you wanted to create a web app? that was a Van Gogh irises generator upload any image, and I will give you that image in the style of van Gogh's irises You can do better than this approach And the reason you can do better is that we can do something where you don't have to do a whole optimization Run in order to create that output Instead we can train a CNN to learn to output photos in the style of van Gogh's irises The basic idea is very similar What we're going to do this time is we're going to have lots of images All right, and we're going to take each image and we're going to feed it into The exact same loss function that we used before All right with a style loss. That's the content loss right, but we're going to use for the style loss. We're going to use Van Gogh's irises And for the content loss we're going to use the image that we're currently looking at we've got lots of images we're going to go through And what we do is we're going to rather than changing the pixels of the original Photo instead what we're going to do is we're going to train a CNN or a whole bunch of layers of a CNN We're going to train a CNN to take this Thing the best way to show you this let's move this out of the way Yeah That's better. So Let's put a CNN in the middle. These are the layers of the CNN right and we're going to try and get that CNN To spit out a new image, so there's an input image and There's an output image and this new CNN we've created is going to spit out An output image that when you put it through this loss function Hopefully it's going to give a small number and if it gives a small number it means that the Content of this photo still looks like the original photo is content and the style of this new image Looks like the style of van Gogh's irises So if you think about it when you have a CNN You can really pick any loss function you like right we've tended to use some pretty simple loss functions so far like means great error or cross-entropy In this case we're going to use a very different loss function which is going to be Style plus content loss using the same approach that we used just before right and because that was generated by a Neural net we know it's differentiable and you can optimize any Loss function as long as the loss function is differentiable so if we now basically take the gradients of This output not with respect to the input image, but with respect to the CNN weights, and we can take those gradients And use them to update the weights of the CNN So that the next iteration through the CNN will be slightly better at turning That image into a picture that has a good style match with van Gogh's irises Does that make sense so at the end of this we run this through lots of images Just we're just training a regular CNN and the only thing we've done differently is to replace the loss function with the style loss plus content loss That we just used and so at the end of it we're going to have a CNN that has learned to take any photo and We'll spit out that photo in the style of van Gogh's irises And so this is a win because it means now in your web app, which is your van Gogh irises generator You now don't have to run an optimization path on the new photo. You just do a single forward pass to a CNN, which is instant Yes, green box over there So this Filters you use right Significantly if you like let's say you have Photoshop and you want to change multiple styles Yeah, this is going to this is going to each neural network. It's going to learn to do just one type of style Their way of like combining multiple styles or is it just going to be a combination of all you can combine multiple styles By just like having multiple bits of style loss for multiple images But you're still going to have the problems that that Network has only learned to create one kind of image All right It hasn't learned now it may be possible to create to train it so that takes both a style image and a content image But I don't think I've seen that done yet Having said that there is something simpler and in my opinion more useful we can do Which is rather than doing style loss plus content loss Let's think of another interesting problem to solve which is called super resolution Super resolution is something which Honestly when Rachel and I started playing around with it a while ago. Nobody was that interested in it But in the last year or so it's become really hot Yes, Rachel Yeah, yeah, so we were kind of playing around with it quite a lot We thought it's really interesting, but suddenly it's got hot and the basic idea of super resolution Is that you start off with a low res photo? And so the reason I started getting interested in this was I wanted to help my mom Take her family photos that were often Pretty low quality and blow them up into something that was big and high quality that she could print out So that's what you do is you're trying to take something which starts with a small low res photo and Turns it into a big high res photo L are low res HR high res Now perhaps you can see that we can use a very similar technique for this What we could do is between the low res photo and the high res photo we could introduce a CNN Right and what that's a and that CNN could look a lot like the CNN from our last idea But it's taking in as input a low res image and then it's sticking it into a loss function and The loss function is only going to calculate Content loss and the content loss it will calculate is between the Input that it's got from the low res after going through the CNN compared to The activations from the high res so in other words has this CNN Successfully created a bigger photo that has the same activations as the high res photo does and so if we pick the right layer For the high res photo and that ought to mean that we've constructed a new image. What's that Rachel? There's a question Yes, absolutely and this is one of the things I wanted to talk about today is In fact, I think it's at the start of the next paper. We're going to look at is they even kind of talk about this And so this is the paper we're going to look at today Perceptual losses for real-time style transfer and super resolutions. This is from 2016 So it took like about a year or so to go through the thing. We just saw to this next stage. Is that right? Maybe half a year, okay So what they point out in the abstract here is that people had done super resolution with CNNs before But previously the loss function they used was simply the mean squared error between the pixel outputs of the upscaling network and the actual high res image And the problem is that it turns out that that tends to create blurry images and it tends to create blurry images because the The CNN has no reason not to create blurry images And blurry images are actually tend to look pretty good in the loss function because as long as you get the general You know, oh, this is probably somebody's face. I'll put like a face color here, but then it's going to be fine Where else if you take the second or third conv block of VGG? Then it needs to know that this is an eyeball or it's not going to look good, right? It needs to know that this is a nose. It's not going to look good So if you do it not with pixel loss, but with the content loss we just learned about You're probably going to get better results so this Like many papers in deep learning this paper introduces its own Language and in the language of this paper perceptual loss is what they call the mean squared errors between the activations of A network with two images. So the thing we've been calling content loss they call perceptual loss So One of the nice things they do at the start of this and I really like it when papers do this is to say Okay, why is this paper important? Well, this paper is important because many problems can be framed as image transformation tasks Where a system receives some input and chucks out some other output for example Denoising learn to take an input image that's full of noise and spit out a beautifully clean image Super resolution take an input image, which is low res and spit out a high res Colorization they can input image which is black and white and spit out something which is color Now one of the interesting things here is that all of these examples you can generate as much input data as you like by taking lots of images which are either from your camera or you download off the internet or from image net and You can make them lower res. You can add noise You can make them black and white right so you can generate as much level data as you like that's one of the really cool things about this whole topic of Generators Well with that example so Going to lower res imagery or some camera It's it's algorithmically done, so it's the known that only going to learn how to like Algorithmically done versus an actual low res imagery that doesn't Yeah, so one thing I just mentioned is the way you would create your label data is not to do that low res on the Camera you would grab the images that you've already taken and make them low res just by doing A Filtering you know in OpenCV or whatever And yeah, that is algorithmic And it may not be It may not be perfect, but there's lots of ways of generating that low res image. You know you can add Yeah, so there's lots of ways of creating a low res image so part of it is about How do you do that creation of low res image? How well do you match the? Real low res data you're going to be getting Then the end in this case things like low resolution images or black and white images It's so hard to start with something which is like it could be like and I've seen versions with just an 8x8 picture and turning it into a photo like It's so hard to do that regardless of how that 8x8 thing was created that often the details of how the Low res image was created don't really matter too much There are some other examples they mentioned which is turning an image into an image which includes segmentation We'll learn more about this in coming lessons But segmentation refers to taking a photo of something and creating a new image that basically has a different color for each object So horses are green cars are blue buildings are red that kind of thing So that's called segmentation as you know from things like the fisheries competition Segmentation can be really important as a part of solving other bigger problems Another example they mentioned here is depth estimation. There's lots of important reasons. You would want to use depth estimation for example Maybe you want to create some fancy video effects where you start with a flat photo, and you want to create some cool new Apple TV thing that like Moves around the photo with a parallax effect. You know So if you were able to use a CNN to figure out how far away every object was automatically And you could like turn a 2d photo into a 3d image automatically so yeah taking An image in and sticking an image out is kind of the idea in computer vision at least of generative networks So generative models, and so this is why I wanted to talk a lot about generative models during this class It's not just about Artistic style artistic style was just my sneaky way of introducing you to the world of generative models Okay, so let's look at how to create this Super resolution idea and your homework or part of your homework this week will be to create the New approach to style transformation New approach to style transfer, okay, so I'm going to build the super resolution version Which is a slightly simpler version, and then you're going to try and build on top of that to create the style transfer, okay? so Make sure you let me know if you're not sure at any point So I've already created a folder of 20,000 a sample of 20,000 image net images And I've created two sizes one is 288 by 288 and one is 72 by 72 and They're available as be calls arrays Okay, so I actually posted the link to these last week, and it's on platform.fast.ai So we'll open up those be calls arrays And one trick you might have hopefully learned in part one is that you can turn a be calls array Into a numpy array by slicing it with everything So anytime you slice the be calls array you get back a numpy array So if your slice is everything then this turns it into a numpy array. This is just a convenient way of Sharing numpy arrays in this case, so we've now got an array of low resolution images and an array of high resolution images So let me start start maybe by showing you the Final network Okay, this is the final network So we start on off by taking in a batch of images low res images And the very first thing we do is stick them through a convolutional block With a stride of one okay, so this is not going to change its size at all but this convolutional block has a filter size of 9 and It generates 64 filters So this is a very large Filter size okay nowadays filter sizes tend to be 3 Actually in a lot of modern Networks the very first layer is very often a large filter size Just the one just one very first layer and the reason is that it basically allows us to immediately increase the receptive field of all of the layers from now on right so by having 9 by 9 And we don't lose any information because we've gone from three channels to 64 filters Right so each of these 9 by 9 convolutions can actually have quite a lot of information because you've got 64 filters So you'll be seeing this quite a lot in in modern CNN architectures just a single Large filter conflare, so this won't be unusual in the future Now the next thing Green box Oh just a moment, sorry yeah this slide one also Yeah, well the stride one is Important for this first layer because you don't want to throw away any information yet right so in the very first layer We want to keep the full image size so with a stride one it doesn't change it doesn't down sample at all Yeah, they overlap a lot absolutely but that's okay a good Implementation of a convolution is going to hopefully Memorize some of that or at least keep it in cache, so hopefully won't slow it down too much One of the discussions, I was just having during the break was like How How practical you know are the things that we're learning at the moment compared to like part one where everything was just designed entirely? To be like here the most practical things which we have best practices for And the answer is like a lot of the stuff. We're going to be learning No one quite knows how practical it is because a lot of it's just hasn't really been around that long Stored and maybe there aren't any great libraries for it yet, so one of the things I'm actually hoping from this part two is by learning The edge of research stuff or beyond amongst a diverse group is That some of you will look at it and think about your whatever you do nine to five Or eight to six or whatever and think oh, I wonder if I could use that for this If that ever pops into your head, please tell us right please talk about it on the forum because that's that's what we're most interested In it's like oh you could use super resolution for blah or Depth finding for this or generative models in general for this thing you know I do in pathology or architecture or Satellite engineering or whatever so Yeah, so it's going to require some imagination Sometimes on your part and so often that's why I do want to spend some time looking at stuff like this Where it's like okay? What are the kinds of things? That this can be done for but one of the you know I'm sure you know in your own field like one of the differences Between an expert and beginner is the way an expert can look at something In first principles and say okay, I could use that for this totally different thing Which has got nothing to do with the example that was originally given to me because I know that The basic steps are the same right and that's what? I'm hoping you guys will will be able to do is kind of not just say This is right batteries again, just like this in You Yeah, it's not to say okay now. I know how to do artistic style You know are there things in your field which have some similarities to? So we were going to talk about the super resolution network And we talked about the idea of the initial con block so After the initial conf block we have the computation now when I say the computation and any kind of generative network There's like the extra the key work. It has to do which in this case is starting with a low res image figure out like What might that black dot be is it is it an eyeball or is it like is it a wheel? Like it basically if you want to do really good Upscaling you actually have to figure out what the objects are so that you know what to draw Right so that's kind of like the key computation this CNN is going to have to learn to do in Generative models we generally like to do that computation at a low resolution There's a couple of reasons why the first is that at a low resolution. There's less work to do so the computation is faster But more importantly at higher resolutions where generally means we have a Smaller receptive field it generally means we have less Ability to kind of capture large amounts of the image at once and if you want to do really Really great Kind of computations where you recognize that all this this blob here is a face And therefore the dot inside it is an eyeball then you're going to need enough of a receptive field to cover That whole area I noticed a couple of you asked for information about receptive fields on the forum thread so There's quite a lot of information about this online so Google is your friend here, but the basic idea is If you have a single convolutional filter of 3x3 the receptive field is 3x3 So it's how much space can that convolutional filter impact Okay, so here's a 3x3 filter now on the other hand what if you had a 3x3 filter Which had a 3x3 filter as its input right so that means that the center one Took all of this right, but what did this one take well this one would have taken depending on the stride Probably these ones here right and this one over here would have taken These ones here so in other words in the second layer I'm assuming a stride of one the receptive field is now 5 by 5 Not 3 by 3 so the receptive field depends on two things one is how many layers deep are you and The second is how much did the previous layers either have a non unit stride or maybe they had max pooling Right so in some way they were coming down sample those two things increase the receptive field And so the reason it's great to be doing Layer computations on a large receptive field is that it then allows you to look at the big picture and look at the context It's not just edges anymore, but the eyeballs and and noses So in this case we have four blocks of computation where each block is a ResNet block So for those of you that don't recall How resnet works it would be a good idea to go back to part one and review But to remind ourselves, let's look at the code Here's a resnet block so all the resnet block does is it takes some input and It does two convolutional blocks on That input and then it adds The result of those convolutions back to the original input so you might remember from part one We actually kind of drew it we said there's some input and it goes through two convolutional blocks and Then it goes back and is added to the original right and if you remember we basically said in that case We've got y equals x plus some function of x Right which means that the function Equals Y minus X and this thing here is a residual right so a whole stack of residual blocks ResNet blocks on top of each other can learn to gradually get hone in on Whatever is whatever it's trying to do in this case what it's trying to do is get the information It's going to need to upscale this in a smart way so We're going to be using a lot more of this idea of kind of taking Blocks that we know work well for something and just reuse them right and so then What's a conv block well all the conv block is in this case is it's a? convolution followed by a batch norm Optionally followed by an activation and one of the things we now know about ResNet blocks is that we generally don't want An activation at the end and that's one of the things that a more recent paper Discovered so you can see that for my second conf block. I have no activation I'm sure you've noticed throughout this course that I Refactor my network architectures a lot my network architectures don't generally list every single layer But they're generally functions which have a bunch of functions which have a bunch of layers in a lot of people don't do this like a lot of the Architectures you find online are like hundreds of lines of layer definitions. I think that's crazy It's so easy to make mistakes when you do it that way and so hard to really see what's going on So you know in general I would strongly recommend that you try to refactor your Architectures so that by the time you write the final thing it's you know half a page And you'll see plenty of examples of that so hopefully that'll be helpful All right, so we've Increased the receptive field we've done a bunch of computation, but we still haven't actually changed the size of the image Which is not very helpful, so the next thing we do is we're going to change the size of the image and The first thing we're going to learn is to do that with something that goes by many names Decomposition One is deconvolution another is it's also known as transposed convolutions And it's also known as fractionally strided Convolutions In Keras they call them D convolutions And the basic idea Is something which I've actually got a spreadsheet to show you Okay, so here's a spreadsheet here's a spreadsheet The Basic idea is that you've got some kind of image, so here's a 4x4 Image some 4x4 data right and you put it through a 3x3 filter convolutional filter And if you're doing Valid convolutions, then that's going to leave you with a 2x2 output Because here's one 3x3 another 3x3 Or of them and so each one is Having the whole filter and the appropriate part of the data, that's just a standard 2d convolution That's so we've we've done that now. Let's say We want to undo that right we want something which can take this result and recreate This input right how would you do that? So one way to do that would be to take this result right so let's copy it over here right and put back that implicit padding so it's Surrounded with all these zeros such that now if we use And let's have some filter, we just started at zero right we have some Convolutional filter right and we're going to put it through this entire Matrix a bunch of zeros with our result matrix in the middle Right and then we can calculate our result in exactly the same way just a normal convolutional filter so if we now use gradient descent We can look and see okay. What is the error right so how much does this? pixel differ from this pixel right and how much does This pixel different from this pixel, and then we add them all together to get our mean squared error So we can now use gradient descent Which hopefully you remember from part one in Excel is called solver and We can say okay Set this cell to a minimum By changing these cells right so this is basically like the simplest possible Optimization solve that And here's what it's come up with right so it's come up with a convolutional filter You'll see that the result is not exactly the same as the original data and of course how could it be right? We don't have enough information. We only have four things that try and regenerate 16 things But it's not terrible right and in general this is This is the challenge with upscaling right when you've got something that's blurred and down sampled You've thrown away information, and so the only way you can get information back is to guess what was there? But the important thing is that by using a convolution like this We can learn Those filters so we can learn how to up sample it in a way that gives us the loss that we want So this is what a D convolution is it's just a convolution on a padded input Right now in this case. I've assumed that my convolutions had a unit stride I there was just one pixel between each convolution if your Convolutions are of stride to that it looks like this picture Okay, and so you can see that as well as putting the two pixels around the outside We've also put a zero pixel In the middle that so these four cells is now our data cells And you can then see it calculating a convolution through here I strongly suggest looking at this link which is where this picture comes from And in turn This link comes from a fantastic paper Called the convolution arithmetic guide Which is a really great paper, and so if you want to know more about both convolutions and D convolutions you can look at this Page and it's got lots of beautiful animations including Animations on they call it transposed convolutions So you can see You There you go, this is the one I just showed you right, so that's the one we just saw in Excel So that's a good really great site Okay, so that's what we're going to do first is we're going to Do D convolutions so in Keras a D convolution is exactly the same as convolution Except with D on the front, but all the same stuff. How many filters do you want? What's the size of your filter? What's your stride or sub sample as they call it border mode so forth? We have a question if tensor flows the back end shouldn't the batch normalization axis equals negative one And then there was a link to GitHub conversation where Francois yeah said that for Theano accesses one yeah, no it should be and in fact Access minus one is the default Yes Well spotted Thank David Gutman He is also responsible for some of our beautiful pictures. We saw earlier Double thing Let's remove And go faster as well So just in case you weren't clear on that you might remember from part one that we reason we had that axis equals one is Because the I know that was the channel axis right so we basically wanted not to throw away the XY information but normal cross channels In Theano and channel is now the last axis and since minus one is the default we actually don't need that Okay, so that's our deconvolution blocks, and so we're using a Stride of two comma two right so that means that each time we go through this deconvolution It's going to be doubling the size of the image For some reason I don't fully understand and haven't really looked into in Keras you actually have to tell it the shape of the output So you can see here. I've actually you can actually see it's gone from 72 by 72 to 144 by 144 To 288 by 288 right so because these are convolutional filters It's learning to upscale right, but it's not upscaling with just three channels. It's upscaling with 64 filters So that's how kind of say we're to do more sophisticated stuff And then finally We we're kind of reversing things here. We have another three by another nine by nine convolution In order to get back our three channels so the idea is we previously had something with 64 channels and So we now want to turn it into something with just three channels the three colors and to do that we want to use quite Context So we have a 9 by 9 single 9 by 9 filter at the end to get our three channels out So at the end we have a 288 by 288 by 3 That's in other words an image So if we go ahead now and train this Then it's going to do basically what we want, but the thing we're going to have to do is to create our loss function right and creating our loss function is A little bit messy, but I'll take you through it slowly and hopefully it'll all make sense So we've taken just to remember some of the symbols here input imp is the original low resolution input tensor and Then the output of this is called out P output and so let's call this whole network here Let's call it the up sampling network, right so this is the thing that's actually responsible doing the outside so we're going to take the up sampling network and we're going to attach it to VGG and The VGG is going to be used only as a loss function Right to get the content loss So before we can take this output and stick it into VGG We need to stick it through our standard mean subtraction pre-processing So this is just the same thing that we did over and over again in part one So let's now define and This output as being this lambda function applied to the output of our up sampling Network okay, so that's what this is this is just our pre-processed up sampling network output So we can now create a VGG network And let's go through every layer and make it not trainable Right like you can't ever make your loss function be trainable The loss function is the fixed in stone thing that tells you how well you do so clearly you have to make sure VGG is not trainable Right now which bit of the VGG network do we want we can try a few things I'm using block to come to Okay, so relatively early and the reason for that is that if you remember when we did the content reconstruction Last week the very first thing we did we found that if you could basically totally reconstruct the original image from early layer activations Whereas by the time we got to layer 4 So block 4 we've got pretty horrendous things right so we're going to use a somewhat early block as our Content loss or as the paper calls it the perceptual loss and you can play around with this see how it goes All right, so now we're going to create two versions of this VGG output and this is something which is I think very poorly understood or appreciated with the Keras is functional API Which is any kind of layer and the model is a layer as far as Keras is concerned can be treated as if it was a function right so we can take this model and pretend it's a function and We can pass it any tensor And what that does is it creates a new model where those two pieces are joined together, right so VGG 2 is now equal to this model on the top and this model on the bottom and remember this model was the result of our upsampling network followed by pre-processing and In the upsampling network is the lambda function to normalize the output image Yeah, that's a good point so we use a fan activation which can go from negative 1 to 1 So if you then go that plus 1 times 127 and a half that gives you something that's between 0 and 255 Which is the range that we want? Interestingly this was suggested in the original paper and supplementary materials More recently in on reddit I think it was the author said that they tried it without the fan activation and therefore without the final Deprocessing and it worked just as well, so you can try Doing that if you wanted to try it you would just remove the activation, and you would just remove this last thing entirely But obviously if you do have a fan Then you need the output and this is actually something I've been playing with with a lot of different Models any time I have some particular range that I want when where to enforce that is by having a Fan or sigmoid followed by something that turns that into the range you want it's not just the images Okay, so we've got two versions of our BGG layer output one which is based on the output of the upscaling network and the other which is based on Just an input right and this just an input is using the high resolution shape as its input Right so that makes sense because this BGG network Is something that we're going to be using at the high resolution scale we're going to be taking the high resolution Target image and the high resolution up sampling result and comparing them, okay? So now that we've done all that we're nearly there. We've now got the high res Perceptual activations, and we've got the low res up sampled perceptual activations We now just need to take the mean sum of squares between them and here it is here In Keras anytime you put something into a network it has to be a layer So if you want to take it just a plain old function and turn it into a layer You just chuck it inside a lambda a capital L lambda So that's all that's for so our final model is going to take our up sampled input and our sorry our low res input and our high res input as our two inputs and Return this loss functions and output Okay one last trick When you fit things in Keras it assumes that you're trying to take some output and make it close to some target In this case our loss is the actual loss function. We want it's not that there's some target, right? We want to make it as low as possible Since it's the sum of squared errors Or mean squared error actually It can't go beneath zero So what we can do is we can basically check Keras and say that our target for the loss is zero And you can't just use the scalar zero remember every time we have a target set of labels in Keras You need one for every row right and you've won for every input so we're going to create an array of zeros Okay, so that's that's just so that we can fit it into what Keras expects and I kind of find that increasingly as I start to move away from the kind of You know the well-trodden path of deep learning more and more you know particularly if you want to use Keras You kind of have to do weird little hacks like this so so be it is a weird little thing There's probably more elegant ways of doing this, but this works So we've got our loss function that we're trying to get every row as close to zero as possible We have a question if we're only using up to block to conv to could we pop off all the layers afterwards? To save some computation sure sure wouldn't be a bad idea at all Okay, so we compile it we fit it one thing you'll notice. I've started doing is using I Did here This callback called TQ DM notebook callback TQ DM is a really terrific library Basically it does something very very simple Which is to add a process here add a progress meter to your loops You can use it in a console as you can see and so basically where you've got a loop You can add TQ DM around it right and That loop does just what it used to do, but it gets its progress It even guesses. You know how much time is left and so forth You can also use it inside a Jupiter notebook And it creates a neat little Neat little graph that gradually goes up and shows you how long is left and so forth so this is just a nice little trick Use some learning rate annealing and At the end of training it for a few epochs We can try out a model now the model. We're interested in is just the up sampling model right we're going to be feeding the up sampling model Low res inputs and getting out the high-res outputs. We don't actually really care about the value of the loss So I'll now define a model which takes as input the low-res input and spits out this output now high-res output So with that model we can try it call predict So here is our original low resolution mashed potato And here's a high resolution measure here, and it's it's amazing what it's done like you can see in the original Like the shadow of the leaf was very unclear the kind of the bits in the mashed potato. We're just kind of vague blobs In this version we have like bare shadows hard edges and so forth Question can you explain the size of the target it's the first dimension of the high-res times 128 Why? You It's the okay, so I see it's this number, so this is the basically the number of images that we have And then It's 128 oh It's 128 because that layer has 128 filters So this ends up giving you The mean squared error of 128 filter losses Well since I did this Yes, and then there was another question would popping the unused layers really save anything Aren't you only getting the layers you want when you do the BGG dot get layer block to conju too? Yeah, I'm not sure I I Don't I can't quite think quickly enough you could try it it might not help And intuitively what features is this model learning? But what it's learning is it's looking at 20,000 images Very very very low resolution images like this and it's learning like When there's a kind of a soft gray bit next to a hard bit you know in certain situations That's probably a shadow and when there's a shadow. This is what a shadow looks like example. It's learning that when there's a curve It doesn't actually meant to look like a jagged edge, but it's actually meant to look like something smooth No, it's really learning What the world looks like you know and then? when you take that world and Lower it and make it small you know what does it then look like and so it's just like when you When you look at a picture like this and particularly if you like That it blur your eyes and defocus your eyes you you can often see You know what it originally looked like because your brain basically is doing the same thing It's like when you read a really blurry text you can still read it because your brain is thinking like it knows I got that must be You So are you suggesting there is a similar universality on the other way around like you know when BGG saying the first layer is a learning a line and then a square and No, sir. I are you saying the same thing is true in this case. Yeah It has to be like there's no way to Up sample Like there's a number of ways you can assemble this lost information So in order to do it in a way that decreases this loss function It actually has to figure out you know what what's probably there But don't you agree Just intuitively thinking about it like example of the you say suggesting like the album of pictures for your mom would you think like Be a bit easier if we're just feeding it pictures of humans because it's like the Interaction of the circle of the eye and the nose So the in the extreme versions of super resolution networks, so they take eight by eight inches You'll see that all of them pretty much the same data set So they put so that a so that is a data set of pictures of celebrity spaces And also every spaces are pretty similar, you know and so they show these fantastic And they are fantastic and amazing results, but they're taken a play a turn of the future of the place and it looks Pretty close, right? That's because they've taken advantage of this if you in our case. We've got 20,000 images from a thousand categories It's not going to do nearly as well If we wanted to do as well as the select a versions we would need hundreds of millions of images Yeah, it just is hard for me to imagine mashed potatoes in a face count like in the same category that's my So And so Examples Writing and Pictures and whatever so you know for your examples You're most likely to be doing stuff which is more demand specific and so you should use more demand specific data These kind of issues That's a question, thank you Okay, so One thing I mentioned here is I haven't used a test set so another piece of the homework is to Add in a test set right and and and tell us Is this mashed potato? Overfit right is this actually just matching the particular Training set version of this mashed potato or not and if it is overfitting can you can you create something that doesn't fit? So there's another piece of homework so it's very simple now to take this and Turn it into our fast style transfer so the fast style transfer is going to do exactly the same thing But rather than taking something turning something low res into something high res It's going to take something That's a photo and turn it into Van Gogh's irises So we're going to do that in just the same way we're going to rather than go from low res through a CNN to find the content loss against high res We're going to take a photo Go through a CNN and do both style loss and content loss against a single fixed style image I've given you links here, so I have not implemented this for you This is for you to implement, but I have given you links to the original paper and very importantly also to the supplementary material Which is a little hard to find because there's two different versions and only one of them is correct And of course I don't tell you which one is correct So the supplementary material goes through all of the exact details of What was their loss function? What was their processing? What was their exact architecture? And so on and so forth So while I wait for that to load Yeah Like we did a doodle regeneration using the models photographers weights Could we create a regular image to see how you would look if you were a model? I? Don't know I'm not exactly if you could come up with a loss function Which is how much does somebody look like a model you could so you'd have to come up with a loss function And and it had to be something where you can generate label data One of the things they mentioned in the paper is that they found it very important to add quite a lot of padding and Specifically they didn't add zero padding you know normally we just had a black border, but they add reflection padding so reflection padding Literally means take the edge and reflect it your padding I've written that for you because there isn't one But you may find it interesting to look at this because this is like one of the simplest examples of a custom layer All right, so we're going to be using custom layers more and more and so I don't want you to be afraid of them So a custom layer in Keras is a Python class So if you haven't done that as I mentioned before for the class started if you haven't done OO programming in Python now's a good time to go and look at some tutorials because we're going to be doing Quite a lot of it take leave a pie torch pie torch absolutely relies on it, so we're going to create a class it has to inherit from layer and Python this is how you can create a constructor Python's always syntax is really gross you have to use this special weird custom name thing which happens to be the constructor Every single damn thing inside a class you have to manually type out self comma as the first parameter if you forget you'll get stupid errors Sorry, it's not my fault And then in the constructor for a layer This is basically a way you just save away any of the information you were given so in this case you need you've said that I want this much padding so you just have to save that somewhere say I need this much padding And then you need to do two things in every Keras custom layer One is you have to define something called get output shape for That is going to pass in The shape of an input and you have to return What is the shape of the output that that would create so in this case if s is the shape of the input? then the output is going to be the same batch size and the same number of channels and Then we're going to add in twice the amount of padding Both the rows and columns, but this is going to tell it Because remember one of the cool things about Keras is like you just check the layers on top of each other and it magically knows How big or the intermediate things are it magically knows because every layer has this thing defined. That's how it works The second thing you have to define is something called call and Call is the thing which will get your layer data, and you have to return Whatever your layer does right and in our case we want to Cause cause it to add reflection padding and in this case So happens that tensorflow has something built in for that called TF dot pad Obviously generally it's nice to create Keras layers that would work with both the ano and tensorflow backends By using that capital K dot notation But in this case the ano didn't have anything obvious that it is easily and since it was just for our class I just decided just to make it tensorflow Okay So here is a complete Layer I can now use that layer in a network definition like this I can call dot predict which will take an input and Turn it into you can see that the bird now has the left and right sides here have been reflected Okay, so That is there for you to use because in the supplementary material for the paper They add that they add spatial reflection padding the beginning of the network and they add a lot 40 by 40 and The reason they add a lot is because they mentioned in the supplementary material that they don't want to use Same Convolutions they want to use valid convolutions in their computation because if you add any black borders during those computation steps it Creates weird artifacts on the edges of the images, so you'll see that through this computation of all their residual blocks The size gets smaller by 4 each time and that's because these are valid convolutions, so that's why they have to add padding to the start So that these steps don't cause the image to become too small So this section here should look very familiar Because it's the same as our app sampling network a bunch of residual blocks To D convolutions and one 9 by 9 convolution, right so this is identical so you can copy it This is the new bit right and so Why do we have we've already talked about why we have this 9 by 9 conv, but why do we have these? down sampling convolutions to start with we start with an image up here of 336 by 336 and we have its size and then we have its size again Why do we do that? Like the reason we do that Is that as I mentioned earlier we want to do our computation? at a lower resolution Because it allows us to have a larger receptive field and it allows us to do less computation, so this this pattern where It's like reflective right like the last thing is the same as the set the top thing the second last thing It's the same as the second thing you can see it's like a reflection symmetric It's really really common in generative models is first of all to take your object downsample it Increasing the number of channels at the same time so you're increasing the receptive field you're creating more and more complex representations You then do a bunch of computation on those representations, and then at the end you up sample again So you're going to see this pattern all the time, and so that's why I wanted you guys to Implement this yourself Okay, so There's that right that's the last major piece of your homework There's questions about what is stride equals one half mean That's exactly the same as deconvolution strive to so I remember I mentioned earlier that another name for deconvolution is fractionally strided convolution So you can remember that little picture we saw this idea like he puts Little columns and rows of zeros in between each row and column, so that's we kind of think of it as doing like a half stride at a time So that's why yeah, this is exactly what we already have I don't think you need to change it at all. I'll accept you'll need to change my same convolutions to valid convolutions But This is well worth reading the whole supplementary material because it really has The details and it's it's so great when a paper has supplementary material like this you'll often find in fact the majority of papers Don't actually tell you the details of how to do what they did and many don't even have code These guys both have code and supplementary material which makes this absolute a plus better Classics works great Okay, so that is super resolution perceptual losses and so on and so forth Let's make sure I don't have any more slides oh There was one other thing it's going to show you Um Which is? these D convolutions Can create some very ugly artifacts, and I can show you some very ugly artifacts because I have some right here You see these you see it on the screen Rachel this checkerboard, okay, this is called a checkerboard pattern The the checkerboard pattern Happens through a very specific reason and I've provided a link to this paper It's an online paper You guys might remember Chris Ola he had a lot of the best Kind of learning materials we looked at in part one He's now got this cool thing for distilled a pub done with some of his colleagues at Google And he wrote this thing Discovering why is it that everybody gets these goddamn checkerboard patterns right and What he shows is that it happens because you have stride to size 3 convolutions Which means that every pair of convolutions sees one pixel twice right so it's like a checkerboard It's just a natural thing that's going to come out So they talk about you know this in some detail and all the kind of things you can do but in the end They point out two things the first is That you can avoid this by making it that your your stride Divides nicely into your size, so if I change size to four They've got right so one thing you could try if You're getting checkerboard patterns, which you will is make your size three convolutions into size four convolutions The second thing that he suggests doing is not to use deconvolutions Instead of using a deconvolution he suggests first of all doing an up sampling What happens when you do an up sampling is it's the basically the opposite of max pooling You take every pixel and you turn it into a 2x2 grid of that exact pixel All right, that's called up sampling If you do an up sampling followed by a regular convolution that also gets rid of the checkerboard pattern and as it happens Keras has Something to do that Which is called? It's called up sampling 2d So all this does is kind of the opposite of max pooling It's going to double the size of your image at which point you can use a standard normal unit strata convolution And avoid the other facts so extra credit After you get your network working is to change it to an up sampling and unit strata convolution network And see if the checkerboard artifacts go away Okay, so that is that At the very end here. I've got some suggestions for some more things that you can look at Although most of those were already in the PowerPoint so Anything else there? Okay, so let's move on I want to talk about going big going big Can mean two things of course it does mean we get to say big data Which is important you have to do that? I'm very proud that even during the big data thing I never said big data without Saying rude things about the stupid idea of big data Who cares about how big it is but in deep learning you know sometimes we do need to use either Large objects like if you're doing diabetic retinopathy you have like 4,000 by 4,000 pictures of eyeballs Or maybe you've got lots of images a lot of lots of objects like if you're working with image net and to handle this Data that doesn't fit in RAM. We need some tricks, so I thought we would try some Interesting project that involves looking at the whole image net competition data set that the image net competition data set is One and a half million images in a thousand categories As I mentioned I think in the last class If you try to download it It will give you a little form saying you have to use it for research purposes And that they're going to check it blah blah blah in practice if you fill out the form you'll get back an answer a seconds later so Anybody who's got a terabyte of space and since you're building your own boxes you now have a terabyte of space You can go ahead and download image net And then you can start working through this project so this project is about implementing a paper called device and Device is a really really interesting paper. I actually just Chatted to the author about it quite recently A Amazing lady named Andrea from who's now at clarify. I'm just a computer vision startup and What she did was device was she created a really interesting multimodal Architecture so multimodal means that we're going to be combining different types of object and in her case. She was combining language With images that's quite an early paper to look at this idea, and she did something which was really interesting she said normally when we do an image net network our Final layer is a one-hot encoding of a category and so that means that a hug and a golden retriever are No more similar or different in terms of that encoding than a pug and a jumbo jumbo jet And that seems kind of weird right like If you had an encoding where similar things were similar in the encoding You could do some pretty cool stuff And in particular what she was trying to do one of the key things she was trying to do is to create something which went beyond the thousand image net categories so that you could Work with types of images that were not in image net at all and So the way she did that was to say all right. Let's throw away the one pot encoded category and Let's replace it with a word embedding of the thing All right, so pug is no longer zero zero zero one zero zero zero zero But it's now the word to vector the pug And that's it. That's the entirety of the thing train that And see what happens I'll provide a link to the paper and one of the things I love about the paper is that What she does is to? Show quite an interesting range of the kinds of cool results and cool things you can do when you replace a one-hot encoded output with a vector output embedding I Just to clarify so every pixel one encoded coded pixel suddenly becomes a vector was like no pixels are not one-hot encoded pixels Encoded by their channels, all right. I mean bit bit of No so here the The let's take let's say this is an image of a pug right it's a type of dog and so pug gets turned into let's say pug is the 300 Class in image net It's going to get turned into a 1000 long vector with a thousand zeros Sorry, not even one zeros and a one in position 300 That's normally what we use as our as our target when we're doing any justification. We're going to throw that 1000 long thing away and replace it with a 300 long thing and the 300 long thing will be the Word vector for pug that we downloaded from Word2Vector So So normally we have our input image comes in it goes through some kind of You Computation in our CNN and it has to predict something and normally the thing it has to predict is a whole bunch of zeros And a one here, and so the way we do that is that the last layer is a softmax layer which encourages One of the things to be much higher than the others so all we do is we throw that away and We replace it with a word vector or that for that thing box or park or jumbo jet and Since the word vectors are generally that might be say 300 dimensions And that's that's dense that's not lots of zeros so we can't use a softmax layer at the end anymore We probably now just use a regular linear layer Okay, so the hard part about doing this really is Processing image there not You know there's nothing weird or interesting or tricky about the architecture all we do is replace the last layer So we're going to leverage big holes quite a lot So we start off by inputting our usual stuff and don't forget with tensorflow to call this limit m thing I created so that you don't use up all of your memory and One thing which can be very helpful is to define actually two parts Once you've got your own box you've got a bunch of spinning hard disks that are big and slow and cheap and maybe a couple of fast expensive small SSDs or NVMe drives So I generally think it's good idea to define a path the both right one two This actually happens to be a mount point that has my big slow Cheap spinning disks and this path happens to live Somewhere which is my fast SSDs and that way throughout my what I'm doing my Code anytime I've got something I'm going to be accessing a lot particularly if it's in a random order I'm going to want to make sure that that thing as long as it's not too big Sits in this path and anytime I'm accessing something which I'm accessing Generally sequentially or which is really big I can put it in this part This is one of the good reasons another good reason to have your own box is that you get this kind of flexibility Okay, so the first thing we need is some word vectors So interestingly Actually the the paper built their own Wikipedia word vectors Actually think that the word2vec vectors you can download from Google are really maybe a better choice here So I've just gone ahead and shown how you can load them in one of the very nice things about Google's word2vec word vectors is That where else do you remember last? In part one when we used word vectors we tended to use glove Glove would not have a word vector for golden retriever. They would have a word vector for golden they don't have like phrase things whereas Google's word vectors have phrases Like golden retriever so for our thing we really need to use Google's word2vec vectors Plus anything like that which has like multi-part concepts as things that we can look at so you can download word2vec I will make them available on our platform that I I site because the only way to get them otherwise is to get them from like this the authors Google Drive directory and Trying to get to a Google Drive directory from Linux is an absolute nightmare So I will save them for you so that you don't have the headache So once you've got them you can load them in And then I they're in a weird Proprietary binary it's like like you're gonna share data Why put it in a weird proprietary binary format and a Google Drive thing that you can't access from Linux anyway this guy did So I then save it as text make it a bit easier to work with The word vectors themselves are in a very simple format They're just the word followed by a space followed by the vector space separated I'm going to save them in a simple Dictionary format so what I'm going to share with you guys will be the dictionary so it's a dictionary from Word or phrase to a numpy array, okay? I'm not sure I've used this idea of zip star before so I should talk about this a little bit So if I've got a dictionary a dictionary which maps from word to vector How do I get out of that a list of the words and the list of the vectors? the short answer is like this But let's think about what that's doing so I don't know like we've used zip quite a bit right so normally with zip You go like zip list 1 comma list 2 Comma whatever right and what that returns is an iterator which first of all gives you Element 1 of list 1 element 1 of list 2 element 1 of list 3 and then element 2 of list 1 so forth That's what zip normally does There's a nice idea in Python that you can put a star Before any argument and if that argument is an iterator something that you can look through It acts as if you had taken that whole list and actually put it Inside those brackets right so let's say that W to V list contained like Fox colon and then some array and then hug Colon and then some array And so forth right when you go zip star that It's the same as actually taking the contents of that list And putting them inside there You would want star star if it was a dictionary star for list not quite Right Star just means you're treating it as an iterator But you're right I mean in this case we are using a list so let's that's not Let's not worry about it. So yeah, you can use let's talk about star star another time But you're right in this case. We have a list Which is actually just in this format as Fox comma array hug Comma array and then lots more right so What this is going to do is when we zip this is it's going to basically take All of these things and Create one list for those that's going to become words And then all these things create one list for those and that's going to become vectors so this idea of You Zip star is something we're going to use quite a lot honestly I don't Normally like think about what it's doing. I just know that any time I've got like a list of tuples, and I want to turn it into a couple of lists You just do zip star. Oh That's all that is it's just a little Python thing Okay, so this gives us a list of words and most of vectors So anytime I start looking at some new data I Always want to test it and so I wanted to make sure this worked the way. I thought it ought to work So one thing I thought was okay. Let's look at the correlation coefficient between small J. Jeremy and big J. Jeremy and Indeed there is some correlation. She would expect For else the correlation between Jeremy and banana. I hate bananas, so I was hoping this would be like massively negative Unfortunately it's not but it is at least lower than the correlation between Jeremy and big Jeremy so like okay. It's it's not always easy to Exactly test data, but you know try and come up with things that ought to be true make sure they are true And so in this case this is giving me some comfort that these word vectors behave the way I expect them to Now I don't really care about capitalization, so I just go ahead and create a lowercase word to vec Dictionary where I just do the lowercase version for everything One trick here is I go through in reverse Because what to vec is ordered Where the most common words are first so by going in reverse it means if there is both a capital J Jeremy and a small J. Jeremy the one that's going to end up in my dictionary will be the more common Okay So What I want for device is to now get this word vector for each one of our 1,000 categories in image net and Then I'm going to go even further than that because I want to go beyond image net So I actually went and downloaded the original word net Categories and I filled it down to find all the nouns and I discovered that there are actually 82,000 nouns in word net which is quite a few it's quite fun looking through them So I'm going to create a map of word vectors for every image net Category be one set and every word net noun that'll be another set and so my goal in this project Will be to try and create something that can do useful things With the full set of word net nouns we're going to go beyond image net We've already got the a thousand image net categories. We've used that many of times before so grab those load them in I can Okay, and then I do the same thing for the full set Wordnet IDs which I will share with you and So now I can go ahead and create a dictionary Which goes through every one of my Every one of my image net thousand categories and converts it into the word vector And notice I have a filter here and that's because some of the image net categories Won't be in word2vec and that's because like sometimes the image net categories will say things like Hug bracket doc you know they won't be exactly in the same format If you wanted to you could probably get a better match than this, but I found even with this simple approach I managed to match 51,600 out of the 82,000 word net nouns which I thought was pretty good so what I did then was I created a list of all of the categories which didn't match and This commented out bit as you can see is something which literally just moved those Folders out of the way so that they're not in my image net path anymore Okay, so the details aren't very important, but hopefully you can see at the end of this process I've got something that maps every image net category to a word vector at least if I could find it and Every word net noun to a vector at least if I could find it and that I've modified my image net Data so that the categories I couldn't find I've moved those folders out of the way Okay, nothing particularly interesting there, and that's because Word nets not that big it's in there, so that's pretty straightforward The images are a bit harder because we've got you know a million or so images So we're going to try everything we can to make this run as quickly as possible So To start with even The very process of getting a list of the file names of everything in image net Takes a non-trivial amount of time so like everything that takes a non-trivial amount of time. We're going to save its output Right so the first thing I do is I use Lob glob I can't remember if we use glob in part one. I think we did yeah It's just the thing that's like LS star dot star right this sort of love so we use glob to grab all of the Image net trading set and then I just go ahead and equal dot dump that yes So I can pick it up later For various reasons that we'll see shortly It's actually a very good idea though at this point to randomize that list of file names put them in a random order The basic idea is later on If we use Kind of chunks of file names that are next to each other. They're not all going to be The same type of thing right so by randomizing the file names now. It's going to save us a bit of time So then I can go ahead and save that randomized list By giving it a different name. I can always come back to the original So I want to resize all of my images to a constant size I'm being a bit lazy here, and then I resize them to 224 by 224. That's the input size for a lot of models obviously Including the one that we're going to use That would probably be better if we resize to something bigger, and then we like randomly zoom and crop Maybe if we have time we'll we'll try that later But for now we're just going to use resize everything to 224 by 224 Okay, so we have a million million images it turns out to resize to 224 by 224 That could be pretty slow So I've got some handy tricks to make it much faster Generally speaking there are three ways to Make an algorithm significantly faster The three ways are Just cache say memory locality to explain these in a moment The second is Sim D also known as vectorization The third is parallel processing So Rachel is very familiar with these because she's currently creating a Course for the master's students here on numerical linear algebra, which is like very heavily about these things So these are the three ways you can make Data processing faster memory locality simply means in your computer you have lots of different kinds of memory You have for example level one cache level two cache RAM Solid-state disk Regular of hard drives The difference in speed as you go up from one to the other is generally like ten times or a hundred times or a thousand times slower like you really really really don't want to go to the next level of the memory hierarchy if you can avoid it and Fortunately level one cache might be more like 16 K Level two cache might be a few Meg Ram is going to be a few gig Solid-state drives is probably going to be a few hundreds of gig and your hard drives are probably going to be a few terabytes So in reality you've got to be careful about how you manage these things so you want to try and make sure that you're Putting stuff in the right place That you're not filling up the resources unnecessarily And that if you use if you're going to use a piece of data multiple times Try to use it each time like immediately use it again, so that it's already in your The second thing which is what we're about to look look at is SIMD which stands for single instruction multiple data something that a Shockingly large number of people even who claim to be professional computer programmers don't know is that every modern CPU is capable of in a single operation in a single thread calculating multiple things at the same time and The way that it does it is that you basically create a little vector of generally about eight things Right and you put all the things you want to calculate so let's say you want to take the square root of something You put eight things into this little vector And then you call a particular CPU instruction which is basically a Take the square root of eight floating-point numbers that is in this register And it does it in a single clock cycle so when we say clock cycle You know your CPU might be say two or three gigahertz right so it's doing two or three billion things Per second well, it's not it's doing two or three billion times eight things per second if you're using SIMD Because so few people are aware of SIMD and because a lot of programming environments don't make it easy to use this IMD a Lot of stuff is not written to take advantage of SIMD Including for example pretty much all of the image processing in Python However you can do this You can go pip install pillow SIMD and That will replace your pillow remember pillow is like the main Python imaging library With a new version that does use SIMD for at least some of its things right Because SIMD only works on Certain CPUs I mean a any vaguely recent CPU it works But because it's only some you have to add some special Directives to the compiler to tell it I want to use I have this kind of CPU so please do use these kinds of instructions And what pillow SIMD does it actually literally replaces your existing pillow Right so that's why you have to say force reinstall because it's going to be like oh you already have pillow But this is like no I want You know where Sandy so if you try this You will find that the speed of your resize literally goes up by 600% You don't have to change any code Okay, so I'm like a huge fan of SIMD in general One of the reasons I'm not particularly fond of Python because it doesn't make it at all easy to use SIMD But luckily some people have written Stuff in C. Which does use SIMD and then provided these Python interfaces, okay, so this is something You remember to try to get working when you go home before you do it write a little benchmark that resizes a thousand images and times it and Then run this command and make sure that it gets 600% faster that way you know it's it's actually working We have two questions, I don't know if you want to finish the three ways to do things faster first or you go One is how could you get the relation between a pug and a dog? And the photo of a pug and its relation to the bigger category of dog Sure we'll think about that Now there, why do we want to randomize the file names can't we use? Shuffle equals true on the keras flow from directory. You'll see yeah The short answer is kind of to do with locality right if you say shuffle equals true you're jumping from here on the hard disk to here on the hard disk to here on the hard disk and Hard disk take that like literally that remember There's a spinning disk with a little needle right and the things moving all over the place So you want to be getting things that are all in a row. It's basically the reason As you'll see this was going to basically work for the concept of dog versus pug because the word vector for dog Is very similar to word vector for pug so at the end. We'll try it. We'll try and we'll we'll see if we can find And dogs see if it works I'm sure it will Finally there's parallel processing parallel processing refers to the fact hopefully as you all know Any modern CPU has multiple cores right which literally means multiple CPUs in your CPU and often Boxes that you buy from home might even have multiple CPUs in them Again Python's not great for parallel processing Python 3 is certainly a lot better But a lot of stuff in Python doesn't use parallel processing very effectively but a Lot of modern CPUs have 10 cores or more even for you know consumer CPU So if you're not using parallel processing you're missing out on a 10x speedup If you're not using sand you're missing out on a 6 to 8x speedup Alright, so if you can do both of these things you can get 50 plus. I mean you will you'll get 50 plus Assuming your CPU has enough course So we're going to do both to get SIMD We're just going to install it and to get parallel processing we're probably not going to see all of it today But we're going to be using parallel processing So I define a few things to do my resizing One thing is I've actually recently Changed how I do resizing as I'm sure you guys have noticed in the past when I resize things to square I've tended to act at a black border to the bottom or a black border to the right Because that's what Keras did Now that I've looked into it like no best practice papers Cackle results in a thing used that way and it makes perfect sense because the CNN is going to have to like Learn to deal with the black border And you're throwing away all that information What pretty much all the best practice approach use is to Rather than rescale the longest side to be the size of your square and then fill it in with black Instead take the smallest side and make that the size of your square The other sides now too big so just chop off the top and bottom or chop off the right or right and left That's called center cropping right so resizing and center cropping So what I've done here is I've got something which resizes to the size of the shortest side And then over here Over here, I've got something which does the center cropping You can look at the details when you get home if you like it's not particularly exciting So I've got something that does the resizing This is something you can improve currently I'm making sure that it's a three channel image And so I'm not doing a black and white or something with an alpha channel. I just ignore them Okay So before I finish up this I think I'm out of time so what we're going to learn next time when we start is we're going to learn about parallel processing So anybody who's interested in pre-reading? Yeah, feel free to start reading and playing around with Python parallel processing all right. Thanks everybody see you next week Hope your assignments go really well, and let me know if I can help you out in the forum", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.3, "text": " So welcome back everybody thanks for coming, and I hope you had a good week and had a fun time playing around with artistic style", "tokens": [50364, 407, 2928, 646, 2201, 3231, 337, 1348, 11, 293, 286, 1454, 291, 632, 257, 665, 1243, 293, 632, 257, 1019, 565, 2433, 926, 365, 17090, 3758, 50729], "temperature": 0.0, "avg_logprob": -0.35152283535208756, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0006505489582195878}, {"id": 1, "seek": 0, "start": 7.3, "end": 9.3, "text": " I know I did", "tokens": [50729, 286, 458, 286, 630, 50829], "temperature": 0.0, "avg_logprob": -0.35152283535208756, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0006505489582195878}, {"id": 2, "seek": 0, "start": 9.72, "end": 11.72, "text": " I thought I'd show you", "tokens": [50850, 286, 1194, 286, 1116, 855, 291, 50950], "temperature": 0.0, "avg_logprob": -0.35152283535208756, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0006505489582195878}, {"id": 3, "seek": 0, "start": 13.24, "end": 14.52, "text": " So I", "tokens": [51026, 407, 286, 51090], "temperature": 0.0, "avg_logprob": -0.35152283535208756, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0006505489582195878}, {"id": 4, "seek": 0, "start": 14.52, "end": 19.240000000000002, "text": " Tried a couple of things myself over the week with this artistic style stuff", "tokens": [51090, 314, 2428, 257, 1916, 295, 721, 2059, 670, 264, 1243, 365, 341, 17090, 3758, 1507, 51326], "temperature": 0.0, "avg_logprob": -0.35152283535208756, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0006505489582195878}, {"id": 5, "seek": 0, "start": 19.88, "end": 24.2, "text": " Just like I just tried a couple of simple little changes, which I thought you might be interested in", "tokens": [51358, 1449, 411, 286, 445, 3031, 257, 1916, 295, 2199, 707, 2962, 11, 597, 286, 1194, 291, 1062, 312, 3102, 294, 51574], "temperature": 0.0, "avg_logprob": -0.35152283535208756, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0006505489582195878}, {"id": 6, "seek": 0, "start": 24.88, "end": 26.88, "text": " Yeah", "tokens": [51608, 865, 51708], "temperature": 0.0, "avg_logprob": -0.35152283535208756, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0006505489582195878}, {"id": 7, "seek": 0, "start": 27.0, "end": 28.240000000000002, "text": " Oh", "tokens": [51714, 876, 51776], "temperature": 0.0, "avg_logprob": -0.35152283535208756, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0006505489582195878}, {"id": 8, "seek": 2824, "start": 28.24, "end": 30.24, "text": " Actually, yeah, okay, so", "tokens": [50364, 5135, 11, 1338, 11, 1392, 11, 370, 50464], "temperature": 0.0, "avg_logprob": -0.24723622081725577, "compression_ratio": 1.7314487632508835, "no_speech_prob": 4.222471488901647e-06}, {"id": 9, "seek": 2824, "start": 30.72, "end": 35.379999999999995, "text": " One thing before I talk about the artistic style is I just wanted to point out some of the really cool stuff that people have", "tokens": [50488, 1485, 551, 949, 286, 751, 466, 264, 17090, 3758, 307, 286, 445, 1415, 281, 935, 484, 512, 295, 264, 534, 1627, 1507, 300, 561, 362, 50721], "temperature": 0.0, "avg_logprob": -0.24723622081725577, "compression_ratio": 1.7314487632508835, "no_speech_prob": 4.222471488901647e-06}, {"id": 10, "seek": 2824, "start": 35.379999999999995, "end": 36.879999999999995, "text": " been contributing", "tokens": [50721, 668, 19270, 50796], "temperature": 0.0, "avg_logprob": -0.24723622081725577, "compression_ratio": 1.7314487632508835, "no_speech_prob": 4.222471488901647e-06}, {"id": 11, "seek": 2824, "start": 36.879999999999995, "end": 43.14, "text": " Over the over the week if you haven't come across it yet be sure to check out the the wiki", "tokens": [50796, 4886, 264, 670, 264, 1243, 498, 291, 2378, 380, 808, 2108, 309, 1939, 312, 988, 281, 1520, 484, 264, 264, 261, 9850, 51109], "temperature": 0.0, "avg_logprob": -0.24723622081725577, "compression_ratio": 1.7314487632508835, "no_speech_prob": 4.222471488901647e-06}, {"id": 12, "seek": 2824, "start": 44.0, "end": 45.519999999999996, "text": " so the", "tokens": [51152, 370, 264, 51228], "temperature": 0.0, "avg_logprob": -0.24723622081725577, "compression_ratio": 1.7314487632508835, "no_speech_prob": 4.222471488901647e-06}, {"id": 13, "seek": 2824, "start": 45.519999999999996, "end": 52.28, "text": " There's a nice thing in discourse where you can basically set any post as being a wiki which means that anybody can edit it", "tokens": [51228, 821, 311, 257, 1481, 551, 294, 23938, 689, 291, 393, 1936, 992, 604, 2183, 382, 885, 257, 261, 9850, 597, 1355, 300, 4472, 393, 8129, 309, 51566], "temperature": 0.0, "avg_logprob": -0.24723622081725577, "compression_ratio": 1.7314487632508835, "no_speech_prob": 4.222471488901647e-06}, {"id": 14, "seek": 2824, "start": 52.28, "end": 57.8, "text": " So I created this wiki post early on and by the end of the week we now have all kinds of stuff with", "tokens": [51566, 407, 286, 2942, 341, 261, 9850, 2183, 2440, 322, 293, 538, 264, 917, 295, 264, 1243, 321, 586, 362, 439, 3685, 295, 1507, 365, 51842], "temperature": 0.0, "avg_logprob": -0.24723622081725577, "compression_ratio": 1.7314487632508835, "no_speech_prob": 4.222471488901647e-06}, {"id": 15, "seek": 5824, "start": 58.24, "end": 61.46, "text": " Links to the stuff in the class a summary of the paper", "tokens": [50364, 37156, 281, 264, 1507, 294, 264, 1508, 257, 12691, 295, 264, 3035, 50525], "temperature": 0.0, "avg_logprob": -0.4260604345976417, "compression_ratio": 1.5056818181818181, "no_speech_prob": 0.00041082012467086315}, {"id": 16, "seek": 5824, "start": 64.36, "end": 66.36, "text": " Examples a list of all the links", "tokens": [50670, 48591, 257, 1329, 295, 439, 264, 6123, 50770], "temperature": 0.0, "avg_logprob": -0.4260604345976417, "compression_ratio": 1.5056818181818181, "no_speech_prob": 0.00041082012467086315}, {"id": 17, "seek": 5824, "start": 68.2, "end": 70.2, "text": " Both snippets", "tokens": [50862, 6767, 35623, 1385, 50962], "temperature": 0.0, "avg_logprob": -0.4260604345976417, "compression_ratio": 1.5056818181818181, "no_speech_prob": 0.00041082012467086315}, {"id": 18, "seek": 5824, "start": 70.68, "end": 76.0, "text": " Handy list of steps that are kind of necessary when you're doing style transfer", "tokens": [50986, 47006, 1329, 295, 4439, 300, 366, 733, 295, 4818, 562, 291, 434, 884, 3758, 5003, 51252], "temperature": 0.0, "avg_logprob": -0.4260604345976417, "compression_ratio": 1.5056818181818181, "no_speech_prob": 0.00041082012467086315}, {"id": 19, "seek": 5824, "start": 76.68, "end": 79.32000000000001, "text": " Lots of stuff about the tensorflow dead summit and so forth", "tokens": [51286, 15908, 295, 1507, 466, 264, 40863, 10565, 3116, 21564, 293, 370, 5220, 51418], "temperature": 0.0, "avg_logprob": -0.4260604345976417, "compression_ratio": 1.5056818181818181, "no_speech_prob": 0.00041082012467086315}, {"id": 20, "seek": 5824, "start": 82.12, "end": 84.12, "text": " Wiki threads every week", "tokens": [51558, 35892, 19314, 633, 1243, 51658], "temperature": 0.0, "avg_logprob": -0.4260604345976417, "compression_ratio": 1.5056818181818181, "no_speech_prob": 0.00041082012467086315}, {"id": 21, "seek": 8412, "start": 84.4, "end": 91.12, "text": " So look out for that and lots of other threads one I saw just this afternoon popped up, which is great from chin chin", "tokens": [50378, 407, 574, 484, 337, 300, 293, 3195, 295, 661, 19314, 472, 286, 1866, 445, 341, 6499, 21545, 493, 11, 597, 307, 869, 490, 14210, 14210, 50714], "temperature": 0.0, "avg_logprob": -0.3568149226726872, "compression_ratio": 1.7235772357723578, "no_speech_prob": 5.2241168305044994e-05}, {"id": 22, "seek": 8412, "start": 96.28, "end": 98.28, "text": " Talked about trying to summarize", "tokens": [50972, 8780, 292, 466, 1382, 281, 20858, 51072], "temperature": 0.0, "avg_logprob": -0.3568149226726872, "compression_ratio": 1.7235772357723578, "no_speech_prob": 5.2241168305044994e-05}, {"id": 23, "seek": 8412, "start": 98.80000000000001, "end": 100.80000000000001, "text": " what they've learned from", "tokens": [51098, 437, 436, 600, 3264, 490, 51198], "temperature": 0.0, "avg_logprob": -0.3568149226726872, "compression_ratio": 1.7235772357723578, "no_speech_prob": 5.2241168305044994e-05}, {"id": 24, "seek": 8412, "start": 101.32000000000001, "end": 106.98, "text": " Lots of other threads across the weekend. This is really sorry across the forum. This is a great thing that we can all do is", "tokens": [51224, 15908, 295, 661, 19314, 2108, 264, 6711, 13, 639, 307, 534, 2597, 2108, 264, 17542, 13, 639, 307, 257, 869, 551, 300, 321, 393, 439, 360, 307, 51507], "temperature": 0.0, "avg_logprob": -0.3568149226726872, "compression_ratio": 1.7235772357723578, "no_speech_prob": 5.2241168305044994e-05}, {"id": 25, "seek": 8412, "start": 107.52000000000001, "end": 109.36000000000001, "text": " you know when you", "tokens": [51534, 291, 458, 562, 291, 51626], "temperature": 0.0, "avg_logprob": -0.3568149226726872, "compression_ratio": 1.7235772357723578, "no_speech_prob": 5.2241168305044994e-05}, {"id": 26, "seek": 8412, "start": 109.36000000000001, "end": 113.84, "text": " Look at lots of different things and kind of takes notes if you put them on the forum for everybody else", "tokens": [51626, 2053, 412, 3195, 295, 819, 721, 293, 733, 295, 2516, 5570, 498, 291, 829, 552, 322, 264, 17542, 337, 2201, 1646, 51850], "temperature": 0.0, "avg_logprob": -0.3568149226726872, "compression_ratio": 1.7235772357723578, "no_speech_prob": 5.2241168305044994e-05}, {"id": 27, "seek": 11412, "start": 114.12, "end": 118.96000000000001, "text": " This is super handy, and so if you haven't quite caught up on all the stuff going on the forum", "tokens": [50364, 639, 307, 1687, 13239, 11, 293, 370, 498, 291, 2378, 380, 1596, 5415, 493, 322, 439, 264, 1507, 516, 322, 264, 17542, 50606], "temperature": 0.0, "avg_logprob": -0.32383914869658803, "compression_ratio": 1.6293436293436294, "no_speech_prob": 3.6478177207754925e-05}, {"id": 28, "seek": 11412, "start": 119.64, "end": 123.84, "text": " Looking at this curating lesson 8 experiments thread would be probably a good place to start", "tokens": [50640, 11053, 412, 341, 1262, 990, 6898, 1649, 12050, 7207, 576, 312, 1391, 257, 665, 1081, 281, 722, 50850], "temperature": 0.0, "avg_logprob": -0.32383914869658803, "compression_ratio": 1.6293436293436294, "no_speech_prob": 3.6478177207754925e-05}, {"id": 29, "seek": 11412, "start": 126.80000000000001, "end": 132.92000000000002, "text": " So a couple of little changes I made in my experiments I tried thinking about like why", "tokens": [50998, 407, 257, 1916, 295, 707, 2962, 286, 1027, 294, 452, 12050, 286, 3031, 1953, 466, 411, 983, 51304], "temperature": 0.0, "avg_logprob": -0.32383914869658803, "compression_ratio": 1.6293436293436294, "no_speech_prob": 3.6478177207754925e-05}, {"id": 30, "seek": 11412, "start": 134.48000000000002, "end": 140.8, "text": " Quite a few if you pointed out how depending on what your starting point is for your optimizer you get to a very different place", "tokens": [51382, 20464, 257, 1326, 498, 291, 10932, 484, 577, 5413, 322, 437, 428, 2891, 935, 307, 337, 428, 5028, 6545, 291, 483, 281, 257, 588, 819, 1081, 51698], "temperature": 0.0, "avg_logprob": -0.32383914869658803, "compression_ratio": 1.6293436293436294, "no_speech_prob": 3.6478177207754925e-05}, {"id": 31, "seek": 11412, "start": 141.56, "end": 143.56, "text": " and so clearly our", "tokens": [51736, 293, 370, 4448, 527, 51836], "temperature": 0.0, "avg_logprob": -0.32383914869658803, "compression_ratio": 1.6293436293436294, "no_speech_prob": 3.6478177207754925e-05}, {"id": 32, "seek": 14356, "start": 143.88, "end": 145.6, "text": " convex optimization", "tokens": [50380, 42432, 19618, 50466], "temperature": 0.0, "avg_logprob": -0.34378131684802826, "compression_ratio": 1.651685393258427, "no_speech_prob": 1.1659250958473422e-05}, {"id": 33, "seek": 14356, "start": 145.6, "end": 151.68, "text": " Is I'm not necessarily finding a local minimum, but at least saddle points is not getting out of so I tried something", "tokens": [50466, 1119, 286, 478, 406, 4725, 5006, 257, 2654, 7285, 11, 457, 412, 1935, 30459, 2793, 307, 406, 1242, 484, 295, 370, 286, 3031, 746, 50770], "temperature": 0.0, "avg_logprob": -0.34378131684802826, "compression_ratio": 1.651685393258427, "no_speech_prob": 1.1659250958473422e-05}, {"id": 34, "seek": 14356, "start": 151.68, "end": 157.16, "text": " Which was to create a take the random image and just add a Gaussian blur to it", "tokens": [50770, 3013, 390, 281, 1884, 257, 747, 264, 4974, 3256, 293, 445, 909, 257, 39148, 14257, 281, 309, 51044], "temperature": 0.0, "avg_logprob": -0.34378131684802826, "compression_ratio": 1.651685393258427, "no_speech_prob": 1.1659250958473422e-05}, {"id": 35, "seek": 14356, "start": 157.52, "end": 160.96, "text": " So Gaussian filter is just a blur and so that makes a random image", "tokens": [51062, 407, 39148, 6608, 307, 445, 257, 14257, 293, 370, 300, 1669, 257, 4974, 3256, 51234], "temperature": 0.0, "avg_logprob": -0.34378131684802826, "compression_ratio": 1.651685393258427, "no_speech_prob": 1.1659250958473422e-05}, {"id": 36, "seek": 14356, "start": 161.44, "end": 164.76, "text": " into this kind of thing and I just found that even the", "tokens": [51258, 666, 341, 733, 295, 551, 293, 286, 445, 1352, 300, 754, 264, 51424], "temperature": 0.0, "avg_logprob": -0.34378131684802826, "compression_ratio": 1.651685393258427, "no_speech_prob": 1.1659250958473422e-05}, {"id": 37, "seek": 14356, "start": 165.56, "end": 170.6, "text": " Plain style looks a lot smoother. So that was one change that I made which I thought worked quite well", "tokens": [51464, 2149, 491, 3758, 1542, 257, 688, 28640, 13, 407, 300, 390, 472, 1319, 300, 286, 1027, 597, 286, 1194, 2732, 1596, 731, 51716], "temperature": 0.0, "avg_logprob": -0.34378131684802826, "compression_ratio": 1.651685393258427, "no_speech_prob": 1.1659250958473422e-05}, {"id": 38, "seek": 17060, "start": 171.6, "end": 178.24, "text": " Another change that I made just to play around with it was I added a different weight to each of the style layers", "tokens": [50414, 3996, 1319, 300, 286, 1027, 445, 281, 862, 926, 365, 309, 390, 286, 3869, 257, 819, 3364, 281, 1184, 295, 264, 3758, 7914, 50746], "temperature": 0.0, "avg_logprob": -0.2974624841109566, "compression_ratio": 1.7056277056277056, "no_speech_prob": 2.3552262064185925e-05}, {"id": 39, "seek": 17060, "start": 178.92, "end": 179.95999999999998, "text": " and", "tokens": [50780, 293, 50832], "temperature": 0.0, "avg_logprob": -0.2974624841109566, "compression_ratio": 1.7056277056277056, "no_speech_prob": 2.3552262064185925e-05}, {"id": 40, "seek": 17060, "start": 179.95999999999998, "end": 185.14, "text": " So my my zip now has a third thing in which is the weights and I just multiply by the weight", "tokens": [50832, 407, 452, 452, 20730, 586, 575, 257, 2636, 551, 294, 597, 307, 264, 17443, 293, 286, 445, 12972, 538, 264, 3364, 51091], "temperature": 0.0, "avg_logprob": -0.2974624841109566, "compression_ratio": 1.7056277056277056, "no_speech_prob": 2.3552262064185925e-05}, {"id": 41, "seek": 17060, "start": 186.32, "end": 192.76, "text": " So I thought that those two things made my little bird look significantly better than my little bird look before so I was happy with that", "tokens": [51150, 407, 286, 1194, 300, 729, 732, 721, 1027, 452, 707, 5255, 574, 10591, 1101, 813, 452, 707, 5255, 574, 949, 370, 286, 390, 2055, 365, 300, 51472], "temperature": 0.0, "avg_logprob": -0.2974624841109566, "compression_ratio": 1.7056277056277056, "no_speech_prob": 2.3552262064185925e-05}, {"id": 42, "seek": 17060, "start": 194.07999999999998, "end": 196.16, "text": " You could do a similar thing for content loss", "tokens": [51538, 509, 727, 360, 257, 2531, 551, 337, 2701, 4470, 51642], "temperature": 0.0, "avg_logprob": -0.2974624841109566, "compression_ratio": 1.7056277056277056, "no_speech_prob": 2.3552262064185925e-05}, {"id": 43, "seek": 19616, "start": 196.56, "end": 203.0, "text": " Also, maybe add more different layers of content loss and give them different weights as well, I'm not sure if anybody's tried that", "tokens": [50384, 2743, 11, 1310, 909, 544, 819, 7914, 295, 2701, 4470, 293, 976, 552, 819, 17443, 382, 731, 11, 286, 478, 406, 988, 498, 4472, 311, 3031, 300, 50706], "temperature": 0.0, "avg_logprob": -0.5328320954975329, "compression_ratio": 1.6479591836734695, "no_speech_prob": 0.002756908070296049}, {"id": 44, "seek": 19616, "start": 203.64, "end": 205.64, "text": " as yet", "tokens": [50738, 382, 1939, 50838], "temperature": 0.0, "avg_logprob": -0.5328320954975329, "compression_ratio": 1.6479591836734695, "no_speech_prob": 0.002756908070296049}, {"id": 45, "seek": 19616, "start": 210.12, "end": 213.76, "text": " Yes, Rachel a question I have a question regards", "tokens": [51062, 1079, 11, 14246, 257, 1168, 286, 362, 257, 1168, 14258, 51244], "temperature": 0.0, "avg_logprob": -0.5328320954975329, "compression_ratio": 1.6479591836734695, "no_speech_prob": 0.002756908070296049}, {"id": 46, "seek": 19616, "start": 215.12, "end": 216.04, "text": " cartoons", "tokens": [51312, 34855, 51358], "temperature": 0.0, "avg_logprob": -0.5328320954975329, "compression_ratio": 1.6479591836734695, "no_speech_prob": 0.002756908070296049}, {"id": 47, "seek": 19616, "start": 216.04, "end": 223.2, "text": " The cartoons when we think of transferring the style what we really mean is transferring the contours of the cartoon to redraw", "tokens": [51358, 440, 34855, 562, 321, 519, 295, 31437, 264, 3758, 437, 321, 534, 914, 307, 31437, 264, 660, 5067, 295, 264, 18569, 281, 2182, 5131, 51716], "temperature": 0.0, "avg_logprob": -0.5328320954975329, "compression_ratio": 1.6479591836734695, "no_speech_prob": 0.002756908070296049}, {"id": 48, "seek": 22320, "start": 223.2, "end": 230.16, "text": " The content in that style and this is not what style transferring is doing here. How might one implement this? Yeah, I", "tokens": [50364, 440, 2701, 294, 300, 3758, 293, 341, 307, 406, 437, 3758, 31437, 307, 884, 510, 13, 1012, 1062, 472, 4445, 341, 30, 865, 11, 286, 50712], "temperature": 0.0, "avg_logprob": -0.41750682484019885, "compression_ratio": 1.578125, "no_speech_prob": 0.0008969192276708782}, {"id": 49, "seek": 22320, "start": 231.04, "end": 235.32, "text": " Don't know that anybody's quite figured that out, but I'll show you a couple of directions that may be useful", "tokens": [50756, 1468, 380, 458, 300, 4472, 311, 1596, 8932, 300, 484, 11, 457, 286, 603, 855, 291, 257, 1916, 295, 11095, 300, 815, 312, 4420, 50970], "temperature": 0.0, "avg_logprob": -0.41750682484019885, "compression_ratio": 1.578125, "no_speech_prob": 0.0008969192276708782}, {"id": 50, "seek": 22320, "start": 239.11999999999998, "end": 246.88, "text": " Yeah, I've tried selecting activations correspond with edges and such as indicated by one of the calm visualization papers and carrying outputs from", "tokens": [51160, 865, 11, 286, 600, 3031, 18182, 2430, 763, 6805, 365, 8819, 293, 1270, 382, 16176, 538, 472, 295, 264, 7151, 25801, 10577, 293, 9792, 23930, 490, 51548], "temperature": 0.0, "avg_logprob": -0.41750682484019885, "compression_ratio": 1.578125, "no_speech_prob": 0.0008969192276708782}, {"id": 51, "seek": 22320, "start": 247.04, "end": 249.04, "text": " typically those activation", "tokens": [51556, 5850, 729, 24433, 51656], "temperature": 0.0, "avg_logprob": -0.41750682484019885, "compression_ratio": 1.578125, "no_speech_prob": 0.0008969192276708782}, {"id": 52, "seek": 24904, "start": 249.6, "end": 255.44, "text": " Yeah, yeah, so I'll show you some things I show you some things you could try I haven't seen anybody do a great job of", "tokens": [50392, 865, 11, 1338, 11, 370, 286, 603, 855, 291, 512, 721, 286, 855, 291, 512, 721, 291, 727, 853, 286, 2378, 380, 1612, 4472, 360, 257, 869, 1691, 295, 50684], "temperature": 0.0, "avg_logprob": -0.298664629900897, "compression_ratio": 1.7625, "no_speech_prob": 6.814507651142776e-05}, {"id": 53, "seek": 24904, "start": 255.44, "end": 256.12, "text": " This yet, but yes", "tokens": [50684, 639, 1939, 11, 457, 2086, 50718], "temperature": 0.0, "avg_logprob": -0.298664629900897, "compression_ratio": 1.7625, "no_speech_prob": 6.814507651142776e-05}, {"id": 54, "seek": 24904, "start": 256.12, "end": 263.15999999999997, "text": " I mean here's one example from the from the forum is somebody pointed out that this this cartoon approach didn't work very well with dr.", "tokens": [50718, 286, 914, 510, 311, 472, 1365, 490, 264, 490, 264, 17542, 307, 2618, 10932, 484, 300, 341, 341, 18569, 3109, 994, 380, 589, 588, 731, 365, 1224, 13, 51070], "temperature": 0.0, "avg_logprob": -0.298664629900897, "compression_ratio": 1.7625, "no_speech_prob": 6.814507651142776e-05}, {"id": 55, "seek": 24904, "start": 263.15999999999997, "end": 263.68, "text": " Seuss", "tokens": [51070, 1100, 2023, 51096], "temperature": 0.0, "avg_logprob": -0.298664629900897, "compression_ratio": 1.7625, "no_speech_prob": 6.814507651142776e-05}, {"id": 56, "seek": 24904, "start": 263.68, "end": 269.88, "text": " But then when they changed their initial image not to be random but to be the picture of the dog it actually look quite a lot", "tokens": [51096, 583, 550, 562, 436, 3105, 641, 5883, 3256, 406, 281, 312, 4974, 457, 281, 312, 264, 3036, 295, 264, 3000, 309, 767, 574, 1596, 257, 688, 51406], "temperature": 0.0, "avg_logprob": -0.298664629900897, "compression_ratio": 1.7625, "no_speech_prob": 6.814507651142776e-05}, {"id": 57, "seek": 24904, "start": 269.88, "end": 271.88, "text": " Better so there's one thing you could try", "tokens": [51406, 15753, 370, 456, 311, 472, 551, 291, 727, 853, 51506], "temperature": 0.0, "avg_logprob": -0.298664629900897, "compression_ratio": 1.7625, "no_speech_prob": 6.814507651142776e-05}, {"id": 58, "seek": 24904, "start": 272.59999999999997, "end": 278.28, "text": " There's some very helpful diagrams that some somebody posted which is fantastic. They're summarizing what we learned", "tokens": [51542, 821, 311, 512, 588, 4961, 36709, 300, 512, 2618, 9437, 597, 307, 5456, 13, 814, 434, 14611, 3319, 437, 321, 3264, 51826], "temperature": 0.0, "avg_logprob": -0.298664629900897, "compression_ratio": 1.7625, "no_speech_prob": 6.814507651142776e-05}, {"id": 59, "seek": 27904, "start": 279.48, "end": 285.8, "text": " I like this summary of what happens if you add versus remove each layer", "tokens": [50386, 286, 411, 341, 12691, 295, 437, 2314, 498, 291, 909, 5717, 4159, 1184, 4583, 50702], "temperature": 0.0, "avg_logprob": -0.31162012540377104, "compression_ratio": 1.6939890710382515, "no_speech_prob": 1.2805217011191417e-05}, {"id": 60, "seek": 27904, "start": 285.8, "end": 287.8, "text": " So this is what happens if you remove", "tokens": [50702, 407, 341, 307, 437, 2314, 498, 291, 4159, 50802], "temperature": 0.0, "avg_logprob": -0.31162012540377104, "compression_ratio": 1.6939890710382515, "no_speech_prob": 1.2805217011191417e-05}, {"id": 61, "seek": 27904, "start": 288.88, "end": 294.92, "text": " block 0 block 1 block 2 block 3 and block 4 to get a sense of how they", "tokens": [50856, 3461, 1958, 3461, 502, 3461, 568, 3461, 805, 293, 3461, 1017, 281, 483, 257, 2020, 295, 577, 436, 51158], "temperature": 0.0, "avg_logprob": -0.31162012540377104, "compression_ratio": 1.6939890710382515, "no_speech_prob": 1.2805217011191417e-05}, {"id": 62, "seek": 27904, "start": 295.40000000000003, "end": 301.0, "text": " Impact things so you can see for the style that the last layer is really important to making it look good", "tokens": [51182, 31005, 721, 370, 291, 393, 536, 337, 264, 3758, 300, 264, 1036, 4583, 307, 534, 1021, 281, 1455, 309, 574, 665, 51462], "temperature": 0.0, "avg_logprob": -0.31162012540377104, "compression_ratio": 1.6939890710382515, "no_speech_prob": 1.2805217011191417e-05}, {"id": 63, "seek": 27904, "start": 301.8, "end": 303.8, "text": " At least for this image", "tokens": [51502, 1711, 1935, 337, 341, 3256, 51602], "temperature": 0.0, "avg_logprob": -0.31162012540377104, "compression_ratio": 1.6939890710382515, "no_speech_prob": 1.2805217011191417e-05}, {"id": 64, "seek": 30380, "start": 304.32, "end": 306.32, "text": " One", "tokens": [50390, 1485, 50490], "temperature": 0.0, "avg_logprob": -0.3394418344265077, "compression_ratio": 1.6533333333333333, "no_speech_prob": 2.4299490178236738e-05}, {"id": 65, "seek": 30380, "start": 306.6, "end": 309.16, "text": " If you had some particularly nice examples", "tokens": [50504, 759, 291, 632, 512, 4098, 1481, 5110, 50632], "temperature": 0.0, "avg_logprob": -0.3394418344265077, "compression_ratio": 1.6533333333333333, "no_speech_prob": 2.4299490178236738e-05}, {"id": 66, "seek": 30380, "start": 309.16, "end": 312.36, "text": " I love this like that seems like there's a certain taste", "tokens": [50632, 286, 959, 341, 411, 300, 2544, 411, 456, 311, 257, 1629, 3939, 50792], "temperature": 0.0, "avg_logprob": -0.3394418344265077, "compression_ratio": 1.6533333333333333, "no_speech_prob": 2.4299490178236738e-05}, {"id": 67, "seek": 30380, "start": 312.76, "end": 319.0, "text": " They're kind of figuring out what photos go with what images I thought this Einstein was terrific. I thought this was terrific as well", "tokens": [50812, 814, 434, 733, 295, 15213, 484, 437, 5787, 352, 365, 437, 5267, 286, 1194, 341, 23486, 390, 20899, 13, 286, 1194, 341, 390, 20899, 382, 731, 51124], "temperature": 0.0, "avg_logprob": -0.3394418344265077, "compression_ratio": 1.6533333333333333, "no_speech_prob": 2.4299490178236738e-05}, {"id": 68, "seek": 30380, "start": 322.40000000000003, "end": 328.12, "text": " Brad came up with this really interesting insight that starting with this picture and adding a style to it", "tokens": [51294, 11895, 1361, 493, 365, 341, 534, 1880, 11269, 300, 2891, 365, 341, 3036, 293, 5127, 257, 3758, 281, 309, 51580], "temperature": 0.0, "avg_logprob": -0.3394418344265077, "compression_ratio": 1.6533333333333333, "no_speech_prob": 2.4299490178236738e-05}, {"id": 69, "seek": 30380, "start": 328.96000000000004, "end": 330.96000000000004, "text": " creates this extraordinary", "tokens": [51622, 7829, 341, 10581, 51722], "temperature": 0.0, "avg_logprob": -0.3394418344265077, "compression_ratio": 1.6533333333333333, "no_speech_prob": 2.4299490178236738e-05}, {"id": 70, "seek": 33096, "start": 331.71999999999997, "end": 336.03999999999996, "text": " Shape here where as he points out you can tell it's a man sitting in the corner", "tokens": [50402, 49148, 510, 689, 382, 415, 2793, 484, 291, 393, 980, 309, 311, 257, 587, 3798, 294, 264, 4538, 50618], "temperature": 0.0, "avg_logprob": -0.33834922919839117, "compression_ratio": 1.6881720430107527, "no_speech_prob": 8.480896212859079e-05}, {"id": 71, "seek": 33096, "start": 336.03999999999996, "end": 341.32, "text": " But there's like less than 10 brushstrokes, but sometimes this style transfer does things which are", "tokens": [50618, 583, 456, 311, 411, 1570, 813, 1266, 5287, 27616, 5993, 11, 457, 2171, 341, 3758, 5003, 775, 721, 597, 366, 50882], "temperature": 0.0, "avg_logprob": -0.33834922919839117, "compression_ratio": 1.6881720430107527, "no_speech_prob": 8.480896212859079e-05}, {"id": 72, "seek": 33096, "start": 342.15999999999997, "end": 344.15999999999997, "text": " surprisingly fantastic I", "tokens": [50924, 17600, 5456, 286, 51024], "temperature": 0.0, "avg_logprob": -0.33834922919839117, "compression_ratio": 1.6881720430107527, "no_speech_prob": 8.480896212859079e-05}, {"id": 73, "seek": 33096, "start": 344.47999999999996, "end": 346.47999999999996, "text": " Have no idea what this is even in the photos", "tokens": [51040, 3560, 572, 1558, 437, 341, 307, 754, 294, 264, 5787, 51140], "temperature": 0.0, "avg_logprob": -0.33834922919839117, "compression_ratio": 1.6881720430107527, "no_speech_prob": 8.480896212859079e-05}, {"id": 74, "seek": 33096, "start": 346.47999999999996, "end": 351.14, "text": " So I don't know what it is the painting either, but I guess I don't watch that kind of music enough", "tokens": [51140, 407, 286, 500, 380, 458, 437, 309, 307, 264, 5370, 2139, 11, 457, 286, 2041, 286, 500, 380, 1159, 300, 733, 295, 1318, 1547, 51373], "temperature": 0.0, "avg_logprob": -0.33834922919839117, "compression_ratio": 1.6881720430107527, "no_speech_prob": 8.480896212859079e-05}, {"id": 75, "seek": 33096, "start": 352.96, "end": 354.4, "text": " So there's", "tokens": [51464, 407, 456, 311, 51536], "temperature": 0.0, "avg_logprob": -0.33834922919839117, "compression_ratio": 1.6881720430107527, "no_speech_prob": 8.480896212859079e-05}, {"id": 76, "seek": 33096, "start": 354.4, "end": 359.84, "text": " lots of interesting ideas you can try and I've got a link here and you might have seen it in the PowerPoint to", "tokens": [51536, 3195, 295, 1880, 3487, 291, 393, 853, 293, 286, 600, 658, 257, 2113, 510, 293, 291, 1062, 362, 1612, 309, 294, 264, 25584, 281, 51808], "temperature": 0.0, "avg_logprob": -0.33834922919839117, "compression_ratio": 1.6881720430107527, "no_speech_prob": 8.480896212859079e-05}, {"id": 77, "seek": 35984, "start": 360.23999999999995, "end": 363.79999999999995, "text": " A clear us implementation that has a whole list of things that you can try", "tokens": [50384, 316, 1850, 505, 11420, 300, 575, 257, 1379, 1329, 295, 721, 300, 291, 393, 853, 50562], "temperature": 0.0, "avg_logprob": -0.38205108642578123, "compression_ratio": 1.7107438016528926, "no_speech_prob": 7.368494698312134e-05}, {"id": 78, "seek": 35984, "start": 364.44, "end": 366.15999999999997, "text": " and", "tokens": [50594, 293, 50680], "temperature": 0.0, "avg_logprob": -0.38205108642578123, "compression_ratio": 1.7107438016528926, "no_speech_prob": 7.368494698312134e-05}, {"id": 79, "seek": 35984, "start": 366.15999999999997, "end": 367.91999999999996, "text": " Here are some particular", "tokens": [50680, 1692, 366, 512, 1729, 50768], "temperature": 0.0, "avg_logprob": -0.38205108642578123, "compression_ratio": 1.7107438016528926, "no_speech_prob": 7.368494698312134e-05}, {"id": 80, "seek": 35984, "start": 367.91999999999996, "end": 369.23999999999995, "text": " examples", "tokens": [50768, 5110, 50834], "temperature": 0.0, "avg_logprob": -0.38205108642578123, "compression_ratio": 1.7107438016528926, "no_speech_prob": 7.368494698312134e-05}, {"id": 81, "seek": 35984, "start": 369.23999999999995, "end": 374.2, "text": " This is something called and all of these examples you can get the details from this link", "tokens": [50834, 639, 307, 746, 1219, 293, 439, 295, 613, 5110, 291, 393, 483, 264, 4365, 490, 341, 2113, 51082], "temperature": 0.0, "avg_logprob": -0.38205108642578123, "compression_ratio": 1.7107438016528926, "no_speech_prob": 7.368494698312134e-05}, {"id": 82, "seek": 35984, "start": 375.35999999999996, "end": 382.15999999999997, "text": " There's something called chain blurring and for some things. This is this might work well for cartoons notice how the matrix", "tokens": [51140, 821, 311, 746, 1219, 5021, 14257, 2937, 293, 337, 512, 721, 13, 639, 307, 341, 1062, 589, 731, 337, 34855, 3449, 577, 264, 8141, 51480], "temperature": 0.0, "avg_logprob": -0.38205108642578123, "compression_ratio": 1.7107438016528926, "no_speech_prob": 7.368494698312134e-05}, {"id": 83, "seek": 35984, "start": 382.67999999999995, "end": 388.59999999999997, "text": " Doesn't do a good job with the cat when you use the classic. This is our paper, right?", "tokens": [51506, 12955, 380, 360, 257, 665, 1691, 365, 264, 3857, 562, 291, 764, 264, 7230, 13, 639, 307, 527, 3035, 11, 558, 30, 51802], "temperature": 0.0, "avg_logprob": -0.38205108642578123, "compression_ratio": 1.7107438016528926, "no_speech_prob": 7.368494698312134e-05}, {"id": 84, "seek": 38860, "start": 389.20000000000005, "end": 396.12, "text": " But if you use this chain blurred approach it does a fantastic job, and so I wonder if that might be one secret to the cartoons", "tokens": [50394, 583, 498, 291, 764, 341, 5021, 43525, 3109, 309, 775, 257, 5456, 1691, 11, 293, 370, 286, 2441, 498, 300, 1062, 312, 472, 4054, 281, 264, 34855, 50740], "temperature": 0.0, "avg_logprob": -0.2457731284347235, "compression_ratio": 1.6521739130434783, "no_speech_prob": 2.546576433815062e-05}, {"id": 85, "seek": 38860, "start": 398.28000000000003, "end": 403.70000000000005, "text": " Some of you I saw in the forum have already tried this which is using color preservation and luminance matching", "tokens": [50848, 2188, 295, 291, 286, 1866, 294, 264, 17542, 362, 1217, 3031, 341, 597, 307, 1228, 2017, 27257, 293, 32476, 719, 14324, 51119], "temperature": 0.0, "avg_logprob": -0.2457731284347235, "compression_ratio": 1.6521739130434783, "no_speech_prob": 2.546576433815062e-05}, {"id": 86, "seek": 38860, "start": 403.84000000000003, "end": 410.44, "text": " Which basically means you're still taking the style, but you're not taking the color, and I think in these particular examples", "tokens": [51126, 3013, 1936, 1355, 291, 434, 920, 1940, 264, 3758, 11, 457, 291, 434, 406, 1940, 264, 2017, 11, 293, 286, 519, 294, 613, 1729, 5110, 51456], "temperature": 0.0, "avg_logprob": -0.2457731284347235, "compression_ratio": 1.6521739130434783, "no_speech_prob": 2.546576433815062e-05}, {"id": 87, "seek": 38860, "start": 410.44, "end": 416.04, "text": " This is really great results. I think it depends a lot on what what things you tried with", "tokens": [51456, 639, 307, 534, 869, 3542, 13, 286, 519, 309, 5946, 257, 688, 322, 437, 437, 721, 291, 3031, 365, 51736], "temperature": 0.0, "avg_logprob": -0.2457731284347235, "compression_ratio": 1.6521739130434783, "no_speech_prob": 2.546576433815062e-05}, {"id": 88, "seek": 41604, "start": 417.04, "end": 419.04, "text": " And you can go a lot further", "tokens": [50414, 400, 291, 393, 352, 257, 688, 3052, 50514], "temperature": 0.0, "avg_logprob": -0.3216260274251302, "compression_ratio": 1.7102803738317758, "no_speech_prob": 3.024162469955627e-05}, {"id": 89, "seek": 41604, "start": 419.24, "end": 422.96000000000004, "text": " For example you can add a mask and then say just do", "tokens": [50524, 1171, 1365, 291, 393, 909, 257, 6094, 293, 550, 584, 445, 360, 50710], "temperature": 0.0, "avg_logprob": -0.3216260274251302, "compression_ratio": 1.7102803738317758, "no_speech_prob": 3.024162469955627e-05}, {"id": 90, "seek": 41604, "start": 423.40000000000003, "end": 429.64000000000004, "text": " Color preservation for one part of the photo so here the top part of the photo has got color preservation and the bottom hasn't", "tokens": [50732, 10458, 27257, 337, 472, 644, 295, 264, 5052, 370, 510, 264, 1192, 644, 295, 264, 5052, 575, 658, 2017, 27257, 293, 264, 2767, 6132, 380, 51044], "temperature": 0.0, "avg_logprob": -0.3216260274251302, "compression_ratio": 1.7102803738317758, "no_speech_prob": 3.024162469955627e-05}, {"id": 91, "seek": 41604, "start": 429.92, "end": 431.92, "text": " That's pretty cool", "tokens": [51058, 663, 311, 1238, 1627, 51158], "temperature": 0.0, "avg_logprob": -0.3216260274251302, "compression_ratio": 1.7102803738317758, "no_speech_prob": 3.024162469955627e-05}, {"id": 92, "seek": 41604, "start": 432.64000000000004, "end": 436.08000000000004, "text": " They even show in that code how you can", "tokens": [51194, 814, 754, 855, 294, 300, 3089, 577, 291, 393, 51366], "temperature": 0.0, "avg_logprob": -0.3216260274251302, "compression_ratio": 1.7102803738317758, "no_speech_prob": 3.024162469955627e-05}, {"id": 93, "seek": 41604, "start": 436.64000000000004, "end": 441.08000000000004, "text": " Use a mask to say one part of my image should not be stylized", "tokens": [51394, 8278, 257, 6094, 281, 584, 472, 644, 295, 452, 3256, 820, 406, 312, 23736, 1602, 51616], "temperature": 0.0, "avg_logprob": -0.3216260274251302, "compression_ratio": 1.7102803738317758, "no_speech_prob": 3.024162469955627e-05}, {"id": 94, "seek": 41604, "start": 441.92, "end": 443.92, "text": " Again, I'm getting some good results", "tokens": [51658, 3764, 11, 286, 478, 1242, 512, 665, 3542, 51758], "temperature": 0.0, "avg_logprob": -0.3216260274251302, "compression_ratio": 1.7102803738317758, "no_speech_prob": 3.024162469955627e-05}, {"id": 95, "seek": 44392, "start": 444.52000000000004, "end": 451.64000000000004, "text": " Well this is really crazy use masks to decide which one of two style images to use and", "tokens": [50394, 1042, 341, 307, 534, 3219, 764, 11830, 281, 4536, 597, 472, 295, 732, 3758, 5267, 281, 764, 293, 50750], "temperature": 0.0, "avg_logprob": -0.31095012771749053, "compression_ratio": 1.7153846153846153, "no_speech_prob": 2.0785075321327895e-05}, {"id": 96, "seek": 44392, "start": 451.76, "end": 456.04, "text": " Then you can really generate some creative stuff, so there's a lot of stuff that you can play with and", "tokens": [50756, 1396, 291, 393, 534, 8460, 512, 5880, 1507, 11, 370, 456, 311, 257, 688, 295, 1507, 300, 291, 393, 862, 365, 293, 50970], "temperature": 0.0, "avg_logprob": -0.31095012771749053, "compression_ratio": 1.7153846153846153, "no_speech_prob": 2.0785075321327895e-05}, {"id": 97, "seek": 44392, "start": 456.64000000000004, "end": 458.84000000000003, "text": " You can go beyond this to coming up with your own ideas", "tokens": [51000, 509, 393, 352, 4399, 341, 281, 1348, 493, 365, 428, 1065, 3487, 51110], "temperature": 0.0, "avg_logprob": -0.31095012771749053, "compression_ratio": 1.7153846153846153, "no_speech_prob": 2.0785075321327895e-05}, {"id": 98, "seek": 44392, "start": 460.28000000000003, "end": 465.32, "text": " Now some of the best stuff you're going to learn a bit more today about how to do some of these things better", "tokens": [51182, 823, 512, 295, 264, 1151, 1507, 291, 434, 516, 281, 1466, 257, 857, 544, 965, 466, 577, 281, 360, 512, 295, 613, 721, 1101, 51434], "temperature": 0.0, "avg_logprob": -0.31095012771749053, "compression_ratio": 1.7153846153846153, "no_speech_prob": 2.0785075321327895e-05}, {"id": 99, "seek": 44392, "start": 465.64, "end": 471.64, "text": " But just to give an idea if you go to like mode net you can literally draw something using", "tokens": [51450, 583, 445, 281, 976, 364, 1558, 498, 291, 352, 281, 411, 4391, 2533, 291, 393, 3736, 2642, 746, 1228, 51750], "temperature": 0.0, "avg_logprob": -0.31095012771749053, "compression_ratio": 1.7153846153846153, "no_speech_prob": 2.0785075321327895e-05}, {"id": 100, "seek": 47164, "start": 472.24, "end": 474.24, "text": " All colors and", "tokens": [50394, 1057, 4577, 293, 50494], "temperature": 0.0, "avg_logprob": -0.33962645757765997, "compression_ratio": 1.6736401673640167, "no_speech_prob": 4.133464608457871e-05}, {"id": 101, "seek": 47164, "start": 474.36, "end": 477.96, "text": " Then choose a style image, and it will turn your drawing", "tokens": [50500, 1396, 2826, 257, 3758, 3256, 11, 293, 309, 486, 1261, 428, 6316, 50680], "temperature": 0.0, "avg_logprob": -0.33962645757765997, "compression_ratio": 1.6736401673640167, "no_speech_prob": 4.133464608457871e-05}, {"id": 102, "seek": 47164, "start": 478.64, "end": 483.56, "text": " Into an image basically the idea being that blue is going to be water and greens going to be foliage", "tokens": [50714, 23373, 364, 3256, 1936, 264, 1558, 885, 300, 3344, 307, 516, 281, 312, 1281, 293, 22897, 516, 281, 312, 49767, 50960], "temperature": 0.0, "avg_logprob": -0.33962645757765997, "compression_ratio": 1.6736401673640167, "no_speech_prob": 4.133464608457871e-05}, {"id": 103, "seek": 47164, "start": 483.56, "end": 485.56, "text": " And I guess red is going to be", "tokens": [50960, 400, 286, 2041, 2182, 307, 516, 281, 312, 51060], "temperature": 0.0, "avg_logprob": -0.33962645757765997, "compression_ratio": 1.6736401673640167, "no_speech_prob": 4.133464608457871e-05}, {"id": 104, "seek": 47164, "start": 486.59999999999997, "end": 488.56, "text": " foreground", "tokens": [51112, 32058, 51210], "temperature": 0.0, "avg_logprob": -0.33962645757765997, "compression_ratio": 1.6736401673640167, "no_speech_prob": 4.133464608457871e-05}, {"id": 105, "seek": 47164, "start": 488.56, "end": 491.52, "text": " So that's there's a lot of good examples of this kind of", "tokens": [51210, 407, 300, 311, 456, 311, 257, 688, 295, 665, 5110, 295, 341, 733, 295, 51358], "temperature": 0.0, "avg_logprob": -0.33962645757765997, "compression_ratio": 1.6736401673640167, "no_speech_prob": 4.133464608457871e-05}, {"id": 106, "seek": 47164, "start": 492.71999999999997, "end": 494.71999999999997, "text": " Neural doodle they call it online", "tokens": [51418, 1734, 1807, 360, 30013, 436, 818, 309, 2950, 51518], "temperature": 0.0, "avg_logprob": -0.33962645757765997, "compression_ratio": 1.6736401673640167, "no_speech_prob": 4.133464608457871e-05}, {"id": 107, "seek": 47164, "start": 496.2, "end": 501.0, "text": " Something else we'll learn more about how to do better today is if you go to a fine layer calm", "tokens": [51592, 6595, 1646, 321, 603, 1466, 544, 466, 577, 281, 360, 1101, 965, 307, 498, 291, 352, 281, 257, 2489, 4583, 7151, 51832], "temperature": 0.0, "avg_logprob": -0.33962645757765997, "compression_ratio": 1.6736401673640167, "no_speech_prob": 4.133464608457871e-05}, {"id": 108, "seek": 50100, "start": 501.0, "end": 503.24, "text": " There's a very recent paper called pics to pics", "tokens": [50364, 821, 311, 257, 588, 5162, 3035, 1219, 46690, 281, 46690, 50476], "temperature": 0.0, "avg_logprob": -0.3209294141349146, "compression_ratio": 1.8804347826086956, "no_speech_prob": 3.0241581043810584e-05}, {"id": 109, "seek": 50100, "start": 504.08, "end": 508.16, "text": " Which is basically we're going to be learning quite a bit in this class about how to do segmentation", "tokens": [50518, 3013, 307, 1936, 321, 434, 516, 281, 312, 2539, 1596, 257, 857, 294, 341, 1508, 466, 577, 281, 360, 9469, 399, 50722], "temperature": 0.0, "avg_logprob": -0.3209294141349146, "compression_ratio": 1.8804347826086956, "no_speech_prob": 3.0241581043810584e-05}, {"id": 110, "seek": 50100, "start": 508.4, "end": 515.28, "text": " Which is where you take a photo and turn it into a colored image basically saying the horse is here the bicycles here the persons", "tokens": [50734, 3013, 307, 689, 291, 747, 257, 5052, 293, 1261, 309, 666, 257, 14332, 3256, 1936, 1566, 264, 6832, 307, 510, 264, 47913, 510, 264, 14453, 51078], "temperature": 0.0, "avg_logprob": -0.3209294141349146, "compression_ratio": 1.8804347826086956, "no_speech_prob": 3.0241581043810584e-05}, {"id": 111, "seek": 50100, "start": 515.28, "end": 518.92, "text": " Here this is basically doing the opposite is that by drawing something?", "tokens": [51078, 1692, 341, 307, 1936, 884, 264, 6182, 307, 300, 538, 6316, 746, 30, 51260], "temperature": 0.0, "avg_logprob": -0.3209294141349146, "compression_ratio": 1.8804347826086956, "no_speech_prob": 3.0241581043810584e-05}, {"id": 112, "seek": 50100, "start": 519.4, "end": 525.68, "text": " Saying I want you to create something that has a window here and a windowsill here and a door here and column there and", "tokens": [51284, 34087, 286, 528, 291, 281, 1884, 746, 300, 575, 257, 4910, 510, 293, 257, 9309, 373, 510, 293, 257, 2853, 510, 293, 7738, 456, 293, 51598], "temperature": 0.0, "avg_logprob": -0.3209294141349146, "compression_ratio": 1.8804347826086956, "no_speech_prob": 3.0241581043810584e-05}, {"id": 113, "seek": 50100, "start": 525.88, "end": 527.88, "text": " It generates a photo", "tokens": [51608, 467, 23815, 257, 5052, 51708], "temperature": 0.0, "avg_logprob": -0.3209294141349146, "compression_ratio": 1.8804347826086956, "no_speech_prob": 3.0241581043810584e-05}, {"id": 114, "seek": 50100, "start": 527.92, "end": 529.92, "text": " Which is fairly remarkable?", "tokens": [51710, 3013, 307, 6457, 12802, 30, 51810], "temperature": 0.0, "avg_logprob": -0.3209294141349146, "compression_ratio": 1.8804347826086956, "no_speech_prob": 3.0241581043810584e-05}, {"id": 115, "seek": 53100, "start": 531.4, "end": 535.32, "text": " So the stuff we've learned so far won't quite get you to do these two things", "tokens": [50384, 407, 264, 1507, 321, 600, 3264, 370, 1400, 1582, 380, 1596, 483, 291, 281, 360, 613, 732, 721, 50580], "temperature": 0.0, "avg_logprob": -0.2898173001733157, "compression_ratio": 1.6124031007751938, "no_speech_prob": 2.4679671696503647e-05}, {"id": 116, "seek": 53100, "start": 535.32, "end": 537.32, "text": " But by the end of today, we should be able to", "tokens": [50580, 583, 538, 264, 917, 295, 965, 11, 321, 820, 312, 1075, 281, 50680], "temperature": 0.0, "avg_logprob": -0.2898173001733157, "compression_ratio": 1.6124031007751938, "no_speech_prob": 2.4679671696503647e-05}, {"id": 117, "seek": 53100, "start": 539.44, "end": 545.84, "text": " This is a nice example that I think some folks at Adobe built showing that you could basically draw", "tokens": [50786, 639, 307, 257, 1481, 1365, 300, 286, 519, 512, 4024, 412, 24862, 3094, 4099, 300, 291, 727, 1936, 2642, 51106], "temperature": 0.0, "avg_logprob": -0.2898173001733157, "compression_ratio": 1.6124031007751938, "no_speech_prob": 2.4679671696503647e-05}, {"id": 118, "seek": 53100, "start": 546.68, "end": 552.84, "text": " Something and it would try and generate an image that was close to your drawing where you just needed a small number of lines", "tokens": [51148, 6595, 293, 309, 576, 853, 293, 8460, 364, 3256, 300, 390, 1998, 281, 428, 6316, 689, 291, 445, 2978, 257, 1359, 1230, 295, 3876, 51456], "temperature": 0.0, "avg_logprob": -0.2898173001733157, "compression_ratio": 1.6124031007751938, "no_speech_prob": 2.4679671696503647e-05}, {"id": 119, "seek": 53100, "start": 553.56, "end": 555.56, "text": " Again, you can find this", "tokens": [51492, 3764, 11, 291, 393, 915, 341, 51592], "temperature": 0.0, "avg_logprob": -0.2898173001733157, "compression_ratio": 1.6124031007751938, "no_speech_prob": 2.4679671696503647e-05}, {"id": 120, "seek": 53100, "start": 555.84, "end": 558.36, "text": " Will link to this paper from the resources", "tokens": [51606, 3099, 2113, 281, 341, 3035, 490, 264, 3593, 51732], "temperature": 0.0, "avg_logprob": -0.2898173001733157, "compression_ratio": 1.6124031007751938, "no_speech_prob": 2.4679671696503647e-05}, {"id": 121, "seek": 55836, "start": 559.0, "end": 562.28, "text": " This actually shows it to you in real time. You can see that there's this", "tokens": [50396, 639, 767, 3110, 309, 281, 291, 294, 957, 565, 13, 509, 393, 536, 300, 456, 311, 341, 50560], "temperature": 0.0, "avg_logprob": -0.3083084179804875, "compression_ratio": 1.64, "no_speech_prob": 7.36836955184117e-05}, {"id": 122, "seek": 55836, "start": 563.96, "end": 569.96, "text": " There's some new way of doing art that's starting to appear where you don't necessarily need a whole lot of technique", "tokens": [50644, 821, 311, 512, 777, 636, 295, 884, 1523, 300, 311, 2891, 281, 4204, 689, 291, 500, 380, 4725, 643, 257, 1379, 688, 295, 6532, 50944], "temperature": 0.0, "avg_logprob": -0.3083084179804875, "compression_ratio": 1.64, "no_speech_prob": 7.36836955184117e-05}, {"id": 123, "seek": 55836, "start": 570.4, "end": 571.6, "text": " I'm not promising", "tokens": [50966, 286, 478, 406, 20257, 51026], "temperature": 0.0, "avg_logprob": -0.3083084179804875, "compression_ratio": 1.64, "no_speech_prob": 7.36836955184117e-05}, {"id": 124, "seek": 55836, "start": 571.6, "end": 572.72, "text": " It's going to turn you into a van Gogh", "tokens": [51026, 467, 311, 516, 281, 1261, 291, 666, 257, 3161, 39690, 71, 51082], "temperature": 0.0, "avg_logprob": -0.3083084179804875, "compression_ratio": 1.64, "no_speech_prob": 7.36836955184117e-05}, {"id": 125, "seek": 55836, "start": 572.72, "end": 578.16, "text": " But you can at least generate images that maybe you're in your head in some style that's somewhat similar to somebody else's", "tokens": [51082, 583, 291, 393, 412, 1935, 8460, 5267, 300, 1310, 291, 434, 294, 428, 1378, 294, 512, 3758, 300, 311, 8344, 2531, 281, 2618, 1646, 311, 51354], "temperature": 0.0, "avg_logprob": -0.3083084179804875, "compression_ratio": 1.64, "no_speech_prob": 7.36836955184117e-05}, {"id": 126, "seek": 55836, "start": 578.36, "end": 580.36, "text": " I think it's really interesting", "tokens": [51364, 286, 519, 309, 311, 534, 1880, 51464], "temperature": 0.0, "avg_logprob": -0.3083084179804875, "compression_ratio": 1.64, "no_speech_prob": 7.36836955184117e-05}, {"id": 127, "seek": 55836, "start": 581.28, "end": 583.28, "text": " Okay", "tokens": [51510, 1033, 51610], "temperature": 0.0, "avg_logprob": -0.3083084179804875, "compression_ratio": 1.64, "no_speech_prob": 7.36836955184117e-05}, {"id": 128, "seek": 58328, "start": 583.28, "end": 585.28, "text": " One", "tokens": [50364, 1485, 50464], "temperature": 0.0, "avg_logprob": -0.3406846961196588, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.00012929261720273644}, {"id": 129, "seek": 58328, "start": 585.68, "end": 592.12, "text": " Thing I was thrilled to see is that at least two of you have already written blog posts on medium", "tokens": [50484, 30902, 286, 390, 18744, 281, 536, 307, 300, 412, 1935, 732, 295, 291, 362, 1217, 3720, 6968, 12300, 322, 6399, 50806], "temperature": 0.0, "avg_logprob": -0.3406846961196588, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.00012929261720273644}, {"id": 130, "seek": 58328, "start": 592.72, "end": 597.16, "text": " That was fantastic to see so I hope more of you might try to do that this week", "tokens": [50836, 663, 390, 5456, 281, 536, 370, 286, 1454, 544, 295, 291, 1062, 853, 281, 360, 300, 341, 1243, 51058], "temperature": 0.0, "avg_logprob": -0.3406846961196588, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.00012929261720273644}, {"id": 131, "seek": 58328, "start": 598.4, "end": 600.4, "text": " Definitely doesn't need to be something that takes a long time", "tokens": [51120, 12151, 1177, 380, 643, 281, 312, 746, 300, 2516, 257, 938, 565, 51220], "temperature": 0.0, "avg_logprob": -0.3406846961196588, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.00012929261720273644}, {"id": 132, "seek": 58328, "start": 601.88, "end": 603.1999999999999, "text": " I", "tokens": [51294, 286, 51360], "temperature": 0.0, "avg_logprob": -0.3406846961196588, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.00012929261720273644}, {"id": 133, "seek": 58328, "start": 603.1999999999999, "end": 608.36, "text": " Know some of you already planned also planning on turning your forum posts into blog posts", "tokens": [51360, 10265, 512, 295, 291, 1217, 8589, 611, 5038, 322, 6246, 428, 17542, 12300, 666, 6968, 12300, 51618], "temperature": 0.0, "avg_logprob": -0.3406846961196588, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.00012929261720273644}, {"id": 134, "seek": 58328, "start": 608.56, "end": 611.92, "text": " So hopefully we'll see a lot more blog posts this week popping up", "tokens": [51628, 407, 4696, 321, 603, 536, 257, 688, 544, 6968, 12300, 341, 1243, 18374, 493, 51796], "temperature": 0.0, "avg_logprob": -0.3406846961196588, "compression_ratio": 1.7478260869565216, "no_speech_prob": 0.00012929261720273644}, {"id": 135, "seek": 61192, "start": 612.8, "end": 616.36, "text": " I know the people who have done that have found that a useful experience as well, so", "tokens": [50408, 286, 458, 264, 561, 567, 362, 1096, 300, 362, 1352, 300, 257, 4420, 1752, 382, 731, 11, 370, 50586], "temperature": 0.0, "avg_logprob": -0.2916448474985308, "compression_ratio": 1.790874524714829, "no_speech_prob": 1.6964238966465928e-05}, {"id": 136, "seek": 61192, "start": 618.8, "end": 624.1999999999999, "text": " One of the things that I suggested doing pretty high on the list of priorities for this week's", "tokens": [50708, 1485, 295, 264, 721, 300, 286, 10945, 884, 1238, 1090, 322, 264, 1329, 295, 15503, 337, 341, 1243, 311, 50978], "temperature": 0.0, "avg_logprob": -0.2916448474985308, "compression_ratio": 1.790874524714829, "no_speech_prob": 1.6964238966465928e-05}, {"id": 137, "seek": 61192, "start": 624.88, "end": 628.28, "text": " Assignment was to go through the paper", "tokens": [51012, 6281, 41134, 390, 281, 352, 807, 264, 3035, 51182], "temperature": 0.0, "avg_logprob": -0.2916448474985308, "compression_ratio": 1.790874524714829, "no_speech_prob": 1.6964238966465928e-05}, {"id": 138, "seek": 61192, "start": 629.24, "end": 632.36, "text": " Knowing what it's going to say you know I think this is really helpful", "tokens": [51230, 25499, 437, 309, 311, 516, 281, 584, 291, 458, 286, 519, 341, 307, 534, 4961, 51386], "temperature": 0.0, "avg_logprob": -0.2916448474985308, "compression_ratio": 1.790874524714829, "no_speech_prob": 1.6964238966465928e-05}, {"id": 139, "seek": 61192, "start": 632.36, "end": 635.92, "text": " It's when you already know how to do something is to go back over that paper", "tokens": [51386, 467, 311, 562, 291, 1217, 458, 577, 281, 360, 746, 307, 281, 352, 646, 670, 300, 3035, 51564], "temperature": 0.0, "avg_logprob": -0.2916448474985308, "compression_ratio": 1.790874524714829, "no_speech_prob": 1.6964238966465928e-05}, {"id": 140, "seek": 61192, "start": 635.92, "end": 640.64, "text": " And this is a great way to learn how to read papers right because you already know what it's telling you", "tokens": [51564, 400, 341, 307, 257, 869, 636, 281, 1466, 577, 281, 1401, 10577, 558, 570, 291, 1217, 458, 437, 309, 311, 3585, 291, 51800], "temperature": 0.0, "avg_logprob": -0.2916448474985308, "compression_ratio": 1.790874524714829, "no_speech_prob": 1.6964238966465928e-05}, {"id": 141, "seek": 64064, "start": 640.96, "end": 642.96, "text": " This is like the way I", "tokens": [50380, 639, 307, 411, 264, 636, 286, 50480], "temperature": 0.0, "avg_logprob": -0.33747361295966694, "compression_ratio": 1.599078341013825, "no_speech_prob": 8.397836609219667e-06}, {"id": 142, "seek": 64064, "start": 643.72, "end": 646.76, "text": " Learn to read papers was totally this method", "tokens": [50518, 17216, 281, 1401, 10577, 390, 3879, 341, 3170, 50670], "temperature": 0.0, "avg_logprob": -0.33747361295966694, "compression_ratio": 1.599078341013825, "no_speech_prob": 8.397836609219667e-06}, {"id": 143, "seek": 64064, "start": 647.36, "end": 649.36, "text": " so I've kind of gone through and I", "tokens": [50700, 370, 286, 600, 733, 295, 2780, 807, 293, 286, 50800], "temperature": 0.0, "avg_logprob": -0.33747361295966694, "compression_ratio": 1.599078341013825, "no_speech_prob": 8.397836609219667e-06}, {"id": 144, "seek": 64064, "start": 649.52, "end": 656.62, "text": " Have highlighted a few key things which I as I went through I thought were kind of important so in the abstract of the paper", "tokens": [50808, 3560, 17173, 257, 1326, 2141, 721, 597, 286, 382, 286, 1437, 807, 286, 1194, 645, 733, 295, 1021, 370, 294, 264, 12649, 295, 264, 3035, 51163], "temperature": 0.0, "avg_logprob": -0.33747361295966694, "compression_ratio": 1.599078341013825, "no_speech_prob": 8.397836609219667e-06}, {"id": 145, "seek": 64064, "start": 657.88, "end": 662.56, "text": " But let me ask say how many people kind of went back and re-looked at this paper again", "tokens": [51226, 583, 718, 385, 1029, 584, 577, 867, 561, 733, 295, 1437, 646, 293, 319, 12, 30953, 412, 341, 3035, 797, 51460], "temperature": 0.0, "avg_logprob": -0.33747361295966694, "compression_ratio": 1.599078341013825, "no_speech_prob": 8.397836609219667e-06}, {"id": 146, "seek": 64064, "start": 663.16, "end": 665.16, "text": " But a few of you that's great", "tokens": [51490, 583, 257, 1326, 295, 291, 300, 311, 869, 51590], "temperature": 0.0, "avg_logprob": -0.33747361295966694, "compression_ratio": 1.599078341013825, "no_speech_prob": 8.397836609219667e-06}, {"id": 147, "seek": 64064, "start": 666.28, "end": 667.96, "text": " So", "tokens": [51646, 407, 51730], "temperature": 0.0, "avg_logprob": -0.33747361295966694, "compression_ratio": 1.599078341013825, "no_speech_prob": 8.397836609219667e-06}, {"id": 148, "seek": 66796, "start": 668.0, "end": 674.44, "text": " In the abstract they basically say what is it they're introducing so it's a system based on a deep neural network that creates artistic images", "tokens": [50366, 682, 264, 12649, 436, 1936, 584, 437, 307, 309, 436, 434, 15424, 370, 309, 311, 257, 1185, 2361, 322, 257, 2452, 18161, 3209, 300, 7829, 17090, 5267, 50688], "temperature": 0.0, "avg_logprob": -0.28838611135677417, "compression_ratio": 1.5962264150943397, "no_speech_prob": 0.00011235100100748241}, {"id": 149, "seek": 66796, "start": 674.44, "end": 679.64, "text": " And high perceptual quality okay, so we're going to read this paper and hopefully at the end of it. We all know how to do that", "tokens": [50688, 400, 1090, 43276, 901, 3125, 1392, 11, 370, 321, 434, 516, 281, 1401, 341, 3035, 293, 4696, 412, 264, 917, 295, 309, 13, 492, 439, 458, 577, 281, 360, 300, 50948], "temperature": 0.0, "avg_logprob": -0.28838611135677417, "compression_ratio": 1.5962264150943397, "no_speech_prob": 0.00011235100100748241}, {"id": 150, "seek": 66796, "start": 681.2, "end": 683.2, "text": " Then in the first section", "tokens": [51026, 1396, 294, 264, 700, 3541, 51126], "temperature": 0.0, "avg_logprob": -0.28838611135677417, "compression_ratio": 1.5962264150943397, "no_speech_prob": 0.00011235100100748241}, {"id": 151, "seek": 66796, "start": 683.6, "end": 689.6800000000001, "text": " They tell us about the basic ideas so when CNN's are trained on object recognition. They developed a", "tokens": [51146, 814, 980, 505, 466, 264, 3875, 3487, 370, 562, 24859, 311, 366, 8895, 322, 2657, 11150, 13, 814, 4743, 257, 51450], "temperature": 0.0, "avg_logprob": -0.28838611135677417, "compression_ratio": 1.5962264150943397, "no_speech_prob": 0.00011235100100748241}, {"id": 152, "seek": 66796, "start": 690.48, "end": 692.4000000000001, "text": " representation of an image", "tokens": [51490, 10290, 295, 364, 3256, 51586], "temperature": 0.0, "avg_logprob": -0.28838611135677417, "compression_ratio": 1.5962264150943397, "no_speech_prob": 0.00011235100100748241}, {"id": 153, "seek": 69240, "start": 692.4, "end": 698.56, "text": " Along the processing hierarchy of the network it's transformed into representations that increasingly care about the actual content", "tokens": [50364, 17457, 264, 9007, 22333, 295, 264, 3209, 309, 311, 16894, 666, 33358, 300, 12980, 1127, 466, 264, 3539, 2701, 50672], "temperature": 0.0, "avg_logprob": -0.3293946357000442, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.002844851929694414}, {"id": 154, "seek": 69240, "start": 699.16, "end": 701.16, "text": " compared to the pixel values", "tokens": [50702, 5347, 281, 264, 19261, 4190, 50802], "temperature": 0.0, "avg_logprob": -0.3293946357000442, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.002844851929694414}, {"id": 155, "seek": 69240, "start": 701.68, "end": 704.98, "text": " So it describes the basic idea of content loss", "tokens": [50828, 407, 309, 15626, 264, 3875, 1558, 295, 2701, 4470, 50993], "temperature": 0.0, "avg_logprob": -0.3293946357000442, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.002844851929694414}, {"id": 156, "seek": 69240, "start": 705.84, "end": 708.12, "text": " Then they describe the basic idea of style loss", "tokens": [51036, 1396, 436, 6786, 264, 3875, 1558, 295, 3758, 4470, 51150], "temperature": 0.0, "avg_logprob": -0.3293946357000442, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.002844851929694414}, {"id": 157, "seek": 69240, "start": 709.88, "end": 713.4399999999999, "text": " Which is looking at the correlations between the different filter responses", "tokens": [51238, 3013, 307, 1237, 412, 264, 13983, 763, 1296, 264, 819, 6608, 13019, 51416], "temperature": 0.0, "avg_logprob": -0.3293946357000442, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.002844851929694414}, {"id": 158, "seek": 69240, "start": 713.72, "end": 717.4, "text": " Over the spatial extent of the feature maps and this is one of these sentences that", "tokens": [51430, 4886, 264, 23598, 8396, 295, 264, 4111, 11317, 293, 341, 307, 472, 295, 613, 16579, 300, 51614], "temperature": 0.0, "avg_logprob": -0.3293946357000442, "compression_ratio": 1.7148760330578512, "no_speech_prob": 0.002844851929694414}, {"id": 159, "seek": 71740, "start": 717.88, "end": 720.0799999999999, "text": " Read on its own doesn't mean very much", "tokens": [50388, 17604, 322, 1080, 1065, 1177, 380, 914, 588, 709, 50498], "temperature": 0.0, "avg_logprob": -0.34328919072305003, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.00036258669570088387}, {"id": 160, "seek": 71740, "start": 720.0799999999999, "end": 723.48, "text": " And now that you know how to do it you can read it and be like okay", "tokens": [50498, 400, 586, 300, 291, 458, 577, 281, 360, 309, 291, 393, 1401, 309, 293, 312, 411, 1392, 50668], "temperature": 0.0, "avg_logprob": -0.34328919072305003, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.00036258669570088387}, {"id": 161, "seek": 71740, "start": 723.48, "end": 728.0, "text": " I think I see what that means and then when you get to the methods section we learn more", "tokens": [50668, 286, 519, 286, 536, 437, 300, 1355, 293, 550, 562, 291, 483, 281, 264, 7150, 3541, 321, 1466, 544, 50894], "temperature": 0.0, "avg_logprob": -0.34328919072305003, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.00036258669570088387}, {"id": 162, "seek": 71740, "start": 728.64, "end": 735.0, "text": " So the idea here is that by including the feature correlations and this answers one of the questions that one of you had on the forum", "tokens": [50926, 407, 264, 1558, 510, 307, 300, 538, 3009, 264, 4111, 13983, 763, 293, 341, 6338, 472, 295, 264, 1651, 300, 472, 295, 291, 632, 322, 264, 17542, 51244], "temperature": 0.0, "avg_logprob": -0.34328919072305003, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.00036258669570088387}, {"id": 163, "seek": 71740, "start": 735.0, "end": 741.24, "text": " By including feature correlations of multiple layers we obtain a multi-scale representation of the input image", "tokens": [51244, 3146, 3009, 4111, 13983, 763, 295, 3866, 7914, 321, 12701, 257, 4825, 12, 20033, 10290, 295, 264, 4846, 3256, 51556], "temperature": 0.0, "avg_logprob": -0.34328919072305003, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.00036258669570088387}, {"id": 164, "seek": 71740, "start": 741.84, "end": 746.12, "text": " This idea of a multi-scale representation is something we're going to be coming across a lot", "tokens": [51586, 639, 1558, 295, 257, 4825, 12, 20033, 10290, 307, 746, 321, 434, 516, 281, 312, 1348, 2108, 257, 688, 51800], "temperature": 0.0, "avg_logprob": -0.34328919072305003, "compression_ratio": 1.88339222614841, "no_speech_prob": 0.00036258669570088387}, {"id": 165, "seek": 74612, "start": 746.48, "end": 751.96, "text": " because a lot of this as we discussed last week a lot of this class is about generative models and", "tokens": [50382, 570, 257, 688, 295, 341, 382, 321, 7152, 1036, 1243, 257, 688, 295, 341, 1508, 307, 466, 1337, 1166, 5245, 293, 50656], "temperature": 0.0, "avg_logprob": -0.31992338161275846, "compression_ratio": 1.9022222222222223, "no_speech_prob": 8.219982555601746e-05}, {"id": 166, "seek": 74612, "start": 752.72, "end": 756.6, "text": " one of the tricky things with generative models is both to get the kind of", "tokens": [50694, 472, 295, 264, 12414, 721, 365, 1337, 1166, 5245, 307, 1293, 281, 483, 264, 733, 295, 50888], "temperature": 0.0, "avg_logprob": -0.31992338161275846, "compression_ratio": 1.9022222222222223, "no_speech_prob": 8.219982555601746e-05}, {"id": 167, "seek": 74612, "start": 757.04, "end": 760.36, "text": " The general idea of the thing you're trying to generate", "tokens": [50910, 440, 2674, 1558, 295, 264, 551, 291, 434, 1382, 281, 8460, 51076], "temperature": 0.0, "avg_logprob": -0.31992338161275846, "compression_ratio": 1.9022222222222223, "no_speech_prob": 8.219982555601746e-05}, {"id": 168, "seek": 74612, "start": 760.88, "end": 766.76, "text": " Correct, but also get all the details correct and so the details generally requires you to zoom into a small scale", "tokens": [51102, 12753, 11, 457, 611, 483, 439, 264, 4365, 3006, 293, 370, 264, 4365, 5101, 7029, 291, 281, 8863, 666, 257, 1359, 4373, 51396], "temperature": 0.0, "avg_logprob": -0.31992338161275846, "compression_ratio": 1.9022222222222223, "no_speech_prob": 8.219982555601746e-05}, {"id": 169, "seek": 74612, "start": 766.92, "end": 770.64, "text": " And getting a kind of the big picture correct is about zooming out to a large scale", "tokens": [51404, 400, 1242, 257, 733, 295, 264, 955, 3036, 3006, 307, 466, 48226, 484, 281, 257, 2416, 4373, 51590], "temperature": 0.0, "avg_logprob": -0.31992338161275846, "compression_ratio": 1.9022222222222223, "no_speech_prob": 8.219982555601746e-05}, {"id": 170, "seek": 77064, "start": 771.24, "end": 777.4399999999999, "text": " So this was one of the key things that they did in this paper was show how to create a style representation that included", "tokens": [50394, 407, 341, 390, 472, 295, 264, 2141, 721, 300, 436, 630, 294, 341, 3035, 390, 855, 577, 281, 1884, 257, 3758, 10290, 300, 5556, 50704], "temperature": 0.0, "avg_logprob": -0.3238973056568819, "compression_ratio": 1.7751937984496124, "no_speech_prob": 3.591240238165483e-05}, {"id": 171, "seek": 77064, "start": 777.96, "end": 783.6, "text": " Multiple resolutions, and we know now know that where they did that was to use multiple style layers", "tokens": [50730, 40056, 32179, 11, 293, 321, 458, 586, 458, 300, 689, 436, 630, 300, 390, 281, 764, 3866, 3758, 7914, 51012], "temperature": 0.0, "avg_logprob": -0.3238973056568819, "compression_ratio": 1.7751937984496124, "no_speech_prob": 3.591240238165483e-05}, {"id": 172, "seek": 77064, "start": 783.6, "end": 789.1999999999999, "text": " And as we go through the layers of a GG they gradually become lower and lower resolution", "tokens": [51012, 400, 382, 321, 352, 807, 264, 7914, 295, 257, 42240, 436, 13145, 1813, 3126, 293, 3126, 8669, 51292], "temperature": 0.0, "avg_logprob": -0.3238973056568819, "compression_ratio": 1.7751937984496124, "no_speech_prob": 3.591240238165483e-05}, {"id": 173, "seek": 77064, "start": 789.64, "end": 791.64, "text": " larger and larger receptive fields", "tokens": [51314, 4833, 293, 4833, 45838, 7909, 51414], "temperature": 0.0, "avg_logprob": -0.3238973056568819, "compression_ratio": 1.7751937984496124, "no_speech_prob": 3.591240238165483e-05}, {"id": 174, "seek": 77064, "start": 794.24, "end": 799.0, "text": " I'm always great to look at the figures and make sure and I was thrilled to see that some of you were trying to", "tokens": [51544, 286, 478, 1009, 869, 281, 574, 412, 264, 9624, 293, 652, 988, 293, 286, 390, 18744, 281, 536, 300, 512, 295, 291, 645, 1382, 281, 51782], "temperature": 0.0, "avg_logprob": -0.3238973056568819, "compression_ratio": 1.7751937984496124, "no_speech_prob": 3.591240238165483e-05}, {"id": 175, "seek": 79900, "start": 799.12, "end": 802.88, "text": " Recreate these figures which actually turned out to be slightly non-trivial", "tokens": [50370, 9647, 265, 473, 613, 9624, 597, 767, 3574, 484, 281, 312, 4748, 2107, 12, 83, 470, 22640, 50558], "temperature": 0.0, "avg_logprob": -0.2829704049192829, "compression_ratio": 1.5767195767195767, "no_speech_prob": 8.801001058600377e-06}, {"id": 176, "seek": 79900, "start": 804.92, "end": 811.0, "text": " So we can see exactly what that figure is and if you haven't tried it for yourself yet", "tokens": [50660, 407, 321, 393, 536, 2293, 437, 300, 2573, 307, 293, 498, 291, 2378, 380, 3031, 309, 337, 1803, 1939, 50964], "temperature": 0.0, "avg_logprob": -0.2829704049192829, "compression_ratio": 1.5767195767195767, "no_speech_prob": 8.801001058600377e-06}, {"id": 177, "seek": 79900, "start": 811.0, "end": 813.0, "text": " You might want to try it see if you can recreate", "tokens": [50964, 509, 1062, 528, 281, 853, 309, 536, 498, 291, 393, 25833, 51064], "temperature": 0.0, "avg_logprob": -0.2829704049192829, "compression_ratio": 1.5767195767195767, "no_speech_prob": 8.801001058600377e-06}, {"id": 178, "seek": 79900, "start": 813.4, "end": 815.4, "text": " this figure", "tokens": [51084, 341, 2573, 51184], "temperature": 0.0, "avg_logprob": -0.2829704049192829, "compression_ratio": 1.5767195767195767, "no_speech_prob": 8.801001058600377e-06}, {"id": 179, "seek": 79900, "start": 819.32, "end": 820.8, "text": " Okay", "tokens": [51380, 1033, 51454], "temperature": 0.0, "avg_logprob": -0.2829704049192829, "compression_ratio": 1.5767195767195767, "no_speech_prob": 8.801001058600377e-06}, {"id": 180, "seek": 79900, "start": 820.8, "end": 824.44, "text": " It's good to try and find in a paper the key finding you know the key", "tokens": [51454, 467, 311, 665, 281, 853, 293, 915, 294, 257, 3035, 264, 2141, 5006, 291, 458, 264, 2141, 51636], "temperature": 0.0, "avg_logprob": -0.2829704049192829, "compression_ratio": 1.5767195767195767, "no_speech_prob": 8.801001058600377e-06}, {"id": 181, "seek": 82444, "start": 825.0, "end": 828.36, "text": " The key thing that they're showing in this case they found that", "tokens": [50392, 440, 2141, 551, 300, 436, 434, 4099, 294, 341, 1389, 436, 1352, 300, 50560], "temperature": 0.0, "avg_logprob": -0.36312882493181925, "compression_ratio": 1.6, "no_speech_prob": 0.00011234939302084967}, {"id": 182, "seek": 82444, "start": 828.72, "end": 835.22, "text": " Representations of content and style and a CNN are separable and you can manipulate both to create new images", "tokens": [50578, 19945, 763, 295, 2701, 293, 3758, 293, 257, 24859, 366, 3128, 712, 293, 291, 393, 20459, 1293, 281, 1884, 777, 5267, 50903], "temperature": 0.0, "avg_logprob": -0.36312882493181925, "compression_ratio": 1.6, "no_speech_prob": 0.00011234939302084967}, {"id": 183, "seek": 82444, "start": 835.44, "end": 840.0400000000001, "text": " It's again. Hopefully that now you can look at that and say oh, yeah that makes sense", "tokens": [50914, 467, 311, 797, 13, 10429, 300, 586, 291, 393, 574, 412, 300, 293, 584, 1954, 11, 1338, 300, 1669, 2020, 51144], "temperature": 0.0, "avg_logprob": -0.36312882493181925, "compression_ratio": 1.6, "no_speech_prob": 0.00011234939302084967}, {"id": 184, "seek": 82444, "start": 848.1600000000001, "end": 852.0400000000001, "text": " You can see that with papers certainly with this paper. There's often quite a lot of", "tokens": [51550, 509, 393, 536, 300, 365, 10577, 3297, 365, 341, 3035, 13, 821, 311, 2049, 1596, 257, 688, 295, 51744], "temperature": 0.0, "avg_logprob": -0.36312882493181925, "compression_ratio": 1.6, "no_speech_prob": 0.00011234939302084967}, {"id": 185, "seek": 85204, "start": 853.0, "end": 857.28, "text": " Introduction that often says the same thing a bunch of different ways, so it's often worth", "tokens": [50412, 27193, 882, 300, 2049, 1619, 264, 912, 551, 257, 3840, 295, 819, 2098, 11, 370, 309, 311, 2049, 3163, 50626], "temperature": 0.0, "avg_logprob": -0.34488682124925696, "compression_ratio": 1.6903765690376569, "no_speech_prob": 1.4970642951084301e-05}, {"id": 186, "seek": 85204, "start": 857.68, "end": 861.92, "text": " You know the first time you read it one paragraph might not make sense", "tokens": [50646, 509, 458, 264, 700, 565, 291, 1401, 309, 472, 18865, 1062, 406, 652, 2020, 50858], "temperature": 0.0, "avg_logprob": -0.34488682124925696, "compression_ratio": 1.6903765690376569, "no_speech_prob": 1.4970642951084301e-05}, {"id": 187, "seek": 85204, "start": 861.92, "end": 865.0799999999999, "text": " But later on they say it in a different way, and it starts to make more sense", "tokens": [50858, 583, 1780, 322, 436, 584, 309, 294, 257, 819, 636, 11, 293, 309, 3719, 281, 652, 544, 2020, 51016], "temperature": 0.0, "avg_logprob": -0.34488682124925696, "compression_ratio": 1.6903765690376569, "no_speech_prob": 1.4970642951084301e-05}, {"id": 188, "seek": 85204, "start": 865.0799999999999, "end": 868.92, "text": " So it's worth looking through the introductory remarks maybe", "tokens": [51016, 407, 309, 311, 3163, 1237, 807, 264, 39048, 19151, 1310, 51208], "temperature": 0.0, "avg_logprob": -0.34488682124925696, "compression_ratio": 1.6903765690376569, "no_speech_prob": 1.4970642951084301e-05}, {"id": 189, "seek": 85204, "start": 869.52, "end": 871.52, "text": " two or three times", "tokens": [51238, 732, 420, 1045, 1413, 51338], "temperature": 0.0, "avg_logprob": -0.34488682124925696, "compression_ratio": 1.6903765690376569, "no_speech_prob": 1.4970642951084301e-05}, {"id": 190, "seek": 85204, "start": 873.04, "end": 877.9599999999999, "text": " They can certainly see that again talking about the different layers how they behave", "tokens": [51414, 814, 393, 3297, 536, 300, 797, 1417, 466, 264, 819, 7914, 577, 436, 15158, 51660], "temperature": 0.0, "avg_logprob": -0.34488682124925696, "compression_ratio": 1.6903765690376569, "no_speech_prob": 1.4970642951084301e-05}, {"id": 191, "seek": 88204, "start": 883.0, "end": 885.0, "text": " Right again showing", "tokens": [50412, 1779, 797, 4099, 50512], "temperature": 0.0, "avg_logprob": -0.326310079032128, "compression_ratio": 1.8109090909090908, "no_speech_prob": 4.264686504029669e-05}, {"id": 192, "seek": 88204, "start": 885.5999999999999, "end": 892.16, "text": " The results of some experiments so again you can see if you couldn't recreate these experiments make sure that you understand how to do it", "tokens": [50542, 440, 3542, 295, 512, 12050, 370, 797, 291, 393, 536, 498, 291, 2809, 380, 25833, 613, 12050, 652, 988, 300, 291, 1223, 577, 281, 360, 309, 50870], "temperature": 0.0, "avg_logprob": -0.326310079032128, "compression_ratio": 1.8109090909090908, "no_speech_prob": 4.264686504029669e-05}, {"id": 193, "seek": 88204, "start": 894.36, "end": 896.4, "text": " And then there's a kind of a lot of stuff", "tokens": [50980, 400, 550, 456, 311, 257, 733, 295, 257, 688, 295, 1507, 51082], "temperature": 0.0, "avg_logprob": -0.326310079032128, "compression_ratio": 1.8109090909090908, "no_speech_prob": 4.264686504029669e-05}, {"id": 194, "seek": 88204, "start": 896.4, "end": 899.48, "text": " I didn't find that interesting until we get to the section called methods", "tokens": [51082, 286, 994, 380, 915, 300, 1880, 1826, 321, 483, 281, 264, 3541, 1219, 7150, 51236], "temperature": 0.0, "avg_logprob": -0.326310079032128, "compression_ratio": 1.8109090909090908, "no_speech_prob": 4.264686504029669e-05}, {"id": 195, "seek": 88204, "start": 900.0, "end": 904.4, "text": " So the method section is the section that hopefully you'll learn the most about reading papers", "tokens": [51262, 407, 264, 3170, 3541, 307, 264, 3541, 300, 4696, 291, 603, 1466, 264, 881, 466, 3760, 10577, 51482], "temperature": 0.0, "avg_logprob": -0.326310079032128, "compression_ratio": 1.8109090909090908, "no_speech_prob": 4.264686504029669e-05}, {"id": 196, "seek": 88204, "start": 904.68, "end": 910.16, "text": " After you've implemented something by reading the section called methods now. I want to show you a few little tricks of notation", "tokens": [51496, 2381, 291, 600, 12270, 746, 538, 3760, 264, 3541, 1219, 7150, 586, 13, 286, 528, 281, 855, 291, 257, 1326, 707, 11733, 295, 24657, 51770], "temperature": 0.0, "avg_logprob": -0.326310079032128, "compression_ratio": 1.8109090909090908, "no_speech_prob": 4.264686504029669e-05}, {"id": 197, "seek": 91016, "start": 910.36, "end": 912.36, "text": " You", "tokens": [50374, 509, 50474], "temperature": 0.0, "avg_logprob": -0.3836635108132964, "compression_ratio": 1.7142857142857142, "no_speech_prob": 4.6111839765217155e-05}, {"id": 198, "seek": 91016, "start": 912.56, "end": 920.0799999999999, "text": " Do need to be careful of little details that fly by like here they used average Pauling yes, that's a sentence which if you weren't reading", "tokens": [50484, 1144, 643, 281, 312, 5026, 295, 707, 4365, 300, 3603, 538, 411, 510, 436, 1143, 4274, 4552, 278, 2086, 11, 300, 311, 257, 8174, 597, 498, 291, 4999, 380, 3760, 50860], "temperature": 0.0, "avg_logprob": -0.3836635108132964, "compression_ratio": 1.7142857142857142, "no_speech_prob": 4.6111839765217155e-05}, {"id": 199, "seek": 91016, "start": 922.0, "end": 926.3199999999999, "text": " Carefully you could skip over it now. We know okay. We need to use average Pauling not max Pauling", "tokens": [50956, 9532, 2277, 291, 727, 10023, 670, 309, 586, 13, 492, 458, 1392, 13, 492, 643, 281, 764, 4274, 4552, 278, 406, 11469, 4552, 278, 51172], "temperature": 0.0, "avg_logprob": -0.3836635108132964, "compression_ratio": 1.7142857142857142, "no_speech_prob": 4.6111839765217155e-05}, {"id": 200, "seek": 91016, "start": 927.68, "end": 933.24, "text": " So they will often have a section which explicitly says now. I'm going to introduce the notation", "tokens": [51240, 407, 436, 486, 2049, 362, 257, 3541, 597, 20803, 1619, 586, 13, 286, 478, 516, 281, 5366, 264, 24657, 51518], "temperature": 0.0, "avg_logprob": -0.3836635108132964, "compression_ratio": 1.7142857142857142, "no_speech_prob": 4.6111839765217155e-05}, {"id": 201, "seek": 91016, "start": 933.88, "end": 939.3199999999999, "text": " This paper doesn't this paper just kind of introduces the notation as part of the discussion", "tokens": [51550, 639, 3035, 1177, 380, 341, 3035, 445, 733, 295, 31472, 264, 24657, 382, 644, 295, 264, 5017, 51822], "temperature": 0.0, "avg_logprob": -0.3836635108132964, "compression_ratio": 1.7142857142857142, "no_speech_prob": 4.6111839765217155e-05}, {"id": 202, "seek": 93932, "start": 939.32, "end": 941.32, "text": " But at some point you'll start getting", "tokens": [50364, 583, 412, 512, 935, 291, 603, 722, 1242, 50464], "temperature": 0.0, "avg_logprob": -0.2718229293823242, "compression_ratio": 1.6423076923076922, "no_speech_prob": 1.300706026086118e-05}, {"id": 203, "seek": 93932, "start": 942.6400000000001, "end": 948.72, "text": " Greek letters or you know things with subscripts or whatever notation starts appearing and so at this point", "tokens": [50530, 10281, 7825, 420, 291, 458, 721, 365, 2325, 39280, 420, 2035, 24657, 3719, 19870, 293, 370, 412, 341, 935, 50834], "temperature": 0.0, "avg_logprob": -0.2718229293823242, "compression_ratio": 1.6423076923076922, "no_speech_prob": 1.300706026086118e-05}, {"id": 204, "seek": 93932, "start": 948.72, "end": 952.38, "text": " You need to start looking very carefully and at least for me", "tokens": [50834, 509, 643, 281, 722, 1237, 588, 7500, 293, 412, 1935, 337, 385, 51017], "temperature": 0.0, "avg_logprob": -0.2718229293823242, "compression_ratio": 1.6423076923076922, "no_speech_prob": 1.300706026086118e-05}, {"id": 205, "seek": 93932, "start": 952.38, "end": 958.0400000000001, "text": " I find I have to go back and read something many times to remember. What's L? What's M? What's M?", "tokens": [51017, 286, 915, 286, 362, 281, 352, 646, 293, 1401, 746, 867, 1413, 281, 1604, 13, 708, 311, 441, 30, 708, 311, 376, 30, 708, 311, 376, 30, 51300], "temperature": 0.0, "avg_logprob": -0.2718229293823242, "compression_ratio": 1.6423076923076922, "no_speech_prob": 1.300706026086118e-05}, {"id": 206, "seek": 93932, "start": 958.0400000000001, "end": 965.1800000000001, "text": " Okay, this is the annoying thing with math notation is the single letters. They generally don't have any kind of mnemonic", "tokens": [51300, 1033, 11, 341, 307, 264, 11304, 551, 365, 5221, 24657, 307, 264, 2167, 7825, 13, 814, 5101, 500, 380, 362, 604, 733, 295, 275, 25989, 11630, 51657], "temperature": 0.0, "avg_logprob": -0.2718229293823242, "compression_ratio": 1.6423076923076922, "no_speech_prob": 1.300706026086118e-05}, {"id": 207, "seek": 96518, "start": 966.06, "end": 969.5799999999999, "text": " Often though you'll find that across papers in a particular field", "tokens": [50408, 20043, 1673, 291, 603, 915, 300, 2108, 10577, 294, 257, 1729, 2519, 50584], "temperature": 0.0, "avg_logprob": -0.3652278026902532, "compression_ratio": 1.6407766990291262, "no_speech_prob": 3.0718016205355525e-05}, {"id": 208, "seek": 96518, "start": 969.9799999999999, "end": 974.7399999999999, "text": " They'll tend to reuse the same kind of English and Greek letters for the same kinds of things", "tokens": [50604, 814, 603, 3928, 281, 26225, 264, 912, 733, 295, 3669, 293, 10281, 7825, 337, 264, 912, 3685, 295, 721, 50842], "temperature": 0.0, "avg_logprob": -0.3652278026902532, "compression_ratio": 1.6407766990291262, "no_speech_prob": 3.0718016205355525e-05}, {"id": 209, "seek": 96518, "start": 974.9799999999999, "end": 977.4799999999999, "text": " All right, so M will generally be the number of rows", "tokens": [50854, 1057, 558, 11, 370, 376, 486, 5101, 312, 264, 1230, 295, 13241, 50979], "temperature": 0.0, "avg_logprob": -0.3652278026902532, "compression_ratio": 1.6407766990291262, "no_speech_prob": 3.0718016205355525e-05}, {"id": 210, "seek": 96518, "start": 978.3, "end": 980.9399999999999, "text": " Capital M capital N will often be the number of columns", "tokens": [51020, 21502, 376, 4238, 426, 486, 2049, 312, 264, 1230, 295, 13766, 51152], "temperature": 0.0, "avg_logprob": -0.3652278026902532, "compression_ratio": 1.6407766990291262, "no_speech_prob": 3.0718016205355525e-05}, {"id": 211, "seek": 96518, "start": 983.62, "end": 987.8199999999999, "text": " K will often be the index that you're summing over so on and so forth", "tokens": [51286, 591, 486, 2049, 312, 264, 8186, 300, 291, 434, 2408, 2810, 670, 370, 322, 293, 370, 5220, 51496], "temperature": 0.0, "avg_logprob": -0.3652278026902532, "compression_ratio": 1.6407766990291262, "no_speech_prob": 3.0718016205355525e-05}, {"id": 212, "seek": 98782, "start": 988.82, "end": 990.82, "text": " So here we've got", "tokens": [50414, 407, 510, 321, 600, 658, 50514], "temperature": 0.0, "avg_logprob": -0.2541504069271251, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00039821103564463556}, {"id": 213, "seek": 98782, "start": 990.98, "end": 997.34, "text": " The first thing which is introduced is X with an arrow on top so X with an arrow on top means it's a vector, right?", "tokens": [50522, 440, 700, 551, 597, 307, 7268, 307, 1783, 365, 364, 11610, 322, 1192, 370, 1783, 365, 364, 11610, 322, 1192, 1355, 309, 311, 257, 8062, 11, 558, 30, 50840], "temperature": 0.0, "avg_logprob": -0.2541504069271251, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00039821103564463556}, {"id": 214, "seek": 98782, "start": 998.3000000000001, "end": 1000.3000000000001, "text": " It's actually an input image", "tokens": [50888, 467, 311, 767, 364, 4846, 3256, 50988], "temperature": 0.0, "avg_logprob": -0.2541504069271251, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00039821103564463556}, {"id": 215, "seek": 98782, "start": 1000.9000000000001, "end": 1003.34, "text": " But they're going to turn it into a vector by flattening it out", "tokens": [51018, 583, 436, 434, 516, 281, 1261, 309, 666, 257, 8062, 538, 24183, 278, 309, 484, 51140], "temperature": 0.0, "avg_logprob": -0.2541504069271251, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00039821103564463556}, {"id": 216, "seek": 98782, "start": 1005.4200000000001, "end": 1006.22, "text": " So okay", "tokens": [51244, 407, 1392, 51284], "temperature": 0.0, "avg_logprob": -0.2541504069271251, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00039821103564463556}, {"id": 217, "seek": 98782, "start": 1006.22, "end": 1011.0200000000001, "text": " So our image is called X and then the CNN has a whole bunch of layers and", "tokens": [51284, 407, 527, 3256, 307, 1219, 1783, 293, 550, 264, 24859, 575, 257, 1379, 3840, 295, 7914, 293, 51524], "temperature": 0.0, "avg_logprob": -0.2541504069271251, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00039821103564463556}, {"id": 218, "seek": 98782, "start": 1011.1800000000001, "end": 1016.5400000000001, "text": " Every time you see something with a subscript or a superscript like this you need to look at both of the two bits because they've", "tokens": [51532, 2048, 565, 291, 536, 746, 365, 257, 2325, 662, 420, 257, 37906, 5944, 411, 341, 291, 643, 281, 574, 412, 1293, 295, 264, 732, 9239, 570, 436, 600, 51800], "temperature": 0.0, "avg_logprob": -0.2541504069271251, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00039821103564463556}, {"id": 219, "seek": 101654, "start": 1016.54, "end": 1021.14, "text": " Both got a meaning right the thing the big thing is like the main object", "tokens": [50364, 6767, 658, 257, 3620, 558, 264, 551, 264, 955, 551, 307, 411, 264, 2135, 2657, 50594], "temperature": 0.0, "avg_logprob": -0.3113729850105617, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.00025315542006865144}, {"id": 220, "seek": 101654, "start": 1021.14, "end": 1026.6599999999999, "text": " so in this case a capital N is a filter and then the subscript or superscript is like", "tokens": [50594, 370, 294, 341, 1389, 257, 4238, 426, 307, 257, 6608, 293, 550, 264, 2325, 662, 420, 37906, 5944, 307, 411, 50870], "temperature": 0.0, "avg_logprob": -0.3113729850105617, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.00025315542006865144}, {"id": 221, "seek": 101654, "start": 1027.22, "end": 1033.3799999999999, "text": " In an array or a tensor in Python. It's like the thing in square brackets, right?", "tokens": [50898, 682, 364, 10225, 420, 257, 40863, 294, 15329, 13, 467, 311, 411, 264, 551, 294, 3732, 26179, 11, 558, 30, 51206], "temperature": 0.0, "avg_logprob": -0.3113729850105617, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.00025315542006865144}, {"id": 222, "seek": 101654, "start": 1033.3799999999999, "end": 1035.54, "text": " so each filter has", "tokens": [51206, 370, 1184, 6608, 575, 51314], "temperature": 0.0, "avg_logprob": -0.3113729850105617, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.00025315542006865144}, {"id": 223, "seek": 101654, "start": 1036.46, "end": 1042.18, "text": " A letter L which is like which number of the filter is it and so often as I read a paper", "tokens": [51360, 316, 5063, 441, 597, 307, 411, 597, 1230, 295, 264, 6608, 307, 309, 293, 370, 2049, 382, 286, 1401, 257, 3035, 51646], "temperature": 0.0, "avg_logprob": -0.3113729850105617, "compression_ratio": 1.6650717703349283, "no_speech_prob": 0.00025315542006865144}, {"id": 224, "seek": 104218, "start": 1042.3, "end": 1048.5, "text": " I'll actually try to write code as I go and like put little comments so that I like right", "tokens": [50370, 286, 603, 767, 853, 281, 2464, 3089, 382, 286, 352, 293, 411, 829, 707, 3053, 370, 300, 286, 411, 558, 50680], "temperature": 0.0, "avg_logprob": -0.3711327800044307, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.007815706543624401}, {"id": 225, "seek": 104218, "start": 1049.22, "end": 1054.68, "text": " Layer square bracket layer number close square bracket, and then I have a comment after they like", "tokens": [50716, 35166, 3732, 16904, 4583, 1230, 1998, 3732, 16904, 11, 293, 550, 286, 362, 257, 2871, 934, 436, 411, 50989], "temperature": 0.0, "avg_logprob": -0.3711327800044307, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.007815706543624401}, {"id": 226, "seek": 104218, "start": 1056.1000000000001, "end": 1062.02, "text": " Just to remind myself, so I'm creating the code and mapping it to the letters so there are NL filters", "tokens": [51060, 1449, 281, 4160, 2059, 11, 370, 286, 478, 4084, 264, 3089, 293, 18350, 309, 281, 264, 7825, 370, 456, 366, 426, 43, 15995, 51356], "temperature": 0.0, "avg_logprob": -0.3711327800044307, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.007815706543624401}, {"id": 227, "seek": 104218, "start": 1062.42, "end": 1068.0600000000002, "text": " We know from a CNN that each filter creates a feature map. So that's why there are NL feature maps", "tokens": [51376, 492, 458, 490, 257, 24859, 300, 1184, 6608, 7829, 257, 4111, 4471, 13, 407, 300, 311, 983, 456, 366, 426, 43, 4111, 11317, 51658], "temperature": 0.0, "avg_logprob": -0.3711327800044307, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.007815706543624401}, {"id": 228, "seek": 104218, "start": 1068.0600000000002, "end": 1071.9, "text": " I remember anytime you see the same letter it means the same thing", "tokens": [51658, 286, 1604, 13038, 291, 536, 264, 912, 5063, 309, 1355, 264, 912, 551, 51850], "temperature": 0.0, "avg_logprob": -0.3711327800044307, "compression_ratio": 1.7635658914728682, "no_speech_prob": 0.007815706543624401}, {"id": 229, "seek": 107218, "start": 1072.9, "end": 1075.66, "text": " within a paper not necessarily across papers", "tokens": [50400, 1951, 257, 3035, 406, 4725, 2108, 10577, 50538], "temperature": 0.0, "avg_logprob": -0.3934867908428242, "compression_ratio": 1.549738219895288, "no_speech_prob": 1.1125556738988962e-05}, {"id": 230, "seek": 107218, "start": 1076.22, "end": 1082.9, "text": " Each feature map is of size M. And as I mentioned before M tends to be rows M tends to be columns", "tokens": [50566, 6947, 4111, 4471, 307, 295, 2744, 376, 13, 400, 382, 286, 2835, 949, 376, 12258, 281, 312, 13241, 376, 12258, 281, 312, 13766, 50900], "temperature": 0.0, "avg_logprob": -0.3934867908428242, "compression_ratio": 1.549738219895288, "no_speech_prob": 1.1125556738988962e-05}, {"id": 231, "seek": 107218, "start": 1083.74, "end": 1090.38, "text": " So here it says M is the height times the width of the feature map so here we can see okay", "tokens": [50942, 407, 510, 309, 1619, 376, 307, 264, 6681, 1413, 264, 11402, 295, 264, 4111, 4471, 370, 510, 321, 393, 536, 1392, 51274], "temperature": 0.0, "avg_logprob": -0.3934867908428242, "compression_ratio": 1.549738219895288, "no_speech_prob": 1.1125556738988962e-05}, {"id": 232, "seek": 107218, "start": 1090.38, "end": 1092.38, "text": " They've they've done dot flat", "tokens": [51274, 814, 600, 436, 600, 1096, 5893, 4962, 51374], "temperature": 0.0, "avg_logprob": -0.3934867908428242, "compression_ratio": 1.549738219895288, "no_speech_prob": 1.1125556738988962e-05}, {"id": 233, "seek": 107218, "start": 1092.78, "end": 1094.78, "text": " Basically to make it all one row", "tokens": [51394, 8537, 281, 652, 309, 439, 472, 5386, 51494], "temperature": 0.0, "avg_logprob": -0.3934867908428242, "compression_ratio": 1.549738219895288, "no_speech_prob": 1.1125556738988962e-05}, {"id": 234, "seek": 109478, "start": 1095.34, "end": 1097.34, "text": " Okay", "tokens": [50392, 1033, 50492], "temperature": 0.0, "avg_logprob": -0.3226666401342018, "compression_ratio": 1.55793991416309, "no_speech_prob": 6.605188536923379e-05}, {"id": 235, "seek": 109478, "start": 1097.74, "end": 1099.54, "text": " Now this is another piece of notation", "tokens": [50512, 823, 341, 307, 1071, 2522, 295, 24657, 50602], "temperature": 0.0, "avg_logprob": -0.3226666401342018, "compression_ratio": 1.55793991416309, "no_speech_prob": 6.605188536923379e-05}, {"id": 236, "seek": 109478, "start": 1099.54, "end": 1105.26, "text": " You'll see all the time a layer L can be stored in a matrix called F and now the L has gone to the top", "tokens": [50602, 509, 603, 536, 439, 264, 565, 257, 4583, 441, 393, 312, 12187, 294, 257, 8141, 1219, 479, 293, 586, 264, 441, 575, 2780, 281, 264, 1192, 50888], "temperature": 0.0, "avg_logprob": -0.3226666401342018, "compression_ratio": 1.55793991416309, "no_speech_prob": 6.605188536923379e-05}, {"id": 237, "seek": 109478, "start": 1105.62, "end": 1108.22, "text": " Doesn't matter same basic idea. It's just an index", "tokens": [50906, 12955, 380, 1871, 912, 3875, 1558, 13, 467, 311, 445, 364, 8186, 51036], "temperature": 0.0, "avg_logprob": -0.3226666401342018, "compression_ratio": 1.55793991416309, "no_speech_prob": 6.605188536923379e-05}, {"id": 238, "seek": 109478, "start": 1109.42, "end": 1112.66, "text": " so the matrix F is going to contain our activations and", "tokens": [51096, 370, 264, 8141, 479, 307, 516, 281, 5304, 527, 2430, 763, 293, 51258], "temperature": 0.0, "avg_logprob": -0.3226666401342018, "compression_ratio": 1.55793991416309, "no_speech_prob": 6.605188536923379e-05}, {"id": 239, "seek": 109478, "start": 1113.46, "end": 1117.82, "text": " This thing here where it says are with a little superscript. This has a very special meaning", "tokens": [51298, 639, 551, 510, 689, 309, 1619, 366, 365, 257, 707, 37906, 5944, 13, 639, 575, 257, 588, 2121, 3620, 51516], "temperature": 0.0, "avg_logprob": -0.3226666401342018, "compression_ratio": 1.55793991416309, "no_speech_prob": 6.605188536923379e-05}, {"id": 240, "seek": 109478, "start": 1118.34, "end": 1120.1, "text": " It's referring to", "tokens": [51542, 467, 311, 13761, 281, 51630], "temperature": 0.0, "avg_logprob": -0.3226666401342018, "compression_ratio": 1.55793991416309, "no_speech_prob": 6.605188536923379e-05}, {"id": 241, "seek": 112010, "start": 1120.1, "end": 1127.3, "text": " Basically what is the the shape of this so when you see this shape it says these are our means that their floats", "tokens": [50364, 8537, 437, 307, 264, 264, 3909, 295, 341, 370, 562, 291, 536, 341, 3909, 309, 1619, 613, 366, 527, 1355, 300, 641, 37878, 50724], "temperature": 0.0, "avg_logprob": -0.34887284214056813, "compression_ratio": 1.972093023255814, "no_speech_prob": 0.0008426358690485358}, {"id": 242, "seek": 112010, "start": 1128.54, "end": 1133.6999999999998, "text": " And this thing here means it's a matrix you can see the X. So it means it's rows by columns", "tokens": [50786, 400, 341, 551, 510, 1355, 309, 311, 257, 8141, 291, 393, 536, 264, 1783, 13, 407, 309, 1355, 309, 311, 13241, 538, 13766, 51044], "temperature": 0.0, "avg_logprob": -0.34887284214056813, "compression_ratio": 1.972093023255814, "no_speech_prob": 0.0008426358690485358}, {"id": 243, "seek": 112010, "start": 1133.6999999999998, "end": 1136.3799999999999, "text": " So there are n rows and m columns in", "tokens": [51044, 407, 456, 366, 297, 13241, 293, 275, 13766, 294, 51178], "temperature": 0.0, "avg_logprob": -0.34887284214056813, "compression_ratio": 1.972093023255814, "no_speech_prob": 0.0008426358690485358}, {"id": 244, "seek": 112010, "start": 1137.2199999999998, "end": 1141.58, "text": " this matrix and every matrix there's one matrix for each layer and", "tokens": [51220, 341, 8141, 293, 633, 8141, 456, 311, 472, 8141, 337, 1184, 4583, 293, 51438], "temperature": 0.0, "avg_logprob": -0.34887284214056813, "compression_ratio": 1.972093023255814, "no_speech_prob": 0.0008426358690485358}, {"id": 245, "seek": 112010, "start": 1141.9399999999998, "end": 1144.9399999999998, "text": " There's different number of rows and different number of columns for each layer", "tokens": [51456, 821, 311, 819, 1230, 295, 13241, 293, 819, 1230, 295, 13766, 337, 1184, 4583, 51606], "temperature": 0.0, "avg_logprob": -0.34887284214056813, "compression_ratio": 1.972093023255814, "no_speech_prob": 0.0008426358690485358}, {"id": 246, "seek": 112010, "start": 1145.62, "end": 1147.62, "text": " so you can basically go through and", "tokens": [51640, 370, 291, 393, 1936, 352, 807, 293, 51740], "temperature": 0.0, "avg_logprob": -0.34887284214056813, "compression_ratio": 1.972093023255814, "no_speech_prob": 0.0008426358690485358}, {"id": 247, "seek": 114762, "start": 1148.02, "end": 1150.2199999999998, "text": " Map it to the code that you've already written", "tokens": [50384, 22053, 309, 281, 264, 3089, 300, 291, 600, 1217, 3720, 50494], "temperature": 0.0, "avg_logprob": -0.3411152488306949, "compression_ratio": 1.6234309623430963, "no_speech_prob": 2.282791683683172e-05}, {"id": 248, "seek": 114762, "start": 1151.9399999999998, "end": 1154.9799999999998, "text": " So I'm not going to read through the whole thing, but there's not very much here", "tokens": [50580, 407, 286, 478, 406, 516, 281, 1401, 807, 264, 1379, 551, 11, 457, 456, 311, 406, 588, 709, 510, 50732], "temperature": 0.0, "avg_logprob": -0.3411152488306949, "compression_ratio": 1.6234309623430963, "no_speech_prob": 2.282791683683172e-05}, {"id": 249, "seek": 114762, "start": 1155.54, "end": 1159.2199999999998, "text": " And it'd be good to make sure that you understand all of it", "tokens": [50760, 400, 309, 1116, 312, 665, 281, 652, 988, 300, 291, 1223, 439, 295, 309, 50944], "temperature": 0.0, "avg_logprob": -0.3411152488306949, "compression_ratio": 1.6234309623430963, "no_speech_prob": 2.282791683683172e-05}, {"id": 250, "seek": 114762, "start": 1160.02, "end": 1163.9799999999998, "text": " perhaps with the exception of the derivative because we don't care about derivatives because", "tokens": [50984, 4317, 365, 264, 11183, 295, 264, 13760, 570, 321, 500, 380, 1127, 466, 33733, 570, 51182], "temperature": 0.0, "avg_logprob": -0.3411152488306949, "compression_ratio": 1.6234309623430963, "no_speech_prob": 2.282791683683172e-05}, {"id": 251, "seek": 114762, "start": 1164.26, "end": 1167.6599999999999, "text": " They get done for us. Thanks to the I know in TensorFlow, so", "tokens": [51196, 814, 483, 1096, 337, 505, 13, 2561, 281, 264, 286, 458, 294, 37624, 11, 370, 51366], "temperature": 0.0, "avg_logprob": -0.3411152488306949, "compression_ratio": 1.6234309623430963, "no_speech_prob": 2.282791683683172e-05}, {"id": 252, "seek": 114762, "start": 1168.26, "end": 1170.26, "text": " You can always skip the bits about derivatives", "tokens": [51396, 509, 393, 1009, 10023, 264, 9239, 466, 33733, 51496], "temperature": 0.0, "avg_logprob": -0.3411152488306949, "compression_ratio": 1.6234309623430963, "no_speech_prob": 2.282791683683172e-05}, {"id": 253, "seek": 117026, "start": 1170.26, "end": 1172.26, "text": " Okay", "tokens": [50364, 1033, 50464], "temperature": 0.0, "avg_logprob": -0.35644316061949116, "compression_ratio": 1.6864864864864866, "no_speech_prob": 5.307492756401189e-05}, {"id": 254, "seek": 117026, "start": 1175.58, "end": 1178.54, "text": " So then they do the same thing basically describing the", "tokens": [50630, 407, 550, 436, 360, 264, 912, 551, 1936, 16141, 264, 50778], "temperature": 0.0, "avg_logprob": -0.35644316061949116, "compression_ratio": 1.6864864864864866, "no_speech_prob": 5.307492756401189e-05}, {"id": 255, "seek": 117026, "start": 1179.26, "end": 1181.18, "text": " Gram matrix", "tokens": [50814, 22130, 8141, 50910], "temperature": 0.0, "avg_logprob": -0.35644316061949116, "compression_ratio": 1.6864864864864866, "no_speech_prob": 5.307492756401189e-05}, {"id": 256, "seek": 117026, "start": 1181.18, "end": 1185.86, "text": " So they show here that the basic idea of the gram matrix is that they create?", "tokens": [50910, 407, 436, 855, 510, 300, 264, 3875, 1558, 295, 264, 21353, 8141, 307, 300, 436, 1884, 30, 51144], "temperature": 0.0, "avg_logprob": -0.35644316061949116, "compression_ratio": 1.6864864864864866, "no_speech_prob": 5.307492756401189e-05}, {"id": 257, "seek": 117026, "start": 1186.66, "end": 1190.26, "text": " an inner product between the vectorized feature map I", "tokens": [51184, 364, 7284, 1674, 1296, 264, 8062, 1602, 4111, 4471, 286, 51364], "temperature": 0.0, "avg_logprob": -0.35644316061949116, "compression_ratio": 1.6864864864864866, "no_speech_prob": 5.307492756401189e-05}, {"id": 258, "seek": 117026, "start": 1190.66, "end": 1197.3, "text": " And J so vectorized here means turned into a vector so the way you turn a matrix into a vector is flattened", "tokens": [51384, 400, 508, 370, 8062, 1602, 510, 1355, 3574, 666, 257, 8062, 370, 264, 636, 291, 1261, 257, 8141, 666, 257, 8062, 307, 24183, 292, 51716], "temperature": 0.0, "avg_logprob": -0.35644316061949116, "compression_ratio": 1.6864864864864866, "no_speech_prob": 5.307492756401189e-05}, {"id": 259, "seek": 119730, "start": 1197.3, "end": 1203.3799999999999, "text": " This means the flattened inner product between the flattened feature maps so those matrices we saw", "tokens": [50364, 639, 1355, 264, 24183, 292, 7284, 1674, 1296, 264, 24183, 292, 4111, 11317, 370, 729, 32284, 321, 1866, 50668], "temperature": 0.0, "avg_logprob": -0.36335528736383144, "compression_ratio": 1.5706214689265536, "no_speech_prob": 1.2029589015583042e-05}, {"id": 260, "seek": 119730, "start": 1206.86, "end": 1208.4199999999998, "text": " Yeah, so", "tokens": [50842, 865, 11, 370, 50920], "temperature": 0.0, "avg_logprob": -0.36335528736383144, "compression_ratio": 1.5706214689265536, "no_speech_prob": 1.2029589015583042e-05}, {"id": 261, "seek": 119730, "start": 1208.4199999999998, "end": 1210.4199999999998, "text": " Hopefully you'll find this helpful", "tokens": [50920, 10429, 291, 603, 915, 341, 4961, 51020], "temperature": 0.0, "avg_logprob": -0.36335528736383144, "compression_ratio": 1.5706214689265536, "no_speech_prob": 1.2029589015583042e-05}, {"id": 262, "seek": 119730, "start": 1210.46, "end": 1213.02, "text": " You'll see there'll be like small little differences", "tokens": [51022, 509, 603, 536, 456, 603, 312, 411, 1359, 707, 7300, 51150], "temperature": 0.0, "avg_logprob": -0.36335528736383144, "compression_ratio": 1.5706214689265536, "no_speech_prob": 1.2029589015583042e-05}, {"id": 263, "seek": 119730, "start": 1213.62, "end": 1214.82, "text": " so", "tokens": [51180, 370, 51240], "temperature": 0.0, "avg_logprob": -0.36335528736383144, "compression_ratio": 1.5706214689265536, "no_speech_prob": 1.2029589015583042e-05}, {"id": 264, "seek": 119730, "start": 1214.82, "end": 1216.82, "text": " rather than", "tokens": [51240, 2831, 813, 51340], "temperature": 0.0, "avg_logprob": -0.36335528736383144, "compression_ratio": 1.5706214689265536, "no_speech_prob": 1.2029589015583042e-05}, {"id": 265, "seek": 119730, "start": 1216.98, "end": 1222.3, "text": " Taking the mean they tend to use here the sum and then they kind of", "tokens": [51348, 17837, 264, 914, 436, 3928, 281, 764, 510, 264, 2408, 293, 550, 436, 733, 295, 51614], "temperature": 0.0, "avg_logprob": -0.36335528736383144, "compression_ratio": 1.5706214689265536, "no_speech_prob": 1.2029589015583042e-05}, {"id": 266, "seek": 122230, "start": 1223.18, "end": 1228.9199999999998, "text": " Divide back out the number of rows and columns to kind of create the mean this way in our code", "tokens": [50408, 9886, 482, 646, 484, 264, 1230, 295, 13241, 293, 13766, 281, 733, 295, 1884, 264, 914, 341, 636, 294, 527, 3089, 50695], "temperature": 0.0, "avg_logprob": -0.3100056026292884, "compression_ratio": 1.7088607594936709, "no_speech_prob": 3.883088720613159e-05}, {"id": 267, "seek": 122230, "start": 1228.9199999999998, "end": 1234.6599999999999, "text": " We actually put the division inside the sum so you see these little differences of how we implement things", "tokens": [50695, 492, 767, 829, 264, 10044, 1854, 264, 2408, 370, 291, 536, 613, 707, 7300, 295, 577, 321, 4445, 721, 50982], "temperature": 0.0, "avg_logprob": -0.3100056026292884, "compression_ratio": 1.7088607594936709, "no_speech_prob": 3.883088720613159e-05}, {"id": 268, "seek": 122230, "start": 1235.3799999999999, "end": 1237.8999999999999, "text": " And sometimes you may seem see actual", "tokens": [51018, 400, 2171, 291, 815, 1643, 536, 3539, 51144], "temperature": 0.0, "avg_logprob": -0.3100056026292884, "compression_ratio": 1.7088607594936709, "no_speech_prob": 3.883088720613159e-05}, {"id": 269, "seek": 122230, "start": 1239.26, "end": 1245.3, "text": " Meaningful differences, and that's often a suggestion of like oh, there's something you could try you know some differences you could try", "tokens": [51212, 19948, 906, 7300, 11, 293, 300, 311, 2049, 257, 16541, 295, 411, 1954, 11, 456, 311, 746, 291, 727, 853, 291, 458, 512, 7300, 291, 727, 853, 51514], "temperature": 0.0, "avg_logprob": -0.3100056026292884, "compression_ratio": 1.7088607594936709, "no_speech_prob": 3.883088720613159e-05}, {"id": 270, "seek": 122230, "start": 1248.46, "end": 1250.46, "text": " Okay, so that describes the", "tokens": [51672, 1033, 11, 370, 300, 15626, 264, 51772], "temperature": 0.0, "avg_logprob": -0.3100056026292884, "compression_ratio": 1.7088607594936709, "no_speech_prob": 3.883088720613159e-05}, {"id": 271, "seek": 125046, "start": 1251.3400000000001, "end": 1254.68, "text": " Notation and the method and that's it", "tokens": [50408, 1726, 399, 293, 264, 3170, 293, 300, 311, 309, 50575], "temperature": 0.0, "avg_logprob": -0.3746061827007093, "compression_ratio": 1.6069651741293531, "no_speech_prob": 2.6274592528352514e-05}, {"id": 272, "seek": 125046, "start": 1255.68, "end": 1258.94, "text": " But then very importantly is throughout this any time you come across", "tokens": [50625, 583, 550, 588, 8906, 307, 3710, 341, 604, 565, 291, 808, 2108, 50788], "temperature": 0.0, "avg_logprob": -0.3746061827007093, "compression_ratio": 1.6069651741293531, "no_speech_prob": 2.6274592528352514e-05}, {"id": 273, "seek": 125046, "start": 1259.82, "end": 1261.82, "text": " some concept", "tokens": [50832, 512, 3410, 50932], "temperature": 0.0, "avg_logprob": -0.3746061827007093, "compression_ratio": 1.6069651741293531, "no_speech_prob": 2.6274592528352514e-05}, {"id": 274, "seek": 125046, "start": 1261.8600000000001, "end": 1269.98, "text": " Which you're not familiar with it'll pretty much always have a reference a citation right so you'll see there's", "tokens": [50934, 3013, 291, 434, 406, 4963, 365, 309, 603, 1238, 709, 1009, 362, 257, 6408, 257, 45590, 558, 370, 291, 603, 536, 456, 311, 51340], "temperature": 0.0, "avg_logprob": -0.3746061827007093, "compression_ratio": 1.6069651741293531, "no_speech_prob": 2.6274592528352514e-05}, {"id": 275, "seek": 125046, "start": 1274.7, "end": 1276.7, "text": " Little numbers all over the place", "tokens": [51576, 8022, 3547, 439, 670, 264, 1081, 51676], "temperature": 0.0, "avg_logprob": -0.3746061827007093, "compression_ratio": 1.6069651741293531, "no_speech_prob": 2.6274592528352514e-05}, {"id": 276, "seek": 125046, "start": 1277.06, "end": 1279.3400000000001, "text": " There's lots of different ways of doing these references", "tokens": [51694, 821, 311, 3195, 295, 819, 2098, 295, 884, 613, 15400, 51808], "temperature": 0.0, "avg_logprob": -0.3746061827007093, "compression_ratio": 1.6069651741293531, "no_speech_prob": 2.6274592528352514e-05}, {"id": 277, "seek": 127934, "start": 1280.02, "end": 1282.02, "text": " But anytime you come across something", "tokens": [50398, 583, 13038, 291, 808, 2108, 746, 50498], "temperature": 0.0, "avg_logprob": -0.2787634216912902, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.368555088760331e-05}, {"id": 278, "seek": 127934, "start": 1282.5, "end": 1288.02, "text": " Which has a citation like it's a new piece of notation or a new concept you don't know what it is", "tokens": [50522, 3013, 575, 257, 45590, 411, 309, 311, 257, 777, 2522, 295, 24657, 420, 257, 777, 3410, 291, 500, 380, 458, 437, 309, 307, 50798], "temperature": 0.0, "avg_logprob": -0.2787634216912902, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.368555088760331e-05}, {"id": 279, "seek": 127934, "start": 1288.58, "end": 1290.74, "text": " Generally the first time I see it in a paper", "tokens": [50826, 21082, 264, 700, 565, 286, 536, 309, 294, 257, 3035, 50934], "temperature": 0.0, "avg_logprob": -0.2787634216912902, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.368555088760331e-05}, {"id": 280, "seek": 127934, "start": 1290.74, "end": 1294.3799999999999, "text": " I ignore it right, but if I keep reading and it turns out to be", "tokens": [50934, 286, 11200, 309, 558, 11, 457, 498, 286, 1066, 3760, 293, 309, 4523, 484, 281, 312, 51116], "temperature": 0.0, "avg_logprob": -0.2787634216912902, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.368555088760331e-05}, {"id": 281, "seek": 127934, "start": 1294.9399999999998, "end": 1301.02, "text": " Something that actually is important, and I can't understand the basic idea at all I generally then put this paper aside", "tokens": [51144, 6595, 300, 767, 307, 1021, 11, 293, 286, 393, 380, 1223, 264, 3875, 1558, 412, 439, 286, 5101, 550, 829, 341, 3035, 7359, 51448], "temperature": 0.0, "avg_logprob": -0.2787634216912902, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.368555088760331e-05}, {"id": 282, "seek": 127934, "start": 1301.02, "end": 1303.6599999999999, "text": " I put it in my to read file and", "tokens": [51448, 286, 829, 309, 294, 452, 281, 1401, 3991, 293, 51580], "temperature": 0.0, "avg_logprob": -0.2787634216912902, "compression_ratio": 1.6751054852320675, "no_speech_prob": 7.368555088760331e-05}, {"id": 283, "seek": 130366, "start": 1304.3400000000001, "end": 1305.42, "text": " Make the new paper", "tokens": [50398, 4387, 264, 777, 3035, 50452], "temperature": 0.0, "avg_logprob": -0.3221048425745081, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.19860880356282e-05}, {"id": 284, "seek": 130366, "start": 1305.42, "end": 1311.9, "text": " I'm reading the thing that it's citing because like very often a paper is entirely meaningless until you've read", "tokens": [50452, 286, 478, 3760, 264, 551, 300, 309, 311, 48749, 570, 411, 588, 2049, 257, 3035, 307, 7696, 33232, 1826, 291, 600, 1401, 50776], "temperature": 0.0, "avg_logprob": -0.3221048425745081, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.19860880356282e-05}, {"id": 285, "seek": 130366, "start": 1312.46, "end": 1314.5400000000002, "text": " One or two of the key papers. It's based on", "tokens": [50804, 1485, 420, 732, 295, 264, 2141, 10577, 13, 467, 311, 2361, 322, 50908], "temperature": 0.0, "avg_logprob": -0.3221048425745081, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.19860880356282e-05}, {"id": 286, "seek": 130366, "start": 1315.94, "end": 1322.22, "text": " Sometimes this can be like reading the dictionary if you don't yet know English it can be like layer upon layer of citations and at", "tokens": [50978, 4803, 341, 393, 312, 411, 3760, 264, 25890, 498, 291, 500, 380, 1939, 458, 3669, 309, 393, 312, 411, 4583, 3564, 4583, 295, 4814, 763, 293, 412, 51292], "temperature": 0.0, "avg_logprob": -0.3221048425745081, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.19860880356282e-05}, {"id": 287, "seek": 130366, "start": 1322.22, "end": 1323.22, "text": " some point", "tokens": [51292, 512, 935, 51342], "temperature": 0.0, "avg_logprob": -0.3221048425745081, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.19860880356282e-05}, {"id": 288, "seek": 130366, "start": 1323.22, "end": 1325.22, "text": " you have to stop I", "tokens": [51342, 291, 362, 281, 1590, 286, 51442], "temperature": 0.0, "avg_logprob": -0.3221048425745081, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.19860880356282e-05}, {"id": 289, "seek": 130366, "start": 1326.38, "end": 1332.74, "text": " Generally thought you should I think you should find that the basic set of papers that things refer to is", "tokens": [51500, 21082, 1194, 291, 820, 286, 519, 291, 820, 915, 300, 264, 3875, 992, 295, 10577, 300, 721, 2864, 281, 307, 51818], "temperature": 0.0, "avg_logprob": -0.3221048425745081, "compression_ratio": 1.7237354085603114, "no_speech_prob": 4.19860880356282e-05}, {"id": 290, "seek": 133274, "start": 1333.38, "end": 1338.26, "text": " Pretty much all stuff you guys know at this point, so I don't think you're going to get stuck in an infinite loop", "tokens": [50396, 10693, 709, 439, 1507, 291, 1074, 458, 412, 341, 935, 11, 370, 286, 500, 380, 519, 291, 434, 516, 281, 483, 5541, 294, 364, 13785, 6367, 50640], "temperature": 0.0, "avg_logprob": -0.2816448662224717, "compression_ratio": 1.7294520547945205, "no_speech_prob": 5.475881334859878e-05}, {"id": 291, "seek": 133274, "start": 1338.78, "end": 1340.78, "text": " But if you ever do", "tokens": [50666, 583, 498, 291, 1562, 360, 50766], "temperature": 0.0, "avg_logprob": -0.2816448662224717, "compression_ratio": 1.7294520547945205, "no_speech_prob": 5.475881334859878e-05}, {"id": 292, "seek": 133274, "start": 1341.02, "end": 1345.38, "text": " You know let let us know in the forum, and we'll try and help you get unstuck", "tokens": [50778, 509, 458, 718, 718, 505, 458, 294, 264, 17542, 11, 293, 321, 603, 853, 293, 854, 291, 483, 18799, 1134, 50996], "temperature": 0.0, "avg_logprob": -0.2816448662224717, "compression_ratio": 1.7294520547945205, "no_speech_prob": 5.475881334859878e-05}, {"id": 293, "seek": 133274, "start": 1346.58, "end": 1349.3, "text": " Or if there's any notation you don't understand let us know", "tokens": [51056, 1610, 498, 456, 311, 604, 24657, 291, 500, 380, 1223, 718, 505, 458, 51192], "temperature": 0.0, "avg_logprob": -0.2816448662224717, "compression_ratio": 1.7294520547945205, "no_speech_prob": 5.475881334859878e-05}, {"id": 294, "seek": 133274, "start": 1349.6200000000001, "end": 1353.34, "text": " Another of the horrible things about math is it's very hard to search for you know", "tokens": [51208, 3996, 295, 264, 9263, 721, 466, 5221, 307, 309, 311, 588, 1152, 281, 3164, 337, 291, 458, 51394], "temperature": 0.0, "avg_logprob": -0.2816448662224717, "compression_ratio": 1.7294520547945205, "no_speech_prob": 5.475881334859878e-05}, {"id": 295, "seek": 133274, "start": 1353.34, "end": 1359.78, "text": " It's not like you can take that function name and search for Python in the function name instead of some weird squiggly shape", "tokens": [51394, 467, 311, 406, 411, 291, 393, 747, 300, 2445, 1315, 293, 3164, 337, 15329, 294, 264, 2445, 1315, 2602, 295, 512, 3657, 2339, 46737, 3909, 51716], "temperature": 0.0, "avg_logprob": -0.2816448662224717, "compression_ratio": 1.7294520547945205, "no_speech_prob": 5.475881334859878e-05}, {"id": 296, "seek": 133274, "start": 1360.22, "end": 1362.22, "text": " So again feel free to ask", "tokens": [51738, 407, 797, 841, 1737, 281, 1029, 51838], "temperature": 0.0, "avg_logprob": -0.2816448662224717, "compression_ratio": 1.7294520547945205, "no_speech_prob": 5.475881334859878e-05}, {"id": 297, "seek": 136274, "start": 1363.14, "end": 1365.14, "text": " If you're not sure about that", "tokens": [50384, 759, 291, 434, 406, 988, 466, 300, 50484], "temperature": 0.0, "avg_logprob": -0.3099526882171631, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.854260391264688e-06}, {"id": 298, "seek": 136274, "start": 1365.46, "end": 1368.06, "text": " There is a great Wikipedia page which lists", "tokens": [50500, 821, 307, 257, 869, 28999, 3028, 597, 14511, 50630], "temperature": 0.0, "avg_logprob": -0.3099526882171631, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.854260391264688e-06}, {"id": 299, "seek": 136274, "start": 1368.58, "end": 1370.58, "text": " But I think it's just called", "tokens": [50656, 583, 286, 519, 309, 311, 445, 1219, 50756], "temperature": 0.0, "avg_logprob": -0.3099526882171631, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.854260391264688e-06}, {"id": 300, "seek": 136274, "start": 1370.66, "end": 1375.14, "text": " Notate out math notation or something which lists pretty much every piece of notation", "tokens": [50760, 1726, 473, 484, 5221, 24657, 420, 746, 597, 14511, 1238, 709, 633, 2522, 295, 24657, 50984], "temperature": 0.0, "avg_logprob": -0.3099526882171631, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.854260391264688e-06}, {"id": 301, "seek": 136274, "start": 1375.82, "end": 1379.54, "text": " There are various places you can look up notation as well", "tokens": [51018, 821, 366, 3683, 3190, 291, 393, 574, 493, 24657, 382, 731, 51204], "temperature": 0.0, "avg_logprob": -0.3099526882171631, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.854260391264688e-06}, {"id": 302, "seek": 136274, "start": 1380.82, "end": 1382.82, "text": " Okay, so that's the paper", "tokens": [51268, 1033, 11, 370, 300, 311, 264, 3035, 51368], "temperature": 0.0, "avg_logprob": -0.3099526882171631, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.854260391264688e-06}, {"id": 303, "seek": 136274, "start": 1385.98, "end": 1388.86, "text": " So let's let's move to the next step", "tokens": [51526, 407, 718, 311, 718, 311, 1286, 281, 264, 958, 1823, 51670], "temperature": 0.0, "avg_logprob": -0.3099526882171631, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.854260391264688e-06}, {"id": 304, "seek": 139274, "start": 1393.22, "end": 1395.22, "text": " I", "tokens": [50388, 286, 50488], "temperature": 0.0, "avg_logprob": -0.29889915539668155, "compression_ratio": 1.6872427983539096, "no_speech_prob": 1.2411425814207178e-05}, {"id": 305, "seek": 139274, "start": 1395.6200000000001, "end": 1397.6200000000001, "text": " Think what I might do is kind of try and", "tokens": [50508, 6557, 437, 286, 1062, 360, 307, 733, 295, 853, 293, 50608], "temperature": 0.0, "avg_logprob": -0.29889915539668155, "compression_ratio": 1.6872427983539096, "no_speech_prob": 1.2411425814207178e-05}, {"id": 306, "seek": 139274, "start": 1398.3, "end": 1403.42, "text": " Draw the basic idea of what we did before so that I can draw the idea of what we're going to do differently this time", "tokens": [50642, 20386, 264, 3875, 1558, 295, 437, 321, 630, 949, 370, 300, 286, 393, 2642, 264, 1558, 295, 437, 321, 434, 516, 281, 360, 7614, 341, 565, 50898], "temperature": 0.0, "avg_logprob": -0.29889915539668155, "compression_ratio": 1.6872427983539096, "no_speech_prob": 1.2411425814207178e-05}, {"id": 307, "seek": 139274, "start": 1403.7, "end": 1407.46, "text": " So previously and now this thing is actually calibrated. You'll be pleased to hear", "tokens": [50912, 407, 8046, 293, 586, 341, 551, 307, 767, 21583, 5468, 13, 509, 603, 312, 10587, 281, 1568, 51100], "temperature": 0.0, "avg_logprob": -0.29889915539668155, "compression_ratio": 1.6872427983539096, "no_speech_prob": 1.2411425814207178e-05}, {"id": 308, "seek": 139274, "start": 1408.1, "end": 1410.54, "text": " we had an a random image and", "tokens": [51132, 321, 632, 364, 257, 4974, 3256, 293, 51254], "temperature": 0.0, "avg_logprob": -0.29889915539668155, "compression_ratio": 1.6872427983539096, "no_speech_prob": 1.2411425814207178e-05}, {"id": 309, "seek": 139274, "start": 1411.9, "end": 1413.9, "text": " we had a", "tokens": [51322, 321, 632, 257, 51422], "temperature": 0.0, "avg_logprob": -0.29889915539668155, "compression_ratio": 1.6872427983539096, "no_speech_prob": 1.2411425814207178e-05}, {"id": 310, "seek": 139274, "start": 1416.26, "end": 1422.5, "text": " Lost function so this doesn't matter what the loss function was right we know that it happened to be a combination of style loss", "tokens": [51540, 23422, 2445, 370, 341, 1177, 380, 1871, 437, 264, 4470, 2445, 390, 558, 321, 458, 300, 309, 2011, 281, 312, 257, 6562, 295, 3758, 4470, 51852], "temperature": 0.0, "avg_logprob": -0.29889915539668155, "compression_ratio": 1.6872427983539096, "no_speech_prob": 1.2411425814207178e-05}, {"id": 311, "seek": 142274, "start": 1423.02, "end": 1428.1, "text": " plus content loss right and what we did was we", "tokens": [50378, 1804, 2701, 4470, 558, 293, 437, 321, 630, 390, 321, 50632], "temperature": 0.0, "avg_logprob": -0.3899995151319002, "compression_ratio": 1.7134146341463414, "no_speech_prob": 3.288732159489882e-06}, {"id": 312, "seek": 142274, "start": 1429.18, "end": 1431.18, "text": " took our image and", "tokens": [50686, 1890, 527, 3256, 293, 50786], "temperature": 0.0, "avg_logprob": -0.3899995151319002, "compression_ratio": 1.7134146341463414, "no_speech_prob": 3.288732159489882e-06}, {"id": 313, "seek": 142274, "start": 1431.18, "end": 1433.18, "text": " We're our random image, and we put it through", "tokens": [50786, 492, 434, 527, 4974, 3256, 11, 293, 321, 829, 309, 807, 50886], "temperature": 0.0, "avg_logprob": -0.3899995151319002, "compression_ratio": 1.7134146341463414, "no_speech_prob": 3.288732159489882e-06}, {"id": 314, "seek": 142274, "start": 1433.7, "end": 1440.82, "text": " This loss function, and we got out of it two things one was the loss and the other was the gradients", "tokens": [50912, 639, 4470, 2445, 11, 293, 321, 658, 484, 295, 309, 732, 721, 472, 390, 264, 4470, 293, 264, 661, 390, 264, 2771, 2448, 51268], "temperature": 0.0, "avg_logprob": -0.3899995151319002, "compression_ratio": 1.7134146341463414, "no_speech_prob": 3.288732159489882e-06}, {"id": 315, "seek": 142274, "start": 1441.34, "end": 1442.5, "text": " and", "tokens": [51294, 293, 51352], "temperature": 0.0, "avg_logprob": -0.3899995151319002, "compression_ratio": 1.7134146341463414, "no_speech_prob": 3.288732159489882e-06}, {"id": 316, "seek": 142274, "start": 1442.5, "end": 1446.6200000000001, "text": " then we use the gradients with respect to the original pixels to", "tokens": [51352, 550, 321, 764, 264, 2771, 2448, 365, 3104, 281, 264, 3380, 18668, 281, 51558], "temperature": 0.0, "avg_logprob": -0.3899995151319002, "compression_ratio": 1.7134146341463414, "no_speech_prob": 3.288732159489882e-06}, {"id": 317, "seek": 144662, "start": 1447.62, "end": 1449.62, "text": " Change the original pixels", "tokens": [50414, 15060, 264, 3380, 18668, 50514], "temperature": 0.0, "avg_logprob": -0.3070357143878937, "compression_ratio": 1.5833333333333333, "no_speech_prob": 7.36856454750523e-05}, {"id": 318, "seek": 144662, "start": 1449.8999999999999, "end": 1456.82, "text": " Right and so we basically repeated that loop again and again and the pixels gradually changed to make the loss", "tokens": [50528, 1779, 293, 370, 321, 1936, 10477, 300, 6367, 797, 293, 797, 293, 264, 18668, 13145, 3105, 281, 652, 264, 4470, 50874], "temperature": 0.0, "avg_logprob": -0.3070357143878937, "compression_ratio": 1.5833333333333333, "no_speech_prob": 7.36856454750523e-05}, {"id": 319, "seek": 144662, "start": 1458.3, "end": 1462.7399999999998, "text": " Go down, so that's the basic approach that we just used", "tokens": [50948, 1037, 760, 11, 370, 300, 311, 264, 3875, 3109, 300, 321, 445, 1143, 51170], "temperature": 0.0, "avg_logprob": -0.3070357143878937, "compression_ratio": 1.5833333333333333, "no_speech_prob": 7.36856454750523e-05}, {"id": 320, "seek": 144662, "start": 1464.9799999999998, "end": 1469.1, "text": " It's a perfectly fine approach for what it is and in fact for if you are", "tokens": [51282, 467, 311, 257, 6239, 2489, 3109, 337, 437, 309, 307, 293, 294, 1186, 337, 498, 291, 366, 51488], "temperature": 0.0, "avg_logprob": -0.3070357143878937, "compression_ratio": 1.5833333333333333, "no_speech_prob": 7.36856454750523e-05}, {"id": 321, "seek": 146910, "start": 1470.1, "end": 1474.6999999999998, "text": " Wanting to do lots of different photos with lots of different styles", "tokens": [50414, 11773, 278, 281, 360, 3195, 295, 819, 5787, 365, 3195, 295, 819, 13273, 50644], "temperature": 0.0, "avg_logprob": -0.34854611896333243, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.00015597950550727546}, {"id": 322, "seek": 146910, "start": 1475.02, "end": 1480.98, "text": " Like if you created a web app where you said, please upload any style image and any content image", "tokens": [50660, 1743, 498, 291, 2942, 257, 3670, 724, 689, 291, 848, 11, 1767, 6580, 604, 3758, 3256, 293, 604, 2701, 3256, 50958], "temperature": 0.0, "avg_logprob": -0.34854611896333243, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.00015597950550727546}, {"id": 323, "seek": 146910, "start": 1481.6999999999998, "end": 1483.6999999999998, "text": " Here's your artistic style version", "tokens": [50994, 1692, 311, 428, 17090, 3758, 3037, 51094], "temperature": 0.0, "avg_logprob": -0.34854611896333243, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.00015597950550727546}, {"id": 324, "seek": 146910, "start": 1484.6599999999999, "end": 1486.6599999999999, "text": " This is probably still the best", "tokens": [51142, 639, 307, 1391, 920, 264, 1151, 51242], "temperature": 0.0, "avg_logprob": -0.34854611896333243, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.00015597950550727546}, {"id": 325, "seek": 146910, "start": 1487.4199999999998, "end": 1489.4199999999998, "text": " Particularly with some of those tweaks I talked about", "tokens": [51280, 32281, 365, 512, 295, 729, 46664, 286, 2825, 466, 51380], "temperature": 0.0, "avg_logprob": -0.34854611896333243, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.00015597950550727546}, {"id": 326, "seek": 146910, "start": 1489.8999999999999, "end": 1492.34, "text": " But what if you wanted to create a web app?", "tokens": [51404, 583, 437, 498, 291, 1415, 281, 1884, 257, 3670, 724, 30, 51526], "temperature": 0.0, "avg_logprob": -0.34854611896333243, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.00015597950550727546}, {"id": 327, "seek": 146910, "start": 1492.9399999999998, "end": 1494.74, "text": " that was a", "tokens": [51556, 300, 390, 257, 51646], "temperature": 0.0, "avg_logprob": -0.34854611896333243, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.00015597950550727546}, {"id": 328, "seek": 149474, "start": 1494.74, "end": 1501.74, "text": " Van Gogh irises generator upload any image, and I will give you that image in the style of van Gogh's irises", "tokens": [50364, 8979, 39690, 71, 3418, 3598, 19265, 6580, 604, 3256, 11, 293, 286, 486, 976, 291, 300, 3256, 294, 264, 3758, 295, 3161, 39690, 71, 311, 3418, 3598, 50714], "temperature": 0.0, "avg_logprob": -0.2910120800288037, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010013463906943798}, {"id": 329, "seek": 149474, "start": 1502.9, "end": 1504.9, "text": " You can do better than this approach", "tokens": [50772, 509, 393, 360, 1101, 813, 341, 3109, 50872], "temperature": 0.0, "avg_logprob": -0.2910120800288037, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010013463906943798}, {"id": 330, "seek": 149474, "start": 1505.3, "end": 1510.66, "text": " And the reason you can do better is that we can do something where you don't have to do a whole optimization", "tokens": [50892, 400, 264, 1778, 291, 393, 360, 1101, 307, 300, 321, 393, 360, 746, 689, 291, 500, 380, 362, 281, 360, 257, 1379, 19618, 51160], "temperature": 0.0, "avg_logprob": -0.2910120800288037, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010013463906943798}, {"id": 331, "seek": 149474, "start": 1511.46, "end": 1514.58, "text": " Run in order to create that output", "tokens": [51200, 8950, 294, 1668, 281, 1884, 300, 5598, 51356], "temperature": 0.0, "avg_logprob": -0.2910120800288037, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010013463906943798}, {"id": 332, "seek": 149474, "start": 1515.26, "end": 1518.1, "text": " Instead we can train a CNN", "tokens": [51390, 7156, 321, 393, 3847, 257, 24859, 51532], "temperature": 0.0, "avg_logprob": -0.2910120800288037, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010013463906943798}, {"id": 333, "seek": 149474, "start": 1518.94, "end": 1523.14, "text": " to learn to output photos in the style of van Gogh's irises", "tokens": [51574, 281, 1466, 281, 5598, 5787, 294, 264, 3758, 295, 3161, 39690, 71, 311, 3418, 3598, 51784], "temperature": 0.0, "avg_logprob": -0.2910120800288037, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.010013463906943798}, {"id": 334, "seek": 152314, "start": 1523.98, "end": 1526.7800000000002, "text": " The basic idea is very similar", "tokens": [50406, 440, 3875, 1558, 307, 588, 2531, 50546], "temperature": 0.0, "avg_logprob": -0.3154159345124897, "compression_ratio": 1.9021739130434783, "no_speech_prob": 4.425481165526435e-06}, {"id": 335, "seek": 152314, "start": 1528.1000000000001, "end": 1530.38, "text": " What we're going to do this time is we're going to have", "tokens": [50612, 708, 321, 434, 516, 281, 360, 341, 565, 307, 321, 434, 516, 281, 362, 50726], "temperature": 0.0, "avg_logprob": -0.3154159345124897, "compression_ratio": 1.9021739130434783, "no_speech_prob": 4.425481165526435e-06}, {"id": 336, "seek": 152314, "start": 1531.3000000000002, "end": 1533.3000000000002, "text": " lots of images", "tokens": [50772, 3195, 295, 5267, 50872], "temperature": 0.0, "avg_logprob": -0.3154159345124897, "compression_ratio": 1.9021739130434783, "no_speech_prob": 4.425481165526435e-06}, {"id": 337, "seek": 152314, "start": 1534.5, "end": 1538.42, "text": " All right, and we're going to take each image and we're going to feed it into", "tokens": [50932, 1057, 558, 11, 293, 321, 434, 516, 281, 747, 1184, 3256, 293, 321, 434, 516, 281, 3154, 309, 666, 51128], "temperature": 0.0, "avg_logprob": -0.3154159345124897, "compression_ratio": 1.9021739130434783, "no_speech_prob": 4.425481165526435e-06}, {"id": 338, "seek": 152314, "start": 1539.8200000000002, "end": 1542.5800000000002, "text": " The exact same loss function that we used before", "tokens": [51198, 440, 1900, 912, 4470, 2445, 300, 321, 1143, 949, 51336], "temperature": 0.0, "avg_logprob": -0.3154159345124897, "compression_ratio": 1.9021739130434783, "no_speech_prob": 4.425481165526435e-06}, {"id": 339, "seek": 152314, "start": 1543.5800000000002, "end": 1550.98, "text": " All right with a style loss. That's the content loss right, but we're going to use for the style loss. We're going to use", "tokens": [51386, 1057, 558, 365, 257, 3758, 4470, 13, 663, 311, 264, 2701, 4470, 558, 11, 457, 321, 434, 516, 281, 764, 337, 264, 3758, 4470, 13, 492, 434, 516, 281, 764, 51756], "temperature": 0.0, "avg_logprob": -0.3154159345124897, "compression_ratio": 1.9021739130434783, "no_speech_prob": 4.425481165526435e-06}, {"id": 340, "seek": 155098, "start": 1551.9, "end": 1553.9, "text": " Van Gogh's irises", "tokens": [50410, 8979, 39690, 71, 311, 3418, 3598, 50510], "temperature": 0.0, "avg_logprob": -0.30249981446699664, "compression_ratio": 1.8369565217391304, "no_speech_prob": 3.4268148738192394e-05}, {"id": 341, "seek": 155098, "start": 1555.3, "end": 1562.74, "text": " And for the content loss we're going to use the image that we're currently looking at we've got lots of images we're going to go through", "tokens": [50580, 400, 337, 264, 2701, 4470, 321, 434, 516, 281, 764, 264, 3256, 300, 321, 434, 4362, 1237, 412, 321, 600, 658, 3195, 295, 5267, 321, 434, 516, 281, 352, 807, 50952], "temperature": 0.0, "avg_logprob": -0.30249981446699664, "compression_ratio": 1.8369565217391304, "no_speech_prob": 3.4268148738192394e-05}, {"id": 342, "seek": 155098, "start": 1564.66, "end": 1570.34, "text": " And what we do is we're going to rather than changing the pixels of the original", "tokens": [51048, 400, 437, 321, 360, 307, 321, 434, 516, 281, 2831, 813, 4473, 264, 18668, 295, 264, 3380, 51332], "temperature": 0.0, "avg_logprob": -0.30249981446699664, "compression_ratio": 1.8369565217391304, "no_speech_prob": 3.4268148738192394e-05}, {"id": 343, "seek": 155098, "start": 1570.74, "end": 1576.9, "text": " Photo instead what we're going to do is we're going to train a CNN or a whole bunch of layers of a CNN", "tokens": [51352, 39175, 2602, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 3847, 257, 24859, 420, 257, 1379, 3840, 295, 7914, 295, 257, 24859, 51660], "temperature": 0.0, "avg_logprob": -0.30249981446699664, "compression_ratio": 1.8369565217391304, "no_speech_prob": 3.4268148738192394e-05}, {"id": 344, "seek": 157690, "start": 1577.5400000000002, "end": 1580.42, "text": " We're going to train a CNN to take this", "tokens": [50396, 492, 434, 516, 281, 3847, 257, 24859, 281, 747, 341, 50540], "temperature": 0.0, "avg_logprob": -0.2847325499628631, "compression_ratio": 1.576158940397351, "no_speech_prob": 2.5071538402698934e-05}, {"id": 345, "seek": 157690, "start": 1583.1000000000001, "end": 1586.6200000000001, "text": " Thing the best way to show you this let's move this out of the way", "tokens": [50674, 30902, 264, 1151, 636, 281, 855, 291, 341, 718, 311, 1286, 341, 484, 295, 264, 636, 50850], "temperature": 0.0, "avg_logprob": -0.2847325499628631, "compression_ratio": 1.576158940397351, "no_speech_prob": 2.5071538402698934e-05}, {"id": 346, "seek": 157690, "start": 1595.02, "end": 1596.74, "text": " Yeah", "tokens": [51270, 865, 51356], "temperature": 0.0, "avg_logprob": -0.2847325499628631, "compression_ratio": 1.576158940397351, "no_speech_prob": 2.5071538402698934e-05}, {"id": 347, "seek": 157690, "start": 1596.74, "end": 1598.74, "text": " That's better. So", "tokens": [51356, 663, 311, 1101, 13, 407, 51456], "temperature": 0.0, "avg_logprob": -0.2847325499628631, "compression_ratio": 1.576158940397351, "no_speech_prob": 2.5071538402698934e-05}, {"id": 348, "seek": 157690, "start": 1598.94, "end": 1605.5800000000002, "text": " Let's put a CNN in the middle. These are the layers of the CNN right and we're going to try and get that CNN", "tokens": [51466, 961, 311, 829, 257, 24859, 294, 264, 2808, 13, 1981, 366, 264, 7914, 295, 264, 24859, 558, 293, 321, 434, 516, 281, 853, 293, 483, 300, 24859, 51798], "temperature": 0.0, "avg_logprob": -0.2847325499628631, "compression_ratio": 1.576158940397351, "no_speech_prob": 2.5071538402698934e-05}, {"id": 349, "seek": 160558, "start": 1606.1, "end": 1612.78, "text": " To spit out a new image, so there's an input image and", "tokens": [50390, 1407, 22127, 484, 257, 777, 3256, 11, 370, 456, 311, 364, 4846, 3256, 293, 50724], "temperature": 0.0, "avg_logprob": -0.2765648985562259, "compression_ratio": 1.7393939393939395, "no_speech_prob": 2.7535577828530222e-05}, {"id": 350, "seek": 160558, "start": 1614.9399999999998, "end": 1618.8999999999999, "text": " There's an output image and this new CNN we've created is going to spit out", "tokens": [50832, 821, 311, 364, 5598, 3256, 293, 341, 777, 24859, 321, 600, 2942, 307, 516, 281, 22127, 484, 51030], "temperature": 0.0, "avg_logprob": -0.2765648985562259, "compression_ratio": 1.7393939393939395, "no_speech_prob": 2.7535577828530222e-05}, {"id": 351, "seek": 160558, "start": 1620.02, "end": 1624.06, "text": " An output image that when you put it through this loss function", "tokens": [51086, 1107, 5598, 3256, 300, 562, 291, 829, 309, 807, 341, 4470, 2445, 51288], "temperature": 0.0, "avg_logprob": -0.2765648985562259, "compression_ratio": 1.7393939393939395, "no_speech_prob": 2.7535577828530222e-05}, {"id": 352, "seek": 160558, "start": 1626.6599999999999, "end": 1633.06, "text": " Hopefully it's going to give a small number and if it gives a small number it means that the", "tokens": [51418, 10429, 309, 311, 516, 281, 976, 257, 1359, 1230, 293, 498, 309, 2709, 257, 1359, 1230, 309, 1355, 300, 264, 51738], "temperature": 0.0, "avg_logprob": -0.2765648985562259, "compression_ratio": 1.7393939393939395, "no_speech_prob": 2.7535577828530222e-05}, {"id": 353, "seek": 163306, "start": 1634.02, "end": 1640.46, "text": " Content of this photo still looks like the original photo is content and the style of this new image", "tokens": [50412, 30078, 295, 341, 5052, 920, 1542, 411, 264, 3380, 5052, 307, 2701, 293, 264, 3758, 295, 341, 777, 3256, 50734], "temperature": 0.0, "avg_logprob": -0.3595870483753293, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.9223005438107066e-05}, {"id": 354, "seek": 163306, "start": 1640.82, "end": 1643.06, "text": " Looks like the style of van Gogh's irises", "tokens": [50752, 10027, 411, 264, 3758, 295, 3161, 39690, 71, 311, 3418, 3598, 50864], "temperature": 0.0, "avg_logprob": -0.3595870483753293, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.9223005438107066e-05}, {"id": 355, "seek": 163306, "start": 1644.1, "end": 1647.8999999999999, "text": " So if you think about it when you have a CNN", "tokens": [50916, 407, 498, 291, 519, 466, 309, 562, 291, 362, 257, 24859, 51106], "temperature": 0.0, "avg_logprob": -0.3595870483753293, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.9223005438107066e-05}, {"id": 356, "seek": 163306, "start": 1649.86, "end": 1655.3999999999999, "text": " You can really pick any loss function you like right we've tended to use some pretty simple loss functions so far like", "tokens": [51204, 509, 393, 534, 1888, 604, 4470, 2445, 291, 411, 558, 321, 600, 34732, 281, 764, 512, 1238, 2199, 4470, 6828, 370, 1400, 411, 51481], "temperature": 0.0, "avg_logprob": -0.3595870483753293, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.9223005438107066e-05}, {"id": 357, "seek": 163306, "start": 1655.86, "end": 1657.86, "text": " means great error or", "tokens": [51504, 1355, 869, 6713, 420, 51604], "temperature": 0.0, "avg_logprob": -0.3595870483753293, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.9223005438107066e-05}, {"id": 358, "seek": 163306, "start": 1658.5, "end": 1659.7, "text": " cross-entropy", "tokens": [51636, 3278, 12, 317, 27514, 51696], "temperature": 0.0, "avg_logprob": -0.3595870483753293, "compression_ratio": 1.631578947368421, "no_speech_prob": 1.9223005438107066e-05}, {"id": 359, "seek": 165970, "start": 1659.7, "end": 1663.7, "text": " In this case we're going to use a very different loss function which is going to be", "tokens": [50364, 682, 341, 1389, 321, 434, 516, 281, 764, 257, 588, 819, 4470, 2445, 597, 307, 516, 281, 312, 50564], "temperature": 0.0, "avg_logprob": -0.35935457636801044, "compression_ratio": 1.719626168224299, "no_speech_prob": 0.001206587883643806}, {"id": 360, "seek": 165970, "start": 1664.7, "end": 1668.9, "text": " Style plus content loss using the same approach that we used just before", "tokens": [50614, 27004, 1804, 2701, 4470, 1228, 264, 912, 3109, 300, 321, 1143, 445, 949, 50824], "temperature": 0.0, "avg_logprob": -0.35935457636801044, "compression_ratio": 1.719626168224299, "no_speech_prob": 0.001206587883643806}, {"id": 361, "seek": 165970, "start": 1669.66, "end": 1672.6200000000001, "text": " right and because that was generated by a", "tokens": [50862, 558, 293, 570, 300, 390, 10833, 538, 257, 51010], "temperature": 0.0, "avg_logprob": -0.35935457636801044, "compression_ratio": 1.719626168224299, "no_speech_prob": 0.001206587883643806}, {"id": 362, "seek": 165970, "start": 1673.18, "end": 1677.6200000000001, "text": " Neural net we know it's differentiable and you can optimize any", "tokens": [51038, 1734, 1807, 2533, 321, 458, 309, 311, 819, 9364, 293, 291, 393, 19719, 604, 51260], "temperature": 0.0, "avg_logprob": -0.35935457636801044, "compression_ratio": 1.719626168224299, "no_speech_prob": 0.001206587883643806}, {"id": 363, "seek": 165970, "start": 1678.06, "end": 1681.94, "text": " Loss function as long as the loss function is differentiable", "tokens": [51282, 441, 772, 2445, 382, 938, 382, 264, 4470, 2445, 307, 819, 9364, 51476], "temperature": 0.0, "avg_logprob": -0.35935457636801044, "compression_ratio": 1.719626168224299, "no_speech_prob": 0.001206587883643806}, {"id": 364, "seek": 165970, "start": 1682.66, "end": 1685.78, "text": " so if we now basically take the gradients of", "tokens": [51512, 370, 498, 321, 586, 1936, 747, 264, 2771, 2448, 295, 51668], "temperature": 0.0, "avg_logprob": -0.35935457636801044, "compression_ratio": 1.719626168224299, "no_speech_prob": 0.001206587883643806}, {"id": 365, "seek": 168578, "start": 1686.58, "end": 1694.62, "text": " This output not with respect to the input image, but with respect to the CNN weights, and we can take those gradients", "tokens": [50404, 639, 5598, 406, 365, 3104, 281, 264, 4846, 3256, 11, 457, 365, 3104, 281, 264, 24859, 17443, 11, 293, 321, 393, 747, 729, 2771, 2448, 50806], "temperature": 0.0, "avg_logprob": -0.33845190568403766, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.00015597915626130998}, {"id": 366, "seek": 168578, "start": 1697.34, "end": 1700.08, "text": " And use them to update the weights of the CNN", "tokens": [50942, 400, 764, 552, 281, 5623, 264, 17443, 295, 264, 24859, 51079], "temperature": 0.0, "avg_logprob": -0.33845190568403766, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.00015597915626130998}, {"id": 367, "seek": 168578, "start": 1700.5, "end": 1704.66, "text": " So that the next iteration through the CNN will be slightly better at turning", "tokens": [51100, 407, 300, 264, 958, 24784, 807, 264, 24859, 486, 312, 4748, 1101, 412, 6246, 51308], "temperature": 0.0, "avg_logprob": -0.33845190568403766, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.00015597915626130998}, {"id": 368, "seek": 168578, "start": 1705.02, "end": 1709.42, "text": " That image into a picture that has a good style match with van Gogh's irises", "tokens": [51326, 663, 3256, 666, 257, 3036, 300, 575, 257, 665, 3758, 2995, 365, 3161, 39690, 71, 311, 3418, 3598, 51546], "temperature": 0.0, "avg_logprob": -0.33845190568403766, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.00015597915626130998}, {"id": 369, "seek": 170942, "start": 1709.42, "end": 1716.38, "text": " Does that make sense so at the end of this we run this through lots of images", "tokens": [50364, 4402, 300, 652, 2020, 370, 412, 264, 917, 295, 341, 321, 1190, 341, 807, 3195, 295, 5267, 50712], "temperature": 0.0, "avg_logprob": -0.2999856799256568, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.00021654300508089364}, {"id": 370, "seek": 170942, "start": 1716.38, "end": 1723.5800000000002, "text": " Just we're just training a regular CNN and the only thing we've done differently is to replace the loss function with the style loss plus", "tokens": [50712, 1449, 321, 434, 445, 3097, 257, 3890, 24859, 293, 264, 787, 551, 321, 600, 1096, 7614, 307, 281, 7406, 264, 4470, 2445, 365, 264, 3758, 4470, 1804, 51072], "temperature": 0.0, "avg_logprob": -0.2999856799256568, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.00021654300508089364}, {"id": 371, "seek": 170942, "start": 1723.5800000000002, "end": 1724.98, "text": " content loss", "tokens": [51072, 2701, 4470, 51142], "temperature": 0.0, "avg_logprob": -0.2999856799256568, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.00021654300508089364}, {"id": 372, "seek": 170942, "start": 1724.98, "end": 1727.54, "text": " That we just used and so at the end of it", "tokens": [51142, 663, 321, 445, 1143, 293, 370, 412, 264, 917, 295, 309, 51270], "temperature": 0.0, "avg_logprob": -0.2999856799256568, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.00021654300508089364}, {"id": 373, "seek": 170942, "start": 1727.54, "end": 1731.3400000000001, "text": " we're going to have a CNN that has learned to take any photo and", "tokens": [51270, 321, 434, 516, 281, 362, 257, 24859, 300, 575, 3264, 281, 747, 604, 5052, 293, 51460], "temperature": 0.0, "avg_logprob": -0.2999856799256568, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.00021654300508089364}, {"id": 374, "seek": 170942, "start": 1731.98, "end": 1735.8200000000002, "text": " We'll spit out that photo in the style of van Gogh's irises", "tokens": [51492, 492, 603, 22127, 484, 300, 5052, 294, 264, 3758, 295, 3161, 39690, 71, 311, 3418, 3598, 51684], "temperature": 0.0, "avg_logprob": -0.2999856799256568, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.00021654300508089364}, {"id": 375, "seek": 173582, "start": 1736.3, "end": 1742.1, "text": " And so this is a win because it means now in your web app, which is your van Gogh irises generator", "tokens": [50388, 400, 370, 341, 307, 257, 1942, 570, 309, 1355, 586, 294, 428, 3670, 724, 11, 597, 307, 428, 3161, 39690, 71, 3418, 3598, 19265, 50678], "temperature": 0.0, "avg_logprob": -0.3628277452024695, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.00013551789743360132}, {"id": 376, "seek": 173582, "start": 1742.6599999999999, "end": 1749.3799999999999, "text": " You now don't have to run an optimization path on the new photo. You just do a single forward pass to a CNN, which is", "tokens": [50706, 509, 586, 500, 380, 362, 281, 1190, 364, 19618, 3100, 322, 264, 777, 5052, 13, 509, 445, 360, 257, 2167, 2128, 1320, 281, 257, 24859, 11, 597, 307, 51042], "temperature": 0.0, "avg_logprob": -0.3628277452024695, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.00013551789743360132}, {"id": 377, "seek": 173582, "start": 1749.98, "end": 1751.82, "text": " instant", "tokens": [51072, 9836, 51164], "temperature": 0.0, "avg_logprob": -0.3628277452024695, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.00013551789743360132}, {"id": 378, "seek": 173582, "start": 1751.82, "end": 1753.8999999999999, "text": " Yes, green box over there", "tokens": [51164, 1079, 11, 3092, 2424, 670, 456, 51268], "temperature": 0.0, "avg_logprob": -0.3628277452024695, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.00013551789743360132}, {"id": 379, "seek": 173582, "start": 1759.1799999999998, "end": 1761.1799999999998, "text": " So this", "tokens": [51532, 407, 341, 51632], "temperature": 0.0, "avg_logprob": -0.3628277452024695, "compression_ratio": 1.4333333333333333, "no_speech_prob": 0.00013551789743360132}, {"id": 380, "seek": 176118, "start": 1761.18, "end": 1763.18, "text": " Filters you use right", "tokens": [50364, 7905, 1559, 291, 764, 558, 50464], "temperature": 0.0, "avg_logprob": -0.41896238230695626, "compression_ratio": 1.8407079646017699, "no_speech_prob": 0.0010322247399017215}, {"id": 381, "seek": 176118, "start": 1763.54, "end": 1767.5800000000002, "text": " Significantly if you like let's say you have Photoshop and you want to change multiple styles", "tokens": [50482, 13515, 1089, 3627, 498, 291, 411, 718, 311, 584, 291, 362, 20821, 293, 291, 528, 281, 1319, 3866, 13273, 50684], "temperature": 0.0, "avg_logprob": -0.41896238230695626, "compression_ratio": 1.8407079646017699, "no_speech_prob": 0.0010322247399017215}, {"id": 382, "seek": 176118, "start": 1767.5800000000002, "end": 1772.8600000000001, "text": " Yeah, this is going to this is going to each neural network. It's going to learn to do just", "tokens": [50684, 865, 11, 341, 307, 516, 281, 341, 307, 516, 281, 1184, 18161, 3209, 13, 467, 311, 516, 281, 1466, 281, 360, 445, 50948], "temperature": 0.0, "avg_logprob": -0.41896238230695626, "compression_ratio": 1.8407079646017699, "no_speech_prob": 0.0010322247399017215}, {"id": 383, "seek": 176118, "start": 1773.5, "end": 1775.5, "text": " one type of style", "tokens": [50980, 472, 2010, 295, 3758, 51080], "temperature": 0.0, "avg_logprob": -0.41896238230695626, "compression_ratio": 1.8407079646017699, "no_speech_prob": 0.0010322247399017215}, {"id": 384, "seek": 176118, "start": 1776.74, "end": 1783.5, "text": " Their way of like combining multiple styles or is it just going to be a combination of all you can combine multiple styles", "tokens": [51142, 6710, 636, 295, 411, 21928, 3866, 13273, 420, 307, 309, 445, 516, 281, 312, 257, 6562, 295, 439, 291, 393, 10432, 3866, 13273, 51480], "temperature": 0.0, "avg_logprob": -0.41896238230695626, "compression_ratio": 1.8407079646017699, "no_speech_prob": 0.0010322247399017215}, {"id": 385, "seek": 176118, "start": 1784.02, "end": 1788.5, "text": " By just like having multiple bits of style loss for multiple images", "tokens": [51506, 3146, 445, 411, 1419, 3866, 9239, 295, 3758, 4470, 337, 3866, 5267, 51730], "temperature": 0.0, "avg_logprob": -0.41896238230695626, "compression_ratio": 1.8407079646017699, "no_speech_prob": 0.0010322247399017215}, {"id": 386, "seek": 178850, "start": 1788.74, "end": 1790.74, "text": " But you're still going to have the problems that that", "tokens": [50376, 583, 291, 434, 920, 516, 281, 362, 264, 2740, 300, 300, 50476], "temperature": 0.0, "avg_logprob": -0.338701411655971, "compression_ratio": 1.5657142857142856, "no_speech_prob": 0.00012148056703153998}, {"id": 387, "seek": 178850, "start": 1791.38, "end": 1795.62, "text": " Network has only learned to create one kind of image", "tokens": [50508, 12640, 575, 787, 3264, 281, 1884, 472, 733, 295, 3256, 50720], "temperature": 0.0, "avg_logprob": -0.338701411655971, "compression_ratio": 1.5657142857142856, "no_speech_prob": 0.00012148056703153998}, {"id": 388, "seek": 178850, "start": 1796.02, "end": 1796.62, "text": " All right", "tokens": [50740, 1057, 558, 50770], "temperature": 0.0, "avg_logprob": -0.338701411655971, "compression_ratio": 1.5657142857142856, "no_speech_prob": 0.00012148056703153998}, {"id": 389, "seek": 178850, "start": 1796.62, "end": 1804.06, "text": " It hasn't learned now it may be possible to create to train it so that takes both a style image and a content image", "tokens": [50770, 467, 6132, 380, 3264, 586, 309, 815, 312, 1944, 281, 1884, 281, 3847, 309, 370, 300, 2516, 1293, 257, 3758, 3256, 293, 257, 2701, 3256, 51142], "temperature": 0.0, "avg_logprob": -0.338701411655971, "compression_ratio": 1.5657142857142856, "no_speech_prob": 0.00012148056703153998}, {"id": 390, "seek": 178850, "start": 1804.38, "end": 1806.38, "text": " But I don't think I've seen that done yet", "tokens": [51158, 583, 286, 500, 380, 519, 286, 600, 1612, 300, 1096, 1939, 51258], "temperature": 0.0, "avg_logprob": -0.338701411655971, "compression_ratio": 1.5657142857142856, "no_speech_prob": 0.00012148056703153998}, {"id": 391, "seek": 181850, "start": 1818.5, "end": 1823.66, "text": " Having said that there is something simpler and in my opinion more useful we can do", "tokens": [50364, 10222, 848, 300, 456, 307, 746, 18587, 293, 294, 452, 4800, 544, 4420, 321, 393, 360, 50622], "temperature": 0.0, "avg_logprob": -0.2887622197469076, "compression_ratio": 1.6829268292682926, "no_speech_prob": 4.611256008502096e-05}, {"id": 392, "seek": 181850, "start": 1824.78, "end": 1829.3, "text": " Which is rather than doing style loss plus content loss", "tokens": [50678, 3013, 307, 2831, 813, 884, 3758, 4470, 1804, 2701, 4470, 50904], "temperature": 0.0, "avg_logprob": -0.2887622197469076, "compression_ratio": 1.6829268292682926, "no_speech_prob": 4.611256008502096e-05}, {"id": 393, "seek": 181850, "start": 1829.98, "end": 1834.82, "text": " Let's think of another interesting problem to solve which is called super resolution", "tokens": [50938, 961, 311, 519, 295, 1071, 1880, 1154, 281, 5039, 597, 307, 1219, 1687, 8669, 51180], "temperature": 0.0, "avg_logprob": -0.2887622197469076, "compression_ratio": 1.6829268292682926, "no_speech_prob": 4.611256008502096e-05}, {"id": 394, "seek": 181850, "start": 1836.94, "end": 1839.0, "text": " Super resolution is something which", "tokens": [51286, 4548, 8669, 307, 746, 597, 51389], "temperature": 0.0, "avg_logprob": -0.2887622197469076, "compression_ratio": 1.6829268292682926, "no_speech_prob": 4.611256008502096e-05}, {"id": 395, "seek": 181850, "start": 1840.3, "end": 1844.18, "text": " Honestly when Rachel and I started playing around with it a while ago. Nobody was that interested in it", "tokens": [51454, 12348, 562, 14246, 293, 286, 1409, 2433, 926, 365, 309, 257, 1339, 2057, 13, 9297, 390, 300, 3102, 294, 309, 51648], "temperature": 0.0, "avg_logprob": -0.2887622197469076, "compression_ratio": 1.6829268292682926, "no_speech_prob": 4.611256008502096e-05}, {"id": 396, "seek": 181850, "start": 1844.74, "end": 1848.1, "text": " But in the last year or so it's become really hot", "tokens": [51676, 583, 294, 264, 1036, 1064, 420, 370, 309, 311, 1813, 534, 2368, 51844], "temperature": 0.0, "avg_logprob": -0.2887622197469076, "compression_ratio": 1.6829268292682926, "no_speech_prob": 4.611256008502096e-05}, {"id": 397, "seek": 184850, "start": 1848.5, "end": 1850.5, "text": " Yes, Rachel", "tokens": [50364, 1079, 11, 14246, 50464], "temperature": 0.0, "avg_logprob": -0.31241926713423296, "compression_ratio": 1.6544117647058822, "no_speech_prob": 2.7535370463738218e-05}, {"id": 398, "seek": 184850, "start": 1852.58, "end": 1855.74, "text": " Yeah, yeah, so we were kind of playing around with it quite a lot", "tokens": [50568, 865, 11, 1338, 11, 370, 321, 645, 733, 295, 2433, 926, 365, 309, 1596, 257, 688, 50726], "temperature": 0.0, "avg_logprob": -0.31241926713423296, "compression_ratio": 1.6544117647058822, "no_speech_prob": 2.7535370463738218e-05}, {"id": 399, "seek": 184850, "start": 1855.74, "end": 1860.26, "text": " We thought it's really interesting, but suddenly it's got hot and the basic idea of super resolution", "tokens": [50726, 492, 1194, 309, 311, 534, 1880, 11, 457, 5800, 309, 311, 658, 2368, 293, 264, 3875, 1558, 295, 1687, 8669, 50952], "temperature": 0.0, "avg_logprob": -0.31241926713423296, "compression_ratio": 1.6544117647058822, "no_speech_prob": 2.7535370463738218e-05}, {"id": 400, "seek": 184850, "start": 1860.26, "end": 1862.86, "text": " Is that you start off with a low res photo?", "tokens": [50952, 1119, 300, 291, 722, 766, 365, 257, 2295, 725, 5052, 30, 51082], "temperature": 0.0, "avg_logprob": -0.31241926713423296, "compression_ratio": 1.6544117647058822, "no_speech_prob": 2.7535370463738218e-05}, {"id": 401, "seek": 184850, "start": 1862.86, "end": 1866.34, "text": " And so the reason I started getting interested in this was I wanted to help my mom", "tokens": [51082, 400, 370, 264, 1778, 286, 1409, 1242, 3102, 294, 341, 390, 286, 1415, 281, 854, 452, 1225, 51256], "temperature": 0.0, "avg_logprob": -0.31241926713423296, "compression_ratio": 1.6544117647058822, "no_speech_prob": 2.7535370463738218e-05}, {"id": 402, "seek": 184850, "start": 1866.62, "end": 1869.26, "text": " Take her family photos that were often", "tokens": [51270, 3664, 720, 1605, 5787, 300, 645, 2049, 51402], "temperature": 0.0, "avg_logprob": -0.31241926713423296, "compression_ratio": 1.6544117647058822, "no_speech_prob": 2.7535370463738218e-05}, {"id": 403, "seek": 184850, "start": 1869.66, "end": 1875.54, "text": " Pretty low quality and blow them up into something that was big and high quality that she could print out", "tokens": [51422, 10693, 2295, 3125, 293, 6327, 552, 493, 666, 746, 300, 390, 955, 293, 1090, 3125, 300, 750, 727, 4482, 484, 51716], "temperature": 0.0, "avg_logprob": -0.31241926713423296, "compression_ratio": 1.6544117647058822, "no_speech_prob": 2.7535370463738218e-05}, {"id": 404, "seek": 187554, "start": 1876.1, "end": 1881.62, "text": " So that's what you do is you're trying to take something which starts with a small low res photo and", "tokens": [50392, 407, 300, 311, 437, 291, 360, 307, 291, 434, 1382, 281, 747, 746, 597, 3719, 365, 257, 1359, 2295, 725, 5052, 293, 50668], "temperature": 0.0, "avg_logprob": -0.4043418700436512, "compression_ratio": 1.7180851063829787, "no_speech_prob": 1.078323202818865e-05}, {"id": 405, "seek": 187554, "start": 1882.82, "end": 1885.58, "text": " Turns it into a big high res photo", "tokens": [50728, 29524, 309, 666, 257, 955, 1090, 725, 5052, 50866], "temperature": 0.0, "avg_logprob": -0.4043418700436512, "compression_ratio": 1.7180851063829787, "no_speech_prob": 1.078323202818865e-05}, {"id": 406, "seek": 187554, "start": 1887.6599999999999, "end": 1890.3799999999999, "text": " L are low res HR", "tokens": [50970, 441, 366, 2295, 725, 19460, 51106], "temperature": 0.0, "avg_logprob": -0.4043418700436512, "compression_ratio": 1.7180851063829787, "no_speech_prob": 1.078323202818865e-05}, {"id": 407, "seek": 187554, "start": 1891.1399999999999, "end": 1892.58, "text": " high res", "tokens": [51144, 1090, 725, 51216], "temperature": 0.0, "avg_logprob": -0.4043418700436512, "compression_ratio": 1.7180851063829787, "no_speech_prob": 1.078323202818865e-05}, {"id": 408, "seek": 187554, "start": 1892.58, "end": 1897.54, "text": " Now perhaps you can see that we can use a very similar technique for this", "tokens": [51216, 823, 4317, 291, 393, 536, 300, 321, 393, 764, 257, 588, 2531, 6532, 337, 341, 51464], "temperature": 0.0, "avg_logprob": -0.4043418700436512, "compression_ratio": 1.7180851063829787, "no_speech_prob": 1.078323202818865e-05}, {"id": 409, "seek": 187554, "start": 1898.02, "end": 1903.5, "text": " What we could do is between the low res photo and the high res photo we could introduce", "tokens": [51488, 708, 321, 727, 360, 307, 1296, 264, 2295, 725, 5052, 293, 264, 1090, 725, 5052, 321, 727, 5366, 51762], "temperature": 0.0, "avg_logprob": -0.4043418700436512, "compression_ratio": 1.7180851063829787, "no_speech_prob": 1.078323202818865e-05}, {"id": 410, "seek": 190554, "start": 1906.54, "end": 1907.86, "text": " a", "tokens": [50414, 257, 50480], "temperature": 0.0, "avg_logprob": -0.4140189488728841, "compression_ratio": 1.582191780821918, "no_speech_prob": 3.1875374588707928e-06}, {"id": 411, "seek": 190554, "start": 1907.86, "end": 1909.86, "text": " CNN", "tokens": [50480, 24859, 50580], "temperature": 0.0, "avg_logprob": -0.4140189488728841, "compression_ratio": 1.582191780821918, "no_speech_prob": 3.1875374588707928e-06}, {"id": 412, "seek": 190554, "start": 1915.02, "end": 1919.58, "text": " Right and what that's a and that CNN could look a lot like the CNN from our last idea", "tokens": [50838, 1779, 293, 437, 300, 311, 257, 293, 300, 24859, 727, 574, 257, 688, 411, 264, 24859, 490, 527, 1036, 1558, 51066], "temperature": 0.0, "avg_logprob": -0.4140189488728841, "compression_ratio": 1.582191780821918, "no_speech_prob": 3.1875374588707928e-06}, {"id": 413, "seek": 190554, "start": 1920.18, "end": 1923.06, "text": " But it's taking in as input a low res", "tokens": [51096, 583, 309, 311, 1940, 294, 382, 4846, 257, 2295, 725, 51240], "temperature": 0.0, "avg_logprob": -0.4140189488728841, "compression_ratio": 1.582191780821918, "no_speech_prob": 3.1875374588707928e-06}, {"id": 414, "seek": 190554, "start": 1924.34, "end": 1929.26, "text": " image and then it's sticking it into a loss function and", "tokens": [51304, 3256, 293, 550, 309, 311, 13465, 309, 666, 257, 4470, 2445, 293, 51550], "temperature": 0.0, "avg_logprob": -0.4140189488728841, "compression_ratio": 1.582191780821918, "no_speech_prob": 3.1875374588707928e-06}, {"id": 415, "seek": 190554, "start": 1930.86, "end": 1933.1, "text": " The loss function is only going to calculate", "tokens": [51630, 440, 4470, 2445, 307, 787, 516, 281, 8873, 51742], "temperature": 0.0, "avg_logprob": -0.4140189488728841, "compression_ratio": 1.582191780821918, "no_speech_prob": 3.1875374588707928e-06}, {"id": 416, "seek": 193310, "start": 1934.1, "end": 1939.54, "text": " Content loss and the content loss it will calculate is between the", "tokens": [50414, 30078, 4470, 293, 264, 2701, 4470, 309, 486, 8873, 307, 1296, 264, 50686], "temperature": 0.0, "avg_logprob": -0.3110336727566189, "compression_ratio": 1.6919191919191918, "no_speech_prob": 3.480795567156747e-05}, {"id": 417, "seek": 193310, "start": 1940.4599999999998, "end": 1943.4199999999998, "text": " Input that it's got from the low res after going through the CNN", "tokens": [50732, 682, 2582, 300, 309, 311, 658, 490, 264, 2295, 725, 934, 516, 807, 264, 24859, 50880], "temperature": 0.0, "avg_logprob": -0.3110336727566189, "compression_ratio": 1.6919191919191918, "no_speech_prob": 3.480795567156747e-05}, {"id": 418, "seek": 193310, "start": 1944.4199999999998, "end": 1946.4199999999998, "text": " compared to", "tokens": [50930, 5347, 281, 51030], "temperature": 0.0, "avg_logprob": -0.3110336727566189, "compression_ratio": 1.6919191919191918, "no_speech_prob": 3.480795567156747e-05}, {"id": 419, "seek": 193310, "start": 1946.54, "end": 1951.34, "text": " The activations from the high res so in other words has this CNN", "tokens": [51036, 440, 2430, 763, 490, 264, 1090, 725, 370, 294, 661, 2283, 575, 341, 24859, 51276], "temperature": 0.0, "avg_logprob": -0.3110336727566189, "compression_ratio": 1.6919191919191918, "no_speech_prob": 3.480795567156747e-05}, {"id": 420, "seek": 193310, "start": 1952.3, "end": 1960.26, "text": " Successfully created a bigger photo that has the same activations as the high res photo does and so if we pick the right layer", "tokens": [51324, 23669, 2277, 2942, 257, 3801, 5052, 300, 575, 264, 912, 2430, 763, 382, 264, 1090, 725, 5052, 775, 293, 370, 498, 321, 1888, 264, 558, 4583, 51722], "temperature": 0.0, "avg_logprob": -0.3110336727566189, "compression_ratio": 1.6919191919191918, "no_speech_prob": 3.480795567156747e-05}, {"id": 421, "seek": 196026, "start": 1960.66, "end": 1967.5, "text": " For the high res photo and that ought to mean that we've constructed a new image. What's that Rachel?", "tokens": [50384, 1171, 264, 1090, 725, 5052, 293, 300, 13416, 281, 914, 300, 321, 600, 17083, 257, 777, 3256, 13, 708, 311, 300, 14246, 30, 50726], "temperature": 0.0, "avg_logprob": -0.2936485244567136, "compression_ratio": 1.5294117647058822, "no_speech_prob": 9.610009146854281e-05}, {"id": 422, "seek": 196026, "start": 1969.02, "end": 1971.02, "text": " There's a question", "tokens": [50802, 821, 311, 257, 1168, 50902], "temperature": 0.0, "avg_logprob": -0.2936485244567136, "compression_ratio": 1.5294117647058822, "no_speech_prob": 9.610009146854281e-05}, {"id": 423, "seek": 196026, "start": 1974.14, "end": 1978.02, "text": " Yes, absolutely and this is one of the things I wanted to talk about today is", "tokens": [51058, 1079, 11, 3122, 293, 341, 307, 472, 295, 264, 721, 286, 1415, 281, 751, 466, 965, 307, 51252], "temperature": 0.0, "avg_logprob": -0.2936485244567136, "compression_ratio": 1.5294117647058822, "no_speech_prob": 9.610009146854281e-05}, {"id": 424, "seek": 196026, "start": 1978.82, "end": 1984.82, "text": " In fact, I think it's at the start of the next paper. We're going to look at is they even kind of talk about this", "tokens": [51292, 682, 1186, 11, 286, 519, 309, 311, 412, 264, 722, 295, 264, 958, 3035, 13, 492, 434, 516, 281, 574, 412, 307, 436, 754, 733, 295, 751, 466, 341, 51592], "temperature": 0.0, "avg_logprob": -0.2936485244567136, "compression_ratio": 1.5294117647058822, "no_speech_prob": 9.610009146854281e-05}, {"id": 425, "seek": 198482, "start": 1985.82, "end": 1988.1399999999999, "text": " And so this is the paper we're going to look at today", "tokens": [50414, 400, 370, 341, 307, 264, 3035, 321, 434, 516, 281, 574, 412, 965, 50530], "temperature": 0.0, "avg_logprob": -0.3405781586964925, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.0001941120863193646}, {"id": 426, "seek": 198482, "start": 1988.74, "end": 1993.06, "text": " Perceptual losses for real-time style transfer and super resolutions. This is from 2016", "tokens": [50560, 3026, 1336, 901, 15352, 337, 957, 12, 3766, 3758, 5003, 293, 1687, 32179, 13, 639, 307, 490, 6549, 50776], "temperature": 0.0, "avg_logprob": -0.3405781586964925, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.0001941120863193646}, {"id": 427, "seek": 198482, "start": 1993.06, "end": 1999.3, "text": " So it took like about a year or so to go through the thing. We just saw to this next stage. Is that right?", "tokens": [50776, 407, 309, 1890, 411, 466, 257, 1064, 420, 370, 281, 352, 807, 264, 551, 13, 492, 445, 1866, 281, 341, 958, 3233, 13, 1119, 300, 558, 30, 51088], "temperature": 0.0, "avg_logprob": -0.3405781586964925, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.0001941120863193646}, {"id": 428, "seek": 198482, "start": 2002.46, "end": 2004.46, "text": " Maybe half a year, okay", "tokens": [51246, 2704, 1922, 257, 1064, 11, 1392, 51346], "temperature": 0.0, "avg_logprob": -0.3405781586964925, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.0001941120863193646}, {"id": 429, "seek": 198482, "start": 2005.9399999999998, "end": 2011.3999999999999, "text": " So what they point out in the abstract here is that people had done super resolution with CNNs before", "tokens": [51420, 407, 437, 436, 935, 484, 294, 264, 12649, 510, 307, 300, 561, 632, 1096, 1687, 8669, 365, 24859, 82, 949, 51693], "temperature": 0.0, "avg_logprob": -0.3405781586964925, "compression_ratio": 1.526530612244898, "no_speech_prob": 0.0001941120863193646}, {"id": 430, "seek": 201140, "start": 2011.76, "end": 2018.16, "text": " But previously the loss function they used was simply the mean squared error between the pixel outputs of the", "tokens": [50382, 583, 8046, 264, 4470, 2445, 436, 1143, 390, 2935, 264, 914, 8889, 6713, 1296, 264, 19261, 23930, 295, 264, 50702], "temperature": 0.0, "avg_logprob": -0.35377413431803384, "compression_ratio": 1.7807486631016043, "no_speech_prob": 5.920910552958958e-05}, {"id": 431, "seek": 201140, "start": 2018.96, "end": 2022.4, "text": " upscaling network and the actual high res image", "tokens": [50742, 493, 4417, 4270, 3209, 293, 264, 3539, 1090, 725, 3256, 50914], "temperature": 0.0, "avg_logprob": -0.35377413431803384, "compression_ratio": 1.7807486631016043, "no_speech_prob": 5.920910552958958e-05}, {"id": 432, "seek": 201140, "start": 2023.24, "end": 2028.3400000000001, "text": " And the problem is that it turns out that that tends to create blurry images", "tokens": [50956, 400, 264, 1154, 307, 300, 309, 4523, 484, 300, 300, 12258, 281, 1884, 37644, 5267, 51211], "temperature": 0.0, "avg_logprob": -0.35377413431803384, "compression_ratio": 1.7807486631016043, "no_speech_prob": 5.920910552958958e-05}, {"id": 433, "seek": 201140, "start": 2028.6000000000001, "end": 2031.96, "text": " and it tends to create blurry images because the", "tokens": [51224, 293, 309, 12258, 281, 1884, 37644, 5267, 570, 264, 51392], "temperature": 0.0, "avg_logprob": -0.35377413431803384, "compression_ratio": 1.7807486631016043, "no_speech_prob": 5.920910552958958e-05}, {"id": 434, "seek": 201140, "start": 2033.24, "end": 2036.2800000000002, "text": " The CNN has no reason not to create blurry images", "tokens": [51456, 440, 24859, 575, 572, 1778, 406, 281, 1884, 37644, 5267, 51608], "temperature": 0.0, "avg_logprob": -0.35377413431803384, "compression_ratio": 1.7807486631016043, "no_speech_prob": 5.920910552958958e-05}, {"id": 435, "seek": 203628, "start": 2036.8, "end": 2041.96, "text": " And blurry images are actually tend to look pretty good in the loss function because as long as you get the general", "tokens": [50390, 400, 37644, 5267, 366, 767, 3928, 281, 574, 1238, 665, 294, 264, 4470, 2445, 570, 382, 938, 382, 291, 483, 264, 2674, 50648], "temperature": 0.0, "avg_logprob": -0.31156133387210594, "compression_ratio": 1.7676767676767677, "no_speech_prob": 0.00020342619973234832}, {"id": 436, "seek": 203628, "start": 2042.24, "end": 2047.8, "text": " You know, oh, this is probably somebody's face. I'll put like a face color here, but then it's going to be fine", "tokens": [50662, 509, 458, 11, 1954, 11, 341, 307, 1391, 2618, 311, 1851, 13, 286, 603, 829, 411, 257, 1851, 2017, 510, 11, 457, 550, 309, 311, 516, 281, 312, 2489, 50940], "temperature": 0.0, "avg_logprob": -0.31156133387210594, "compression_ratio": 1.7676767676767677, "no_speech_prob": 0.00020342619973234832}, {"id": 437, "seek": 203628, "start": 2048.12, "end": 2052.2799999999997, "text": " Where else if you take the second or third conv block of VGG?", "tokens": [50956, 2305, 1646, 498, 291, 747, 264, 1150, 420, 2636, 3754, 3461, 295, 691, 27561, 30, 51164], "temperature": 0.0, "avg_logprob": -0.31156133387210594, "compression_ratio": 1.7676767676767677, "no_speech_prob": 0.00020342619973234832}, {"id": 438, "seek": 203628, "start": 2052.92, "end": 2056.96, "text": " Then it needs to know that this is an eyeball or it's not going to look good, right?", "tokens": [51196, 1396, 309, 2203, 281, 458, 300, 341, 307, 364, 38868, 420, 309, 311, 406, 516, 281, 574, 665, 11, 558, 30, 51398], "temperature": 0.0, "avg_logprob": -0.31156133387210594, "compression_ratio": 1.7676767676767677, "no_speech_prob": 0.00020342619973234832}, {"id": 439, "seek": 203628, "start": 2056.96, "end": 2059.3, "text": " It needs to know that this is a nose. It's not going to look good", "tokens": [51398, 467, 2203, 281, 458, 300, 341, 307, 257, 6690, 13, 467, 311, 406, 516, 281, 574, 665, 51515], "temperature": 0.0, "avg_logprob": -0.31156133387210594, "compression_ratio": 1.7676767676767677, "no_speech_prob": 0.00020342619973234832}, {"id": 440, "seek": 203628, "start": 2059.36, "end": 2064.24, "text": " So if you do it not with pixel loss, but with the content loss we just learned about", "tokens": [51518, 407, 498, 291, 360, 309, 406, 365, 19261, 4470, 11, 457, 365, 264, 2701, 4470, 321, 445, 3264, 466, 51762], "temperature": 0.0, "avg_logprob": -0.31156133387210594, "compression_ratio": 1.7676767676767677, "no_speech_prob": 0.00020342619973234832}, {"id": 441, "seek": 206424, "start": 2064.9599999999996, "end": 2066.9599999999996, "text": " You're probably going to get better results", "tokens": [50400, 509, 434, 1391, 516, 281, 483, 1101, 3542, 50500], "temperature": 0.0, "avg_logprob": -0.3611754405347607, "compression_ratio": 1.6394230769230769, "no_speech_prob": 2.3552493075840175e-05}, {"id": 442, "seek": 206424, "start": 2067.16, "end": 2069.12, "text": " so this", "tokens": [50510, 370, 341, 50608], "temperature": 0.0, "avg_logprob": -0.3611754405347607, "compression_ratio": 1.6394230769230769, "no_speech_prob": 2.3552493075840175e-05}, {"id": 443, "seek": 206424, "start": 2069.12, "end": 2072.8399999999997, "text": " Like many papers in deep learning this paper introduces its own", "tokens": [50608, 1743, 867, 10577, 294, 2452, 2539, 341, 3035, 31472, 1080, 1065, 50794], "temperature": 0.0, "avg_logprob": -0.3611754405347607, "compression_ratio": 1.6394230769230769, "no_speech_prob": 2.3552493075840175e-05}, {"id": 444, "seek": 206424, "start": 2074.56, "end": 2079.64, "text": " Language and in the language of this paper perceptual loss is what they call", "tokens": [50880, 24445, 293, 294, 264, 2856, 295, 341, 3035, 43276, 901, 4470, 307, 437, 436, 818, 51134], "temperature": 0.0, "avg_logprob": -0.3611754405347607, "compression_ratio": 1.6394230769230769, "no_speech_prob": 2.3552493075840175e-05}, {"id": 445, "seek": 206424, "start": 2080.64, "end": 2084.2999999999997, "text": " the mean squared errors between the activations of", "tokens": [51184, 264, 914, 8889, 13603, 1296, 264, 2430, 763, 295, 51367], "temperature": 0.0, "avg_logprob": -0.3611754405347607, "compression_ratio": 1.6394230769230769, "no_speech_prob": 2.3552493075840175e-05}, {"id": 446, "seek": 206424, "start": 2085.24, "end": 2090.8799999999997, "text": " A network with two images. So the thing we've been calling content loss they call perceptual loss", "tokens": [51414, 316, 3209, 365, 732, 5267, 13, 407, 264, 551, 321, 600, 668, 5141, 2701, 4470, 436, 818, 43276, 901, 4470, 51696], "temperature": 0.0, "avg_logprob": -0.3611754405347607, "compression_ratio": 1.6394230769230769, "no_speech_prob": 2.3552493075840175e-05}, {"id": 447, "seek": 209088, "start": 2090.92, "end": 2092.92, "text": " So", "tokens": [50366, 407, 50466], "temperature": 0.0, "avg_logprob": -0.30078510322956126, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.401991413440555e-05}, {"id": 448, "seek": 209088, "start": 2093.04, "end": 2098.76, "text": " One of the nice things they do at the start of this and I really like it when papers do this is to say", "tokens": [50472, 1485, 295, 264, 1481, 721, 436, 360, 412, 264, 722, 295, 341, 293, 286, 534, 411, 309, 562, 10577, 360, 341, 307, 281, 584, 50758], "temperature": 0.0, "avg_logprob": -0.30078510322956126, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.401991413440555e-05}, {"id": 449, "seek": 209088, "start": 2098.76, "end": 2100.44, "text": " Okay, why is this paper important?", "tokens": [50758, 1033, 11, 983, 307, 341, 3035, 1021, 30, 50842], "temperature": 0.0, "avg_logprob": -0.30078510322956126, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.401991413440555e-05}, {"id": 450, "seek": 209088, "start": 2100.44, "end": 2105.52, "text": " Well, this paper is important because many problems can be framed as image transformation tasks", "tokens": [50842, 1042, 11, 341, 3035, 307, 1021, 570, 867, 2740, 393, 312, 30420, 382, 3256, 9887, 9608, 51096], "temperature": 0.0, "avg_logprob": -0.30078510322956126, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.401991413440555e-05}, {"id": 451, "seek": 209088, "start": 2106.1600000000003, "end": 2111.76, "text": " Where a system receives some input and chucks out some other output for example", "tokens": [51128, 2305, 257, 1185, 20717, 512, 4846, 293, 417, 15493, 484, 512, 661, 5598, 337, 1365, 51408], "temperature": 0.0, "avg_logprob": -0.30078510322956126, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.401991413440555e-05}, {"id": 452, "seek": 209088, "start": 2112.04, "end": 2118.1600000000003, "text": " Denoising learn to take an input image that's full of noise and spit out a beautifully clean image", "tokens": [51422, 413, 5808, 3436, 1466, 281, 747, 364, 4846, 3256, 300, 311, 1577, 295, 5658, 293, 22127, 484, 257, 16525, 2541, 3256, 51728], "temperature": 0.0, "avg_logprob": -0.30078510322956126, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.401991413440555e-05}, {"id": 453, "seek": 211816, "start": 2119.12, "end": 2123.0, "text": " Super resolution take an input image, which is low res and spit out a high res", "tokens": [50412, 4548, 8669, 747, 364, 4846, 3256, 11, 597, 307, 2295, 725, 293, 22127, 484, 257, 1090, 725, 50606], "temperature": 0.0, "avg_logprob": -0.3293944585890997, "compression_ratio": 1.8641975308641976, "no_speech_prob": 3.7052879633847624e-05}, {"id": 454, "seek": 211816, "start": 2124.2, "end": 2128.7599999999998, "text": " Colorization they can input image which is black and white and spit out something which is color", "tokens": [50666, 10458, 2144, 436, 393, 4846, 3256, 597, 307, 2211, 293, 2418, 293, 22127, 484, 746, 597, 307, 2017, 50894], "temperature": 0.0, "avg_logprob": -0.3293944585890997, "compression_ratio": 1.8641975308641976, "no_speech_prob": 3.7052879633847624e-05}, {"id": 455, "seek": 211816, "start": 2129.56, "end": 2135.8799999999997, "text": " Now one of the interesting things here is that all of these examples you can generate as much", "tokens": [50934, 823, 472, 295, 264, 1880, 721, 510, 307, 300, 439, 295, 613, 5110, 291, 393, 8460, 382, 709, 51250], "temperature": 0.0, "avg_logprob": -0.3293944585890997, "compression_ratio": 1.8641975308641976, "no_speech_prob": 3.7052879633847624e-05}, {"id": 456, "seek": 211816, "start": 2136.64, "end": 2138.3599999999997, "text": " input data as you like", "tokens": [51288, 4846, 1412, 382, 291, 411, 51374], "temperature": 0.0, "avg_logprob": -0.3293944585890997, "compression_ratio": 1.8641975308641976, "no_speech_prob": 3.7052879633847624e-05}, {"id": 457, "seek": 211816, "start": 2138.3599999999997, "end": 2143.92, "text": " by taking lots of images which are either from your camera or you download off the internet or from image net and", "tokens": [51374, 538, 1940, 3195, 295, 5267, 597, 366, 2139, 490, 428, 2799, 420, 291, 5484, 766, 264, 4705, 420, 490, 3256, 2533, 293, 51652], "temperature": 0.0, "avg_logprob": -0.3293944585890997, "compression_ratio": 1.8641975308641976, "no_speech_prob": 3.7052879633847624e-05}, {"id": 458, "seek": 211816, "start": 2144.0, "end": 2146.8799999999997, "text": " You can make them lower res. You can add noise", "tokens": [51656, 509, 393, 652, 552, 3126, 725, 13, 509, 393, 909, 5658, 51800], "temperature": 0.0, "avg_logprob": -0.3293944585890997, "compression_ratio": 1.8641975308641976, "no_speech_prob": 3.7052879633847624e-05}, {"id": 459, "seek": 214688, "start": 2147.48, "end": 2152.1600000000003, "text": " You can make them black and white right so you can generate as much level data as you like", "tokens": [50394, 509, 393, 652, 552, 2211, 293, 2418, 558, 370, 291, 393, 8460, 382, 709, 1496, 1412, 382, 291, 411, 50628], "temperature": 0.0, "avg_logprob": -0.4092833955409163, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0002098811964970082}, {"id": 460, "seek": 214688, "start": 2152.2000000000003, "end": 2155.12, "text": " that's one of the really cool things about this whole topic of", "tokens": [50630, 300, 311, 472, 295, 264, 534, 1627, 721, 466, 341, 1379, 4829, 295, 50776], "temperature": 0.0, "avg_logprob": -0.4092833955409163, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0002098811964970082}, {"id": 461, "seek": 214688, "start": 2158.08, "end": 2160.08, "text": " Generators", "tokens": [50924, 15409, 3391, 51024], "temperature": 0.0, "avg_logprob": -0.4092833955409163, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0002098811964970082}, {"id": 462, "seek": 214688, "start": 2168.48, "end": 2170.7200000000003, "text": " Well with that example so", "tokens": [51444, 1042, 365, 300, 1365, 370, 51556], "temperature": 0.0, "avg_logprob": -0.4092833955409163, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0002098811964970082}, {"id": 463, "seek": 214688, "start": 2172.08, "end": 2175.1400000000003, "text": " Going to lower res imagery or some camera", "tokens": [51624, 10963, 281, 3126, 725, 24340, 420, 512, 2799, 51777], "temperature": 0.0, "avg_logprob": -0.4092833955409163, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0002098811964970082}, {"id": 464, "seek": 217514, "start": 2175.58, "end": 2181.3399999999997, "text": " It's it's algorithmically done, so it's the known that only going to learn how to like", "tokens": [50386, 467, 311, 309, 311, 9284, 984, 1096, 11, 370, 309, 311, 264, 2570, 300, 787, 516, 281, 1466, 577, 281, 411, 50674], "temperature": 0.0, "avg_logprob": -0.32297723558213975, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.00017674322589300573}, {"id": 465, "seek": 217514, "start": 2183.22, "end": 2187.14, "text": " Algorithmically done versus an actual low res imagery that doesn't", "tokens": [50768, 35014, 6819, 76, 984, 1096, 5717, 364, 3539, 2295, 725, 24340, 300, 1177, 380, 50964], "temperature": 0.0, "avg_logprob": -0.32297723558213975, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.00017674322589300573}, {"id": 466, "seek": 217514, "start": 2189.7, "end": 2196.3399999999997, "text": " Yeah, so one thing I just mentioned is the way you would create your label data is not to do that low res on the", "tokens": [51092, 865, 11, 370, 472, 551, 286, 445, 2835, 307, 264, 636, 291, 576, 1884, 428, 7645, 1412, 307, 406, 281, 360, 300, 2295, 725, 322, 264, 51424], "temperature": 0.0, "avg_logprob": -0.32297723558213975, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.00017674322589300573}, {"id": 467, "seek": 217514, "start": 2196.3399999999997, "end": 2201.62, "text": " Camera you would grab the images that you've already taken and make them low res just by doing", "tokens": [51424, 23734, 291, 576, 4444, 264, 5267, 300, 291, 600, 1217, 2726, 293, 652, 552, 2295, 725, 445, 538, 884, 51688], "temperature": 0.0, "avg_logprob": -0.32297723558213975, "compression_ratio": 1.7028301886792452, "no_speech_prob": 0.00017674322589300573}, {"id": 468, "seek": 220162, "start": 2202.1, "end": 2204.1, "text": " A", "tokens": [50388, 316, 50488], "temperature": 0.0, "avg_logprob": -0.3549414316813151, "compression_ratio": 1.7863247863247864, "no_speech_prob": 1.3211810255597811e-05}, {"id": 469, "seek": 220162, "start": 2204.22, "end": 2206.5, "text": " Filtering you know in OpenCV or whatever", "tokens": [50494, 7905, 34200, 291, 458, 294, 7238, 34, 53, 420, 2035, 50608], "temperature": 0.0, "avg_logprob": -0.3549414316813151, "compression_ratio": 1.7863247863247864, "no_speech_prob": 1.3211810255597811e-05}, {"id": 470, "seek": 220162, "start": 2207.22, "end": 2209.46, "text": " And yeah, that is algorithmic", "tokens": [50644, 400, 1338, 11, 300, 307, 9284, 299, 50756], "temperature": 0.0, "avg_logprob": -0.3549414316813151, "compression_ratio": 1.7863247863247864, "no_speech_prob": 1.3211810255597811e-05}, {"id": 471, "seek": 220162, "start": 2210.18, "end": 2212.18, "text": " And it may not be", "tokens": [50792, 400, 309, 815, 406, 312, 50892], "temperature": 0.0, "avg_logprob": -0.3549414316813151, "compression_ratio": 1.7863247863247864, "no_speech_prob": 1.3211810255597811e-05}, {"id": 472, "seek": 220162, "start": 2212.9, "end": 2217.18, "text": " It may not be perfect, but there's lots of ways of generating that low res image. You know you can add", "tokens": [50928, 467, 815, 406, 312, 2176, 11, 457, 456, 311, 3195, 295, 2098, 295, 17746, 300, 2295, 725, 3256, 13, 509, 458, 291, 393, 909, 51142], "temperature": 0.0, "avg_logprob": -0.3549414316813151, "compression_ratio": 1.7863247863247864, "no_speech_prob": 1.3211810255597811e-05}, {"id": 473, "seek": 220162, "start": 2217.62, "end": 2221.2999999999997, "text": " Yeah, so there's lots of ways of creating a low res image so part of it is about", "tokens": [51164, 865, 11, 370, 456, 311, 3195, 295, 2098, 295, 4084, 257, 2295, 725, 3256, 370, 644, 295, 309, 307, 466, 51348], "temperature": 0.0, "avg_logprob": -0.3549414316813151, "compression_ratio": 1.7863247863247864, "no_speech_prob": 1.3211810255597811e-05}, {"id": 474, "seek": 220162, "start": 2221.2999999999997, "end": 2225.7, "text": " How do you do that creation of low res image? How well do you match the?", "tokens": [51348, 1012, 360, 291, 360, 300, 8016, 295, 2295, 725, 3256, 30, 1012, 731, 360, 291, 2995, 264, 30, 51568], "temperature": 0.0, "avg_logprob": -0.3549414316813151, "compression_ratio": 1.7863247863247864, "no_speech_prob": 1.3211810255597811e-05}, {"id": 475, "seek": 220162, "start": 2226.3399999999997, "end": 2228.3399999999997, "text": " Real low res data you're going to be getting", "tokens": [51600, 8467, 2295, 725, 1412, 291, 434, 516, 281, 312, 1242, 51700], "temperature": 0.0, "avg_logprob": -0.3549414316813151, "compression_ratio": 1.7863247863247864, "no_speech_prob": 1.3211810255597811e-05}, {"id": 476, "seek": 220162, "start": 2229.3399999999997, "end": 2231.3399999999997, "text": " Then the end in this case", "tokens": [51750, 1396, 264, 917, 294, 341, 1389, 51850], "temperature": 0.0, "avg_logprob": -0.3549414316813151, "compression_ratio": 1.7863247863247864, "no_speech_prob": 1.3211810255597811e-05}, {"id": 477, "seek": 223162, "start": 2231.62, "end": 2232.98, "text": " things like", "tokens": [50364, 721, 411, 50432], "temperature": 0.0, "avg_logprob": -0.3358052981797085, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.4112590482400265e-06}, {"id": 478, "seek": 223162, "start": 2232.98, "end": 2235.5, "text": " low resolution images or black and white images", "tokens": [50432, 2295, 8669, 5267, 420, 2211, 293, 2418, 5267, 50558], "temperature": 0.0, "avg_logprob": -0.3358052981797085, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.4112590482400265e-06}, {"id": 479, "seek": 223162, "start": 2236.18, "end": 2241.8599999999997, "text": " It's so hard to start with something which is like it could be like and I've seen versions with just an 8x8", "tokens": [50592, 467, 311, 370, 1152, 281, 722, 365, 746, 597, 307, 411, 309, 727, 312, 411, 293, 286, 600, 1612, 9606, 365, 445, 364, 1649, 87, 23, 50876], "temperature": 0.0, "avg_logprob": -0.3358052981797085, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.4112590482400265e-06}, {"id": 480, "seek": 223162, "start": 2242.5, "end": 2245.94, "text": " picture and turning it into a photo like", "tokens": [50908, 3036, 293, 6246, 309, 666, 257, 5052, 411, 51080], "temperature": 0.0, "avg_logprob": -0.3358052981797085, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.4112590482400265e-06}, {"id": 481, "seek": 223162, "start": 2247.1, "end": 2253.94, "text": " It's so hard to do that regardless of how that 8x8 thing was created that often the details of how the", "tokens": [51138, 467, 311, 370, 1152, 281, 360, 300, 10060, 295, 577, 300, 1649, 87, 23, 551, 390, 2942, 300, 2049, 264, 4365, 295, 577, 264, 51480], "temperature": 0.0, "avg_logprob": -0.3358052981797085, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.4112590482400265e-06}, {"id": 482, "seek": 223162, "start": 2254.42, "end": 2257.14, "text": " Low res image was created don't really matter too much", "tokens": [51504, 17078, 725, 3256, 390, 2942, 500, 380, 534, 1871, 886, 709, 51640], "temperature": 0.0, "avg_logprob": -0.3358052981797085, "compression_ratio": 1.7345971563981042, "no_speech_prob": 7.4112590482400265e-06}, {"id": 483, "seek": 225714, "start": 2257.18, "end": 2263.7, "text": " There are some other examples they mentioned which is turning an image into an image which includes segmentation", "tokens": [50366, 821, 366, 512, 661, 5110, 436, 2835, 597, 307, 6246, 364, 3256, 666, 364, 3256, 597, 5974, 9469, 399, 50692], "temperature": 0.0, "avg_logprob": -0.48240527700870595, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.000842632376588881}, {"id": 484, "seek": 225714, "start": 2264.8199999999997, "end": 2267.3799999999997, "text": " We'll learn more about this in coming lessons", "tokens": [50748, 492, 603, 1466, 544, 466, 341, 294, 1348, 8820, 50876], "temperature": 0.0, "avg_logprob": -0.48240527700870595, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.000842632376588881}, {"id": 485, "seek": 225714, "start": 2267.9, "end": 2275.58, "text": " But segmentation refers to taking a photo of something and creating a new image that basically has a different color for each object", "tokens": [50902, 583, 9469, 399, 14942, 281, 1940, 257, 5052, 295, 746, 293, 4084, 257, 777, 3256, 300, 1936, 575, 257, 819, 2017, 337, 1184, 2657, 51286], "temperature": 0.0, "avg_logprob": -0.48240527700870595, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.000842632376588881}, {"id": 486, "seek": 225714, "start": 2275.58, "end": 2280.5, "text": " So horses are green cars are blue buildings are red that kind of thing", "tokens": [51286, 407, 13112, 366, 3092, 5163, 366, 3344, 7446, 366, 2182, 300, 733, 295, 551, 51532], "temperature": 0.0, "avg_logprob": -0.48240527700870595, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.000842632376588881}, {"id": 487, "seek": 225714, "start": 2280.5, "end": 2284.3399999999997, "text": " So that's called segmentation as you know from things like the fisheries competition", "tokens": [51532, 407, 300, 311, 1219, 9469, 399, 382, 291, 458, 490, 721, 411, 264, 20698, 530, 6211, 51724], "temperature": 0.0, "avg_logprob": -0.48240527700870595, "compression_ratio": 1.7392996108949417, "no_speech_prob": 0.000842632376588881}, {"id": 488, "seek": 228434, "start": 2284.34, "end": 2288.1400000000003, "text": " Segmentation can be really important as a part of solving other bigger problems", "tokens": [50364, 1100, 10433, 399, 393, 312, 534, 1021, 382, 257, 644, 295, 12606, 661, 3801, 2740, 50554], "temperature": 0.0, "avg_logprob": -0.4728223298725329, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.220084419008344e-05}, {"id": 489, "seek": 228434, "start": 2289.6600000000003, "end": 2296.3, "text": " Another example they mentioned here is depth estimation. There's lots of important reasons. You would want to use depth estimation for example", "tokens": [50630, 3996, 1365, 436, 2835, 510, 307, 7161, 35701, 13, 821, 311, 3195, 295, 1021, 4112, 13, 509, 576, 528, 281, 764, 7161, 35701, 337, 1365, 50962], "temperature": 0.0, "avg_logprob": -0.4728223298725329, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.220084419008344e-05}, {"id": 490, "seek": 228434, "start": 2296.98, "end": 2305.1800000000003, "text": " Maybe you want to create some fancy video effects where you start with a flat photo, and you want to create some cool new", "tokens": [50996, 2704, 291, 528, 281, 1884, 512, 10247, 960, 5065, 689, 291, 722, 365, 257, 4962, 5052, 11, 293, 291, 528, 281, 1884, 512, 1627, 777, 51406], "temperature": 0.0, "avg_logprob": -0.4728223298725329, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.220084419008344e-05}, {"id": 491, "seek": 228434, "start": 2306.02, "end": 2308.02, "text": " Apple TV thing that like", "tokens": [51448, 6373, 3558, 551, 300, 411, 51548], "temperature": 0.0, "avg_logprob": -0.4728223298725329, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.220084419008344e-05}, {"id": 492, "seek": 228434, "start": 2308.7400000000002, "end": 2312.26, "text": " Moves around the photo with a parallax effect. You know", "tokens": [51584, 3335, 977, 926, 264, 5052, 365, 257, 8069, 2797, 1802, 13, 509, 458, 51760], "temperature": 0.0, "avg_logprob": -0.4728223298725329, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.220084419008344e-05}, {"id": 493, "seek": 231226, "start": 2312.26, "end": 2318.82, "text": " So if you were able to use a CNN to figure out how far away every object was automatically", "tokens": [50364, 407, 498, 291, 645, 1075, 281, 764, 257, 24859, 281, 2573, 484, 577, 1400, 1314, 633, 2657, 390, 6772, 50692], "temperature": 0.0, "avg_logprob": -0.47434993584950763, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.002511434955522418}, {"id": 494, "seek": 231226, "start": 2318.82, "end": 2322.42, "text": " And you could like turn a 2d photo into a 3d image", "tokens": [50692, 400, 291, 727, 411, 1261, 257, 568, 67, 5052, 666, 257, 805, 67, 3256, 50872], "temperature": 0.0, "avg_logprob": -0.47434993584950763, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.002511434955522418}, {"id": 495, "seek": 231226, "start": 2323.2200000000003, "end": 2324.5800000000004, "text": " automatically", "tokens": [50912, 6772, 50980], "temperature": 0.0, "avg_logprob": -0.47434993584950763, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.002511434955522418}, {"id": 496, "seek": 231226, "start": 2324.5800000000004, "end": 2326.5800000000004, "text": " so yeah taking", "tokens": [50980, 370, 1338, 1940, 51080], "temperature": 0.0, "avg_logprob": -0.47434993584950763, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.002511434955522418}, {"id": 497, "seek": 231226, "start": 2326.5800000000004, "end": 2333.0600000000004, "text": " An image in and sticking an image out is kind of the idea in computer vision at least of generative networks", "tokens": [51080, 1107, 3256, 294, 293, 13465, 364, 3256, 484, 307, 733, 295, 264, 1558, 294, 3820, 5201, 412, 1935, 295, 1337, 1166, 9590, 51404], "temperature": 0.0, "avg_logprob": -0.47434993584950763, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.002511434955522418}, {"id": 498, "seek": 231226, "start": 2333.0600000000004, "end": 2338.6600000000003, "text": " So generative models, and so this is why I wanted to talk a lot about generative models during this class", "tokens": [51404, 407, 1337, 1166, 5245, 11, 293, 370, 341, 307, 983, 286, 1415, 281, 751, 257, 688, 466, 1337, 1166, 5245, 1830, 341, 1508, 51684], "temperature": 0.0, "avg_logprob": -0.47434993584950763, "compression_ratio": 1.6452991452991452, "no_speech_prob": 0.002511434955522418}, {"id": 499, "seek": 233866, "start": 2338.66, "end": 2340.66, "text": " It's not just about", "tokens": [50364, 467, 311, 406, 445, 466, 50464], "temperature": 0.0, "avg_logprob": -0.5305154827279104, "compression_ratio": 1.6096256684491979, "no_speech_prob": 0.00010720835416577756}, {"id": 500, "seek": 233866, "start": 2340.8999999999996, "end": 2346.8199999999997, "text": " Artistic style artistic style was just my sneaky way of introducing you to the world of generative models", "tokens": [50476, 5735, 3142, 3758, 17090, 3758, 390, 445, 452, 39518, 636, 295, 15424, 291, 281, 264, 1002, 295, 1337, 1166, 5245, 50772], "temperature": 0.0, "avg_logprob": -0.5305154827279104, "compression_ratio": 1.6096256684491979, "no_speech_prob": 0.00010720835416577756}, {"id": 501, "seek": 233866, "start": 2351.22, "end": 2354.1, "text": " Okay, so let's look at how to create this", "tokens": [50992, 1033, 11, 370, 718, 311, 574, 412, 577, 281, 1884, 341, 51136], "temperature": 0.0, "avg_logprob": -0.5305154827279104, "compression_ratio": 1.6096256684491979, "no_speech_prob": 0.00010720835416577756}, {"id": 502, "seek": 233866, "start": 2355.54, "end": 2362.66, "text": " Super resolution idea and your homework or part of your homework this week will be to create the", "tokens": [51208, 4548, 8669, 1558, 293, 428, 14578, 420, 644, 295, 428, 14578, 341, 1243, 486, 312, 281, 1884, 264, 51564], "temperature": 0.0, "avg_logprob": -0.5305154827279104, "compression_ratio": 1.6096256684491979, "no_speech_prob": 0.00010720835416577756}, {"id": 503, "seek": 233866, "start": 2364.2599999999998, "end": 2366.2599999999998, "text": " New approach to style transformation", "tokens": [51644, 1873, 3109, 281, 3758, 9887, 51744], "temperature": 0.0, "avg_logprob": -0.5305154827279104, "compression_ratio": 1.6096256684491979, "no_speech_prob": 0.00010720835416577756}, {"id": 504, "seek": 236626, "start": 2366.98, "end": 2371.26, "text": " New approach to style transfer, okay, so I'm going to build the super resolution version", "tokens": [50400, 1873, 3109, 281, 3758, 5003, 11, 1392, 11, 370, 286, 478, 516, 281, 1322, 264, 1687, 8669, 3037, 50614], "temperature": 0.0, "avg_logprob": -0.2749642607986286, "compression_ratio": 1.6359447004608294, "no_speech_prob": 6.922138709342107e-05}, {"id": 505, "seek": 236626, "start": 2371.26, "end": 2378.1000000000004, "text": " Which is a slightly simpler version, and then you're going to try and build on top of that to create the style transfer, okay?", "tokens": [50614, 3013, 307, 257, 4748, 18587, 3037, 11, 293, 550, 291, 434, 516, 281, 853, 293, 1322, 322, 1192, 295, 300, 281, 1884, 264, 3758, 5003, 11, 1392, 30, 50956], "temperature": 0.0, "avg_logprob": -0.2749642607986286, "compression_ratio": 1.6359447004608294, "no_speech_prob": 6.922138709342107e-05}, {"id": 506, "seek": 236626, "start": 2378.78, "end": 2380.46, "text": " so", "tokens": [50990, 370, 51074], "temperature": 0.0, "avg_logprob": -0.2749642607986286, "compression_ratio": 1.6359447004608294, "no_speech_prob": 6.922138709342107e-05}, {"id": 507, "seek": 236626, "start": 2380.46, "end": 2383.1800000000003, "text": " Make sure you let me know if you're not sure at any point", "tokens": [51074, 4387, 988, 291, 718, 385, 458, 498, 291, 434, 406, 988, 412, 604, 935, 51210], "temperature": 0.0, "avg_logprob": -0.2749642607986286, "compression_ratio": 1.6359447004608294, "no_speech_prob": 6.922138709342107e-05}, {"id": 508, "seek": 236626, "start": 2384.0600000000004, "end": 2391.1400000000003, "text": " So I've already created a folder of 20,000 a sample of 20,000 image net images", "tokens": [51254, 407, 286, 600, 1217, 2942, 257, 10820, 295, 945, 11, 1360, 257, 6889, 295, 945, 11, 1360, 3256, 2533, 5267, 51608], "temperature": 0.0, "avg_logprob": -0.2749642607986286, "compression_ratio": 1.6359447004608294, "no_speech_prob": 6.922138709342107e-05}, {"id": 509, "seek": 239114, "start": 2391.98, "end": 2397.9, "text": " And I've created two sizes one is 288 by 288 and one is 72 by 72 and", "tokens": [50406, 400, 286, 600, 2942, 732, 11602, 472, 307, 7562, 23, 538, 7562, 23, 293, 472, 307, 18731, 538, 18731, 293, 50702], "temperature": 0.0, "avg_logprob": -0.3630433400472005, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.0002531517529860139}, {"id": 510, "seek": 239114, "start": 2398.7799999999997, "end": 2400.7799999999997, "text": " They're available as be calls arrays", "tokens": [50746, 814, 434, 2435, 382, 312, 5498, 41011, 50846], "temperature": 0.0, "avg_logprob": -0.3630433400472005, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.0002531517529860139}, {"id": 511, "seek": 239114, "start": 2405.98, "end": 2411.2599999999998, "text": " Okay, so I actually posted the link to these last week, and it's on platform.fast.ai", "tokens": [51106, 1033, 11, 370, 286, 767, 9437, 264, 2113, 281, 613, 1036, 1243, 11, 293, 309, 311, 322, 3663, 13, 7011, 13, 1301, 51370], "temperature": 0.0, "avg_logprob": -0.3630433400472005, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.0002531517529860139}, {"id": 512, "seek": 239114, "start": 2411.8599999999997, "end": 2413.98, "text": " So we'll open up those be calls arrays", "tokens": [51400, 407, 321, 603, 1269, 493, 729, 312, 5498, 41011, 51506], "temperature": 0.0, "avg_logprob": -0.3630433400472005, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.0002531517529860139}, {"id": 513, "seek": 239114, "start": 2414.3799999999997, "end": 2419.46, "text": " And one trick you might have hopefully learned in part one is that you can turn a be calls array", "tokens": [51526, 400, 472, 4282, 291, 1062, 362, 4696, 3264, 294, 644, 472, 307, 300, 291, 393, 1261, 257, 312, 5498, 10225, 51780], "temperature": 0.0, "avg_logprob": -0.3630433400472005, "compression_ratio": 1.5748792270531402, "no_speech_prob": 0.0002531517529860139}, {"id": 514, "seek": 241946, "start": 2419.7, "end": 2423.98, "text": " Into a numpy array by slicing it with everything", "tokens": [50376, 23373, 257, 1031, 8200, 10225, 538, 46586, 309, 365, 1203, 50590], "temperature": 0.0, "avg_logprob": -0.3330457185444079, "compression_ratio": 1.8483412322274881, "no_speech_prob": 0.0001488379784859717}, {"id": 515, "seek": 241946, "start": 2424.5, "end": 2428.54, "text": " So anytime you slice the be calls array you get back a numpy array", "tokens": [50616, 407, 13038, 291, 13153, 264, 312, 5498, 10225, 291, 483, 646, 257, 1031, 8200, 10225, 50818], "temperature": 0.0, "avg_logprob": -0.3330457185444079, "compression_ratio": 1.8483412322274881, "no_speech_prob": 0.0001488379784859717}, {"id": 516, "seek": 241946, "start": 2428.58, "end": 2434.78, "text": " So if your slice is everything then this turns it into a numpy array. This is just a convenient way of", "tokens": [50820, 407, 498, 428, 13153, 307, 1203, 550, 341, 4523, 309, 666, 257, 1031, 8200, 10225, 13, 639, 307, 445, 257, 10851, 636, 295, 51130], "temperature": 0.0, "avg_logprob": -0.3330457185444079, "compression_ratio": 1.8483412322274881, "no_speech_prob": 0.0001488379784859717}, {"id": 517, "seek": 241946, "start": 2435.66, "end": 2443.02, "text": " Sharing numpy arrays in this case, so we've now got an array of low resolution images and an array of high resolution images", "tokens": [51174, 49060, 1031, 8200, 41011, 294, 341, 1389, 11, 370, 321, 600, 586, 658, 364, 10225, 295, 2295, 8669, 5267, 293, 364, 10225, 295, 1090, 8669, 5267, 51542], "temperature": 0.0, "avg_logprob": -0.3330457185444079, "compression_ratio": 1.8483412322274881, "no_speech_prob": 0.0001488379784859717}, {"id": 518, "seek": 241946, "start": 2444.9, "end": 2448.62, "text": " So let me start start maybe by showing you the", "tokens": [51636, 407, 718, 385, 722, 722, 1310, 538, 4099, 291, 264, 51822], "temperature": 0.0, "avg_logprob": -0.3330457185444079, "compression_ratio": 1.8483412322274881, "no_speech_prob": 0.0001488379784859717}, {"id": 519, "seek": 244946, "start": 2450.46, "end": 2452.46, "text": " Final network", "tokens": [50414, 13443, 3209, 50514], "temperature": 0.0, "avg_logprob": -0.28536873772030785, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.4510455912386533e-05}, {"id": 520, "seek": 244946, "start": 2454.58, "end": 2456.58, "text": " Okay, this is the final network", "tokens": [50620, 1033, 11, 341, 307, 264, 2572, 3209, 50720], "temperature": 0.0, "avg_logprob": -0.28536873772030785, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.4510455912386533e-05}, {"id": 521, "seek": 244946, "start": 2457.62, "end": 2463.38, "text": " So we start on off by taking in a batch of images low res images", "tokens": [50772, 407, 321, 722, 322, 766, 538, 1940, 294, 257, 15245, 295, 5267, 2295, 725, 5267, 51060], "temperature": 0.0, "avg_logprob": -0.28536873772030785, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.4510455912386533e-05}, {"id": 522, "seek": 244946, "start": 2464.58, "end": 2468.54, "text": " And the very first thing we do is stick them through a convolutional block", "tokens": [51120, 400, 264, 588, 700, 551, 321, 360, 307, 2897, 552, 807, 257, 45216, 304, 3461, 51318], "temperature": 0.0, "avg_logprob": -0.28536873772030785, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.4510455912386533e-05}, {"id": 523, "seek": 244946, "start": 2469.06, "end": 2472.58, "text": " With a stride of one okay, so this is not going to change its size at all", "tokens": [51344, 2022, 257, 1056, 482, 295, 472, 1392, 11, 370, 341, 307, 406, 516, 281, 1319, 1080, 2744, 412, 439, 51520], "temperature": 0.0, "avg_logprob": -0.28536873772030785, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.4510455912386533e-05}, {"id": 524, "seek": 244946, "start": 2473.14, "end": 2477.14, "text": " but this convolutional block has a filter size of 9 and", "tokens": [51548, 457, 341, 45216, 304, 3461, 575, 257, 6608, 2744, 295, 1722, 293, 51748], "temperature": 0.0, "avg_logprob": -0.28536873772030785, "compression_ratio": 1.6153846153846154, "no_speech_prob": 1.4510455912386533e-05}, {"id": 525, "seek": 247714, "start": 2478.02, "end": 2480.02, "text": " It generates 64 filters", "tokens": [50408, 467, 23815, 12145, 15995, 50508], "temperature": 0.0, "avg_logprob": -0.29074793686101463, "compression_ratio": 1.6213592233009708, "no_speech_prob": 7.36857982701622e-05}, {"id": 526, "seek": 247714, "start": 2480.9, "end": 2482.9, "text": " So this is a very large", "tokens": [50552, 407, 341, 307, 257, 588, 2416, 50652], "temperature": 0.0, "avg_logprob": -0.29074793686101463, "compression_ratio": 1.6213592233009708, "no_speech_prob": 7.36857982701622e-05}, {"id": 527, "seek": 247714, "start": 2483.2599999999998, "end": 2486.7, "text": " Filter size okay nowadays filter sizes tend to be 3", "tokens": [50670, 39592, 2744, 1392, 13434, 6608, 11602, 3928, 281, 312, 805, 50842], "temperature": 0.0, "avg_logprob": -0.29074793686101463, "compression_ratio": 1.6213592233009708, "no_speech_prob": 7.36857982701622e-05}, {"id": 528, "seek": 247714, "start": 2489.8199999999997, "end": 2491.8199999999997, "text": " Actually in a lot of modern", "tokens": [50998, 5135, 294, 257, 688, 295, 4363, 51098], "temperature": 0.0, "avg_logprob": -0.29074793686101463, "compression_ratio": 1.6213592233009708, "no_speech_prob": 7.36857982701622e-05}, {"id": 529, "seek": 247714, "start": 2491.8199999999997, "end": 2497.02, "text": " Networks the very first layer is very often a large filter size", "tokens": [51098, 12640, 82, 264, 588, 700, 4583, 307, 588, 2049, 257, 2416, 6608, 2744, 51358], "temperature": 0.0, "avg_logprob": -0.29074793686101463, "compression_ratio": 1.6213592233009708, "no_speech_prob": 7.36857982701622e-05}, {"id": 530, "seek": 247714, "start": 2497.2999999999997, "end": 2499.8599999999997, "text": " Just the one just one very first layer", "tokens": [51372, 1449, 264, 472, 445, 472, 588, 700, 4583, 51500], "temperature": 0.0, "avg_logprob": -0.29074793686101463, "compression_ratio": 1.6213592233009708, "no_speech_prob": 7.36857982701622e-05}, {"id": 531, "seek": 247714, "start": 2499.8599999999997, "end": 2506.58, "text": " and the reason is that it basically allows us to immediately increase the receptive field of all of the", "tokens": [51500, 293, 264, 1778, 307, 300, 309, 1936, 4045, 505, 281, 4258, 3488, 264, 45838, 2519, 295, 439, 295, 264, 51836], "temperature": 0.0, "avg_logprob": -0.29074793686101463, "compression_ratio": 1.6213592233009708, "no_speech_prob": 7.36857982701622e-05}, {"id": 532, "seek": 250714, "start": 2507.22, "end": 2510.94, "text": " layers from now on right so by having 9 by 9", "tokens": [50368, 7914, 490, 586, 322, 558, 370, 538, 1419, 1722, 538, 1722, 50554], "temperature": 0.0, "avg_logprob": -0.2951314972668159, "compression_ratio": 1.6225490196078431, "no_speech_prob": 2.046287954726722e-05}, {"id": 533, "seek": 250714, "start": 2511.8599999999997, "end": 2518.74, "text": " And we don't lose any information because we've gone from three channels to 64 filters", "tokens": [50600, 400, 321, 500, 380, 3624, 604, 1589, 570, 321, 600, 2780, 490, 1045, 9235, 281, 12145, 15995, 50944], "temperature": 0.0, "avg_logprob": -0.2951314972668159, "compression_ratio": 1.6225490196078431, "no_speech_prob": 2.046287954726722e-05}, {"id": 534, "seek": 250714, "start": 2519.14, "end": 2525.54, "text": " Right so each of these 9 by 9 convolutions can actually have quite a lot of information because you've got 64 filters", "tokens": [50964, 1779, 370, 1184, 295, 613, 1722, 538, 1722, 3754, 15892, 393, 767, 362, 1596, 257, 688, 295, 1589, 570, 291, 600, 658, 12145, 15995, 51284], "temperature": 0.0, "avg_logprob": -0.2951314972668159, "compression_ratio": 1.6225490196078431, "no_speech_prob": 2.046287954726722e-05}, {"id": 535, "seek": 250714, "start": 2525.7799999999997, "end": 2530.16, "text": " So you'll be seeing this quite a lot in in modern CNN", "tokens": [51296, 407, 291, 603, 312, 2577, 341, 1596, 257, 688, 294, 294, 4363, 24859, 51515], "temperature": 0.0, "avg_logprob": -0.2951314972668159, "compression_ratio": 1.6225490196078431, "no_speech_prob": 2.046287954726722e-05}, {"id": 536, "seek": 250714, "start": 2530.7799999999997, "end": 2532.7799999999997, "text": " architectures just a single", "tokens": [51546, 6331, 1303, 445, 257, 2167, 51646], "temperature": 0.0, "avg_logprob": -0.2951314972668159, "compression_ratio": 1.6225490196078431, "no_speech_prob": 2.046287954726722e-05}, {"id": 537, "seek": 253278, "start": 2532.86, "end": 2537.1400000000003, "text": " Large filter conflare, so this won't be unusual in the future", "tokens": [50368, 33092, 6608, 416, 3423, 543, 11, 370, 341, 1582, 380, 312, 10901, 294, 264, 2027, 50582], "temperature": 0.0, "avg_logprob": -0.4688753055620797, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0004305539187043905}, {"id": 538, "seek": 253278, "start": 2538.1000000000004, "end": 2540.1000000000004, "text": " Now the next thing", "tokens": [50630, 823, 264, 958, 551, 50730], "temperature": 0.0, "avg_logprob": -0.4688753055620797, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0004305539187043905}, {"id": 539, "seek": 253278, "start": 2540.7000000000003, "end": 2542.7000000000003, "text": " Green box", "tokens": [50760, 6969, 2424, 50860], "temperature": 0.0, "avg_logprob": -0.4688753055620797, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0004305539187043905}, {"id": 540, "seek": 253278, "start": 2545.82, "end": 2548.1000000000004, "text": " Oh just a moment, sorry yeah", "tokens": [51016, 876, 445, 257, 1623, 11, 2597, 1338, 51130], "temperature": 0.0, "avg_logprob": -0.4688753055620797, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0004305539187043905}, {"id": 541, "seek": 253278, "start": 2548.78, "end": 2550.78, "text": " this slide one also", "tokens": [51164, 341, 4137, 472, 611, 51264], "temperature": 0.0, "avg_logprob": -0.4688753055620797, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0004305539187043905}, {"id": 542, "seek": 253278, "start": 2552.7400000000002, "end": 2554.7400000000002, "text": " Yeah, well the stride one is", "tokens": [51362, 865, 11, 731, 264, 1056, 482, 472, 307, 51462], "temperature": 0.0, "avg_logprob": -0.4688753055620797, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0004305539187043905}, {"id": 543, "seek": 253278, "start": 2555.5800000000004, "end": 2560.98, "text": " Important for this first layer because you don't want to throw away any information yet right so in the very first layer", "tokens": [51504, 42908, 337, 341, 700, 4583, 570, 291, 500, 380, 528, 281, 3507, 1314, 604, 1589, 1939, 558, 370, 294, 264, 588, 700, 4583, 51774], "temperature": 0.0, "avg_logprob": -0.4688753055620797, "compression_ratio": 1.5210526315789474, "no_speech_prob": 0.0004305539187043905}, {"id": 544, "seek": 256098, "start": 2561.14, "end": 2567.54, "text": " We want to keep the full image size so with a stride one it doesn't change it doesn't down sample at all", "tokens": [50372, 492, 528, 281, 1066, 264, 1577, 3256, 2744, 370, 365, 257, 1056, 482, 472, 309, 1177, 380, 1319, 309, 1177, 380, 760, 6889, 412, 439, 50692], "temperature": 0.0, "avg_logprob": -0.35500604966107535, "compression_ratio": 1.5656565656565657, "no_speech_prob": 7.031158747849986e-05}, {"id": 545, "seek": 256098, "start": 2572.54, "end": 2575.22, "text": " Yeah, they overlap a lot absolutely", "tokens": [50942, 865, 11, 436, 19959, 257, 688, 3122, 51076], "temperature": 0.0, "avg_logprob": -0.35500604966107535, "compression_ratio": 1.5656565656565657, "no_speech_prob": 7.031158747849986e-05}, {"id": 546, "seek": 256098, "start": 2576.26, "end": 2578.26, "text": " but that's okay a", "tokens": [51128, 457, 300, 311, 1392, 257, 51228], "temperature": 0.0, "avg_logprob": -0.35500604966107535, "compression_ratio": 1.5656565656565657, "no_speech_prob": 7.031158747849986e-05}, {"id": 547, "seek": 256098, "start": 2579.1, "end": 2580.58, "text": " good", "tokens": [51270, 665, 51344], "temperature": 0.0, "avg_logprob": -0.35500604966107535, "compression_ratio": 1.5656565656565657, "no_speech_prob": 7.031158747849986e-05}, {"id": 548, "seek": 256098, "start": 2580.58, "end": 2583.06, "text": " Implementation of a convolution is going to hopefully", "tokens": [51344, 4331, 781, 19631, 295, 257, 45216, 307, 516, 281, 4696, 51468], "temperature": 0.0, "avg_logprob": -0.35500604966107535, "compression_ratio": 1.5656565656565657, "no_speech_prob": 7.031158747849986e-05}, {"id": 549, "seek": 256098, "start": 2583.86, "end": 2589.3, "text": " Memorize some of that or at least keep it in cache, so hopefully won't slow it down too much", "tokens": [51508, 8731, 284, 1125, 512, 295, 300, 420, 412, 1935, 1066, 309, 294, 19459, 11, 370, 4696, 1582, 380, 2964, 309, 760, 886, 709, 51780], "temperature": 0.0, "avg_logprob": -0.35500604966107535, "compression_ratio": 1.5656565656565657, "no_speech_prob": 7.031158747849986e-05}, {"id": 550, "seek": 258930, "start": 2590.3, "end": 2596.54, "text": " One of the discussions, I was just having during the break was like", "tokens": [50414, 1485, 295, 264, 11088, 11, 286, 390, 445, 1419, 1830, 264, 1821, 390, 411, 50726], "temperature": 0.0, "avg_logprob": -0.3399663198561895, "compression_ratio": 1.669767441860465, "no_speech_prob": 6.204992678249255e-05}, {"id": 551, "seek": 258930, "start": 2600.1800000000003, "end": 2601.38, "text": " How", "tokens": [50908, 1012, 50968], "temperature": 0.0, "avg_logprob": -0.3399663198561895, "compression_ratio": 1.669767441860465, "no_speech_prob": 6.204992678249255e-05}, {"id": 552, "seek": 258930, "start": 2601.38, "end": 2609.1800000000003, "text": " How practical you know are the things that we're learning at the moment compared to like part one where everything was just designed entirely?", "tokens": [50968, 1012, 8496, 291, 458, 366, 264, 721, 300, 321, 434, 2539, 412, 264, 1623, 5347, 281, 411, 644, 472, 689, 1203, 390, 445, 4761, 7696, 30, 51358], "temperature": 0.0, "avg_logprob": -0.3399663198561895, "compression_ratio": 1.669767441860465, "no_speech_prob": 6.204992678249255e-05}, {"id": 553, "seek": 258930, "start": 2609.1800000000003, "end": 2613.0600000000004, "text": " To be like here the most practical things which we have best practices for", "tokens": [51358, 1407, 312, 411, 510, 264, 881, 8496, 721, 597, 321, 362, 1151, 7525, 337, 51552], "temperature": 0.0, "avg_logprob": -0.3399663198561895, "compression_ratio": 1.669767441860465, "no_speech_prob": 6.204992678249255e-05}, {"id": 554, "seek": 258930, "start": 2613.5800000000004, "end": 2616.1000000000004, "text": " And the answer is like a lot of the stuff. We're going to be learning", "tokens": [51578, 400, 264, 1867, 307, 411, 257, 688, 295, 264, 1507, 13, 492, 434, 516, 281, 312, 2539, 51704], "temperature": 0.0, "avg_logprob": -0.3399663198561895, "compression_ratio": 1.669767441860465, "no_speech_prob": 6.204992678249255e-05}, {"id": 555, "seek": 261610, "start": 2617.02, "end": 2622.94, "text": " No one quite knows how practical it is because a lot of it's just hasn't really been around that long", "tokens": [50410, 883, 472, 1596, 3255, 577, 8496, 309, 307, 570, 257, 688, 295, 309, 311, 445, 6132, 380, 534, 668, 926, 300, 938, 50706], "temperature": 0.0, "avg_logprob": -0.3180008331934611, "compression_ratio": 1.6041666666666667, "no_speech_prob": 9.610073175281286e-05}, {"id": 556, "seek": 261610, "start": 2624.18, "end": 2628.02, "text": " Stored and maybe there aren't any great libraries for it yet, so one of the things", "tokens": [50768, 745, 2769, 293, 1310, 456, 3212, 380, 604, 869, 15148, 337, 309, 1939, 11, 370, 472, 295, 264, 721, 50960], "temperature": 0.0, "avg_logprob": -0.3180008331934611, "compression_ratio": 1.6041666666666667, "no_speech_prob": 9.610073175281286e-05}, {"id": 557, "seek": 261610, "start": 2628.02, "end": 2631.54, "text": " I'm actually hoping from this part two is by learning", "tokens": [50960, 286, 478, 767, 7159, 490, 341, 644, 732, 307, 538, 2539, 51136], "temperature": 0.0, "avg_logprob": -0.3180008331934611, "compression_ratio": 1.6041666666666667, "no_speech_prob": 9.610073175281286e-05}, {"id": 558, "seek": 261610, "start": 2633.5, "end": 2635.74, "text": " The edge of research stuff or beyond", "tokens": [51234, 440, 4691, 295, 2132, 1507, 420, 4399, 51346], "temperature": 0.0, "avg_logprob": -0.3180008331934611, "compression_ratio": 1.6041666666666667, "no_speech_prob": 9.610073175281286e-05}, {"id": 559, "seek": 261610, "start": 2636.38, "end": 2638.38, "text": " amongst a diverse group is", "tokens": [51378, 12918, 257, 9521, 1594, 307, 51478], "temperature": 0.0, "avg_logprob": -0.3180008331934611, "compression_ratio": 1.6041666666666667, "no_speech_prob": 9.610073175281286e-05}, {"id": 560, "seek": 261610, "start": 2638.5, "end": 2643.66, "text": " That some of you will look at it and think about your whatever you do nine to five", "tokens": [51484, 663, 512, 295, 291, 486, 574, 412, 309, 293, 519, 466, 428, 2035, 291, 360, 4949, 281, 1732, 51742], "temperature": 0.0, "avg_logprob": -0.3180008331934611, "compression_ratio": 1.6041666666666667, "no_speech_prob": 9.610073175281286e-05}, {"id": 561, "seek": 264366, "start": 2644.2599999999998, "end": 2649.46, "text": " Or eight to six or whatever and think oh, I wonder if I could use that", "tokens": [50394, 1610, 3180, 281, 2309, 420, 2035, 293, 519, 1954, 11, 286, 2441, 498, 286, 727, 764, 300, 50654], "temperature": 0.0, "avg_logprob": -0.3290570576985677, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.302677502389997e-05}, {"id": 562, "seek": 264366, "start": 2650.1, "end": 2651.58, "text": " for this", "tokens": [50686, 337, 341, 50760], "temperature": 0.0, "avg_logprob": -0.3290570576985677, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.302677502389997e-05}, {"id": 563, "seek": 264366, "start": 2651.58, "end": 2658.8599999999997, "text": " If that ever pops into your head, please tell us right please talk about it on the forum because that's that's what we're most interested", "tokens": [50760, 759, 300, 1562, 16795, 666, 428, 1378, 11, 1767, 980, 505, 558, 1767, 751, 466, 309, 322, 264, 17542, 570, 300, 311, 300, 311, 437, 321, 434, 881, 3102, 51124], "temperature": 0.0, "avg_logprob": -0.3290570576985677, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.302677502389997e-05}, {"id": 564, "seek": 264366, "start": 2658.8599999999997, "end": 2661.2599999999998, "text": " In it's like oh you could use", "tokens": [51124, 682, 309, 311, 411, 1954, 291, 727, 764, 51244], "temperature": 0.0, "avg_logprob": -0.3290570576985677, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.302677502389997e-05}, {"id": 565, "seek": 264366, "start": 2662.06, "end": 2664.06, "text": " super resolution for blah or", "tokens": [51284, 1687, 8669, 337, 12288, 420, 51384], "temperature": 0.0, "avg_logprob": -0.3290570576985677, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.302677502389997e-05}, {"id": 566, "seek": 264366, "start": 2664.54, "end": 2671.66, "text": " Depth finding for this or generative models in general for this thing you know I do in pathology or architecture or", "tokens": [51408, 4056, 392, 5006, 337, 341, 420, 1337, 1166, 5245, 294, 2674, 337, 341, 551, 291, 458, 286, 360, 294, 3100, 1793, 420, 9482, 420, 51764], "temperature": 0.0, "avg_logprob": -0.3290570576985677, "compression_ratio": 1.6896551724137931, "no_speech_prob": 6.302677502389997e-05}, {"id": 567, "seek": 267166, "start": 2672.22, "end": 2674.22, "text": " Satellite engineering or whatever", "tokens": [50392, 318, 10810, 642, 7043, 420, 2035, 50492], "temperature": 0.0, "avg_logprob": -0.299104829268022, "compression_ratio": 1.6944444444444444, "no_speech_prob": 3.3213713322766125e-05}, {"id": 568, "seek": 267166, "start": 2674.94, "end": 2676.54, "text": " so", "tokens": [50528, 370, 50608], "temperature": 0.0, "avg_logprob": -0.299104829268022, "compression_ratio": 1.6944444444444444, "no_speech_prob": 3.3213713322766125e-05}, {"id": 569, "seek": 267166, "start": 2676.54, "end": 2678.54, "text": " Yeah, so it's going to require some imagination", "tokens": [50608, 865, 11, 370, 309, 311, 516, 281, 3651, 512, 12938, 50708], "temperature": 0.0, "avg_logprob": -0.299104829268022, "compression_ratio": 1.6944444444444444, "no_speech_prob": 3.3213713322766125e-05}, {"id": 570, "seek": 267166, "start": 2678.94, "end": 2685.8599999999997, "text": " Sometimes on your part and so often that's why I do want to spend some time looking at stuff like this", "tokens": [50728, 4803, 322, 428, 644, 293, 370, 2049, 300, 311, 983, 286, 360, 528, 281, 3496, 512, 565, 1237, 412, 1507, 411, 341, 51074], "temperature": 0.0, "avg_logprob": -0.299104829268022, "compression_ratio": 1.6944444444444444, "no_speech_prob": 3.3213713322766125e-05}, {"id": 571, "seek": 267166, "start": 2686.7, "end": 2688.7, "text": " Where it's like okay?", "tokens": [51116, 2305, 309, 311, 411, 1392, 30, 51216], "temperature": 0.0, "avg_logprob": -0.299104829268022, "compression_ratio": 1.6944444444444444, "no_speech_prob": 3.3213713322766125e-05}, {"id": 572, "seek": 267166, "start": 2688.7799999999997, "end": 2690.7799999999997, "text": " What are the kinds of things?", "tokens": [51220, 708, 366, 264, 3685, 295, 721, 30, 51320], "temperature": 0.0, "avg_logprob": -0.299104829268022, "compression_ratio": 1.6944444444444444, "no_speech_prob": 3.3213713322766125e-05}, {"id": 573, "seek": 267166, "start": 2690.8999999999996, "end": 2695.8199999999997, "text": " That this can be done for but one of the you know I'm sure you know in your own field like one of the differences", "tokens": [51326, 663, 341, 393, 312, 1096, 337, 457, 472, 295, 264, 291, 458, 286, 478, 988, 291, 458, 294, 428, 1065, 2519, 411, 472, 295, 264, 7300, 51572], "temperature": 0.0, "avg_logprob": -0.299104829268022, "compression_ratio": 1.6944444444444444, "no_speech_prob": 3.3213713322766125e-05}, {"id": 574, "seek": 267166, "start": 2695.8199999999997, "end": 2699.66, "text": " Between an expert and beginner is the way an expert can look at something", "tokens": [51572, 18967, 364, 5844, 293, 22080, 307, 264, 636, 364, 5844, 393, 574, 412, 746, 51764], "temperature": 0.0, "avg_logprob": -0.299104829268022, "compression_ratio": 1.6944444444444444, "no_speech_prob": 3.3213713322766125e-05}, {"id": 575, "seek": 269966, "start": 2700.2999999999997, "end": 2705.5, "text": " In first principles and say okay, I could use that for this totally different thing", "tokens": [50396, 682, 700, 9156, 293, 584, 1392, 11, 286, 727, 764, 300, 337, 341, 3879, 819, 551, 50656], "temperature": 0.0, "avg_logprob": -0.37235415259072946, "compression_ratio": 1.579185520361991, "no_speech_prob": 4.6837376430630684e-05}, {"id": 576, "seek": 269966, "start": 2705.5, "end": 2709.3799999999997, "text": " Which has got nothing to do with the example that was originally given to me because I know that", "tokens": [50656, 3013, 575, 658, 1825, 281, 360, 365, 264, 1365, 300, 390, 7993, 2212, 281, 385, 570, 286, 458, 300, 50850], "temperature": 0.0, "avg_logprob": -0.37235415259072946, "compression_ratio": 1.579185520361991, "no_speech_prob": 4.6837376430630684e-05}, {"id": 577, "seek": 269966, "start": 2709.5, "end": 2712.3799999999997, "text": " The basic steps are the same right and that's what?", "tokens": [50856, 440, 3875, 4439, 366, 264, 912, 558, 293, 300, 311, 437, 30, 51000], "temperature": 0.0, "avg_logprob": -0.37235415259072946, "compression_ratio": 1.579185520361991, "no_speech_prob": 4.6837376430630684e-05}, {"id": 578, "seek": 269966, "start": 2712.98, "end": 2717.7999999999997, "text": " I'm hoping you guys will will be able to do is kind of not just say", "tokens": [51030, 286, 478, 7159, 291, 1074, 486, 486, 312, 1075, 281, 360, 307, 733, 295, 406, 445, 584, 51271], "temperature": 0.0, "avg_logprob": -0.37235415259072946, "compression_ratio": 1.579185520361991, "no_speech_prob": 4.6837376430630684e-05}, {"id": 579, "seek": 269966, "start": 2719.2999999999997, "end": 2723.06, "text": " This is right batteries again, just like this in", "tokens": [51346, 639, 307, 558, 13070, 797, 11, 445, 411, 341, 294, 51534], "temperature": 0.0, "avg_logprob": -0.37235415259072946, "compression_ratio": 1.579185520361991, "no_speech_prob": 4.6837376430630684e-05}, {"id": 580, "seek": 272306, "start": 2723.06, "end": 2725.06, "text": " You", "tokens": [50364, 509, 50464], "temperature": 0.0, "avg_logprob": -0.48082498822893416, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.0003150327247567475}, {"id": 581, "seek": 272306, "start": 2726.5, "end": 2729.58, "text": " Yeah, it's not to say okay now. I know how to do artistic style", "tokens": [50536, 865, 11, 309, 311, 406, 281, 584, 1392, 586, 13, 286, 458, 577, 281, 360, 17090, 3758, 50690], "temperature": 0.0, "avg_logprob": -0.48082498822893416, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.0003150327247567475}, {"id": 582, "seek": 272306, "start": 2730.42, "end": 2735.82, "text": " You know are there things in your field which have some similarities to?", "tokens": [50732, 509, 458, 366, 456, 721, 294, 428, 2519, 597, 362, 512, 24197, 281, 30, 51002], "temperature": 0.0, "avg_logprob": -0.48082498822893416, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.0003150327247567475}, {"id": 583, "seek": 272306, "start": 2738.22, "end": 2742.86, "text": " So we were going to talk about the super resolution network", "tokens": [51122, 407, 321, 645, 516, 281, 751, 466, 264, 1687, 8669, 3209, 51354], "temperature": 0.0, "avg_logprob": -0.48082498822893416, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.0003150327247567475}, {"id": 584, "seek": 272306, "start": 2746.1, "end": 2747.86, "text": " And", "tokens": [51516, 400, 51604], "temperature": 0.0, "avg_logprob": -0.48082498822893416, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.0003150327247567475}, {"id": 585, "seek": 272306, "start": 2747.86, "end": 2749.86, "text": " we talked about the idea of the", "tokens": [51604, 321, 2825, 466, 264, 1558, 295, 264, 51704], "temperature": 0.0, "avg_logprob": -0.48082498822893416, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.0003150327247567475}, {"id": 586, "seek": 272306, "start": 2750.58, "end": 2752.58, "text": " initial con block", "tokens": [51740, 5883, 416, 3461, 51840], "temperature": 0.0, "avg_logprob": -0.48082498822893416, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.0003150327247567475}, {"id": 587, "seek": 275258, "start": 2753.06, "end": 2754.46, "text": " so", "tokens": [50388, 370, 50458], "temperature": 0.0, "avg_logprob": -0.35984529194078946, "compression_ratio": 1.6502242152466369, "no_speech_prob": 2.8857068173238076e-05}, {"id": 588, "seek": 275258, "start": 2754.46, "end": 2762.1, "text": " After the initial conf block we have the computation now when I say the computation and any kind of generative network", "tokens": [50458, 2381, 264, 5883, 1497, 3461, 321, 362, 264, 24903, 586, 562, 286, 584, 264, 24903, 293, 604, 733, 295, 1337, 1166, 3209, 50840], "temperature": 0.0, "avg_logprob": -0.35984529194078946, "compression_ratio": 1.6502242152466369, "no_speech_prob": 2.8857068173238076e-05}, {"id": 589, "seek": 275258, "start": 2762.66, "end": 2769.5, "text": " There's like the extra the key work. It has to do which in this case is starting with a low res image", "tokens": [50868, 821, 311, 411, 264, 2857, 264, 2141, 589, 13, 467, 575, 281, 360, 597, 294, 341, 1389, 307, 2891, 365, 257, 2295, 725, 3256, 51210], "temperature": 0.0, "avg_logprob": -0.35984529194078946, "compression_ratio": 1.6502242152466369, "no_speech_prob": 2.8857068173238076e-05}, {"id": 590, "seek": 275258, "start": 2770.1, "end": 2772.1, "text": " figure out like", "tokens": [51240, 2573, 484, 411, 51340], "temperature": 0.0, "avg_logprob": -0.35984529194078946, "compression_ratio": 1.6502242152466369, "no_speech_prob": 2.8857068173238076e-05}, {"id": 591, "seek": 275258, "start": 2772.2599999999998, "end": 2777.46, "text": " What might that black dot be is it is it an eyeball or is it like is it a wheel?", "tokens": [51348, 708, 1062, 300, 2211, 5893, 312, 307, 309, 307, 309, 364, 38868, 420, 307, 309, 411, 307, 309, 257, 5589, 30, 51608], "temperature": 0.0, "avg_logprob": -0.35984529194078946, "compression_ratio": 1.6502242152466369, "no_speech_prob": 2.8857068173238076e-05}, {"id": 592, "seek": 275258, "start": 2778.2999999999997, "end": 2780.58, "text": " Like it basically if you want to do really good", "tokens": [51650, 1743, 309, 1936, 498, 291, 528, 281, 360, 534, 665, 51764], "temperature": 0.0, "avg_logprob": -0.35984529194078946, "compression_ratio": 1.6502242152466369, "no_speech_prob": 2.8857068173238076e-05}, {"id": 593, "seek": 278058, "start": 2781.34, "end": 2786.8199999999997, "text": " Upscaling you actually have to figure out what the objects are so that you know what to draw", "tokens": [50402, 624, 1878, 66, 4270, 291, 767, 362, 281, 2573, 484, 437, 264, 6565, 366, 370, 300, 291, 458, 437, 281, 2642, 50676], "temperature": 0.0, "avg_logprob": -0.29813333736952913, "compression_ratio": 1.755656108597285, "no_speech_prob": 1.5936595445964485e-05}, {"id": 594, "seek": 278058, "start": 2787.5, "end": 2793.02, "text": " Right so that's kind of like the key computation this CNN is going to have to learn to do in", "tokens": [50710, 1779, 370, 300, 311, 733, 295, 411, 264, 2141, 24903, 341, 24859, 307, 516, 281, 362, 281, 1466, 281, 360, 294, 50986], "temperature": 0.0, "avg_logprob": -0.29813333736952913, "compression_ratio": 1.755656108597285, "no_speech_prob": 1.5936595445964485e-05}, {"id": 595, "seek": 278058, "start": 2794.02, "end": 2799.44, "text": " Generative models we generally like to do that computation at a low resolution", "tokens": [51036, 15409, 1166, 5245, 321, 5101, 411, 281, 360, 300, 24903, 412, 257, 2295, 8669, 51307], "temperature": 0.0, "avg_logprob": -0.29813333736952913, "compression_ratio": 1.755656108597285, "no_speech_prob": 1.5936595445964485e-05}, {"id": 596, "seek": 278058, "start": 2800.2999999999997, "end": 2806.7, "text": " There's a couple of reasons why the first is that at a low resolution. There's less work to do so the computation is faster", "tokens": [51350, 821, 311, 257, 1916, 295, 4112, 983, 264, 700, 307, 300, 412, 257, 2295, 8669, 13, 821, 311, 1570, 589, 281, 360, 370, 264, 24903, 307, 4663, 51670], "temperature": 0.0, "avg_logprob": -0.29813333736952913, "compression_ratio": 1.755656108597285, "no_speech_prob": 1.5936595445964485e-05}, {"id": 597, "seek": 280670, "start": 2807.2999999999997, "end": 2812.0, "text": " But more importantly at higher resolutions where generally means we have a", "tokens": [50394, 583, 544, 8906, 412, 2946, 32179, 689, 5101, 1355, 321, 362, 257, 50629], "temperature": 0.0, "avg_logprob": -0.36285720931159127, "compression_ratio": 1.6881720430107527, "no_speech_prob": 2.8857026336481795e-05}, {"id": 598, "seek": 280670, "start": 2812.74, "end": 2816.3399999999997, "text": " Smaller receptive field it generally means we have less", "tokens": [50666, 15287, 260, 45838, 2519, 309, 5101, 1355, 321, 362, 1570, 50846], "temperature": 0.0, "avg_logprob": -0.36285720931159127, "compression_ratio": 1.6881720430107527, "no_speech_prob": 2.8857026336481795e-05}, {"id": 599, "seek": 280670, "start": 2817.18, "end": 2821.54, "text": " Ability to kind of capture large amounts of the image at once and if you want to do really", "tokens": [50888, 2847, 1140, 281, 733, 295, 7983, 2416, 11663, 295, 264, 3256, 412, 1564, 293, 498, 291, 528, 281, 360, 534, 51106], "temperature": 0.0, "avg_logprob": -0.36285720931159127, "compression_ratio": 1.6881720430107527, "no_speech_prob": 2.8857026336481795e-05}, {"id": 600, "seek": 280670, "start": 2823.3399999999997, "end": 2825.3399999999997, "text": " Really great", "tokens": [51196, 4083, 869, 51296], "temperature": 0.0, "avg_logprob": -0.36285720931159127, "compression_ratio": 1.6881720430107527, "no_speech_prob": 2.8857026336481795e-05}, {"id": 601, "seek": 280670, "start": 2825.66, "end": 2830.5, "text": " Kind of computations where you recognize that all this this blob here is a face", "tokens": [51312, 9242, 295, 2807, 763, 689, 291, 5521, 300, 439, 341, 341, 46115, 510, 307, 257, 1851, 51554], "temperature": 0.0, "avg_logprob": -0.36285720931159127, "compression_ratio": 1.6881720430107527, "no_speech_prob": 2.8857026336481795e-05}, {"id": 602, "seek": 283050, "start": 2831.22, "end": 2837.0, "text": " And therefore the dot inside it is an eyeball then you're going to need enough of a receptive field to cover", "tokens": [50400, 400, 4412, 264, 5893, 1854, 309, 307, 364, 38868, 550, 291, 434, 516, 281, 643, 1547, 295, 257, 45838, 2519, 281, 2060, 50689], "temperature": 0.0, "avg_logprob": -0.3209717248075752, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0015247751725837588}, {"id": 603, "seek": 283050, "start": 2837.62, "end": 2844.94, "text": " That whole area I noticed a couple of you asked for information about receptive fields on the forum thread so", "tokens": [50720, 663, 1379, 1859, 286, 5694, 257, 1916, 295, 291, 2351, 337, 1589, 466, 45838, 7909, 322, 264, 17542, 7207, 370, 51086], "temperature": 0.0, "avg_logprob": -0.3209717248075752, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0015247751725837588}, {"id": 604, "seek": 283050, "start": 2847.02, "end": 2852.02, "text": " There's quite a lot of information about this online so Google is your friend here, but the basic idea is", "tokens": [51190, 821, 311, 1596, 257, 688, 295, 1589, 466, 341, 2950, 370, 3329, 307, 428, 1277, 510, 11, 457, 264, 3875, 1558, 307, 51440], "temperature": 0.0, "avg_logprob": -0.3209717248075752, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0015247751725837588}, {"id": 605, "seek": 283050, "start": 2852.54, "end": 2857.82, "text": " If you have a single convolutional filter of 3x3 the receptive field is 3x3", "tokens": [51466, 759, 291, 362, 257, 2167, 45216, 304, 6608, 295, 805, 87, 18, 264, 45838, 2519, 307, 805, 87, 18, 51730], "temperature": 0.0, "avg_logprob": -0.3209717248075752, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0015247751725837588}, {"id": 606, "seek": 285782, "start": 2858.82, "end": 2865.86, "text": " So it's how much space can that convolutional filter impact", "tokens": [50414, 407, 309, 311, 577, 709, 1901, 393, 300, 45216, 304, 6608, 2712, 50766], "temperature": 0.0, "avg_logprob": -0.2764117756827933, "compression_ratio": 1.5140845070422535, "no_speech_prob": 5.1441416871966794e-05}, {"id": 607, "seek": 285782, "start": 2870.6200000000003, "end": 2878.34, "text": " Okay, so here's a 3x3 filter now on the other hand what if you had a 3x3 filter", "tokens": [51004, 1033, 11, 370, 510, 311, 257, 805, 87, 18, 6608, 586, 322, 264, 661, 1011, 437, 498, 291, 632, 257, 805, 87, 18, 6608, 51390], "temperature": 0.0, "avg_logprob": -0.2764117756827933, "compression_ratio": 1.5140845070422535, "no_speech_prob": 5.1441416871966794e-05}, {"id": 608, "seek": 285782, "start": 2880.9, "end": 2886.78, "text": " Which had a 3x3 filter as its input right so that means that the center one", "tokens": [51518, 3013, 632, 257, 805, 87, 18, 6608, 382, 1080, 4846, 558, 370, 300, 1355, 300, 264, 3056, 472, 51812], "temperature": 0.0, "avg_logprob": -0.2764117756827933, "compression_ratio": 1.5140845070422535, "no_speech_prob": 5.1441416871966794e-05}, {"id": 609, "seek": 288782, "start": 2887.82, "end": 2893.7400000000002, "text": " Took all of this right, but what did this one take well this one would have taken depending on the stride", "tokens": [50364, 1407, 453, 439, 295, 341, 558, 11, 457, 437, 630, 341, 472, 747, 731, 341, 472, 576, 362, 2726, 5413, 322, 264, 1056, 482, 50660], "temperature": 0.0, "avg_logprob": -0.382154339238217, "compression_ratio": 1.6839080459770115, "no_speech_prob": 6.854274033685215e-06}, {"id": 610, "seek": 288782, "start": 2895.2200000000003, "end": 2901.86, "text": " Probably these ones here right and this one over here would have taken", "tokens": [50734, 9210, 613, 2306, 510, 558, 293, 341, 472, 670, 510, 576, 362, 2726, 51066], "temperature": 0.0, "avg_logprob": -0.382154339238217, "compression_ratio": 1.6839080459770115, "no_speech_prob": 6.854274033685215e-06}, {"id": 611, "seek": 288782, "start": 2904.1800000000003, "end": 2907.6400000000003, "text": " These ones here so in other words in the second layer", "tokens": [51182, 1981, 2306, 510, 370, 294, 661, 2283, 294, 264, 1150, 4583, 51355], "temperature": 0.0, "avg_logprob": -0.382154339238217, "compression_ratio": 1.6839080459770115, "no_speech_prob": 6.854274033685215e-06}, {"id": 612, "seek": 288782, "start": 2908.3, "end": 2911.94, "text": " I'm assuming a stride of one the receptive field is now", "tokens": [51388, 286, 478, 11926, 257, 1056, 482, 295, 472, 264, 45838, 2519, 307, 586, 51570], "temperature": 0.0, "avg_logprob": -0.382154339238217, "compression_ratio": 1.6839080459770115, "no_speech_prob": 6.854274033685215e-06}, {"id": 613, "seek": 288782, "start": 2913.02, "end": 2915.02, "text": " 5 by 5", "tokens": [51624, 1025, 538, 1025, 51724], "temperature": 0.0, "avg_logprob": -0.382154339238217, "compression_ratio": 1.6839080459770115, "no_speech_prob": 6.854274033685215e-06}, {"id": 614, "seek": 291502, "start": 2915.06, "end": 2917.06, "text": " Not 3 by 3", "tokens": [50366, 1726, 805, 538, 805, 50466], "temperature": 0.0, "avg_logprob": -0.4105426834290286, "compression_ratio": 1.6536585365853658, "no_speech_prob": 2.111243702529464e-05}, {"id": 615, "seek": 291502, "start": 2917.18, "end": 2922.18, "text": " so the receptive field depends on two things one is how many layers deep are you and", "tokens": [50472, 370, 264, 45838, 2519, 5946, 322, 732, 721, 472, 307, 577, 867, 7914, 2452, 366, 291, 293, 50722], "temperature": 0.0, "avg_logprob": -0.4105426834290286, "compression_ratio": 1.6536585365853658, "no_speech_prob": 2.111243702529464e-05}, {"id": 616, "seek": 291502, "start": 2922.66, "end": 2930.08, "text": " The second is how much did the previous layers either have a non unit stride or maybe they had max pooling", "tokens": [50746, 440, 1150, 307, 577, 709, 630, 264, 3894, 7914, 2139, 362, 257, 2107, 4985, 1056, 482, 420, 1310, 436, 632, 11469, 7005, 278, 51117], "temperature": 0.0, "avg_logprob": -0.4105426834290286, "compression_ratio": 1.6536585365853658, "no_speech_prob": 2.111243702529464e-05}, {"id": 617, "seek": 291502, "start": 2930.54, "end": 2936.18, "text": " Right so in some way they were coming down sample those two things increase the receptive field", "tokens": [51140, 1779, 370, 294, 512, 636, 436, 645, 1348, 760, 6889, 729, 732, 721, 3488, 264, 45838, 2519, 51422], "temperature": 0.0, "avg_logprob": -0.4105426834290286, "compression_ratio": 1.6536585365853658, "no_speech_prob": 2.111243702529464e-05}, {"id": 618, "seek": 291502, "start": 2936.78, "end": 2939.94, "text": " And so the reason it's great to be doing", "tokens": [51452, 400, 370, 264, 1778, 309, 311, 869, 281, 312, 884, 51610], "temperature": 0.0, "avg_logprob": -0.4105426834290286, "compression_ratio": 1.6536585365853658, "no_speech_prob": 2.111243702529464e-05}, {"id": 619, "seek": 293994, "start": 2940.94, "end": 2948.66, "text": " Layer computations on a large receptive field is that it then allows you to look at the big picture and look at the context", "tokens": [50414, 35166, 2807, 763, 322, 257, 2416, 45838, 2519, 307, 300, 309, 550, 4045, 291, 281, 574, 412, 264, 955, 3036, 293, 574, 412, 264, 4319, 50800], "temperature": 0.0, "avg_logprob": -0.3493934392929077, "compression_ratio": 1.5583756345177664, "no_speech_prob": 7.031147833913565e-05}, {"id": 620, "seek": 293994, "start": 2948.7400000000002, "end": 2953.2200000000003, "text": " It's not just edges anymore, but the eyeballs and and noses", "tokens": [50804, 467, 311, 406, 445, 8819, 3602, 11, 457, 264, 43758, 293, 293, 3269, 279, 51028], "temperature": 0.0, "avg_logprob": -0.3493934392929077, "compression_ratio": 1.5583756345177664, "no_speech_prob": 7.031147833913565e-05}, {"id": 621, "seek": 293994, "start": 2955.34, "end": 2957.34, "text": " So in this case we have", "tokens": [51134, 407, 294, 341, 1389, 321, 362, 51234], "temperature": 0.0, "avg_logprob": -0.3493934392929077, "compression_ratio": 1.5583756345177664, "no_speech_prob": 7.031147833913565e-05}, {"id": 622, "seek": 293994, "start": 2957.58, "end": 2961.02, "text": " four blocks of computation where each block is a", "tokens": [51246, 1451, 8474, 295, 24903, 689, 1184, 3461, 307, 257, 51418], "temperature": 0.0, "avg_logprob": -0.3493934392929077, "compression_ratio": 1.5583756345177664, "no_speech_prob": 7.031147833913565e-05}, {"id": 623, "seek": 293994, "start": 2961.7400000000002, "end": 2963.1, "text": " ResNet block", "tokens": [51454, 5015, 31890, 3461, 51522], "temperature": 0.0, "avg_logprob": -0.3493934392929077, "compression_ratio": 1.5583756345177664, "no_speech_prob": 7.031147833913565e-05}, {"id": 624, "seek": 293994, "start": 2963.1, "end": 2965.7000000000003, "text": " So for those of you that don't recall", "tokens": [51522, 407, 337, 729, 295, 291, 300, 500, 380, 9901, 51652], "temperature": 0.0, "avg_logprob": -0.3493934392929077, "compression_ratio": 1.5583756345177664, "no_speech_prob": 7.031147833913565e-05}, {"id": 625, "seek": 296570, "start": 2966.22, "end": 2969.8199999999997, "text": " How resnet works it would be a good idea to go back to part one and review", "tokens": [50390, 1012, 725, 7129, 1985, 309, 576, 312, 257, 665, 1558, 281, 352, 646, 281, 644, 472, 293, 3131, 50570], "temperature": 0.0, "avg_logprob": -0.3481163024902344, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0034295518416911364}, {"id": 626, "seek": 296570, "start": 2970.4199999999996, "end": 2972.46, "text": " But to remind ourselves, let's look at the code", "tokens": [50600, 583, 281, 4160, 4175, 11, 718, 311, 574, 412, 264, 3089, 50702], "temperature": 0.0, "avg_logprob": -0.3481163024902344, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0034295518416911364}, {"id": 627, "seek": 296570, "start": 2973.5, "end": 2975.46, "text": " Here's a resnet block", "tokens": [50754, 1692, 311, 257, 725, 7129, 3461, 50852], "temperature": 0.0, "avg_logprob": -0.3481163024902344, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0034295518416911364}, {"id": 628, "seek": 296570, "start": 2975.46, "end": 2978.7, "text": " so all the resnet block does is it takes some input and", "tokens": [50852, 370, 439, 264, 725, 7129, 3461, 775, 307, 309, 2516, 512, 4846, 293, 51014], "temperature": 0.0, "avg_logprob": -0.3481163024902344, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0034295518416911364}, {"id": 629, "seek": 296570, "start": 2979.58, "end": 2982.4199999999996, "text": " It does two convolutional blocks on", "tokens": [51058, 467, 775, 732, 45216, 304, 8474, 322, 51200], "temperature": 0.0, "avg_logprob": -0.3481163024902344, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0034295518416911364}, {"id": 630, "seek": 296570, "start": 2983.22, "end": 2985.5, "text": " That input and then it adds", "tokens": [51240, 663, 4846, 293, 550, 309, 10860, 51354], "temperature": 0.0, "avg_logprob": -0.3481163024902344, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0034295518416911364}, {"id": 631, "seek": 296570, "start": 2986.2599999999998, "end": 2991.54, "text": " The result of those convolutions back to the original input so you might remember from part one", "tokens": [51392, 440, 1874, 295, 729, 3754, 15892, 646, 281, 264, 3380, 4846, 370, 291, 1062, 1604, 490, 644, 472, 51656], "temperature": 0.0, "avg_logprob": -0.3481163024902344, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0034295518416911364}, {"id": 632, "seek": 299154, "start": 2991.54, "end": 2996.94, "text": " We actually kind of drew it we said there's some input and it goes through two convolutional blocks", "tokens": [50364, 492, 767, 733, 295, 12804, 309, 321, 848, 456, 311, 512, 4846, 293, 309, 1709, 807, 732, 45216, 304, 8474, 50634], "temperature": 0.0, "avg_logprob": -0.36859097798665363, "compression_ratio": 1.586021505376344, "no_speech_prob": 0.006692735943943262}, {"id": 633, "seek": 299154, "start": 2998.06, "end": 2999.34, "text": " and", "tokens": [50690, 293, 50754], "temperature": 0.0, "avg_logprob": -0.36859097798665363, "compression_ratio": 1.586021505376344, "no_speech_prob": 0.006692735943943262}, {"id": 634, "seek": 299154, "start": 2999.34, "end": 3005.2599999999998, "text": " Then it goes back and is added to the original right and if you remember we basically said in that case", "tokens": [50754, 1396, 309, 1709, 646, 293, 307, 3869, 281, 264, 3380, 558, 293, 498, 291, 1604, 321, 1936, 848, 294, 300, 1389, 51050], "temperature": 0.0, "avg_logprob": -0.36859097798665363, "compression_ratio": 1.586021505376344, "no_speech_prob": 0.006692735943943262}, {"id": 635, "seek": 299154, "start": 3006.18, "end": 3010.9, "text": " We've got y equals x plus some function of x", "tokens": [51096, 492, 600, 658, 288, 6915, 2031, 1804, 512, 2445, 295, 2031, 51332], "temperature": 0.0, "avg_logprob": -0.36859097798665363, "compression_ratio": 1.586021505376344, "no_speech_prob": 0.006692735943943262}, {"id": 636, "seek": 299154, "start": 3012.3, "end": 3014.58, "text": " Right which means that the function", "tokens": [51402, 1779, 597, 1355, 300, 264, 2445, 51516], "temperature": 0.0, "avg_logprob": -0.36859097798665363, "compression_ratio": 1.586021505376344, "no_speech_prob": 0.006692735943943262}, {"id": 637, "seek": 299154, "start": 3016.7799999999997, "end": 3018.7799999999997, "text": " Equals", "tokens": [51626, 15624, 1124, 51726], "temperature": 0.0, "avg_logprob": -0.36859097798665363, "compression_ratio": 1.586021505376344, "no_speech_prob": 0.006692735943943262}, {"id": 638, "seek": 301878, "start": 3018.9, "end": 3022.34, "text": " Y minus X and this thing here is a", "tokens": [50370, 398, 3175, 1783, 293, 341, 551, 510, 307, 257, 50542], "temperature": 0.0, "avg_logprob": -0.3059384614518545, "compression_ratio": 1.7361111111111112, "no_speech_prob": 2.3552549464511685e-05}, {"id": 639, "seek": 301878, "start": 3023.26, "end": 3025.26, "text": " residual right so a whole stack of", "tokens": [50588, 27980, 558, 370, 257, 1379, 8630, 295, 50688], "temperature": 0.0, "avg_logprob": -0.3059384614518545, "compression_ratio": 1.7361111111111112, "no_speech_prob": 2.3552549464511685e-05}, {"id": 640, "seek": 301878, "start": 3025.6600000000003, "end": 3026.7000000000003, "text": " residual blocks", "tokens": [50708, 27980, 8474, 50760], "temperature": 0.0, "avg_logprob": -0.3059384614518545, "compression_ratio": 1.7361111111111112, "no_speech_prob": 2.3552549464511685e-05}, {"id": 641, "seek": 301878, "start": 3026.7000000000003, "end": 3031.5400000000004, "text": " ResNet blocks on top of each other can learn to gradually get hone in on", "tokens": [50760, 5015, 31890, 8474, 322, 1192, 295, 1184, 661, 393, 1466, 281, 13145, 483, 43212, 294, 322, 51002], "temperature": 0.0, "avg_logprob": -0.3059384614518545, "compression_ratio": 1.7361111111111112, "no_speech_prob": 2.3552549464511685e-05}, {"id": 642, "seek": 301878, "start": 3031.7400000000002, "end": 3036.5800000000004, "text": " Whatever is whatever it's trying to do in this case what it's trying to do is get the information", "tokens": [51012, 8541, 307, 2035, 309, 311, 1382, 281, 360, 294, 341, 1389, 437, 309, 311, 1382, 281, 360, 307, 483, 264, 1589, 51254], "temperature": 0.0, "avg_logprob": -0.3059384614518545, "compression_ratio": 1.7361111111111112, "no_speech_prob": 2.3552549464511685e-05}, {"id": 643, "seek": 301878, "start": 3036.5800000000004, "end": 3039.82, "text": " It's going to need to upscale this in a smart way", "tokens": [51254, 467, 311, 516, 281, 643, 281, 493, 20033, 341, 294, 257, 4069, 636, 51416], "temperature": 0.0, "avg_logprob": -0.3059384614518545, "compression_ratio": 1.7361111111111112, "no_speech_prob": 2.3552549464511685e-05}, {"id": 644, "seek": 301878, "start": 3040.94, "end": 3042.94, "text": " so", "tokens": [51472, 370, 51572], "temperature": 0.0, "avg_logprob": -0.3059384614518545, "compression_ratio": 1.7361111111111112, "no_speech_prob": 2.3552549464511685e-05}, {"id": 645, "seek": 301878, "start": 3043.02, "end": 3046.86, "text": " We're going to be using a lot more of this idea of kind of taking", "tokens": [51576, 492, 434, 516, 281, 312, 1228, 257, 688, 544, 295, 341, 1558, 295, 733, 295, 1940, 51768], "temperature": 0.0, "avg_logprob": -0.3059384614518545, "compression_ratio": 1.7361111111111112, "no_speech_prob": 2.3552549464511685e-05}, {"id": 646, "seek": 304686, "start": 3047.6600000000003, "end": 3052.26, "text": " Blocks that we know work well for something and just reuse them right and so then", "tokens": [50404, 9865, 2761, 300, 321, 458, 589, 731, 337, 746, 293, 445, 26225, 552, 558, 293, 370, 550, 50634], "temperature": 0.0, "avg_logprob": -0.3723434829711914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 2.885660796891898e-05}, {"id": 647, "seek": 304686, "start": 3052.82, "end": 3056.7000000000003, "text": " What's a conv block well all the conv block is in this case is it's a?", "tokens": [50662, 708, 311, 257, 3754, 3461, 731, 439, 264, 3754, 3461, 307, 294, 341, 1389, 307, 309, 311, 257, 30, 50856], "temperature": 0.0, "avg_logprob": -0.3723434829711914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 2.885660796891898e-05}, {"id": 648, "seek": 304686, "start": 3057.78, "end": 3058.98, "text": " convolution", "tokens": [50910, 45216, 50970], "temperature": 0.0, "avg_logprob": -0.3723434829711914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 2.885660796891898e-05}, {"id": 649, "seek": 304686, "start": 3058.98, "end": 3060.98, "text": " followed by a batch norm", "tokens": [50970, 6263, 538, 257, 15245, 2026, 51070], "temperature": 0.0, "avg_logprob": -0.3723434829711914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 2.885660796891898e-05}, {"id": 650, "seek": 304686, "start": 3061.86, "end": 3066.6200000000003, "text": " Optionally followed by an activation and one of the things we now know about", "tokens": [51114, 29284, 379, 6263, 538, 364, 24433, 293, 472, 295, 264, 721, 321, 586, 458, 466, 51352], "temperature": 0.0, "avg_logprob": -0.3723434829711914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 2.885660796891898e-05}, {"id": 651, "seek": 304686, "start": 3067.5, "end": 3070.2200000000003, "text": " ResNet blocks is that we generally don't want", "tokens": [51396, 5015, 31890, 8474, 307, 300, 321, 5101, 500, 380, 528, 51532], "temperature": 0.0, "avg_logprob": -0.3723434829711914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 2.885660796891898e-05}, {"id": 652, "seek": 304686, "start": 3071.82, "end": 3075.42, "text": " An activation at the end and that's one of the things that a more recent paper", "tokens": [51612, 1107, 24433, 412, 264, 917, 293, 300, 311, 472, 295, 264, 721, 300, 257, 544, 5162, 3035, 51792], "temperature": 0.0, "avg_logprob": -0.3723434829711914, "compression_ratio": 1.7772727272727273, "no_speech_prob": 2.885660796891898e-05}, {"id": 653, "seek": 307542, "start": 3076.2200000000003, "end": 3080.7400000000002, "text": " Discovered so you can see that for my second conf block. I have no activation", "tokens": [50404, 40386, 292, 370, 291, 393, 536, 300, 337, 452, 1150, 1497, 3461, 13, 286, 362, 572, 24433, 50630], "temperature": 0.0, "avg_logprob": -0.33141180674235027, "compression_ratio": 1.8095238095238095, "no_speech_prob": 4.908634946332313e-05}, {"id": 654, "seek": 307542, "start": 3082.2200000000003, "end": 3085.9, "text": " I'm sure you've noticed throughout this course that I", "tokens": [50704, 286, 478, 988, 291, 600, 5694, 3710, 341, 1164, 300, 286, 50888], "temperature": 0.0, "avg_logprob": -0.33141180674235027, "compression_ratio": 1.8095238095238095, "no_speech_prob": 4.908634946332313e-05}, {"id": 655, "seek": 307542, "start": 3086.58, "end": 3092.06, "text": " Refactor my network architectures a lot my network architectures don't generally list every single layer", "tokens": [50922, 16957, 15104, 452, 3209, 6331, 1303, 257, 688, 452, 3209, 6331, 1303, 500, 380, 5101, 1329, 633, 2167, 4583, 51196], "temperature": 0.0, "avg_logprob": -0.33141180674235027, "compression_ratio": 1.8095238095238095, "no_speech_prob": 4.908634946332313e-05}, {"id": 656, "seek": 307542, "start": 3092.2200000000003, "end": 3096.94, "text": " But they're generally functions which have a bunch of functions which have a bunch of layers in", "tokens": [51204, 583, 436, 434, 5101, 6828, 597, 362, 257, 3840, 295, 6828, 597, 362, 257, 3840, 295, 7914, 294, 51440], "temperature": 0.0, "avg_logprob": -0.33141180674235027, "compression_ratio": 1.8095238095238095, "no_speech_prob": 4.908634946332313e-05}, {"id": 657, "seek": 307542, "start": 3097.54, "end": 3100.8, "text": " a lot of people don't do this like a lot of the", "tokens": [51470, 257, 688, 295, 561, 500, 380, 360, 341, 411, 257, 688, 295, 264, 51633], "temperature": 0.0, "avg_logprob": -0.33141180674235027, "compression_ratio": 1.8095238095238095, "no_speech_prob": 4.908634946332313e-05}, {"id": 658, "seek": 310080, "start": 3101.6800000000003, "end": 3106.92, "text": " Architectures you find online are like hundreds of lines of layer definitions. I think that's crazy", "tokens": [50408, 29306, 1303, 291, 915, 2950, 366, 411, 6779, 295, 3876, 295, 4583, 21988, 13, 286, 519, 300, 311, 3219, 50670], "temperature": 0.0, "avg_logprob": -0.3042758794931265, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.00047284274478442967}, {"id": 659, "seek": 310080, "start": 3106.96, "end": 3112.1200000000003, "text": " It's so easy to make mistakes when you do it that way and so hard to really see what's going on", "tokens": [50672, 467, 311, 370, 1858, 281, 652, 8038, 562, 291, 360, 309, 300, 636, 293, 370, 1152, 281, 534, 536, 437, 311, 516, 322, 50930], "temperature": 0.0, "avg_logprob": -0.3042758794931265, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.00047284274478442967}, {"id": 660, "seek": 310080, "start": 3112.32, "end": 3116.48, "text": " So you know in general I would strongly recommend that you try to refactor your", "tokens": [50940, 407, 291, 458, 294, 2674, 286, 576, 10613, 2748, 300, 291, 853, 281, 1895, 15104, 428, 51148], "temperature": 0.0, "avg_logprob": -0.3042758794931265, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.00047284274478442967}, {"id": 661, "seek": 310080, "start": 3117.36, "end": 3122.5600000000004, "text": " Architectures so that by the time you write the final thing it's you know half a page", "tokens": [51192, 29306, 1303, 370, 300, 538, 264, 565, 291, 2464, 264, 2572, 551, 309, 311, 291, 458, 1922, 257, 3028, 51452], "temperature": 0.0, "avg_logprob": -0.3042758794931265, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.00047284274478442967}, {"id": 662, "seek": 310080, "start": 3123.52, "end": 3127.28, "text": " And you'll see plenty of examples of that so hopefully that'll be helpful", "tokens": [51500, 400, 291, 603, 536, 7140, 295, 5110, 295, 300, 370, 4696, 300, 603, 312, 4961, 51688], "temperature": 0.0, "avg_logprob": -0.3042758794931265, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.00047284274478442967}, {"id": 663, "seek": 312728, "start": 3128.28, "end": 3130.1600000000003, "text": " All right, so we've", "tokens": [50414, 1057, 558, 11, 370, 321, 600, 50508], "temperature": 0.0, "avg_logprob": -0.28065284093221027, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00022341399744618684}, {"id": 664, "seek": 312728, "start": 3130.1600000000003, "end": 3136.1200000000003, "text": " Increased the receptive field we've done a bunch of computation, but we still haven't actually changed the size of the image", "tokens": [50508, 30367, 1937, 264, 45838, 2519, 321, 600, 1096, 257, 3840, 295, 24903, 11, 457, 321, 920, 2378, 380, 767, 3105, 264, 2744, 295, 264, 3256, 50806], "temperature": 0.0, "avg_logprob": -0.28065284093221027, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00022341399744618684}, {"id": 665, "seek": 312728, "start": 3136.6000000000004, "end": 3141.48, "text": " Which is not very helpful, so the next thing we do is we're going to change the size of the image and", "tokens": [50830, 3013, 307, 406, 588, 4961, 11, 370, 264, 958, 551, 321, 360, 307, 321, 434, 516, 281, 1319, 264, 2744, 295, 264, 3256, 293, 51074], "temperature": 0.0, "avg_logprob": -0.28065284093221027, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00022341399744618684}, {"id": 666, "seek": 312728, "start": 3142.4, "end": 3147.7200000000003, "text": " The first thing we're going to learn is to do that with something that goes by many names", "tokens": [51120, 440, 700, 551, 321, 434, 516, 281, 1466, 307, 281, 360, 300, 365, 746, 300, 1709, 538, 867, 5288, 51386], "temperature": 0.0, "avg_logprob": -0.28065284093221027, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00022341399744618684}, {"id": 667, "seek": 314772, "start": 3147.72, "end": 3149.72, "text": " Decomposition", "tokens": [50364, 1346, 1112, 38078, 50464], "temperature": 0.0, "avg_logprob": -0.5440895978142234, "compression_ratio": 1.4955752212389382, "no_speech_prob": 4.985938358004205e-05}, {"id": 668, "seek": 314772, "start": 3154.8799999999997, "end": 3162.52, "text": " One is deconvolution another is it's also known as transposed convolutions", "tokens": [50722, 1485, 307, 979, 266, 85, 3386, 1071, 307, 309, 311, 611, 2570, 382, 7132, 1744, 3754, 15892, 51104], "temperature": 0.0, "avg_logprob": -0.5440895978142234, "compression_ratio": 1.4955752212389382, "no_speech_prob": 4.985938358004205e-05}, {"id": 669, "seek": 314772, "start": 3165.12, "end": 3169.1, "text": " And it's also known as fractionally strided", "tokens": [51234, 400, 309, 311, 611, 2570, 382, 14135, 379, 1056, 2112, 51433], "temperature": 0.0, "avg_logprob": -0.5440895978142234, "compression_ratio": 1.4955752212389382, "no_speech_prob": 4.985938358004205e-05}, {"id": 670, "seek": 314772, "start": 3171.8799999999997, "end": 3173.8799999999997, "text": " Convolutions", "tokens": [51572, 2656, 85, 15892, 51672], "temperature": 0.0, "avg_logprob": -0.5440895978142234, "compression_ratio": 1.4955752212389382, "no_speech_prob": 4.985938358004205e-05}, {"id": 671, "seek": 314772, "start": 3174.48, "end": 3176.48, "text": " In Keras they call them", "tokens": [51702, 682, 591, 6985, 436, 818, 552, 51802], "temperature": 0.0, "avg_logprob": -0.5440895978142234, "compression_ratio": 1.4955752212389382, "no_speech_prob": 4.985938358004205e-05}, {"id": 672, "seek": 317648, "start": 3177.04, "end": 3179.04, "text": " D convolutions", "tokens": [50392, 413, 3754, 15892, 50492], "temperature": 0.0, "avg_logprob": -0.3796773067740507, "compression_ratio": 1.639344262295082, "no_speech_prob": 2.8409633159753866e-05}, {"id": 673, "seek": 317648, "start": 3179.6, "end": 3181.6, "text": " And the basic idea", "tokens": [50520, 400, 264, 3875, 1558, 50620], "temperature": 0.0, "avg_logprob": -0.3796773067740507, "compression_ratio": 1.639344262295082, "no_speech_prob": 2.8409633159753866e-05}, {"id": 674, "seek": 317648, "start": 3182.96, "end": 3185.36, "text": " Is something which I've actually got a spreadsheet to show you", "tokens": [50688, 1119, 746, 597, 286, 600, 767, 658, 257, 27733, 281, 855, 291, 50808], "temperature": 0.0, "avg_logprob": -0.3796773067740507, "compression_ratio": 1.639344262295082, "no_speech_prob": 2.8409633159753866e-05}, {"id": 675, "seek": 317648, "start": 3187.68, "end": 3189.96, "text": " Okay, so here's a spreadsheet here's a spreadsheet", "tokens": [50924, 1033, 11, 370, 510, 311, 257, 27733, 510, 311, 257, 27733, 51038], "temperature": 0.0, "avg_logprob": -0.3796773067740507, "compression_ratio": 1.639344262295082, "no_speech_prob": 2.8409633159753866e-05}, {"id": 676, "seek": 317648, "start": 3191.68, "end": 3193.2400000000002, "text": " The", "tokens": [51124, 440, 51202], "temperature": 0.0, "avg_logprob": -0.3796773067740507, "compression_ratio": 1.639344262295082, "no_speech_prob": 2.8409633159753866e-05}, {"id": 677, "seek": 317648, "start": 3193.2400000000002, "end": 3196.6, "text": " Basic idea is that you've got some kind of image, so here's a 4x4", "tokens": [51202, 31598, 1558, 307, 300, 291, 600, 658, 512, 733, 295, 3256, 11, 370, 510, 311, 257, 1017, 87, 19, 51370], "temperature": 0.0, "avg_logprob": -0.3796773067740507, "compression_ratio": 1.639344262295082, "no_speech_prob": 2.8409633159753866e-05}, {"id": 678, "seek": 317648, "start": 3197.44, "end": 3204.12, "text": " Image some 4x4 data right and you put it through a 3x3 filter convolutional filter", "tokens": [51412, 29903, 512, 1017, 87, 19, 1412, 558, 293, 291, 829, 309, 807, 257, 805, 87, 18, 6608, 45216, 304, 6608, 51746], "temperature": 0.0, "avg_logprob": -0.3796773067740507, "compression_ratio": 1.639344262295082, "no_speech_prob": 2.8409633159753866e-05}, {"id": 679, "seek": 320412, "start": 3204.64, "end": 3206.64, "text": " And if you're doing", "tokens": [50390, 400, 498, 291, 434, 884, 50490], "temperature": 0.0, "avg_logprob": -0.36255870395236545, "compression_ratio": 1.5075376884422111, "no_speech_prob": 2.753556145762559e-05}, {"id": 680, "seek": 320412, "start": 3207.4, "end": 3212.08, "text": " Valid convolutions, then that's going to leave you with a 2x2 output", "tokens": [50528, 7188, 327, 3754, 15892, 11, 550, 300, 311, 516, 281, 1856, 291, 365, 257, 568, 87, 17, 5598, 50762], "temperature": 0.0, "avg_logprob": -0.36255870395236545, "compression_ratio": 1.5075376884422111, "no_speech_prob": 2.753556145762559e-05}, {"id": 681, "seek": 320412, "start": 3213.2, "end": 3215.96, "text": " Because here's one 3x3 another 3x3", "tokens": [50818, 1436, 510, 311, 472, 805, 87, 18, 1071, 805, 87, 18, 50956], "temperature": 0.0, "avg_logprob": -0.36255870395236545, "compression_ratio": 1.5075376884422111, "no_speech_prob": 2.753556145762559e-05}, {"id": 682, "seek": 320412, "start": 3217.64, "end": 3221.04, "text": " Or of them and so each one is", "tokens": [51040, 1610, 295, 552, 293, 370, 1184, 472, 307, 51210], "temperature": 0.0, "avg_logprob": -0.36255870395236545, "compression_ratio": 1.5075376884422111, "no_speech_prob": 2.753556145762559e-05}, {"id": 683, "seek": 320412, "start": 3223.72, "end": 3228.96, "text": " Having the whole filter and the appropriate part of the data, that's just a standard 2d convolution", "tokens": [51344, 10222, 264, 1379, 6608, 293, 264, 6854, 644, 295, 264, 1412, 11, 300, 311, 445, 257, 3832, 568, 67, 45216, 51606], "temperature": 0.0, "avg_logprob": -0.36255870395236545, "compression_ratio": 1.5075376884422111, "no_speech_prob": 2.753556145762559e-05}, {"id": 684, "seek": 320412, "start": 3228.96, "end": 3231.56, "text": " That's so we've we've done that now. Let's say", "tokens": [51606, 663, 311, 370, 321, 600, 321, 600, 1096, 300, 586, 13, 961, 311, 584, 51736], "temperature": 0.0, "avg_logprob": -0.36255870395236545, "compression_ratio": 1.5075376884422111, "no_speech_prob": 2.753556145762559e-05}, {"id": 685, "seek": 323156, "start": 3232.12, "end": 3235.92, "text": " We want to undo that right we want something which can take this", "tokens": [50392, 492, 528, 281, 23779, 300, 558, 321, 528, 746, 597, 393, 747, 341, 50582], "temperature": 0.0, "avg_logprob": -0.3551486643349252, "compression_ratio": 1.656084656084656, "no_speech_prob": 0.00021654280135408044}, {"id": 686, "seek": 323156, "start": 3236.68, "end": 3238.32, "text": " result and", "tokens": [50620, 1874, 293, 50702], "temperature": 0.0, "avg_logprob": -0.3551486643349252, "compression_ratio": 1.656084656084656, "no_speech_prob": 0.00021654280135408044}, {"id": 687, "seek": 323156, "start": 3238.32, "end": 3239.4, "text": " recreate", "tokens": [50702, 25833, 50756], "temperature": 0.0, "avg_logprob": -0.3551486643349252, "compression_ratio": 1.656084656084656, "no_speech_prob": 0.00021654280135408044}, {"id": 688, "seek": 323156, "start": 3239.4, "end": 3242.2, "text": " This input right how would you do that?", "tokens": [50756, 639, 4846, 558, 577, 576, 291, 360, 300, 30, 50896], "temperature": 0.0, "avg_logprob": -0.3551486643349252, "compression_ratio": 1.656084656084656, "no_speech_prob": 0.00021654280135408044}, {"id": 689, "seek": 323156, "start": 3242.88, "end": 3250.36, "text": " So one way to do that would be to take this result right so let's copy it over here right and put back", "tokens": [50930, 407, 472, 636, 281, 360, 300, 576, 312, 281, 747, 341, 1874, 558, 370, 718, 311, 5055, 309, 670, 510, 558, 293, 829, 646, 51304], "temperature": 0.0, "avg_logprob": -0.3551486643349252, "compression_ratio": 1.656084656084656, "no_speech_prob": 0.00021654280135408044}, {"id": 690, "seek": 323156, "start": 3251.24, "end": 3253.84, "text": " that implicit padding so it's", "tokens": [51348, 300, 26947, 39562, 370, 309, 311, 51478], "temperature": 0.0, "avg_logprob": -0.3551486643349252, "compression_ratio": 1.656084656084656, "no_speech_prob": 0.00021654280135408044}, {"id": 691, "seek": 323156, "start": 3254.6, "end": 3258.04, "text": " Surrounded with all these zeros such that now if we use", "tokens": [51516, 6732, 50167, 365, 439, 613, 35193, 1270, 300, 586, 498, 321, 764, 51688], "temperature": 0.0, "avg_logprob": -0.3551486643349252, "compression_ratio": 1.656084656084656, "no_speech_prob": 0.00021654280135408044}, {"id": 692, "seek": 326156, "start": 3262.56, "end": 3267.04, "text": " And let's have some filter, we just started at zero right we have some", "tokens": [50414, 400, 718, 311, 362, 512, 6608, 11, 321, 445, 1409, 412, 4018, 558, 321, 362, 512, 50638], "temperature": 0.0, "avg_logprob": -0.3371443294343494, "compression_ratio": 1.6585365853658536, "no_speech_prob": 9.61021869443357e-05}, {"id": 693, "seek": 326156, "start": 3268.36, "end": 3272.72, "text": " Convolutional filter right and we're going to put it through this entire", "tokens": [50704, 2656, 85, 3386, 304, 6608, 558, 293, 321, 434, 516, 281, 829, 309, 807, 341, 2302, 50922], "temperature": 0.0, "avg_logprob": -0.3371443294343494, "compression_ratio": 1.6585365853658536, "no_speech_prob": 9.61021869443357e-05}, {"id": 694, "seek": 326156, "start": 3274.56, "end": 3278.6, "text": " Matrix a bunch of zeros with our result matrix in the middle", "tokens": [51014, 36274, 257, 3840, 295, 35193, 365, 527, 1874, 8141, 294, 264, 2808, 51216], "temperature": 0.0, "avg_logprob": -0.3371443294343494, "compression_ratio": 1.6585365853658536, "no_speech_prob": 9.61021869443357e-05}, {"id": 695, "seek": 326156, "start": 3279.2, "end": 3284.64, "text": " Right and then we can calculate our result in exactly the same way just a normal convolutional filter", "tokens": [51246, 1779, 293, 550, 321, 393, 8873, 527, 1874, 294, 2293, 264, 912, 636, 445, 257, 2710, 45216, 304, 6608, 51518], "temperature": 0.0, "avg_logprob": -0.3371443294343494, "compression_ratio": 1.6585365853658536, "no_speech_prob": 9.61021869443357e-05}, {"id": 696, "seek": 326156, "start": 3285.16, "end": 3287.16, "text": " so if we now use", "tokens": [51544, 370, 498, 321, 586, 764, 51644], "temperature": 0.0, "avg_logprob": -0.3371443294343494, "compression_ratio": 1.6585365853658536, "no_speech_prob": 9.61021869443357e-05}, {"id": 697, "seek": 326156, "start": 3287.4, "end": 3289.08, "text": " gradient descent", "tokens": [51656, 16235, 23475, 51740], "temperature": 0.0, "avg_logprob": -0.3371443294343494, "compression_ratio": 1.6585365853658536, "no_speech_prob": 9.61021869443357e-05}, {"id": 698, "seek": 328908, "start": 3289.08, "end": 3293.84, "text": " We can look and see okay. What is the error right so how much does this?", "tokens": [50364, 492, 393, 574, 293, 536, 1392, 13, 708, 307, 264, 6713, 558, 370, 577, 709, 775, 341, 30, 50602], "temperature": 0.0, "avg_logprob": -0.33329661349032785, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0002959563280455768}, {"id": 699, "seek": 328908, "start": 3294.6, "end": 3298.56, "text": " pixel differ from this pixel right and how much does", "tokens": [50640, 19261, 743, 490, 341, 19261, 558, 293, 577, 709, 775, 50838], "temperature": 0.0, "avg_logprob": -0.33329661349032785, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0002959563280455768}, {"id": 700, "seek": 328908, "start": 3299.3199999999997, "end": 3305.3199999999997, "text": " This pixel different from this pixel, and then we add them all together to get our mean squared error", "tokens": [50876, 639, 19261, 819, 490, 341, 19261, 11, 293, 550, 321, 909, 552, 439, 1214, 281, 483, 527, 914, 8889, 6713, 51176], "temperature": 0.0, "avg_logprob": -0.33329661349032785, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0002959563280455768}, {"id": 701, "seek": 328908, "start": 3306.24, "end": 3308.24, "text": " So we can now use gradient descent", "tokens": [51222, 407, 321, 393, 586, 764, 16235, 23475, 51322], "temperature": 0.0, "avg_logprob": -0.33329661349032785, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0002959563280455768}, {"id": 702, "seek": 328908, "start": 3309.04, "end": 3312.2, "text": " Which hopefully you remember from part one in Excel is called solver", "tokens": [51362, 3013, 4696, 291, 1604, 490, 644, 472, 294, 19060, 307, 1219, 1404, 331, 51520], "temperature": 0.0, "avg_logprob": -0.33329661349032785, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0002959563280455768}, {"id": 703, "seek": 328908, "start": 3313.08, "end": 3314.2, "text": " and", "tokens": [51564, 293, 51620], "temperature": 0.0, "avg_logprob": -0.33329661349032785, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0002959563280455768}, {"id": 704, "seek": 328908, "start": 3314.2, "end": 3316.12, "text": " We can say okay", "tokens": [51620, 492, 393, 584, 1392, 51716], "temperature": 0.0, "avg_logprob": -0.33329661349032785, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0002959563280455768}, {"id": 705, "seek": 328908, "start": 3316.12, "end": 3318.12, "text": " Set this cell", "tokens": [51716, 8928, 341, 2815, 51816], "temperature": 0.0, "avg_logprob": -0.33329661349032785, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0002959563280455768}, {"id": 706, "seek": 331812, "start": 3318.12, "end": 3319.92, "text": " to a minimum", "tokens": [50364, 281, 257, 7285, 50454], "temperature": 0.0, "avg_logprob": -0.3316964858617538, "compression_ratio": 1.5743589743589743, "no_speech_prob": 3.0718118068762124e-05}, {"id": 707, "seek": 331812, "start": 3319.92, "end": 3324.7999999999997, "text": " By changing these cells right so this is basically like the simplest possible", "tokens": [50454, 3146, 4473, 613, 5438, 558, 370, 341, 307, 1936, 411, 264, 22811, 1944, 50698], "temperature": 0.0, "avg_logprob": -0.3316964858617538, "compression_ratio": 1.5743589743589743, "no_speech_prob": 3.0718118068762124e-05}, {"id": 708, "seek": 331812, "start": 3326.4, "end": 3328.4, "text": " Optimization solve that", "tokens": [50778, 35013, 2144, 5039, 300, 50878], "temperature": 0.0, "avg_logprob": -0.3316964858617538, "compression_ratio": 1.5743589743589743, "no_speech_prob": 3.0718118068762124e-05}, {"id": 709, "seek": 331812, "start": 3331.2799999999997, "end": 3334.44, "text": " And here's what it's come up with right so it's come up with", "tokens": [51022, 400, 510, 311, 437, 309, 311, 808, 493, 365, 558, 370, 309, 311, 808, 493, 365, 51180], "temperature": 0.0, "avg_logprob": -0.3316964858617538, "compression_ratio": 1.5743589743589743, "no_speech_prob": 3.0718118068762124e-05}, {"id": 710, "seek": 331812, "start": 3335.56, "end": 3337.56, "text": " a convolutional filter", "tokens": [51236, 257, 45216, 304, 6608, 51336], "temperature": 0.0, "avg_logprob": -0.3316964858617538, "compression_ratio": 1.5743589743589743, "no_speech_prob": 3.0718118068762124e-05}, {"id": 711, "seek": 331812, "start": 3338.12, "end": 3344.96, "text": " You'll see that the result is not exactly the same as the original data and of course how could it be right?", "tokens": [51364, 509, 603, 536, 300, 264, 1874, 307, 406, 2293, 264, 912, 382, 264, 3380, 1412, 293, 295, 1164, 577, 727, 309, 312, 558, 30, 51706], "temperature": 0.0, "avg_logprob": -0.3316964858617538, "compression_ratio": 1.5743589743589743, "no_speech_prob": 3.0718118068762124e-05}, {"id": 712, "seek": 334496, "start": 3344.96, "end": 3350.4, "text": " We don't have enough information. We only have four things that try and regenerate 16 things", "tokens": [50364, 492, 500, 380, 362, 1547, 1589, 13, 492, 787, 362, 1451, 721, 300, 853, 293, 26358, 473, 3165, 721, 50636], "temperature": 0.0, "avg_logprob": -0.2796523825636188, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0005703112692572176}, {"id": 713, "seek": 334496, "start": 3350.92, "end": 3353.92, "text": " But it's not terrible right and in general this is", "tokens": [50662, 583, 309, 311, 406, 6237, 558, 293, 294, 2674, 341, 307, 50812], "temperature": 0.0, "avg_logprob": -0.2796523825636188, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0005703112692572176}, {"id": 714, "seek": 334496, "start": 3354.48, "end": 3360.48, "text": " This is the challenge with upscaling right when you've got something that's blurred and down sampled", "tokens": [50840, 639, 307, 264, 3430, 365, 493, 4417, 4270, 558, 562, 291, 600, 658, 746, 300, 311, 43525, 293, 760, 3247, 15551, 51140], "temperature": 0.0, "avg_logprob": -0.2796523825636188, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0005703112692572176}, {"id": 715, "seek": 334496, "start": 3360.7200000000003, "end": 3366.44, "text": " You've thrown away information, and so the only way you can get information back is to guess what was there?", "tokens": [51152, 509, 600, 11732, 1314, 1589, 11, 293, 370, 264, 787, 636, 291, 393, 483, 1589, 646, 307, 281, 2041, 437, 390, 456, 30, 51438], "temperature": 0.0, "avg_logprob": -0.2796523825636188, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0005703112692572176}, {"id": 716, "seek": 334496, "start": 3367.2400000000002, "end": 3370.88, "text": " But the important thing is that by using a convolution like this", "tokens": [51478, 583, 264, 1021, 551, 307, 300, 538, 1228, 257, 45216, 411, 341, 51660], "temperature": 0.0, "avg_logprob": -0.2796523825636188, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0005703112692572176}, {"id": 717, "seek": 334496, "start": 3371.52, "end": 3373.52, "text": " We can learn", "tokens": [51692, 492, 393, 1466, 51792], "temperature": 0.0, "avg_logprob": -0.2796523825636188, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0005703112692572176}, {"id": 718, "seek": 337352, "start": 3373.88, "end": 3379.68, "text": " Those filters so we can learn how to up sample it in a way that gives us the loss that we want", "tokens": [50382, 3950, 15995, 370, 321, 393, 1466, 577, 281, 493, 6889, 309, 294, 257, 636, 300, 2709, 505, 264, 4470, 300, 321, 528, 50672], "temperature": 0.0, "avg_logprob": -0.3377670839608434, "compression_ratio": 1.6073298429319371, "no_speech_prob": 2.1444835510919802e-05}, {"id": 719, "seek": 337352, "start": 3380.16, "end": 3383.92, "text": " So this is what a D convolution is it's just a convolution on", "tokens": [50696, 407, 341, 307, 437, 257, 413, 45216, 307, 309, 311, 445, 257, 45216, 322, 50884], "temperature": 0.0, "avg_logprob": -0.3377670839608434, "compression_ratio": 1.6073298429319371, "no_speech_prob": 2.1444835510919802e-05}, {"id": 720, "seek": 337352, "start": 3384.72, "end": 3386.72, "text": " a padded input", "tokens": [50924, 257, 6887, 9207, 4846, 51024], "temperature": 0.0, "avg_logprob": -0.3377670839608434, "compression_ratio": 1.6073298429319371, "no_speech_prob": 2.1444835510919802e-05}, {"id": 721, "seek": 337352, "start": 3387.24, "end": 3393.08, "text": " Right now in this case. I've assumed that my convolutions had a unit stride", "tokens": [51050, 1779, 586, 294, 341, 1389, 13, 286, 600, 15895, 300, 452, 3754, 15892, 632, 257, 4985, 1056, 482, 51342], "temperature": 0.0, "avg_logprob": -0.3377670839608434, "compression_ratio": 1.6073298429319371, "no_speech_prob": 2.1444835510919802e-05}, {"id": 722, "seek": 337352, "start": 3393.08, "end": 3396.44, "text": " I there was just one pixel between each convolution", "tokens": [51342, 286, 456, 390, 445, 472, 19261, 1296, 1184, 45216, 51510], "temperature": 0.0, "avg_logprob": -0.3377670839608434, "compression_ratio": 1.6073298429319371, "no_speech_prob": 2.1444835510919802e-05}, {"id": 723, "seek": 337352, "start": 3397.08, "end": 3399.08, "text": " if your", "tokens": [51542, 498, 428, 51642], "temperature": 0.0, "avg_logprob": -0.3377670839608434, "compression_ratio": 1.6073298429319371, "no_speech_prob": 2.1444835510919802e-05}, {"id": 724, "seek": 339908, "start": 3399.56, "end": 3403.72, "text": " Convolutions are of stride to that it looks like this picture", "tokens": [50388, 2656, 85, 15892, 366, 295, 1056, 482, 281, 300, 309, 1542, 411, 341, 3036, 50596], "temperature": 0.0, "avg_logprob": -0.34341763926076363, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.602337427670136e-05}, {"id": 725, "seek": 339908, "start": 3405.04, "end": 3408.88, "text": " Okay, and so you can see that as well as putting the two pixels around the outside", "tokens": [50662, 1033, 11, 293, 370, 291, 393, 536, 300, 382, 731, 382, 3372, 264, 732, 18668, 926, 264, 2380, 50854], "temperature": 0.0, "avg_logprob": -0.34341763926076363, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.602337427670136e-05}, {"id": 726, "seek": 339908, "start": 3409.56, "end": 3411.92, "text": " We've also put a zero pixel", "tokens": [50888, 492, 600, 611, 829, 257, 4018, 19261, 51006], "temperature": 0.0, "avg_logprob": -0.34341763926076363, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.602337427670136e-05}, {"id": 727, "seek": 339908, "start": 3412.64, "end": 3417.24, "text": " In the middle that so these four cells is now our data cells", "tokens": [51042, 682, 264, 2808, 300, 370, 613, 1451, 5438, 307, 586, 527, 1412, 5438, 51272], "temperature": 0.0, "avg_logprob": -0.34341763926076363, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.602337427670136e-05}, {"id": 728, "seek": 339908, "start": 3417.24, "end": 3421.08, "text": " And you can then see it calculating a convolution through here", "tokens": [51272, 400, 291, 393, 550, 536, 309, 28258, 257, 45216, 807, 510, 51464], "temperature": 0.0, "avg_logprob": -0.34341763926076363, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.602337427670136e-05}, {"id": 729, "seek": 339908, "start": 3421.48, "end": 3426.24, "text": " I strongly suggest looking at this link which is where this picture comes from", "tokens": [51484, 286, 10613, 3402, 1237, 412, 341, 2113, 597, 307, 689, 341, 3036, 1487, 490, 51722], "temperature": 0.0, "avg_logprob": -0.34341763926076363, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.602337427670136e-05}, {"id": 730, "seek": 342624, "start": 3427.24, "end": 3429.24, "text": " And in turn", "tokens": [50414, 400, 294, 1261, 50514], "temperature": 0.0, "avg_logprob": -0.29994722854259404, "compression_ratio": 1.6346153846153846, "no_speech_prob": 7.967201236169785e-05}, {"id": 731, "seek": 342624, "start": 3429.56, "end": 3432.2599999999998, "text": " This link comes from a fantastic paper", "tokens": [50530, 639, 2113, 1487, 490, 257, 5456, 3035, 50665], "temperature": 0.0, "avg_logprob": -0.29994722854259404, "compression_ratio": 1.6346153846153846, "no_speech_prob": 7.967201236169785e-05}, {"id": 732, "seek": 342624, "start": 3432.7999999999997, "end": 3434.9599999999996, "text": " Called the convolution arithmetic guide", "tokens": [50692, 45001, 264, 45216, 42973, 5934, 50800], "temperature": 0.0, "avg_logprob": -0.29994722854259404, "compression_ratio": 1.6346153846153846, "no_speech_prob": 7.967201236169785e-05}, {"id": 733, "seek": 342624, "start": 3435.3999999999996, "end": 3441.9199999999996, "text": " Which is a really great paper, and so if you want to know more about both convolutions and D convolutions you can look at this", "tokens": [50822, 3013, 307, 257, 534, 869, 3035, 11, 293, 370, 498, 291, 528, 281, 458, 544, 466, 1293, 3754, 15892, 293, 413, 3754, 15892, 291, 393, 574, 412, 341, 51148], "temperature": 0.0, "avg_logprob": -0.29994722854259404, "compression_ratio": 1.6346153846153846, "no_speech_prob": 7.967201236169785e-05}, {"id": 734, "seek": 342624, "start": 3442.52, "end": 3444.52, "text": " Page and it's got lots of beautiful", "tokens": [51178, 21217, 293, 309, 311, 658, 3195, 295, 2238, 51278], "temperature": 0.0, "avg_logprob": -0.29994722854259404, "compression_ratio": 1.6346153846153846, "no_speech_prob": 7.967201236169785e-05}, {"id": 735, "seek": 342624, "start": 3445.16, "end": 3446.64, "text": " animations", "tokens": [51310, 22868, 51384], "temperature": 0.0, "avg_logprob": -0.29994722854259404, "compression_ratio": 1.6346153846153846, "no_speech_prob": 7.967201236169785e-05}, {"id": 736, "seek": 342624, "start": 3446.64, "end": 3447.8799999999997, "text": " including", "tokens": [51384, 3009, 51446], "temperature": 0.0, "avg_logprob": -0.29994722854259404, "compression_ratio": 1.6346153846153846, "no_speech_prob": 7.967201236169785e-05}, {"id": 737, "seek": 342624, "start": 3447.8799999999997, "end": 3450.8799999999997, "text": " Animations on they call it transposed convolutions", "tokens": [51446, 21691, 763, 322, 436, 818, 309, 7132, 1744, 3754, 15892, 51596], "temperature": 0.0, "avg_logprob": -0.29994722854259404, "compression_ratio": 1.6346153846153846, "no_speech_prob": 7.967201236169785e-05}, {"id": 738, "seek": 342624, "start": 3452.56, "end": 3454.56, "text": " So you can see", "tokens": [51680, 407, 291, 393, 536, 51780], "temperature": 0.0, "avg_logprob": -0.29994722854259404, "compression_ratio": 1.6346153846153846, "no_speech_prob": 7.967201236169785e-05}, {"id": 739, "seek": 345624, "start": 3457.24, "end": 3458.7599999999998, "text": " You", "tokens": [50414, 509, 50490], "temperature": 0.0, "avg_logprob": -0.34141837226019967, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.705259587150067e-05}, {"id": 740, "seek": 345624, "start": 3458.7599999999998, "end": 3462.4399999999996, "text": " There you go, this is the one I just showed you right, so that's the one we just saw in Excel", "tokens": [50490, 821, 291, 352, 11, 341, 307, 264, 472, 286, 445, 4712, 291, 558, 11, 370, 300, 311, 264, 472, 321, 445, 1866, 294, 19060, 50674], "temperature": 0.0, "avg_logprob": -0.34141837226019967, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.705259587150067e-05}, {"id": 741, "seek": 345624, "start": 3464.2799999999997, "end": 3466.4399999999996, "text": " So that's a good really great site", "tokens": [50766, 407, 300, 311, 257, 665, 534, 869, 3621, 50874], "temperature": 0.0, "avg_logprob": -0.34141837226019967, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.705259587150067e-05}, {"id": 742, "seek": 345624, "start": 3472.24, "end": 3474.72, "text": " Okay, so that's what we're going to do first", "tokens": [51164, 1033, 11, 370, 300, 311, 437, 321, 434, 516, 281, 360, 700, 51288], "temperature": 0.0, "avg_logprob": -0.34141837226019967, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.705259587150067e-05}, {"id": 743, "seek": 345624, "start": 3475.7599999999998, "end": 3477.7599999999998, "text": " is we're going to", "tokens": [51340, 307, 321, 434, 516, 281, 51440], "temperature": 0.0, "avg_logprob": -0.34141837226019967, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.705259587150067e-05}, {"id": 744, "seek": 345624, "start": 3478.2, "end": 3484.24, "text": " Do D convolutions so in Keras a D convolution is exactly the same as convolution", "tokens": [51462, 1144, 413, 3754, 15892, 370, 294, 591, 6985, 257, 413, 45216, 307, 2293, 264, 912, 382, 45216, 51764], "temperature": 0.0, "avg_logprob": -0.34141837226019967, "compression_ratio": 1.6626506024096386, "no_speech_prob": 3.705259587150067e-05}, {"id": 745, "seek": 348424, "start": 3484.72, "end": 3490.3999999999996, "text": " Except with D on the front, but all the same stuff. How many filters do you want? What's the size of your filter?", "tokens": [50388, 16192, 365, 413, 322, 264, 1868, 11, 457, 439, 264, 912, 1507, 13, 1012, 867, 15995, 360, 291, 528, 30, 708, 311, 264, 2744, 295, 428, 6608, 30, 50672], "temperature": 0.0, "avg_logprob": -0.31000717480977374, "compression_ratio": 1.515625, "no_speech_prob": 0.00015597211313433945}, {"id": 746, "seek": 348424, "start": 3491.2, "end": 3496.2, "text": " What's your stride or sub sample as they call it border mode so forth?", "tokens": [50712, 708, 311, 428, 1056, 482, 420, 1422, 6889, 382, 436, 818, 309, 7838, 4391, 370, 5220, 30, 50962], "temperature": 0.0, "avg_logprob": -0.31000717480977374, "compression_ratio": 1.515625, "no_speech_prob": 0.00015597211313433945}, {"id": 747, "seek": 348424, "start": 3498.2, "end": 3505.68, "text": " We have a question if tensor flows the back end shouldn't the batch normalization axis equals negative one", "tokens": [51062, 492, 362, 257, 1168, 498, 40863, 12867, 264, 646, 917, 4659, 380, 264, 15245, 2710, 2144, 10298, 6915, 3671, 472, 51436], "temperature": 0.0, "avg_logprob": -0.31000717480977374, "compression_ratio": 1.515625, "no_speech_prob": 0.00015597211313433945}, {"id": 748, "seek": 351424, "start": 3514.9599999999996, "end": 3516.9599999999996, "text": " And then there was a link to", "tokens": [50400, 400, 550, 456, 390, 257, 2113, 281, 50500], "temperature": 0.0, "avg_logprob": -0.4980284999793684, "compression_ratio": 1.455497382198953, "no_speech_prob": 0.0014549994375556707}, {"id": 749, "seek": 351424, "start": 3518.08, "end": 3524.8199999999997, "text": " GitHub conversation where Francois yeah said that for Theano accesses one yeah, no it should be and in fact", "tokens": [50556, 23331, 3761, 689, 34695, 271, 1338, 848, 300, 337, 440, 3730, 2105, 279, 472, 1338, 11, 572, 309, 820, 312, 293, 294, 1186, 50893], "temperature": 0.0, "avg_logprob": -0.4980284999793684, "compression_ratio": 1.455497382198953, "no_speech_prob": 0.0014549994375556707}, {"id": 750, "seek": 351424, "start": 3525.3599999999997, "end": 3527.9199999999996, "text": " Access minus one is the default", "tokens": [50920, 17166, 3175, 472, 307, 264, 7576, 51048], "temperature": 0.0, "avg_logprob": -0.4980284999793684, "compression_ratio": 1.455497382198953, "no_speech_prob": 0.0014549994375556707}, {"id": 751, "seek": 351424, "start": 3530.8799999999997, "end": 3532.8799999999997, "text": " Yes", "tokens": [51196, 1079, 51296], "temperature": 0.0, "avg_logprob": -0.4980284999793684, "compression_ratio": 1.455497382198953, "no_speech_prob": 0.0014549994375556707}, {"id": 752, "seek": 351424, "start": 3533.3199999999997, "end": 3535.3199999999997, "text": " Well spotted Thank David Gutman", "tokens": [51318, 1042, 21010, 1044, 4389, 24481, 1601, 51418], "temperature": 0.0, "avg_logprob": -0.4980284999793684, "compression_ratio": 1.455497382198953, "no_speech_prob": 0.0014549994375556707}, {"id": 753, "seek": 351424, "start": 3536.3999999999996, "end": 3539.4799999999996, "text": " He is also responsible for some of our beautiful pictures. We saw earlier", "tokens": [51472, 634, 307, 611, 6250, 337, 512, 295, 527, 2238, 5242, 13, 492, 1866, 3071, 51626], "temperature": 0.0, "avg_logprob": -0.4980284999793684, "compression_ratio": 1.455497382198953, "no_speech_prob": 0.0014549994375556707}, {"id": 754, "seek": 353948, "start": 3539.48, "end": 3541.48, "text": " Double thing", "tokens": [50364, 16633, 551, 50464], "temperature": 0.0, "avg_logprob": -0.4238906805066095, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.0009849288035184145}, {"id": 755, "seek": 353948, "start": 3543.28, "end": 3545.28, "text": " Let's remove", "tokens": [50554, 961, 311, 4159, 50654], "temperature": 0.0, "avg_logprob": -0.4238906805066095, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.0009849288035184145}, {"id": 756, "seek": 353948, "start": 3552.36, "end": 3554.36, "text": " And go faster as well", "tokens": [51008, 400, 352, 4663, 382, 731, 51108], "temperature": 0.0, "avg_logprob": -0.4238906805066095, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.0009849288035184145}, {"id": 757, "seek": 353948, "start": 3555.68, "end": 3561.52, "text": " So just in case you weren't clear on that you might remember from part one that we reason we had that axis equals one is", "tokens": [51174, 407, 445, 294, 1389, 291, 4999, 380, 1850, 322, 300, 291, 1062, 1604, 490, 644, 472, 300, 321, 1778, 321, 632, 300, 10298, 6915, 472, 307, 51466], "temperature": 0.0, "avg_logprob": -0.4238906805066095, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.0009849288035184145}, {"id": 758, "seek": 353948, "start": 3561.52, "end": 3568.12, "text": " Because the I know that was the channel axis right so we basically wanted not to throw away the XY information", "tokens": [51466, 1436, 264, 286, 458, 300, 390, 264, 2269, 10298, 558, 370, 321, 1936, 1415, 406, 281, 3507, 1314, 264, 48826, 1589, 51796], "temperature": 0.0, "avg_logprob": -0.4238906805066095, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.0009849288035184145}, {"id": 759, "seek": 356812, "start": 3568.24, "end": 3569.92, "text": " but normal cross channels", "tokens": [50370, 457, 2710, 3278, 9235, 50454], "temperature": 0.0, "avg_logprob": -0.43406647130062703, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.00010720641148509458}, {"id": 760, "seek": 356812, "start": 3569.92, "end": 3577.6, "text": " In Theano and channel is now the last axis and since minus one is the default we actually don't need that", "tokens": [50454, 682, 440, 3730, 293, 2269, 307, 586, 264, 1036, 10298, 293, 1670, 3175, 472, 307, 264, 7576, 321, 767, 500, 380, 643, 300, 50838], "temperature": 0.0, "avg_logprob": -0.43406647130062703, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.00010720641148509458}, {"id": 761, "seek": 356812, "start": 3582.7599999999998, "end": 3587.16, "text": " Okay, so that's our deconvolution blocks, and so we're using a", "tokens": [51096, 1033, 11, 370, 300, 311, 527, 979, 266, 85, 3386, 8474, 11, 293, 370, 321, 434, 1228, 257, 51316], "temperature": 0.0, "avg_logprob": -0.43406647130062703, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.00010720641148509458}, {"id": 762, "seek": 356812, "start": 3590.6, "end": 3595.68, "text": " Stride of two comma two right so that means that each time we go through this deconvolution", "tokens": [51488, 8251, 482, 295, 732, 22117, 732, 558, 370, 300, 1355, 300, 1184, 565, 321, 352, 807, 341, 979, 266, 85, 3386, 51742], "temperature": 0.0, "avg_logprob": -0.43406647130062703, "compression_ratio": 1.5543478260869565, "no_speech_prob": 0.00010720641148509458}, {"id": 763, "seek": 359568, "start": 3595.68, "end": 3597.8199999999997, "text": " It's going to be doubling the size of the image", "tokens": [50364, 467, 311, 516, 281, 312, 33651, 264, 2744, 295, 264, 3256, 50471], "temperature": 0.0, "avg_logprob": -0.287986788256415, "compression_ratio": 1.6981132075471699, "no_speech_prob": 9.314555063610896e-05}, {"id": 764, "seek": 359568, "start": 3598.72, "end": 3606.08, "text": " For some reason I don't fully understand and haven't really looked into in Keras you actually have to tell it the shape of the output", "tokens": [50516, 1171, 512, 1778, 286, 500, 380, 4498, 1223, 293, 2378, 380, 534, 2956, 666, 294, 591, 6985, 291, 767, 362, 281, 980, 309, 264, 3909, 295, 264, 5598, 50884], "temperature": 0.0, "avg_logprob": -0.287986788256415, "compression_ratio": 1.6981132075471699, "no_speech_prob": 9.314555063610896e-05}, {"id": 765, "seek": 359568, "start": 3606.8399999999997, "end": 3612.48, "text": " So you can see here. I've actually you can actually see it's gone from 72 by 72 to 144 by 144", "tokens": [50922, 407, 291, 393, 536, 510, 13, 286, 600, 767, 291, 393, 767, 536, 309, 311, 2780, 490, 18731, 538, 18731, 281, 45218, 538, 45218, 51204], "temperature": 0.0, "avg_logprob": -0.287986788256415, "compression_ratio": 1.6981132075471699, "no_speech_prob": 9.314555063610896e-05}, {"id": 766, "seek": 359568, "start": 3613.16, "end": 3617.7999999999997, "text": " To 288 by 288 right so because these are convolutional filters", "tokens": [51238, 1407, 7562, 23, 538, 7562, 23, 558, 370, 570, 613, 366, 45216, 304, 15995, 51470], "temperature": 0.0, "avg_logprob": -0.287986788256415, "compression_ratio": 1.6981132075471699, "no_speech_prob": 9.314555063610896e-05}, {"id": 767, "seek": 359568, "start": 3617.7999999999997, "end": 3625.44, "text": " It's learning to upscale right, but it's not upscaling with just three channels. It's upscaling with 64 filters", "tokens": [51470, 467, 311, 2539, 281, 493, 20033, 558, 11, 457, 309, 311, 406, 493, 4417, 4270, 365, 445, 1045, 9235, 13, 467, 311, 493, 4417, 4270, 365, 12145, 15995, 51852], "temperature": 0.0, "avg_logprob": -0.287986788256415, "compression_ratio": 1.6981132075471699, "no_speech_prob": 9.314555063610896e-05}, {"id": 768, "seek": 362568, "start": 3625.68, "end": 3628.2, "text": " So that's how kind of say we're to do more sophisticated stuff", "tokens": [50364, 407, 300, 311, 577, 733, 295, 584, 321, 434, 281, 360, 544, 16950, 1507, 50490], "temperature": 0.0, "avg_logprob": -0.33144861338089926, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.683807128458284e-05}, {"id": 769, "seek": 362568, "start": 3630.6, "end": 3632.6, "text": " And then finally", "tokens": [50610, 400, 550, 2721, 50710], "temperature": 0.0, "avg_logprob": -0.33144861338089926, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.683807128458284e-05}, {"id": 770, "seek": 362568, "start": 3632.7999999999997, "end": 3636.8399999999997, "text": " We we're kind of reversing things here. We have another three by", "tokens": [50720, 492, 321, 434, 733, 295, 14582, 278, 721, 510, 13, 492, 362, 1071, 1045, 538, 50922], "temperature": 0.0, "avg_logprob": -0.33144861338089926, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.683807128458284e-05}, {"id": 771, "seek": 362568, "start": 3637.6, "end": 3639.6, "text": " another nine by nine convolution", "tokens": [50960, 1071, 4949, 538, 4949, 45216, 51060], "temperature": 0.0, "avg_logprob": -0.33144861338089926, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.683807128458284e-05}, {"id": 772, "seek": 362568, "start": 3640.08, "end": 3646.48, "text": " In order to get back our three channels so the idea is we previously had something with 64 channels", "tokens": [51084, 682, 1668, 281, 483, 646, 527, 1045, 9235, 370, 264, 1558, 307, 321, 8046, 632, 746, 365, 12145, 9235, 51404], "temperature": 0.0, "avg_logprob": -0.33144861338089926, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.683807128458284e-05}, {"id": 773, "seek": 362568, "start": 3647.2799999999997, "end": 3648.3999999999996, "text": " and", "tokens": [51444, 293, 51500], "temperature": 0.0, "avg_logprob": -0.33144861338089926, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.683807128458284e-05}, {"id": 774, "seek": 362568, "start": 3648.3999999999996, "end": 3653.9199999999996, "text": " So we now want to turn it into something with just three channels the three colors and to do that we want to use quite", "tokens": [51500, 407, 321, 586, 528, 281, 1261, 309, 666, 746, 365, 445, 1045, 9235, 264, 1045, 4577, 293, 281, 360, 300, 321, 528, 281, 764, 1596, 51776], "temperature": 0.0, "avg_logprob": -0.33144861338089926, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.683807128458284e-05}, {"id": 775, "seek": 365392, "start": 3654.08, "end": 3655.2000000000003, "text": " Context", "tokens": [50372, 4839, 3828, 50428], "temperature": 0.0, "avg_logprob": -0.3755059286812756, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0002571378427091986}, {"id": 776, "seek": 365392, "start": 3655.2000000000003, "end": 3659.76, "text": " So we have a 9 by 9 single 9 by 9 filter at the end to get our three channels out", "tokens": [50428, 407, 321, 362, 257, 1722, 538, 1722, 2167, 1722, 538, 1722, 6608, 412, 264, 917, 281, 483, 527, 1045, 9235, 484, 50656], "temperature": 0.0, "avg_logprob": -0.3755059286812756, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0002571378427091986}, {"id": 777, "seek": 365392, "start": 3659.88, "end": 3663.6800000000003, "text": " So at the end we have a 288 by 288 by 3", "tokens": [50662, 407, 412, 264, 917, 321, 362, 257, 7562, 23, 538, 7562, 23, 538, 805, 50852], "temperature": 0.0, "avg_logprob": -0.3755059286812756, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0002571378427091986}, {"id": 778, "seek": 365392, "start": 3664.44, "end": 3666.8, "text": " That's in other words an image", "tokens": [50890, 663, 311, 294, 661, 2283, 364, 3256, 51008], "temperature": 0.0, "avg_logprob": -0.3755059286812756, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0002571378427091986}, {"id": 779, "seek": 365392, "start": 3668.2400000000002, "end": 3670.6800000000003, "text": " So if we go ahead now and train this", "tokens": [51080, 407, 498, 321, 352, 2286, 586, 293, 3847, 341, 51202], "temperature": 0.0, "avg_logprob": -0.3755059286812756, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0002571378427091986}, {"id": 780, "seek": 365392, "start": 3671.32, "end": 3676.26, "text": " Then it's going to do basically what we want, but the thing we're going to have to do is to create our loss function", "tokens": [51234, 1396, 309, 311, 516, 281, 360, 1936, 437, 321, 528, 11, 457, 264, 551, 321, 434, 516, 281, 362, 281, 360, 307, 281, 1884, 527, 4470, 2445, 51481], "temperature": 0.0, "avg_logprob": -0.3755059286812756, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0002571378427091986}, {"id": 781, "seek": 365392, "start": 3676.48, "end": 3677.8, "text": " right and", "tokens": [51492, 558, 293, 51558], "temperature": 0.0, "avg_logprob": -0.3755059286812756, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0002571378427091986}, {"id": 782, "seek": 365392, "start": 3677.8, "end": 3679.8, "text": " creating our loss function", "tokens": [51558, 4084, 527, 4470, 2445, 51658], "temperature": 0.0, "avg_logprob": -0.3755059286812756, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0002571378427091986}, {"id": 783, "seek": 365392, "start": 3680.0, "end": 3682.0, "text": " is", "tokens": [51668, 307, 51768], "temperature": 0.0, "avg_logprob": -0.3755059286812756, "compression_ratio": 1.7019230769230769, "no_speech_prob": 0.0002571378427091986}, {"id": 784, "seek": 368200, "start": 3682.12, "end": 3687.96, "text": " A little bit messy, but I'll take you through it slowly and hopefully it'll all make sense", "tokens": [50370, 316, 707, 857, 16191, 11, 457, 286, 603, 747, 291, 807, 309, 5692, 293, 4696, 309, 603, 439, 652, 2020, 50662], "temperature": 0.0, "avg_logprob": -0.4641399644825557, "compression_ratio": 1.53125, "no_speech_prob": 5.4759268095949665e-05}, {"id": 785, "seek": 368200, "start": 3692.68, "end": 3695.52, "text": " So we've taken just to remember some of the", "tokens": [50898, 407, 321, 600, 2726, 445, 281, 1604, 512, 295, 264, 51040], "temperature": 0.0, "avg_logprob": -0.4641399644825557, "compression_ratio": 1.53125, "no_speech_prob": 5.4759268095949665e-05}, {"id": 786, "seek": 368200, "start": 3696.32, "end": 3700.32, "text": " symbols here input imp is the original", "tokens": [51080, 16944, 510, 4846, 704, 307, 264, 3380, 51280], "temperature": 0.0, "avg_logprob": -0.4641399644825557, "compression_ratio": 1.53125, "no_speech_prob": 5.4759268095949665e-05}, {"id": 787, "seek": 368200, "start": 3700.8, "end": 3703.88, "text": " low resolution input tensor and", "tokens": [51304, 2295, 8669, 4846, 40863, 293, 51458], "temperature": 0.0, "avg_logprob": -0.4641399644825557, "compression_ratio": 1.53125, "no_speech_prob": 5.4759268095949665e-05}, {"id": 788, "seek": 368200, "start": 3704.4, "end": 3711.24, "text": " Then the output of this is called out P output and so let's call this whole network here", "tokens": [51484, 1396, 264, 5598, 295, 341, 307, 1219, 484, 430, 5598, 293, 370, 718, 311, 818, 341, 1379, 3209, 510, 51826], "temperature": 0.0, "avg_logprob": -0.4641399644825557, "compression_ratio": 1.53125, "no_speech_prob": 5.4759268095949665e-05}, {"id": 789, "seek": 371124, "start": 3711.3599999999997, "end": 3717.04, "text": " Let's call it the up sampling network, right so this is the thing that's actually responsible doing the outside", "tokens": [50370, 961, 311, 818, 309, 264, 493, 21179, 3209, 11, 558, 370, 341, 307, 264, 551, 300, 311, 767, 6250, 884, 264, 2380, 50654], "temperature": 0.0, "avg_logprob": -0.36603432140131104, "compression_ratio": 1.7230769230769232, "no_speech_prob": 4.0694125345908105e-05}, {"id": 790, "seek": 371124, "start": 3717.6, "end": 3722.6, "text": " so we're going to take the up sampling network and we're going to attach it to VGG and", "tokens": [50682, 370, 321, 434, 516, 281, 747, 264, 493, 21179, 3209, 293, 321, 434, 516, 281, 5085, 309, 281, 691, 27561, 293, 50932], "temperature": 0.0, "avg_logprob": -0.36603432140131104, "compression_ratio": 1.7230769230769232, "no_speech_prob": 4.0694125345908105e-05}, {"id": 791, "seek": 371124, "start": 3722.7599999999998, "end": 3726.9599999999996, "text": " The VGG is going to be used only as a loss function", "tokens": [50940, 440, 691, 27561, 307, 516, 281, 312, 1143, 787, 382, 257, 4470, 2445, 51150], "temperature": 0.0, "avg_logprob": -0.36603432140131104, "compression_ratio": 1.7230769230769232, "no_speech_prob": 4.0694125345908105e-05}, {"id": 792, "seek": 371124, "start": 3727.68, "end": 3729.68, "text": " Right to get the content loss", "tokens": [51186, 1779, 281, 483, 264, 2701, 4470, 51286], "temperature": 0.0, "avg_logprob": -0.36603432140131104, "compression_ratio": 1.7230769230769232, "no_speech_prob": 4.0694125345908105e-05}, {"id": 793, "seek": 371124, "start": 3730.9199999999996, "end": 3735.64, "text": " So before we can take this output and stick it into VGG", "tokens": [51348, 407, 949, 321, 393, 747, 341, 5598, 293, 2897, 309, 666, 691, 27561, 51584], "temperature": 0.0, "avg_logprob": -0.36603432140131104, "compression_ratio": 1.7230769230769232, "no_speech_prob": 4.0694125345908105e-05}, {"id": 794, "seek": 373564, "start": 3735.8399999999997, "end": 3739.72, "text": " We need to stick it through our standard mean subtraction pre-processing", "tokens": [50374, 492, 643, 281, 2897, 309, 807, 527, 3832, 914, 16390, 313, 659, 12, 41075, 278, 50568], "temperature": 0.0, "avg_logprob": -0.31158686232292787, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0013670054031535983}, {"id": 795, "seek": 373564, "start": 3739.8399999999997, "end": 3743.44, "text": " So this is just the same thing that we did over and over again in part one", "tokens": [50574, 407, 341, 307, 445, 264, 912, 551, 300, 321, 630, 670, 293, 670, 797, 294, 644, 472, 50754], "temperature": 0.0, "avg_logprob": -0.31158686232292787, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0013670054031535983}, {"id": 796, "seek": 373564, "start": 3745.04, "end": 3747.04, "text": " So let's now define and", "tokens": [50834, 407, 718, 311, 586, 6964, 293, 50934], "temperature": 0.0, "avg_logprob": -0.31158686232292787, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0013670054031535983}, {"id": 797, "seek": 373564, "start": 3749.0, "end": 3755.8799999999997, "text": " This output as being this lambda function applied to the output of our up sampling", "tokens": [51032, 639, 5598, 382, 885, 341, 13607, 2445, 6456, 281, 264, 5598, 295, 527, 493, 21179, 51376], "temperature": 0.0, "avg_logprob": -0.31158686232292787, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0013670054031535983}, {"id": 798, "seek": 373564, "start": 3756.7999999999997, "end": 3761.2, "text": " Network okay, so that's what this is this is just our pre-processed", "tokens": [51422, 12640, 1392, 11, 370, 300, 311, 437, 341, 307, 341, 307, 445, 527, 659, 12, 41075, 292, 51642], "temperature": 0.0, "avg_logprob": -0.31158686232292787, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0013670054031535983}, {"id": 799, "seek": 373564, "start": 3761.72, "end": 3763.72, "text": " up sampling network output", "tokens": [51668, 493, 21179, 3209, 5598, 51768], "temperature": 0.0, "avg_logprob": -0.31158686232292787, "compression_ratio": 1.7107843137254901, "no_speech_prob": 0.0013670054031535983}, {"id": 800, "seek": 376564, "start": 3766.24, "end": 3770.52, "text": " So we can now create a VGG network", "tokens": [50394, 407, 321, 393, 586, 1884, 257, 691, 27561, 3209, 50608], "temperature": 0.0, "avg_logprob": -0.46234271400853205, "compression_ratio": 1.6306818181818181, "no_speech_prob": 8.614619582658634e-05}, {"id": 801, "seek": 376564, "start": 3772.72, "end": 3776.04, "text": " And let's go through every layer and make it not trainable", "tokens": [50718, 400, 718, 311, 352, 807, 633, 4583, 293, 652, 309, 406, 3847, 712, 50884], "temperature": 0.0, "avg_logprob": -0.46234271400853205, "compression_ratio": 1.6306818181818181, "no_speech_prob": 8.614619582658634e-05}, {"id": 802, "seek": 376564, "start": 3776.3599999999997, "end": 3781.0, "text": " Right like you can't ever make your loss function be trainable", "tokens": [50900, 1779, 411, 291, 393, 380, 1562, 652, 428, 4470, 2445, 312, 3847, 712, 51132], "temperature": 0.0, "avg_logprob": -0.46234271400853205, "compression_ratio": 1.6306818181818181, "no_speech_prob": 8.614619582658634e-05}, {"id": 803, "seek": 376564, "start": 3781.08, "end": 3787.56, "text": " The loss function is the fixed in stone thing that tells you how well you do so clearly you have to make sure VGG is", "tokens": [51136, 440, 4470, 2445, 307, 264, 6806, 294, 7581, 551, 300, 5112, 291, 577, 731, 291, 360, 370, 4448, 291, 362, 281, 652, 988, 691, 27561, 307, 51460], "temperature": 0.0, "avg_logprob": -0.46234271400853205, "compression_ratio": 1.6306818181818181, "no_speech_prob": 8.614619582658634e-05}, {"id": 804, "seek": 376564, "start": 3787.56, "end": 3789.56, "text": " not trainable", "tokens": [51460, 406, 3847, 712, 51560], "temperature": 0.0, "avg_logprob": -0.46234271400853205, "compression_ratio": 1.6306818181818181, "no_speech_prob": 8.614619582658634e-05}, {"id": 805, "seek": 378956, "start": 3790.0, "end": 3796.92, "text": " Right now which bit of the VGG network do we want we can try a few things I'm using block to come to", "tokens": [50386, 1779, 586, 597, 857, 295, 264, 691, 27561, 3209, 360, 321, 528, 321, 393, 853, 257, 1326, 721, 286, 478, 1228, 3461, 281, 808, 281, 50732], "temperature": 0.0, "avg_logprob": -0.3204004970597632, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.00015117996372282505}, {"id": 806, "seek": 378956, "start": 3797.52, "end": 3804.58, "text": " Okay, so relatively early and the reason for that is that if you remember when we did the content reconstruction", "tokens": [50762, 1033, 11, 370, 7226, 2440, 293, 264, 1778, 337, 300, 307, 300, 498, 291, 1604, 562, 321, 630, 264, 2701, 31565, 51115], "temperature": 0.0, "avg_logprob": -0.3204004970597632, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.00015117996372282505}, {"id": 807, "seek": 378956, "start": 3805.08, "end": 3810.72, "text": " Last week the very first thing we did we found that if you could basically totally reconstruct the original image", "tokens": [51140, 5264, 1243, 264, 588, 700, 551, 321, 630, 321, 1352, 300, 498, 291, 727, 1936, 3879, 31499, 264, 3380, 3256, 51422], "temperature": 0.0, "avg_logprob": -0.3204004970597632, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.00015117996372282505}, {"id": 808, "seek": 378956, "start": 3811.24, "end": 3813.44, "text": " from early layer activations", "tokens": [51448, 490, 2440, 4583, 2430, 763, 51558], "temperature": 0.0, "avg_logprob": -0.3204004970597632, "compression_ratio": 1.6181818181818182, "no_speech_prob": 0.00015117996372282505}, {"id": 809, "seek": 381344, "start": 3813.96, "end": 3815.96, "text": " Whereas by the time we got to layer 4", "tokens": [50390, 13813, 538, 264, 565, 321, 658, 281, 4583, 1017, 50490], "temperature": 0.0, "avg_logprob": -0.35267678226333066, "compression_ratio": 1.5816326530612246, "no_speech_prob": 0.0033765514381229877}, {"id": 810, "seek": 381344, "start": 3816.44, "end": 3822.52, "text": " So block 4 we've got pretty horrendous things right so we're going to use a somewhat early", "tokens": [50514, 407, 3461, 1017, 321, 600, 658, 1238, 49520, 563, 721, 558, 370, 321, 434, 516, 281, 764, 257, 8344, 2440, 50818], "temperature": 0.0, "avg_logprob": -0.35267678226333066, "compression_ratio": 1.5816326530612246, "no_speech_prob": 0.0033765514381229877}, {"id": 811, "seek": 381344, "start": 3823.76, "end": 3825.76, "text": " block as our", "tokens": [50880, 3461, 382, 527, 50980], "temperature": 0.0, "avg_logprob": -0.35267678226333066, "compression_ratio": 1.5816326530612246, "no_speech_prob": 0.0033765514381229877}, {"id": 812, "seek": 381344, "start": 3826.08, "end": 3832.52, "text": " Content loss or as the paper calls it the perceptual loss and you can play around with this see how it goes", "tokens": [50996, 30078, 4470, 420, 382, 264, 3035, 5498, 309, 264, 43276, 901, 4470, 293, 291, 393, 862, 926, 365, 341, 536, 577, 309, 1709, 51318], "temperature": 0.0, "avg_logprob": -0.35267678226333066, "compression_ratio": 1.5816326530612246, "no_speech_prob": 0.0033765514381229877}, {"id": 813, "seek": 381344, "start": 3835.36, "end": 3837.7200000000003, "text": " All right, so now we're going to create", "tokens": [51460, 1057, 558, 11, 370, 586, 321, 434, 516, 281, 1884, 51578], "temperature": 0.0, "avg_logprob": -0.35267678226333066, "compression_ratio": 1.5816326530612246, "no_speech_prob": 0.0033765514381229877}, {"id": 814, "seek": 381344, "start": 3839.08, "end": 3841.08, "text": " two versions of this", "tokens": [51646, 732, 9606, 295, 341, 51746], "temperature": 0.0, "avg_logprob": -0.35267678226333066, "compression_ratio": 1.5816326530612246, "no_speech_prob": 0.0033765514381229877}, {"id": 815, "seek": 384108, "start": 3841.88, "end": 3846.16, "text": " VGG output and this is something which is I think very", "tokens": [50404, 691, 27561, 5598, 293, 341, 307, 746, 597, 307, 286, 519, 588, 50618], "temperature": 0.0, "avg_logprob": -0.3885129591997932, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00020027300342917442}, {"id": 816, "seek": 384108, "start": 3846.7999999999997, "end": 3849.2, "text": " poorly understood or appreciated with the", "tokens": [50650, 22271, 7320, 420, 17169, 365, 264, 50770], "temperature": 0.0, "avg_logprob": -0.3885129591997932, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00020027300342917442}, {"id": 817, "seek": 384108, "start": 3849.7999999999997, "end": 3851.48, "text": " Keras is functional API", "tokens": [50800, 591, 6985, 307, 11745, 9362, 50884], "temperature": 0.0, "avg_logprob": -0.3885129591997932, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00020027300342917442}, {"id": 818, "seek": 384108, "start": 3851.48, "end": 3858.7999999999997, "text": " Which is any kind of layer and the model is a layer as far as Keras is concerned can be treated as if it was a function", "tokens": [50884, 3013, 307, 604, 733, 295, 4583, 293, 264, 2316, 307, 257, 4583, 382, 1400, 382, 591, 6985, 307, 5922, 393, 312, 8668, 382, 498, 309, 390, 257, 2445, 51250], "temperature": 0.0, "avg_logprob": -0.3885129591997932, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00020027300342917442}, {"id": 819, "seek": 384108, "start": 3860.08, "end": 3863.7999999999997, "text": " right so we can take this model and pretend it's a function and", "tokens": [51314, 558, 370, 321, 393, 747, 341, 2316, 293, 11865, 309, 311, 257, 2445, 293, 51500], "temperature": 0.0, "avg_logprob": -0.3885129591997932, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00020027300342917442}, {"id": 820, "seek": 384108, "start": 3864.3199999999997, "end": 3866.84, "text": " We can pass it any tensor", "tokens": [51526, 492, 393, 1320, 309, 604, 40863, 51652], "temperature": 0.0, "avg_logprob": -0.3885129591997932, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00020027300342917442}, {"id": 821, "seek": 386684, "start": 3867.56, "end": 3874.84, "text": " And what that does is it creates a new model where those two pieces are joined together, right so", "tokens": [50400, 400, 437, 300, 775, 307, 309, 7829, 257, 777, 2316, 689, 729, 732, 3755, 366, 6869, 1214, 11, 558, 370, 50764], "temperature": 0.0, "avg_logprob": -0.4579881562127007, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.01691475696861744}, {"id": 822, "seek": 386684, "start": 3876.0, "end": 3878.0, "text": " VGG 2 is", "tokens": [50822, 691, 27561, 568, 307, 50922], "temperature": 0.0, "avg_logprob": -0.4579881562127007, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.01691475696861744}, {"id": 823, "seek": 386684, "start": 3878.0, "end": 3880.0, "text": " now equal to", "tokens": [50922, 586, 2681, 281, 51022], "temperature": 0.0, "avg_logprob": -0.4579881562127007, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.01691475696861744}, {"id": 824, "seek": 386684, "start": 3880.0, "end": 3883.04, "text": " this model on the top and", "tokens": [51022, 341, 2316, 322, 264, 1192, 293, 51174], "temperature": 0.0, "avg_logprob": -0.4579881562127007, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.01691475696861744}, {"id": 825, "seek": 386684, "start": 3884.44, "end": 3889.32, "text": " this model on the bottom and remember this model was the result of our", "tokens": [51244, 341, 2316, 322, 264, 2767, 293, 1604, 341, 2316, 390, 264, 1874, 295, 527, 51488], "temperature": 0.0, "avg_logprob": -0.4579881562127007, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.01691475696861744}, {"id": 826, "seek": 386684, "start": 3890.6000000000004, "end": 3893.6400000000003, "text": " upsampling network followed by pre-processing and", "tokens": [51552, 15497, 335, 11970, 3209, 6263, 538, 659, 12, 41075, 278, 293, 51704], "temperature": 0.0, "avg_logprob": -0.4579881562127007, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.01691475696861744}, {"id": 827, "seek": 389364, "start": 3893.96, "end": 3900.2599999999998, "text": " In the upsampling network is the lambda function to normalize the output image", "tokens": [50380, 682, 264, 15497, 335, 11970, 3209, 307, 264, 13607, 2445, 281, 2710, 1125, 264, 5598, 3256, 50695], "temperature": 0.0, "avg_logprob": -0.34587888820196994, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.649671220453456e-05}, {"id": 828, "seek": 389364, "start": 3900.64, "end": 3907.92, "text": " Yeah, that's a good point so we use a fan activation which can go from negative 1 to 1", "tokens": [50714, 865, 11, 300, 311, 257, 665, 935, 370, 321, 764, 257, 3429, 24433, 597, 393, 352, 490, 3671, 502, 281, 502, 51078], "temperature": 0.0, "avg_logprob": -0.34587888820196994, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.649671220453456e-05}, {"id": 829, "seek": 389364, "start": 3909.04, "end": 3914.72, "text": " So if you then go that plus 1 times 127 and a half that gives you something that's between 0 and 255", "tokens": [51134, 407, 498, 291, 550, 352, 300, 1804, 502, 1413, 47561, 293, 257, 1922, 300, 2709, 291, 746, 300, 311, 1296, 1958, 293, 3552, 20, 51418], "temperature": 0.0, "avg_logprob": -0.34587888820196994, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.649671220453456e-05}, {"id": 830, "seek": 389364, "start": 3915.24, "end": 3917.24, "text": " Which is the range that we want?", "tokens": [51444, 3013, 307, 264, 3613, 300, 321, 528, 30, 51544], "temperature": 0.0, "avg_logprob": -0.34587888820196994, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.649671220453456e-05}, {"id": 831, "seek": 389364, "start": 3918.04, "end": 3922.2, "text": " Interestingly this was suggested in the original paper and supplementary materials", "tokens": [51584, 30564, 341, 390, 10945, 294, 264, 3380, 3035, 293, 15436, 822, 5319, 51792], "temperature": 0.0, "avg_logprob": -0.34587888820196994, "compression_ratio": 1.5528455284552845, "no_speech_prob": 5.649671220453456e-05}, {"id": 832, "seek": 392220, "start": 3922.6, "end": 3925.0, "text": " More recently in on reddit", "tokens": [50384, 5048, 3938, 294, 322, 2182, 17975, 50504], "temperature": 0.0, "avg_logprob": -0.34825221790986904, "compression_ratio": 1.7412935323383085, "no_speech_prob": 9.461075387662277e-05}, {"id": 833, "seek": 392220, "start": 3925.0, "end": 3931.8399999999997, "text": " I think it was the author said that they tried it without the fan activation and therefore without the final", "tokens": [50504, 286, 519, 309, 390, 264, 3793, 848, 300, 436, 3031, 309, 1553, 264, 3429, 24433, 293, 4412, 1553, 264, 2572, 50846], "temperature": 0.0, "avg_logprob": -0.34825221790986904, "compression_ratio": 1.7412935323383085, "no_speech_prob": 9.461075387662277e-05}, {"id": 834, "seek": 392220, "start": 3933.72, "end": 3937.04, "text": " Deprocessing and it worked just as well, so you can try", "tokens": [50940, 4056, 340, 780, 278, 293, 309, 2732, 445, 382, 731, 11, 370, 291, 393, 853, 51106], "temperature": 0.0, "avg_logprob": -0.34825221790986904, "compression_ratio": 1.7412935323383085, "no_speech_prob": 9.461075387662277e-05}, {"id": 835, "seek": 392220, "start": 3937.68, "end": 3944.2, "text": " Doing that if you wanted to try it you would just remove the activation, and you would just remove this last thing entirely", "tokens": [51138, 18496, 300, 498, 291, 1415, 281, 853, 309, 291, 576, 445, 4159, 264, 24433, 11, 293, 291, 576, 445, 4159, 341, 1036, 551, 7696, 51464], "temperature": 0.0, "avg_logprob": -0.34825221790986904, "compression_ratio": 1.7412935323383085, "no_speech_prob": 9.461075387662277e-05}, {"id": 836, "seek": 392220, "start": 3945.7599999999998, "end": 3947.7599999999998, "text": " But obviously if you do have a fan", "tokens": [51542, 583, 2745, 498, 291, 360, 362, 257, 3429, 51642], "temperature": 0.0, "avg_logprob": -0.34825221790986904, "compression_ratio": 1.7412935323383085, "no_speech_prob": 9.461075387662277e-05}, {"id": 837, "seek": 394776, "start": 3948.0800000000004, "end": 3953.5600000000004, "text": " Then you need the output and this is actually something I've been playing with with a lot of different", "tokens": [50380, 1396, 291, 643, 264, 5598, 293, 341, 307, 767, 746, 286, 600, 668, 2433, 365, 365, 257, 688, 295, 819, 50654], "temperature": 0.0, "avg_logprob": -0.3194977406705363, "compression_ratio": 1.5646551724137931, "no_speech_prob": 9.314542694482952e-05}, {"id": 838, "seek": 394776, "start": 3954.28, "end": 3958.0400000000004, "text": " Models any time I have some particular range that I want", "tokens": [50690, 6583, 1625, 604, 565, 286, 362, 512, 1729, 3613, 300, 286, 528, 50878], "temperature": 0.0, "avg_logprob": -0.3194977406705363, "compression_ratio": 1.5646551724137931, "no_speech_prob": 9.314542694482952e-05}, {"id": 839, "seek": 394776, "start": 3958.6400000000003, "end": 3961.2400000000002, "text": " when where to enforce that is by having a", "tokens": [50908, 562, 689, 281, 24825, 300, 307, 538, 1419, 257, 51038], "temperature": 0.0, "avg_logprob": -0.3194977406705363, "compression_ratio": 1.5646551724137931, "no_speech_prob": 9.314542694482952e-05}, {"id": 840, "seek": 394776, "start": 3961.6400000000003, "end": 3967.6400000000003, "text": " Fan or sigmoid followed by something that turns that into the range you want it's not just the images", "tokens": [51058, 18564, 420, 4556, 3280, 327, 6263, 538, 746, 300, 4523, 300, 666, 264, 3613, 291, 528, 309, 311, 406, 445, 264, 5267, 51358], "temperature": 0.0, "avg_logprob": -0.3194977406705363, "compression_ratio": 1.5646551724137931, "no_speech_prob": 9.314542694482952e-05}, {"id": 841, "seek": 394776, "start": 3971.6000000000004, "end": 3977.48, "text": " Okay, so we've got two versions of our BGG layer output one", "tokens": [51556, 1033, 11, 370, 321, 600, 658, 732, 9606, 295, 527, 363, 27561, 4583, 5598, 472, 51850], "temperature": 0.0, "avg_logprob": -0.3194977406705363, "compression_ratio": 1.5646551724137931, "no_speech_prob": 9.314542694482952e-05}, {"id": 842, "seek": 397776, "start": 3977.84, "end": 3981.88, "text": " which is based on the output of the upscaling network and", "tokens": [50368, 597, 307, 2361, 322, 264, 5598, 295, 264, 493, 4417, 4270, 3209, 293, 50570], "temperature": 0.0, "avg_logprob": -0.34123197415979895, "compression_ratio": 1.971264367816092, "no_speech_prob": 8.664591405249666e-06}, {"id": 843, "seek": 397776, "start": 3982.4, "end": 3984.44, "text": " the other which is based on", "tokens": [50596, 264, 661, 597, 307, 2361, 322, 50698], "temperature": 0.0, "avg_logprob": -0.34123197415979895, "compression_ratio": 1.971264367816092, "no_speech_prob": 8.664591405249666e-06}, {"id": 844, "seek": 397776, "start": 3985.84, "end": 3993.32, "text": " Just an input right and this just an input is using the high resolution shape as its input", "tokens": [50768, 1449, 364, 4846, 558, 293, 341, 445, 364, 4846, 307, 1228, 264, 1090, 8669, 3909, 382, 1080, 4846, 51142], "temperature": 0.0, "avg_logprob": -0.34123197415979895, "compression_ratio": 1.971264367816092, "no_speech_prob": 8.664591405249666e-06}, {"id": 845, "seek": 397776, "start": 3993.92, "end": 3997.94, "text": " Right so that makes sense because this BGG network", "tokens": [51172, 1779, 370, 300, 1669, 2020, 570, 341, 363, 27561, 3209, 51373], "temperature": 0.0, "avg_logprob": -0.34123197415979895, "compression_ratio": 1.971264367816092, "no_speech_prob": 8.664591405249666e-06}, {"id": 846, "seek": 397776, "start": 3999.0800000000004, "end": 4005.1800000000003, "text": " Is something that we're going to be using at the high resolution scale we're going to be taking the high resolution", "tokens": [51430, 1119, 746, 300, 321, 434, 516, 281, 312, 1228, 412, 264, 1090, 8669, 4373, 321, 434, 516, 281, 312, 1940, 264, 1090, 8669, 51735], "temperature": 0.0, "avg_logprob": -0.34123197415979895, "compression_ratio": 1.971264367816092, "no_speech_prob": 8.664591405249666e-06}, {"id": 847, "seek": 400518, "start": 4005.8199999999997, "end": 4011.2599999999998, "text": " Target image and the high resolution up sampling result and comparing them, okay?", "tokens": [50396, 24586, 3256, 293, 264, 1090, 8669, 493, 21179, 1874, 293, 15763, 552, 11, 1392, 30, 50668], "temperature": 0.0, "avg_logprob": -0.33945189083323757, "compression_ratio": 1.6804123711340206, "no_speech_prob": 1.5446228644577786e-05}, {"id": 848, "seek": 400518, "start": 4012.62, "end": 4016.5, "text": " So now that we've done all that we're nearly there. We've now got", "tokens": [50736, 407, 586, 300, 321, 600, 1096, 439, 300, 321, 434, 6217, 456, 13, 492, 600, 586, 658, 50930], "temperature": 0.0, "avg_logprob": -0.33945189083323757, "compression_ratio": 1.6804123711340206, "no_speech_prob": 1.5446228644577786e-05}, {"id": 849, "seek": 400518, "start": 4017.3399999999997, "end": 4019.3399999999997, "text": " the high res", "tokens": [50972, 264, 1090, 725, 51072], "temperature": 0.0, "avg_logprob": -0.33945189083323757, "compression_ratio": 1.6804123711340206, "no_speech_prob": 1.5446228644577786e-05}, {"id": 850, "seek": 400518, "start": 4020.7799999999997, "end": 4026.98, "text": " Perceptual activations, and we've got the low res up sampled perceptual activations", "tokens": [51144, 3026, 1336, 901, 2430, 763, 11, 293, 321, 600, 658, 264, 2295, 725, 493, 3247, 15551, 43276, 901, 2430, 763, 51454], "temperature": 0.0, "avg_logprob": -0.33945189083323757, "compression_ratio": 1.6804123711340206, "no_speech_prob": 1.5446228644577786e-05}, {"id": 851, "seek": 400518, "start": 4027.06, "end": 4032.3199999999997, "text": " We now just need to take the mean sum of squares between them and here it is here", "tokens": [51458, 492, 586, 445, 643, 281, 747, 264, 914, 2408, 295, 19368, 1296, 552, 293, 510, 309, 307, 510, 51721], "temperature": 0.0, "avg_logprob": -0.33945189083323757, "compression_ratio": 1.6804123711340206, "no_speech_prob": 1.5446228644577786e-05}, {"id": 852, "seek": 403232, "start": 4032.96, "end": 4034.48, "text": " In", "tokens": [50396, 682, 50472], "temperature": 0.0, "avg_logprob": -0.3914214932188696, "compression_ratio": 1.7259615384615385, "no_speech_prob": 4.7576133511029184e-05}, {"id": 853, "seek": 403232, "start": 4034.48, "end": 4038.7200000000003, "text": " Keras anytime you put something into a network it has to be a layer", "tokens": [50472, 591, 6985, 13038, 291, 829, 746, 666, 257, 3209, 309, 575, 281, 312, 257, 4583, 50684], "temperature": 0.0, "avg_logprob": -0.3914214932188696, "compression_ratio": 1.7259615384615385, "no_speech_prob": 4.7576133511029184e-05}, {"id": 854, "seek": 403232, "start": 4039.4, "end": 4043.1200000000003, "text": " So if you want to take it just a plain old function and turn it into a layer", "tokens": [50718, 407, 498, 291, 528, 281, 747, 309, 445, 257, 11121, 1331, 2445, 293, 1261, 309, 666, 257, 4583, 50904], "temperature": 0.0, "avg_logprob": -0.3914214932188696, "compression_ratio": 1.7259615384615385, "no_speech_prob": 4.7576133511029184e-05}, {"id": 855, "seek": 403232, "start": 4043.28, "end": 4046.7200000000003, "text": " You just chuck it inside a lambda a capital L lambda", "tokens": [50912, 509, 445, 20870, 309, 1854, 257, 13607, 257, 4238, 441, 13607, 51084], "temperature": 0.0, "avg_logprob": -0.3914214932188696, "compression_ratio": 1.7259615384615385, "no_speech_prob": 4.7576133511029184e-05}, {"id": 856, "seek": 403232, "start": 4047.32, "end": 4049.28, "text": " So that's all that's for", "tokens": [51114, 407, 300, 311, 439, 300, 311, 337, 51212], "temperature": 0.0, "avg_logprob": -0.3914214932188696, "compression_ratio": 1.7259615384615385, "no_speech_prob": 4.7576133511029184e-05}, {"id": 857, "seek": 403232, "start": 4049.28, "end": 4053.92, "text": " so our final model is going to take our up sampled input and", "tokens": [51212, 370, 527, 2572, 2316, 307, 516, 281, 747, 527, 493, 3247, 15551, 4846, 293, 51444], "temperature": 0.0, "avg_logprob": -0.3914214932188696, "compression_ratio": 1.7259615384615385, "no_speech_prob": 4.7576133511029184e-05}, {"id": 858, "seek": 403232, "start": 4054.6800000000003, "end": 4060.1600000000003, "text": " our sorry our low res input and our high res input as our two inputs and", "tokens": [51482, 527, 2597, 527, 2295, 725, 4846, 293, 527, 1090, 725, 4846, 382, 527, 732, 15743, 293, 51756], "temperature": 0.0, "avg_logprob": -0.3914214932188696, "compression_ratio": 1.7259615384615385, "no_speech_prob": 4.7576133511029184e-05}, {"id": 859, "seek": 406016, "start": 4060.3999999999996, "end": 4062.72, "text": " Return this loss functions and output", "tokens": [50376, 24350, 341, 4470, 6828, 293, 5598, 50492], "temperature": 0.0, "avg_logprob": -0.3311593306692023, "compression_ratio": 1.7168949771689497, "no_speech_prob": 2.5867315343930386e-05}, {"id": 860, "seek": 406016, "start": 4064.7599999999998, "end": 4066.7599999999998, "text": " Okay one last trick", "tokens": [50594, 1033, 472, 1036, 4282, 50694], "temperature": 0.0, "avg_logprob": -0.3311593306692023, "compression_ratio": 1.7168949771689497, "no_speech_prob": 2.5867315343930386e-05}, {"id": 861, "seek": 406016, "start": 4067.24, "end": 4075.6, "text": " When you fit things in Keras it assumes that you're trying to take some output and make it close to some target", "tokens": [50718, 1133, 291, 3318, 721, 294, 591, 6985, 309, 37808, 300, 291, 434, 1382, 281, 747, 512, 5598, 293, 652, 309, 1998, 281, 512, 3779, 51136], "temperature": 0.0, "avg_logprob": -0.3311593306692023, "compression_ratio": 1.7168949771689497, "no_speech_prob": 2.5867315343930386e-05}, {"id": 862, "seek": 406016, "start": 4076.48, "end": 4082.64, "text": " In this case our loss is the actual loss function. We want it's not that there's some target, right?", "tokens": [51180, 682, 341, 1389, 527, 4470, 307, 264, 3539, 4470, 2445, 13, 492, 528, 309, 311, 406, 300, 456, 311, 512, 3779, 11, 558, 30, 51488], "temperature": 0.0, "avg_logprob": -0.3311593306692023, "compression_ratio": 1.7168949771689497, "no_speech_prob": 2.5867315343930386e-05}, {"id": 863, "seek": 406016, "start": 4082.64, "end": 4084.64, "text": " We want to make it as low as possible", "tokens": [51488, 492, 528, 281, 652, 309, 382, 2295, 382, 1944, 51588], "temperature": 0.0, "avg_logprob": -0.3311593306692023, "compression_ratio": 1.7168949771689497, "no_speech_prob": 2.5867315343930386e-05}, {"id": 864, "seek": 406016, "start": 4085.04, "end": 4087.04, "text": " Since it's the sum of squared errors", "tokens": [51608, 4162, 309, 311, 264, 2408, 295, 8889, 13603, 51708], "temperature": 0.0, "avg_logprob": -0.3311593306692023, "compression_ratio": 1.7168949771689497, "no_speech_prob": 2.5867315343930386e-05}, {"id": 865, "seek": 406016, "start": 4087.8399999999997, "end": 4089.8399999999997, "text": " Or mean squared error actually", "tokens": [51748, 1610, 914, 8889, 6713, 767, 51848], "temperature": 0.0, "avg_logprob": -0.3311593306692023, "compression_ratio": 1.7168949771689497, "no_speech_prob": 2.5867315343930386e-05}, {"id": 866, "seek": 409016, "start": 4090.16, "end": 4092.16, "text": " It can't go beneath zero", "tokens": [50364, 467, 393, 380, 352, 17149, 4018, 50464], "temperature": 0.0, "avg_logprob": -0.3270188447470977, "compression_ratio": 1.6835443037974684, "no_speech_prob": 6.605157977901399e-05}, {"id": 867, "seek": 409016, "start": 4092.52, "end": 4099.0, "text": " So what we can do is we can basically check Keras and say that our target for the loss is zero", "tokens": [50482, 407, 437, 321, 393, 360, 307, 321, 393, 1936, 1520, 591, 6985, 293, 584, 300, 527, 3779, 337, 264, 4470, 307, 4018, 50806], "temperature": 0.0, "avg_logprob": -0.3270188447470977, "compression_ratio": 1.6835443037974684, "no_speech_prob": 6.605157977901399e-05}, {"id": 868, "seek": 409016, "start": 4099.0, "end": 4105.48, "text": " And you can't just use the scalar zero remember every time we have a target set of labels in Keras", "tokens": [50806, 400, 291, 393, 380, 445, 764, 264, 39684, 4018, 1604, 633, 565, 321, 362, 257, 3779, 992, 295, 16949, 294, 591, 6985, 51130], "temperature": 0.0, "avg_logprob": -0.3270188447470977, "compression_ratio": 1.6835443037974684, "no_speech_prob": 6.605157977901399e-05}, {"id": 869, "seek": 409016, "start": 4105.48, "end": 4110.76, "text": " You need one for every row right and you've won for every input so we're going to create an array of", "tokens": [51130, 509, 643, 472, 337, 633, 5386, 558, 293, 291, 600, 1582, 337, 633, 4846, 370, 321, 434, 516, 281, 1884, 364, 10225, 295, 51394], "temperature": 0.0, "avg_logprob": -0.3270188447470977, "compression_ratio": 1.6835443037974684, "no_speech_prob": 6.605157977901399e-05}, {"id": 870, "seek": 409016, "start": 4111.4, "end": 4112.92, "text": " zeros", "tokens": [51426, 35193, 51502], "temperature": 0.0, "avg_logprob": -0.3270188447470977, "compression_ratio": 1.6835443037974684, "no_speech_prob": 6.605157977901399e-05}, {"id": 871, "seek": 409016, "start": 4112.92, "end": 4118.0, "text": " Okay, so that's that's just so that we can fit it into what Keras expects", "tokens": [51502, 1033, 11, 370, 300, 311, 300, 311, 445, 370, 300, 321, 393, 3318, 309, 666, 437, 591, 6985, 33280, 51756], "temperature": 0.0, "avg_logprob": -0.3270188447470977, "compression_ratio": 1.6835443037974684, "no_speech_prob": 6.605157977901399e-05}, {"id": 872, "seek": 411800, "start": 4118.0, "end": 4122.68, "text": " and I kind of find that increasingly as I start to move away from the", "tokens": [50364, 293, 286, 733, 295, 915, 300, 12980, 382, 286, 722, 281, 1286, 1314, 490, 264, 50598], "temperature": 0.0, "avg_logprob": -0.3176603754726025, "compression_ratio": 1.682170542635659, "no_speech_prob": 5.0644364819163457e-05}, {"id": 873, "seek": 411800, "start": 4123.52, "end": 4125.52, "text": " kind of", "tokens": [50640, 733, 295, 50740], "temperature": 0.0, "avg_logprob": -0.3176603754726025, "compression_ratio": 1.682170542635659, "no_speech_prob": 5.0644364819163457e-05}, {"id": 874, "seek": 411800, "start": 4125.96, "end": 4131.28, "text": " You know the well-trodden path of deep learning more and more you know particularly if you want to use Keras", "tokens": [50762, 509, 458, 264, 731, 12, 83, 11452, 1556, 3100, 295, 2452, 2539, 544, 293, 544, 291, 458, 4098, 498, 291, 528, 281, 764, 591, 6985, 51028], "temperature": 0.0, "avg_logprob": -0.3176603754726025, "compression_ratio": 1.682170542635659, "no_speech_prob": 5.0644364819163457e-05}, {"id": 875, "seek": 411800, "start": 4131.68, "end": 4137.36, "text": " You kind of have to do weird little hacks like this so so be it is a weird little thing", "tokens": [51048, 509, 733, 295, 362, 281, 360, 3657, 707, 33617, 411, 341, 370, 370, 312, 309, 307, 257, 3657, 707, 551, 51332], "temperature": 0.0, "avg_logprob": -0.3176603754726025, "compression_ratio": 1.682170542635659, "no_speech_prob": 5.0644364819163457e-05}, {"id": 876, "seek": 411800, "start": 4138.28, "end": 4141.36, "text": " There's probably more elegant ways of doing this, but this works", "tokens": [51378, 821, 311, 1391, 544, 21117, 2098, 295, 884, 341, 11, 457, 341, 1985, 51532], "temperature": 0.0, "avg_logprob": -0.3176603754726025, "compression_ratio": 1.682170542635659, "no_speech_prob": 5.0644364819163457e-05}, {"id": 877, "seek": 411800, "start": 4141.72, "end": 4147.8, "text": " So we've got our loss function that we're trying to get every row as close to zero as possible", "tokens": [51550, 407, 321, 600, 658, 527, 4470, 2445, 300, 321, 434, 1382, 281, 483, 633, 5386, 382, 1998, 281, 4018, 382, 1944, 51854], "temperature": 0.0, "avg_logprob": -0.3176603754726025, "compression_ratio": 1.682170542635659, "no_speech_prob": 5.0644364819163457e-05}, {"id": 878, "seek": 414800, "start": 4148.76, "end": 4155.96, "text": " We have a question if we're only using up to block to conv to could we pop off all the layers afterwards?", "tokens": [50402, 492, 362, 257, 1168, 498, 321, 434, 787, 1228, 493, 281, 3461, 281, 3754, 281, 727, 321, 1665, 766, 439, 264, 7914, 10543, 30, 50762], "temperature": 0.0, "avg_logprob": -0.39288665999227496, "compression_ratio": 1.4545454545454546, "no_speech_prob": 3.7635421904269606e-05}, {"id": 879, "seek": 414800, "start": 4155.96, "end": 4159.6, "text": " To save some computation sure sure wouldn't be a bad idea at all", "tokens": [50762, 1407, 3155, 512, 24903, 988, 988, 2759, 380, 312, 257, 1578, 1558, 412, 439, 50944], "temperature": 0.0, "avg_logprob": -0.39288665999227496, "compression_ratio": 1.4545454545454546, "no_speech_prob": 3.7635421904269606e-05}, {"id": 880, "seek": 414800, "start": 4162.28, "end": 4168.92, "text": " Okay, so we compile it we fit it one thing you'll notice. I've started doing is using", "tokens": [51078, 1033, 11, 370, 321, 31413, 309, 321, 3318, 309, 472, 551, 291, 603, 3449, 13, 286, 600, 1409, 884, 307, 1228, 51410], "temperature": 0.0, "avg_logprob": -0.39288665999227496, "compression_ratio": 1.4545454545454546, "no_speech_prob": 3.7635421904269606e-05}, {"id": 881, "seek": 416892, "start": 4168.92, "end": 4170.92, "text": " I", "tokens": [50364, 286, 50464], "temperature": 0.0, "avg_logprob": -0.4359366266350997, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.00021318580547813326}, {"id": 882, "seek": 416892, "start": 4171.76, "end": 4173.76, "text": " Did here", "tokens": [50506, 2589, 510, 50606], "temperature": 0.0, "avg_logprob": -0.4359366266350997, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.00021318580547813326}, {"id": 883, "seek": 416892, "start": 4175.88, "end": 4183.64, "text": " This callback called TQ DM notebook callback TQ DM is a really terrific library", "tokens": [50712, 639, 818, 3207, 1219, 314, 48, 15322, 21060, 818, 3207, 314, 48, 15322, 307, 257, 534, 20899, 6405, 51100], "temperature": 0.0, "avg_logprob": -0.4359366266350997, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.00021318580547813326}, {"id": 884, "seek": 416892, "start": 4184.84, "end": 4187.4, "text": " Basically it does something very very simple", "tokens": [51160, 8537, 309, 775, 746, 588, 588, 2199, 51288], "temperature": 0.0, "avg_logprob": -0.4359366266350997, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.00021318580547813326}, {"id": 885, "seek": 416892, "start": 4187.84, "end": 4192.28, "text": " Which is to add a process here add a progress meter to your loops", "tokens": [51310, 3013, 307, 281, 909, 257, 1399, 510, 909, 257, 4205, 9255, 281, 428, 16121, 51532], "temperature": 0.0, "avg_logprob": -0.4359366266350997, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.00021318580547813326}, {"id": 886, "seek": 416892, "start": 4192.96, "end": 4198.6, "text": " You can use it in a console as you can see and so basically where you've got a loop", "tokens": [51566, 509, 393, 764, 309, 294, 257, 11076, 382, 291, 393, 536, 293, 370, 1936, 689, 291, 600, 658, 257, 6367, 51848], "temperature": 0.0, "avg_logprob": -0.4359366266350997, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.00021318580547813326}, {"id": 887, "seek": 419860, "start": 4198.6, "end": 4201.4400000000005, "text": " You can add TQ DM around it right and", "tokens": [50364, 509, 393, 909, 314, 48, 15322, 926, 309, 558, 293, 50506], "temperature": 0.0, "avg_logprob": -0.33655152269589006, "compression_ratio": 1.6244343891402715, "no_speech_prob": 2.931113886006642e-05}, {"id": 888, "seek": 419860, "start": 4202.4400000000005, "end": 4206.08, "text": " That loop does just what it used to do, but it gets its progress", "tokens": [50556, 663, 6367, 775, 445, 437, 309, 1143, 281, 360, 11, 457, 309, 2170, 1080, 4205, 50738], "temperature": 0.0, "avg_logprob": -0.33655152269589006, "compression_ratio": 1.6244343891402715, "no_speech_prob": 2.931113886006642e-05}, {"id": 889, "seek": 419860, "start": 4206.96, "end": 4210.56, "text": " It even guesses. You know how much time is left and so forth", "tokens": [50782, 467, 754, 42703, 13, 509, 458, 577, 709, 565, 307, 1411, 293, 370, 5220, 50962], "temperature": 0.0, "avg_logprob": -0.33655152269589006, "compression_ratio": 1.6244343891402715, "no_speech_prob": 2.931113886006642e-05}, {"id": 890, "seek": 419860, "start": 4211.280000000001, "end": 4213.280000000001, "text": " You can also use it inside a Jupiter notebook", "tokens": [50998, 509, 393, 611, 764, 309, 1854, 257, 24567, 21060, 51098], "temperature": 0.0, "avg_logprob": -0.33655152269589006, "compression_ratio": 1.6244343891402715, "no_speech_prob": 2.931113886006642e-05}, {"id": 891, "seek": 419860, "start": 4214.120000000001, "end": 4216.320000000001, "text": " And it creates a neat little", "tokens": [51140, 400, 309, 7829, 257, 10654, 707, 51250], "temperature": 0.0, "avg_logprob": -0.33655152269589006, "compression_ratio": 1.6244343891402715, "no_speech_prob": 2.931113886006642e-05}, {"id": 892, "seek": 419860, "start": 4221.200000000001, "end": 4227.8, "text": " Neat little graph that gradually goes up and shows you how long is left and so forth so this is just a nice little trick", "tokens": [51494, 1734, 267, 707, 4295, 300, 13145, 1709, 493, 293, 3110, 291, 577, 938, 307, 1411, 293, 370, 5220, 370, 341, 307, 445, 257, 1481, 707, 4282, 51824], "temperature": 0.0, "avg_logprob": -0.33655152269589006, "compression_ratio": 1.6244343891402715, "no_speech_prob": 2.931113886006642e-05}, {"id": 893, "seek": 422860, "start": 4229.6, "end": 4232.4800000000005, "text": " Use some learning rate annealing and", "tokens": [50414, 8278, 512, 2539, 3314, 22256, 4270, 293, 50558], "temperature": 0.0, "avg_logprob": -0.35727846482220815, "compression_ratio": 1.6852791878172588, "no_speech_prob": 6.854285857116338e-06}, {"id": 894, "seek": 422860, "start": 4234.200000000001, "end": 4236.96, "text": " At the end of training it for a few epochs", "tokens": [50644, 1711, 264, 917, 295, 3097, 309, 337, 257, 1326, 30992, 28346, 50782], "temperature": 0.0, "avg_logprob": -0.35727846482220815, "compression_ratio": 1.6852791878172588, "no_speech_prob": 6.854285857116338e-06}, {"id": 895, "seek": 422860, "start": 4237.92, "end": 4245.08, "text": " We can try out a model now the model. We're interested in is just the up sampling model right we're going to be feeding the up", "tokens": [50830, 492, 393, 853, 484, 257, 2316, 586, 264, 2316, 13, 492, 434, 3102, 294, 307, 445, 264, 493, 21179, 2316, 558, 321, 434, 516, 281, 312, 12919, 264, 493, 51188], "temperature": 0.0, "avg_logprob": -0.35727846482220815, "compression_ratio": 1.6852791878172588, "no_speech_prob": 6.854285857116338e-06}, {"id": 896, "seek": 422860, "start": 4245.08, "end": 4246.4800000000005, "text": " sampling model", "tokens": [51188, 21179, 2316, 51258], "temperature": 0.0, "avg_logprob": -0.35727846482220815, "compression_ratio": 1.6852791878172588, "no_speech_prob": 6.854285857116338e-06}, {"id": 897, "seek": 422860, "start": 4246.4800000000005, "end": 4252.240000000001, "text": " Low res inputs and getting out the high-res outputs. We don't actually really care about the value of the loss", "tokens": [51258, 17078, 725, 15743, 293, 1242, 484, 264, 1090, 12, 495, 23930, 13, 492, 500, 380, 767, 534, 1127, 466, 264, 2158, 295, 264, 4470, 51546], "temperature": 0.0, "avg_logprob": -0.35727846482220815, "compression_ratio": 1.6852791878172588, "no_speech_prob": 6.854285857116338e-06}, {"id": 898, "seek": 425224, "start": 4252.84, "end": 4260.24, "text": " So I'll now define a model which takes as input the low-res input and spits out this output now high-res output", "tokens": [50394, 407, 286, 603, 586, 6964, 257, 2316, 597, 2516, 382, 4846, 264, 2295, 12, 495, 4846, 293, 637, 1208, 484, 341, 5598, 586, 1090, 12, 495, 5598, 50764], "temperature": 0.0, "avg_logprob": -0.4089100213698399, "compression_ratio": 1.6649484536082475, "no_speech_prob": 0.0005703120259568095}, {"id": 899, "seek": 425224, "start": 4262.4, "end": 4265.719999999999, "text": " So with that model we can try it call predict", "tokens": [50872, 407, 365, 300, 2316, 321, 393, 853, 309, 818, 6069, 51038], "temperature": 0.0, "avg_logprob": -0.4089100213698399, "compression_ratio": 1.6649484536082475, "no_speech_prob": 0.0005703120259568095}, {"id": 900, "seek": 425224, "start": 4267.4, "end": 4270.84, "text": " So here is our original low resolution mashed potato", "tokens": [51122, 407, 510, 307, 527, 3380, 2295, 8669, 38964, 7445, 51294], "temperature": 0.0, "avg_logprob": -0.4089100213698399, "compression_ratio": 1.6649484536082475, "no_speech_prob": 0.0005703120259568095}, {"id": 901, "seek": 425224, "start": 4274.24, "end": 4281.76, "text": " And here's a high resolution measure here, and it's it's amazing what it's done like you can see in the original", "tokens": [51464, 400, 510, 311, 257, 1090, 8669, 3481, 510, 11, 293, 309, 311, 309, 311, 2243, 437, 309, 311, 1096, 411, 291, 393, 536, 294, 264, 3380, 51840], "temperature": 0.0, "avg_logprob": -0.4089100213698399, "compression_ratio": 1.6649484536082475, "no_speech_prob": 0.0005703120259568095}, {"id": 902, "seek": 428224, "start": 4282.679999999999, "end": 4290.0, "text": " Like the shadow of the leaf was very unclear the kind of the bits in the mashed potato. We're just kind of vague blobs", "tokens": [50386, 1743, 264, 8576, 295, 264, 10871, 390, 588, 25636, 264, 733, 295, 264, 9239, 294, 264, 38964, 7445, 13, 492, 434, 445, 733, 295, 24247, 1749, 929, 50752], "temperature": 0.0, "avg_logprob": -0.3754916577725797, "compression_ratio": 1.5238095238095237, "no_speech_prob": 3.3213815186172724e-05}, {"id": 903, "seek": 428224, "start": 4291.04, "end": 4295.28, "text": " In this version we have like bare shadows hard edges", "tokens": [50804, 682, 341, 3037, 321, 362, 411, 6949, 14740, 1152, 8819, 51016], "temperature": 0.0, "avg_logprob": -0.3754916577725797, "compression_ratio": 1.5238095238095237, "no_speech_prob": 3.3213815186172724e-05}, {"id": 904, "seek": 428224, "start": 4296.599999999999, "end": 4298.599999999999, "text": " and so forth", "tokens": [51082, 293, 370, 5220, 51182], "temperature": 0.0, "avg_logprob": -0.3754916577725797, "compression_ratio": 1.5238095238095237, "no_speech_prob": 3.3213815186172724e-05}, {"id": 905, "seek": 428224, "start": 4299.84, "end": 4305.599999999999, "text": " Question can you explain the size of the target it's the first dimension of the high-res times 128", "tokens": [51244, 14464, 393, 291, 2903, 264, 2744, 295, 264, 3779, 309, 311, 264, 700, 10139, 295, 264, 1090, 12, 495, 1413, 29810, 51532], "temperature": 0.0, "avg_logprob": -0.3754916577725797, "compression_ratio": 1.5238095238095237, "no_speech_prob": 3.3213815186172724e-05}, {"id": 906, "seek": 428224, "start": 4306.96, "end": 4308.96, "text": " Why?", "tokens": [51600, 1545, 30, 51700], "temperature": 0.0, "avg_logprob": -0.3754916577725797, "compression_ratio": 1.5238095238095237, "no_speech_prob": 3.3213815186172724e-05}, {"id": 907, "seek": 431224, "start": 4312.24, "end": 4314.24, "text": " You", "tokens": [50364, 509, 50464], "temperature": 0.0, "avg_logprob": -0.4141002068152794, "compression_ratio": 1.4322033898305084, "no_speech_prob": 4.264472590875812e-05}, {"id": 908, "seek": 431224, "start": 4318.719999999999, "end": 4326.3, "text": " It's the okay, so I see it's this number, so this is the basically the number of images that we have", "tokens": [50688, 467, 311, 264, 1392, 11, 370, 286, 536, 309, 311, 341, 1230, 11, 370, 341, 307, 264, 1936, 264, 1230, 295, 5267, 300, 321, 362, 51067], "temperature": 0.0, "avg_logprob": -0.4141002068152794, "compression_ratio": 1.4322033898305084, "no_speech_prob": 4.264472590875812e-05}, {"id": 909, "seek": 431224, "start": 4329.2, "end": 4331.2, "text": " And then", "tokens": [51212, 400, 550, 51312], "temperature": 0.0, "avg_logprob": -0.4141002068152794, "compression_ratio": 1.4322033898305084, "no_speech_prob": 4.264472590875812e-05}, {"id": 910, "seek": 431224, "start": 4332.48, "end": 4335.04, "text": " It's 128 oh", "tokens": [51376, 467, 311, 29810, 1954, 51504], "temperature": 0.0, "avg_logprob": -0.4141002068152794, "compression_ratio": 1.4322033898305084, "no_speech_prob": 4.264472590875812e-05}, {"id": 911, "seek": 431224, "start": 4337.04, "end": 4341.679999999999, "text": " It's 128 because that layer has 128 filters", "tokens": [51604, 467, 311, 29810, 570, 300, 4583, 575, 29810, 15995, 51836], "temperature": 0.0, "avg_logprob": -0.4141002068152794, "compression_ratio": 1.4322033898305084, "no_speech_prob": 4.264472590875812e-05}, {"id": 912, "seek": 434224, "start": 4342.24, "end": 4344.24, "text": " So this ends up giving you", "tokens": [50364, 407, 341, 5314, 493, 2902, 291, 50464], "temperature": 0.0, "avg_logprob": -0.36340686942957623, "compression_ratio": 1.4734299516908214, "no_speech_prob": 3.882748569594696e-05}, {"id": 913, "seek": 434224, "start": 4346.76, "end": 4350.88, "text": " The mean squared error of 128 filter losses", "tokens": [50590, 440, 914, 8889, 6713, 295, 29810, 6608, 15352, 50796], "temperature": 0.0, "avg_logprob": -0.36340686942957623, "compression_ratio": 1.4734299516908214, "no_speech_prob": 3.882748569594696e-05}, {"id": 914, "seek": 434224, "start": 4352.84, "end": 4354.84, "text": " Well since I did this", "tokens": [50894, 1042, 1670, 286, 630, 341, 50994], "temperature": 0.0, "avg_logprob": -0.36340686942957623, "compression_ratio": 1.4734299516908214, "no_speech_prob": 3.882748569594696e-05}, {"id": 915, "seek": 434224, "start": 4357.639999999999, "end": 4362.639999999999, "text": " Yes, and then there was another question would popping the unused layers really save anything", "tokens": [51134, 1079, 11, 293, 550, 456, 390, 1071, 1168, 576, 18374, 264, 44383, 7914, 534, 3155, 1340, 51384], "temperature": 0.0, "avg_logprob": -0.36340686942957623, "compression_ratio": 1.4734299516908214, "no_speech_prob": 3.882748569594696e-05}, {"id": 916, "seek": 434224, "start": 4363.2, "end": 4369.639999999999, "text": " Aren't you only getting the layers you want when you do the BGG dot get layer block to conju too?", "tokens": [51412, 15464, 380, 291, 787, 1242, 264, 7914, 291, 528, 562, 291, 360, 264, 363, 27561, 5893, 483, 4583, 3461, 281, 416, 8954, 886, 30, 51734], "temperature": 0.0, "avg_logprob": -0.36340686942957623, "compression_ratio": 1.4734299516908214, "no_speech_prob": 3.882748569594696e-05}, {"id": 917, "seek": 434224, "start": 4369.639999999999, "end": 4371.639999999999, "text": " Yeah, I'm not sure I", "tokens": [51734, 865, 11, 286, 478, 406, 988, 286, 51834], "temperature": 0.0, "avg_logprob": -0.36340686942957623, "compression_ratio": 1.4734299516908214, "no_speech_prob": 3.882748569594696e-05}, {"id": 918, "seek": 437224, "start": 4372.24, "end": 4374.16, "text": " I", "tokens": [50364, 286, 50460], "temperature": 0.0, "avg_logprob": -0.3685413809383617, "compression_ratio": 1.5297619047619047, "no_speech_prob": 1.4971054952184204e-05}, {"id": 919, "seek": 437224, "start": 4374.16, "end": 4379.04, "text": " Don't I can't quite think quickly enough you could try it it might not help", "tokens": [50460, 1468, 380, 286, 393, 380, 1596, 519, 2661, 1547, 291, 727, 853, 309, 309, 1062, 406, 854, 50704], "temperature": 0.0, "avg_logprob": -0.3685413809383617, "compression_ratio": 1.5297619047619047, "no_speech_prob": 1.4971054952184204e-05}, {"id": 920, "seek": 437224, "start": 4379.88, "end": 4383.58, "text": " And intuitively what features is this model learning?", "tokens": [50746, 400, 46506, 437, 4122, 307, 341, 2316, 2539, 30, 50931], "temperature": 0.0, "avg_logprob": -0.3685413809383617, "compression_ratio": 1.5297619047619047, "no_speech_prob": 1.4971054952184204e-05}, {"id": 921, "seek": 437224, "start": 4386.48, "end": 4389.84, "text": " But what it's learning is it's looking at 20,000 images", "tokens": [51076, 583, 437, 309, 311, 2539, 307, 309, 311, 1237, 412, 945, 11, 1360, 5267, 51244], "temperature": 0.0, "avg_logprob": -0.3685413809383617, "compression_ratio": 1.5297619047619047, "no_speech_prob": 1.4971054952184204e-05}, {"id": 922, "seek": 437224, "start": 4390.48, "end": 4394.96, "text": " Very very very low resolution images like this and it's learning", "tokens": [51276, 4372, 588, 588, 2295, 8669, 5267, 411, 341, 293, 309, 311, 2539, 51500], "temperature": 0.0, "avg_logprob": -0.3685413809383617, "compression_ratio": 1.5297619047619047, "no_speech_prob": 1.4971054952184204e-05}, {"id": 923, "seek": 437224, "start": 4395.719999999999, "end": 4397.5599999999995, "text": " like", "tokens": [51538, 411, 51630], "temperature": 0.0, "avg_logprob": -0.3685413809383617, "compression_ratio": 1.5297619047619047, "no_speech_prob": 1.4971054952184204e-05}, {"id": 924, "seek": 439756, "start": 4397.56, "end": 4403.240000000001, "text": " When there's a kind of a soft gray bit next to a hard bit you know in certain situations", "tokens": [50364, 1133, 456, 311, 257, 733, 295, 257, 2787, 10855, 857, 958, 281, 257, 1152, 857, 291, 458, 294, 1629, 6851, 50648], "temperature": 0.0, "avg_logprob": -0.2677573107798165, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.00011061128316214308}, {"id": 925, "seek": 439756, "start": 4403.240000000001, "end": 4410.120000000001, "text": " That's probably a shadow and when there's a shadow. This is what a shadow looks like example. It's learning that when there's a curve", "tokens": [50648, 663, 311, 1391, 257, 8576, 293, 562, 456, 311, 257, 8576, 13, 639, 307, 437, 257, 8576, 1542, 411, 1365, 13, 467, 311, 2539, 300, 562, 456, 311, 257, 7605, 50992], "temperature": 0.0, "avg_logprob": -0.2677573107798165, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.00011061128316214308}, {"id": 926, "seek": 439756, "start": 4411.240000000001, "end": 4416.620000000001, "text": " It doesn't actually meant to look like a jagged edge, but it's actually meant to look like something smooth", "tokens": [51048, 467, 1177, 380, 767, 4140, 281, 574, 411, 257, 6368, 3004, 4691, 11, 457, 309, 311, 767, 4140, 281, 574, 411, 746, 5508, 51317], "temperature": 0.0, "avg_logprob": -0.2677573107798165, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.00011061128316214308}, {"id": 927, "seek": 439756, "start": 4417.56, "end": 4419.56, "text": " No, it's really learning", "tokens": [51364, 883, 11, 309, 311, 534, 2539, 51464], "temperature": 0.0, "avg_logprob": -0.2677573107798165, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.00011061128316214308}, {"id": 928, "seek": 439756, "start": 4419.84, "end": 4422.6, "text": " What the world looks like you know and then?", "tokens": [51478, 708, 264, 1002, 1542, 411, 291, 458, 293, 550, 30, 51616], "temperature": 0.0, "avg_logprob": -0.2677573107798165, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.00011061128316214308}, {"id": 929, "seek": 439756, "start": 4423.400000000001, "end": 4425.6, "text": " when you take that world and", "tokens": [51656, 562, 291, 747, 300, 1002, 293, 51766], "temperature": 0.0, "avg_logprob": -0.2677573107798165, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.00011061128316214308}, {"id": 930, "seek": 442560, "start": 4426.280000000001, "end": 4431.400000000001, "text": " Lower it and make it small you know what does it then look like and so it's just like when you", "tokens": [50398, 25523, 309, 293, 652, 309, 1359, 291, 458, 437, 775, 309, 550, 574, 411, 293, 370, 309, 311, 445, 411, 562, 291, 50654], "temperature": 0.0, "avg_logprob": -0.32572284591532197, "compression_ratio": 1.8713692946058091, "no_speech_prob": 4.400079706101678e-05}, {"id": 931, "seek": 442560, "start": 4432.04, "end": 4435.0, "text": " When you look at a picture like this and particularly if you like", "tokens": [50686, 1133, 291, 574, 412, 257, 3036, 411, 341, 293, 4098, 498, 291, 411, 50834], "temperature": 0.0, "avg_logprob": -0.32572284591532197, "compression_ratio": 1.8713692946058091, "no_speech_prob": 4.400079706101678e-05}, {"id": 932, "seek": 442560, "start": 4435.64, "end": 4440.06, "text": " That it blur your eyes and defocus your eyes you you can often see", "tokens": [50866, 663, 309, 14257, 428, 2575, 293, 1060, 15206, 428, 2575, 291, 291, 393, 2049, 536, 51087], "temperature": 0.0, "avg_logprob": -0.32572284591532197, "compression_ratio": 1.8713692946058091, "no_speech_prob": 4.400079706101678e-05}, {"id": 933, "seek": 442560, "start": 4440.96, "end": 4444.4800000000005, "text": " You know what it originally looked like because your brain basically is doing the same thing", "tokens": [51132, 509, 458, 437, 309, 7993, 2956, 411, 570, 428, 3567, 1936, 307, 884, 264, 912, 551, 51308], "temperature": 0.0, "avg_logprob": -0.32572284591532197, "compression_ratio": 1.8713692946058091, "no_speech_prob": 4.400079706101678e-05}, {"id": 934, "seek": 442560, "start": 4444.56, "end": 4450.360000000001, "text": " It's like when you read a really blurry text you can still read it because your brain is thinking like it knows", "tokens": [51312, 467, 311, 411, 562, 291, 1401, 257, 534, 37644, 2487, 291, 393, 920, 1401, 309, 570, 428, 3567, 307, 1953, 411, 309, 3255, 51602], "temperature": 0.0, "avg_logprob": -0.32572284591532197, "compression_ratio": 1.8713692946058091, "no_speech_prob": 4.400079706101678e-05}, {"id": 935, "seek": 442560, "start": 4450.360000000001, "end": 4452.360000000001, "text": " I got that must be", "tokens": [51602, 286, 658, 300, 1633, 312, 51702], "temperature": 0.0, "avg_logprob": -0.32572284591532197, "compression_ratio": 1.8713692946058091, "no_speech_prob": 4.400079706101678e-05}, {"id": 936, "seek": 445560, "start": 4456.320000000001, "end": 4458.320000000001, "text": " You", "tokens": [50400, 509, 50500], "temperature": 0.0, "avg_logprob": -0.44847166383421266, "compression_ratio": 1.5657142857142856, "no_speech_prob": 6.013555685058236e-05}, {"id": 937, "seek": 445560, "start": 4458.56, "end": 4461.320000000001, "text": " So are you suggesting there is a similar", "tokens": [50512, 407, 366, 291, 18094, 456, 307, 257, 2531, 50650], "temperature": 0.0, "avg_logprob": -0.44847166383421266, "compression_ratio": 1.5657142857142856, "no_speech_prob": 6.013555685058236e-05}, {"id": 938, "seek": 445560, "start": 4461.96, "end": 4469.56, "text": " universality on the other way around like you know when BGG saying the first layer is a learning a line and then a square and", "tokens": [50682, 5950, 1860, 322, 264, 661, 636, 926, 411, 291, 458, 562, 363, 38, 38, 1566, 264, 700, 4583, 307, 257, 2539, 257, 1622, 293, 550, 257, 3732, 293, 51062], "temperature": 0.0, "avg_logprob": -0.44847166383421266, "compression_ratio": 1.5657142857142856, "no_speech_prob": 6.013555685058236e-05}, {"id": 939, "seek": 445560, "start": 4469.88, "end": 4475.18, "text": " No, sir. I are you saying the same thing is true in this case. Yeah", "tokens": [51078, 883, 11, 4735, 13, 286, 366, 291, 1566, 264, 912, 551, 307, 2074, 294, 341, 1389, 13, 865, 51343], "temperature": 0.0, "avg_logprob": -0.44847166383421266, "compression_ratio": 1.5657142857142856, "no_speech_prob": 6.013555685058236e-05}, {"id": 940, "seek": 445560, "start": 4477.64, "end": 4479.64, "text": " It has to be like there's no way to", "tokens": [51466, 467, 575, 281, 312, 411, 456, 311, 572, 636, 281, 51566], "temperature": 0.0, "avg_logprob": -0.44847166383421266, "compression_ratio": 1.5657142857142856, "no_speech_prob": 6.013555685058236e-05}, {"id": 941, "seek": 447964, "start": 4480.6, "end": 4482.6, "text": " Up sample", "tokens": [50412, 5858, 6889, 50512], "temperature": 0.0, "avg_logprob": -0.4416221530958154, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0027146684005856514}, {"id": 942, "seek": 447964, "start": 4482.84, "end": 4486.72, "text": " Like there's a number of ways you can assemble this lost information", "tokens": [50524, 1743, 456, 311, 257, 1230, 295, 2098, 291, 393, 22364, 341, 2731, 1589, 50718], "temperature": 0.0, "avg_logprob": -0.4416221530958154, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0027146684005856514}, {"id": 943, "seek": 447964, "start": 4486.92, "end": 4491.18, "text": " So in order to do it in a way that decreases this loss function", "tokens": [50728, 407, 294, 1668, 281, 360, 309, 294, 257, 636, 300, 24108, 341, 4470, 2445, 50941], "temperature": 0.0, "avg_logprob": -0.4416221530958154, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0027146684005856514}, {"id": 944, "seek": 447964, "start": 4491.72, "end": 4495.68, "text": " It actually has to figure out you know what what's probably there", "tokens": [50968, 467, 767, 575, 281, 2573, 484, 291, 458, 437, 437, 311, 1391, 456, 51166], "temperature": 0.0, "avg_logprob": -0.4416221530958154, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0027146684005856514}, {"id": 945, "seek": 447964, "start": 4497.76, "end": 4499.64, "text": " But don't you agree", "tokens": [51270, 583, 500, 380, 291, 3986, 51364], "temperature": 0.0, "avg_logprob": -0.4416221530958154, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0027146684005856514}, {"id": 946, "seek": 447964, "start": 4499.64, "end": 4505.88, "text": " Just intuitively thinking about it like example of the you say suggesting like the album of pictures for your mom", "tokens": [51364, 1449, 46506, 1953, 466, 309, 411, 1365, 295, 264, 291, 584, 18094, 411, 264, 6030, 295, 5242, 337, 428, 1225, 51676], "temperature": 0.0, "avg_logprob": -0.4416221530958154, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0027146684005856514}, {"id": 947, "seek": 447964, "start": 4505.88, "end": 4507.88, "text": " would you think like", "tokens": [51676, 576, 291, 519, 411, 51776], "temperature": 0.0, "avg_logprob": -0.4416221530958154, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0027146684005856514}, {"id": 948, "seek": 450788, "start": 4508.08, "end": 4512.2, "text": " Be a bit easier if we're just feeding it pictures of humans because it's like the", "tokens": [50374, 879, 257, 857, 3571, 498, 321, 434, 445, 12919, 309, 5242, 295, 6255, 570, 309, 311, 411, 264, 50580], "temperature": 0.0, "avg_logprob": -0.6202740615673279, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.004679342731833458}, {"id": 949, "seek": 450788, "start": 4512.52, "end": 4514.68, "text": " Interaction of the circle of the eye and the nose", "tokens": [50596, 5751, 2894, 295, 264, 6329, 295, 264, 3313, 293, 264, 6690, 50704], "temperature": 0.0, "avg_logprob": -0.6202740615673279, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.004679342731833458}, {"id": 950, "seek": 450788, "start": 4516.8, "end": 4523.04, "text": " So the in the extreme versions of super resolution networks, so they take eight by eight inches", "tokens": [50810, 407, 264, 294, 264, 8084, 9606, 295, 1687, 8669, 9590, 11, 370, 436, 747, 3180, 538, 3180, 8478, 51122], "temperature": 0.0, "avg_logprob": -0.6202740615673279, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.004679342731833458}, {"id": 951, "seek": 450788, "start": 4523.76, "end": 4526.64, "text": " You'll see that all of them pretty much the same data set", "tokens": [51158, 509, 603, 536, 300, 439, 295, 552, 1238, 709, 264, 912, 1412, 992, 51302], "temperature": 0.0, "avg_logprob": -0.6202740615673279, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.004679342731833458}, {"id": 952, "seek": 450788, "start": 4526.64, "end": 4532.12, "text": " So they put so that a so that is a data set of pictures of celebrity spaces", "tokens": [51302, 407, 436, 829, 370, 300, 257, 370, 300, 307, 257, 1412, 992, 295, 5242, 295, 18597, 7673, 51576], "temperature": 0.0, "avg_logprob": -0.6202740615673279, "compression_ratio": 1.6790697674418604, "no_speech_prob": 0.004679342731833458}, {"id": 953, "seek": 453212, "start": 4532.5599999999995, "end": 4537.36, "text": " And also every spaces are pretty similar, you know and so they show these fantastic", "tokens": [50386, 400, 611, 633, 7673, 366, 1238, 2531, 11, 291, 458, 293, 370, 436, 855, 613, 5456, 50626], "temperature": 0.0, "avg_logprob": -0.49081161104399584, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.005554306320846081}, {"id": 954, "seek": 453212, "start": 4537.36, "end": 4542.599999999999, "text": " And they are fantastic and amazing results, but they're taken a play a turn of the future of the place and it looks", "tokens": [50626, 400, 436, 366, 5456, 293, 2243, 3542, 11, 457, 436, 434, 2726, 257, 862, 257, 1261, 295, 264, 2027, 295, 264, 1081, 293, 309, 1542, 50888], "temperature": 0.0, "avg_logprob": -0.49081161104399584, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.005554306320846081}, {"id": 955, "seek": 453212, "start": 4543.12, "end": 4544.8, "text": " Pretty close, right?", "tokens": [50914, 10693, 1998, 11, 558, 30, 50998], "temperature": 0.0, "avg_logprob": -0.49081161104399584, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.005554306320846081}, {"id": 956, "seek": 453212, "start": 4544.8, "end": 4551.2, "text": " That's because they've taken advantage of this if you in our case. We've got 20,000 images from a thousand categories", "tokens": [50998, 663, 311, 570, 436, 600, 2726, 5002, 295, 341, 498, 291, 294, 527, 1389, 13, 492, 600, 658, 945, 11, 1360, 5267, 490, 257, 4714, 10479, 51318], "temperature": 0.0, "avg_logprob": -0.49081161104399584, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.005554306320846081}, {"id": 957, "seek": 453212, "start": 4552.16, "end": 4554.16, "text": " It's not going to do nearly as well", "tokens": [51366, 467, 311, 406, 516, 281, 360, 6217, 382, 731, 51466], "temperature": 0.0, "avg_logprob": -0.49081161104399584, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.005554306320846081}, {"id": 958, "seek": 453212, "start": 4554.64, "end": 4558.28, "text": " If we wanted to do as well as the select a versions we would need", "tokens": [51490, 759, 321, 1415, 281, 360, 382, 731, 382, 264, 3048, 257, 9606, 321, 576, 643, 51672], "temperature": 0.0, "avg_logprob": -0.49081161104399584, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.005554306320846081}, {"id": 959, "seek": 453212, "start": 4559.04, "end": 4561.04, "text": " hundreds of millions of images", "tokens": [51710, 6779, 295, 6803, 295, 5267, 51810], "temperature": 0.0, "avg_logprob": -0.49081161104399584, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.005554306320846081}, {"id": 960, "seek": 456212, "start": 4562.72, "end": 4569.2, "text": " Yeah, it just is hard for me to imagine mashed potatoes in a face count like in the same category that's my", "tokens": [50394, 865, 11, 309, 445, 307, 1152, 337, 385, 281, 3811, 38964, 11811, 294, 257, 1851, 1207, 411, 294, 264, 912, 7719, 300, 311, 452, 50718], "temperature": 0.0, "avg_logprob": -0.615053231375558, "compression_ratio": 1.1818181818181819, "no_speech_prob": 0.00023043739201966673}, {"id": 961, "seek": 456212, "start": 4577.48, "end": 4579.48, "text": " So", "tokens": [51132, 407, 51232], "temperature": 0.0, "avg_logprob": -0.615053231375558, "compression_ratio": 1.1818181818181819, "no_speech_prob": 0.00023043739201966673}, {"id": 962, "seek": 456212, "start": 4585.44, "end": 4587.44, "text": " And so", "tokens": [51530, 400, 370, 51630], "temperature": 0.0, "avg_logprob": -0.615053231375558, "compression_ratio": 1.1818181818181819, "no_speech_prob": 0.00023043739201966673}, {"id": 963, "seek": 458744, "start": 4588.44, "end": 4590.44, "text": " Examples", "tokens": [50414, 48591, 50514], "temperature": 0.0, "avg_logprob": -0.513058432217302, "compression_ratio": 1.5, "no_speech_prob": 0.009705785661935806}, {"id": 964, "seek": 458744, "start": 4591.919999999999, "end": 4593.919999999999, "text": " Writing and", "tokens": [50588, 32774, 293, 50688], "temperature": 0.0, "avg_logprob": -0.513058432217302, "compression_ratio": 1.5, "no_speech_prob": 0.009705785661935806}, {"id": 965, "seek": 458744, "start": 4594.16, "end": 4597.48, "text": " Pictures and whatever so you know for your examples", "tokens": [50700, 45877, 293, 2035, 370, 291, 458, 337, 428, 5110, 50866], "temperature": 0.0, "avg_logprob": -0.513058432217302, "compression_ratio": 1.5, "no_speech_prob": 0.009705785661935806}, {"id": 966, "seek": 458744, "start": 4598.36, "end": 4603.96, "text": " You're most likely to be doing stuff which is more demand specific and so you should use more demand specific data", "tokens": [50910, 509, 434, 881, 3700, 281, 312, 884, 1507, 597, 307, 544, 4733, 2685, 293, 370, 291, 820, 764, 544, 4733, 2685, 1412, 51190], "temperature": 0.0, "avg_logprob": -0.513058432217302, "compression_ratio": 1.5, "no_speech_prob": 0.009705785661935806}, {"id": 967, "seek": 458744, "start": 4606.679999999999, "end": 4608.679999999999, "text": " These kind of issues", "tokens": [51326, 1981, 733, 295, 2663, 51426], "temperature": 0.0, "avg_logprob": -0.513058432217302, "compression_ratio": 1.5, "no_speech_prob": 0.009705785661935806}, {"id": 968, "seek": 458744, "start": 4610.639999999999, "end": 4612.639999999999, "text": " That's a question, thank you", "tokens": [51524, 663, 311, 257, 1168, 11, 1309, 291, 51624], "temperature": 0.0, "avg_logprob": -0.513058432217302, "compression_ratio": 1.5, "no_speech_prob": 0.009705785661935806}, {"id": 969, "seek": 461744, "start": 4617.44, "end": 4619.44, "text": " Okay, so", "tokens": [50364, 1033, 11, 370, 50464], "temperature": 0.0, "avg_logprob": -0.34256017208099365, "compression_ratio": 1.464968152866242, "no_speech_prob": 1.1659509254968725e-05}, {"id": 970, "seek": 461744, "start": 4623.24, "end": 4625.639999999999, "text": " One thing I mentioned here is I haven't used a test set", "tokens": [50654, 1485, 551, 286, 2835, 510, 307, 286, 2378, 380, 1143, 257, 1500, 992, 50774], "temperature": 0.0, "avg_logprob": -0.34256017208099365, "compression_ratio": 1.464968152866242, "no_speech_prob": 1.1659509254968725e-05}, {"id": 971, "seek": 461744, "start": 4626.639999999999, "end": 4628.639999999999, "text": " so another piece of the homework is to", "tokens": [50824, 370, 1071, 2522, 295, 264, 14578, 307, 281, 50924], "temperature": 0.0, "avg_logprob": -0.34256017208099365, "compression_ratio": 1.464968152866242, "no_speech_prob": 1.1659509254968725e-05}, {"id": 972, "seek": 461744, "start": 4629.36, "end": 4632.759999999999, "text": " Add in a test set right and and and tell us", "tokens": [50960, 5349, 294, 257, 1500, 992, 558, 293, 293, 293, 980, 505, 51130], "temperature": 0.0, "avg_logprob": -0.34256017208099365, "compression_ratio": 1.464968152866242, "no_speech_prob": 1.1659509254968725e-05}, {"id": 973, "seek": 461744, "start": 4633.4, "end": 4635.4, "text": " Is this mashed potato?", "tokens": [51162, 1119, 341, 38964, 7445, 30, 51262], "temperature": 0.0, "avg_logprob": -0.34256017208099365, "compression_ratio": 1.464968152866242, "no_speech_prob": 1.1659509254968725e-05}, {"id": 974, "seek": 461744, "start": 4635.799999999999, "end": 4640.419999999999, "text": " Overfit right is this actually just matching the particular", "tokens": [51282, 4886, 6845, 558, 307, 341, 767, 445, 14324, 264, 1729, 51513], "temperature": 0.0, "avg_logprob": -0.34256017208099365, "compression_ratio": 1.464968152866242, "no_speech_prob": 1.1659509254968725e-05}, {"id": 975, "seek": 464042, "start": 4641.14, "end": 4648.9800000000005, "text": " Training set version of this mashed potato or not and if it is overfitting can you can you create something that doesn't fit?", "tokens": [50400, 20620, 992, 3037, 295, 341, 38964, 7445, 420, 406, 293, 498, 309, 307, 670, 69, 2414, 393, 291, 393, 291, 1884, 746, 300, 1177, 380, 3318, 30, 50792], "temperature": 0.0, "avg_logprob": -0.30742127186543233, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.005554812494665384}, {"id": 976, "seek": 464042, "start": 4650.7, "end": 4652.7, "text": " So there's another piece of homework", "tokens": [50878, 407, 456, 311, 1071, 2522, 295, 14578, 50978], "temperature": 0.0, "avg_logprob": -0.30742127186543233, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.005554812494665384}, {"id": 977, "seek": 464042, "start": 4653.38, "end": 4658.22, "text": " so it's very simple now to take this and", "tokens": [51012, 370, 309, 311, 588, 2199, 586, 281, 747, 341, 293, 51254], "temperature": 0.0, "avg_logprob": -0.30742127186543233, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.005554812494665384}, {"id": 978, "seek": 464042, "start": 4659.66, "end": 4665.46, "text": " Turn it into our fast style transfer so the fast style transfer is going to do exactly the same thing", "tokens": [51326, 7956, 309, 666, 527, 2370, 3758, 5003, 370, 264, 2370, 3758, 5003, 307, 516, 281, 360, 2293, 264, 912, 551, 51616], "temperature": 0.0, "avg_logprob": -0.30742127186543233, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.005554812494665384}, {"id": 979, "seek": 466546, "start": 4666.06, "end": 4670.52, "text": " But rather than taking something turning something low res into something high res", "tokens": [50394, 583, 2831, 813, 1940, 746, 6246, 746, 2295, 725, 666, 746, 1090, 725, 50617], "temperature": 0.0, "avg_logprob": -0.29854016187714366, "compression_ratio": 1.7953216374269005, "no_speech_prob": 4.9086182116298005e-05}, {"id": 980, "seek": 466546, "start": 4671.14, "end": 4673.14, "text": " It's going to take something", "tokens": [50648, 467, 311, 516, 281, 747, 746, 50748], "temperature": 0.0, "avg_logprob": -0.29854016187714366, "compression_ratio": 1.7953216374269005, "no_speech_prob": 4.9086182116298005e-05}, {"id": 981, "seek": 466546, "start": 4673.34, "end": 4675.34, "text": " That's a photo and turn it into", "tokens": [50758, 663, 311, 257, 5052, 293, 1261, 309, 666, 50858], "temperature": 0.0, "avg_logprob": -0.29854016187714366, "compression_ratio": 1.7953216374269005, "no_speech_prob": 4.9086182116298005e-05}, {"id": 982, "seek": 466546, "start": 4676.46, "end": 4678.46, "text": " Van Gogh's irises", "tokens": [50914, 8979, 39690, 71, 311, 3418, 3598, 51014], "temperature": 0.0, "avg_logprob": -0.29854016187714366, "compression_ratio": 1.7953216374269005, "no_speech_prob": 4.9086182116298005e-05}, {"id": 983, "seek": 466546, "start": 4681.26, "end": 4686.46, "text": " So we're going to do that in just the same way we're going to rather than go from", "tokens": [51154, 407, 321, 434, 516, 281, 360, 300, 294, 445, 264, 912, 636, 321, 434, 516, 281, 2831, 813, 352, 490, 51414], "temperature": 0.0, "avg_logprob": -0.29854016187714366, "compression_ratio": 1.7953216374269005, "no_speech_prob": 4.9086182116298005e-05}, {"id": 984, "seek": 466546, "start": 4687.14, "end": 4689.14, "text": " low res through a", "tokens": [51448, 2295, 725, 807, 257, 51548], "temperature": 0.0, "avg_logprob": -0.29854016187714366, "compression_ratio": 1.7953216374269005, "no_speech_prob": 4.9086182116298005e-05}, {"id": 985, "seek": 466546, "start": 4689.22, "end": 4692.86, "text": " CNN to find the content loss against high res", "tokens": [51552, 24859, 281, 915, 264, 2701, 4470, 1970, 1090, 725, 51734], "temperature": 0.0, "avg_logprob": -0.29854016187714366, "compression_ratio": 1.7953216374269005, "no_speech_prob": 4.9086182116298005e-05}, {"id": 986, "seek": 469286, "start": 4693.86, "end": 4696.62, "text": " We're going to take a photo", "tokens": [50414, 492, 434, 516, 281, 747, 257, 5052, 50552], "temperature": 0.0, "avg_logprob": -0.30458383560180663, "compression_ratio": 1.6812749003984064, "no_speech_prob": 9.761505498318002e-05}, {"id": 987, "seek": 469286, "start": 4697.0599999999995, "end": 4702.78, "text": " Go through a CNN and do both style loss and content loss against a single", "tokens": [50574, 1037, 807, 257, 24859, 293, 360, 1293, 3758, 4470, 293, 2701, 4470, 1970, 257, 2167, 50860], "temperature": 0.0, "avg_logprob": -0.30458383560180663, "compression_ratio": 1.6812749003984064, "no_speech_prob": 9.761505498318002e-05}, {"id": 988, "seek": 469286, "start": 4703.339999999999, "end": 4705.339999999999, "text": " fixed style image", "tokens": [50888, 6806, 3758, 3256, 50988], "temperature": 0.0, "avg_logprob": -0.30458383560180663, "compression_ratio": 1.6812749003984064, "no_speech_prob": 9.761505498318002e-05}, {"id": 989, "seek": 469286, "start": 4706.219999999999, "end": 4710.5, "text": " I've given you links here, so I have not implemented this for you", "tokens": [51032, 286, 600, 2212, 291, 6123, 510, 11, 370, 286, 362, 406, 12270, 341, 337, 291, 51246], "temperature": 0.0, "avg_logprob": -0.30458383560180663, "compression_ratio": 1.6812749003984064, "no_speech_prob": 9.761505498318002e-05}, {"id": 990, "seek": 469286, "start": 4710.5, "end": 4717.12, "text": " This is for you to implement, but I have given you links to the original paper and very importantly also to the supplementary material", "tokens": [51246, 639, 307, 337, 291, 281, 4445, 11, 457, 286, 362, 2212, 291, 6123, 281, 264, 3380, 3035, 293, 588, 8906, 611, 281, 264, 15436, 822, 2527, 51577], "temperature": 0.0, "avg_logprob": -0.30458383560180663, "compression_ratio": 1.6812749003984064, "no_speech_prob": 9.761505498318002e-05}, {"id": 991, "seek": 469286, "start": 4717.74, "end": 4721.54, "text": " Which is a little hard to find because there's two different versions and only one of them is correct", "tokens": [51608, 3013, 307, 257, 707, 1152, 281, 915, 570, 456, 311, 732, 819, 9606, 293, 787, 472, 295, 552, 307, 3006, 51798], "temperature": 0.0, "avg_logprob": -0.30458383560180663, "compression_ratio": 1.6812749003984064, "no_speech_prob": 9.761505498318002e-05}, {"id": 992, "seek": 472154, "start": 4722.14, "end": 4724.14, "text": " And of course I don't tell you which one is correct", "tokens": [50394, 400, 295, 1164, 286, 500, 380, 980, 291, 597, 472, 307, 3006, 50494], "temperature": 0.0, "avg_logprob": -0.32768926228562445, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.00011591814109124243}, {"id": 993, "seek": 472154, "start": 4725.62, "end": 4727.62, "text": " So the supplementary material", "tokens": [50568, 407, 264, 15436, 822, 2527, 50668], "temperature": 0.0, "avg_logprob": -0.32768926228562445, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.00011591814109124243}, {"id": 994, "seek": 472154, "start": 4728.86, "end": 4731.82, "text": " goes through all of the exact details of", "tokens": [50730, 1709, 807, 439, 295, 264, 1900, 4365, 295, 50878], "temperature": 0.0, "avg_logprob": -0.32768926228562445, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.00011591814109124243}, {"id": 995, "seek": 472154, "start": 4733.14, "end": 4737.58, "text": " What was their loss function? What was their processing? What was their exact architecture?", "tokens": [50944, 708, 390, 641, 4470, 2445, 30, 708, 390, 641, 9007, 30, 708, 390, 641, 1900, 9482, 30, 51166], "temperature": 0.0, "avg_logprob": -0.32768926228562445, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.00011591814109124243}, {"id": 996, "seek": 472154, "start": 4738.22, "end": 4740.22, "text": " And so on and so forth", "tokens": [51198, 400, 370, 322, 293, 370, 5220, 51298], "temperature": 0.0, "avg_logprob": -0.32768926228562445, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.00011591814109124243}, {"id": 997, "seek": 472154, "start": 4740.5, "end": 4742.5, "text": " So while I wait for that to load", "tokens": [51312, 407, 1339, 286, 1699, 337, 300, 281, 3677, 51412], "temperature": 0.0, "avg_logprob": -0.32768926228562445, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.00011591814109124243}, {"id": 998, "seek": 472154, "start": 4744.38, "end": 4746.38, "text": " Yeah", "tokens": [51506, 865, 51606], "temperature": 0.0, "avg_logprob": -0.32768926228562445, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.00011591814109124243}, {"id": 999, "seek": 474638, "start": 4747.06, "end": 4751.58, "text": " Like we did a doodle regeneration using the models photographers weights", "tokens": [50398, 1743, 321, 630, 257, 360, 30013, 43813, 1228, 264, 5245, 33835, 17443, 50624], "temperature": 0.0, "avg_logprob": -0.28163521378128614, "compression_ratio": 1.6532663316582914, "no_speech_prob": 0.0001686468895059079}, {"id": 1000, "seek": 474638, "start": 4752.66, "end": 4757.26, "text": " Could we create a regular image to see how you would look if you were a model? I?", "tokens": [50678, 7497, 321, 1884, 257, 3890, 3256, 281, 536, 577, 291, 576, 574, 498, 291, 645, 257, 2316, 30, 286, 30, 50908], "temperature": 0.0, "avg_logprob": -0.28163521378128614, "compression_ratio": 1.6532663316582914, "no_speech_prob": 0.0001686468895059079}, {"id": 1001, "seek": 474638, "start": 4762.26, "end": 4765.78, "text": " Don't know I'm not exactly if you could come up with a loss function", "tokens": [51158, 1468, 380, 458, 286, 478, 406, 2293, 498, 291, 727, 808, 493, 365, 257, 4470, 2445, 51334], "temperature": 0.0, "avg_logprob": -0.28163521378128614, "compression_ratio": 1.6532663316582914, "no_speech_prob": 0.0001686468895059079}, {"id": 1002, "seek": 474638, "start": 4766.06, "end": 4771.7, "text": " Which is how much does somebody look like a model you could so you'd have to come up with a loss function", "tokens": [51348, 3013, 307, 577, 709, 775, 2618, 574, 411, 257, 2316, 291, 727, 370, 291, 1116, 362, 281, 808, 493, 365, 257, 4470, 2445, 51630], "temperature": 0.0, "avg_logprob": -0.28163521378128614, "compression_ratio": 1.6532663316582914, "no_speech_prob": 0.0001686468895059079}, {"id": 1003, "seek": 477170, "start": 4772.7, "end": 4776.5, "text": " And and it had to be something where you can generate label data", "tokens": [50414, 400, 293, 309, 632, 281, 312, 746, 689, 291, 393, 8460, 7645, 1412, 50604], "temperature": 0.0, "avg_logprob": -0.45886307670956566, "compression_ratio": 1.7239819004524888, "no_speech_prob": 1.834258364397101e-05}, {"id": 1004, "seek": 477170, "start": 4779.54, "end": 4785.139999999999, "text": " One of the things they mentioned in the paper is that they found it very important to", "tokens": [50756, 1485, 295, 264, 721, 436, 2835, 294, 264, 3035, 307, 300, 436, 1352, 309, 588, 1021, 281, 51036], "temperature": 0.0, "avg_logprob": -0.45886307670956566, "compression_ratio": 1.7239819004524888, "no_speech_prob": 1.834258364397101e-05}, {"id": 1005, "seek": 477170, "start": 4785.74, "end": 4787.74, "text": " add quite a lot of padding and", "tokens": [51066, 909, 1596, 257, 688, 295, 39562, 293, 51166], "temperature": 0.0, "avg_logprob": -0.45886307670956566, "compression_ratio": 1.7239819004524888, "no_speech_prob": 1.834258364397101e-05}, {"id": 1006, "seek": 477170, "start": 4788.38, "end": 4794.78, "text": " Specifically they didn't add zero padding you know normally we just had a black border, but they add reflection padding so reflection padding", "tokens": [51198, 26058, 436, 994, 380, 909, 4018, 39562, 291, 458, 5646, 321, 445, 632, 257, 2211, 7838, 11, 457, 436, 909, 12914, 39562, 370, 12914, 39562, 51518], "temperature": 0.0, "avg_logprob": -0.45886307670956566, "compression_ratio": 1.7239819004524888, "no_speech_prob": 1.834258364397101e-05}, {"id": 1007, "seek": 477170, "start": 4795.42, "end": 4799.42, "text": " Literally means take the edge and reflect it your padding", "tokens": [51550, 23768, 1355, 747, 264, 4691, 293, 5031, 309, 428, 39562, 51750], "temperature": 0.0, "avg_logprob": -0.45886307670956566, "compression_ratio": 1.7239819004524888, "no_speech_prob": 1.834258364397101e-05}, {"id": 1008, "seek": 479942, "start": 4800.42, "end": 4803.86, "text": " I've written that for you because there isn't one", "tokens": [50414, 286, 600, 3720, 300, 337, 291, 570, 456, 1943, 380, 472, 50586], "temperature": 0.0, "avg_logprob": -0.2839058362520658, "compression_ratio": 1.7801724137931034, "no_speech_prob": 5.507596597453812e-06}, {"id": 1009, "seek": 479942, "start": 4804.9, "end": 4810.38, "text": " But you may find it interesting to look at this because this is like one of the simplest examples of a custom layer", "tokens": [50638, 583, 291, 815, 915, 309, 1880, 281, 574, 412, 341, 570, 341, 307, 411, 472, 295, 264, 22811, 5110, 295, 257, 2375, 4583, 50912], "temperature": 0.0, "avg_logprob": -0.2839058362520658, "compression_ratio": 1.7801724137931034, "no_speech_prob": 5.507596597453812e-06}, {"id": 1010, "seek": 479942, "start": 4810.46, "end": 4816.18, "text": " All right, so we're going to be using custom layers more and more and so I don't want you to be afraid of them", "tokens": [50916, 1057, 558, 11, 370, 321, 434, 516, 281, 312, 1228, 2375, 7914, 544, 293, 544, 293, 370, 286, 500, 380, 528, 291, 281, 312, 4638, 295, 552, 51202], "temperature": 0.0, "avg_logprob": -0.2839058362520658, "compression_ratio": 1.7801724137931034, "no_speech_prob": 5.507596597453812e-06}, {"id": 1011, "seek": 479942, "start": 4816.74, "end": 4820.9, "text": " So a custom layer in Keras is a Python class", "tokens": [51230, 407, 257, 2375, 4583, 294, 591, 6985, 307, 257, 15329, 1508, 51438], "temperature": 0.0, "avg_logprob": -0.2839058362520658, "compression_ratio": 1.7801724137931034, "no_speech_prob": 5.507596597453812e-06}, {"id": 1012, "seek": 479942, "start": 4820.9800000000005, "end": 4824.66, "text": " So if you haven't done that as I mentioned before for the class started if you haven't done", "tokens": [51442, 407, 498, 291, 2378, 380, 1096, 300, 382, 286, 2835, 949, 337, 264, 1508, 1409, 498, 291, 2378, 380, 1096, 51626], "temperature": 0.0, "avg_logprob": -0.2839058362520658, "compression_ratio": 1.7801724137931034, "no_speech_prob": 5.507596597453812e-06}, {"id": 1013, "seek": 482466, "start": 4825.42, "end": 4830.26, "text": " OO programming in Python now's a good time to go and look at some tutorials because we're going to be doing", "tokens": [50402, 422, 46, 9410, 294, 15329, 586, 311, 257, 665, 565, 281, 352, 293, 574, 412, 512, 17616, 570, 321, 434, 516, 281, 312, 884, 50644], "temperature": 0.0, "avg_logprob": -0.3698598480224609, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00029136714874766767}, {"id": 1014, "seek": 482466, "start": 4830.54, "end": 4835.9, "text": " Quite a lot of it take leave a pie torch pie torch absolutely relies on it, so we're going to create a class", "tokens": [50658, 20464, 257, 688, 295, 309, 747, 1856, 257, 1730, 27822, 1730, 27822, 3122, 30910, 322, 309, 11, 370, 321, 434, 516, 281, 1884, 257, 1508, 50926], "temperature": 0.0, "avg_logprob": -0.3698598480224609, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00029136714874766767}, {"id": 1015, "seek": 482466, "start": 4836.9, "end": 4839.099999999999, "text": " it has to inherit from layer and", "tokens": [50976, 309, 575, 281, 21389, 490, 4583, 293, 51086], "temperature": 0.0, "avg_logprob": -0.3698598480224609, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00029136714874766767}, {"id": 1016, "seek": 482466, "start": 4840.58, "end": 4843.3, "text": " Python this is how you can create a constructor", "tokens": [51160, 15329, 341, 307, 577, 291, 393, 1884, 257, 47479, 51296], "temperature": 0.0, "avg_logprob": -0.3698598480224609, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00029136714874766767}, {"id": 1017, "seek": 482466, "start": 4844.139999999999, "end": 4852.0, "text": " Python's always syntax is really gross you have to use this special weird custom name thing which happens to be the constructor", "tokens": [51338, 15329, 311, 1009, 28431, 307, 534, 11367, 291, 362, 281, 764, 341, 2121, 3657, 2375, 1315, 551, 597, 2314, 281, 312, 264, 47479, 51731], "temperature": 0.0, "avg_logprob": -0.3698598480224609, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.00029136714874766767}, {"id": 1018, "seek": 485200, "start": 4853.0, "end": 4859.96, "text": " Every single damn thing inside a class you have to manually type out self comma as the first parameter if you forget you'll get stupid errors", "tokens": [50414, 2048, 2167, 8151, 551, 1854, 257, 1508, 291, 362, 281, 16945, 2010, 484, 2698, 22117, 382, 264, 700, 13075, 498, 291, 2870, 291, 603, 483, 6631, 13603, 50762], "temperature": 0.0, "avg_logprob": -0.31500709265993354, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.00031015160493552685}, {"id": 1019, "seek": 485200, "start": 4860.56, "end": 4862.56, "text": " Sorry, it's not my fault", "tokens": [50792, 4919, 11, 309, 311, 406, 452, 7441, 50892], "temperature": 0.0, "avg_logprob": -0.31500709265993354, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.00031015160493552685}, {"id": 1020, "seek": 485200, "start": 4862.92, "end": 4865.92, "text": " And then in the constructor for a layer", "tokens": [50910, 400, 550, 294, 264, 47479, 337, 257, 4583, 51060], "temperature": 0.0, "avg_logprob": -0.31500709265993354, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.00031015160493552685}, {"id": 1021, "seek": 485200, "start": 4866.2, "end": 4871.84, "text": " This is basically a way you just save away any of the information you were given so in this case you need you've said that", "tokens": [51074, 639, 307, 1936, 257, 636, 291, 445, 3155, 1314, 604, 295, 264, 1589, 291, 645, 2212, 370, 294, 341, 1389, 291, 643, 291, 600, 848, 300, 51356], "temperature": 0.0, "avg_logprob": -0.31500709265993354, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.00031015160493552685}, {"id": 1022, "seek": 485200, "start": 4871.84, "end": 4876.56, "text": " I want this much padding so you just have to save that somewhere say I need this much padding", "tokens": [51356, 286, 528, 341, 709, 39562, 370, 291, 445, 362, 281, 3155, 300, 4079, 584, 286, 643, 341, 709, 39562, 51592], "temperature": 0.0, "avg_logprob": -0.31500709265993354, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.00031015160493552685}, {"id": 1023, "seek": 485200, "start": 4877.24, "end": 4881.6, "text": " And then you need to do two things in every Keras custom layer", "tokens": [51626, 400, 550, 291, 643, 281, 360, 732, 721, 294, 633, 591, 6985, 2375, 4583, 51844], "temperature": 0.0, "avg_logprob": -0.31500709265993354, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.00031015160493552685}, {"id": 1024, "seek": 488200, "start": 4882.0, "end": 4885.8, "text": " One is you have to define something called get output shape for", "tokens": [50364, 1485, 307, 291, 362, 281, 6964, 746, 1219, 483, 5598, 3909, 337, 50554], "temperature": 0.0, "avg_logprob": -0.30123161783023755, "compression_ratio": 1.8805970149253732, "no_speech_prob": 2.885676803998649e-05}, {"id": 1025, "seek": 488200, "start": 4886.76, "end": 4888.76, "text": " That is going to pass in", "tokens": [50602, 663, 307, 516, 281, 1320, 294, 50702], "temperature": 0.0, "avg_logprob": -0.30123161783023755, "compression_ratio": 1.8805970149253732, "no_speech_prob": 2.885676803998649e-05}, {"id": 1026, "seek": 488200, "start": 4889.4, "end": 4892.68, "text": " The shape of an input and you have to return", "tokens": [50734, 440, 3909, 295, 364, 4846, 293, 291, 362, 281, 2736, 50898], "temperature": 0.0, "avg_logprob": -0.30123161783023755, "compression_ratio": 1.8805970149253732, "no_speech_prob": 2.885676803998649e-05}, {"id": 1027, "seek": 488200, "start": 4893.0, "end": 4899.12, "text": " What is the shape of the output that that would create so in this case if s is the shape of the input?", "tokens": [50914, 708, 307, 264, 3909, 295, 264, 5598, 300, 300, 576, 1884, 370, 294, 341, 1389, 498, 262, 307, 264, 3909, 295, 264, 4846, 30, 51220], "temperature": 0.0, "avg_logprob": -0.30123161783023755, "compression_ratio": 1.8805970149253732, "no_speech_prob": 2.885676803998649e-05}, {"id": 1028, "seek": 488200, "start": 4899.4, "end": 4902.44, "text": " then the output is going to be the same batch size and", "tokens": [51234, 550, 264, 5598, 307, 516, 281, 312, 264, 912, 15245, 2744, 293, 51386], "temperature": 0.0, "avg_logprob": -0.30123161783023755, "compression_ratio": 1.8805970149253732, "no_speech_prob": 2.885676803998649e-05}, {"id": 1029, "seek": 488200, "start": 4903.24, "end": 4905.36, "text": " the same number of channels and", "tokens": [51426, 264, 912, 1230, 295, 9235, 293, 51532], "temperature": 0.0, "avg_logprob": -0.30123161783023755, "compression_ratio": 1.8805970149253732, "no_speech_prob": 2.885676803998649e-05}, {"id": 1030, "seek": 488200, "start": 4905.88, "end": 4908.52, "text": " Then we're going to add in twice the amount of padding", "tokens": [51558, 1396, 321, 434, 516, 281, 909, 294, 6091, 264, 2372, 295, 39562, 51690], "temperature": 0.0, "avg_logprob": -0.30123161783023755, "compression_ratio": 1.8805970149253732, "no_speech_prob": 2.885676803998649e-05}, {"id": 1031, "seek": 490852, "start": 4909.040000000001, "end": 4912.52, "text": " Both the rows and columns, but this is going to tell it", "tokens": [50390, 6767, 264, 13241, 293, 13766, 11, 457, 341, 307, 516, 281, 980, 309, 50564], "temperature": 0.0, "avg_logprob": -0.3129130344764859, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0002341351064387709}, {"id": 1032, "seek": 490852, "start": 4913.080000000001, "end": 4919.120000000001, "text": " Because remember one of the cool things about Keras is like you just check the layers on top of each other and it magically knows", "tokens": [50592, 1436, 1604, 472, 295, 264, 1627, 721, 466, 591, 6985, 307, 411, 291, 445, 1520, 264, 7914, 322, 1192, 295, 1184, 661, 293, 309, 39763, 3255, 50894], "temperature": 0.0, "avg_logprob": -0.3129130344764859, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0002341351064387709}, {"id": 1033, "seek": 490852, "start": 4919.320000000001, "end": 4925.92, "text": " How big or the intermediate things are it magically knows because every layer has this thing defined. That's how it works", "tokens": [50904, 1012, 955, 420, 264, 19376, 721, 366, 309, 39763, 3255, 570, 633, 4583, 575, 341, 551, 7642, 13, 663, 311, 577, 309, 1985, 51234], "temperature": 0.0, "avg_logprob": -0.3129130344764859, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0002341351064387709}, {"id": 1034, "seek": 490852, "start": 4928.160000000001, "end": 4930.88, "text": " The second thing you have to define is something called call and", "tokens": [51346, 440, 1150, 551, 291, 362, 281, 6964, 307, 746, 1219, 818, 293, 51482], "temperature": 0.0, "avg_logprob": -0.3129130344764859, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0002341351064387709}, {"id": 1035, "seek": 490852, "start": 4931.68, "end": 4935.92, "text": " Call is the thing which will get your layer data, and you have to return", "tokens": [51522, 7807, 307, 264, 551, 597, 486, 483, 428, 4583, 1412, 11, 293, 291, 362, 281, 2736, 51734], "temperature": 0.0, "avg_logprob": -0.3129130344764859, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.0002341351064387709}, {"id": 1036, "seek": 493592, "start": 4936.92, "end": 4941.32, "text": " Whatever your layer does right and in our case we want to", "tokens": [50414, 8541, 428, 4583, 775, 558, 293, 294, 527, 1389, 321, 528, 281, 50634], "temperature": 0.0, "avg_logprob": -0.4116973876953125, "compression_ratio": 1.5380710659898478, "no_speech_prob": 0.00020988019241485745}, {"id": 1037, "seek": 493592, "start": 4942.12, "end": 4946.78, "text": " Cause cause it to add reflection padding and in this case", "tokens": [50674, 10865, 3082, 309, 281, 909, 12914, 39562, 293, 294, 341, 1389, 50907], "temperature": 0.0, "avg_logprob": -0.4116973876953125, "compression_ratio": 1.5380710659898478, "no_speech_prob": 0.00020988019241485745}, {"id": 1038, "seek": 493592, "start": 4947.28, "end": 4951.4, "text": " So happens that tensorflow has something built in for that called TF dot pad", "tokens": [50932, 407, 2314, 300, 40863, 10565, 575, 746, 3094, 294, 337, 300, 1219, 40964, 5893, 6887, 51138], "temperature": 0.0, "avg_logprob": -0.4116973876953125, "compression_ratio": 1.5380710659898478, "no_speech_prob": 0.00020988019241485745}, {"id": 1039, "seek": 493592, "start": 4952.8, "end": 4954.8, "text": " Obviously generally it's nice to create", "tokens": [51208, 7580, 5101, 309, 311, 1481, 281, 1884, 51308], "temperature": 0.0, "avg_logprob": -0.4116973876953125, "compression_ratio": 1.5380710659898478, "no_speech_prob": 0.00020988019241485745}, {"id": 1040, "seek": 493592, "start": 4955.88, "end": 4959.68, "text": " Keras layers that would work with both the ano and tensorflow backends", "tokens": [51362, 591, 6985, 7914, 300, 576, 589, 365, 1293, 264, 19816, 293, 40863, 10565, 646, 2581, 51552], "temperature": 0.0, "avg_logprob": -0.4116973876953125, "compression_ratio": 1.5380710659898478, "no_speech_prob": 0.00020988019241485745}, {"id": 1041, "seek": 495968, "start": 4960.16, "end": 4963.0, "text": " By using that capital K dot notation", "tokens": [50388, 3146, 1228, 300, 4238, 591, 5893, 24657, 50530], "temperature": 0.0, "avg_logprob": -0.31366589425624103, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.004538320936262608}, {"id": 1042, "seek": 495968, "start": 4963.280000000001, "end": 4969.52, "text": " But in this case the ano didn't have anything obvious that it is easily and since it was just for our class", "tokens": [50544, 583, 294, 341, 1389, 264, 19816, 994, 380, 362, 1340, 6322, 300, 309, 307, 3612, 293, 1670, 309, 390, 445, 337, 527, 1508, 50856], "temperature": 0.0, "avg_logprob": -0.31366589425624103, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.004538320936262608}, {"id": 1043, "seek": 495968, "start": 4969.52, "end": 4971.52, "text": " I just decided just to make it tensorflow", "tokens": [50856, 286, 445, 3047, 445, 281, 652, 309, 40863, 10565, 50956], "temperature": 0.0, "avg_logprob": -0.31366589425624103, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.004538320936262608}, {"id": 1044, "seek": 495968, "start": 4971.92, "end": 4973.12, "text": " Okay", "tokens": [50976, 1033, 51036], "temperature": 0.0, "avg_logprob": -0.31366589425624103, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.004538320936262608}, {"id": 1045, "seek": 495968, "start": 4973.12, "end": 4975.12, "text": " So here is a complete", "tokens": [51036, 407, 510, 307, 257, 3566, 51136], "temperature": 0.0, "avg_logprob": -0.31366589425624103, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.004538320936262608}, {"id": 1046, "seek": 495968, "start": 4975.56, "end": 4980.58, "text": " Layer I can now use that layer in a network definition like this", "tokens": [51158, 35166, 286, 393, 586, 764, 300, 4583, 294, 257, 3209, 7123, 411, 341, 51409], "temperature": 0.0, "avg_logprob": -0.31366589425624103, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.004538320936262608}, {"id": 1047, "seek": 495968, "start": 4981.4400000000005, "end": 4983.4400000000005, "text": " I can call dot predict", "tokens": [51452, 286, 393, 818, 5893, 6069, 51552], "temperature": 0.0, "avg_logprob": -0.31366589425624103, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.004538320936262608}, {"id": 1048, "seek": 495968, "start": 4983.96, "end": 4985.96, "text": " which will take an input and", "tokens": [51578, 597, 486, 747, 364, 4846, 293, 51678], "temperature": 0.0, "avg_logprob": -0.31366589425624103, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.004538320936262608}, {"id": 1049, "seek": 498596, "start": 4986.76, "end": 4992.36, "text": " Turn it into you can see that the bird now has the left and right sides here have been", "tokens": [50404, 7956, 309, 666, 291, 393, 536, 300, 264, 5255, 586, 575, 264, 1411, 293, 558, 4881, 510, 362, 668, 50684], "temperature": 0.0, "avg_logprob": -0.285778598508973, "compression_ratio": 1.632183908045977, "no_speech_prob": 7.141826790757477e-05}, {"id": 1050, "seek": 498596, "start": 4993.36, "end": 4994.68, "text": " reflected", "tokens": [50734, 15502, 50800], "temperature": 0.0, "avg_logprob": -0.285778598508973, "compression_ratio": 1.632183908045977, "no_speech_prob": 7.141826790757477e-05}, {"id": 1051, "seek": 498596, "start": 4994.68, "end": 4996.68, "text": " Okay, so", "tokens": [50800, 1033, 11, 370, 50900], "temperature": 0.0, "avg_logprob": -0.285778598508973, "compression_ratio": 1.632183908045977, "no_speech_prob": 7.141826790757477e-05}, {"id": 1052, "seek": 498596, "start": 4997.4800000000005, "end": 5002.24, "text": " That is there for you to use because in the supplementary material for the paper", "tokens": [50940, 663, 307, 456, 337, 291, 281, 764, 570, 294, 264, 15436, 822, 2527, 337, 264, 3035, 51178], "temperature": 0.0, "avg_logprob": -0.285778598508973, "compression_ratio": 1.632183908045977, "no_speech_prob": 7.141826790757477e-05}, {"id": 1053, "seek": 498596, "start": 5004.0, "end": 5010.16, "text": " They add that they add spatial reflection padding the beginning of the network and they add a lot", "tokens": [51266, 814, 909, 300, 436, 909, 23598, 12914, 39562, 264, 2863, 295, 264, 3209, 293, 436, 909, 257, 688, 51574], "temperature": 0.0, "avg_logprob": -0.285778598508973, "compression_ratio": 1.632183908045977, "no_speech_prob": 7.141826790757477e-05}, {"id": 1054, "seek": 501016, "start": 5010.92, "end": 5012.76, "text": " 40 by 40 and", "tokens": [50402, 3356, 538, 3356, 293, 50494], "temperature": 0.0, "avg_logprob": -0.29105266657742584, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00011774402810260653}, {"id": 1055, "seek": 501016, "start": 5012.76, "end": 5020.32, "text": " The reason they add a lot is because they mentioned in the supplementary material that they don't want to use", "tokens": [50494, 440, 1778, 436, 909, 257, 688, 307, 570, 436, 2835, 294, 264, 15436, 822, 2527, 300, 436, 500, 380, 528, 281, 764, 50872], "temperature": 0.0, "avg_logprob": -0.29105266657742584, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00011774402810260653}, {"id": 1056, "seek": 501016, "start": 5023.44, "end": 5024.44, "text": " Same", "tokens": [51028, 10635, 51078], "temperature": 0.0, "avg_logprob": -0.29105266657742584, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00011774402810260653}, {"id": 1057, "seek": 501016, "start": 5024.44, "end": 5032.16, "text": " Convolutions they want to use valid convolutions in their computation because if you add any black borders during those computation steps it", "tokens": [51078, 2656, 85, 15892, 436, 528, 281, 764, 7363, 3754, 15892, 294, 641, 24903, 570, 498, 291, 909, 604, 2211, 16287, 1830, 729, 24903, 4439, 309, 51464], "temperature": 0.0, "avg_logprob": -0.29105266657742584, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00011774402810260653}, {"id": 1058, "seek": 501016, "start": 5032.5599999999995, "end": 5039.28, "text": " Creates weird artifacts on the edges of the images, so you'll see that through this computation of all their residual blocks", "tokens": [51484, 11972, 279, 3657, 24617, 322, 264, 8819, 295, 264, 5267, 11, 370, 291, 603, 536, 300, 807, 341, 24903, 295, 439, 641, 27980, 8474, 51820], "temperature": 0.0, "avg_logprob": -0.29105266657742584, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00011774402810260653}, {"id": 1059, "seek": 503928, "start": 5039.759999999999, "end": 5047.5199999999995, "text": " The size gets smaller by 4 each time and that's because these are valid convolutions, so that's why they have to add", "tokens": [50388, 440, 2744, 2170, 4356, 538, 1017, 1184, 565, 293, 300, 311, 570, 613, 366, 7363, 3754, 15892, 11, 370, 300, 311, 983, 436, 362, 281, 909, 50776], "temperature": 0.0, "avg_logprob": -0.3182529302743765, "compression_ratio": 1.5679611650485437, "no_speech_prob": 4.3318879761500284e-05}, {"id": 1060, "seek": 503928, "start": 5048.4, "end": 5050.32, "text": " padding to the start", "tokens": [50820, 39562, 281, 264, 722, 50916], "temperature": 0.0, "avg_logprob": -0.3182529302743765, "compression_ratio": 1.5679611650485437, "no_speech_prob": 4.3318879761500284e-05}, {"id": 1061, "seek": 503928, "start": 5050.32, "end": 5054.12, "text": " So that these steps don't cause the image to become too small", "tokens": [50916, 407, 300, 613, 4439, 500, 380, 3082, 264, 3256, 281, 1813, 886, 1359, 51106], "temperature": 0.0, "avg_logprob": -0.3182529302743765, "compression_ratio": 1.5679611650485437, "no_speech_prob": 4.3318879761500284e-05}, {"id": 1062, "seek": 503928, "start": 5055.8, "end": 5059.36, "text": " So this section here should look very familiar", "tokens": [51190, 407, 341, 3541, 510, 820, 574, 588, 4963, 51368], "temperature": 0.0, "avg_logprob": -0.3182529302743765, "compression_ratio": 1.5679611650485437, "no_speech_prob": 4.3318879761500284e-05}, {"id": 1063, "seek": 503928, "start": 5060.759999999999, "end": 5064.759999999999, "text": " Because it's the same as our app sampling network a bunch of residual blocks", "tokens": [51438, 1436, 309, 311, 264, 912, 382, 527, 724, 21179, 3209, 257, 3840, 295, 27980, 8474, 51638], "temperature": 0.0, "avg_logprob": -0.3182529302743765, "compression_ratio": 1.5679611650485437, "no_speech_prob": 4.3318879761500284e-05}, {"id": 1064, "seek": 506476, "start": 5065.76, "end": 5074.0, "text": " To D convolutions and one 9 by 9 convolution, right so this is identical so you can copy it", "tokens": [50414, 1407, 413, 3754, 15892, 293, 472, 1722, 538, 1722, 45216, 11, 558, 370, 341, 307, 14800, 370, 291, 393, 5055, 309, 50826], "temperature": 0.0, "avg_logprob": -0.40662779989121833, "compression_ratio": 1.6875, "no_speech_prob": 3.8830985431559384e-05}, {"id": 1065, "seek": 506476, "start": 5076.16, "end": 5079.52, "text": " This is the new bit right and so", "tokens": [50934, 639, 307, 264, 777, 857, 558, 293, 370, 51102], "temperature": 0.0, "avg_logprob": -0.40662779989121833, "compression_ratio": 1.6875, "no_speech_prob": 3.8830985431559384e-05}, {"id": 1066, "seek": 506476, "start": 5080.68, "end": 5085.76, "text": " Why do we have we've already talked about why we have this 9 by 9 conv, but why do we have these?", "tokens": [51160, 1545, 360, 321, 362, 321, 600, 1217, 2825, 466, 983, 321, 362, 341, 1722, 538, 1722, 3754, 11, 457, 983, 360, 321, 362, 613, 30, 51414], "temperature": 0.0, "avg_logprob": -0.40662779989121833, "compression_ratio": 1.6875, "no_speech_prob": 3.8830985431559384e-05}, {"id": 1067, "seek": 506476, "start": 5086.96, "end": 5091.4400000000005, "text": " down sampling convolutions to start with we start with an image up here of", "tokens": [51474, 760, 21179, 3754, 15892, 281, 722, 365, 321, 722, 365, 364, 3256, 493, 510, 295, 51698], "temperature": 0.0, "avg_logprob": -0.40662779989121833, "compression_ratio": 1.6875, "no_speech_prob": 3.8830985431559384e-05}, {"id": 1068, "seek": 509144, "start": 5091.639999999999, "end": 5097.219999999999, "text": " 336 by 336 and we have its size and then we have its size again", "tokens": [50374, 805, 11309, 538, 805, 11309, 293, 321, 362, 1080, 2744, 293, 550, 321, 362, 1080, 2744, 797, 50653], "temperature": 0.0, "avg_logprob": -0.315740405811983, "compression_ratio": 1.707182320441989, "no_speech_prob": 0.0008969338377937675}, {"id": 1069, "seek": 509144, "start": 5098.5199999999995, "end": 5100.5199999999995, "text": " Why do we do that?", "tokens": [50718, 1545, 360, 321, 360, 300, 30, 50818], "temperature": 0.0, "avg_logprob": -0.315740405811983, "compression_ratio": 1.707182320441989, "no_speech_prob": 0.0008969338377937675}, {"id": 1070, "seek": 509144, "start": 5101.16, "end": 5103.28, "text": " Like the reason we do that", "tokens": [50850, 1743, 264, 1778, 321, 360, 300, 50956], "temperature": 0.0, "avg_logprob": -0.315740405811983, "compression_ratio": 1.707182320441989, "no_speech_prob": 0.0008969338377937675}, {"id": 1071, "seek": 509144, "start": 5104.12, "end": 5108.4, "text": " Is that as I mentioned earlier we want to do our computation?", "tokens": [50998, 1119, 300, 382, 286, 2835, 3071, 321, 528, 281, 360, 527, 24903, 30, 51212], "temperature": 0.0, "avg_logprob": -0.315740405811983, "compression_ratio": 1.707182320441989, "no_speech_prob": 0.0008969338377937675}, {"id": 1072, "seek": 509144, "start": 5109.16, "end": 5111.04, "text": " at a lower resolution", "tokens": [51250, 412, 257, 3126, 8669, 51344], "temperature": 0.0, "avg_logprob": -0.315740405811983, "compression_ratio": 1.707182320441989, "no_speech_prob": 0.0008969338377937675}, {"id": 1073, "seek": 509144, "start": 5111.04, "end": 5117.799999999999, "text": " Because it allows us to have a larger receptive field and it allows us to do less computation, so this", "tokens": [51344, 1436, 309, 4045, 505, 281, 362, 257, 4833, 45838, 2519, 293, 309, 4045, 505, 281, 360, 1570, 24903, 11, 370, 341, 51682], "temperature": 0.0, "avg_logprob": -0.315740405811983, "compression_ratio": 1.707182320441989, "no_speech_prob": 0.0008969338377937675}, {"id": 1074, "seek": 509144, "start": 5118.5599999999995, "end": 5120.16, "text": " this pattern", "tokens": [51720, 341, 5102, 51800], "temperature": 0.0, "avg_logprob": -0.315740405811983, "compression_ratio": 1.707182320441989, "no_speech_prob": 0.0008969338377937675}, {"id": 1075, "seek": 512016, "start": 5120.16, "end": 5122.16, "text": " where", "tokens": [50364, 689, 50464], "temperature": 0.0, "avg_logprob": -0.29164772033691405, "compression_ratio": 1.9417040358744395, "no_speech_prob": 6.302735710050911e-05}, {"id": 1076, "seek": 512016, "start": 5122.28, "end": 5128.08, "text": " It's like reflective right like the last thing is the same as the set the top thing the second last thing", "tokens": [50470, 467, 311, 411, 28931, 558, 411, 264, 1036, 551, 307, 264, 912, 382, 264, 992, 264, 1192, 551, 264, 1150, 1036, 551, 50760], "temperature": 0.0, "avg_logprob": -0.29164772033691405, "compression_ratio": 1.9417040358744395, "no_speech_prob": 6.302735710050911e-05}, {"id": 1077, "seek": 512016, "start": 5128.08, "end": 5132.16, "text": " It's the same as the second thing you can see it's like a reflection symmetric", "tokens": [50760, 467, 311, 264, 912, 382, 264, 1150, 551, 291, 393, 536, 309, 311, 411, 257, 12914, 32330, 50964], "temperature": 0.0, "avg_logprob": -0.29164772033691405, "compression_ratio": 1.9417040358744395, "no_speech_prob": 6.302735710050911e-05}, {"id": 1078, "seek": 512016, "start": 5132.5599999999995, "end": 5136.72, "text": " It's really really common in generative models is first of all to take your object", "tokens": [50984, 467, 311, 534, 534, 2689, 294, 1337, 1166, 5245, 307, 700, 295, 439, 281, 747, 428, 2657, 51192], "temperature": 0.0, "avg_logprob": -0.29164772033691405, "compression_ratio": 1.9417040358744395, "no_speech_prob": 6.302735710050911e-05}, {"id": 1079, "seek": 512016, "start": 5137.88, "end": 5139.639999999999, "text": " downsample it", "tokens": [51250, 760, 19988, 781, 309, 51338], "temperature": 0.0, "avg_logprob": -0.29164772033691405, "compression_ratio": 1.9417040358744395, "no_speech_prob": 6.302735710050911e-05}, {"id": 1080, "seek": 512016, "start": 5139.639999999999, "end": 5146.32, "text": " Increasing the number of channels at the same time so you're increasing the receptive field you're creating more and more complex representations", "tokens": [51338, 30367, 3349, 264, 1230, 295, 9235, 412, 264, 912, 565, 370, 291, 434, 5662, 264, 45838, 2519, 291, 434, 4084, 544, 293, 544, 3997, 33358, 51672], "temperature": 0.0, "avg_logprob": -0.29164772033691405, "compression_ratio": 1.9417040358744395, "no_speech_prob": 6.302735710050911e-05}, {"id": 1081, "seek": 514632, "start": 5146.599999999999, "end": 5152.38, "text": " You then do a bunch of computation on those representations, and then at the end you up sample again", "tokens": [50378, 509, 550, 360, 257, 3840, 295, 24903, 322, 729, 33358, 11, 293, 550, 412, 264, 917, 291, 493, 6889, 797, 50667], "temperature": 0.0, "avg_logprob": -0.34243418719317464, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.0002453687193337828}, {"id": 1082, "seek": 514632, "start": 5152.5199999999995, "end": 5157.2, "text": " So you're going to see this pattern all the time, and so that's why I wanted you guys to", "tokens": [50674, 407, 291, 434, 516, 281, 536, 341, 5102, 439, 264, 565, 11, 293, 370, 300, 311, 983, 286, 1415, 291, 1074, 281, 50908], "temperature": 0.0, "avg_logprob": -0.34243418719317464, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.0002453687193337828}, {"id": 1083, "seek": 514632, "start": 5158.04, "end": 5160.04, "text": " Implement this yourself", "tokens": [50950, 4331, 43704, 341, 1803, 51050], "temperature": 0.0, "avg_logprob": -0.34243418719317464, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.0002453687193337828}, {"id": 1084, "seek": 514632, "start": 5160.719999999999, "end": 5162.719999999999, "text": " Okay, so", "tokens": [51084, 1033, 11, 370, 51184], "temperature": 0.0, "avg_logprob": -0.34243418719317464, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.0002453687193337828}, {"id": 1085, "seek": 514632, "start": 5163.44, "end": 5168.0, "text": " There's that right that's the last major piece of your homework", "tokens": [51220, 821, 311, 300, 558, 300, 311, 264, 1036, 2563, 2522, 295, 428, 14578, 51448], "temperature": 0.0, "avg_logprob": -0.34243418719317464, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.0002453687193337828}, {"id": 1086, "seek": 516800, "start": 5168.16, "end": 5171.96, "text": " There's questions about what is stride equals one half mean", "tokens": [50372, 821, 311, 1651, 466, 437, 307, 1056, 482, 6915, 472, 1922, 914, 50562], "temperature": 0.0, "avg_logprob": -0.4284135715381519, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.0001535617047920823}, {"id": 1087, "seek": 516800, "start": 5172.56, "end": 5176.28, "text": " That's exactly the same as deconvolution strive to", "tokens": [50592, 663, 311, 2293, 264, 912, 382, 979, 266, 85, 3386, 23829, 281, 50778], "temperature": 0.0, "avg_logprob": -0.4284135715381519, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.0001535617047920823}, {"id": 1088, "seek": 516800, "start": 5176.92, "end": 5178.92, "text": " so I remember I mentioned earlier that", "tokens": [50810, 370, 286, 1604, 286, 2835, 3071, 300, 50910], "temperature": 0.0, "avg_logprob": -0.4284135715381519, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.0001535617047920823}, {"id": 1089, "seek": 516800, "start": 5180.12, "end": 5182.12, "text": " another name for", "tokens": [50970, 1071, 1315, 337, 51070], "temperature": 0.0, "avg_logprob": -0.4284135715381519, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.0001535617047920823}, {"id": 1090, "seek": 516800, "start": 5182.52, "end": 5184.08, "text": " deconvolution is", "tokens": [51090, 979, 266, 85, 3386, 307, 51168], "temperature": 0.0, "avg_logprob": -0.4284135715381519, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.0001535617047920823}, {"id": 1091, "seek": 516800, "start": 5184.08, "end": 5186.08, "text": " fractionally strided convolution", "tokens": [51168, 14135, 379, 1056, 2112, 45216, 51268], "temperature": 0.0, "avg_logprob": -0.4284135715381519, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.0001535617047920823}, {"id": 1092, "seek": 516800, "start": 5187.36, "end": 5191.12, "text": " So you can remember that little picture we saw this idea like he puts", "tokens": [51332, 407, 291, 393, 1604, 300, 707, 3036, 321, 1866, 341, 1558, 411, 415, 8137, 51520], "temperature": 0.0, "avg_logprob": -0.4284135715381519, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.0001535617047920823}, {"id": 1093, "seek": 519112, "start": 5191.5599999999995, "end": 5198.04, "text": " Little columns and rows of zeros in between each row and column, so that's we kind of think of it as doing like a", "tokens": [50386, 8022, 13766, 293, 13241, 295, 35193, 294, 1296, 1184, 5386, 293, 7738, 11, 370, 300, 311, 321, 733, 295, 519, 295, 309, 382, 884, 411, 257, 50710], "temperature": 0.0, "avg_logprob": -0.36230602034603254, "compression_ratio": 1.5888324873096447, "no_speech_prob": 0.00023050374875310808}, {"id": 1094, "seek": 519112, "start": 5198.76, "end": 5200.76, "text": " half stride at a time", "tokens": [50746, 1922, 1056, 482, 412, 257, 565, 50846], "temperature": 0.0, "avg_logprob": -0.36230602034603254, "compression_ratio": 1.5888324873096447, "no_speech_prob": 0.00023050374875310808}, {"id": 1095, "seek": 519112, "start": 5204.8, "end": 5208.18, "text": " So that's why yeah, this is exactly what we already have", "tokens": [51048, 407, 300, 311, 983, 1338, 11, 341, 307, 2293, 437, 321, 1217, 362, 51217], "temperature": 0.0, "avg_logprob": -0.36230602034603254, "compression_ratio": 1.5888324873096447, "no_speech_prob": 0.00023050374875310808}, {"id": 1096, "seek": 519112, "start": 5208.88, "end": 5215.2, "text": " I don't think you need to change it at all. I'll accept you'll need to change my same convolutions to valid convolutions", "tokens": [51252, 286, 500, 380, 519, 291, 643, 281, 1319, 309, 412, 439, 13, 286, 603, 3241, 291, 603, 643, 281, 1319, 452, 912, 3754, 15892, 281, 7363, 3754, 15892, 51568], "temperature": 0.0, "avg_logprob": -0.36230602034603254, "compression_ratio": 1.5888324873096447, "no_speech_prob": 0.00023050374875310808}, {"id": 1097, "seek": 521520, "start": 5216.2, "end": 5218.2, "text": " But", "tokens": [50414, 583, 50514], "temperature": 0.0, "avg_logprob": -0.29501166394961775, "compression_ratio": 1.7763157894736843, "no_speech_prob": 3.3736963814590126e-05}, {"id": 1098, "seek": 521520, "start": 5219.0, "end": 5221.0, "text": " This is well worth reading the whole", "tokens": [50554, 639, 307, 731, 3163, 3760, 264, 1379, 50654], "temperature": 0.0, "avg_logprob": -0.29501166394961775, "compression_ratio": 1.7763157894736843, "no_speech_prob": 3.3736963814590126e-05}, {"id": 1099, "seek": 521520, "start": 5222.32, "end": 5224.32, "text": " supplementary material because it really has", "tokens": [50720, 15436, 822, 2527, 570, 309, 534, 575, 50820], "temperature": 0.0, "avg_logprob": -0.29501166394961775, "compression_ratio": 1.7763157894736843, "no_speech_prob": 3.3736963814590126e-05}, {"id": 1100, "seek": 521520, "start": 5224.84, "end": 5231.88, "text": " The details and it's it's so great when a paper has supplementary material like this you'll often find in fact the majority of papers", "tokens": [50846, 440, 4365, 293, 309, 311, 309, 311, 370, 869, 562, 257, 3035, 575, 15436, 822, 2527, 411, 341, 291, 603, 2049, 915, 294, 1186, 264, 6286, 295, 10577, 51198], "temperature": 0.0, "avg_logprob": -0.29501166394961775, "compression_ratio": 1.7763157894736843, "no_speech_prob": 3.3736963814590126e-05}, {"id": 1101, "seek": 521520, "start": 5232.4, "end": 5238.8, "text": " Don't actually tell you the details of how to do what they did and many don't even have code", "tokens": [51224, 1468, 380, 767, 980, 291, 264, 4365, 295, 577, 281, 360, 437, 436, 630, 293, 867, 500, 380, 754, 362, 3089, 51544], "temperature": 0.0, "avg_logprob": -0.29501166394961775, "compression_ratio": 1.7763157894736843, "no_speech_prob": 3.3736963814590126e-05}, {"id": 1102, "seek": 521520, "start": 5239.08, "end": 5244.2, "text": " These guys both have code and supplementary material which makes this absolute a plus better", "tokens": [51558, 1981, 1074, 1293, 362, 3089, 293, 15436, 822, 2527, 597, 1669, 341, 8236, 257, 1804, 1101, 51814], "temperature": 0.0, "avg_logprob": -0.29501166394961775, "compression_ratio": 1.7763157894736843, "no_speech_prob": 3.3736963814590126e-05}, {"id": 1103, "seek": 524520, "start": 5245.4, "end": 5247.4, "text": " Classics works great", "tokens": [50374, 9471, 1167, 1985, 869, 50474], "temperature": 0.0, "avg_logprob": -0.38849492342966907, "compression_ratio": 1.352112676056338, "no_speech_prob": 0.00010889440454775468}, {"id": 1104, "seek": 524520, "start": 5249.2, "end": 5256.36, "text": " Okay, so that is super resolution perceptual losses and so on and so forth", "tokens": [50564, 1033, 11, 370, 300, 307, 1687, 8669, 43276, 901, 15352, 293, 370, 322, 293, 370, 5220, 50922], "temperature": 0.0, "avg_logprob": -0.38849492342966907, "compression_ratio": 1.352112676056338, "no_speech_prob": 0.00010889440454775468}, {"id": 1105, "seek": 524520, "start": 5265.5199999999995, "end": 5267.5199999999995, "text": " Let's make sure I don't have any more slides oh", "tokens": [51380, 961, 311, 652, 988, 286, 500, 380, 362, 604, 544, 9788, 1954, 51480], "temperature": 0.0, "avg_logprob": -0.38849492342966907, "compression_ratio": 1.352112676056338, "no_speech_prob": 0.00010889440454775468}, {"id": 1106, "seek": 524520, "start": 5269.8, "end": 5271.8, "text": " There was one other thing it's going to show you", "tokens": [51594, 821, 390, 472, 661, 551, 309, 311, 516, 281, 855, 291, 51694], "temperature": 0.0, "avg_logprob": -0.38849492342966907, "compression_ratio": 1.352112676056338, "no_speech_prob": 0.00010889440454775468}, {"id": 1107, "seek": 527180, "start": 5271.8, "end": 5273.64, "text": " Um", "tokens": [50364, 3301, 50456], "temperature": 0.0, "avg_logprob": -0.35985870361328126, "compression_ratio": 1.6845238095238095, "no_speech_prob": 6.709209264954552e-05}, {"id": 1108, "seek": 527180, "start": 5273.64, "end": 5275.64, "text": " Which is?", "tokens": [50456, 3013, 307, 30, 50556], "temperature": 0.0, "avg_logprob": -0.35985870361328126, "compression_ratio": 1.6845238095238095, "no_speech_prob": 6.709209264954552e-05}, {"id": 1109, "seek": 527180, "start": 5275.84, "end": 5277.84, "text": " these D convolutions", "tokens": [50566, 613, 413, 3754, 15892, 50666], "temperature": 0.0, "avg_logprob": -0.35985870361328126, "compression_ratio": 1.6845238095238095, "no_speech_prob": 6.709209264954552e-05}, {"id": 1110, "seek": 527180, "start": 5278.2, "end": 5286.0, "text": " Can create some very ugly artifacts, and I can show you some very ugly artifacts because I have some right here", "tokens": [50684, 1664, 1884, 512, 588, 12246, 24617, 11, 293, 286, 393, 855, 291, 512, 588, 12246, 24617, 570, 286, 362, 512, 558, 510, 51074], "temperature": 0.0, "avg_logprob": -0.35985870361328126, "compression_ratio": 1.6845238095238095, "no_speech_prob": 6.709209264954552e-05}, {"id": 1111, "seek": 527180, "start": 5287.52, "end": 5292.72, "text": " You see these you see it on the screen Rachel this checkerboard, okay, this is called a checkerboard pattern", "tokens": [51150, 509, 536, 613, 291, 536, 309, 322, 264, 2568, 14246, 341, 1520, 260, 3787, 11, 1392, 11, 341, 307, 1219, 257, 1520, 260, 3787, 5102, 51410], "temperature": 0.0, "avg_logprob": -0.35985870361328126, "compression_ratio": 1.6845238095238095, "no_speech_prob": 6.709209264954552e-05}, {"id": 1112, "seek": 527180, "start": 5296.56, "end": 5298.84, "text": " The the checkerboard pattern", "tokens": [51602, 440, 264, 1520, 260, 3787, 5102, 51716], "temperature": 0.0, "avg_logprob": -0.35985870361328126, "compression_ratio": 1.6845238095238095, "no_speech_prob": 6.709209264954552e-05}, {"id": 1113, "seek": 529884, "start": 5299.84, "end": 5304.32, "text": " Happens through a very specific reason and I've provided a link to this paper", "tokens": [50414, 7412, 694, 807, 257, 588, 2685, 1778, 293, 286, 600, 5649, 257, 2113, 281, 341, 3035, 50638], "temperature": 0.0, "avg_logprob": -0.316120601835705, "compression_ratio": 1.5116279069767442, "no_speech_prob": 2.078503712255042e-05}, {"id": 1114, "seek": 529884, "start": 5305.84, "end": 5307.84, "text": " It's an online paper", "tokens": [50714, 467, 311, 364, 2950, 3035, 50814], "temperature": 0.0, "avg_logprob": -0.316120601835705, "compression_ratio": 1.5116279069767442, "no_speech_prob": 2.078503712255042e-05}, {"id": 1115, "seek": 529884, "start": 5309.12, "end": 5312.76, "text": " You guys might remember Chris Ola he had a lot of the best", "tokens": [50878, 509, 1074, 1062, 1604, 6688, 422, 875, 415, 632, 257, 688, 295, 264, 1151, 51060], "temperature": 0.0, "avg_logprob": -0.316120601835705, "compression_ratio": 1.5116279069767442, "no_speech_prob": 2.078503712255042e-05}, {"id": 1116, "seek": 529884, "start": 5313.32, "end": 5316.4800000000005, "text": " Kind of learning materials we looked at in part one", "tokens": [51088, 9242, 295, 2539, 5319, 321, 2956, 412, 294, 644, 472, 51246], "temperature": 0.0, "avg_logprob": -0.316120601835705, "compression_ratio": 1.5116279069767442, "no_speech_prob": 2.078503712255042e-05}, {"id": 1117, "seek": 529884, "start": 5316.4800000000005, "end": 5321.72, "text": " He's now got this cool thing for distilled a pub done with some of his colleagues at Google", "tokens": [51246, 634, 311, 586, 658, 341, 1627, 551, 337, 1483, 6261, 257, 1535, 1096, 365, 512, 295, 702, 7734, 412, 3329, 51508], "temperature": 0.0, "avg_logprob": -0.316120601835705, "compression_ratio": 1.5116279069767442, "no_speech_prob": 2.078503712255042e-05}, {"id": 1118, "seek": 529884, "start": 5322.4800000000005, "end": 5324.4800000000005, "text": " And he wrote this thing", "tokens": [51546, 400, 415, 4114, 341, 551, 51646], "temperature": 0.0, "avg_logprob": -0.316120601835705, "compression_ratio": 1.5116279069767442, "no_speech_prob": 2.078503712255042e-05}, {"id": 1119, "seek": 532448, "start": 5325.32, "end": 5330.719999999999, "text": " Discovering why is it that everybody gets these goddamn checkerboard patterns right and", "tokens": [50406, 40386, 278, 983, 307, 309, 300, 2201, 2170, 613, 32951, 1520, 260, 3787, 8294, 558, 293, 50676], "temperature": 0.0, "avg_logprob": -0.353307259388459, "compression_ratio": 1.592964824120603, "no_speech_prob": 4.9859489081427455e-05}, {"id": 1120, "seek": 532448, "start": 5331.4, "end": 5336.2, "text": " What he shows is that it happens because you have", "tokens": [50710, 708, 415, 3110, 307, 300, 309, 2314, 570, 291, 362, 50950], "temperature": 0.0, "avg_logprob": -0.353307259388459, "compression_ratio": 1.592964824120603, "no_speech_prob": 4.9859489081427455e-05}, {"id": 1121, "seek": 532448, "start": 5337.08, "end": 5340.04, "text": " stride to size 3 convolutions", "tokens": [50994, 1056, 482, 281, 2744, 805, 3754, 15892, 51142], "temperature": 0.0, "avg_logprob": -0.353307259388459, "compression_ratio": 1.592964824120603, "no_speech_prob": 4.9859489081427455e-05}, {"id": 1122, "seek": 532448, "start": 5340.04, "end": 5347.959999999999, "text": " Which means that every pair of convolutions sees one pixel twice right so it's like a checkerboard", "tokens": [51142, 3013, 1355, 300, 633, 6119, 295, 3754, 15892, 8194, 472, 19261, 6091, 558, 370, 309, 311, 411, 257, 1520, 260, 3787, 51538], "temperature": 0.0, "avg_logprob": -0.353307259388459, "compression_ratio": 1.592964824120603, "no_speech_prob": 4.9859489081427455e-05}, {"id": 1123, "seek": 532448, "start": 5348.24, "end": 5350.44, "text": " It's just a natural thing that's going to come out", "tokens": [51552, 467, 311, 445, 257, 3303, 551, 300, 311, 516, 281, 808, 484, 51662], "temperature": 0.0, "avg_logprob": -0.353307259388459, "compression_ratio": 1.592964824120603, "no_speech_prob": 4.9859489081427455e-05}, {"id": 1124, "seek": 535044, "start": 5351.32, "end": 5355.719999999999, "text": " So they talk about you know this in some detail and all the kind of things you can do", "tokens": [50408, 407, 436, 751, 466, 291, 458, 341, 294, 512, 2607, 293, 439, 264, 733, 295, 721, 291, 393, 360, 50628], "temperature": 0.0, "avg_logprob": -0.2997778574625651, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.7778460460249335e-05}, {"id": 1125, "seek": 535044, "start": 5356.719999999999, "end": 5358.32, "text": " but in the end", "tokens": [50678, 457, 294, 264, 917, 50758], "temperature": 0.0, "avg_logprob": -0.2997778574625651, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.7778460460249335e-05}, {"id": 1126, "seek": 535044, "start": 5358.32, "end": 5361.4, "text": " They point out two things the first is", "tokens": [50758, 814, 935, 484, 732, 721, 264, 700, 307, 50912], "temperature": 0.0, "avg_logprob": -0.2997778574625651, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.7778460460249335e-05}, {"id": 1127, "seek": 535044, "start": 5362.679999999999, "end": 5364.679999999999, "text": " That you can avoid this", "tokens": [50976, 663, 291, 393, 5042, 341, 51076], "temperature": 0.0, "avg_logprob": -0.2997778574625651, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.7778460460249335e-05}, {"id": 1128, "seek": 535044, "start": 5365.32, "end": 5367.32, "text": " by making it that your", "tokens": [51108, 538, 1455, 309, 300, 428, 51208], "temperature": 0.0, "avg_logprob": -0.2997778574625651, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.7778460460249335e-05}, {"id": 1129, "seek": 535044, "start": 5368.599999999999, "end": 5370.599999999999, "text": " your stride", "tokens": [51272, 428, 1056, 482, 51372], "temperature": 0.0, "avg_logprob": -0.2997778574625651, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.7778460460249335e-05}, {"id": 1130, "seek": 535044, "start": 5371.599999999999, "end": 5375.679999999999, "text": " Divides nicely into your size, so if I change size to four", "tokens": [51422, 413, 1843, 279, 9594, 666, 428, 2744, 11, 370, 498, 286, 1319, 2744, 281, 1451, 51626], "temperature": 0.0, "avg_logprob": -0.2997778574625651, "compression_ratio": 1.5670731707317074, "no_speech_prob": 1.7778460460249335e-05}, {"id": 1131, "seek": 537568, "start": 5376.68, "end": 5378.68, "text": " They've got right so", "tokens": [50414, 814, 600, 658, 558, 370, 50514], "temperature": 0.0, "avg_logprob": -0.333255729675293, "compression_ratio": 1.7831858407079646, "no_speech_prob": 0.00010720799036789685}, {"id": 1132, "seek": 537568, "start": 5379.64, "end": 5381.64, "text": " one thing you could try if", "tokens": [50562, 472, 551, 291, 727, 853, 498, 50662], "temperature": 0.0, "avg_logprob": -0.333255729675293, "compression_ratio": 1.7831858407079646, "no_speech_prob": 0.00010720799036789685}, {"id": 1133, "seek": 537568, "start": 5381.72, "end": 5388.64, "text": " You're getting checkerboard patterns, which you will is make your size three convolutions into size four convolutions", "tokens": [50666, 509, 434, 1242, 1520, 260, 3787, 8294, 11, 597, 291, 486, 307, 652, 428, 2744, 1045, 3754, 15892, 666, 2744, 1451, 3754, 15892, 51012], "temperature": 0.0, "avg_logprob": -0.333255729675293, "compression_ratio": 1.7831858407079646, "no_speech_prob": 0.00010720799036789685}, {"id": 1134, "seek": 537568, "start": 5389.52, "end": 5393.56, "text": " The second thing that he suggests doing is not to use", "tokens": [51056, 440, 1150, 551, 300, 415, 13409, 884, 307, 406, 281, 764, 51258], "temperature": 0.0, "avg_logprob": -0.333255729675293, "compression_ratio": 1.7831858407079646, "no_speech_prob": 0.00010720799036789685}, {"id": 1135, "seek": 537568, "start": 5394.6, "end": 5395.92, "text": " deconvolutions", "tokens": [51310, 979, 266, 85, 15892, 51376], "temperature": 0.0, "avg_logprob": -0.333255729675293, "compression_ratio": 1.7831858407079646, "no_speech_prob": 0.00010720799036789685}, {"id": 1136, "seek": 537568, "start": 5395.92, "end": 5400.400000000001, "text": " Instead of using a deconvolution he suggests first of all doing an up sampling", "tokens": [51376, 7156, 295, 1228, 257, 979, 266, 85, 3386, 415, 13409, 700, 295, 439, 884, 364, 493, 21179, 51600], "temperature": 0.0, "avg_logprob": -0.333255729675293, "compression_ratio": 1.7831858407079646, "no_speech_prob": 0.00010720799036789685}, {"id": 1137, "seek": 537568, "start": 5401.04, "end": 5405.4800000000005, "text": " What happens when you do an up sampling is it's the basically the opposite of max pooling", "tokens": [51632, 708, 2314, 562, 291, 360, 364, 493, 21179, 307, 309, 311, 264, 1936, 264, 6182, 295, 11469, 7005, 278, 51854], "temperature": 0.0, "avg_logprob": -0.333255729675293, "compression_ratio": 1.7831858407079646, "no_speech_prob": 0.00010720799036789685}, {"id": 1138, "seek": 540568, "start": 5405.68, "end": 5412.16, "text": " You take every pixel and you turn it into a 2x2 grid of that exact pixel", "tokens": [50364, 509, 747, 633, 19261, 293, 291, 1261, 309, 666, 257, 568, 87, 17, 10748, 295, 300, 1900, 19261, 50688], "temperature": 0.0, "avg_logprob": -0.32990760307807426, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.0462814063648693e-05}, {"id": 1139, "seek": 540568, "start": 5412.96, "end": 5414.96, "text": " All right, that's called up sampling", "tokens": [50728, 1057, 558, 11, 300, 311, 1219, 493, 21179, 50828], "temperature": 0.0, "avg_logprob": -0.32990760307807426, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.0462814063648693e-05}, {"id": 1140, "seek": 540568, "start": 5415.84, "end": 5422.0, "text": " If you do an up sampling followed by a regular convolution that also gets rid of the checkerboard pattern", "tokens": [50872, 759, 291, 360, 364, 493, 21179, 6263, 538, 257, 3890, 45216, 300, 611, 2170, 3973, 295, 264, 1520, 260, 3787, 5102, 51180], "temperature": 0.0, "avg_logprob": -0.32990760307807426, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.0462814063648693e-05}, {"id": 1141, "seek": 540568, "start": 5422.88, "end": 5424.72, "text": " and as it happens", "tokens": [51224, 293, 382, 309, 2314, 51316], "temperature": 0.0, "avg_logprob": -0.32990760307807426, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.0462814063648693e-05}, {"id": 1142, "seek": 540568, "start": 5424.72, "end": 5426.4800000000005, "text": " Keras has", "tokens": [51316, 591, 6985, 575, 51404], "temperature": 0.0, "avg_logprob": -0.32990760307807426, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.0462814063648693e-05}, {"id": 1143, "seek": 540568, "start": 5426.4800000000005, "end": 5428.4800000000005, "text": " Something to do that", "tokens": [51404, 6595, 281, 360, 300, 51504], "temperature": 0.0, "avg_logprob": -0.32990760307807426, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.0462814063648693e-05}, {"id": 1144, "seek": 540568, "start": 5428.4800000000005, "end": 5430.4800000000005, "text": " Which is called?", "tokens": [51504, 3013, 307, 1219, 30, 51604], "temperature": 0.0, "avg_logprob": -0.32990760307807426, "compression_ratio": 1.4789473684210526, "no_speech_prob": 2.0462814063648693e-05}, {"id": 1145, "seek": 543568, "start": 5435.68, "end": 5437.68, "text": " It's called up sampling 2d", "tokens": [50364, 467, 311, 1219, 493, 21179, 568, 67, 50464], "temperature": 0.0, "avg_logprob": -0.3237708806991577, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.0004238803521730006}, {"id": 1146, "seek": 543568, "start": 5439.4800000000005, "end": 5442.3, "text": " So all this does is kind of the opposite of max pooling", "tokens": [50554, 407, 439, 341, 775, 307, 733, 295, 264, 6182, 295, 11469, 7005, 278, 50695], "temperature": 0.0, "avg_logprob": -0.3237708806991577, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.0004238803521730006}, {"id": 1147, "seek": 543568, "start": 5442.3, "end": 5447.16, "text": " It's going to double the size of your image at which point you can use a standard normal", "tokens": [50695, 467, 311, 516, 281, 3834, 264, 2744, 295, 428, 3256, 412, 597, 935, 291, 393, 764, 257, 3832, 2710, 50938], "temperature": 0.0, "avg_logprob": -0.3237708806991577, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.0004238803521730006}, {"id": 1148, "seek": 543568, "start": 5447.92, "end": 5449.64, "text": " unit strata convolution", "tokens": [50976, 4985, 1056, 3274, 45216, 51062], "temperature": 0.0, "avg_logprob": -0.3237708806991577, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.0004238803521730006}, {"id": 1149, "seek": 543568, "start": 5449.64, "end": 5452.88, "text": " And avoid the other facts so extra credit", "tokens": [51062, 400, 5042, 264, 661, 9130, 370, 2857, 5397, 51224], "temperature": 0.0, "avg_logprob": -0.3237708806991577, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.0004238803521730006}, {"id": 1150, "seek": 543568, "start": 5453.4400000000005, "end": 5459.76, "text": " After you get your network working is to change it to an up sampling and unit strata convolution network", "tokens": [51252, 2381, 291, 483, 428, 3209, 1364, 307, 281, 1319, 309, 281, 364, 493, 21179, 293, 4985, 1056, 3274, 45216, 3209, 51568], "temperature": 0.0, "avg_logprob": -0.3237708806991577, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.0004238803521730006}, {"id": 1151, "seek": 543568, "start": 5461.56, "end": 5464.280000000001, "text": " And see if the checkerboard artifacts go away", "tokens": [51658, 400, 536, 498, 264, 1520, 260, 3787, 24617, 352, 1314, 51794], "temperature": 0.0, "avg_logprob": -0.3237708806991577, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.0004238803521730006}, {"id": 1152, "seek": 546568, "start": 5466.400000000001, "end": 5468.400000000001, "text": " Okay, so that is that", "tokens": [50400, 1033, 11, 370, 300, 307, 300, 50500], "temperature": 0.0, "avg_logprob": -0.3312229156494141, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.8924987671198323e-05}, {"id": 1153, "seek": 546568, "start": 5469.320000000001, "end": 5473.56, "text": " At the very end here. I've got some suggestions for some more things that you can look at", "tokens": [50546, 1711, 264, 588, 917, 510, 13, 286, 600, 658, 512, 13396, 337, 512, 544, 721, 300, 291, 393, 574, 412, 50758], "temperature": 0.0, "avg_logprob": -0.3312229156494141, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.8924987671198323e-05}, {"id": 1154, "seek": 546568, "start": 5474.320000000001, "end": 5476.92, "text": " Although most of those were already in the PowerPoint so", "tokens": [50796, 5780, 881, 295, 729, 645, 1217, 294, 264, 25584, 370, 50926], "temperature": 0.0, "avg_logprob": -0.3312229156494141, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.8924987671198323e-05}, {"id": 1155, "seek": 546568, "start": 5478.04, "end": 5480.04, "text": " Anything else there?", "tokens": [50982, 11998, 1646, 456, 30, 51082], "temperature": 0.0, "avg_logprob": -0.3312229156494141, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.8924987671198323e-05}, {"id": 1156, "seek": 546568, "start": 5480.68, "end": 5482.68, "text": " Okay, so let's move on", "tokens": [51114, 1033, 11, 370, 718, 311, 1286, 322, 51214], "temperature": 0.0, "avg_logprob": -0.3312229156494141, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.8924987671198323e-05}, {"id": 1157, "seek": 546568, "start": 5489.56, "end": 5491.56, "text": " I want to talk about", "tokens": [51558, 286, 528, 281, 751, 466, 51658], "temperature": 0.0, "avg_logprob": -0.3312229156494141, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.8924987671198323e-05}, {"id": 1158, "seek": 546568, "start": 5492.64, "end": 5494.200000000001, "text": " going big", "tokens": [51712, 516, 955, 51790], "temperature": 0.0, "avg_logprob": -0.3312229156494141, "compression_ratio": 1.4550898203592815, "no_speech_prob": 1.8924987671198323e-05}, {"id": 1159, "seek": 549420, "start": 5494.2, "end": 5495.679999999999, "text": " going big", "tokens": [50364, 516, 955, 50438], "temperature": 0.0, "avg_logprob": -0.3105786641438802, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.000107208477857057}, {"id": 1160, "seek": 549420, "start": 5495.679999999999, "end": 5500.12, "text": " Can mean two things of course it does mean we get to say big data", "tokens": [50438, 1664, 914, 732, 721, 295, 1164, 309, 775, 914, 321, 483, 281, 584, 955, 1412, 50660], "temperature": 0.0, "avg_logprob": -0.3105786641438802, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.000107208477857057}, {"id": 1161, "seek": 549420, "start": 5500.72, "end": 5502.72, "text": " Which is important you have to do that?", "tokens": [50690, 3013, 307, 1021, 291, 362, 281, 360, 300, 30, 50790], "temperature": 0.0, "avg_logprob": -0.3105786641438802, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.000107208477857057}, {"id": 1162, "seek": 549420, "start": 5506.12, "end": 5511.36, "text": " I'm very proud that even during the big data thing I never said big data without", "tokens": [50960, 286, 478, 588, 4570, 300, 754, 1830, 264, 955, 1412, 551, 286, 1128, 848, 955, 1412, 1553, 51222], "temperature": 0.0, "avg_logprob": -0.3105786641438802, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.000107208477857057}, {"id": 1163, "seek": 549420, "start": 5512.76, "end": 5515.04, "text": " Saying rude things about the stupid idea of big data", "tokens": [51292, 34087, 18895, 721, 466, 264, 6631, 1558, 295, 955, 1412, 51406], "temperature": 0.0, "avg_logprob": -0.3105786641438802, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.000107208477857057}, {"id": 1164, "seek": 549420, "start": 5516.5199999999995, "end": 5521.04, "text": " Who cares about how big it is but in deep learning you know sometimes we do need to use either", "tokens": [51480, 2102, 12310, 466, 577, 955, 309, 307, 457, 294, 2452, 2539, 291, 458, 2171, 321, 360, 643, 281, 764, 2139, 51706], "temperature": 0.0, "avg_logprob": -0.3105786641438802, "compression_ratio": 1.6618357487922706, "no_speech_prob": 0.000107208477857057}, {"id": 1165, "seek": 552104, "start": 5522.04, "end": 5528.64, "text": " Large objects like if you're doing diabetic retinopathy you have like 4,000 by 4,000 pictures of eyeballs", "tokens": [50414, 33092, 6565, 411, 498, 291, 434, 884, 50238, 1533, 259, 404, 9527, 291, 362, 411, 1017, 11, 1360, 538, 1017, 11, 1360, 5242, 295, 43758, 50744], "temperature": 0.0, "avg_logprob": -0.32996655687873744, "compression_ratio": 1.52, "no_speech_prob": 5.06444375787396e-05}, {"id": 1166, "seek": 552104, "start": 5529.28, "end": 5534.8, "text": " Or maybe you've got lots of images a lot of lots of objects like if you're working with image net and", "tokens": [50776, 1610, 1310, 291, 600, 658, 3195, 295, 5267, 257, 688, 295, 3195, 295, 6565, 411, 498, 291, 434, 1364, 365, 3256, 2533, 293, 51052], "temperature": 0.0, "avg_logprob": -0.32996655687873744, "compression_ratio": 1.52, "no_speech_prob": 5.06444375787396e-05}, {"id": 1167, "seek": 552104, "start": 5535.72, "end": 5537.72, "text": " to handle this", "tokens": [51098, 281, 4813, 341, 51198], "temperature": 0.0, "avg_logprob": -0.32996655687873744, "compression_ratio": 1.52, "no_speech_prob": 5.06444375787396e-05}, {"id": 1168, "seek": 552104, "start": 5539.0, "end": 5543.62, "text": " Data that doesn't fit in RAM. We need some tricks, so I thought we would try some", "tokens": [51262, 11888, 300, 1177, 380, 3318, 294, 14561, 13, 492, 643, 512, 11733, 11, 370, 286, 1194, 321, 576, 853, 512, 51493], "temperature": 0.0, "avg_logprob": -0.32996655687873744, "compression_ratio": 1.52, "no_speech_prob": 5.06444375787396e-05}, {"id": 1169, "seek": 554362, "start": 5544.3, "end": 5552.18, "text": " Interesting project that involves looking at the whole image net competition data set that the image net competition data set is", "tokens": [50398, 14711, 1716, 300, 11626, 1237, 412, 264, 1379, 3256, 2533, 6211, 1412, 992, 300, 264, 3256, 2533, 6211, 1412, 992, 307, 50792], "temperature": 0.0, "avg_logprob": -0.34992292885468385, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0041986736468970776}, {"id": 1170, "seek": 554362, "start": 5553.78, "end": 5556.78, "text": " One and a half million images in a thousand categories", "tokens": [50872, 1485, 293, 257, 1922, 2459, 5267, 294, 257, 4714, 10479, 51022], "temperature": 0.0, "avg_logprob": -0.34992292885468385, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0041986736468970776}, {"id": 1171, "seek": 554362, "start": 5558.22, "end": 5560.42, "text": " As I mentioned I think in the last class", "tokens": [51094, 1018, 286, 2835, 286, 519, 294, 264, 1036, 1508, 51204], "temperature": 0.0, "avg_logprob": -0.34992292885468385, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0041986736468970776}, {"id": 1172, "seek": 554362, "start": 5561.0599999999995, "end": 5562.9, "text": " If you try to download it", "tokens": [51236, 759, 291, 853, 281, 5484, 309, 51328], "temperature": 0.0, "avg_logprob": -0.34992292885468385, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0041986736468970776}, {"id": 1173, "seek": 554362, "start": 5562.9, "end": 5566.099999999999, "text": " It will give you a little form saying you have to use it for research purposes", "tokens": [51328, 467, 486, 976, 291, 257, 707, 1254, 1566, 291, 362, 281, 764, 309, 337, 2132, 9932, 51488], "temperature": 0.0, "avg_logprob": -0.34992292885468385, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0041986736468970776}, {"id": 1174, "seek": 554362, "start": 5566.099999999999, "end": 5571.46, "text": " And that they're going to check it blah blah blah in practice if you fill out the form you'll get back an answer a seconds", "tokens": [51488, 400, 300, 436, 434, 516, 281, 1520, 309, 12288, 12288, 12288, 294, 3124, 498, 291, 2836, 484, 264, 1254, 291, 603, 483, 646, 364, 1867, 257, 3949, 51756], "temperature": 0.0, "avg_logprob": -0.34992292885468385, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0041986736468970776}, {"id": 1175, "seek": 554362, "start": 5571.46, "end": 5572.98, "text": " later so", "tokens": [51756, 1780, 370, 51832], "temperature": 0.0, "avg_logprob": -0.34992292885468385, "compression_ratio": 1.7662835249042146, "no_speech_prob": 0.0041986736468970776}, {"id": 1176, "seek": 557298, "start": 5573.299999999999, "end": 5579.459999999999, "text": " Anybody who's got a terabyte of space and since you're building your own boxes you now have a terabyte of space", "tokens": [50380, 19082, 567, 311, 658, 257, 1796, 34529, 295, 1901, 293, 1670, 291, 434, 2390, 428, 1065, 9002, 291, 586, 362, 257, 1796, 34529, 295, 1901, 50688], "temperature": 0.0, "avg_logprob": -0.3317974176299706, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.757627175422385e-05}, {"id": 1177, "seek": 557298, "start": 5580.0599999999995, "end": 5582.0599999999995, "text": " You can go ahead and download image net", "tokens": [50718, 509, 393, 352, 2286, 293, 5484, 3256, 2533, 50818], "temperature": 0.0, "avg_logprob": -0.3317974176299706, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.757627175422385e-05}, {"id": 1178, "seek": 557298, "start": 5583.379999999999, "end": 5588.78, "text": " And then you can start working through this project so this project is about", "tokens": [50884, 400, 550, 291, 393, 722, 1364, 807, 341, 1716, 370, 341, 1716, 307, 466, 51154], "temperature": 0.0, "avg_logprob": -0.3317974176299706, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.757627175422385e-05}, {"id": 1179, "seek": 557298, "start": 5590.0599999999995, "end": 5592.0599999999995, "text": " implementing a paper called", "tokens": [51218, 18114, 257, 3035, 1219, 51318], "temperature": 0.0, "avg_logprob": -0.3317974176299706, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.757627175422385e-05}, {"id": 1180, "seek": 557298, "start": 5592.419999999999, "end": 5594.0199999999995, "text": " device and", "tokens": [51336, 4302, 293, 51416], "temperature": 0.0, "avg_logprob": -0.3317974176299706, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.757627175422385e-05}, {"id": 1181, "seek": 557298, "start": 5594.0199999999995, "end": 5597.9, "text": " Device is a really really interesting paper. I actually just", "tokens": [51416, 50140, 307, 257, 534, 534, 1880, 3035, 13, 286, 767, 445, 51610], "temperature": 0.0, "avg_logprob": -0.3317974176299706, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.757627175422385e-05}, {"id": 1182, "seek": 557298, "start": 5599.099999999999, "end": 5601.099999999999, "text": " Chatted to the author about it quite recently", "tokens": [51670, 761, 32509, 281, 264, 3793, 466, 309, 1596, 3938, 51770], "temperature": 0.0, "avg_logprob": -0.3317974176299706, "compression_ratio": 1.6846846846846846, "no_speech_prob": 4.757627175422385e-05}, {"id": 1183, "seek": 560110, "start": 5601.46, "end": 5603.46, "text": " A", "tokens": [50382, 316, 50482], "temperature": 0.0, "avg_logprob": -0.45690366384145376, "compression_ratio": 1.505, "no_speech_prob": 9.027976921061054e-05}, {"id": 1184, "seek": 560110, "start": 5603.5, "end": 5608.620000000001, "text": " Amazing lady named Andrea from who's now at clarify. I'm just a computer vision startup and", "tokens": [50484, 14165, 7262, 4926, 24215, 490, 567, 311, 586, 412, 17594, 13, 286, 478, 445, 257, 3820, 5201, 18578, 293, 50740], "temperature": 0.0, "avg_logprob": -0.45690366384145376, "compression_ratio": 1.505, "no_speech_prob": 9.027976921061054e-05}, {"id": 1185, "seek": 560110, "start": 5609.9400000000005, "end": 5613.46, "text": " What she did was device was she created a really interesting", "tokens": [50806, 708, 750, 630, 390, 4302, 390, 750, 2942, 257, 534, 1880, 50982], "temperature": 0.0, "avg_logprob": -0.45690366384145376, "compression_ratio": 1.505, "no_speech_prob": 9.027976921061054e-05}, {"id": 1186, "seek": 560110, "start": 5614.620000000001, "end": 5615.9400000000005, "text": " multimodal", "tokens": [51040, 32972, 378, 304, 51106], "temperature": 0.0, "avg_logprob": -0.45690366384145376, "compression_ratio": 1.505, "no_speech_prob": 9.027976921061054e-05}, {"id": 1187, "seek": 560110, "start": 5615.9400000000005, "end": 5623.42, "text": " Architecture so multimodal means that we're going to be combining different types of object and in her case. She was combining", "tokens": [51106, 43049, 370, 32972, 378, 304, 1355, 300, 321, 434, 516, 281, 312, 21928, 819, 3467, 295, 2657, 293, 294, 720, 1389, 13, 1240, 390, 21928, 51480], "temperature": 0.0, "avg_logprob": -0.45690366384145376, "compression_ratio": 1.505, "no_speech_prob": 9.027976921061054e-05}, {"id": 1188, "seek": 560110, "start": 5624.860000000001, "end": 5626.06, "text": " language", "tokens": [51552, 2856, 51612], "temperature": 0.0, "avg_logprob": -0.45690366384145376, "compression_ratio": 1.505, "no_speech_prob": 9.027976921061054e-05}, {"id": 1189, "seek": 562606, "start": 5626.06, "end": 5633.52, "text": " With images that's quite an early paper to look at this idea, and she did something which was really interesting she said", "tokens": [50364, 2022, 5267, 300, 311, 1596, 364, 2440, 3035, 281, 574, 412, 341, 1558, 11, 293, 750, 630, 746, 597, 390, 534, 1880, 750, 848, 50737], "temperature": 0.0, "avg_logprob": -0.3512616917706918, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0010162368416786194}, {"id": 1190, "seek": 562606, "start": 5634.54, "end": 5638.14, "text": " normally when we do an image net network our", "tokens": [50788, 5646, 562, 321, 360, 364, 3256, 2533, 3209, 527, 50968], "temperature": 0.0, "avg_logprob": -0.3512616917706918, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0010162368416786194}, {"id": 1191, "seek": 562606, "start": 5639.860000000001, "end": 5642.46, "text": " Final layer is a one-hot encoding of", "tokens": [51054, 13443, 4583, 307, 257, 472, 12, 12194, 43430, 295, 51184], "temperature": 0.0, "avg_logprob": -0.3512616917706918, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0010162368416786194}, {"id": 1192, "seek": 562606, "start": 5643.22, "end": 5645.22, "text": " a category and", "tokens": [51222, 257, 7719, 293, 51322], "temperature": 0.0, "avg_logprob": -0.3512616917706918, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0010162368416786194}, {"id": 1193, "seek": 562606, "start": 5645.54, "end": 5649.580000000001, "text": " so that means that a hug and a golden retriever are", "tokens": [51338, 370, 300, 1355, 300, 257, 8777, 293, 257, 9729, 19817, 331, 366, 51540], "temperature": 0.0, "avg_logprob": -0.3512616917706918, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0010162368416786194}, {"id": 1194, "seek": 564958, "start": 5650.58, "end": 5656.38, "text": " No more similar or different in terms of that encoding than a pug and a jumbo jumbo jet", "tokens": [50414, 883, 544, 2531, 420, 819, 294, 2115, 295, 300, 43430, 813, 257, 47900, 293, 257, 29067, 1763, 29067, 1763, 14452, 50704], "temperature": 0.0, "avg_logprob": -0.3344733641319668, "compression_ratio": 1.8165938864628821, "no_speech_prob": 0.00021995064162183553}, {"id": 1195, "seek": 564958, "start": 5657.38, "end": 5660.38, "text": " And that seems kind of weird right like", "tokens": [50754, 400, 300, 2544, 733, 295, 3657, 558, 411, 50904], "temperature": 0.0, "avg_logprob": -0.3344733641319668, "compression_ratio": 1.8165938864628821, "no_speech_prob": 0.00021995064162183553}, {"id": 1196, "seek": 564958, "start": 5661.7, "end": 5665.64, "text": " If you had an encoding where similar things were similar in the encoding", "tokens": [50970, 759, 291, 632, 364, 43430, 689, 2531, 721, 645, 2531, 294, 264, 43430, 51167], "temperature": 0.0, "avg_logprob": -0.3344733641319668, "compression_ratio": 1.8165938864628821, "no_speech_prob": 0.00021995064162183553}, {"id": 1197, "seek": 564958, "start": 5666.46, "end": 5668.46, "text": " You could do some pretty cool stuff", "tokens": [51208, 509, 727, 360, 512, 1238, 1627, 1507, 51308], "temperature": 0.0, "avg_logprob": -0.3344733641319668, "compression_ratio": 1.8165938864628821, "no_speech_prob": 0.00021995064162183553}, {"id": 1198, "seek": 564958, "start": 5668.74, "end": 5674.14, "text": " And in particular what she was trying to do one of the key things she was trying to do is to create something which went", "tokens": [51322, 400, 294, 1729, 437, 750, 390, 1382, 281, 360, 472, 295, 264, 2141, 721, 750, 390, 1382, 281, 360, 307, 281, 1884, 746, 597, 1437, 51592], "temperature": 0.0, "avg_logprob": -0.3344733641319668, "compression_ratio": 1.8165938864628821, "no_speech_prob": 0.00021995064162183553}, {"id": 1199, "seek": 564958, "start": 5674.22, "end": 5677.98, "text": " beyond the thousand image net categories so that you could", "tokens": [51596, 4399, 264, 4714, 3256, 2533, 10479, 370, 300, 291, 727, 51784], "temperature": 0.0, "avg_logprob": -0.3344733641319668, "compression_ratio": 1.8165938864628821, "no_speech_prob": 0.00021995064162183553}, {"id": 1200, "seek": 567798, "start": 5678.82, "end": 5682.86, "text": " Work with types of images that were not in image net at all and", "tokens": [50406, 6603, 365, 3467, 295, 5267, 300, 645, 406, 294, 3256, 2533, 412, 439, 293, 50608], "temperature": 0.0, "avg_logprob": -0.38832873924105776, "compression_ratio": 1.7511520737327189, "no_speech_prob": 2.7535528715816326e-05}, {"id": 1201, "seek": 567798, "start": 5683.78, "end": 5689.219999999999, "text": " So the way she did that was to say all right. Let's throw away the one pot encoded category and", "tokens": [50654, 407, 264, 636, 750, 630, 300, 390, 281, 584, 439, 558, 13, 961, 311, 3507, 1314, 264, 472, 1847, 2058, 12340, 7719, 293, 50926], "temperature": 0.0, "avg_logprob": -0.38832873924105776, "compression_ratio": 1.7511520737327189, "no_speech_prob": 2.7535528715816326e-05}, {"id": 1202, "seek": 567798, "start": 5689.78, "end": 5693.459999999999, "text": " Let's replace it with a word embedding of the thing", "tokens": [50954, 961, 311, 7406, 309, 365, 257, 1349, 12240, 3584, 295, 264, 551, 51138], "temperature": 0.0, "avg_logprob": -0.38832873924105776, "compression_ratio": 1.7511520737327189, "no_speech_prob": 2.7535528715816326e-05}, {"id": 1203, "seek": 567798, "start": 5693.98, "end": 5699.0199999999995, "text": " All right, so pug is no longer zero zero zero one zero zero zero zero", "tokens": [51164, 1057, 558, 11, 370, 47900, 307, 572, 2854, 4018, 4018, 4018, 472, 4018, 4018, 4018, 4018, 51416], "temperature": 0.0, "avg_logprob": -0.38832873924105776, "compression_ratio": 1.7511520737327189, "no_speech_prob": 2.7535528715816326e-05}, {"id": 1204, "seek": 567798, "start": 5699.219999999999, "end": 5702.299999999999, "text": " But it's now the word to vector the pug", "tokens": [51426, 583, 309, 311, 586, 264, 1349, 281, 8062, 264, 47900, 51580], "temperature": 0.0, "avg_logprob": -0.38832873924105776, "compression_ratio": 1.7511520737327189, "no_speech_prob": 2.7535528715816326e-05}, {"id": 1205, "seek": 567798, "start": 5703.339999999999, "end": 5707.099999999999, "text": " And that's it. That's the entirety of the thing train that", "tokens": [51632, 400, 300, 311, 309, 13, 663, 311, 264, 31557, 295, 264, 551, 3847, 300, 51820], "temperature": 0.0, "avg_logprob": -0.38832873924105776, "compression_ratio": 1.7511520737327189, "no_speech_prob": 2.7535528715816326e-05}, {"id": 1206, "seek": 570798, "start": 5708.379999999999, "end": 5710.139999999999, "text": " And see what happens", "tokens": [50384, 400, 536, 437, 2314, 50472], "temperature": 0.0, "avg_logprob": -0.32767642628062854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 6.814702646806836e-05}, {"id": 1207, "seek": 570798, "start": 5710.139999999999, "end": 5714.5, "text": " I'll provide a link to the paper and one of the things I love about the paper is that", "tokens": [50472, 286, 603, 2893, 257, 2113, 281, 264, 3035, 293, 472, 295, 264, 721, 286, 959, 466, 264, 3035, 307, 300, 50690], "temperature": 0.0, "avg_logprob": -0.32767642628062854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 6.814702646806836e-05}, {"id": 1208, "seek": 570798, "start": 5715.419999999999, "end": 5717.419999999999, "text": " What she does is to?", "tokens": [50736, 708, 750, 775, 307, 281, 30, 50836], "temperature": 0.0, "avg_logprob": -0.32767642628062854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 6.814702646806836e-05}, {"id": 1209, "seek": 570798, "start": 5717.66, "end": 5725.74, "text": " Show quite an interesting range of the kinds of cool results and cool things you can do when you replace a one-hot encoded output", "tokens": [50848, 6895, 1596, 364, 1880, 3613, 295, 264, 3685, 295, 1627, 3542, 293, 1627, 721, 291, 393, 360, 562, 291, 7406, 257, 472, 12, 12194, 2058, 12340, 5598, 51252], "temperature": 0.0, "avg_logprob": -0.32767642628062854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 6.814702646806836e-05}, {"id": 1210, "seek": 570798, "start": 5725.94, "end": 5727.94, "text": " with a vector output", "tokens": [51262, 365, 257, 8062, 5598, 51362], "temperature": 0.0, "avg_logprob": -0.32767642628062854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 6.814702646806836e-05}, {"id": 1211, "seek": 570798, "start": 5728.5, "end": 5730.5, "text": " embedding", "tokens": [51390, 12240, 3584, 51490], "temperature": 0.0, "avg_logprob": -0.32767642628062854, "compression_ratio": 1.5567567567567568, "no_speech_prob": 6.814702646806836e-05}, {"id": 1212, "seek": 573050, "start": 5730.5, "end": 5732.5, "text": " I", "tokens": [50364, 286, 50464], "temperature": 0.0, "avg_logprob": -0.4539905729747954, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00027371416217647493}, {"id": 1213, "seek": 573050, "start": 5734.18, "end": 5741.1, "text": " Just to clarify so every pixel one encoded coded pixel suddenly becomes a vector was like no", "tokens": [50548, 1449, 281, 17594, 370, 633, 19261, 472, 2058, 12340, 34874, 19261, 5800, 3643, 257, 8062, 390, 411, 572, 50894], "temperature": 0.0, "avg_logprob": -0.4539905729747954, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00027371416217647493}, {"id": 1214, "seek": 573050, "start": 5741.38, "end": 5743.38, "text": " pixels are not one-hot encoded", "tokens": [50908, 18668, 366, 406, 472, 12, 12194, 2058, 12340, 51008], "temperature": 0.0, "avg_logprob": -0.4539905729747954, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00027371416217647493}, {"id": 1215, "seek": 573050, "start": 5743.38, "end": 5744.98, "text": " pixels", "tokens": [51008, 18668, 51088], "temperature": 0.0, "avg_logprob": -0.4539905729747954, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00027371416217647493}, {"id": 1216, "seek": 573050, "start": 5744.98, "end": 5748.34, "text": " Encoded by their channels, all right. I mean bit bit of", "tokens": [51088, 29584, 12340, 538, 641, 9235, 11, 439, 558, 13, 286, 914, 857, 857, 295, 51256], "temperature": 0.0, "avg_logprob": -0.4539905729747954, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00027371416217647493}, {"id": 1217, "seek": 573050, "start": 5751.02, "end": 5753.02, "text": " No so here the", "tokens": [51390, 883, 370, 510, 264, 51490], "temperature": 0.0, "avg_logprob": -0.4539905729747954, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00027371416217647493}, {"id": 1218, "seek": 573050, "start": 5753.22, "end": 5760.3, "text": " The let's take let's say this is an image of a pug right it's a type of dog and so", "tokens": [51500, 440, 718, 311, 747, 718, 311, 584, 341, 307, 364, 3256, 295, 257, 47900, 558, 309, 311, 257, 2010, 295, 3000, 293, 370, 51854], "temperature": 0.0, "avg_logprob": -0.4539905729747954, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00027371416217647493}, {"id": 1219, "seek": 576050, "start": 5760.5, "end": 5764.26, "text": " pug gets turned into let's say pug is the", "tokens": [50364, 47900, 2170, 3574, 666, 718, 311, 584, 47900, 307, 264, 50552], "temperature": 0.0, "avg_logprob": -0.4702132225036621, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.187556103512179e-06}, {"id": 1220, "seek": 576050, "start": 5765.22, "end": 5767.22, "text": " 300", "tokens": [50600, 6641, 50700], "temperature": 0.0, "avg_logprob": -0.4702132225036621, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.187556103512179e-06}, {"id": 1221, "seek": 576050, "start": 5768.14, "end": 5770.14, "text": " Class in image net", "tokens": [50746, 9471, 294, 3256, 2533, 50846], "temperature": 0.0, "avg_logprob": -0.4702132225036621, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.187556103512179e-06}, {"id": 1222, "seek": 576050, "start": 5770.34, "end": 5774.66, "text": " It's going to get turned into a 1000 long vector with a thousand zeros", "tokens": [50856, 467, 311, 516, 281, 483, 3574, 666, 257, 9714, 938, 8062, 365, 257, 4714, 35193, 51072], "temperature": 0.0, "avg_logprob": -0.4702132225036621, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.187556103512179e-06}, {"id": 1223, "seek": 576050, "start": 5775.18, "end": 5778.38, "text": " Sorry, not even one zeros and a one in position 300", "tokens": [51098, 4919, 11, 406, 754, 472, 35193, 293, 257, 472, 294, 2535, 6641, 51258], "temperature": 0.0, "avg_logprob": -0.4702132225036621, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.187556103512179e-06}, {"id": 1224, "seek": 576050, "start": 5779.22, "end": 5785.94, "text": " That's normally what we use as our as our target when we're doing any justification. We're going to throw that", "tokens": [51300, 663, 311, 5646, 437, 321, 764, 382, 527, 382, 527, 3779, 562, 321, 434, 884, 604, 31591, 13, 492, 434, 516, 281, 3507, 300, 51636], "temperature": 0.0, "avg_logprob": -0.4702132225036621, "compression_ratio": 1.528205128205128, "no_speech_prob": 3.187556103512179e-06}, {"id": 1225, "seek": 578594, "start": 5786.86, "end": 5790.219999999999, "text": " 1000 long thing away and replace it with a", "tokens": [50410, 9714, 938, 551, 1314, 293, 7406, 309, 365, 257, 50578], "temperature": 0.0, "avg_logprob": -0.3899188930705442, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.00011061092664021999}, {"id": 1226, "seek": 578594, "start": 5791.5, "end": 5795.219999999999, "text": " 300 long thing and the 300 long thing will be the", "tokens": [50642, 6641, 938, 551, 293, 264, 6641, 938, 551, 486, 312, 264, 50828], "temperature": 0.0, "avg_logprob": -0.3899188930705442, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.00011061092664021999}, {"id": 1227, "seek": 578594, "start": 5795.9, "end": 5799.98, "text": " Word vector for pug that we downloaded from Word2Vector", "tokens": [50862, 8725, 8062, 337, 47900, 300, 321, 21748, 490, 8725, 17, 53, 20814, 51066], "temperature": 0.0, "avg_logprob": -0.3899188930705442, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.00011061092664021999}, {"id": 1228, "seek": 578594, "start": 5803.66, "end": 5805.66, "text": " So", "tokens": [51250, 407, 51350], "temperature": 0.0, "avg_logprob": -0.3899188930705442, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.00011061092664021999}, {"id": 1229, "seek": 578594, "start": 5808.98, "end": 5815.259999999999, "text": " So normally we have our input image comes in it goes through some kind of", "tokens": [51516, 407, 5646, 321, 362, 527, 4846, 3256, 1487, 294, 309, 1709, 807, 512, 733, 295, 51830], "temperature": 0.0, "avg_logprob": -0.3899188930705442, "compression_ratio": 1.530612244897959, "no_speech_prob": 0.00011061092664021999}, {"id": 1230, "seek": 581594, "start": 5816.82, "end": 5818.82, "text": " You", "tokens": [50408, 509, 50508], "temperature": 0.0, "avg_logprob": -0.2935152901543511, "compression_ratio": 1.6551724137931034, "no_speech_prob": 6.0140991990920156e-05}, {"id": 1231, "seek": 581594, "start": 5819.0199999999995, "end": 5826.46, "text": " Computation in our CNN and it has to predict something and normally the thing it has to predict is a whole bunch of zeros", "tokens": [50518, 37804, 399, 294, 527, 24859, 293, 309, 575, 281, 6069, 746, 293, 5646, 264, 551, 309, 575, 281, 6069, 307, 257, 1379, 3840, 295, 35193, 50890], "temperature": 0.0, "avg_logprob": -0.2935152901543511, "compression_ratio": 1.6551724137931034, "no_speech_prob": 6.0140991990920156e-05}, {"id": 1232, "seek": 581594, "start": 5827.139999999999, "end": 5833.46, "text": " And a one here, and so the way we do that is that the last layer is a softmax layer", "tokens": [50924, 400, 257, 472, 510, 11, 293, 370, 264, 636, 321, 360, 300, 307, 300, 264, 1036, 4583, 307, 257, 2787, 41167, 4583, 51240], "temperature": 0.0, "avg_logprob": -0.2935152901543511, "compression_ratio": 1.6551724137931034, "no_speech_prob": 6.0140991990920156e-05}, {"id": 1233, "seek": 581594, "start": 5834.5, "end": 5836.5, "text": " which encourages", "tokens": [51292, 597, 28071, 51392], "temperature": 0.0, "avg_logprob": -0.2935152901543511, "compression_ratio": 1.6551724137931034, "no_speech_prob": 6.0140991990920156e-05}, {"id": 1234, "seek": 581594, "start": 5836.7, "end": 5838.78, "text": " One of the things to be much higher than the others", "tokens": [51402, 1485, 295, 264, 721, 281, 312, 709, 2946, 813, 264, 2357, 51506], "temperature": 0.0, "avg_logprob": -0.2935152901543511, "compression_ratio": 1.6551724137931034, "no_speech_prob": 6.0140991990920156e-05}, {"id": 1235, "seek": 581594, "start": 5839.78, "end": 5842.46, "text": " so all we do is we throw that away and", "tokens": [51556, 370, 439, 321, 360, 307, 321, 3507, 300, 1314, 293, 51690], "temperature": 0.0, "avg_logprob": -0.2935152901543511, "compression_ratio": 1.6551724137931034, "no_speech_prob": 6.0140991990920156e-05}, {"id": 1236, "seek": 581594, "start": 5843.5, "end": 5845.5, "text": " We replace it with", "tokens": [51742, 492, 7406, 309, 365, 51842], "temperature": 0.0, "avg_logprob": -0.2935152901543511, "compression_ratio": 1.6551724137931034, "no_speech_prob": 6.0140991990920156e-05}, {"id": 1237, "seek": 584594, "start": 5846.82, "end": 5848.82, "text": " a word vector", "tokens": [50408, 257, 1349, 8062, 50508], "temperature": 0.0, "avg_logprob": -0.3192606090027609, "compression_ratio": 1.5257731958762886, "no_speech_prob": 6.401904101949185e-05}, {"id": 1238, "seek": 584594, "start": 5849.219999999999, "end": 5850.74, "text": " or that", "tokens": [50528, 420, 300, 50604], "temperature": 0.0, "avg_logprob": -0.3192606090027609, "compression_ratio": 1.5257731958762886, "no_speech_prob": 6.401904101949185e-05}, {"id": 1239, "seek": 584594, "start": 5850.74, "end": 5853.82, "text": " for that thing box or park or jumbo jet and", "tokens": [50604, 337, 300, 551, 2424, 420, 3884, 420, 29067, 1763, 14452, 293, 50758], "temperature": 0.0, "avg_logprob": -0.3192606090027609, "compression_ratio": 1.5257731958762886, "no_speech_prob": 6.401904101949185e-05}, {"id": 1240, "seek": 584594, "start": 5854.339999999999, "end": 5857.82, "text": " Since the word vectors are generally that might be say 300 dimensions", "tokens": [50784, 4162, 264, 1349, 18875, 366, 5101, 300, 1062, 312, 584, 6641, 12819, 50958], "temperature": 0.0, "avg_logprob": -0.3192606090027609, "compression_ratio": 1.5257731958762886, "no_speech_prob": 6.401904101949185e-05}, {"id": 1241, "seek": 584594, "start": 5860.219999999999, "end": 5866.54, "text": " And that's that's dense that's not lots of zeros so we can't use a softmax layer at the end anymore", "tokens": [51078, 400, 300, 311, 300, 311, 18011, 300, 311, 406, 3195, 295, 35193, 370, 321, 393, 380, 764, 257, 2787, 41167, 4583, 412, 264, 917, 3602, 51394], "temperature": 0.0, "avg_logprob": -0.3192606090027609, "compression_ratio": 1.5257731958762886, "no_speech_prob": 6.401904101949185e-05}, {"id": 1242, "seek": 584594, "start": 5866.82, "end": 5869.7, "text": " We probably now just use a regular linear layer", "tokens": [51408, 492, 1391, 586, 445, 764, 257, 3890, 8213, 4583, 51552], "temperature": 0.0, "avg_logprob": -0.3192606090027609, "compression_ratio": 1.5257731958762886, "no_speech_prob": 6.401904101949185e-05}, {"id": 1243, "seek": 584594, "start": 5873.299999999999, "end": 5875.299999999999, "text": " Okay, so the", "tokens": [51732, 1033, 11, 370, 264, 51832], "temperature": 0.0, "avg_logprob": -0.3192606090027609, "compression_ratio": 1.5257731958762886, "no_speech_prob": 6.401904101949185e-05}, {"id": 1244, "seek": 587594, "start": 5875.94, "end": 5878.419999999999, "text": " hard part about doing this really is", "tokens": [50364, 1152, 644, 466, 884, 341, 534, 307, 50488], "temperature": 0.0, "avg_logprob": -0.36577869690570636, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.5689522115280852e-05}, {"id": 1245, "seek": 587594, "start": 5879.58, "end": 5881.58, "text": " Processing image there not", "tokens": [50546, 31093, 278, 3256, 456, 406, 50646], "temperature": 0.0, "avg_logprob": -0.36577869690570636, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.5689522115280852e-05}, {"id": 1246, "seek": 587594, "start": 5881.66, "end": 5886.82, "text": " You know there's nothing weird or interesting or tricky about the architecture all we do is replace the last layer", "tokens": [50650, 509, 458, 456, 311, 1825, 3657, 420, 1880, 420, 12414, 466, 264, 9482, 439, 321, 360, 307, 7406, 264, 1036, 4583, 50908], "temperature": 0.0, "avg_logprob": -0.36577869690570636, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.5689522115280852e-05}, {"id": 1247, "seek": 587594, "start": 5887.7, "end": 5890.82, "text": " So we're going to leverage big holes quite a lot", "tokens": [50952, 407, 321, 434, 516, 281, 13982, 955, 8118, 1596, 257, 688, 51108], "temperature": 0.0, "avg_logprob": -0.36577869690570636, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.5689522115280852e-05}, {"id": 1248, "seek": 587594, "start": 5892.66, "end": 5897.5599999999995, "text": " So we start off by inputting our usual stuff and don't forget with tensorflow to call this limit m thing", "tokens": [51200, 407, 321, 722, 766, 538, 4846, 783, 527, 7713, 1507, 293, 500, 380, 2870, 365, 40863, 10565, 281, 818, 341, 4948, 275, 551, 51445], "temperature": 0.0, "avg_logprob": -0.36577869690570636, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.5689522115280852e-05}, {"id": 1249, "seek": 587594, "start": 5897.5599999999995, "end": 5899.82, "text": " I created so that you don't use up all of your memory", "tokens": [51445, 286, 2942, 370, 300, 291, 500, 380, 764, 493, 439, 295, 428, 4675, 51558], "temperature": 0.0, "avg_logprob": -0.36577869690570636, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.5689522115280852e-05}, {"id": 1250, "seek": 587594, "start": 5900.74, "end": 5902.74, "text": " and", "tokens": [51604, 293, 51704], "temperature": 0.0, "avg_logprob": -0.36577869690570636, "compression_ratio": 1.6455696202531647, "no_speech_prob": 1.5689522115280852e-05}, {"id": 1251, "seek": 590274, "start": 5903.34, "end": 5906.98, "text": " One thing which can be very helpful is to define actually two parts", "tokens": [50394, 1485, 551, 597, 393, 312, 588, 4961, 307, 281, 6964, 767, 732, 3166, 50576], "temperature": 0.0, "avg_logprob": -0.2969477709601907, "compression_ratio": 1.5073170731707317, "no_speech_prob": 5.0644579459913075e-05}, {"id": 1252, "seek": 590274, "start": 5907.78, "end": 5909.54, "text": " Once you've got your own box", "tokens": [50616, 3443, 291, 600, 658, 428, 1065, 2424, 50704], "temperature": 0.0, "avg_logprob": -0.2969477709601907, "compression_ratio": 1.5073170731707317, "no_speech_prob": 5.0644579459913075e-05}, {"id": 1253, "seek": 590274, "start": 5909.54, "end": 5915.78, "text": " you've got a bunch of spinning hard disks that are big and slow and cheap and", "tokens": [50704, 291, 600, 658, 257, 3840, 295, 15640, 1152, 41617, 300, 366, 955, 293, 2964, 293, 7084, 293, 51016], "temperature": 0.0, "avg_logprob": -0.2969477709601907, "compression_ratio": 1.5073170731707317, "no_speech_prob": 5.0644579459913075e-05}, {"id": 1254, "seek": 590274, "start": 5916.42, "end": 5918.42, "text": " maybe a couple of", "tokens": [51048, 1310, 257, 1916, 295, 51148], "temperature": 0.0, "avg_logprob": -0.2969477709601907, "compression_ratio": 1.5073170731707317, "no_speech_prob": 5.0644579459913075e-05}, {"id": 1255, "seek": 590274, "start": 5918.66, "end": 5920.82, "text": " fast expensive small", "tokens": [51160, 2370, 5124, 1359, 51268], "temperature": 0.0, "avg_logprob": -0.2969477709601907, "compression_ratio": 1.5073170731707317, "no_speech_prob": 5.0644579459913075e-05}, {"id": 1256, "seek": 590274, "start": 5921.7, "end": 5923.7, "text": " SSDs or NVMe drives", "tokens": [51312, 30262, 82, 420, 46512, 12671, 11754, 51412], "temperature": 0.0, "avg_logprob": -0.2969477709601907, "compression_ratio": 1.5073170731707317, "no_speech_prob": 5.0644579459913075e-05}, {"id": 1257, "seek": 590274, "start": 5924.219999999999, "end": 5927.5, "text": " So I generally think it's good idea to define a path", "tokens": [51438, 407, 286, 5101, 519, 309, 311, 665, 1558, 281, 6964, 257, 3100, 51602], "temperature": 0.0, "avg_logprob": -0.2969477709601907, "compression_ratio": 1.5073170731707317, "no_speech_prob": 5.0644579459913075e-05}, {"id": 1258, "seek": 590274, "start": 5928.099999999999, "end": 5930.099999999999, "text": " the both right one two", "tokens": [51632, 264, 1293, 558, 472, 732, 51732], "temperature": 0.0, "avg_logprob": -0.2969477709601907, "compression_ratio": 1.5073170731707317, "no_speech_prob": 5.0644579459913075e-05}, {"id": 1259, "seek": 593010, "start": 5930.660000000001, "end": 5935.820000000001, "text": " This actually happens to be a mount point that has my big slow", "tokens": [50392, 639, 767, 2314, 281, 312, 257, 3746, 935, 300, 575, 452, 955, 2964, 50650], "temperature": 0.0, "avg_logprob": -0.29365028873566656, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.887944568414241e-05}, {"id": 1260, "seek": 593010, "start": 5937.02, "end": 5940.68, "text": " Cheap spinning disks and this path happens to live", "tokens": [50710, 3351, 569, 15640, 41617, 293, 341, 3100, 2314, 281, 1621, 50893], "temperature": 0.0, "avg_logprob": -0.29365028873566656, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.887944568414241e-05}, {"id": 1261, "seek": 593010, "start": 5941.38, "end": 5946.5, "text": " Somewhere which is my fast SSDs and that way throughout my what I'm doing my", "tokens": [50928, 34500, 597, 307, 452, 2370, 30262, 82, 293, 300, 636, 3710, 452, 437, 286, 478, 884, 452, 51184], "temperature": 0.0, "avg_logprob": -0.29365028873566656, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.887944568414241e-05}, {"id": 1262, "seek": 593010, "start": 5947.42, "end": 5952.860000000001, "text": " Code anytime I've got something I'm going to be accessing a lot particularly if it's in a random order", "tokens": [51230, 15549, 13038, 286, 600, 658, 746, 286, 478, 516, 281, 312, 26440, 257, 688, 4098, 498, 309, 311, 294, 257, 4974, 1668, 51502], "temperature": 0.0, "avg_logprob": -0.29365028873566656, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.887944568414241e-05}, {"id": 1263, "seek": 593010, "start": 5952.860000000001, "end": 5956.58, "text": " I'm going to want to make sure that that thing as long as it's not too big", "tokens": [51502, 286, 478, 516, 281, 528, 281, 652, 988, 300, 300, 551, 382, 938, 382, 309, 311, 406, 886, 955, 51688], "temperature": 0.0, "avg_logprob": -0.29365028873566656, "compression_ratio": 1.6502242152466369, "no_speech_prob": 8.887944568414241e-05}, {"id": 1264, "seek": 595658, "start": 5956.82, "end": 5961.38, "text": " Sits in this path and anytime I'm accessing something which I'm accessing", "tokens": [50376, 318, 1208, 294, 341, 3100, 293, 13038, 286, 478, 26440, 746, 597, 286, 478, 26440, 50604], "temperature": 0.0, "avg_logprob": -0.32406403746785994, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.069427086506039e-05}, {"id": 1265, "seek": 595658, "start": 5961.94, "end": 5965.78, "text": " Generally sequentially or which is really big I can put it in this part", "tokens": [50632, 21082, 5123, 3137, 420, 597, 307, 534, 955, 286, 393, 829, 309, 294, 341, 644, 50824], "temperature": 0.0, "avg_logprob": -0.32406403746785994, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.069427086506039e-05}, {"id": 1266, "seek": 595658, "start": 5966.82, "end": 5972.14, "text": " This is one of the good reasons another good reason to have your own box is that you get this kind of flexibility", "tokens": [50876, 639, 307, 472, 295, 264, 665, 4112, 1071, 665, 1778, 281, 362, 428, 1065, 2424, 307, 300, 291, 483, 341, 733, 295, 12635, 51142], "temperature": 0.0, "avg_logprob": -0.32406403746785994, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.069427086506039e-05}, {"id": 1267, "seek": 595658, "start": 5974.58, "end": 5978.38, "text": " Okay, so the first thing we need is some word vectors", "tokens": [51264, 1033, 11, 370, 264, 700, 551, 321, 643, 307, 512, 1349, 18875, 51454], "temperature": 0.0, "avg_logprob": -0.32406403746785994, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.069427086506039e-05}, {"id": 1268, "seek": 595658, "start": 5980.82, "end": 5982.82, "text": " So interestingly", "tokens": [51576, 407, 25873, 51676], "temperature": 0.0, "avg_logprob": -0.32406403746785994, "compression_ratio": 1.6176470588235294, "no_speech_prob": 4.069427086506039e-05}, {"id": 1269, "seek": 598282, "start": 5983.7, "end": 5989.58, "text": " Actually the the paper built their own Wikipedia word vectors", "tokens": [50408, 5135, 264, 264, 3035, 3094, 641, 1065, 28999, 1349, 18875, 50702], "temperature": 0.0, "avg_logprob": -0.36882777272919076, "compression_ratio": 1.6292682926829267, "no_speech_prob": 5.0644528528209776e-05}, {"id": 1270, "seek": 598282, "start": 5991.219999999999, "end": 5997.94, "text": " Actually think that the word2vec vectors you can download from Google are really maybe a better choice here", "tokens": [50784, 5135, 519, 300, 264, 1349, 17, 303, 66, 18875, 291, 393, 5484, 490, 3329, 366, 534, 1310, 257, 1101, 3922, 510, 51120], "temperature": 0.0, "avg_logprob": -0.36882777272919076, "compression_ratio": 1.6292682926829267, "no_speech_prob": 5.0644528528209776e-05}, {"id": 1271, "seek": 598282, "start": 5999.219999999999, "end": 6002.5, "text": " So I've just gone ahead and shown how you can load them in", "tokens": [51184, 407, 286, 600, 445, 2780, 2286, 293, 4898, 577, 291, 393, 3677, 552, 294, 51348], "temperature": 0.0, "avg_logprob": -0.36882777272919076, "compression_ratio": 1.6292682926829267, "no_speech_prob": 5.0644528528209776e-05}, {"id": 1272, "seek": 598282, "start": 6003.0599999999995, "end": 6007.5, "text": " one of the very nice things about Google's word2vec word vectors is", "tokens": [51376, 472, 295, 264, 588, 1481, 721, 466, 3329, 311, 1349, 17, 303, 66, 1349, 18875, 307, 51598], "temperature": 0.0, "avg_logprob": -0.36882777272919076, "compression_ratio": 1.6292682926829267, "no_speech_prob": 5.0644528528209776e-05}, {"id": 1273, "seek": 598282, "start": 6008.0199999999995, "end": 6011.099999999999, "text": " That where else do you remember last?", "tokens": [51624, 663, 689, 1646, 360, 291, 1604, 1036, 30, 51778], "temperature": 0.0, "avg_logprob": -0.36882777272919076, "compression_ratio": 1.6292682926829267, "no_speech_prob": 5.0644528528209776e-05}, {"id": 1274, "seek": 601110, "start": 6011.9800000000005, "end": 6015.5, "text": " In part one when we used word vectors we tended to use glove", "tokens": [50408, 682, 644, 472, 562, 321, 1143, 1349, 18875, 321, 34732, 281, 764, 26928, 50584], "temperature": 0.0, "avg_logprob": -0.35537782529505285, "compression_ratio": 1.9, "no_speech_prob": 5.9208683524047956e-05}, {"id": 1275, "seek": 601110, "start": 6016.820000000001, "end": 6023.38, "text": " Glove would not have a word vector for golden retriever. They would have a word vector for golden", "tokens": [50650, 10786, 303, 576, 406, 362, 257, 1349, 8062, 337, 9729, 19817, 331, 13, 814, 576, 362, 257, 1349, 8062, 337, 9729, 50978], "temperature": 0.0, "avg_logprob": -0.35537782529505285, "compression_ratio": 1.9, "no_speech_prob": 5.9208683524047956e-05}, {"id": 1276, "seek": 601110, "start": 6024.54, "end": 6026.46, "text": " they don't have like", "tokens": [51036, 436, 500, 380, 362, 411, 51132], "temperature": 0.0, "avg_logprob": -0.35537782529505285, "compression_ratio": 1.9, "no_speech_prob": 5.9208683524047956e-05}, {"id": 1277, "seek": 601110, "start": 6026.46, "end": 6029.820000000001, "text": " phrase things whereas Google's word vectors have", "tokens": [51132, 9535, 721, 9735, 3329, 311, 1349, 18875, 362, 51300], "temperature": 0.0, "avg_logprob": -0.35537782529505285, "compression_ratio": 1.9, "no_speech_prob": 5.9208683524047956e-05}, {"id": 1278, "seek": 601110, "start": 6030.9800000000005, "end": 6032.1, "text": " phrases", "tokens": [51358, 20312, 51414], "temperature": 0.0, "avg_logprob": -0.35537782529505285, "compression_ratio": 1.9, "no_speech_prob": 5.9208683524047956e-05}, {"id": 1279, "seek": 601110, "start": 6032.1, "end": 6038.18, "text": " Like golden retriever so for our thing we really need to use Google's word2vec vectors", "tokens": [51414, 1743, 9729, 19817, 331, 370, 337, 527, 551, 321, 534, 643, 281, 764, 3329, 311, 1349, 17, 303, 66, 18875, 51718], "temperature": 0.0, "avg_logprob": -0.35537782529505285, "compression_ratio": 1.9, "no_speech_prob": 5.9208683524047956e-05}, {"id": 1280, "seek": 603818, "start": 6038.3, "end": 6044.34, "text": " Plus anything like that which has like multi-part concepts as things that we can look at", "tokens": [50370, 7721, 1340, 411, 300, 597, 575, 411, 4825, 12, 6971, 10392, 382, 721, 300, 321, 393, 574, 412, 50672], "temperature": 0.0, "avg_logprob": -0.36183976566090303, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.00019110215362161398}, {"id": 1281, "seek": 603818, "start": 6045.58, "end": 6048.46, "text": " so you can download word2vec I", "tokens": [50734, 370, 291, 393, 5484, 1349, 17, 303, 66, 286, 50878], "temperature": 0.0, "avg_logprob": -0.36183976566090303, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.00019110215362161398}, {"id": 1282, "seek": 603818, "start": 6049.62, "end": 6054.1, "text": " will make them available on our platform that I I site because", "tokens": [50936, 486, 652, 552, 2435, 322, 527, 3663, 300, 286, 286, 3621, 570, 51160], "temperature": 0.0, "avg_logprob": -0.36183976566090303, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.00019110215362161398}, {"id": 1283, "seek": 603818, "start": 6054.780000000001, "end": 6060.46, "text": " the only way to get them otherwise is to get them from like this the authors Google Drive directory and", "tokens": [51194, 264, 787, 636, 281, 483, 552, 5911, 307, 281, 483, 552, 490, 411, 341, 264, 16552, 3329, 15622, 21120, 293, 51478], "temperature": 0.0, "avg_logprob": -0.36183976566090303, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.00019110215362161398}, {"id": 1284, "seek": 603818, "start": 6061.38, "end": 6064.9400000000005, "text": " Trying to get to a Google Drive directory from Linux is an absolute nightmare", "tokens": [51524, 20180, 281, 483, 281, 257, 3329, 15622, 21120, 490, 18734, 307, 364, 8236, 18724, 51702], "temperature": 0.0, "avg_logprob": -0.36183976566090303, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.00019110215362161398}, {"id": 1285, "seek": 606494, "start": 6065.139999999999, "end": 6068.419999999999, "text": " So I will save them for you so that you don't have the headache", "tokens": [50374, 407, 286, 486, 3155, 552, 337, 291, 370, 300, 291, 500, 380, 362, 264, 23520, 50538], "temperature": 0.0, "avg_logprob": -0.394531997979856, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.00018813998030964285}, {"id": 1286, "seek": 606494, "start": 6072.099999999999, "end": 6074.82, "text": " So once you've got them you can load them in", "tokens": [50722, 407, 1564, 291, 600, 658, 552, 291, 393, 3677, 552, 294, 50858], "temperature": 0.0, "avg_logprob": -0.394531997979856, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.00018813998030964285}, {"id": 1287, "seek": 606494, "start": 6075.46, "end": 6077.98, "text": " And then I they're in a weird", "tokens": [50890, 400, 550, 286, 436, 434, 294, 257, 3657, 51016], "temperature": 0.0, "avg_logprob": -0.394531997979856, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.00018813998030964285}, {"id": 1288, "seek": 606494, "start": 6078.74, "end": 6082.48, "text": " Proprietary binary it's like like you're gonna share data", "tokens": [51054, 430, 5072, 302, 822, 17434, 309, 311, 411, 411, 291, 434, 799, 2073, 1412, 51241], "temperature": 0.0, "avg_logprob": -0.394531997979856, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.00018813998030964285}, {"id": 1289, "seek": 606494, "start": 6082.48, "end": 6088.379999999999, "text": " Why put it in a weird proprietary binary format and a Google Drive thing that you can't access from Linux anyway this guy did", "tokens": [51241, 1545, 829, 309, 294, 257, 3657, 38992, 17434, 7877, 293, 257, 3329, 15622, 551, 300, 291, 393, 380, 2105, 490, 18734, 4033, 341, 2146, 630, 51536], "temperature": 0.0, "avg_logprob": -0.394531997979856, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.00018813998030964285}, {"id": 1290, "seek": 606494, "start": 6089.419999999999, "end": 6092.44, "text": " So I then save it as text make it a bit easier to work with", "tokens": [51588, 407, 286, 550, 3155, 309, 382, 2487, 652, 309, 257, 857, 3571, 281, 589, 365, 51739], "temperature": 0.0, "avg_logprob": -0.394531997979856, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.00018813998030964285}, {"id": 1291, "seek": 609244, "start": 6093.36, "end": 6096.96, "text": " The word vectors themselves are in a very simple format", "tokens": [50410, 440, 1349, 18875, 2969, 366, 294, 257, 588, 2199, 7877, 50590], "temperature": 0.0, "avg_logprob": -0.34792199976304, "compression_ratio": 1.6736842105263159, "no_speech_prob": 2.9311087928363122e-05}, {"id": 1292, "seek": 609244, "start": 6097.719999999999, "end": 6102.419999999999, "text": " They're just the word followed by a space followed by the vector", "tokens": [50628, 814, 434, 445, 264, 1349, 6263, 538, 257, 1901, 6263, 538, 264, 8062, 50863], "temperature": 0.0, "avg_logprob": -0.34792199976304, "compression_ratio": 1.6736842105263159, "no_speech_prob": 2.9311087928363122e-05}, {"id": 1293, "seek": 609244, "start": 6103.4, "end": 6104.919999999999, "text": " space separated", "tokens": [50912, 1901, 12005, 50988], "temperature": 0.0, "avg_logprob": -0.34792199976304, "compression_ratio": 1.6736842105263159, "no_speech_prob": 2.9311087928363122e-05}, {"id": 1294, "seek": 609244, "start": 6104.919999999999, "end": 6106.919999999999, "text": " I'm going to save them in a", "tokens": [50988, 286, 478, 516, 281, 3155, 552, 294, 257, 51088], "temperature": 0.0, "avg_logprob": -0.34792199976304, "compression_ratio": 1.6736842105263159, "no_speech_prob": 2.9311087928363122e-05}, {"id": 1295, "seek": 609244, "start": 6108.2, "end": 6110.2, "text": " simple", "tokens": [51152, 2199, 51252], "temperature": 0.0, "avg_logprob": -0.34792199976304, "compression_ratio": 1.6736842105263159, "no_speech_prob": 2.9311087928363122e-05}, {"id": 1296, "seek": 609244, "start": 6110.679999999999, "end": 6115.679999999999, "text": " Dictionary format so what I'm going to share with you guys will be the dictionary so it's a dictionary from", "tokens": [51276, 413, 4105, 822, 7877, 370, 437, 286, 478, 516, 281, 2073, 365, 291, 1074, 486, 312, 264, 25890, 370, 309, 311, 257, 25890, 490, 51526], "temperature": 0.0, "avg_logprob": -0.34792199976304, "compression_ratio": 1.6736842105263159, "no_speech_prob": 2.9311087928363122e-05}, {"id": 1297, "seek": 609244, "start": 6116.24, "end": 6120.839999999999, "text": " Word or phrase to a numpy array, okay?", "tokens": [51554, 8725, 420, 9535, 281, 257, 1031, 8200, 10225, 11, 1392, 30, 51784], "temperature": 0.0, "avg_logprob": -0.34792199976304, "compression_ratio": 1.6736842105263159, "no_speech_prob": 2.9311087928363122e-05}, {"id": 1298, "seek": 612084, "start": 6121.360000000001, "end": 6123.360000000001, "text": " I", "tokens": [50390, 286, 50490], "temperature": 0.0, "avg_logprob": -0.26886697915884167, "compression_ratio": 1.7098214285714286, "no_speech_prob": 5.5621851061005145e-05}, {"id": 1299, "seek": 612084, "start": 6123.72, "end": 6128.0, "text": "'m not sure I've used this idea of zip star before so I should talk about this a little bit", "tokens": [50508, 478, 406, 988, 286, 600, 1143, 341, 1558, 295, 20730, 3543, 949, 370, 286, 820, 751, 466, 341, 257, 707, 857, 50722], "temperature": 0.0, "avg_logprob": -0.26886697915884167, "compression_ratio": 1.7098214285714286, "no_speech_prob": 5.5621851061005145e-05}, {"id": 1300, "seek": 612084, "start": 6128.88, "end": 6135.0, "text": " So if I've got a dictionary a dictionary which maps from word to vector", "tokens": [50766, 407, 498, 286, 600, 658, 257, 25890, 257, 25890, 597, 11317, 490, 1349, 281, 8062, 51072], "temperature": 0.0, "avg_logprob": -0.26886697915884167, "compression_ratio": 1.7098214285714286, "no_speech_prob": 5.5621851061005145e-05}, {"id": 1301, "seek": 612084, "start": 6135.84, "end": 6140.2, "text": " How do I get out of that a list of the words and the list of the vectors?", "tokens": [51114, 1012, 360, 286, 483, 484, 295, 300, 257, 1329, 295, 264, 2283, 293, 264, 1329, 295, 264, 18875, 30, 51332], "temperature": 0.0, "avg_logprob": -0.26886697915884167, "compression_ratio": 1.7098214285714286, "no_speech_prob": 5.5621851061005145e-05}, {"id": 1302, "seek": 612084, "start": 6140.84, "end": 6142.84, "text": " the short answer is", "tokens": [51364, 264, 2099, 1867, 307, 51464], "temperature": 0.0, "avg_logprob": -0.26886697915884167, "compression_ratio": 1.7098214285714286, "no_speech_prob": 5.5621851061005145e-05}, {"id": 1303, "seek": 612084, "start": 6143.2, "end": 6145.2, "text": " like this", "tokens": [51482, 411, 341, 51582], "temperature": 0.0, "avg_logprob": -0.26886697915884167, "compression_ratio": 1.7098214285714286, "no_speech_prob": 5.5621851061005145e-05}, {"id": 1304, "seek": 612084, "start": 6145.56, "end": 6150.72, "text": " But let's think about what that's doing so I don't know like we've used zip quite a bit right so normally with zip", "tokens": [51600, 583, 718, 311, 519, 466, 437, 300, 311, 884, 370, 286, 500, 380, 458, 411, 321, 600, 1143, 20730, 1596, 257, 857, 558, 370, 5646, 365, 20730, 51858], "temperature": 0.0, "avg_logprob": -0.26886697915884167, "compression_ratio": 1.7098214285714286, "no_speech_prob": 5.5621851061005145e-05}, {"id": 1305, "seek": 615084, "start": 6151.0, "end": 6153.0, "text": " You go like zip", "tokens": [50372, 509, 352, 411, 20730, 50472], "temperature": 0.0, "avg_logprob": -0.29604372867318085, "compression_ratio": 1.6703296703296704, "no_speech_prob": 3.480786472209729e-05}, {"id": 1306, "seek": 615084, "start": 6153.4800000000005, "end": 6155.8, "text": " list 1 comma list 2", "tokens": [50496, 1329, 502, 22117, 1329, 568, 50612], "temperature": 0.0, "avg_logprob": -0.29604372867318085, "compression_ratio": 1.6703296703296704, "no_speech_prob": 3.480786472209729e-05}, {"id": 1307, "seek": 615084, "start": 6156.32, "end": 6162.66, "text": " Comma whatever right and what that returns is an iterator which first of all gives you", "tokens": [50638, 3046, 64, 2035, 558, 293, 437, 300, 11247, 307, 364, 17138, 1639, 597, 700, 295, 439, 2709, 291, 50955], "temperature": 0.0, "avg_logprob": -0.29604372867318085, "compression_ratio": 1.6703296703296704, "no_speech_prob": 3.480786472209729e-05}, {"id": 1308, "seek": 615084, "start": 6163.16, "end": 6169.56, "text": " Element 1 of list 1 element 1 of list 2 element 1 of list 3 and then element 2 of list 1 so forth", "tokens": [50980, 20900, 502, 295, 1329, 502, 4478, 502, 295, 1329, 568, 4478, 502, 295, 1329, 805, 293, 550, 4478, 568, 295, 1329, 502, 370, 5220, 51300], "temperature": 0.0, "avg_logprob": -0.29604372867318085, "compression_ratio": 1.6703296703296704, "no_speech_prob": 3.480786472209729e-05}, {"id": 1309, "seek": 615084, "start": 6169.56, "end": 6171.56, "text": " That's what zip normally does", "tokens": [51300, 663, 311, 437, 20730, 5646, 775, 51400], "temperature": 0.0, "avg_logprob": -0.29604372867318085, "compression_ratio": 1.6703296703296704, "no_speech_prob": 3.480786472209729e-05}, {"id": 1310, "seek": 615084, "start": 6173.400000000001, "end": 6175.400000000001, "text": " There's a nice idea in", "tokens": [51492, 821, 311, 257, 1481, 1558, 294, 51592], "temperature": 0.0, "avg_logprob": -0.29604372867318085, "compression_ratio": 1.6703296703296704, "no_speech_prob": 3.480786472209729e-05}, {"id": 1311, "seek": 615084, "start": 6176.08, "end": 6178.88, "text": " Python that you can put a star", "tokens": [51626, 15329, 300, 291, 393, 829, 257, 3543, 51766], "temperature": 0.0, "avg_logprob": -0.29604372867318085, "compression_ratio": 1.6703296703296704, "no_speech_prob": 3.480786472209729e-05}, {"id": 1312, "seek": 617888, "start": 6179.84, "end": 6186.8, "text": " Before any argument and if that argument is an iterator something that you can look through", "tokens": [50412, 4546, 604, 6770, 293, 498, 300, 6770, 307, 364, 17138, 1639, 746, 300, 291, 393, 574, 807, 50760], "temperature": 0.0, "avg_logprob": -0.4002130423019181, "compression_ratio": 1.5664739884393064, "no_speech_prob": 8.801087460597046e-06}, {"id": 1313, "seek": 617888, "start": 6187.52, "end": 6192.08, "text": " It acts as if you had taken that whole list and actually put it", "tokens": [50796, 467, 10672, 382, 498, 291, 632, 2726, 300, 1379, 1329, 293, 767, 829, 309, 51024], "temperature": 0.0, "avg_logprob": -0.4002130423019181, "compression_ratio": 1.5664739884393064, "no_speech_prob": 8.801087460597046e-06}, {"id": 1314, "seek": 617888, "start": 6193.52, "end": 6198.16, "text": " Inside those brackets right so let's say that W to V list", "tokens": [51096, 15123, 729, 26179, 558, 370, 718, 311, 584, 300, 343, 281, 691, 1329, 51328], "temperature": 0.0, "avg_logprob": -0.4002130423019181, "compression_ratio": 1.5664739884393064, "no_speech_prob": 8.801087460597046e-06}, {"id": 1315, "seek": 617888, "start": 6199.0, "end": 6200.8, "text": " contained like", "tokens": [51370, 16212, 411, 51460], "temperature": 0.0, "avg_logprob": -0.4002130423019181, "compression_ratio": 1.5664739884393064, "no_speech_prob": 8.801087460597046e-06}, {"id": 1316, "seek": 617888, "start": 6200.8, "end": 6206.64, "text": " Fox colon and then some array and then hug", "tokens": [51460, 11388, 8255, 293, 550, 512, 10225, 293, 550, 8777, 51752], "temperature": 0.0, "avg_logprob": -0.4002130423019181, "compression_ratio": 1.5664739884393064, "no_speech_prob": 8.801087460597046e-06}, {"id": 1317, "seek": 620664, "start": 6207.64, "end": 6210.72, "text": " Colon and then some array", "tokens": [50414, 21408, 293, 550, 512, 10225, 50568], "temperature": 0.0, "avg_logprob": -0.500391232765327, "compression_ratio": 1.5, "no_speech_prob": 0.00010720871068770066}, {"id": 1318, "seek": 620664, "start": 6213.360000000001, "end": 6217.160000000001, "text": " And so forth right when you go zip star that", "tokens": [50700, 400, 370, 5220, 558, 562, 291, 352, 20730, 3543, 300, 50890], "temperature": 0.0, "avg_logprob": -0.500391232765327, "compression_ratio": 1.5, "no_speech_prob": 0.00010720871068770066}, {"id": 1319, "seek": 620664, "start": 6217.84, "end": 6222.160000000001, "text": " It's the same as actually taking the contents of that list", "tokens": [50924, 467, 311, 264, 912, 382, 767, 1940, 264, 15768, 295, 300, 1329, 51140], "temperature": 0.0, "avg_logprob": -0.500391232765327, "compression_ratio": 1.5, "no_speech_prob": 0.00010720871068770066}, {"id": 1320, "seek": 620664, "start": 6223.08, "end": 6225.12, "text": " And putting them inside there", "tokens": [51186, 400, 3372, 552, 1854, 456, 51288], "temperature": 0.0, "avg_logprob": -0.500391232765327, "compression_ratio": 1.5, "no_speech_prob": 0.00010720871068770066}, {"id": 1321, "seek": 620664, "start": 6229.320000000001, "end": 6234.88, "text": " You would want star star if it was a dictionary star for list not quite", "tokens": [51498, 509, 576, 528, 3543, 3543, 498, 309, 390, 257, 25890, 3543, 337, 1329, 406, 1596, 51776], "temperature": 0.0, "avg_logprob": -0.500391232765327, "compression_ratio": 1.5, "no_speech_prob": 0.00010720871068770066}, {"id": 1322, "seek": 623488, "start": 6234.92, "end": 6236.92, "text": " Right", "tokens": [50366, 1779, 50466], "temperature": 0.0, "avg_logprob": -0.3530377213672925, "compression_ratio": 1.663265306122449, "no_speech_prob": 3.883081808453426e-05}, {"id": 1323, "seek": 623488, "start": 6236.92, "end": 6239.12, "text": " Star just means you're treating it as an iterator", "tokens": [50466, 5705, 445, 1355, 291, 434, 15083, 309, 382, 364, 17138, 1639, 50576], "temperature": 0.0, "avg_logprob": -0.3530377213672925, "compression_ratio": 1.663265306122449, "no_speech_prob": 3.883081808453426e-05}, {"id": 1324, "seek": 623488, "start": 6244.0, "end": 6247.24, "text": " But you're right I mean in this case we are using a list so let's that's not", "tokens": [50820, 583, 291, 434, 558, 286, 914, 294, 341, 1389, 321, 366, 1228, 257, 1329, 370, 718, 311, 300, 311, 406, 50982], "temperature": 0.0, "avg_logprob": -0.3530377213672925, "compression_ratio": 1.663265306122449, "no_speech_prob": 3.883081808453426e-05}, {"id": 1325, "seek": 623488, "start": 6247.92, "end": 6251.52, "text": " Let's not worry about it. So yeah, you can use let's talk about star star another time", "tokens": [51016, 961, 311, 406, 3292, 466, 309, 13, 407, 1338, 11, 291, 393, 764, 718, 311, 751, 466, 3543, 3543, 1071, 565, 51196], "temperature": 0.0, "avg_logprob": -0.3530377213672925, "compression_ratio": 1.663265306122449, "no_speech_prob": 3.883081808453426e-05}, {"id": 1326, "seek": 623488, "start": 6252.32, "end": 6254.32, "text": " But you're right in this case. We have a list", "tokens": [51236, 583, 291, 434, 558, 294, 341, 1389, 13, 492, 362, 257, 1329, 51336], "temperature": 0.0, "avg_logprob": -0.3530377213672925, "compression_ratio": 1.663265306122449, "no_speech_prob": 3.883081808453426e-05}, {"id": 1327, "seek": 623488, "start": 6254.88, "end": 6259.32, "text": " Which is actually just in this format as Fox comma array", "tokens": [51364, 3013, 307, 767, 445, 294, 341, 7877, 382, 11388, 22117, 10225, 51586], "temperature": 0.0, "avg_logprob": -0.3530377213672925, "compression_ratio": 1.663265306122449, "no_speech_prob": 3.883081808453426e-05}, {"id": 1328, "seek": 623488, "start": 6260.2, "end": 6261.68, "text": " hug", "tokens": [51630, 8777, 51704], "temperature": 0.0, "avg_logprob": -0.3530377213672925, "compression_ratio": 1.663265306122449, "no_speech_prob": 3.883081808453426e-05}, {"id": 1329, "seek": 626168, "start": 6261.68, "end": 6266.200000000001, "text": " Comma array and then lots more right so", "tokens": [50364, 3046, 64, 10225, 293, 550, 3195, 544, 558, 370, 50590], "temperature": 0.0, "avg_logprob": -0.32828810276129305, "compression_ratio": 1.9225806451612903, "no_speech_prob": 0.0008693632553331554}, {"id": 1330, "seek": 626168, "start": 6267.400000000001, "end": 6272.68, "text": " What this is going to do is when we zip this is it's going to basically take", "tokens": [50650, 708, 341, 307, 516, 281, 360, 307, 562, 321, 20730, 341, 307, 309, 311, 516, 281, 1936, 747, 50914], "temperature": 0.0, "avg_logprob": -0.32828810276129305, "compression_ratio": 1.9225806451612903, "no_speech_prob": 0.0008693632553331554}, {"id": 1331, "seek": 626168, "start": 6274.400000000001, "end": 6276.400000000001, "text": " All of these things and", "tokens": [51000, 1057, 295, 613, 721, 293, 51100], "temperature": 0.0, "avg_logprob": -0.32828810276129305, "compression_ratio": 1.9225806451612903, "no_speech_prob": 0.0008693632553331554}, {"id": 1332, "seek": 626168, "start": 6277.04, "end": 6279.64, "text": " Create one list for those that's going to become words", "tokens": [51132, 20248, 472, 1329, 337, 729, 300, 311, 516, 281, 1813, 2283, 51262], "temperature": 0.0, "avg_logprob": -0.32828810276129305, "compression_ratio": 1.9225806451612903, "no_speech_prob": 0.0008693632553331554}, {"id": 1333, "seek": 626168, "start": 6280.52, "end": 6285.0, "text": " And then all these things create one list for those and that's going to become vectors", "tokens": [51306, 400, 550, 439, 613, 721, 1884, 472, 1329, 337, 729, 293, 300, 311, 516, 281, 1813, 18875, 51530], "temperature": 0.0, "avg_logprob": -0.32828810276129305, "compression_ratio": 1.9225806451612903, "no_speech_prob": 0.0008693632553331554}, {"id": 1334, "seek": 626168, "start": 6285.8, "end": 6287.8, "text": " so this idea of", "tokens": [51570, 370, 341, 1558, 295, 51670], "temperature": 0.0, "avg_logprob": -0.32828810276129305, "compression_ratio": 1.9225806451612903, "no_speech_prob": 0.0008693632553331554}, {"id": 1335, "seek": 628780, "start": 6287.96, "end": 6289.96, "text": " You", "tokens": [50372, 509, 50472], "temperature": 0.0, "avg_logprob": -0.3519627864544208, "compression_ratio": 1.5803571428571428, "no_speech_prob": 5.862767920916667e-06}, {"id": 1336, "seek": 628780, "start": 6290.0, "end": 6294.96, "text": " Zip star is something we're going to use quite a lot honestly I don't", "tokens": [50474, 1176, 647, 3543, 307, 746, 321, 434, 516, 281, 764, 1596, 257, 688, 6095, 286, 500, 380, 50722], "temperature": 0.0, "avg_logprob": -0.3519627864544208, "compression_ratio": 1.5803571428571428, "no_speech_prob": 5.862767920916667e-06}, {"id": 1337, "seek": 628780, "start": 6296.24, "end": 6300.24, "text": " Normally like think about what it's doing. I just know that any time I've got", "tokens": [50786, 17424, 411, 519, 466, 437, 309, 311, 884, 13, 286, 445, 458, 300, 604, 565, 286, 600, 658, 50986], "temperature": 0.0, "avg_logprob": -0.3519627864544208, "compression_ratio": 1.5803571428571428, "no_speech_prob": 5.862767920916667e-06}, {"id": 1338, "seek": 628780, "start": 6301.52, "end": 6304.76, "text": " like a list of tuples, and I want to turn it into a", "tokens": [51050, 411, 257, 1329, 295, 2604, 2622, 11, 293, 286, 528, 281, 1261, 309, 666, 257, 51212], "temperature": 0.0, "avg_logprob": -0.3519627864544208, "compression_ratio": 1.5803571428571428, "no_speech_prob": 5.862767920916667e-06}, {"id": 1339, "seek": 628780, "start": 6305.76, "end": 6307.6, "text": " couple of lists", "tokens": [51262, 1916, 295, 14511, 51354], "temperature": 0.0, "avg_logprob": -0.3519627864544208, "compression_ratio": 1.5803571428571428, "no_speech_prob": 5.862767920916667e-06}, {"id": 1340, "seek": 628780, "start": 6307.6, "end": 6309.6, "text": " You just do zip star. Oh", "tokens": [51354, 509, 445, 360, 20730, 3543, 13, 876, 51454], "temperature": 0.0, "avg_logprob": -0.3519627864544208, "compression_ratio": 1.5803571428571428, "no_speech_prob": 5.862767920916667e-06}, {"id": 1341, "seek": 628780, "start": 6310.400000000001, "end": 6312.84, "text": " That's all that is it's just a little Python thing", "tokens": [51494, 663, 311, 439, 300, 307, 309, 311, 445, 257, 707, 15329, 551, 51616], "temperature": 0.0, "avg_logprob": -0.3519627864544208, "compression_ratio": 1.5803571428571428, "no_speech_prob": 5.862767920916667e-06}, {"id": 1342, "seek": 628780, "start": 6313.6, "end": 6316.56, "text": " Okay, so this gives us a list of words and most of vectors", "tokens": [51654, 1033, 11, 370, 341, 2709, 505, 257, 1329, 295, 2283, 293, 881, 295, 18875, 51802], "temperature": 0.0, "avg_logprob": -0.3519627864544208, "compression_ratio": 1.5803571428571428, "no_speech_prob": 5.862767920916667e-06}, {"id": 1343, "seek": 631780, "start": 6317.84, "end": 6320.72, "text": " So anytime I start looking at some new data", "tokens": [50366, 407, 13038, 286, 722, 1237, 412, 512, 777, 1412, 50510], "temperature": 0.0, "avg_logprob": -0.35931316557384674, "compression_ratio": 1.7630522088353413, "no_speech_prob": 2.2473906938103028e-05}, {"id": 1344, "seek": 631780, "start": 6321.360000000001, "end": 6322.68, "text": " I", "tokens": [50542, 286, 50608], "temperature": 0.0, "avg_logprob": -0.35931316557384674, "compression_ratio": 1.7630522088353413, "no_speech_prob": 2.2473906938103028e-05}, {"id": 1345, "seek": 631780, "start": 6322.68, "end": 6327.320000000001, "text": " Always want to test it and so I wanted to make sure this worked the way. I thought it ought to work", "tokens": [50608, 11270, 528, 281, 1500, 309, 293, 370, 286, 1415, 281, 652, 988, 341, 2732, 264, 636, 13, 286, 1194, 309, 13416, 281, 589, 50840], "temperature": 0.0, "avg_logprob": -0.35931316557384674, "compression_ratio": 1.7630522088353413, "no_speech_prob": 2.2473906938103028e-05}, {"id": 1346, "seek": 631780, "start": 6327.320000000001, "end": 6333.56, "text": " So one thing I thought was okay. Let's look at the correlation coefficient between small J. Jeremy and big J. Jeremy and", "tokens": [50840, 407, 472, 551, 286, 1194, 390, 1392, 13, 961, 311, 574, 412, 264, 20009, 17619, 1296, 1359, 508, 13, 17809, 293, 955, 508, 13, 17809, 293, 51152], "temperature": 0.0, "avg_logprob": -0.35931316557384674, "compression_ratio": 1.7630522088353413, "no_speech_prob": 2.2473906938103028e-05}, {"id": 1347, "seek": 631780, "start": 6334.64, "end": 6337.320000000001, "text": " Indeed there is some correlation. She would expect", "tokens": [51206, 15061, 456, 307, 512, 20009, 13, 1240, 576, 2066, 51340], "temperature": 0.0, "avg_logprob": -0.35931316557384674, "compression_ratio": 1.7630522088353413, "no_speech_prob": 2.2473906938103028e-05}, {"id": 1348, "seek": 631780, "start": 6338.400000000001, "end": 6345.24, "text": " For else the correlation between Jeremy and banana. I hate bananas, so I was hoping this would be like massively negative", "tokens": [51394, 1171, 1646, 264, 20009, 1296, 17809, 293, 14194, 13, 286, 4700, 22742, 11, 370, 286, 390, 7159, 341, 576, 312, 411, 29379, 3671, 51736], "temperature": 0.0, "avg_logprob": -0.35931316557384674, "compression_ratio": 1.7630522088353413, "no_speech_prob": 2.2473906938103028e-05}, {"id": 1349, "seek": 634524, "start": 6345.639999999999, "end": 6352.8, "text": " Unfortunately it's not but it is at least lower than the correlation between Jeremy and big Jeremy so like okay. It's it's not always easy to", "tokens": [50384, 8590, 309, 311, 406, 457, 309, 307, 412, 1935, 3126, 813, 264, 20009, 1296, 17809, 293, 955, 17809, 370, 411, 1392, 13, 467, 311, 309, 311, 406, 1009, 1858, 281, 50742], "temperature": 0.0, "avg_logprob": -0.31964867203323927, "compression_ratio": 1.6330935251798562, "no_speech_prob": 4.400098623591475e-05}, {"id": 1350, "seek": 634524, "start": 6353.88, "end": 6358.28, "text": " Exactly test data, but you know try and come up with things that ought to be true make sure they are true", "tokens": [50796, 7587, 1500, 1412, 11, 457, 291, 458, 853, 293, 808, 493, 365, 721, 300, 13416, 281, 312, 2074, 652, 988, 436, 366, 2074, 51016], "temperature": 0.0, "avg_logprob": -0.31964867203323927, "compression_ratio": 1.6330935251798562, "no_speech_prob": 4.400098623591475e-05}, {"id": 1351, "seek": 634524, "start": 6358.92, "end": 6364.32, "text": " And so in this case this is giving me some comfort that these word vectors behave the way I expect them to", "tokens": [51048, 400, 370, 294, 341, 1389, 341, 307, 2902, 385, 512, 3400, 300, 613, 1349, 18875, 15158, 264, 636, 286, 2066, 552, 281, 51318], "temperature": 0.0, "avg_logprob": -0.31964867203323927, "compression_ratio": 1.6330935251798562, "no_speech_prob": 4.400098623591475e-05}, {"id": 1352, "seek": 634524, "start": 6366.12, "end": 6372.12, "text": " Now I don't really care about capitalization, so I just go ahead and create a lowercase word to vec", "tokens": [51408, 823, 286, 500, 380, 534, 1127, 466, 4238, 2144, 11, 370, 286, 445, 352, 2286, 293, 1884, 257, 3126, 9765, 1349, 281, 42021, 51708], "temperature": 0.0, "avg_logprob": -0.31964867203323927, "compression_ratio": 1.6330935251798562, "no_speech_prob": 4.400098623591475e-05}, {"id": 1353, "seek": 637212, "start": 6372.64, "end": 6376.32, "text": " Dictionary where I just do the lowercase version for everything", "tokens": [50390, 413, 4105, 822, 689, 286, 445, 360, 264, 3126, 9765, 3037, 337, 1203, 50574], "temperature": 0.0, "avg_logprob": -0.33286518997020936, "compression_ratio": 1.6150234741784038, "no_speech_prob": 3.5912795283365995e-05}, {"id": 1354, "seek": 637212, "start": 6378.8, "end": 6381.48, "text": " One trick here is I go through in reverse", "tokens": [50698, 1485, 4282, 510, 307, 286, 352, 807, 294, 9943, 50832], "temperature": 0.0, "avg_logprob": -0.33286518997020936, "compression_ratio": 1.6150234741784038, "no_speech_prob": 3.5912795283365995e-05}, {"id": 1355, "seek": 637212, "start": 6382.44, "end": 6384.44, "text": " Because what to vec is ordered", "tokens": [50880, 1436, 437, 281, 42021, 307, 8866, 50980], "temperature": 0.0, "avg_logprob": -0.33286518997020936, "compression_ratio": 1.6150234741784038, "no_speech_prob": 3.5912795283365995e-05}, {"id": 1356, "seek": 637212, "start": 6384.96, "end": 6390.88, "text": " Where the most common words are first so by going in reverse it means if there is both a capital J", "tokens": [51006, 2305, 264, 881, 2689, 2283, 366, 700, 370, 538, 516, 294, 9943, 309, 1355, 498, 456, 307, 1293, 257, 4238, 508, 51302], "temperature": 0.0, "avg_logprob": -0.33286518997020936, "compression_ratio": 1.6150234741784038, "no_speech_prob": 3.5912795283365995e-05}, {"id": 1357, "seek": 637212, "start": 6390.88, "end": 6395.44, "text": " Jeremy and a small J. Jeremy the one that's going to end up in my dictionary will be the more common", "tokens": [51302, 17809, 293, 257, 1359, 508, 13, 17809, 264, 472, 300, 311, 516, 281, 917, 493, 294, 452, 25890, 486, 312, 264, 544, 2689, 51530], "temperature": 0.0, "avg_logprob": -0.33286518997020936, "compression_ratio": 1.6150234741784038, "no_speech_prob": 3.5912795283365995e-05}, {"id": 1358, "seek": 637212, "start": 6396.24, "end": 6398.24, "text": " Okay", "tokens": [51570, 1033, 51670], "temperature": 0.0, "avg_logprob": -0.33286518997020936, "compression_ratio": 1.6150234741784038, "no_speech_prob": 3.5912795283365995e-05}, {"id": 1359, "seek": 637212, "start": 6399.24, "end": 6401.24, "text": " So", "tokens": [51720, 407, 51820], "temperature": 0.0, "avg_logprob": -0.33286518997020936, "compression_ratio": 1.6150234741784038, "no_speech_prob": 3.5912795283365995e-05}, {"id": 1360, "seek": 640212, "start": 6402.12, "end": 6408.44, "text": " What I want for device is to now get this word vector for each one of our", "tokens": [50364, 708, 286, 528, 337, 4302, 307, 281, 586, 483, 341, 1349, 8062, 337, 1184, 472, 295, 527, 50680], "temperature": 0.0, "avg_logprob": -0.2861035226405352, "compression_ratio": 1.6113744075829384, "no_speech_prob": 2.3552544007543474e-05}, {"id": 1361, "seek": 640212, "start": 6408.96, "end": 6410.96, "text": " 1,000 categories", "tokens": [50706, 502, 11, 1360, 10479, 50806], "temperature": 0.0, "avg_logprob": -0.2861035226405352, "compression_ratio": 1.6113744075829384, "no_speech_prob": 2.3552544007543474e-05}, {"id": 1362, "seek": 640212, "start": 6411.2, "end": 6413.2, "text": " in image net and", "tokens": [50818, 294, 3256, 2533, 293, 50918], "temperature": 0.0, "avg_logprob": -0.2861035226405352, "compression_ratio": 1.6113744075829384, "no_speech_prob": 2.3552544007543474e-05}, {"id": 1363, "seek": 640212, "start": 6413.48, "end": 6418.12, "text": " Then I'm going to go even further than that because I want to go beyond image net", "tokens": [50932, 1396, 286, 478, 516, 281, 352, 754, 3052, 813, 300, 570, 286, 528, 281, 352, 4399, 3256, 2533, 51164], "temperature": 0.0, "avg_logprob": -0.2861035226405352, "compression_ratio": 1.6113744075829384, "no_speech_prob": 2.3552544007543474e-05}, {"id": 1364, "seek": 640212, "start": 6418.44, "end": 6422.2, "text": " So I actually went and downloaded the original word net", "tokens": [51180, 407, 286, 767, 1437, 293, 21748, 264, 3380, 1349, 2533, 51368], "temperature": 0.0, "avg_logprob": -0.2861035226405352, "compression_ratio": 1.6113744075829384, "no_speech_prob": 2.3552544007543474e-05}, {"id": 1365, "seek": 640212, "start": 6423.2, "end": 6428.12, "text": " Categories and I filled it down to find all the nouns and I discovered that there are actually", "tokens": [51418, 383, 2968, 2083, 293, 286, 6412, 309, 760, 281, 915, 439, 264, 48184, 293, 286, 6941, 300, 456, 366, 767, 51664], "temperature": 0.0, "avg_logprob": -0.2861035226405352, "compression_ratio": 1.6113744075829384, "no_speech_prob": 2.3552544007543474e-05}, {"id": 1366, "seek": 642812, "start": 6429.08, "end": 6434.32, "text": " 82,000 nouns in word net which is quite a few it's quite fun looking through them", "tokens": [50412, 29097, 11, 1360, 48184, 294, 1349, 2533, 597, 307, 1596, 257, 1326, 309, 311, 1596, 1019, 1237, 807, 552, 50674], "temperature": 0.0, "avg_logprob": -0.3189076979955037, "compression_ratio": 1.6830357142857142, "no_speech_prob": 3.1201663659885526e-05}, {"id": 1367, "seek": 642812, "start": 6434.48, "end": 6438.96, "text": " So I'm going to create a map of word vectors for every image net", "tokens": [50682, 407, 286, 478, 516, 281, 1884, 257, 4471, 295, 1349, 18875, 337, 633, 3256, 2533, 50906], "temperature": 0.0, "avg_logprob": -0.3189076979955037, "compression_ratio": 1.6830357142857142, "no_speech_prob": 3.1201663659885526e-05}, {"id": 1368, "seek": 642812, "start": 6439.24, "end": 6445.5199999999995, "text": " Category be one set and every word net noun that'll be another set and so my goal in this project", "tokens": [50920, 383, 48701, 312, 472, 992, 293, 633, 1349, 2533, 23307, 300, 603, 312, 1071, 992, 293, 370, 452, 3387, 294, 341, 1716, 51234], "temperature": 0.0, "avg_logprob": -0.3189076979955037, "compression_ratio": 1.6830357142857142, "no_speech_prob": 3.1201663659885526e-05}, {"id": 1369, "seek": 642812, "start": 6445.8, "end": 6448.599999999999, "text": " Will be to try and create something that can do useful things", "tokens": [51248, 3099, 312, 281, 853, 293, 1884, 746, 300, 393, 360, 4420, 721, 51388], "temperature": 0.0, "avg_logprob": -0.3189076979955037, "compression_ratio": 1.6830357142857142, "no_speech_prob": 3.1201663659885526e-05}, {"id": 1370, "seek": 642812, "start": 6449.36, "end": 6453.16, "text": " With the full set of word net nouns we're going to go beyond image net", "tokens": [51426, 2022, 264, 1577, 992, 295, 1349, 2533, 48184, 321, 434, 516, 281, 352, 4399, 3256, 2533, 51616], "temperature": 0.0, "avg_logprob": -0.3189076979955037, "compression_ratio": 1.6830357142857142, "no_speech_prob": 3.1201663659885526e-05}, {"id": 1371, "seek": 645316, "start": 6454.0, "end": 6459.84, "text": " We've already got the a thousand image net categories. We've used that many of times before so grab those load them in", "tokens": [50406, 492, 600, 1217, 658, 264, 257, 4714, 3256, 2533, 10479, 13, 492, 600, 1143, 300, 867, 295, 1413, 949, 370, 4444, 729, 3677, 552, 294, 50698], "temperature": 0.0, "avg_logprob": -0.43428699786846453, "compression_ratio": 1.4696132596685083, "no_speech_prob": 7.843620551284403e-05}, {"id": 1372, "seek": 645316, "start": 6461.08, "end": 6462.72, "text": " I", "tokens": [50760, 286, 50842], "temperature": 0.0, "avg_logprob": -0.43428699786846453, "compression_ratio": 1.4696132596685083, "no_speech_prob": 7.843620551284403e-05}, {"id": 1373, "seek": 645316, "start": 6462.72, "end": 6464.16, "text": " can", "tokens": [50842, 393, 50914], "temperature": 0.0, "avg_logprob": -0.43428699786846453, "compression_ratio": 1.4696132596685083, "no_speech_prob": 7.843620551284403e-05}, {"id": 1374, "seek": 645316, "start": 6464.16, "end": 6466.16, "text": " Okay, and then I do the same thing for", "tokens": [50914, 1033, 11, 293, 550, 286, 360, 264, 912, 551, 337, 51014], "temperature": 0.0, "avg_logprob": -0.43428699786846453, "compression_ratio": 1.4696132596685083, "no_speech_prob": 7.843620551284403e-05}, {"id": 1375, "seek": 645316, "start": 6467.16, "end": 6469.16, "text": " the full set", "tokens": [51064, 264, 1577, 992, 51164], "temperature": 0.0, "avg_logprob": -0.43428699786846453, "compression_ratio": 1.4696132596685083, "no_speech_prob": 7.843620551284403e-05}, {"id": 1376, "seek": 645316, "start": 6469.28, "end": 6471.76, "text": " Wordnet IDs which I will share with you", "tokens": [51170, 8725, 7129, 48212, 597, 286, 486, 2073, 365, 291, 51294], "temperature": 0.0, "avg_logprob": -0.43428699786846453, "compression_ratio": 1.4696132596685083, "no_speech_prob": 7.843620551284403e-05}, {"id": 1377, "seek": 645316, "start": 6472.88, "end": 6474.5599999999995, "text": " and", "tokens": [51350, 293, 51434], "temperature": 0.0, "avg_logprob": -0.43428699786846453, "compression_ratio": 1.4696132596685083, "no_speech_prob": 7.843620551284403e-05}, {"id": 1378, "seek": 645316, "start": 6474.5599999999995, "end": 6478.68, "text": " So now I can go ahead and create a dictionary", "tokens": [51434, 407, 586, 286, 393, 352, 2286, 293, 1884, 257, 25890, 51640], "temperature": 0.0, "avg_logprob": -0.43428699786846453, "compression_ratio": 1.4696132596685083, "no_speech_prob": 7.843620551284403e-05}, {"id": 1379, "seek": 647868, "start": 6479.68, "end": 6482.360000000001, "text": " Which goes through every one of my", "tokens": [50414, 3013, 1709, 807, 633, 472, 295, 452, 50548], "temperature": 0.0, "avg_logprob": -0.37233825876742976, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.0007321701268665493}, {"id": 1380, "seek": 647868, "start": 6483.72, "end": 6486.16, "text": " Every one of my image net thousand categories", "tokens": [50616, 2048, 472, 295, 452, 3256, 2533, 4714, 10479, 50738], "temperature": 0.0, "avg_logprob": -0.37233825876742976, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.0007321701268665493}, {"id": 1381, "seek": 647868, "start": 6487.16, "end": 6489.16, "text": " and converts it into the", "tokens": [50788, 293, 38874, 309, 666, 264, 50888], "temperature": 0.0, "avg_logprob": -0.37233825876742976, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.0007321701268665493}, {"id": 1382, "seek": 647868, "start": 6490.0, "end": 6491.6, "text": " word vector", "tokens": [50930, 1349, 8062, 51010], "temperature": 0.0, "avg_logprob": -0.37233825876742976, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.0007321701268665493}, {"id": 1383, "seek": 647868, "start": 6491.6, "end": 6493.6, "text": " And notice I have a filter here", "tokens": [51010, 400, 3449, 286, 362, 257, 6608, 510, 51110], "temperature": 0.0, "avg_logprob": -0.37233825876742976, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.0007321701268665493}, {"id": 1384, "seek": 647868, "start": 6493.76, "end": 6496.16, "text": " and that's because some of the", "tokens": [51118, 293, 300, 311, 570, 512, 295, 264, 51238], "temperature": 0.0, "avg_logprob": -0.37233825876742976, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.0007321701268665493}, {"id": 1385, "seek": 647868, "start": 6496.88, "end": 6498.88, "text": " image net categories", "tokens": [51274, 3256, 2533, 10479, 51374], "temperature": 0.0, "avg_logprob": -0.37233825876742976, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.0007321701268665493}, {"id": 1386, "seek": 647868, "start": 6500.0, "end": 6506.320000000001, "text": " Won't be in word2vec and that's because like sometimes the image net categories will say things like", "tokens": [51430, 14710, 380, 312, 294, 1349, 17, 303, 66, 293, 300, 311, 570, 411, 2171, 264, 3256, 2533, 10479, 486, 584, 721, 411, 51746], "temperature": 0.0, "avg_logprob": -0.37233825876742976, "compression_ratio": 1.776470588235294, "no_speech_prob": 0.0007321701268665493}, {"id": 1387, "seek": 650632, "start": 6506.679999999999, "end": 6511.44, "text": " Hug bracket doc you know they won't be exactly in the same format", "tokens": [50382, 46892, 16904, 3211, 291, 458, 436, 1582, 380, 312, 2293, 294, 264, 912, 7877, 50620], "temperature": 0.0, "avg_logprob": -0.329551230085657, "compression_ratio": 1.5758928571428572, "no_speech_prob": 7.722141890553758e-05}, {"id": 1388, "seek": 650632, "start": 6511.84, "end": 6517.88, "text": " If you wanted to you could probably get a better match than this, but I found even with this simple approach", "tokens": [50640, 759, 291, 1415, 281, 291, 727, 1391, 483, 257, 1101, 2995, 813, 341, 11, 457, 286, 1352, 754, 365, 341, 2199, 3109, 50942], "temperature": 0.0, "avg_logprob": -0.329551230085657, "compression_ratio": 1.5758928571428572, "no_speech_prob": 7.722141890553758e-05}, {"id": 1389, "seek": 650632, "start": 6517.88, "end": 6519.88, "text": " I managed to match", "tokens": [50942, 286, 6453, 281, 2995, 51042], "temperature": 0.0, "avg_logprob": -0.329551230085657, "compression_ratio": 1.5758928571428572, "no_speech_prob": 7.722141890553758e-05}, {"id": 1390, "seek": 650632, "start": 6520.0, "end": 6522.0, "text": " 51,600 out of the 82,000", "tokens": [51048, 18485, 11, 15707, 484, 295, 264, 29097, 11, 1360, 51148], "temperature": 0.0, "avg_logprob": -0.329551230085657, "compression_ratio": 1.5758928571428572, "no_speech_prob": 7.722141890553758e-05}, {"id": 1391, "seek": 650632, "start": 6522.92, "end": 6525.5599999999995, "text": " word net nouns which I thought was", "tokens": [51194, 1349, 2533, 48184, 597, 286, 1194, 390, 51326], "temperature": 0.0, "avg_logprob": -0.329551230085657, "compression_ratio": 1.5758928571428572, "no_speech_prob": 7.722141890553758e-05}, {"id": 1392, "seek": 650632, "start": 6526.5199999999995, "end": 6528.36, "text": " pretty good", "tokens": [51374, 1238, 665, 51466], "temperature": 0.0, "avg_logprob": -0.329551230085657, "compression_ratio": 1.5758928571428572, "no_speech_prob": 7.722141890553758e-05}, {"id": 1393, "seek": 650632, "start": 6528.36, "end": 6534.92, "text": " so what I did then was I created a list of all of the categories which didn't match and", "tokens": [51466, 370, 437, 286, 630, 550, 390, 286, 2942, 257, 1329, 295, 439, 295, 264, 10479, 597, 994, 380, 2995, 293, 51794], "temperature": 0.0, "avg_logprob": -0.329551230085657, "compression_ratio": 1.5758928571428572, "no_speech_prob": 7.722141890553758e-05}, {"id": 1394, "seek": 653492, "start": 6535.72, "end": 6539.84, "text": " This commented out bit as you can see is something which literally just moved those", "tokens": [50404, 639, 26940, 484, 857, 382, 291, 393, 536, 307, 746, 597, 3736, 445, 4259, 729, 50610], "temperature": 0.0, "avg_logprob": -0.2791265509594446, "compression_ratio": 1.5848214285714286, "no_speech_prob": 4.133469701628201e-05}, {"id": 1395, "seek": 653492, "start": 6540.76, "end": 6544.08, "text": " Folders out of the way so that they're not in my image net", "tokens": [50656, 24609, 433, 484, 295, 264, 636, 370, 300, 436, 434, 406, 294, 452, 3256, 2533, 50822], "temperature": 0.0, "avg_logprob": -0.2791265509594446, "compression_ratio": 1.5848214285714286, "no_speech_prob": 4.133469701628201e-05}, {"id": 1396, "seek": 653492, "start": 6545.16, "end": 6547.16, "text": " path anymore", "tokens": [50876, 3100, 3602, 50976], "temperature": 0.0, "avg_logprob": -0.2791265509594446, "compression_ratio": 1.5848214285714286, "no_speech_prob": 4.133469701628201e-05}, {"id": 1397, "seek": 653492, "start": 6547.52, "end": 6552.4, "text": " Okay, so the details aren't very important, but hopefully you can see at the end of this process", "tokens": [50994, 1033, 11, 370, 264, 4365, 3212, 380, 588, 1021, 11, 457, 4696, 291, 393, 536, 412, 264, 917, 295, 341, 1399, 51238], "temperature": 0.0, "avg_logprob": -0.2791265509594446, "compression_ratio": 1.5848214285714286, "no_speech_prob": 4.133469701628201e-05}, {"id": 1398, "seek": 653492, "start": 6552.88, "end": 6559.4400000000005, "text": " I've got something that maps every image net category to a word vector at least if I could find it and", "tokens": [51262, 286, 600, 658, 746, 300, 11317, 633, 3256, 2533, 7719, 281, 257, 1349, 8062, 412, 1935, 498, 286, 727, 915, 309, 293, 51590], "temperature": 0.0, "avg_logprob": -0.2791265509594446, "compression_ratio": 1.5848214285714286, "no_speech_prob": 4.133469701628201e-05}, {"id": 1399, "seek": 655944, "start": 6560.0, "end": 6567.639999999999, "text": " Every word net noun to a vector at least if I could find it and that I've modified my image net", "tokens": [50392, 2048, 1349, 2533, 23307, 281, 257, 8062, 412, 1935, 498, 286, 727, 915, 309, 293, 300, 286, 600, 15873, 452, 3256, 2533, 50774], "temperature": 0.0, "avg_logprob": -0.297954042079085, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.00012339404202066362}, {"id": 1400, "seek": 655944, "start": 6569.32, "end": 6574.799999999999, "text": " Data so that the categories I couldn't find I've moved those folders out of the way", "tokens": [50858, 11888, 370, 300, 264, 10479, 286, 2809, 380, 915, 286, 600, 4259, 729, 31082, 484, 295, 264, 636, 51132], "temperature": 0.0, "avg_logprob": -0.297954042079085, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.00012339404202066362}, {"id": 1401, "seek": 655944, "start": 6576.4, "end": 6582.919999999999, "text": " Okay, nothing particularly interesting there, and that's because", "tokens": [51212, 1033, 11, 1825, 4098, 1880, 456, 11, 293, 300, 311, 570, 51538], "temperature": 0.0, "avg_logprob": -0.297954042079085, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.00012339404202066362}, {"id": 1402, "seek": 658292, "start": 6583.92, "end": 6588.0, "text": " Word nets not that big it's in there, so that's pretty straightforward", "tokens": [50414, 8725, 36170, 406, 300, 955, 309, 311, 294, 456, 11, 370, 300, 311, 1238, 15325, 50618], "temperature": 0.0, "avg_logprob": -0.3466613075949929, "compression_ratio": 1.4705882352941178, "no_speech_prob": 6.922161992406473e-05}, {"id": 1403, "seek": 658292, "start": 6588.68, "end": 6592.12, "text": " The images are a bit harder because we've got you know a million or so images", "tokens": [50652, 440, 5267, 366, 257, 857, 6081, 570, 321, 600, 658, 291, 458, 257, 2459, 420, 370, 5267, 50824], "temperature": 0.0, "avg_logprob": -0.3466613075949929, "compression_ratio": 1.4705882352941178, "no_speech_prob": 6.922161992406473e-05}, {"id": 1404, "seek": 658292, "start": 6593.52, "end": 6598.4800000000005, "text": " So we're going to try everything we can to make this run as quickly as possible", "tokens": [50894, 407, 321, 434, 516, 281, 853, 1203, 321, 393, 281, 652, 341, 1190, 382, 2661, 382, 1944, 51142], "temperature": 0.0, "avg_logprob": -0.3466613075949929, "compression_ratio": 1.4705882352941178, "no_speech_prob": 6.922161992406473e-05}, {"id": 1405, "seek": 658292, "start": 6602.4, "end": 6604.4, "text": " So", "tokens": [51338, 407, 51438], "temperature": 0.0, "avg_logprob": -0.3466613075949929, "compression_ratio": 1.4705882352941178, "no_speech_prob": 6.922161992406473e-05}, {"id": 1406, "seek": 658292, "start": 6604.68, "end": 6606.68, "text": " To start with even", "tokens": [51452, 1407, 722, 365, 754, 51552], "temperature": 0.0, "avg_logprob": -0.3466613075949929, "compression_ratio": 1.4705882352941178, "no_speech_prob": 6.922161992406473e-05}, {"id": 1407, "seek": 660668, "start": 6607.68, "end": 6613.4400000000005, "text": " The very process of getting a list of the file names of everything in image net", "tokens": [50414, 440, 588, 1399, 295, 1242, 257, 1329, 295, 264, 3991, 5288, 295, 1203, 294, 3256, 2533, 50702], "temperature": 0.0, "avg_logprob": -0.37120313725919807, "compression_ratio": 1.8085106382978724, "no_speech_prob": 0.0001971683814190328}, {"id": 1408, "seek": 660668, "start": 6614.08, "end": 6618.96, "text": " Takes a non-trivial amount of time so like everything that takes a non-trivial amount of time. We're going to save its output", "tokens": [50734, 44347, 257, 2107, 12, 83, 470, 22640, 2372, 295, 565, 370, 411, 1203, 300, 2516, 257, 2107, 12, 83, 470, 22640, 2372, 295, 565, 13, 492, 434, 516, 281, 3155, 1080, 5598, 50978], "temperature": 0.0, "avg_logprob": -0.37120313725919807, "compression_ratio": 1.8085106382978724, "no_speech_prob": 0.0001971683814190328}, {"id": 1409, "seek": 660668, "start": 6619.68, "end": 6622.38, "text": " Right so the first thing I do is I use", "tokens": [51014, 1779, 370, 264, 700, 551, 286, 360, 307, 286, 764, 51149], "temperature": 0.0, "avg_logprob": -0.37120313725919807, "compression_ratio": 1.8085106382978724, "no_speech_prob": 0.0001971683814190328}, {"id": 1410, "seek": 660668, "start": 6623.52, "end": 6627.6, "text": " Lob glob I can't remember if we use glob in part one. I think we did yeah", "tokens": [51206, 30719, 16125, 286, 393, 380, 1604, 498, 321, 764, 16125, 294, 644, 472, 13, 286, 519, 321, 630, 1338, 51410], "temperature": 0.0, "avg_logprob": -0.37120313725919807, "compression_ratio": 1.8085106382978724, "no_speech_prob": 0.0001971683814190328}, {"id": 1411, "seek": 660668, "start": 6627.6, "end": 6631.26, "text": " It's just the thing that's like LS star dot star right this sort of love", "tokens": [51410, 467, 311, 445, 264, 551, 300, 311, 411, 36657, 3543, 5893, 3543, 558, 341, 1333, 295, 959, 51593], "temperature": 0.0, "avg_logprob": -0.37120313725919807, "compression_ratio": 1.8085106382978724, "no_speech_prob": 0.0001971683814190328}, {"id": 1412, "seek": 660668, "start": 6632.200000000001, "end": 6634.92, "text": " so we use glob to grab all of the", "tokens": [51640, 370, 321, 764, 16125, 281, 4444, 439, 295, 264, 51776], "temperature": 0.0, "avg_logprob": -0.37120313725919807, "compression_ratio": 1.8085106382978724, "no_speech_prob": 0.0001971683814190328}, {"id": 1413, "seek": 663492, "start": 6635.68, "end": 6640.84, "text": " Image net trading set and then I just go ahead and equal dot dump that yes", "tokens": [50402, 29903, 2533, 9529, 992, 293, 550, 286, 445, 352, 2286, 293, 2681, 5893, 11430, 300, 2086, 50660], "temperature": 0.0, "avg_logprob": -0.3971029487816063, "compression_ratio": 1.5132275132275133, "no_speech_prob": 6.302708789007738e-05}, {"id": 1414, "seek": 663492, "start": 6643.4400000000005, "end": 6645.4400000000005, "text": " So I can pick it up later", "tokens": [50790, 407, 286, 393, 1888, 309, 493, 1780, 50890], "temperature": 0.0, "avg_logprob": -0.3971029487816063, "compression_ratio": 1.5132275132275133, "no_speech_prob": 6.302708789007738e-05}, {"id": 1415, "seek": 663492, "start": 6646.96, "end": 6649.36, "text": " For various reasons that we'll see shortly", "tokens": [50966, 1171, 3683, 4112, 300, 321, 603, 536, 13392, 51086], "temperature": 0.0, "avg_logprob": -0.3971029487816063, "compression_ratio": 1.5132275132275133, "no_speech_prob": 6.302708789007738e-05}, {"id": 1416, "seek": 663492, "start": 6649.36, "end": 6655.52, "text": " It's actually a very good idea though at this point to randomize that list of file names put them in a random order", "tokens": [51086, 467, 311, 767, 257, 588, 665, 1558, 1673, 412, 341, 935, 281, 4974, 1125, 300, 1329, 295, 3991, 5288, 829, 552, 294, 257, 4974, 1668, 51394], "temperature": 0.0, "avg_logprob": -0.3971029487816063, "compression_ratio": 1.5132275132275133, "no_speech_prob": 6.302708789007738e-05}, {"id": 1417, "seek": 663492, "start": 6656.4800000000005, "end": 6658.4800000000005, "text": " The basic idea is later on", "tokens": [51442, 440, 3875, 1558, 307, 1780, 322, 51542], "temperature": 0.0, "avg_logprob": -0.3971029487816063, "compression_ratio": 1.5132275132275133, "no_speech_prob": 6.302708789007738e-05}, {"id": 1418, "seek": 665848, "start": 6659.48, "end": 6661.12, "text": " If we use", "tokens": [50414, 759, 321, 764, 50496], "temperature": 0.0, "avg_logprob": -0.2905632812197846, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0002098812401527539}, {"id": 1419, "seek": 665848, "start": 6661.12, "end": 6664.86, "text": " Kind of chunks of file names that are next to each other. They're not all going to be", "tokens": [50496, 9242, 295, 24004, 295, 3991, 5288, 300, 366, 958, 281, 1184, 661, 13, 814, 434, 406, 439, 516, 281, 312, 50683], "temperature": 0.0, "avg_logprob": -0.2905632812197846, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0002098812401527539}, {"id": 1420, "seek": 665848, "start": 6665.599999999999, "end": 6671.04, "text": " The same type of thing right so by randomizing the file names now. It's going to save us a bit of time", "tokens": [50720, 440, 912, 2010, 295, 551, 558, 370, 538, 4974, 3319, 264, 3991, 5288, 586, 13, 467, 311, 516, 281, 3155, 505, 257, 857, 295, 565, 50992], "temperature": 0.0, "avg_logprob": -0.2905632812197846, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0002098812401527539}, {"id": 1421, "seek": 665848, "start": 6671.599999999999, "end": 6674.5199999999995, "text": " So then I can go ahead and save that randomized list", "tokens": [51020, 407, 550, 286, 393, 352, 2286, 293, 3155, 300, 38513, 1329, 51166], "temperature": 0.0, "avg_logprob": -0.2905632812197846, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0002098812401527539}, {"id": 1422, "seek": 665848, "start": 6675.04, "end": 6678.12, "text": " By giving it a different name. I can always come back to the original", "tokens": [51192, 3146, 2902, 309, 257, 819, 1315, 13, 286, 393, 1009, 808, 646, 281, 264, 3380, 51346], "temperature": 0.0, "avg_logprob": -0.2905632812197846, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0002098812401527539}, {"id": 1423, "seek": 665848, "start": 6679.5599999999995, "end": 6682.799999999999, "text": " So I want to resize all of my images to a constant size", "tokens": [51418, 407, 286, 528, 281, 50069, 439, 295, 452, 5267, 281, 257, 5754, 2744, 51580], "temperature": 0.0, "avg_logprob": -0.2905632812197846, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0002098812401527539}, {"id": 1424, "seek": 668280, "start": 6683.8, "end": 6690.320000000001, "text": " I'm being a bit lazy here, and then I resize them to 224 by 224. That's the input size for a", "tokens": [50414, 286, 478, 885, 257, 857, 14847, 510, 11, 293, 550, 286, 50069, 552, 281, 5853, 19, 538, 5853, 19, 13, 663, 311, 264, 4846, 2744, 337, 257, 50740], "temperature": 0.0, "avg_logprob": -0.320443902696882, "compression_ratio": 1.5320197044334976, "no_speech_prob": 0.0007554014446213841}, {"id": 1425, "seek": 668280, "start": 6691.2, "end": 6693.2, "text": " lot of models obviously", "tokens": [50784, 688, 295, 5245, 2745, 50884], "temperature": 0.0, "avg_logprob": -0.320443902696882, "compression_ratio": 1.5320197044334976, "no_speech_prob": 0.0007554014446213841}, {"id": 1426, "seek": 668280, "start": 6694.28, "end": 6696.28, "text": " Including the one that we're going to use", "tokens": [50938, 27137, 264, 472, 300, 321, 434, 516, 281, 764, 51038], "temperature": 0.0, "avg_logprob": -0.320443902696882, "compression_ratio": 1.5320197044334976, "no_speech_prob": 0.0007554014446213841}, {"id": 1427, "seek": 668280, "start": 6696.76, "end": 6704.18, "text": " That would probably be better if we resize to something bigger, and then we like randomly zoom and crop", "tokens": [51062, 663, 576, 1391, 312, 1101, 498, 321, 50069, 281, 746, 3801, 11, 293, 550, 321, 411, 16979, 8863, 293, 9086, 51433], "temperature": 0.0, "avg_logprob": -0.320443902696882, "compression_ratio": 1.5320197044334976, "no_speech_prob": 0.0007554014446213841}, {"id": 1428, "seek": 668280, "start": 6704.96, "end": 6707.72, "text": " Maybe if we have time we'll we'll try that later", "tokens": [51472, 2704, 498, 321, 362, 565, 321, 603, 321, 603, 853, 300, 1780, 51610], "temperature": 0.0, "avg_logprob": -0.320443902696882, "compression_ratio": 1.5320197044334976, "no_speech_prob": 0.0007554014446213841}, {"id": 1429, "seek": 670772, "start": 6708.72, "end": 6713.6, "text": " But for now we're just going to use resize everything to 224 by 224", "tokens": [50414, 583, 337, 586, 321, 434, 445, 516, 281, 764, 50069, 1203, 281, 5853, 19, 538, 5853, 19, 50658], "temperature": 0.0, "avg_logprob": -0.3328230348351884, "compression_ratio": 1.4486486486486487, "no_speech_prob": 4.908649862045422e-05}, {"id": 1430, "seek": 670772, "start": 6715.0, "end": 6721.400000000001, "text": " Okay, so we have a million million images it turns out to resize to 224 by 224", "tokens": [50728, 1033, 11, 370, 321, 362, 257, 2459, 2459, 5267, 309, 4523, 484, 281, 50069, 281, 5853, 19, 538, 5853, 19, 51048], "temperature": 0.0, "avg_logprob": -0.3328230348351884, "compression_ratio": 1.4486486486486487, "no_speech_prob": 4.908649862045422e-05}, {"id": 1431, "seek": 670772, "start": 6722.280000000001, "end": 6724.280000000001, "text": " That could be pretty slow", "tokens": [51092, 663, 727, 312, 1238, 2964, 51192], "temperature": 0.0, "avg_logprob": -0.3328230348351884, "compression_ratio": 1.4486486486486487, "no_speech_prob": 4.908649862045422e-05}, {"id": 1432, "seek": 670772, "start": 6724.68, "end": 6729.0, "text": " So I've got some handy tricks to make it much faster", "tokens": [51212, 407, 286, 600, 658, 512, 13239, 11733, 281, 652, 309, 709, 4663, 51428], "temperature": 0.0, "avg_logprob": -0.3328230348351884, "compression_ratio": 1.4486486486486487, "no_speech_prob": 4.908649862045422e-05}, {"id": 1433, "seek": 670772, "start": 6730.64, "end": 6734.2, "text": " Generally speaking there are three ways to", "tokens": [51510, 21082, 4124, 456, 366, 1045, 2098, 281, 51688], "temperature": 0.0, "avg_logprob": -0.3328230348351884, "compression_ratio": 1.4486486486486487, "no_speech_prob": 4.908649862045422e-05}, {"id": 1434, "seek": 673420, "start": 6734.72, "end": 6737.84, "text": " Make an algorithm significantly faster", "tokens": [50390, 4387, 364, 9284, 10591, 4663, 50546], "temperature": 0.0, "avg_logprob": -0.48705056134392233, "compression_ratio": 1.2476190476190476, "no_speech_prob": 0.0001334177504759282}, {"id": 1435, "seek": 673420, "start": 6742.04, "end": 6744.04, "text": " The three ways are", "tokens": [50756, 440, 1045, 2098, 366, 50856], "temperature": 0.0, "avg_logprob": -0.48705056134392233, "compression_ratio": 1.2476190476190476, "no_speech_prob": 0.0001334177504759282}, {"id": 1436, "seek": 673420, "start": 6745.679999999999, "end": 6750.72, "text": " Just cache say memory locality to explain these in a moment", "tokens": [50938, 1449, 19459, 584, 4675, 1628, 1860, 281, 2903, 613, 294, 257, 1623, 51190], "temperature": 0.0, "avg_logprob": -0.48705056134392233, "compression_ratio": 1.2476190476190476, "no_speech_prob": 0.0001334177504759282}, {"id": 1437, "seek": 673420, "start": 6756.84, "end": 6758.84, "text": " The second is", "tokens": [51496, 440, 1150, 307, 51596], "temperature": 0.0, "avg_logprob": -0.48705056134392233, "compression_ratio": 1.2476190476190476, "no_speech_prob": 0.0001334177504759282}, {"id": 1438, "seek": 675884, "start": 6758.84, "end": 6765.6, "text": " Sim D also known as vectorization", "tokens": [50364, 3998, 413, 611, 2570, 382, 8062, 2144, 50702], "temperature": 0.0, "avg_logprob": -0.531150991266424, "compression_ratio": 1.219298245614035, "no_speech_prob": 0.0001273060479434207}, {"id": 1439, "seek": 675884, "start": 6771.08, "end": 6773.4800000000005, "text": " The third is parallel processing", "tokens": [50976, 440, 2636, 307, 8952, 9007, 51096], "temperature": 0.0, "avg_logprob": -0.531150991266424, "compression_ratio": 1.219298245614035, "no_speech_prob": 0.0001273060479434207}, {"id": 1440, "seek": 675884, "start": 6778.28, "end": 6782.12, "text": " So Rachel is very familiar with these because she's currently creating a", "tokens": [51336, 407, 14246, 307, 588, 4963, 365, 613, 570, 750, 311, 4362, 4084, 257, 51528], "temperature": 0.0, "avg_logprob": -0.531150991266424, "compression_ratio": 1.219298245614035, "no_speech_prob": 0.0001273060479434207}, {"id": 1441, "seek": 678212, "start": 6783.12, "end": 6788.96, "text": " Course for the master's students here on numerical linear algebra, which is like very heavily about these things", "tokens": [50414, 27327, 337, 264, 4505, 311, 1731, 510, 322, 29054, 8213, 21989, 11, 597, 307, 411, 588, 10950, 466, 613, 721, 50706], "temperature": 0.0, "avg_logprob": -0.3591037797339169, "compression_ratio": 1.540909090909091, "no_speech_prob": 0.0003459876752458513}, {"id": 1442, "seek": 678212, "start": 6789.5599999999995, "end": 6791.5599999999995, "text": " So these are the three ways you can make", "tokens": [50736, 407, 613, 366, 264, 1045, 2098, 291, 393, 652, 50836], "temperature": 0.0, "avg_logprob": -0.3591037797339169, "compression_ratio": 1.540909090909091, "no_speech_prob": 0.0003459876752458513}, {"id": 1443, "seek": 678212, "start": 6792.0, "end": 6798.72, "text": " Data processing faster memory locality simply means in your computer you have lots of different kinds of memory", "tokens": [50858, 11888, 9007, 4663, 4675, 1628, 1860, 2935, 1355, 294, 428, 3820, 291, 362, 3195, 295, 819, 3685, 295, 4675, 51194], "temperature": 0.0, "avg_logprob": -0.3591037797339169, "compression_ratio": 1.540909090909091, "no_speech_prob": 0.0003459876752458513}, {"id": 1444, "seek": 678212, "start": 6799.16, "end": 6801.12, "text": " You have for example", "tokens": [51216, 509, 362, 337, 1365, 51314], "temperature": 0.0, "avg_logprob": -0.3591037797339169, "compression_ratio": 1.540909090909091, "no_speech_prob": 0.0003459876752458513}, {"id": 1445, "seek": 678212, "start": 6801.12, "end": 6803.12, "text": " level one cache", "tokens": [51314, 1496, 472, 19459, 51414], "temperature": 0.0, "avg_logprob": -0.3591037797339169, "compression_ratio": 1.540909090909091, "no_speech_prob": 0.0003459876752458513}, {"id": 1446, "seek": 678212, "start": 6803.76, "end": 6805.76, "text": " level two cache", "tokens": [51446, 1496, 732, 19459, 51546], "temperature": 0.0, "avg_logprob": -0.3591037797339169, "compression_ratio": 1.540909090909091, "no_speech_prob": 0.0003459876752458513}, {"id": 1447, "seek": 678212, "start": 6806.36, "end": 6808.36, "text": " RAM", "tokens": [51576, 14561, 51676], "temperature": 0.0, "avg_logprob": -0.3591037797339169, "compression_ratio": 1.540909090909091, "no_speech_prob": 0.0003459876752458513}, {"id": 1448, "seek": 678212, "start": 6808.88, "end": 6810.88, "text": " Solid-state disk", "tokens": [51702, 26664, 12, 15406, 12355, 51802], "temperature": 0.0, "avg_logprob": -0.3591037797339169, "compression_ratio": 1.540909090909091, "no_speech_prob": 0.0003459876752458513}, {"id": 1449, "seek": 681088, "start": 6811.76, "end": 6813.76, "text": " Regular of hard drives", "tokens": [50408, 45659, 295, 1152, 11754, 50508], "temperature": 0.0, "avg_logprob": -0.336811154387718, "compression_ratio": 1.658878504672897, "no_speech_prob": 1.451034677302232e-05}, {"id": 1450, "seek": 681088, "start": 6816.4400000000005, "end": 6822.0, "text": " The difference in speed as you go up from one to the other is generally like", "tokens": [50642, 440, 2649, 294, 3073, 382, 291, 352, 493, 490, 472, 281, 264, 661, 307, 5101, 411, 50920], "temperature": 0.0, "avg_logprob": -0.336811154387718, "compression_ratio": 1.658878504672897, "no_speech_prob": 1.451034677302232e-05}, {"id": 1451, "seek": 681088, "start": 6822.68, "end": 6825.4800000000005, "text": " ten times or a hundred times or a thousand times", "tokens": [50954, 2064, 1413, 420, 257, 3262, 1413, 420, 257, 4714, 1413, 51094], "temperature": 0.0, "avg_logprob": -0.336811154387718, "compression_ratio": 1.658878504672897, "no_speech_prob": 1.451034677302232e-05}, {"id": 1452, "seek": 681088, "start": 6826.0, "end": 6832.16, "text": " slower like you really really really don't want to go to the next level of the memory hierarchy if you can avoid it and", "tokens": [51120, 14009, 411, 291, 534, 534, 534, 500, 380, 528, 281, 352, 281, 264, 958, 1496, 295, 264, 4675, 22333, 498, 291, 393, 5042, 309, 293, 51428], "temperature": 0.0, "avg_logprob": -0.336811154387718, "compression_ratio": 1.658878504672897, "no_speech_prob": 1.451034677302232e-05}, {"id": 1453, "seek": 681088, "start": 6833.0, "end": 6836.68, "text": " Fortunately level one cache might be more like 16 K", "tokens": [51470, 20652, 1496, 472, 19459, 1062, 312, 544, 411, 3165, 591, 51654], "temperature": 0.0, "avg_logprob": -0.336811154387718, "compression_ratio": 1.658878504672897, "no_speech_prob": 1.451034677302232e-05}, {"id": 1454, "seek": 681088, "start": 6837.64, "end": 6839.8, "text": " Level two cache might be a few Meg", "tokens": [51702, 16872, 732, 19459, 1062, 312, 257, 1326, 9986, 51810], "temperature": 0.0, "avg_logprob": -0.336811154387718, "compression_ratio": 1.658878504672897, "no_speech_prob": 1.451034677302232e-05}, {"id": 1455, "seek": 684088, "start": 6840.88, "end": 6842.88, "text": " Ram is going to be a few gig", "tokens": [50364, 9078, 307, 516, 281, 312, 257, 1326, 8741, 50464], "temperature": 0.0, "avg_logprob": -0.30272469954057174, "compression_ratio": 1.7975206611570247, "no_speech_prob": 4.832533159060404e-05}, {"id": 1456, "seek": 684088, "start": 6844.04, "end": 6849.84, "text": " Solid-state drives is probably going to be a few hundreds of gig and your hard drives are probably going to be a few terabytes", "tokens": [50522, 26664, 12, 15406, 11754, 307, 1391, 516, 281, 312, 257, 1326, 6779, 295, 8741, 293, 428, 1152, 11754, 366, 1391, 516, 281, 312, 257, 1326, 1796, 24538, 50812], "temperature": 0.0, "avg_logprob": -0.30272469954057174, "compression_ratio": 1.7975206611570247, "no_speech_prob": 4.832533159060404e-05}, {"id": 1457, "seek": 684088, "start": 6850.2, "end": 6853.56, "text": " So in reality you've got to be careful about how you manage these things", "tokens": [50830, 407, 294, 4103, 291, 600, 658, 281, 312, 5026, 466, 577, 291, 3067, 613, 721, 50998], "temperature": 0.0, "avg_logprob": -0.30272469954057174, "compression_ratio": 1.7975206611570247, "no_speech_prob": 4.832533159060404e-05}, {"id": 1458, "seek": 684088, "start": 6854.88, "end": 6856.96, "text": " so you want to try and make sure that you're", "tokens": [51064, 370, 291, 528, 281, 853, 293, 652, 988, 300, 291, 434, 51168], "temperature": 0.0, "avg_logprob": -0.30272469954057174, "compression_ratio": 1.7975206611570247, "no_speech_prob": 4.832533159060404e-05}, {"id": 1459, "seek": 684088, "start": 6858.04, "end": 6860.04, "text": " Putting stuff in the right place", "tokens": [51222, 31367, 1507, 294, 264, 558, 1081, 51322], "temperature": 0.0, "avg_logprob": -0.30272469954057174, "compression_ratio": 1.7975206611570247, "no_speech_prob": 4.832533159060404e-05}, {"id": 1460, "seek": 684088, "start": 6860.04, "end": 6863.28, "text": " That you're not filling up the resources unnecessarily", "tokens": [51322, 663, 291, 434, 406, 10623, 493, 264, 3593, 16799, 3289, 51484], "temperature": 0.0, "avg_logprob": -0.30272469954057174, "compression_ratio": 1.7975206611570247, "no_speech_prob": 4.832533159060404e-05}, {"id": 1461, "seek": 684088, "start": 6863.72, "end": 6868.32, "text": " And that if you use if you're going to use a piece of data multiple times", "tokens": [51506, 400, 300, 498, 291, 764, 498, 291, 434, 516, 281, 764, 257, 2522, 295, 1412, 3866, 1413, 51736], "temperature": 0.0, "avg_logprob": -0.30272469954057174, "compression_ratio": 1.7975206611570247, "no_speech_prob": 4.832533159060404e-05}, {"id": 1462, "seek": 686832, "start": 6868.96, "end": 6874.719999999999, "text": " Try to use it each time like immediately use it again, so that it's already in your", "tokens": [50396, 6526, 281, 764, 309, 1184, 565, 411, 4258, 764, 309, 797, 11, 370, 300, 309, 311, 1217, 294, 428, 50684], "temperature": 0.0, "avg_logprob": -0.32759207173397664, "compression_ratio": 1.5225225225225225, "no_speech_prob": 7.967222336446866e-05}, {"id": 1463, "seek": 686832, "start": 6877.599999999999, "end": 6884.679999999999, "text": " The second thing which is what we're about to look look at is SIMD which stands for single instruction multiple data", "tokens": [50828, 440, 1150, 551, 597, 307, 437, 321, 434, 466, 281, 574, 574, 412, 307, 24738, 35, 597, 7382, 337, 2167, 10951, 3866, 1412, 51182], "temperature": 0.0, "avg_logprob": -0.32759207173397664, "compression_ratio": 1.5225225225225225, "no_speech_prob": 7.967222336446866e-05}, {"id": 1464, "seek": 686832, "start": 6885.799999999999, "end": 6887.2, "text": " something that a", "tokens": [51238, 746, 300, 257, 51308], "temperature": 0.0, "avg_logprob": -0.32759207173397664, "compression_ratio": 1.5225225225225225, "no_speech_prob": 7.967222336446866e-05}, {"id": 1465, "seek": 686832, "start": 6887.2, "end": 6894.799999999999, "text": " Shockingly large number of people even who claim to be professional computer programmers don't know is that every modern", "tokens": [51308, 39474, 12163, 2416, 1230, 295, 561, 754, 567, 3932, 281, 312, 4843, 3820, 41504, 500, 380, 458, 307, 300, 633, 4363, 51688], "temperature": 0.0, "avg_logprob": -0.32759207173397664, "compression_ratio": 1.5225225225225225, "no_speech_prob": 7.967222336446866e-05}, {"id": 1466, "seek": 689480, "start": 6895.8, "end": 6898.08, "text": " CPU is capable of", "tokens": [50414, 13199, 307, 8189, 295, 50528], "temperature": 0.0, "avg_logprob": -0.331726906147409, "compression_ratio": 1.8, "no_speech_prob": 4.9086182116298005e-05}, {"id": 1467, "seek": 689480, "start": 6899.6, "end": 6902.6, "text": " in a single operation in a single thread", "tokens": [50604, 294, 257, 2167, 6916, 294, 257, 2167, 7207, 50754], "temperature": 0.0, "avg_logprob": -0.331726906147409, "compression_ratio": 1.8, "no_speech_prob": 4.9086182116298005e-05}, {"id": 1468, "seek": 689480, "start": 6903.360000000001, "end": 6905.360000000001, "text": " calculating multiple things at the same time and", "tokens": [50792, 28258, 3866, 721, 412, 264, 912, 565, 293, 50892], "temperature": 0.0, "avg_logprob": -0.331726906147409, "compression_ratio": 1.8, "no_speech_prob": 4.9086182116298005e-05}, {"id": 1469, "seek": 689480, "start": 6905.84, "end": 6911.52, "text": " The way that it does it is that you basically create a little vector of generally about eight things", "tokens": [50916, 440, 636, 300, 309, 775, 309, 307, 300, 291, 1936, 1884, 257, 707, 8062, 295, 5101, 466, 3180, 721, 51200], "temperature": 0.0, "avg_logprob": -0.331726906147409, "compression_ratio": 1.8, "no_speech_prob": 4.9086182116298005e-05}, {"id": 1470, "seek": 689480, "start": 6912.04, "end": 6916.68, "text": " Right and you put all the things you want to calculate so let's say you want to take the square root of something", "tokens": [51226, 1779, 293, 291, 829, 439, 264, 721, 291, 528, 281, 8873, 370, 718, 311, 584, 291, 528, 281, 747, 264, 3732, 5593, 295, 746, 51458], "temperature": 0.0, "avg_logprob": -0.331726906147409, "compression_ratio": 1.8, "no_speech_prob": 4.9086182116298005e-05}, {"id": 1471, "seek": 689480, "start": 6916.76, "end": 6919.0, "text": " You put eight things into this little vector", "tokens": [51462, 509, 829, 3180, 721, 666, 341, 707, 8062, 51574], "temperature": 0.0, "avg_logprob": -0.331726906147409, "compression_ratio": 1.8, "no_speech_prob": 4.9086182116298005e-05}, {"id": 1472, "seek": 689480, "start": 6921.28, "end": 6924.64, "text": " And then you call a particular CPU instruction", "tokens": [51688, 400, 550, 291, 818, 257, 1729, 13199, 10951, 51856], "temperature": 0.0, "avg_logprob": -0.331726906147409, "compression_ratio": 1.8, "no_speech_prob": 4.9086182116298005e-05}, {"id": 1473, "seek": 692480, "start": 6924.8, "end": 6926.28, "text": " which is basically a", "tokens": [50364, 597, 307, 1936, 257, 50438], "temperature": 0.0, "avg_logprob": -0.31166444222132367, "compression_ratio": 1.6891891891891893, "no_speech_prob": 9.22336766961962e-06}, {"id": 1474, "seek": 692480, "start": 6926.28, "end": 6931.52, "text": " Take the square root of eight floating-point numbers that is in this register", "tokens": [50438, 3664, 264, 3732, 5593, 295, 3180, 12607, 12, 6053, 3547, 300, 307, 294, 341, 7280, 50700], "temperature": 0.0, "avg_logprob": -0.31166444222132367, "compression_ratio": 1.6891891891891893, "no_speech_prob": 9.22336766961962e-06}, {"id": 1475, "seek": 692480, "start": 6931.52, "end": 6935.900000000001, "text": " And it does it in a single clock cycle so when we say clock cycle", "tokens": [50700, 400, 309, 775, 309, 294, 257, 2167, 7830, 6586, 370, 562, 321, 584, 7830, 6586, 50919], "temperature": 0.0, "avg_logprob": -0.31166444222132367, "compression_ratio": 1.6891891891891893, "no_speech_prob": 9.22336766961962e-06}, {"id": 1476, "seek": 692480, "start": 6935.900000000001, "end": 6942.28, "text": " You know your CPU might be say two or three gigahertz right so it's doing two or three billion things", "tokens": [50919, 509, 458, 428, 13199, 1062, 312, 584, 732, 420, 1045, 8741, 64, 35655, 558, 370, 309, 311, 884, 732, 420, 1045, 5218, 721, 51238], "temperature": 0.0, "avg_logprob": -0.31166444222132367, "compression_ratio": 1.6891891891891893, "no_speech_prob": 9.22336766961962e-06}, {"id": 1477, "seek": 692480, "start": 6942.72, "end": 6949.4800000000005, "text": " Per second well, it's not it's doing two or three billion times eight things per second if you're using", "tokens": [51260, 3026, 1150, 731, 11, 309, 311, 406, 309, 311, 884, 732, 420, 1045, 5218, 1413, 3180, 721, 680, 1150, 498, 291, 434, 1228, 51598], "temperature": 0.0, "avg_logprob": -0.31166444222132367, "compression_ratio": 1.6891891891891893, "no_speech_prob": 9.22336766961962e-06}, {"id": 1478, "seek": 692480, "start": 6950.28, "end": 6952.24, "text": " SIMD", "tokens": [51638, 24738, 35, 51736], "temperature": 0.0, "avg_logprob": -0.31166444222132367, "compression_ratio": 1.6891891891891893, "no_speech_prob": 9.22336766961962e-06}, {"id": 1479, "seek": 695224, "start": 6952.24, "end": 6959.0, "text": " Because so few people are aware of SIMD and because a lot of programming environments don't make it easy to use this IMD a", "tokens": [50364, 1436, 370, 1326, 561, 366, 3650, 295, 24738, 35, 293, 570, 257, 688, 295, 9410, 12388, 500, 380, 652, 309, 1858, 281, 764, 341, 21463, 35, 257, 50702], "temperature": 0.0, "avg_logprob": -0.3510359513132196, "compression_ratio": 1.6541666666666666, "no_speech_prob": 0.0001273101952392608}, {"id": 1480, "seek": 695224, "start": 6959.16, "end": 6962.32, "text": " Lot of stuff is not written to take advantage of SIMD", "tokens": [50710, 20131, 295, 1507, 307, 406, 3720, 281, 747, 5002, 295, 24738, 35, 50868], "temperature": 0.0, "avg_logprob": -0.3510359513132196, "compression_ratio": 1.6541666666666666, "no_speech_prob": 0.0001273101952392608}, {"id": 1481, "seek": 695224, "start": 6963.04, "end": 6967.28, "text": " Including for example pretty much all of the image processing in Python", "tokens": [50904, 27137, 337, 1365, 1238, 709, 439, 295, 264, 3256, 9007, 294, 15329, 51116], "temperature": 0.0, "avg_logprob": -0.3510359513132196, "compression_ratio": 1.6541666666666666, "no_speech_prob": 0.0001273101952392608}, {"id": 1482, "seek": 695224, "start": 6968.92, "end": 6970.96, "text": " However you can do this", "tokens": [51198, 2908, 291, 393, 360, 341, 51300], "temperature": 0.0, "avg_logprob": -0.3510359513132196, "compression_ratio": 1.6541666666666666, "no_speech_prob": 0.0001273101952392608}, {"id": 1483, "seek": 695224, "start": 6971.719999999999, "end": 6973.719999999999, "text": " You can go pip install", "tokens": [51338, 509, 393, 352, 8489, 3625, 51438], "temperature": 0.0, "avg_logprob": -0.3510359513132196, "compression_ratio": 1.6541666666666666, "no_speech_prob": 0.0001273101952392608}, {"id": 1484, "seek": 695224, "start": 6974.599999999999, "end": 6976.599999999999, "text": " pillow SIMD and", "tokens": [51482, 18581, 24738, 35, 293, 51582], "temperature": 0.0, "avg_logprob": -0.3510359513132196, "compression_ratio": 1.6541666666666666, "no_speech_prob": 0.0001273101952392608}, {"id": 1485, "seek": 695224, "start": 6976.639999999999, "end": 6981.679999999999, "text": " That will replace your pillow remember pillow is like the main Python imaging library", "tokens": [51584, 663, 486, 7406, 428, 18581, 1604, 18581, 307, 411, 264, 2135, 15329, 25036, 6405, 51836], "temperature": 0.0, "avg_logprob": -0.3510359513132196, "compression_ratio": 1.6541666666666666, "no_speech_prob": 0.0001273101952392608}, {"id": 1486, "seek": 698168, "start": 6981.96, "end": 6987.88, "text": " With a new version that does use SIMD for at least some of its things right", "tokens": [50378, 2022, 257, 777, 3037, 300, 775, 764, 24738, 35, 337, 412, 1935, 512, 295, 1080, 721, 558, 50674], "temperature": 0.0, "avg_logprob": -0.3315466281979583, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.00015117852308321744}, {"id": 1487, "seek": 698168, "start": 6989.0, "end": 6991.320000000001, "text": " Because SIMD only works on", "tokens": [50730, 1436, 24738, 35, 787, 1985, 322, 50846], "temperature": 0.0, "avg_logprob": -0.3315466281979583, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.00015117852308321744}, {"id": 1488, "seek": 698168, "start": 6992.12, "end": 6995.56, "text": " Certain CPUs I mean a any vaguely recent CPU it works", "tokens": [50886, 13407, 13199, 82, 286, 914, 257, 604, 13501, 48863, 5162, 13199, 309, 1985, 51058], "temperature": 0.0, "avg_logprob": -0.3315466281979583, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.00015117852308321744}, {"id": 1489, "seek": 698168, "start": 6995.56, "end": 6998.84, "text": " But because it's only some you have to add some special", "tokens": [51058, 583, 570, 309, 311, 787, 512, 291, 362, 281, 909, 512, 2121, 51222], "temperature": 0.0, "avg_logprob": -0.3315466281979583, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.00015117852308321744}, {"id": 1490, "seek": 698168, "start": 6999.240000000001, "end": 7006.16, "text": " Directives to the compiler to tell it I want to use I have this kind of CPU so please do use these kinds of instructions", "tokens": [51242, 18308, 1539, 281, 264, 31958, 281, 980, 309, 286, 528, 281, 764, 286, 362, 341, 733, 295, 13199, 370, 1767, 360, 764, 613, 3685, 295, 9415, 51588], "temperature": 0.0, "avg_logprob": -0.3315466281979583, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.00015117852308321744}, {"id": 1491, "seek": 700616, "start": 7007.12, "end": 7012.04, "text": " And what pillow SIMD does it actually literally replaces your existing pillow", "tokens": [50412, 400, 437, 18581, 24738, 35, 775, 309, 767, 3736, 46734, 428, 6741, 18581, 50658], "temperature": 0.0, "avg_logprob": -0.33295553298223585, "compression_ratio": 1.58203125, "no_speech_prob": 0.0001559785450808704}, {"id": 1492, "seek": 700616, "start": 7012.639999999999, "end": 7017.28, "text": " Right so that's why you have to say force reinstall because it's going to be like oh you already have pillow", "tokens": [50688, 1779, 370, 300, 311, 983, 291, 362, 281, 584, 3464, 35056, 336, 570, 309, 311, 516, 281, 312, 411, 1954, 291, 1217, 362, 18581, 50920], "temperature": 0.0, "avg_logprob": -0.33295553298223585, "compression_ratio": 1.58203125, "no_speech_prob": 0.0001559785450808704}, {"id": 1493, "seek": 700616, "start": 7017.48, "end": 7019.48, "text": " But this is like no I want", "tokens": [50930, 583, 341, 307, 411, 572, 286, 528, 51030], "temperature": 0.0, "avg_logprob": -0.33295553298223585, "compression_ratio": 1.58203125, "no_speech_prob": 0.0001559785450808704}, {"id": 1494, "seek": 700616, "start": 7019.5599999999995, "end": 7022.08, "text": " You know where Sandy so if you try this", "tokens": [51034, 509, 458, 689, 27390, 370, 498, 291, 853, 341, 51160], "temperature": 0.0, "avg_logprob": -0.33295553298223585, "compression_ratio": 1.58203125, "no_speech_prob": 0.0001559785450808704}, {"id": 1495, "seek": 700616, "start": 7022.599999999999, "end": 7027.2, "text": " You will find that the speed of your resize literally goes up by 600%", "tokens": [51186, 509, 486, 915, 300, 264, 3073, 295, 428, 50069, 3736, 1709, 493, 538, 11849, 4, 51416], "temperature": 0.0, "avg_logprob": -0.33295553298223585, "compression_ratio": 1.58203125, "no_speech_prob": 0.0001559785450808704}, {"id": 1496, "seek": 700616, "start": 7027.8, "end": 7029.8, "text": " You don't have to change any code", "tokens": [51446, 509, 500, 380, 362, 281, 1319, 604, 3089, 51546], "temperature": 0.0, "avg_logprob": -0.33295553298223585, "compression_ratio": 1.58203125, "no_speech_prob": 0.0001559785450808704}, {"id": 1497, "seek": 700616, "start": 7030.0, "end": 7035.68, "text": " Okay, so I'm like a huge fan of SIMD in general", "tokens": [51556, 1033, 11, 370, 286, 478, 411, 257, 2603, 3429, 295, 24738, 35, 294, 2674, 51840], "temperature": 0.0, "avg_logprob": -0.33295553298223585, "compression_ratio": 1.58203125, "no_speech_prob": 0.0001559785450808704}, {"id": 1498, "seek": 703616, "start": 7036.16, "end": 7041.48, "text": " One of the reasons I'm not particularly fond of Python because it doesn't make it at all easy to use SIMD", "tokens": [50364, 1485, 295, 264, 4112, 286, 478, 406, 4098, 9557, 295, 15329, 570, 309, 1177, 380, 652, 309, 412, 439, 1858, 281, 764, 24738, 35, 50630], "temperature": 0.0, "avg_logprob": -0.3041209764378045, "compression_ratio": 1.5317460317460319, "no_speech_prob": 4.400091347633861e-05}, {"id": 1499, "seek": 703616, "start": 7044.16, "end": 7046.16, "text": " But luckily some people have written", "tokens": [50764, 583, 22880, 512, 561, 362, 3720, 50864], "temperature": 0.0, "avg_logprob": -0.3041209764378045, "compression_ratio": 1.5317460317460319, "no_speech_prob": 4.400091347633861e-05}, {"id": 1500, "seek": 703616, "start": 7046.48, "end": 7052.88, "text": " Stuff in C. Which does use SIMD and then provided these Python interfaces, okay, so this is something", "tokens": [50880, 31347, 294, 383, 13, 3013, 775, 764, 24738, 35, 293, 550, 5649, 613, 15329, 28416, 11, 1392, 11, 370, 341, 307, 746, 51200], "temperature": 0.0, "avg_logprob": -0.3041209764378045, "compression_ratio": 1.5317460317460319, "no_speech_prob": 4.400091347633861e-05}, {"id": 1501, "seek": 703616, "start": 7053.5199999999995, "end": 7055.8, "text": " You remember to try to get working when you go home", "tokens": [51232, 509, 1604, 281, 853, 281, 483, 1364, 562, 291, 352, 1280, 51346], "temperature": 0.0, "avg_logprob": -0.3041209764378045, "compression_ratio": 1.5317460317460319, "no_speech_prob": 4.400091347633861e-05}, {"id": 1502, "seek": 703616, "start": 7056.8, "end": 7062.44, "text": " before you do it write a little benchmark that resizes a thousand images and times it and", "tokens": [51396, 949, 291, 360, 309, 2464, 257, 707, 18927, 300, 725, 5660, 257, 4714, 5267, 293, 1413, 309, 293, 51678], "temperature": 0.0, "avg_logprob": -0.3041209764378045, "compression_ratio": 1.5317460317460319, "no_speech_prob": 4.400091347633861e-05}, {"id": 1503, "seek": 706244, "start": 7062.839999999999, "end": 7068.599999999999, "text": " Then run this command and make sure that it gets 600% faster that way you know it's it's actually working", "tokens": [50384, 1396, 1190, 341, 5622, 293, 652, 988, 300, 309, 2170, 11849, 4, 4663, 300, 636, 291, 458, 309, 311, 309, 311, 767, 1364, 50672], "temperature": 0.0, "avg_logprob": -0.27997347952305585, "compression_ratio": 1.563063063063063, "no_speech_prob": 5.8290836022933945e-05}, {"id": 1504, "seek": 706244, "start": 7070.759999999999, "end": 7078.04, "text": " We have two questions, I don't know if you want to finish the three ways to do things faster first or you go", "tokens": [50780, 492, 362, 732, 1651, 11, 286, 500, 380, 458, 498, 291, 528, 281, 2413, 264, 1045, 2098, 281, 360, 721, 4663, 700, 420, 291, 352, 51144], "temperature": 0.0, "avg_logprob": -0.27997347952305585, "compression_ratio": 1.563063063063063, "no_speech_prob": 5.8290836022933945e-05}, {"id": 1505, "seek": 706244, "start": 7079.12, "end": 7083.04, "text": " One is how could you get the relation between a pug and a dog?", "tokens": [51198, 1485, 307, 577, 727, 291, 483, 264, 9721, 1296, 257, 47900, 293, 257, 3000, 30, 51394], "temperature": 0.0, "avg_logprob": -0.27997347952305585, "compression_ratio": 1.563063063063063, "no_speech_prob": 5.8290836022933945e-05}, {"id": 1506, "seek": 706244, "start": 7083.799999999999, "end": 7087.62, "text": " And the photo of a pug and its relation to the bigger category of dog", "tokens": [51432, 400, 264, 5052, 295, 257, 47900, 293, 1080, 9721, 281, 264, 3801, 7719, 295, 3000, 51623], "temperature": 0.0, "avg_logprob": -0.27997347952305585, "compression_ratio": 1.563063063063063, "no_speech_prob": 5.8290836022933945e-05}, {"id": 1507, "seek": 709244, "start": 7092.96, "end": 7094.96, "text": " Sure we'll think about that", "tokens": [50390, 4894, 321, 603, 519, 466, 300, 50490], "temperature": 0.0, "avg_logprob": -0.31766779526420263, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0001881417556433007}, {"id": 1508, "seek": 709244, "start": 7096.0, "end": 7100.08, "text": " Now there, why do we want to randomize the file names can't we use?", "tokens": [50542, 823, 456, 11, 983, 360, 321, 528, 281, 4974, 1125, 264, 3991, 5288, 393, 380, 321, 764, 30, 50746], "temperature": 0.0, "avg_logprob": -0.31766779526420263, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0001881417556433007}, {"id": 1509, "seek": 709244, "start": 7101.16, "end": 7105.599999999999, "text": " Shuffle equals true on the keras flow from directory. You'll see yeah", "tokens": [50800, 1160, 21665, 6915, 2074, 322, 264, 350, 6985, 3095, 490, 21120, 13, 509, 603, 536, 1338, 51022], "temperature": 0.0, "avg_logprob": -0.31766779526420263, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0001881417556433007}, {"id": 1510, "seek": 709244, "start": 7106.5599999999995, "end": 7111.28, "text": " The short answer is kind of to do with locality right if you say shuffle equals true", "tokens": [51070, 440, 2099, 1867, 307, 733, 295, 281, 360, 365, 1628, 1860, 558, 498, 291, 584, 39426, 6915, 2074, 51306], "temperature": 0.0, "avg_logprob": -0.31766779526420263, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0001881417556433007}, {"id": 1511, "seek": 709244, "start": 7111.5599999999995, "end": 7115.799999999999, "text": " you're jumping from here on the hard disk to here on the hard disk to here on the hard disk and", "tokens": [51320, 291, 434, 11233, 490, 510, 322, 264, 1152, 12355, 281, 510, 322, 264, 1152, 12355, 281, 510, 322, 264, 1152, 12355, 293, 51532], "temperature": 0.0, "avg_logprob": -0.31766779526420263, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0001881417556433007}, {"id": 1512, "seek": 711580, "start": 7116.12, "end": 7118.92, "text": " Hard disk take that like literally that remember", "tokens": [50380, 11817, 12355, 747, 300, 411, 3736, 300, 1604, 50520], "temperature": 0.0, "avg_logprob": -0.3733339739275408, "compression_ratio": 1.75, "no_speech_prob": 0.0002780286013148725}, {"id": 1513, "seek": 711580, "start": 7118.92, "end": 7122.84, "text": " There's a spinning disk with a little needle right and the things moving all over the place", "tokens": [50520, 821, 311, 257, 15640, 12355, 365, 257, 707, 11037, 558, 293, 264, 721, 2684, 439, 670, 264, 1081, 50716], "temperature": 0.0, "avg_logprob": -0.3733339739275408, "compression_ratio": 1.75, "no_speech_prob": 0.0002780286013148725}, {"id": 1514, "seek": 711580, "start": 7122.96, "end": 7126.92, "text": " So you want to be getting things that are all in a row. It's basically the reason", "tokens": [50722, 407, 291, 528, 281, 312, 1242, 721, 300, 366, 439, 294, 257, 5386, 13, 467, 311, 1936, 264, 1778, 50920], "temperature": 0.0, "avg_logprob": -0.3733339739275408, "compression_ratio": 1.75, "no_speech_prob": 0.0002780286013148725}, {"id": 1515, "seek": 711580, "start": 7129.6, "end": 7137.24, "text": " As you'll see this was going to basically work for the concept of dog versus pug because the word vector for dog", "tokens": [51054, 1018, 291, 603, 536, 341, 390, 516, 281, 1936, 589, 337, 264, 3410, 295, 3000, 5717, 47900, 570, 264, 1349, 8062, 337, 3000, 51436], "temperature": 0.0, "avg_logprob": -0.3733339739275408, "compression_ratio": 1.75, "no_speech_prob": 0.0002780286013148725}, {"id": 1516, "seek": 711580, "start": 7138.0, "end": 7143.4400000000005, "text": " Is very similar to word vector for pug so at the end. We'll try it. We'll try and we'll we'll see if we can find", "tokens": [51474, 1119, 588, 2531, 281, 1349, 8062, 337, 47900, 370, 412, 264, 917, 13, 492, 603, 853, 309, 13, 492, 603, 853, 293, 321, 603, 321, 603, 536, 498, 321, 393, 915, 51746], "temperature": 0.0, "avg_logprob": -0.3733339739275408, "compression_ratio": 1.75, "no_speech_prob": 0.0002780286013148725}, {"id": 1517, "seek": 714344, "start": 7143.96, "end": 7145.96, "text": " And dogs see if it works", "tokens": [50390, 400, 7197, 536, 498, 309, 1985, 50490], "temperature": 0.0, "avg_logprob": -0.40776309451541387, "compression_ratio": 1.6073298429319371, "no_speech_prob": 4.611245094565675e-05}, {"id": 1518, "seek": 714344, "start": 7146.719999999999, "end": 7148.719999999999, "text": " I'm sure it will", "tokens": [50528, 286, 478, 988, 309, 486, 50628], "temperature": 0.0, "avg_logprob": -0.40776309451541387, "compression_ratio": 1.6073298429319371, "no_speech_prob": 4.611245094565675e-05}, {"id": 1519, "seek": 714344, "start": 7148.719999999999, "end": 7154.179999999999, "text": " Finally there's parallel processing parallel processing refers to the fact hopefully as you all know", "tokens": [50628, 6288, 456, 311, 8952, 9007, 8952, 9007, 14942, 281, 264, 1186, 4696, 382, 291, 439, 458, 50901], "temperature": 0.0, "avg_logprob": -0.40776309451541387, "compression_ratio": 1.6073298429319371, "no_speech_prob": 4.611245094565675e-05}, {"id": 1520, "seek": 714344, "start": 7154.96, "end": 7162.44, "text": " Any modern CPU has multiple cores right which literally means multiple CPUs in your CPU", "tokens": [50940, 2639, 4363, 13199, 575, 3866, 24826, 558, 597, 3736, 1355, 3866, 13199, 82, 294, 428, 13199, 51314], "temperature": 0.0, "avg_logprob": -0.40776309451541387, "compression_ratio": 1.6073298429319371, "no_speech_prob": 4.611245094565675e-05}, {"id": 1521, "seek": 714344, "start": 7163.799999999999, "end": 7165.799999999999, "text": " and often", "tokens": [51382, 293, 2049, 51482], "temperature": 0.0, "avg_logprob": -0.40776309451541387, "compression_ratio": 1.6073298429319371, "no_speech_prob": 4.611245094565675e-05}, {"id": 1522, "seek": 714344, "start": 7165.96, "end": 7169.48, "text": " Boxes that you buy from home might even have multiple CPUs in them", "tokens": [51490, 15112, 279, 300, 291, 2256, 490, 1280, 1062, 754, 362, 3866, 13199, 82, 294, 552, 51666], "temperature": 0.0, "avg_logprob": -0.40776309451541387, "compression_ratio": 1.6073298429319371, "no_speech_prob": 4.611245094565675e-05}, {"id": 1523, "seek": 716948, "start": 7170.2, "end": 7171.759999999999, "text": " Again", "tokens": [50400, 3764, 50478], "temperature": 0.0, "avg_logprob": -0.35399566650390624, "compression_ratio": 1.8151658767772512, "no_speech_prob": 8.614570106146857e-05}, {"id": 1524, "seek": 716948, "start": 7171.759999999999, "end": 7176.12, "text": " Python's not great for parallel processing Python 3 is certainly a lot better", "tokens": [50478, 15329, 311, 406, 869, 337, 8952, 9007, 15329, 805, 307, 3297, 257, 688, 1101, 50696], "temperature": 0.0, "avg_logprob": -0.35399566650390624, "compression_ratio": 1.8151658767772512, "no_speech_prob": 8.614570106146857e-05}, {"id": 1525, "seek": 716948, "start": 7176.839999999999, "end": 7180.48, "text": " But a lot of stuff in Python doesn't use parallel processing very effectively", "tokens": [50732, 583, 257, 688, 295, 1507, 294, 15329, 1177, 380, 764, 8952, 9007, 588, 8659, 50914], "temperature": 0.0, "avg_logprob": -0.35399566650390624, "compression_ratio": 1.8151658767772512, "no_speech_prob": 8.614570106146857e-05}, {"id": 1526, "seek": 716948, "start": 7181.48, "end": 7182.919999999999, "text": " but a", "tokens": [50964, 457, 257, 51036], "temperature": 0.0, "avg_logprob": -0.35399566650390624, "compression_ratio": 1.8151658767772512, "no_speech_prob": 8.614570106146857e-05}, {"id": 1527, "seek": 716948, "start": 7182.919999999999, "end": 7188.759999999999, "text": " Lot of modern CPUs have 10 cores or more even for you know consumer CPU", "tokens": [51036, 20131, 295, 4363, 13199, 82, 362, 1266, 24826, 420, 544, 754, 337, 291, 458, 9711, 13199, 51328], "temperature": 0.0, "avg_logprob": -0.35399566650390624, "compression_ratio": 1.8151658767772512, "no_speech_prob": 8.614570106146857e-05}, {"id": 1528, "seek": 716948, "start": 7188.839999999999, "end": 7193.32, "text": " So if you're not using parallel processing you're missing out on a 10x speedup", "tokens": [51332, 407, 498, 291, 434, 406, 1228, 8952, 9007, 291, 434, 5361, 484, 322, 257, 1266, 87, 3073, 1010, 51556], "temperature": 0.0, "avg_logprob": -0.35399566650390624, "compression_ratio": 1.8151658767772512, "no_speech_prob": 8.614570106146857e-05}, {"id": 1529, "seek": 716948, "start": 7193.959999999999, "end": 7196.5599999999995, "text": " If you're not using sand you're missing out on a", "tokens": [51588, 759, 291, 434, 406, 1228, 4932, 291, 434, 5361, 484, 322, 257, 51718], "temperature": 0.0, "avg_logprob": -0.35399566650390624, "compression_ratio": 1.8151658767772512, "no_speech_prob": 8.614570106146857e-05}, {"id": 1530, "seek": 716948, "start": 7197.24, "end": 7199.24, "text": " 6 to 8x speedup", "tokens": [51752, 1386, 281, 1649, 87, 3073, 1010, 51852], "temperature": 0.0, "avg_logprob": -0.35399566650390624, "compression_ratio": 1.8151658767772512, "no_speech_prob": 8.614570106146857e-05}, {"id": 1531, "seek": 719948, "start": 7199.48, "end": 7205.24, "text": " Alright, so if you can do both of these things you can get 50 plus. I mean you will you'll get 50 plus", "tokens": [50364, 2798, 11, 370, 498, 291, 393, 360, 1293, 295, 613, 721, 291, 393, 483, 2625, 1804, 13, 286, 914, 291, 486, 291, 603, 483, 2625, 1804, 50652], "temperature": 0.0, "avg_logprob": -0.2496213440847869, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.321193435112946e-05}, {"id": 1532, "seek": 719948, "start": 7206.959999999999, "end": 7208.959999999999, "text": " Assuming your CPU has enough course", "tokens": [50738, 6281, 24919, 428, 13199, 575, 1547, 1164, 50838], "temperature": 0.0, "avg_logprob": -0.2496213440847869, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.321193435112946e-05}, {"id": 1533, "seek": 719948, "start": 7209.639999999999, "end": 7212.36, "text": " So we're going to do both to get SIMD", "tokens": [50872, 407, 321, 434, 516, 281, 360, 1293, 281, 483, 24738, 35, 51008], "temperature": 0.0, "avg_logprob": -0.2496213440847869, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.321193435112946e-05}, {"id": 1534, "seek": 719948, "start": 7212.36, "end": 7217.32, "text": " We're just going to install it and to get parallel processing we're probably not going to see all of it today", "tokens": [51008, 492, 434, 445, 516, 281, 3625, 309, 293, 281, 483, 8952, 9007, 321, 434, 1391, 406, 516, 281, 536, 439, 295, 309, 965, 51256], "temperature": 0.0, "avg_logprob": -0.2496213440847869, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.321193435112946e-05}, {"id": 1535, "seek": 719948, "start": 7217.32, "end": 7219.32, "text": " But we're going to be using parallel processing", "tokens": [51256, 583, 321, 434, 516, 281, 312, 1228, 8952, 9007, 51356], "temperature": 0.0, "avg_logprob": -0.2496213440847869, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.321193435112946e-05}, {"id": 1536, "seek": 719948, "start": 7221.12, "end": 7226.44, "text": " So I define a few things to do my resizing", "tokens": [51446, 407, 286, 6964, 257, 1326, 721, 281, 360, 452, 725, 3319, 51712], "temperature": 0.0, "avg_logprob": -0.2496213440847869, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.321193435112946e-05}, {"id": 1537, "seek": 722644, "start": 7227.36, "end": 7230.0, "text": " One thing is I've actually recently", "tokens": [50410, 1485, 551, 307, 286, 600, 767, 3938, 50542], "temperature": 0.0, "avg_logprob": -0.3388162176293063, "compression_ratio": 1.5794871794871794, "no_speech_prob": 7.967228157212958e-05}, {"id": 1538, "seek": 722644, "start": 7230.639999999999, "end": 7236.08, "text": " Changed how I do resizing as I'm sure you guys have noticed in the past when I resize things to square", "tokens": [50574, 761, 10296, 577, 286, 360, 725, 3319, 382, 286, 478, 988, 291, 1074, 362, 5694, 294, 264, 1791, 562, 286, 50069, 721, 281, 3732, 50846], "temperature": 0.0, "avg_logprob": -0.3388162176293063, "compression_ratio": 1.5794871794871794, "no_speech_prob": 7.967228157212958e-05}, {"id": 1539, "seek": 722644, "start": 7236.32, "end": 7241.08, "text": " I've tended to act at a black border to the bottom or a black border to the right", "tokens": [50858, 286, 600, 34732, 281, 605, 412, 257, 2211, 7838, 281, 264, 2767, 420, 257, 2211, 7838, 281, 264, 558, 51096], "temperature": 0.0, "avg_logprob": -0.3388162176293063, "compression_ratio": 1.5794871794871794, "no_speech_prob": 7.967228157212958e-05}, {"id": 1540, "seek": 722644, "start": 7242.04, "end": 7244.04, "text": " Because that's what Keras did", "tokens": [51144, 1436, 300, 311, 437, 591, 6985, 630, 51244], "temperature": 0.0, "avg_logprob": -0.3388162176293063, "compression_ratio": 1.5794871794871794, "no_speech_prob": 7.967228157212958e-05}, {"id": 1541, "seek": 722644, "start": 7245.08, "end": 7247.599999999999, "text": " Now that I've looked into it like no", "tokens": [51296, 823, 300, 286, 600, 2956, 666, 309, 411, 572, 51422], "temperature": 0.0, "avg_logprob": -0.3388162176293063, "compression_ratio": 1.5794871794871794, "no_speech_prob": 7.967228157212958e-05}, {"id": 1542, "seek": 722644, "start": 7248.4, "end": 7250.4, "text": " best practice papers", "tokens": [51462, 1151, 3124, 10577, 51562], "temperature": 0.0, "avg_logprob": -0.3388162176293063, "compression_ratio": 1.5794871794871794, "no_speech_prob": 7.967228157212958e-05}, {"id": 1543, "seek": 725040, "start": 7250.5199999999995, "end": 7255.679999999999, "text": " Cackle results in a thing used that way and it makes perfect sense because the CNN is going to have to like", "tokens": [50370, 383, 326, 14677, 3542, 294, 257, 551, 1143, 300, 636, 293, 309, 1669, 2176, 2020, 570, 264, 24859, 307, 516, 281, 362, 281, 411, 50628], "temperature": 0.0, "avg_logprob": -0.3701269967215402, "compression_ratio": 1.7107438016528926, "no_speech_prob": 0.02931123785674572}, {"id": 1544, "seek": 725040, "start": 7255.879999999999, "end": 7257.879999999999, "text": " Learn to deal with the black border", "tokens": [50638, 17216, 281, 2028, 365, 264, 2211, 7838, 50738], "temperature": 0.0, "avg_logprob": -0.3701269967215402, "compression_ratio": 1.7107438016528926, "no_speech_prob": 0.02931123785674572}, {"id": 1545, "seek": 725040, "start": 7258.5599999999995, "end": 7260.5599999999995, "text": " And you're throwing away all that information", "tokens": [50772, 400, 291, 434, 10238, 1314, 439, 300, 1589, 50872], "temperature": 0.0, "avg_logprob": -0.3701269967215402, "compression_ratio": 1.7107438016528926, "no_speech_prob": 0.02931123785674572}, {"id": 1546, "seek": 725040, "start": 7262.04, "end": 7265.4, "text": " What pretty much all the best practice approach use is to", "tokens": [50946, 708, 1238, 709, 439, 264, 1151, 3124, 3109, 764, 307, 281, 51114], "temperature": 0.0, "avg_logprob": -0.3701269967215402, "compression_ratio": 1.7107438016528926, "no_speech_prob": 0.02931123785674572}, {"id": 1547, "seek": 725040, "start": 7266.32, "end": 7272.96, "text": " Rather than rescale the longest side to be the size of your square and then fill it in with black", "tokens": [51160, 16571, 813, 9610, 1220, 264, 15438, 1252, 281, 312, 264, 2744, 295, 428, 3732, 293, 550, 2836, 309, 294, 365, 2211, 51492], "temperature": 0.0, "avg_logprob": -0.3701269967215402, "compression_ratio": 1.7107438016528926, "no_speech_prob": 0.02931123785674572}, {"id": 1548, "seek": 725040, "start": 7273.799999999999, "end": 7278.08, "text": " Instead take the smallest side and make that the size of your square", "tokens": [51534, 7156, 747, 264, 16998, 1252, 293, 652, 300, 264, 2744, 295, 428, 3732, 51748], "temperature": 0.0, "avg_logprob": -0.3701269967215402, "compression_ratio": 1.7107438016528926, "no_speech_prob": 0.02931123785674572}, {"id": 1549, "seek": 727808, "start": 7278.5199999999995, "end": 7284.44, "text": " The other sides now too big so just chop off the top and bottom or chop off the right or right and left", "tokens": [50386, 440, 661, 4881, 586, 886, 955, 370, 445, 7931, 766, 264, 1192, 293, 2767, 420, 7931, 766, 264, 558, 420, 558, 293, 1411, 50682], "temperature": 0.0, "avg_logprob": -0.37568649492765727, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.4300165023305453e-05}, {"id": 1550, "seek": 727808, "start": 7284.5599999999995, "end": 7288.92, "text": " That's called center cropping right so resizing and center cropping", "tokens": [50688, 663, 311, 1219, 3056, 4848, 3759, 558, 370, 725, 3319, 293, 3056, 4848, 3759, 50906], "temperature": 0.0, "avg_logprob": -0.37568649492765727, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.4300165023305453e-05}, {"id": 1551, "seek": 727808, "start": 7289.68, "end": 7297.4, "text": " So what I've done here is I've got something which resizes to the size of the shortest side", "tokens": [50944, 407, 437, 286, 600, 1096, 510, 307, 286, 600, 658, 746, 597, 725, 5660, 281, 264, 2744, 295, 264, 31875, 1252, 51330], "temperature": 0.0, "avg_logprob": -0.37568649492765727, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.4300165023305453e-05}, {"id": 1552, "seek": 727808, "start": 7298.96, "end": 7300.2, "text": " And", "tokens": [51408, 400, 51470], "temperature": 0.0, "avg_logprob": -0.37568649492765727, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.4300165023305453e-05}, {"id": 1553, "seek": 727808, "start": 7300.2, "end": 7301.32, "text": " then", "tokens": [51470, 550, 51526], "temperature": 0.0, "avg_logprob": -0.37568649492765727, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.4300165023305453e-05}, {"id": 1554, "seek": 727808, "start": 7301.32, "end": 7303.32, "text": " over here", "tokens": [51526, 670, 510, 51626], "temperature": 0.0, "avg_logprob": -0.37568649492765727, "compression_ratio": 1.6785714285714286, "no_speech_prob": 2.4300165023305453e-05}, {"id": 1555, "seek": 730332, "start": 7304.32, "end": 7308.5, "text": " Over here, I've got something which does the center cropping", "tokens": [50414, 4886, 510, 11, 286, 600, 658, 746, 597, 775, 264, 3056, 4848, 3759, 50623], "temperature": 0.0, "avg_logprob": -0.290251172107199, "compression_ratio": 1.6814159292035398, "no_speech_prob": 7.141851529013366e-05}, {"id": 1556, "seek": 730332, "start": 7309.84, "end": 7313.4, "text": " You can look at the details when you get home if you like it's not particularly exciting", "tokens": [50690, 509, 393, 574, 412, 264, 4365, 562, 291, 483, 1280, 498, 291, 411, 309, 311, 406, 4098, 4670, 50868], "temperature": 0.0, "avg_logprob": -0.290251172107199, "compression_ratio": 1.6814159292035398, "no_speech_prob": 7.141851529013366e-05}, {"id": 1557, "seek": 730332, "start": 7314.28, "end": 7316.28, "text": " So I've got something that does the resizing", "tokens": [50912, 407, 286, 600, 658, 746, 300, 775, 264, 725, 3319, 51012], "temperature": 0.0, "avg_logprob": -0.290251172107199, "compression_ratio": 1.6814159292035398, "no_speech_prob": 7.141851529013366e-05}, {"id": 1558, "seek": 730332, "start": 7318.04, "end": 7322.84, "text": " This is something you can improve currently I'm making sure that it's a three channel image", "tokens": [51100, 639, 307, 746, 291, 393, 3470, 4362, 286, 478, 1455, 988, 300, 309, 311, 257, 1045, 2269, 3256, 51340], "temperature": 0.0, "avg_logprob": -0.290251172107199, "compression_ratio": 1.6814159292035398, "no_speech_prob": 7.141851529013366e-05}, {"id": 1559, "seek": 730332, "start": 7322.84, "end": 7328.04, "text": " And so I'm not doing a black and white or something with an alpha channel. I just ignore them", "tokens": [51340, 400, 370, 286, 478, 406, 884, 257, 2211, 293, 2418, 420, 746, 365, 364, 8961, 2269, 13, 286, 445, 11200, 552, 51600], "temperature": 0.0, "avg_logprob": -0.290251172107199, "compression_ratio": 1.6814159292035398, "no_speech_prob": 7.141851529013366e-05}, {"id": 1560, "seek": 732804, "start": 7329.04, "end": 7331.04, "text": " Okay", "tokens": [50414, 1033, 50514], "temperature": 0.0, "avg_logprob": -0.36253810164952044, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.00016603748372290283}, {"id": 1561, "seek": 732804, "start": 7332.2, "end": 7334.4, "text": " So before I finish up this", "tokens": [50572, 407, 949, 286, 2413, 493, 341, 50682], "temperature": 0.0, "avg_logprob": -0.36253810164952044, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.00016603748372290283}, {"id": 1562, "seek": 732804, "start": 7335.28, "end": 7341.72, "text": " I think I'm out of time so what we're going to learn next time when we start is we're going to learn about parallel processing", "tokens": [50726, 286, 519, 286, 478, 484, 295, 565, 370, 437, 321, 434, 516, 281, 1466, 958, 565, 562, 321, 722, 307, 321, 434, 516, 281, 1466, 466, 8952, 9007, 51048], "temperature": 0.0, "avg_logprob": -0.36253810164952044, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.00016603748372290283}, {"id": 1563, "seek": 732804, "start": 7342.16, "end": 7344.64, "text": " So anybody who's interested in pre-reading?", "tokens": [51070, 407, 4472, 567, 311, 3102, 294, 659, 12, 35908, 30, 51194], "temperature": 0.0, "avg_logprob": -0.36253810164952044, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.00016603748372290283}, {"id": 1564, "seek": 732804, "start": 7345.48, "end": 7352.86, "text": " Yeah, feel free to start reading and playing around with Python parallel processing all right. Thanks everybody see you next week", "tokens": [51236, 865, 11, 841, 1737, 281, 722, 3760, 293, 2433, 926, 365, 15329, 8952, 9007, 439, 558, 13, 2561, 2201, 536, 291, 958, 1243, 51605], "temperature": 0.0, "avg_logprob": -0.36253810164952044, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.00016603748372290283}, {"id": 1565, "seek": 732804, "start": 7353.32, "end": 7356.84, "text": " Hope your assignments go really well, and let me know if I can help you out in the forum", "tokens": [51628, 6483, 428, 22546, 352, 534, 731, 11, 293, 718, 385, 458, 498, 286, 393, 854, 291, 484, 294, 264, 17542, 51804], "temperature": 0.0, "avg_logprob": -0.36253810164952044, "compression_ratio": 1.6640316205533596, "no_speech_prob": 0.00016603748372290283}], "language": "en"}