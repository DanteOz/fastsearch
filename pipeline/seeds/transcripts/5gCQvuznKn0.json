{"text": " When Rachel and I talked over, you know, what what should she cover in this year's NLP course? Because neither of us has taught an explicitly NLP course before we found ourselves in a slightly awkward situation in which that there's a bit of a mismatch between what would university students generally be expected to have learned having done an NLP course versus what do we actually think is useful because what's happened as she said is that this field's undergone a lot of change in the last few years and that means that when you interview for jobs you're likely to be asked questions that in fact most of the time if you're being asked questions by a senior person about NLP they won't be very familiar with actually the current techniques because they went to university and most people after they've gone to university don't necessarily keep up so we do think it's important that you understand a broader kind of spectrum of what NLP is being generally considered to be so that's why you've looked at things like limitization and stop words stuff even though it never comes up I've never used either of those things I mean at least if you don't I've tried using them it's always worked better without them so I thought one thing I might briefly touch on is putting aside there what might you need to get interviews for a job or pass an exam what are the things that I personally have found extremely extremely useful that you've covered in this course so that you can kind of know the difference between what you definitely want to take away as part of your toolkit versus what you need to know to pass an exam or pass a job interview so looking through the notebooks you've covered so far the one that stands out to me the most is regular expressions and it also stands out to me that when Rachel asked who feels very comfortable with regular expressions I was very surprised by how few hands went up not as a criticism but just to say like I use regular expressions many times every day to do things in my code editor to gather data to like everything almost that involves anything involving file names or data gathering or data managing or whatever always I use regular expressions so the fact that a lot of you aren't familiar with it makes me think you're not taking advantage of a tool that's in your toolbox so I would say of all the things to take away that would be the one the one at the top of my list so I thought I'd give you a quick example of what a workflow might look like involving regular expressions most editors support regular expressions deeply I happen to use an editor called Vim which I quite like I think it's particularly good for data science but this these ideas will hold across many editors and just before the class started I just downloaded a data set containing some addresses and phone numbers and things and I thought like maybe I'll show you how I go about cleaning up a data set so this particular data set apparently is Austin public health locations which I just downloaded from data.gov and I was thinking how would I answer the question what are all of the phone numbers of Austin public health locations and I need you to provide them to us in a particular format which is in a particular format which is say like digit digit digit space digit digit digit space digit digit digit something like that right so how would you go about doing that from this data set this is the kind of thing that's going to come up all the time so the first thing I would do would be to select all of the rows in this text file that contain a phone number and so I would tend to be a bit cautious about guessing what a phone number is but looking through here it looks like the phone numbers are generally digit dash digit dash digit so Vim has a really nice way to find lines containing a regular expression which is G G stands for grep grep is the normal unix command for finding stuff and generally the arguments to commands in Vim have slashes around have slashes around them so I'm going to search for phone numbers alright so I guess we could say phone numbers is a digit you know one or more digits followed by a hyphen followed by one or more digits followed by a hyphen followed by one or more digits and one of the things to notice is that every program library programming language has slightly different regular expressions Vim's particular oddity is that they require backslashes in more places most regular expressions don't need a backslash before the plus Vim does unless you change preference setting so this is going to go ahead and find all of the lines that match this regular expression and then do what and this is really nice in Vim you can then provide another command to run on those so the command I want to run is delete which is D but actually I want to do all of the ones that don't match that so like many systems exclamation mark means not means the opposite so this is going to delete all the lines that don't match this regular expression done so it's just deleted 67 lines maybe it would be helpful actually if I just undo that to do it without the exclamation mark to see what lines is it going to delete just to double check that this looks reasonable and that they don't have things that look like they might be phone numbers in them so that looks fine guess these are ones that don't have phone numbers so part of my workflow is I tend to do a lot of undo redo as I play around and Vim you is undo so I can just hit up arrow to go back to my previous command that I ran and here I am so the second thing I want to do is find all of the phone numbers and maybe I would probably do this in one step but to make it more clear I'll do it in two find all of the phone numbers and just make each line just the phone number so that would be one way to do that would be a search for a place so I could go search for digit and then dash and then digit and then dash and then digits and then I want to replace it with everything I just found which is the same as Python backslash one in fact since I didn't put parentheses around it I can just say ampersand that means everything I just mentioned actually let's do it with backslash one so if you put parentheses and again with Vim it's a bit weird you have to backslash the parentheses so I've got to capture the whole thing replace it the line with that and then we're also going to need to say search for everything else in the line so arbitrary text and then something that might be a phone number and then arbitrary text and replace it with just the contents in the parentheses okay so that's not quite right as you can see because it's left me with what looks like partial phone numbers so one of the nice things about like one of the things I'm really careful to do in all of my work is to do things like very interactively so I would much rather work in Vim or a Jupyter notebook than write a program because I want to I want to be playing with the data right so this is a really nice way to do things so now I can hit you to undo and then I can go back and have a look and see why did this fail and so this is where it's good to start learning some of the details about regular expressions and one of the things that's useful to learn is the idea of a greedy match a greedy match is the idea that when you match something with a wild card like star or plus it wants to find as many as big a group as possible so the reason this didn't work is that dot star dot means everything right and so including digits so like there's two possible ways to match this it could either match everything up to the first of these digits and then stop there and then start capturing digits or it could match everything including the digits and then it would only need to find one so strictly speaking what it did here which was in the dot star included those first two digits totally correct right I mean it's it's it's what I asked for but it's not what I wanted so you can see how valuable it is to do this kind of interactively I can just hit you to undo and try again a couple of ways I could fix this one is in in regular expressions you can ask for a non greedy match and the way you do that is you put a question mark after a asterisk or a plus and that means as sure as possible right so this is now a non greedy match of the star which means the greedy match will go on my digits. Which might not be supported by them. So one of the tricks here is different systems also support different subsets of functionality so this question marks not working so then I'd go vim regex non greedy let's see how do I make it okay so I don't I've not seen this before what is this one not sure so it says instead of dot star use this apparently this is a non greedy. So let's try it. Okay so that worked that's not bad but perhaps the way I would tend to do it in practice would be instead of a dot I might say everything except for a zero to nine so to create a set of possible things you put them in square brackets so that means a SDF and there's a shortcut which is if you put something hyphen something you mean that means everything between these two so these are all the digits or all the letters and then to mean everything except those in square brackets you pop a carrot symbol so this would be non digits as many as possible and so this would also fix the problem except it didn't let's see. Okay so I'm checking I just searched for that and that is working so that's good. Oh I see the problem. Okay so again it's good that we're doing things interactively my logic's not right so I can't search for non digits because there's lots of digits that aren't in phone numbers that aren't going to match so which reminds me people so when I'm running courses I did a lot of students tend to hang out with me in the study room and we just work together and I tend to get a few comments about things people are surprised by when they're working with me maybe the main one is gosh I'm surprised how many mistakes you make except generally phrased slightly more politely there's plenty of seats over here if you guys want seats it's really useful to remember that the stuff that you see teachers do is stuff that we generally spend quite a lot of time preparing one of my deep learning courses basically takes me six months full-time repair so by the time you see it hopefully I've got things working 99% of the time whatever I'm doing doesn't work and so I found the biggest difference between people who are successful at things in general and those who aren't seems to be entirely about tenacity which is both something I've anecdotally found and also seems to be something which some social science research finds as well and particularly for machine learning machine learning you have to be super tenacious for because it's something where when things don't work they often don't work in kind of mysterious and hard to debug ways it's not like kind of you're creating a web service or something and you need these specific steps to work and then each step you get it to work and check it off machine learning is not at all like that and you're going to have to keep going regardless of you know the fact that it didn't work the second thing I think I hear more than anything else is wow I'm surprised at how fast you are at using your tools so like I'm super fast with the shell and with the editors I use and stuff like that and again that's something I've found a lot of people doing code-based stuff really well tend to be extremely familiar with all the keyboard shortcuts and all the little tricks so that as soon as something pops out of their head they can get it into their machine so getting to know your editor and shell and stuff really well is a good idea okay so I think we'll go back to our non-greedy version of this because that actually worked pretty well so the last thing to do here would be to reformat this and it's interesting it's actually showed us it's very clear now that they're actually somebody had an error right so another good reason to do your data munching very interactively is you can see mistakes clearly Austin must be a 5 1 12 area code so we can fix their mistake for them so if now we want to reformat this in the format that was requested we can just go ahead and we've actually already got the basics we need which was backslash d backslash plus so we'll capture that and then backslash b backslash plus and we'll capture that backslash b plus capture that and so we're going to go backslash and then we're going to replace it with a slightly different format. We can now send that off when we finish doing our data munching so yeah question for debugging regular expressions yeah the main trick is something that you one of the tricks is something I showed I kind of did quickly earlier which is I was trying to figure out why my care at 0 to 9 star wasn't working so I got rid of a search from the place and I just wanted to kind of take little pieces so the first thing was oh maybe the inverse of a set operator is different in Vim so I tried just so slash mean search in Vim so I just said search for a non 0 to 9 and then I started hitting n which means go to the next one and I just made sure it seems to be going through the non digits right and so then it's just a case of like checking each of your assumptions and then making your search smaller and smaller and smaller another thing is to do like less than each go so I could have actually done the whole reformatting and finding straight from here right if I so once I you know I could have put straight from here I could have gone search for each group and replace and I could have done it in one go rather than two but like I kind of think splitting things up into multiple steps where you can see each step is a good idea I think in general debugging anything the main trick is to once something doesn't work is to like find the smallest thing that doesn't work and then find the like keep going back from there to find a small thing that does work and now once you know what the specific thing that doesn't work is fixing it is normally pretty easy one of the challenges with debugging in general is that if something in your code isn't working it means that something that you thought worked in a particular way is not working in that way so like you actually have to start with an understanding that you're wrong about something which can be quite hard for people so often like one of the challenges I have with newer programmers is to say okay we're going to go right back to the start and create the simplest possible thing and then check every little step and new programmers are often like no no I already know this bit so we can jump to there I think the problem is X and debugging is never about I think the problem is X it's always about starting with I don't know what the problem is because I made a mistake and so you just like requires a lot of humility you go back you check everything and eventually we've all had this feeling when you find the bug oh I'm an idiot so don't wait to find out we you know I already know I'm an idiot right so let's just work on that assumption when we start debugging okay so regular expressions things that not just that go in your code but they go in your day-to-day life they go in your editor a lot of the programs you use if you search the docs you'll find they probably already support regular expressions in lots of places so the other ones I wrote down here SVD so matrix decomposition is just a really powerful technique I certainly don't use it as much as rejects or transfer learning but it's definitely something that is really handy to know well the I'm obviously biased but in my opinion Rachel's computational linear algebra course is the best place to learn more about that so if you're interested in diving deeper this is the master's course that she taught in 2017 on this topic so it's just like this course that we're teaching you now it was a master's elective course so it's not something you'll zip through in an afternoon but you can certainly jump into the SVD notebooks for example and particularly randomized SVD or just like randomized algorithms and data structures this is something that few people that you work with will be familiar with it's just something that hasn't been widely taught it's starting to change but the vast majority of people who are that kind of management level so they've been out of university for a few years probably won't have come across randomized algorithms and data structures but the basic idea as Rachel mentioned is that you can take a matrix and replace it with one with far fewer columns by multiplying it by a random matrix and then do whatever you're trying to do to that multiplied out version and you'll get roughly the same result and there are ways to make it even a little bit better than than just the random multiplication it's that it's a super surprising and counterintuitive result but something you can use to speed up many things by many orders of magnitude and in general there are many randomized algorithms and randomized data structures probably the one that will be the most widely known and widely used is called the bloom filter which is one of the things that Rachel covers but it's covered in lots and lots of places bloom filters are used for example in your web browser they're a probabilistic so randomized data structure which tell you whether something is a member of a set but they only reliably tell you if something is not in a set if something is in the set it just returns a maybe and so your web browser uses it for things like oh is this from a blocked domain and so it can very quickly use a really small approximate data structure which would return a response oh maybe this is a blocked domain and so like ninety nine point nine nine percent of the time it's not and it's confident that it's if it's not that a bloom filter tells you 100% certainly and if it is then it can check slowly you know through an online system whether it really is or not so probabilistic and randomized data structures and algorithms in general is super cool and randomized SVD is certainly one of those super cool ones so then the third area is transfer learning and specifically transfer learning for deep neural networks now it's a bit tricky because transfer learning in NLP is I think most easily taught by saying oh it's just the same as computer vision but I know some of you haven't done computer vision transfer learning yet so I think the only way to solve this problem is to make sure you do all know how to do computer vision transfer learning so we're actually going to start there so for those of you that already did the deep learning certificate or have done the online deep learning MOOC this will all be review for you so I've added a review CV transfer notebook to the repo which is literally a copy of lesson one of course dot fast at AI which is the same as the University of San Francisco certificate course but it's kind of the minimal version so let's start by talking about computer vision transfer learning so the starting point to do to use any of these deep learning notebooks as Rachel mentioned is to grab a GPU if you're a student probably the easiest option is to and cheapest option is that there's a thing called the github student developer pack and if you click get your pack and you say yes I'm a student just fill in your details then that will get you something like a hundred dollars worth or so of AWS credits and then what you can do is you can go to you can go to salamander.ai which is a instant jupyter notebook system where you can use those AWS credits to get an instant jupyter notebook and so that's probably the easiest way another really good option is one that we mentioned last time which is Google Cloud GCP and they will give you three hundred dollars of credits everybody they require a little bit more setup but if you go to cost up faster AI and click on server setup and click on Google Cloud it's actually still super easy basically you just copy and paste half a dozen lines I guess but one of the nice things about that is that it spins up a jupyter notebook automatically for you or the GPU drivers are installed automatically for you and even all the fast AI courses are installed automatically by Google as part of their platform so that's super helpful so those are the two options that I currently think are best it varies over time things come and go so you can always check cost up faster AI server setup to see what's available and you can also see in the using a GPU section our specific recommendations and you can also see the differences in pricing okay so so I've got jupyter notebook running and I loaded up reviews CP transfer on a GPU machine and I'll first of all give you the super high level view of what we do what we're going to do is that we're going to try to recognize the contents of the Oxford IIT pet data set and this data set contains pets and they are grouped into these various groups of 37 types of dogs and cats and so when this was created this was considered a extremely brutally difficult data set and so the Oxford University researchers that studied it created a very pet specific model that used a lot of domain specific information about animals and they were able to get slightly better than 50% accuracy at recognizing pet breeds this was I remember the except here let's see 2012 okay so that was in 2012 so that's the data set we're going to use one of the things that's super helpful when you use the fast AI library is that there's a lot of data sets built into it so using this data set is as simple as using the fast AI and tar data command and passing in the fast AI URL dot pets constant and you that's it that's all you need to do it or download and unzip the data set for you the this particular data set as you'll find in the readme for it has two things it's got annotations which is like whereabouts are the pets in it and then the images themselves so we're just going to grab the images so fast AI has a get image files function that returns all the images so file names so here's an example so the first thing you need to do to create a machine learning model of any kind well supervised model so supervised model is a model that has labels as we need labels and in this case the label is embedded in the file name so we need some way to label these files based on finding everything before underscore digit and after forward slash in a file name so what would be a good way to do that regular expression so here is the regular expression right capture everything that's not a slash at least one and capture followed by an underscore followed by a digit one or more and this pattern of blah square bracket not blah plus is super super common right because it basically means find the first slash and then find lots of things that aren't slashes right or find a quote mark and then lots of things that aren't quote marks so this is a useful idiom to become familiar with the other thing to remember realize is that if you haven't done much with regular expressions you go there's seats over here if you want one if you're not familiar with regular expressions is that often the first time you look at one you know they look confusing and like I'm never going to understand that but the trick is just to like remember that this is kind of like 12 lines of code right so you look at every character one at a time and you just say what's that so a slash start capturing a group containing not a slash one or more but just look at one letter at a time and then the nice thing is in Jupyter Notebook in Jupyter Notebook you can start playing right and so like what I would tend to do if I wanted to kind of build a regular expression like this or understand this one would be I would start by giving myself something to work with so let's grab a file name okay or maybe even turn that into a string rather than a path just to make it even simpler to look at and then we could start doing things like saying re.match actually maybe re.find and then you can start like looking for things so anytime you look for a regular expression you should pretty much always use the r variant of strings because in Python if you put r before your string it basically says treat backslashes as normal backslashes in normal strings in Python a backslash n for example means new line when you're working with regular expressions you generally want backslashes just to be backslashes so that's what ah means so we could say oh find all the like let's see what we find if we look for zero to nine for example that so you can start like exploring there's lots of online regular expression tools but and some of them are worth using but I don't use any of them because I find Jupyter Notebook is a great regular expression tool right so there's like oh is that the same as backslash D oh I guess it is what if we have two backslash days oh okay you know and so then we can start exploring like oh well what's what's this thing here finding oh okay all right so you can start to explore so then it's like oh let's put a underscore oh looking even better right so by the way a slash followed by a bunch of things that aren't a slash followed by underscore also matches why is it matching great Pyrenees and not just great that's because it's greedy remember so plus is a wild card and it's going to try and find as many as it can okay so in this case this is as many as it can so why did we put a bunch of digits and then JPEG and then dollar means end of the string so why did we put all that here as well because I think it's a good idea to like double check things are formatted the way you thought they are so it would give us an error if it failed to find something so for example if one of the things was actually a PNG you know it would give us an error saying this didn't match so it's a good idea to be you know as clear to Python as possible about what it is you're looking for so fast AI has a labeling thing which can find something from a name using a regular expression and so you can just pass in the path where the images are stored the file names and the pattern to look for okay we won't talk about it now but you can also ask for image augmentation and you can also normalize so in as you'll see for both NLP and computer vision fast AI has a show batch which will display a bit of your data for you and so this is in terms of my workflow this is the first thing I do after I load some data is to look at it okay so basically what we do is we we grab this data so it's stored in data which contains the training set and the validation set that's all done automatically by fast AI and we can create a model which the data plus the model together in fast AI according learner and you can fit the learner and you can fine-tune the learner and at the end you get an error and you can see the error rate we got was 6.2 percent and so the first thing to kind of note if you haven't done deep learning before is how astonishingly world-changing it is just in terms of it it's the first thing that kind of works for complex tasks like this in 2012 the world's best Oxford researchers got a little bit better than 50 percent accuracy we've got 90 93 plus percent accuracy 90 nearly 94 percent accuracy with basically no work and it took about a minute and a half the there's a couple of secrets to making this happen the first is obviously that we're using deep learning which is super flexible so I think you've you've all done confidence before is that right anybody not done confidence yet okay so things like convolutional neural networks are just really flexible they can have lots and lots of parameters and most importantly you can regularize them so that they don't overfit we can run them on GPUs so we can run them in a reasonable amount of time but the second trick going on here is that this particular convolutional neural network we use is that by default fast AI if you pass it an architecture that it recognizes like a resonant 34 will load a pre-trained model so what people used to do in deep learning is that they would generally start with random weights right so a deep learning model remember is just you get some input you put it through a matrix multiply you replace the negatives with zeros you put it through another matrix multiply you replace the negatives with zeros you do that 18 times and then you do a softmax and a loss function just normally cross entropy loss that would be classification right for vision we don't just use a normal matrix multiply we use one with tied weights called a convolution but it's it's just a type of matrix multiplying when you look at it so the same basic idea and so what do we multiply by or what do we do a convolution with you know the the old way to do it was with some randomly initialized weights nowadays we're realizing that this is very rarely what we want randomly initialized weights by definition start out doing basically nothing useful at all so it takes a long time to train a model that starts with randomly initialized weights to do anything interesting so increasingly particularly starting with research that came out in 2013 research started coming out in 2013 showed that if you start with non-random weights and specifically they looked at weights of models that have been trained on a data set called image net which contains 1.3 million images covering a thousand different types of object if you start with a model that's not trained with which doesn't have random weights but has weights that have already learned to recognize image net and then just train in the normal way so it's literally you train a normal network but instead of randomly initialized weights their weights that you just borrowed from an existing model it turned out to give the state-of-the-art accuracy on all 13 data sets that the researchers in 2013 tried it with and this was quite surprising to a lot of people because the data sets they tried it with varied a lot they were everything from flower recognition to figuring out what architect created a building to type of sculpture and artwork all kinds of different stuff so I'd say the the overall kind of big leap in 2013 was people recognizing that transfer learning was useful even if you didn't have a model to start with which was in your domain so if you were trying to recognize artworks you didn't have to find somebody that had already trained an artwork model you could start with an image net model and you would still get world-class results so that's why fast AI by default will will always give you a pre-trained model when you start training so here when we say learn is a convolutional neural network learner that's going to train on the data that we just provided training a resident 34 model the first thing it'll do is if you haven't run this before is it'll go to the internet and download a set of weights that have been trained to make a resident 34 good at recognizing image net pictures and then when you say fit it's going to train a neural net in the usual way using stochastic gradient descent or a variant by default fast AI uses a variant called Adam and so you can see that even after one epoch you're down beneath a 10% error and in this case it's particularly good right from the start because image net actually does contain pictures of animals not all of the breeds of animal here but deep learning networks each layer tends to recognize increasingly specific features and so the final layers of image net are very good at recognizing fur and ears and eyes and tail shapes and stuff because it's had to recognize other kinds of animals so it doesn't take much fiddling to make it recognize these particular 37 pet breeds so then since we started we being Rachel and I started fast AI a few years ago we actually decided to kind of focus on transfer learning from the start and one of the things that we got very interested in was like what what can we do to transfer learn well like there's been very little academic research on that question because it's academic research generally isn't particularly well aligned with practical realities of what actually matters because academics to get cited and stuff they kind of have to work in existing established research question areas and transfer learning generally hasn't been one of those so we kind of found the research a bit lacking but when we thought about it we thought it doesn't really make any sense to train the whole model if you're doing fine-tuning of a pre-trained network in the same way because we know that the first layers of a conv net are super super general they find things like particular colors vertical or horizontal lines you know stuff like that and the later layers are super super specific right the last layer has to find the exact thousand categories that we need so we certainly were the only ones thinking this way but us and others started kind of wondering how do we take advantage of that knowledge because if we just take a pre-trained network and fine-tune it in the normal way we know that the last layers are going to be totally wrong for our new domain but the first layers are probably really good for our new domain and so when the gradients come through it's going to actually screw up the first layers because there's going to be a lot of gradient throughout the network so one of the things that pretty obviously you might want to do is to train the last layers more and in fact there's one particular layer of a transfer learning network that's particularly important and that is the final layer and the reason the final layer is important is because that is the one that actually does have random weights why does it have random weights because the final layer of an image net network is a simple linear model that takes the penultimate layer weights and projects them through a thousand dimensional space right one one vector element for every one of those thousand image net classes so it's like what's the probability that this is a hammer what's the probability that's an aeroplane what's the probability that's a sailboat so you get these a thousand activations in the final layer so the final layer of the image net network is useless to us because we're doing 37 pet breeds so fast AI automatically when you're doing transfer learning deletes the last layer and replaces it with a new one and the new last layer has an appropriate number of outputs for our data which in this case is 37 outputs and it randomly initializes them so the final layer actually fast AI adds a little mini neural network with two layers but same idea the final layer or the final layers are random so we should train them first right because they're totally totally wrong to start with so what actually happens is when you create a learner in fast AI you can see pre-trained here defaults to true and if pre-trained is true then it will delete the last layer it'll put in a new layer of random weights and it does what's called freezing it freezes every layer except the last one and what freezing does is during the SGD stage is it does not do a weight update for the frozen layers so the in this case we've got say 34 layers right so layers 1 through 33 will not have their weights updated by SGD and layer 34 will and so the amazing thing is that this actual 15 seconds here that gets us better than 10% error is actually only training the last layer right so depending on what system you use either that'll be a linear layer or a little mini neural net with just one hidden layer so you can see that all we need to do to get super good accuracy on this data set was to just train a new little linear classifier from the existing image net weights for everything up to the penultimate layer so that's also why these steps are a little bit faster they're only 15 14 or 15 seconds per epoch so this is this is training the last layer and in transfer learning the idea of kind of like freezing the features of some network and then just training one or two linear layers on top of it is pretty common it's pretty popular works pretty well but it's not as general as the next step which is here where we say unfreeze and what unfreeze does is it says okay now I want to update the weights of all the layers with SGD so when we fit now you can say it takes a little longer because it has to back prop through more layers and update more weights but it does let the error rate go even further down because it can now change the learning rate of the earlier layers as well so so that's trick number one for transfer learning trick number two for transfer learning is here so and it's this you know from what you studied already that the key hyperparameter in neural networks is the learning rate and if you think about it this thing we did where we froze the first 33 layers was basically identical to setting the learning rate for the first 33 layers to zero because the learning rate of zero remember the weight update rule is weights at t plus one is weights at t plus learning rate times gradient the gradient of the loss function with respect to the weights so with the learning rate of zero it does nothing what's happening here is something we call discriminative learning rates which is the kind of next level of nuance over that the very first layer is going to get a learning rate of one in x6 because the very first layer needs very very little fine-tuning right it's very unlikely that you need to find a different way of finding horizontal lines or patches of blue right the very very last layer is going to have a learning rate a hundred times higher than that one in x4 and then this particular notation when used in fast AI is how we tell fast AI to train all of the layers using a sliding scale of learning rates where the first layer gets this learning rate the last layer gets that learning rate and all the layers in between get equally geometrically spaced learning rates between them so that's called discriminative discriminative learning rates so those are the two tricks right layer freezing and discriminative learning rate and with those two things you're basically going to be at the state of the art for transfer learning so what we'll do after the break as we'll see what happened when two years ago we tried using those tricks for an LP because I mentioned in 2013 people started realizing from the computer vision the transfer learning was important and we you know started building as a community some of these tricks as of two years ago it hadn't been done in NLP still which super super surprised me and we tried it out and it turned out to work super well so let's have a break and let's come back at 12.10. Okay let's keep going so I've had a request at the break for a to go over freezing and unfreezing in a bit more detail so to do that I'm going to refer to the convolution example spreadsheet from the deep learning course so if you're for all of these things are interested in learning them more please check out the deep learning course because we can't possibly cover all of deep learning as well as all of NLP in this course but we're trying to give you a sense of the main pieces this is an example of a number seven from MNIST the popular handwriting recognition data set it contains lots of zeros where the white is and ones where the drawing was and things between the two where it's on the edges and so if we use conditional formatting in Excel you can see the number seven pop out a convolution is something which simply has a three by three filter like this is a random three by three convolution filter and then the output of the convolution is shown here and as you can see it is specifically it basically contains the result of a three by three part of the image dot product with three three by three convolutional kernel like so so every pixel looks like that and then and then we generally have multiple ones of these randomly created little kernels and each one creates its own output like this and then to make life easier we don't treat them as a bunch of three by three matrices we treat it instead as a three by three by K tensor and so the output then creates a three dimensional tensor so each of these layers gets less damaged together or if we're doing RGB images rather than black and white we would have a rank four tensor so then we take the these outputs and we put them through a non-linearity like relu relu means replace the negatives with zeros and then we put it through another convolution so here's our second kernel now I'm in this case the input is a rank three tensor rather than a rank two tensor so our convolution requires two layers and we've got it's basically the same deal so now we're doing a dot product with with this three by three with each of these and adding them together along with this three by three so if this is unclear then yeah please check out the deep learning course but that's the basic idea from that we then we do max pooling which we want or we do strive to convolutions and then we do a matrix multiply and we end up with a number and the number is the loss we take the derivative of the loss with respect to the weights and what that then lets us do is we then can go back and update the weights to be slightly better weights that's what SGD does and so that equation is new weights is whatever the old weights were minus the learning rate times the gradient now the thing is that the filter in layer one generally needs very little if any updating because it's creates things that kind of find edges and colors and gradients things that are very very general where else the filters in the later layers generally need lots of updating because they're finding things that are very specific to the exact task they were trained for so if we set the learning rate for this layer to be like one in x6 it's not going to change very much at all right it's going to change very very slowly and then if we change this one to say make this learning rate say one in x2 for this layer then it's going to change much faster right so that's discriminative learning rates freezing is just the extreme version of that freezing is basically saying for some subset of layers let's set the learning rate to zero so they don't get updated at all and specifically generally for fine-tuning you want to initially train only the randomly generated new layers so that that one or two layers we put on the end train them first and so by default that's what happens when you create a pre-trained model in fast AI is actually all of the layers except the randomly the randomly generated ones start out frozen so that's why we didn't have to say learn dot freeze because it assumes that's what you want okay any quest any more questions about the first half of this class so I apologize for attempting to cover vast swaths of computer vision and deep learning in one hour but that's because there's good materials you can use to learn them properly so a couple of years ago I started I really didn't have any NLP background myself and kind of I guess this is on the tenacity theme I started wondering about what would happen if we use these same techniques for NLP or are they being used for NLP and so I started going to meetups and conferences and finding famous NLP people and asking them you know is transfer learning super important to lots of people working on it is it used all the time and the answer was no no no and I'd say what do you think it's a good idea is there an opportunity here and the answer also was no no no NLP is special you can't use computer vision techniques in NLP we're our own thing you know go and learn proper NLP like a proper NLP person so it's always very dismaying when you try to kind of get into a new field and do something different because there are lots of people who have spent their whole lives in that field and they'll always be very dismissive of new people wanting to try new things so you just kind of have to ignore it so I ignored it just seemed like an obviously good idea to like the stuff I just described is not in any way specific to computer vision so I tried to think about like what was the equivalent of something like pets or something but for computer vision and the data set that I thought was the most interesting is this one called IMDB that you've already briefly looked at I think it's super interesting because the documents in IMDB are quite long they're like two thousand words one thousand two thousand words long they're the kinds of things that NLP researchers a couple of years ago was saying were too long to like do useful things with other than the simple bag of words stuff kind of naive base and stuff that Rachel's already taught you about really people at that time weren't doing much useful stuff with longer documents so it was a couple of attempts but very very little so it seemed like kind of a largely unsolved problem and so I just did the most dumb stupid obvious thing I could which was basically to do these steps but with NLP so I needed the equivalent of an image net pre-trained model but for NLP so I tried to think like what's the equivalent like what we need something that kind of understands English under some definition of understands it kind of needs a sense of like what grammar looks like and what words there are and which ones are kind of happy and sad words and kind of what words like not and don't mean and negatives and kind of try to get as much you know knowledge a bit of language as possible into a model and so I thought what would be a good way to do that and turned out one of my friends a guy called Stephen Meridy had recently been doing research on a kind of model called a language model and a language model is a model as you've learned which predicts the next word of a sentence or more generally the predicts the next word of a document and Stephen Meridy had got a new state-of-the-art result for language modeling so state-of-the-art means he had got a more accurate language model than anybody had built before and it didn't take particularly long time to train and it was you know so it's pretty efficient pretty accurate and I started thinking about it and I started thinking like in order to predict the next word of a sentence what would the model have to know what would it have to learn right so for example I went to the fair and I had a really delicious hot what probably a dog right oh I'm so sweaty it's a really hot probably a day not a dog right now so to be able to predict the next word of that sentence it's not enough just to know like n grams right because hot day and hot dog both come together right even kind of context would not be enough because you might well go to the fair on a hot day you might well have a hot dog on a hot day right you need to know what kinds of things people eat versus what kinds of things make people sweat for example right or even more tricky like a really important element of the financial crisis was the Dodd-Frank legislation signed into law by President blah right which means you need to know either like when was the financial crisis and who was president then or who was the president who signed the Dodd-Frank legislation into law right you actually need to know something about not just language but what's going on in the world and the concept of time and the concept of politicians right so I kind of realized a really really really good language model kind of needs to know a lot about the world and actually this is something that philosophers have been discussing for many many years there's a famous thought experiment called the Chinese room thought experiment from the philosophy of mind which is basically deals with the hypothesis that a any advanced enough language model is indistinguishable from intelligence so basically if something can like like if you know if the sequence if the thing to complete is the lot the prime factorization of this really large number is then to actually fix correct get that language model correctly you have to factor prime numbers for instance and particularly once you start not just predicting the next word but then you can say well predict the word after that pick the word after that pick the word after that so it turns out that if you use a lot of parameters and a lot of data to create a really good language model it's quite surprising what that can do and so you can start saying like don't just predict the next word but keep predicting the next word so a group called open AI I called Alec Radford in particular actually took the research that we had been doing on kind of single GPUs and said I wonder what would happen if you scaled that up massively and open AI kind of created the supercharged version of the same thing called GPT and this one is GPT 2 and so then they started saying what would happen if we just feed it text so they fed it so they trained it on you know a not insignificant subset of the web and then they trained it with they prompted it with in a shocking finding scientists discovered a herd of unicorns living in a remote previously unexplored valley in the Andes Mountains even more surprising to the researchers was the fact that the unicorn spoke perfect English so somebody wrote that person and then that was the input to a language model and the language model was this pre-trained GPT 2 model which had been pre-trained on for a very long time on a very large amount of data and the the next word the language model predicted was the and then they said okay predict the word after that that was scientist predict the next word after that it was named and ended up with this whole thing is made by a computer now the scientists named the population after their distinctive horn over its unicorn these four horns silver white unicorns were previously unknown to science dr. Jorge Perez an evolutionary biologist from the University of La Paz were exploring the Andes when they found a small valley Perez noticed the valley had what appeared to be a natural fountain Perez and the others ventured further into the valley by the time we reached the top the water looked blue they were astonished to see the unicorn herd these creatures could be seen from the air they were so close they could touch their horns they discovered that the creatures also spoke some fairly regular English so oh well this while the unicorns still unclear some believe perhaps the creatures were created what a unicorn and a human and a unicorn met each other at a time before human civilization in South America such incidents seem to be quite common so you can see that a language model like to understand the capabilities of a large neural network trained on a large amount of data you kind of have to rethink your understanding of what a mathematical function can do this is a mathematical function right and this mathematical function has been trained to do nothing other than fill in the next word of a sentence but it's done it for a lot of sentences right and it has I think like I can't quite remember but hundreds of millions or billions of parameters to two number of parameters see area yeah that's right I think it's so they've released the 345 million parameter version and the version I showed you is 1.5 billion so the yeah so with a with over a billion parameters and the extraordinary amount of data you you know our intuitions about what you can learn just by learning to predict the next word of a sentence the intuitions not going to be right okay you have to kind of think of it at the foundations and realize that a language model if it's good has to learn a lot of things like like if you think about it that last one needed to know where lapas is for example because then the generated text talked about well it used academics named Paul gay Perez that would be associate which be associated with that area and it talked about the Andes Mountains which are associated with that area and they picked a university in that area so it's it's really amazing what a language model ends up being able to develop so when I created you 11 feet it was before all this had happened but it was clear that from first principles a good language model such as the kind of thing that Stephen Merrity had recently been building ought to know quite a lot about language and about the world and so I decided to use that as my image net version tree train pre train model so from there one of the nice things about a language model is we don't need any label data which is super great right so you could create a fan you know the equivalent of GPT-2 but for medical texts by training on you know PubMed or medical journals or whatever so in my case I just created a language model from Wikipedia because based on what we know from computer vision it didn't seem to matter too much like in computer vision what kind of images you pre train on so my guess was it wouldn't matter too much what kind of texts they pre train on so in in fast AI if you go to docs dot fast AI you can find applications text and one of the really nice things about fast AI is that the documentation is full of tutorials and all of the documentation is actually built directly out of Jupiter notebooks and so you can actually open the Jupiter notebooks and so what I've done is I've copied one of the Jupiter notebooks out of the fast AI repo and saved it into our course as review NLP transfer and I kind of deleted some of it just to make it a bit smaller but here's the entire process copied straight from the fast AI docs for doing transfer learning for text as the the the lines of code are nearly identical to what you saw in the computer vision one but instead of untar data urls dot pets we've got untar data urls dot imdb and in this case I'm using a sample one of the most important workflow tricks for people doing machine learning is to do 99% of your work on 1% of your data take a really small amount at random and do nearly all of your work on that you should at least be able to overfit to a training set really well on a tiny amount of data you can do lots of experiments in a tiny amount of data so one of the things that we have in fast AI is is sample sized versions of pretty much all of our data sets and so when you start working with a new data set that that's always the first thing I do is to create a smallish random subset so we're going to start with a smallish random subset of IMDB and you can see it's basically got the film reviews and that is valid but now so that's just in a data frame so we can actually we didn't have to read the data frame we can just directly go text language model data bunch from CSP passing the CSP and we can then start using it for larger corpuses this step will take a few minutes so it can be useful to save the kind of pre tokenized numericalized version as Rachel said this this one's actually so small it's not really that necessary so we have a smaller batch size of smaller GPUs so we load in our IMDB texts and we say do it both in language model form and in classifier form and then we create a language model learner now this step it's actually optional but remember I told you the language model I created was trained on Wikipedia right so what we could do is we could take that Wikipedia language model and just directly create a text classifier and load in the pre trained Wikipedia model and then we could start fitting and that would actually that actually works okay that would be the equivalent of the computer vision version but in LP transfer learning is even better because what we can do is whatever we were going to use for classification like in this case movie reviews we can actually fine-tune the language model specifically so it's good at predicting the next word of a movie review so here when we say language model learner by default again pre trained is true and it knows that the language model that it wants to use by default is a Wikipedia language model so it starts with something that's learned to predict the next word of Wikipedia well right but then we're passing in our movie reviews so now when we say fit it fine-tunes the random you know the new randomly created weights which in this case are the word embeddings that aren't in the vocab and it starts training those right and so then just like we did before for vision you then go unfreeze and then you fit some more with discriminative learning rates so as you can see the code is identical and so what we end up with is a language model that's not just good at predicting the next word of the encyclopedia but it's good at predicting the next word of a movie review and therefore it needs to know something about like who are actors and who are actresses and which ones are popular and which ones aren't and what kinds of words do people use when they're excited about a movie versus not and so forth so what we can then do is we can then create a text classifier and having saved the fine-tuned IMDB model we can load that into the classifier and so use that right so we now have the language model with a set of random weights on top with two activations because we have negative or positive movie reviews and now we can fit that and then we can unfreeze and then we can fit some more so if we remove the descriptive stuff okay so the actual amount of code we needed was tell it where the path is create the language model and classifier data bunches fit the language model fine-tune the language model save the language model create the classifier load the pre-trained weights into it fit the classifier fine-tune the classifier okay so there's actually maybe a dozen lines of code required and the lines of code are almost identical to the vision ones as I was going through this I was kind of interested in things like so what are the kind of the nice things about using a higher level framework like fast AI is you can do things super quickly you can understand the concepts but then it's important that you know how to dig into the details so one of the best ways to do that is to read the source code I mean obviously at least read the documentation but then also read the source code so the documentation you just type doc as Rachel mentioned gives you the brief version but more importantly if you click show in docs then you'll get the full details including links to the papers that are being implemented and sample code that you can run and so forth so that's doc that only works with fast AI the equivalent for normal Python is help but it has a lot less information but what you can do for anything in Python in Jupiter is put two question marks and then you'll get the source code okay and so if we want to know what exactly what is get language what language model learning doing then we can create the source code now in this case I was interested in thinking like well how does it deal with the fact that the vocab for Wikipedia is different for the vocab to IMDB and so Rachel told you about how that happens in the last course so I was thinking well where does that happen so I saw that language model learner call something called load pre-trained so I thought oh okay well let's look at load pre-trained so here's the definition of load pre-trained that calls something called convert weights so that must be the thing that actually converts the vocab so here's convert weights and so here's the algorithm that Rachel was talking about which takes the that random randomly initializes words that are in the IMDB vocab that weren't in the Wikipedia vocab as you can see once you start kind of trying to dig through multiple layers of code in Jupiter notebooks it gets a little bit unwieldy so in terms of like tools which are useful to know one that I strongly recommend is visual studio code and that makes it really easy to dig through code like what I just described and in particular a new thing that just came out a couple of weeks ago is something called VS code remote development because both probably at USF for your anytime you're using a GPU here and most likely in your workplace after you're finished with your course you'll spend nearly all of your time working on a remote server that's the reality of most particularly deep learning based development which is increasingly what most machine learning is since we need to use high quality GPUs which aren't normally in laptops and also you need to use the data in the organization which is unlikely to be sitting on your laptop so one approach to this is to work remotely work remotely through something like Vim which is actually a great approach to doing it so if I was using Vim the way I would have done this what I would have been said okay language model learner is what I want to know about so in Vim there's these things called tags so you can go tag and you can start typing language and then you can hit tab and it'll find any symbols that start with language and it'll take you straight to their definition in the code and I could start reading through and I'd say oh load pre-trained that looks interesting and then you hit control right square bracket and that would take you straight to the definition of that convert weights okay right square bracket takes you straight to the definition of that so you can certainly do all this stuff in Vim it works super well control t to go back to where I was and so forth but perhaps a easier choice nowadays particularly with this new remote development system is Visual Studio Code where you can do the same thing in Visual Studio Code like so basically you can say file open folder after connecting to your SSH machine and you'll literally see this is my this is the directory of the box I have SSH'd into you can see here home jhoward git fastai ls-home slash jhoward git so it's actually showing me the contents of my remote machine right and so then I've opened up that directory on my remote machine and so I can for example I could go straight to I can start typing length so control t and then start typing language and hit enter and it takes me straight to the code and so I can do things like oh load pre-trained I could just wave my mouse over it and it'll pop up a definition or I can hit control and click on it and it'll take me straight there I'll convert weights well that sounds interesting control click on it take me straight there I want to go back I can hit the back button on my mouse or I can hit alt left either will take me back to where I was before or it's like oh what else what else uses load pre-trained so I can find everything that uses it by hitting alt shift f12 and so here all now I can jump to every part of the code that calls that method or I can open up the sidebar and I can immediately see here's all of the methods that are defined in this class and I could jump straight to any of them and so forth so Visual Studio code is a really nice way of jumping around through a code base and getting to understand it and now that you can use it on an SSH machine just as easily as you can on your own machine it's to me it's the clear clear winner for wanting to understand what's going on and it works particularly well when combined with things like fast AI which are going to design to give you this very layered API where you can understand just the top layer and then gradually go down down down to the pie torch underneath so that was review CV transfer and review NLP transfer so in both cases we start out with a pre-trained model we fine-tune it well we first of all we train the new randomly out of weights and then we find you in the whole thing with discriminative learning rates and for NLP there was one other optional step which is a really good idea which is to fine-tune the language model before you fine-tune the classifier I'm not sure if Rachel's going to get into it in this course or not but there is one other key difference which is for vision we normally use convolutional neural networks which are already familiar with but for language we normally use either a recurrent neural network or a transformer and I know Rachel's going to be teaching about transformers later in the course I don't know if she's going to do RNNs or not but as you can see as a kind of a practitioner you don't have to care too much about that difference it's it's not really that important right to me it's just like I don't know I'm called using the sine function or the tan function on my computer I don't really care how it's implemented or exactly those minor details it's just a part of the toolkit that I use unless you're doing research into architectures and stuff in which case obviously you need to know those details so so finally coming back to 5NNIMDB this is what Rachel started going through in the last lesson this is just really showing you in a much slower step-by-step process all of those all of those steps right and particularly understanding this idea that there's a vocabulary and that that vocabulary will differ when you use a new corpus and you're fine-tuning is super important but I trained this model for a while and so first of all fine-tuned I fine-tuned the language model then I loaded that into a classifier and fine-tuned the classifier and here it is here we are lower encoder and so I just gave it so once you've fine-tuned the language model the classifier generally you can train pretty quickly so it took me about a minute to fine-tune the to train the newly added weights so that was after freezing and then I unfroze and train for another two or three minutes per epoch or for epochs and the accuracy I got was 94.1% so this is on a single GPU training for not very long and to give you a sense of like what does that mean I checked up the literature and before you will answer this this transfer learning approach is called ULM fit that's a paper we released a couple of years ago before we released this paper 94.1 was the best result that had ever been achieved for this data set right so this process is not showing you like an okay way to kind of get by it NLP this is literally matching what before this was the best result anybody had gotten and it's super easy to get quite a bit better than this we got to 95% plus just training a little bit longer and doing a reverse model and stuff as well and like even the the language model although it's like nothing nearly as big or trained as long or with as much data as GPT-2 it's still making perfectly adequate text generation as you can see okay so I think that's all I wanted to cover today definitely encourage people to get involved in the NLP community this idea of transfer learning and fine-tuning for NLP is super super new nobody had heard of it until I don't know a couple of years ago it's people are vaguely aware of it now because the open AI work got a lot of publicity but even that people are very focused on the actual language model itself the text generation not many people have noticed that that's just a side effect and what actually matters is that we can create replace the language modeling layer with a classifier or a sequence label or a translator or whatever and like pretty much instantly get state-of-the-art results on almost any NLP task you can come across so you know in terms of thinking like what do you do next post-university for those of you through in the USF course there's this wide open opportunity to take like anywhere you see people analyzing text or or gathering text as part of their business model there's an opportunity to do that far far better well for areas where people are currently manually reading and processing text you can quite likely automate that now so we're kind of in one of these really nice little periods of time between like technology invented here and technology used everywhere there and that bit in the middle is the bit where people like you can go and create new businesses and products and stuff like that which didn't exist before and so it's a really good really good time to do that or if you're looking to join an existing startup looking for startups that are taking advantage of NLP transfer learning to do something that was previously not done at all or was done badly would be a great opportunity as well okay so anybody have any questions before we wrap up okay thanks everybody and next time we'll be back with Rachel", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.16, "text": " When Rachel and I talked over, you know, what what should she cover in this year's NLP course?", "tokens": [1133, 14246, 293, 286, 2825, 670, 11, 291, 458, 11, 437, 437, 820, 750, 2060, 294, 341, 1064, 311, 426, 45196, 1164, 30], "temperature": 0.0, "avg_logprob": -0.13205716750201058, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0480937734246254}, {"id": 1, "seek": 0, "start": 8.16, "end": 13.32, "text": " Because neither of us has taught an explicitly NLP course before we found ourselves in a", "tokens": [1436, 9662, 295, 505, 575, 5928, 364, 20803, 426, 45196, 1164, 949, 321, 1352, 4175, 294, 257], "temperature": 0.0, "avg_logprob": -0.13205716750201058, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0480937734246254}, {"id": 2, "seek": 0, "start": 13.32, "end": 19.38, "text": " slightly awkward situation in which that there's a bit of a mismatch between what would university", "tokens": [4748, 11411, 2590, 294, 597, 300, 456, 311, 257, 857, 295, 257, 23220, 852, 1296, 437, 576, 5454], "temperature": 0.0, "avg_logprob": -0.13205716750201058, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0480937734246254}, {"id": 3, "seek": 0, "start": 19.38, "end": 26.96, "text": " students generally be expected to have learned having done an NLP course versus what do we", "tokens": [1731, 5101, 312, 5176, 281, 362, 3264, 1419, 1096, 364, 426, 45196, 1164, 5717, 437, 360, 321], "temperature": 0.0, "avg_logprob": -0.13205716750201058, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0480937734246254}, {"id": 4, "seek": 2696, "start": 26.96, "end": 32.46, "text": " actually think is useful because what's happened as she said is that this field's undergone", "tokens": [767, 519, 307, 4420, 570, 437, 311, 2011, 382, 750, 848, 307, 300, 341, 2519, 311, 833, 39743], "temperature": 0.0, "avg_logprob": -0.10790543383862598, "compression_ratio": 1.634703196347032, "no_speech_prob": 5.56027953280136e-05}, {"id": 5, "seek": 2696, "start": 32.46, "end": 39.94, "text": " a lot of change in the last few years and that means that when you interview for jobs", "tokens": [257, 688, 295, 1319, 294, 264, 1036, 1326, 924, 293, 300, 1355, 300, 562, 291, 4049, 337, 4782], "temperature": 0.0, "avg_logprob": -0.10790543383862598, "compression_ratio": 1.634703196347032, "no_speech_prob": 5.56027953280136e-05}, {"id": 6, "seek": 2696, "start": 39.94, "end": 44.120000000000005, "text": " you're likely to be asked questions that in fact most of the time if you're being asked", "tokens": [291, 434, 3700, 281, 312, 2351, 1651, 300, 294, 1186, 881, 295, 264, 565, 498, 291, 434, 885, 2351], "temperature": 0.0, "avg_logprob": -0.10790543383862598, "compression_ratio": 1.634703196347032, "no_speech_prob": 5.56027953280136e-05}, {"id": 7, "seek": 2696, "start": 44.120000000000005, "end": 51.1, "text": " questions by a senior person about NLP they won't be very familiar with actually the current", "tokens": [1651, 538, 257, 7965, 954, 466, 426, 45196, 436, 1582, 380, 312, 588, 4963, 365, 767, 264, 2190], "temperature": 0.0, "avg_logprob": -0.10790543383862598, "compression_ratio": 1.634703196347032, "no_speech_prob": 5.56027953280136e-05}, {"id": 8, "seek": 5110, "start": 51.1, "end": 57.0, "text": " techniques because they went to university and most people after they've gone to university", "tokens": [7512, 570, 436, 1437, 281, 5454, 293, 881, 561, 934, 436, 600, 2780, 281, 5454], "temperature": 0.0, "avg_logprob": -0.07571945786476135, "compression_ratio": 1.6, "no_speech_prob": 2.4298058633576147e-05}, {"id": 9, "seek": 5110, "start": 57.0, "end": 64.64, "text": " don't necessarily keep up so we do think it's important that you understand a broader kind", "tokens": [500, 380, 4725, 1066, 493, 370, 321, 360, 519, 309, 311, 1021, 300, 291, 1223, 257, 13227, 733], "temperature": 0.0, "avg_logprob": -0.07571945786476135, "compression_ratio": 1.6, "no_speech_prob": 2.4298058633576147e-05}, {"id": 10, "seek": 5110, "start": 64.64, "end": 71.76, "text": " of spectrum of what NLP is being generally considered to be so that's why you've looked", "tokens": [295, 11143, 295, 437, 426, 45196, 307, 885, 5101, 4888, 281, 312, 370, 300, 311, 983, 291, 600, 2956], "temperature": 0.0, "avg_logprob": -0.07571945786476135, "compression_ratio": 1.6, "no_speech_prob": 2.4298058633576147e-05}, {"id": 11, "seek": 5110, "start": 71.76, "end": 79.0, "text": " at things like limitization and stop words stuff even though it never comes up I've never", "tokens": [412, 721, 411, 4948, 2144, 293, 1590, 2283, 1507, 754, 1673, 309, 1128, 1487, 493, 286, 600, 1128], "temperature": 0.0, "avg_logprob": -0.07571945786476135, "compression_ratio": 1.6, "no_speech_prob": 2.4298058633576147e-05}, {"id": 12, "seek": 7900, "start": 79.0, "end": 84.08, "text": " used either of those things I mean at least if you don't I've tried using them it's always", "tokens": [1143, 2139, 295, 729, 721, 286, 914, 412, 1935, 498, 291, 500, 380, 286, 600, 3031, 1228, 552, 309, 311, 1009], "temperature": 0.0, "avg_logprob": -0.10286209370830271, "compression_ratio": 1.7290076335877862, "no_speech_prob": 1.0615523024171125e-05}, {"id": 13, "seek": 7900, "start": 84.08, "end": 90.8, "text": " worked better without them so I thought one thing I might briefly touch on is putting", "tokens": [2732, 1101, 1553, 552, 370, 286, 1194, 472, 551, 286, 1062, 10515, 2557, 322, 307, 3372], "temperature": 0.0, "avg_logprob": -0.10286209370830271, "compression_ratio": 1.7290076335877862, "no_speech_prob": 1.0615523024171125e-05}, {"id": 14, "seek": 7900, "start": 90.8, "end": 97.0, "text": " aside there what might you need to get interviews for a job or pass an exam what are the things", "tokens": [7359, 456, 437, 1062, 291, 643, 281, 483, 12318, 337, 257, 1691, 420, 1320, 364, 1139, 437, 366, 264, 721], "temperature": 0.0, "avg_logprob": -0.10286209370830271, "compression_ratio": 1.7290076335877862, "no_speech_prob": 1.0615523024171125e-05}, {"id": 15, "seek": 7900, "start": 97.0, "end": 104.08, "text": " that I personally have found extremely extremely useful that you've covered in this course", "tokens": [300, 286, 5665, 362, 1352, 4664, 4664, 4420, 300, 291, 600, 5343, 294, 341, 1164], "temperature": 0.0, "avg_logprob": -0.10286209370830271, "compression_ratio": 1.7290076335877862, "no_speech_prob": 1.0615523024171125e-05}, {"id": 16, "seek": 7900, "start": 104.08, "end": 108.2, "text": " so that you can kind of know the difference between what you definitely want to take away", "tokens": [370, 300, 291, 393, 733, 295, 458, 264, 2649, 1296, 437, 291, 2138, 528, 281, 747, 1314], "temperature": 0.0, "avg_logprob": -0.10286209370830271, "compression_ratio": 1.7290076335877862, "no_speech_prob": 1.0615523024171125e-05}, {"id": 17, "seek": 10820, "start": 108.2, "end": 114.68, "text": " as part of your toolkit versus what you need to know to pass an exam or pass a job interview", "tokens": [382, 644, 295, 428, 40167, 5717, 437, 291, 643, 281, 458, 281, 1320, 364, 1139, 420, 1320, 257, 1691, 4049], "temperature": 0.0, "avg_logprob": -0.09305788546192403, "compression_ratio": 1.7967479674796747, "no_speech_prob": 7.527630714321276e-06}, {"id": 18, "seek": 10820, "start": 114.68, "end": 120.24000000000001, "text": " so looking through the notebooks you've covered so far the one that stands out to me the most", "tokens": [370, 1237, 807, 264, 43782, 291, 600, 5343, 370, 1400, 264, 472, 300, 7382, 484, 281, 385, 264, 881], "temperature": 0.0, "avg_logprob": -0.09305788546192403, "compression_ratio": 1.7967479674796747, "no_speech_prob": 7.527630714321276e-06}, {"id": 19, "seek": 10820, "start": 120.24000000000001, "end": 125.08, "text": " is regular expressions and it also stands out to me that when Rachel asked who feels", "tokens": [307, 3890, 15277, 293, 309, 611, 7382, 484, 281, 385, 300, 562, 14246, 2351, 567, 3417], "temperature": 0.0, "avg_logprob": -0.09305788546192403, "compression_ratio": 1.7967479674796747, "no_speech_prob": 7.527630714321276e-06}, {"id": 20, "seek": 10820, "start": 125.08, "end": 130.32, "text": " very comfortable with regular expressions I was very surprised by how few hands went", "tokens": [588, 4619, 365, 3890, 15277, 286, 390, 588, 6100, 538, 577, 1326, 2377, 1437], "temperature": 0.0, "avg_logprob": -0.09305788546192403, "compression_ratio": 1.7967479674796747, "no_speech_prob": 7.527630714321276e-06}, {"id": 21, "seek": 10820, "start": 130.32, "end": 136.56, "text": " up not as a criticism but just to say like I use regular expressions many times every", "tokens": [493, 406, 382, 257, 15835, 457, 445, 281, 584, 411, 286, 764, 3890, 15277, 867, 1413, 633], "temperature": 0.0, "avg_logprob": -0.09305788546192403, "compression_ratio": 1.7967479674796747, "no_speech_prob": 7.527630714321276e-06}, {"id": 22, "seek": 13656, "start": 136.56, "end": 145.76, "text": " day to do things in my code editor to gather data to like everything almost that involves", "tokens": [786, 281, 360, 721, 294, 452, 3089, 9839, 281, 5448, 1412, 281, 411, 1203, 1920, 300, 11626], "temperature": 0.0, "avg_logprob": -0.08176842331886292, "compression_ratio": 1.714975845410628, "no_speech_prob": 3.0715975299244747e-05}, {"id": 23, "seek": 13656, "start": 145.76, "end": 155.4, "text": " anything involving file names or data gathering or data managing or whatever always I use", "tokens": [1340, 17030, 3991, 5288, 420, 1412, 13519, 420, 1412, 11642, 420, 2035, 1009, 286, 764], "temperature": 0.0, "avg_logprob": -0.08176842331886292, "compression_ratio": 1.714975845410628, "no_speech_prob": 3.0715975299244747e-05}, {"id": 24, "seek": 13656, "start": 155.4, "end": 159.68, "text": " regular expressions so the fact that a lot of you aren't familiar with it makes me think", "tokens": [3890, 15277, 370, 264, 1186, 300, 257, 688, 295, 291, 3212, 380, 4963, 365, 309, 1669, 385, 519], "temperature": 0.0, "avg_logprob": -0.08176842331886292, "compression_ratio": 1.714975845410628, "no_speech_prob": 3.0715975299244747e-05}, {"id": 25, "seek": 13656, "start": 159.68, "end": 166.36, "text": " you're not taking advantage of a tool that's in your toolbox so I would say of all the", "tokens": [291, 434, 406, 1940, 5002, 295, 257, 2290, 300, 311, 294, 428, 44593, 370, 286, 576, 584, 295, 439, 264], "temperature": 0.0, "avg_logprob": -0.08176842331886292, "compression_ratio": 1.714975845410628, "no_speech_prob": 3.0715975299244747e-05}, {"id": 26, "seek": 16636, "start": 166.36, "end": 172.36, "text": " things to take away that would be the one the one at the top of my list so I thought", "tokens": [721, 281, 747, 1314, 300, 576, 312, 264, 472, 264, 472, 412, 264, 1192, 295, 452, 1329, 370, 286, 1194], "temperature": 0.0, "avg_logprob": -0.1197396993637085, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3006750123167876e-05}, {"id": 27, "seek": 16636, "start": 172.36, "end": 180.16000000000003, "text": " I'd give you a quick example of what a workflow might look like involving regular expressions", "tokens": [286, 1116, 976, 291, 257, 1702, 1365, 295, 437, 257, 20993, 1062, 574, 411, 17030, 3890, 15277], "temperature": 0.0, "avg_logprob": -0.1197396993637085, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3006750123167876e-05}, {"id": 28, "seek": 16636, "start": 180.16000000000003, "end": 188.44000000000003, "text": " most editors support regular expressions deeply I happen to use an editor called Vim which", "tokens": [881, 31446, 1406, 3890, 15277, 8760, 286, 1051, 281, 764, 364, 9839, 1219, 691, 332, 597], "temperature": 0.0, "avg_logprob": -0.1197396993637085, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3006750123167876e-05}, {"id": 29, "seek": 16636, "start": 188.44000000000003, "end": 194.16000000000003, "text": " I quite like I think it's particularly good for data science but this these ideas will", "tokens": [286, 1596, 411, 286, 519, 309, 311, 4098, 665, 337, 1412, 3497, 457, 341, 613, 3487, 486], "temperature": 0.0, "avg_logprob": -0.1197396993637085, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3006750123167876e-05}, {"id": 30, "seek": 19416, "start": 194.16, "end": 200.8, "text": " hold across many editors and just before the class started I just downloaded a data set", "tokens": [1797, 2108, 867, 31446, 293, 445, 949, 264, 1508, 1409, 286, 445, 21748, 257, 1412, 992], "temperature": 0.0, "avg_logprob": -0.11911165873209635, "compression_ratio": 1.6540284360189574, "no_speech_prob": 1.4284716598922387e-05}, {"id": 31, "seek": 19416, "start": 200.8, "end": 205.51999999999998, "text": " containing some addresses and phone numbers and things and I thought like maybe I'll show", "tokens": [19273, 512, 16862, 293, 2593, 3547, 293, 721, 293, 286, 1194, 411, 1310, 286, 603, 855], "temperature": 0.0, "avg_logprob": -0.11911165873209635, "compression_ratio": 1.6540284360189574, "no_speech_prob": 1.4284716598922387e-05}, {"id": 32, "seek": 19416, "start": 205.51999999999998, "end": 211.35999999999999, "text": " you how I go about cleaning up a data set so this particular data set apparently is", "tokens": [291, 577, 286, 352, 466, 8924, 493, 257, 1412, 992, 370, 341, 1729, 1412, 992, 7970, 307], "temperature": 0.0, "avg_logprob": -0.11911165873209635, "compression_ratio": 1.6540284360189574, "no_speech_prob": 1.4284716598922387e-05}, {"id": 33, "seek": 19416, "start": 211.35999999999999, "end": 217.84, "text": " Austin public health locations which I just downloaded from data.gov and I was thinking", "tokens": [15356, 1908, 1585, 9253, 597, 286, 445, 21748, 490, 1412, 13, 16089, 293, 286, 390, 1953], "temperature": 0.0, "avg_logprob": -0.11911165873209635, "compression_ratio": 1.6540284360189574, "no_speech_prob": 1.4284716598922387e-05}, {"id": 34, "seek": 21784, "start": 217.84, "end": 224.16, "text": " how would I answer the question what are all of the phone numbers of Austin public health", "tokens": [577, 576, 286, 1867, 264, 1168, 437, 366, 439, 295, 264, 2593, 3547, 295, 15356, 1908, 1585], "temperature": 0.0, "avg_logprob": -0.12891471183906167, "compression_ratio": 1.881118881118881, "no_speech_prob": 1.1300088772259187e-05}, {"id": 35, "seek": 21784, "start": 224.16, "end": 232.96, "text": " locations and I need you to provide them to us in a particular format which is in a particular", "tokens": [9253, 293, 286, 643, 291, 281, 2893, 552, 281, 505, 294, 257, 1729, 7877, 597, 307, 294, 257, 1729], "temperature": 0.0, "avg_logprob": -0.12891471183906167, "compression_ratio": 1.881118881118881, "no_speech_prob": 1.1300088772259187e-05}, {"id": 36, "seek": 21784, "start": 232.96, "end": 242.8, "text": " format which is say like digit digit digit space digit digit digit space digit digit", "tokens": [7877, 597, 307, 584, 411, 14293, 14293, 14293, 1901, 14293, 14293, 14293, 1901, 14293, 14293], "temperature": 0.0, "avg_logprob": -0.12891471183906167, "compression_ratio": 1.881118881118881, "no_speech_prob": 1.1300088772259187e-05}, {"id": 37, "seek": 24280, "start": 242.8, "end": 249.72, "text": " digit something like that right so how would you go about doing that from this data set", "tokens": [14293, 746, 411, 300, 558, 370, 577, 576, 291, 352, 466, 884, 300, 490, 341, 1412, 992], "temperature": 0.0, "avg_logprob": -0.0736512352438534, "compression_ratio": 1.76, "no_speech_prob": 5.862640136911068e-06}, {"id": 38, "seek": 24280, "start": 249.72, "end": 253.72, "text": " this is the kind of thing that's going to come up all the time so the first thing I", "tokens": [341, 307, 264, 733, 295, 551, 300, 311, 516, 281, 808, 493, 439, 264, 565, 370, 264, 700, 551, 286], "temperature": 0.0, "avg_logprob": -0.0736512352438534, "compression_ratio": 1.76, "no_speech_prob": 5.862640136911068e-06}, {"id": 39, "seek": 24280, "start": 253.72, "end": 266.52, "text": " would do would be to select all of the rows in this text file that contain a phone number", "tokens": [576, 360, 576, 312, 281, 3048, 439, 295, 264, 13241, 294, 341, 2487, 3991, 300, 5304, 257, 2593, 1230], "temperature": 0.0, "avg_logprob": -0.0736512352438534, "compression_ratio": 1.76, "no_speech_prob": 5.862640136911068e-06}, {"id": 40, "seek": 24280, "start": 266.52, "end": 271.72, "text": " and so I would tend to be a bit cautious about guessing what a phone number is but looking", "tokens": [293, 370, 286, 576, 3928, 281, 312, 257, 857, 25278, 466, 17939, 437, 257, 2593, 1230, 307, 457, 1237], "temperature": 0.0, "avg_logprob": -0.0736512352438534, "compression_ratio": 1.76, "no_speech_prob": 5.862640136911068e-06}, {"id": 41, "seek": 27172, "start": 271.72, "end": 277.8, "text": " through here it looks like the phone numbers are generally digit dash digit dash digit", "tokens": [807, 510, 309, 1542, 411, 264, 2593, 3547, 366, 5101, 14293, 8240, 14293, 8240, 14293], "temperature": 0.0, "avg_logprob": -0.12847548325856525, "compression_ratio": 1.5828220858895705, "no_speech_prob": 1.9832796169794165e-05}, {"id": 42, "seek": 27172, "start": 277.8, "end": 286.20000000000005, "text": " so Vim has a really nice way to find lines containing a regular expression which is G", "tokens": [370, 691, 332, 575, 257, 534, 1481, 636, 281, 915, 3876, 19273, 257, 3890, 6114, 597, 307, 460], "temperature": 0.0, "avg_logprob": -0.12847548325856525, "compression_ratio": 1.5828220858895705, "no_speech_prob": 1.9832796169794165e-05}, {"id": 43, "seek": 27172, "start": 286.20000000000005, "end": 291.88000000000005, "text": " G stands for grep grep is the normal unix command for finding stuff and generally the", "tokens": [460, 7382, 337, 6066, 79, 6066, 79, 307, 264, 2710, 517, 970, 5622, 337, 5006, 1507, 293, 5101, 264], "temperature": 0.0, "avg_logprob": -0.12847548325856525, "compression_ratio": 1.5828220858895705, "no_speech_prob": 1.9832796169794165e-05}, {"id": 44, "seek": 29188, "start": 291.88, "end": 302.44, "text": " arguments to commands in Vim have slashes around have slashes around them so I'm going", "tokens": [12869, 281, 16901, 294, 691, 332, 362, 1061, 12808, 926, 362, 1061, 12808, 926, 552, 370, 286, 478, 516], "temperature": 0.0, "avg_logprob": -0.0862645497397771, "compression_ratio": 1.8013698630136987, "no_speech_prob": 1.3006866538489703e-05}, {"id": 45, "seek": 29188, "start": 302.44, "end": 313.76, "text": " to search for phone numbers alright so I guess we could say phone numbers is a digit you", "tokens": [281, 3164, 337, 2593, 3547, 5845, 370, 286, 2041, 321, 727, 584, 2593, 3547, 307, 257, 14293, 291], "temperature": 0.0, "avg_logprob": -0.0862645497397771, "compression_ratio": 1.8013698630136987, "no_speech_prob": 1.3006866538489703e-05}, {"id": 46, "seek": 29188, "start": 313.76, "end": 320.32, "text": " know one or more digits followed by a hyphen followed by one or more digits followed by", "tokens": [458, 472, 420, 544, 27011, 6263, 538, 257, 2477, 47059, 6263, 538, 472, 420, 544, 27011, 6263, 538], "temperature": 0.0, "avg_logprob": -0.0862645497397771, "compression_ratio": 1.8013698630136987, "no_speech_prob": 1.3006866538489703e-05}, {"id": 47, "seek": 32032, "start": 320.32, "end": 327.04, "text": " a hyphen followed by one or more digits and one of the things to notice is that every", "tokens": [257, 2477, 47059, 6263, 538, 472, 420, 544, 27011, 293, 472, 295, 264, 721, 281, 3449, 307, 300, 633], "temperature": 0.0, "avg_logprob": -0.12108184764911602, "compression_ratio": 1.6904761904761905, "no_speech_prob": 4.289258413336938e-06}, {"id": 48, "seek": 32032, "start": 327.04, "end": 334.44, "text": " program library programming language has slightly different regular expressions Vim's particular", "tokens": [1461, 6405, 9410, 2856, 575, 4748, 819, 3890, 15277, 691, 332, 311, 1729], "temperature": 0.0, "avg_logprob": -0.12108184764911602, "compression_ratio": 1.6904761904761905, "no_speech_prob": 4.289258413336938e-06}, {"id": 49, "seek": 32032, "start": 334.44, "end": 339.8, "text": " oddity is that they require backslashes in more places most regular expressions don't", "tokens": [7401, 507, 307, 300, 436, 3651, 646, 10418, 12808, 294, 544, 3190, 881, 3890, 15277, 500, 380], "temperature": 0.0, "avg_logprob": -0.12108184764911602, "compression_ratio": 1.6904761904761905, "no_speech_prob": 4.289258413336938e-06}, {"id": 50, "seek": 32032, "start": 339.8, "end": 348.6, "text": " need a backslash before the plus Vim does unless you change preference setting so this", "tokens": [643, 257, 646, 10418, 1299, 949, 264, 1804, 691, 332, 775, 5969, 291, 1319, 17502, 3287, 370, 341], "temperature": 0.0, "avg_logprob": -0.12108184764911602, "compression_ratio": 1.6904761904761905, "no_speech_prob": 4.289258413336938e-06}, {"id": 51, "seek": 34860, "start": 348.6, "end": 356.16, "text": " is going to go ahead and find all of the lines that match this regular expression and then", "tokens": [307, 516, 281, 352, 2286, 293, 915, 439, 295, 264, 3876, 300, 2995, 341, 3890, 6114, 293, 550], "temperature": 0.0, "avg_logprob": -0.0866110879321431, "compression_ratio": 1.7524752475247525, "no_speech_prob": 1.4970730262575671e-05}, {"id": 52, "seek": 34860, "start": 356.16, "end": 364.64000000000004, "text": " do what and this is really nice in Vim you can then provide another command to run on", "tokens": [360, 437, 293, 341, 307, 534, 1481, 294, 691, 332, 291, 393, 550, 2893, 1071, 5622, 281, 1190, 322], "temperature": 0.0, "avg_logprob": -0.0866110879321431, "compression_ratio": 1.7524752475247525, "no_speech_prob": 1.4970730262575671e-05}, {"id": 53, "seek": 34860, "start": 364.64000000000004, "end": 370.64000000000004, "text": " those so the command I want to run is delete which is D but actually I want to do all of", "tokens": [729, 370, 264, 5622, 286, 528, 281, 1190, 307, 12097, 597, 307, 413, 457, 767, 286, 528, 281, 360, 439, 295], "temperature": 0.0, "avg_logprob": -0.0866110879321431, "compression_ratio": 1.7524752475247525, "no_speech_prob": 1.4970730262575671e-05}, {"id": 54, "seek": 34860, "start": 370.64000000000004, "end": 377.68, "text": " the ones that don't match that so like many systems exclamation mark means not means the", "tokens": [264, 2306, 300, 500, 380, 2995, 300, 370, 411, 867, 3652, 1624, 43233, 1491, 1355, 406, 1355, 264], "temperature": 0.0, "avg_logprob": -0.0866110879321431, "compression_ratio": 1.7524752475247525, "no_speech_prob": 1.4970730262575671e-05}, {"id": 55, "seek": 37768, "start": 377.68, "end": 381.68, "text": " opposite so this is going to delete all the lines that don't match this regular expression", "tokens": [6182, 370, 341, 307, 516, 281, 12097, 439, 264, 3876, 300, 500, 380, 2995, 341, 3890, 6114], "temperature": 0.0, "avg_logprob": -0.08195863118985804, "compression_ratio": 1.7635467980295567, "no_speech_prob": 1.280521337321261e-05}, {"id": 56, "seek": 37768, "start": 381.68, "end": 391.16, "text": " done so it's just deleted 67 lines maybe it would be helpful actually if I just undo that", "tokens": [1096, 370, 309, 311, 445, 22981, 23879, 3876, 1310, 309, 576, 312, 4961, 767, 498, 286, 445, 23779, 300], "temperature": 0.0, "avg_logprob": -0.08195863118985804, "compression_ratio": 1.7635467980295567, "no_speech_prob": 1.280521337321261e-05}, {"id": 57, "seek": 37768, "start": 391.16, "end": 396.4, "text": " to do it without the exclamation mark to see what lines is it going to delete just to double", "tokens": [281, 360, 309, 1553, 264, 1624, 43233, 1491, 281, 536, 437, 3876, 307, 309, 516, 281, 12097, 445, 281, 3834], "temperature": 0.0, "avg_logprob": -0.08195863118985804, "compression_ratio": 1.7635467980295567, "no_speech_prob": 1.280521337321261e-05}, {"id": 58, "seek": 37768, "start": 396.4, "end": 402.12, "text": " check that this looks reasonable and that they don't have things that look like they", "tokens": [1520, 300, 341, 1542, 10585, 293, 300, 436, 500, 380, 362, 721, 300, 574, 411, 436], "temperature": 0.0, "avg_logprob": -0.08195863118985804, "compression_ratio": 1.7635467980295567, "no_speech_prob": 1.280521337321261e-05}, {"id": 59, "seek": 40212, "start": 402.12, "end": 408.84000000000003, "text": " might be phone numbers in them so that looks fine guess these are ones that don't have", "tokens": [1062, 312, 2593, 3547, 294, 552, 370, 300, 1542, 2489, 2041, 613, 366, 2306, 300, 500, 380, 362], "temperature": 0.0, "avg_logprob": -0.17578347069876535, "compression_ratio": 1.5705882352941176, "no_speech_prob": 1.2606473319465294e-05}, {"id": 60, "seek": 40212, "start": 408.84000000000003, "end": 414.72, "text": " phone numbers so part of my workflow is I tend to do a lot of undo redo as I play around", "tokens": [2593, 3547, 370, 644, 295, 452, 20993, 307, 286, 3928, 281, 360, 257, 688, 295, 23779, 29956, 382, 286, 862, 926], "temperature": 0.0, "avg_logprob": -0.17578347069876535, "compression_ratio": 1.5705882352941176, "no_speech_prob": 1.2606473319465294e-05}, {"id": 61, "seek": 40212, "start": 414.72, "end": 422.4, "text": " and Vim you is undo so I can just hit up arrow to go back to my previous command that I ran", "tokens": [293, 691, 332, 291, 307, 23779, 370, 286, 393, 445, 2045, 493, 11610, 281, 352, 646, 281, 452, 3894, 5622, 300, 286, 5872], "temperature": 0.0, "avg_logprob": -0.17578347069876535, "compression_ratio": 1.5705882352941176, "no_speech_prob": 1.2606473319465294e-05}, {"id": 62, "seek": 42240, "start": 422.4, "end": 434.02, "text": " and here I am so the second thing I want to do is find all of the phone numbers and maybe", "tokens": [293, 510, 286, 669, 370, 264, 1150, 551, 286, 528, 281, 360, 307, 915, 439, 295, 264, 2593, 3547, 293, 1310], "temperature": 0.0, "avg_logprob": -0.1309684585122501, "compression_ratio": 1.777027027027027, "no_speech_prob": 2.144356221833732e-05}, {"id": 63, "seek": 42240, "start": 434.02, "end": 436.96, "text": " I would probably do this in one step but to make it more clear I'll do it in two find", "tokens": [286, 576, 1391, 360, 341, 294, 472, 1823, 457, 281, 652, 309, 544, 1850, 286, 603, 360, 309, 294, 732, 915], "temperature": 0.0, "avg_logprob": -0.1309684585122501, "compression_ratio": 1.777027027027027, "no_speech_prob": 2.144356221833732e-05}, {"id": 64, "seek": 42240, "start": 436.96, "end": 444.08, "text": " all of the phone numbers and just make each line just the phone number so that would be", "tokens": [439, 295, 264, 2593, 3547, 293, 445, 652, 1184, 1622, 445, 264, 2593, 1230, 370, 300, 576, 312], "temperature": 0.0, "avg_logprob": -0.1309684585122501, "compression_ratio": 1.777027027027027, "no_speech_prob": 2.144356221833732e-05}, {"id": 65, "seek": 44408, "start": 444.08, "end": 454.91999999999996, "text": " one way to do that would be a search for a place so I could go search for digit and then", "tokens": [472, 636, 281, 360, 300, 576, 312, 257, 3164, 337, 257, 1081, 370, 286, 727, 352, 3164, 337, 14293, 293, 550], "temperature": 0.0, "avg_logprob": -0.1653636249143686, "compression_ratio": 1.7350993377483444, "no_speech_prob": 5.2247145504225045e-05}, {"id": 66, "seek": 44408, "start": 454.91999999999996, "end": 463.44, "text": " dash and then digit and then dash and then digits and then I want to replace it with", "tokens": [8240, 293, 550, 14293, 293, 550, 8240, 293, 550, 27011, 293, 550, 286, 528, 281, 7406, 309, 365], "temperature": 0.0, "avg_logprob": -0.1653636249143686, "compression_ratio": 1.7350993377483444, "no_speech_prob": 5.2247145504225045e-05}, {"id": 67, "seek": 44408, "start": 463.44, "end": 473.12, "text": " everything I just found which is the same as Python backslash one in fact since I didn't", "tokens": [1203, 286, 445, 1352, 597, 307, 264, 912, 382, 15329, 646, 10418, 1299, 472, 294, 1186, 1670, 286, 994, 380], "temperature": 0.0, "avg_logprob": -0.1653636249143686, "compression_ratio": 1.7350993377483444, "no_speech_prob": 5.2247145504225045e-05}, {"id": 68, "seek": 47312, "start": 473.12, "end": 480.88, "text": " put parentheses around it I can just say ampersand that means everything I just mentioned actually", "tokens": [829, 34153, 926, 309, 286, 393, 445, 584, 18648, 433, 474, 300, 1355, 1203, 286, 445, 2835, 767], "temperature": 0.0, "avg_logprob": -0.23168697076685288, "compression_ratio": 1.6428571428571428, "no_speech_prob": 7.721592555753887e-05}, {"id": 69, "seek": 47312, "start": 480.88, "end": 486.8, "text": " let's do it with backslash one so if you put parentheses and again with Vim it's a bit", "tokens": [718, 311, 360, 309, 365, 646, 10418, 1299, 472, 370, 498, 291, 829, 34153, 293, 797, 365, 691, 332, 309, 311, 257, 857], "temperature": 0.0, "avg_logprob": -0.23168697076685288, "compression_ratio": 1.6428571428571428, "no_speech_prob": 7.721592555753887e-05}, {"id": 70, "seek": 47312, "start": 486.8, "end": 494.28000000000003, "text": " weird you have to backslash the parentheses so I've got to capture the whole thing replace", "tokens": [3657, 291, 362, 281, 646, 10418, 1299, 264, 34153, 370, 286, 600, 658, 281, 7983, 264, 1379, 551, 7406], "temperature": 0.0, "avg_logprob": -0.23168697076685288, "compression_ratio": 1.6428571428571428, "no_speech_prob": 7.721592555753887e-05}, {"id": 71, "seek": 49428, "start": 494.28, "end": 505.2, "text": " it the line with that and then we're also going to need to say search for everything", "tokens": [309, 264, 1622, 365, 300, 293, 550, 321, 434, 611, 516, 281, 643, 281, 584, 3164, 337, 1203], "temperature": 0.0, "avg_logprob": -0.1225975581577846, "compression_ratio": 1.710344827586207, "no_speech_prob": 1.6441546904388815e-05}, {"id": 72, "seek": 49428, "start": 505.2, "end": 510.96, "text": " else in the line so arbitrary text and then something that might be a phone number and", "tokens": [1646, 294, 264, 1622, 370, 23211, 2487, 293, 550, 746, 300, 1062, 312, 257, 2593, 1230, 293], "temperature": 0.0, "avg_logprob": -0.1225975581577846, "compression_ratio": 1.710344827586207, "no_speech_prob": 1.6441546904388815e-05}, {"id": 73, "seek": 49428, "start": 510.96, "end": 523.1999999999999, "text": " then arbitrary text and replace it with just the contents in the parentheses", "tokens": [550, 23211, 2487, 293, 7406, 309, 365, 445, 264, 15768, 294, 264, 34153], "temperature": 0.0, "avg_logprob": -0.1225975581577846, "compression_ratio": 1.710344827586207, "no_speech_prob": 1.6441546904388815e-05}, {"id": 74, "seek": 52320, "start": 523.2, "end": 532.48, "text": " okay so that's not quite right as you can see because it's left me with what looks like", "tokens": [1392, 370, 300, 311, 406, 1596, 558, 382, 291, 393, 536, 570, 309, 311, 1411, 385, 365, 437, 1542, 411], "temperature": 0.0, "avg_logprob": -0.08583839043327, "compression_ratio": 1.6774193548387097, "no_speech_prob": 1.2411236639309209e-05}, {"id": 75, "seek": 52320, "start": 532.48, "end": 538.8000000000001, "text": " partial phone numbers so one of the nice things about like one of the things I'm really careful", "tokens": [14641, 2593, 3547, 370, 472, 295, 264, 1481, 721, 466, 411, 472, 295, 264, 721, 286, 478, 534, 5026], "temperature": 0.0, "avg_logprob": -0.08583839043327, "compression_ratio": 1.6774193548387097, "no_speech_prob": 1.2411236639309209e-05}, {"id": 76, "seek": 52320, "start": 538.8000000000001, "end": 544.5200000000001, "text": " to do in all of my work is to do things like very interactively so I would much rather", "tokens": [281, 360, 294, 439, 295, 452, 589, 307, 281, 360, 721, 411, 588, 4648, 3413, 370, 286, 576, 709, 2831], "temperature": 0.0, "avg_logprob": -0.08583839043327, "compression_ratio": 1.6774193548387097, "no_speech_prob": 1.2411236639309209e-05}, {"id": 77, "seek": 52320, "start": 544.5200000000001, "end": 552.08, "text": " work in Vim or a Jupyter notebook than write a program because I want to I want to be playing", "tokens": [589, 294, 691, 332, 420, 257, 22125, 88, 391, 21060, 813, 2464, 257, 1461, 570, 286, 528, 281, 286, 528, 281, 312, 2433], "temperature": 0.0, "avg_logprob": -0.08583839043327, "compression_ratio": 1.6774193548387097, "no_speech_prob": 1.2411236639309209e-05}, {"id": 78, "seek": 55208, "start": 552.08, "end": 556.84, "text": " with the data right so this is a really nice way to do things so now I can hit you to undo", "tokens": [365, 264, 1412, 558, 370, 341, 307, 257, 534, 1481, 636, 281, 360, 721, 370, 586, 286, 393, 2045, 291, 281, 23779], "temperature": 0.0, "avg_logprob": -0.0913660657274854, "compression_ratio": 1.7920792079207921, "no_speech_prob": 3.120074688922614e-05}, {"id": 79, "seek": 55208, "start": 556.84, "end": 564.1, "text": " and then I can go back and have a look and see why did this fail and so this is where", "tokens": [293, 550, 286, 393, 352, 646, 293, 362, 257, 574, 293, 536, 983, 630, 341, 3061, 293, 370, 341, 307, 689], "temperature": 0.0, "avg_logprob": -0.0913660657274854, "compression_ratio": 1.7920792079207921, "no_speech_prob": 3.120074688922614e-05}, {"id": 80, "seek": 55208, "start": 564.1, "end": 568.96, "text": " it's good to start learning some of the details about regular expressions and one of the things", "tokens": [309, 311, 665, 281, 722, 2539, 512, 295, 264, 4365, 466, 3890, 15277, 293, 472, 295, 264, 721], "temperature": 0.0, "avg_logprob": -0.0913660657274854, "compression_ratio": 1.7920792079207921, "no_speech_prob": 3.120074688922614e-05}, {"id": 81, "seek": 55208, "start": 568.96, "end": 576.76, "text": " that's useful to learn is the idea of a greedy match a greedy match is the idea that when", "tokens": [300, 311, 4420, 281, 1466, 307, 264, 1558, 295, 257, 28228, 2995, 257, 28228, 2995, 307, 264, 1558, 300, 562], "temperature": 0.0, "avg_logprob": -0.0913660657274854, "compression_ratio": 1.7920792079207921, "no_speech_prob": 3.120074688922614e-05}, {"id": 82, "seek": 57676, "start": 576.76, "end": 584.28, "text": " you match something with a wild card like star or plus it wants to find as many as big", "tokens": [291, 2995, 746, 365, 257, 4868, 2920, 411, 3543, 420, 1804, 309, 2738, 281, 915, 382, 867, 382, 955], "temperature": 0.0, "avg_logprob": -0.06715293578159662, "compression_ratio": 1.765, "no_speech_prob": 6.854213097540196e-06}, {"id": 83, "seek": 57676, "start": 584.28, "end": 593.28, "text": " a group as possible so the reason this didn't work is that dot star dot means everything", "tokens": [257, 1594, 382, 1944, 370, 264, 1778, 341, 994, 380, 589, 307, 300, 5893, 3543, 5893, 1355, 1203], "temperature": 0.0, "avg_logprob": -0.06715293578159662, "compression_ratio": 1.765, "no_speech_prob": 6.854213097540196e-06}, {"id": 84, "seek": 57676, "start": 593.28, "end": 599.36, "text": " right and so including digits so like there's two possible ways to match this it could either", "tokens": [558, 293, 370, 3009, 27011, 370, 411, 456, 311, 732, 1944, 2098, 281, 2995, 341, 309, 727, 2139], "temperature": 0.0, "avg_logprob": -0.06715293578159662, "compression_ratio": 1.765, "no_speech_prob": 6.854213097540196e-06}, {"id": 85, "seek": 57676, "start": 599.36, "end": 604.72, "text": " match everything up to the first of these digits and then stop there and then start", "tokens": [2995, 1203, 493, 281, 264, 700, 295, 613, 27011, 293, 550, 1590, 456, 293, 550, 722], "temperature": 0.0, "avg_logprob": -0.06715293578159662, "compression_ratio": 1.765, "no_speech_prob": 6.854213097540196e-06}, {"id": 86, "seek": 60472, "start": 604.72, "end": 609.52, "text": " capturing digits or it could match everything including the digits and then it would only", "tokens": [23384, 27011, 420, 309, 727, 2995, 1203, 3009, 264, 27011, 293, 550, 309, 576, 787], "temperature": 0.0, "avg_logprob": -0.08767996101735909, "compression_ratio": 1.7470355731225296, "no_speech_prob": 9.368593964609317e-06}, {"id": 87, "seek": 60472, "start": 609.52, "end": 614.9200000000001, "text": " need to find one so strictly speaking what it did here which was in the dot star included", "tokens": [643, 281, 915, 472, 370, 20792, 4124, 437, 309, 630, 510, 597, 390, 294, 264, 5893, 3543, 5556], "temperature": 0.0, "avg_logprob": -0.08767996101735909, "compression_ratio": 1.7470355731225296, "no_speech_prob": 9.368593964609317e-06}, {"id": 88, "seek": 60472, "start": 614.9200000000001, "end": 620.72, "text": " those first two digits totally correct right I mean it's it's it's what I asked for but", "tokens": [729, 700, 732, 27011, 3879, 3006, 558, 286, 914, 309, 311, 309, 311, 309, 311, 437, 286, 2351, 337, 457], "temperature": 0.0, "avg_logprob": -0.08767996101735909, "compression_ratio": 1.7470355731225296, "no_speech_prob": 9.368593964609317e-06}, {"id": 89, "seek": 60472, "start": 620.72, "end": 627.4, "text": " it's not what I wanted so you can see how valuable it is to do this kind of interactively", "tokens": [309, 311, 406, 437, 286, 1415, 370, 291, 393, 536, 577, 8263, 309, 307, 281, 360, 341, 733, 295, 4648, 3413], "temperature": 0.0, "avg_logprob": -0.08767996101735909, "compression_ratio": 1.7470355731225296, "no_speech_prob": 9.368593964609317e-06}, {"id": 90, "seek": 60472, "start": 627.4, "end": 633.36, "text": " I can just hit you to undo and try again a couple of ways I could fix this one is in", "tokens": [286, 393, 445, 2045, 291, 281, 23779, 293, 853, 797, 257, 1916, 295, 2098, 286, 727, 3191, 341, 472, 307, 294], "temperature": 0.0, "avg_logprob": -0.08767996101735909, "compression_ratio": 1.7470355731225296, "no_speech_prob": 9.368593964609317e-06}, {"id": 91, "seek": 63336, "start": 633.36, "end": 641.24, "text": " in regular expressions you can ask for a non greedy match and the way you do that is you", "tokens": [294, 3890, 15277, 291, 393, 1029, 337, 257, 2107, 28228, 2995, 293, 264, 636, 291, 360, 300, 307, 291], "temperature": 0.0, "avg_logprob": -0.14753414267924295, "compression_ratio": 1.6878980891719746, "no_speech_prob": 2.178211070713587e-05}, {"id": 92, "seek": 63336, "start": 641.24, "end": 648.08, "text": " put a question mark after a asterisk or a plus and that means as sure as possible right", "tokens": [829, 257, 1168, 1491, 934, 257, 257, 3120, 7797, 420, 257, 1804, 293, 300, 1355, 382, 988, 382, 1944, 558], "temperature": 0.0, "avg_logprob": -0.14753414267924295, "compression_ratio": 1.6878980891719746, "no_speech_prob": 2.178211070713587e-05}, {"id": 93, "seek": 63336, "start": 648.08, "end": 652.38, "text": " so this is now a non greedy match of the star which means the greedy match will go on my", "tokens": [370, 341, 307, 586, 257, 2107, 28228, 2995, 295, 264, 3543, 597, 1355, 264, 28228, 2995, 486, 352, 322, 452], "temperature": 0.0, "avg_logprob": -0.14753414267924295, "compression_ratio": 1.6878980891719746, "no_speech_prob": 2.178211070713587e-05}, {"id": 94, "seek": 65238, "start": 652.38, "end": 664.36, "text": " digits.", "tokens": [27011, 13], "temperature": 0.0, "avg_logprob": -0.13811467675601735, "compression_ratio": 1.320754716981132, "no_speech_prob": 7.2961820478667505e-06}, {"id": 95, "seek": 65238, "start": 664.36, "end": 674.16, "text": " Which might not be supported by them.", "tokens": [3013, 1062, 406, 312, 8104, 538, 552, 13], "temperature": 0.0, "avg_logprob": -0.13811467675601735, "compression_ratio": 1.320754716981132, "no_speech_prob": 7.2961820478667505e-06}, {"id": 96, "seek": 65238, "start": 674.16, "end": 679.76, "text": " So one of the tricks here is different systems also support different subsets of functionality", "tokens": [407, 472, 295, 264, 11733, 510, 307, 819, 3652, 611, 1406, 819, 2090, 1385, 295, 14980], "temperature": 0.0, "avg_logprob": -0.13811467675601735, "compression_ratio": 1.320754716981132, "no_speech_prob": 7.2961820478667505e-06}, {"id": 97, "seek": 67976, "start": 679.76, "end": 692.0, "text": " so this question marks not working so then I'd go vim regex non greedy let's see how", "tokens": [370, 341, 1168, 10640, 406, 1364, 370, 550, 286, 1116, 352, 371, 332, 319, 432, 87, 2107, 28228, 718, 311, 536, 577], "temperature": 0.0, "avg_logprob": -0.2148304172590667, "compression_ratio": 1.4132231404958677, "no_speech_prob": 4.907969196210615e-05}, {"id": 98, "seek": 67976, "start": 692.0, "end": 702.48, "text": " do I make it okay so I don't I've not seen this before what is this one not sure so it", "tokens": [360, 286, 652, 309, 1392, 370, 286, 500, 380, 286, 600, 406, 1612, 341, 949, 437, 307, 341, 472, 406, 988, 370, 309], "temperature": 0.0, "avg_logprob": -0.2148304172590667, "compression_ratio": 1.4132231404958677, "no_speech_prob": 4.907969196210615e-05}, {"id": 99, "seek": 70248, "start": 702.48, "end": 713.04, "text": " says instead of dot star use this apparently this is a non greedy.", "tokens": [1619, 2602, 295, 5893, 3543, 764, 341, 7970, 341, 307, 257, 2107, 28228, 13], "temperature": 0.0, "avg_logprob": -0.26850207646687824, "compression_ratio": 1.3333333333333333, "no_speech_prob": 9.972209227271378e-06}, {"id": 100, "seek": 70248, "start": 713.04, "end": 719.12, "text": " So let's try it.", "tokens": [407, 718, 311, 853, 309, 13], "temperature": 0.0, "avg_logprob": -0.26850207646687824, "compression_ratio": 1.3333333333333333, "no_speech_prob": 9.972209227271378e-06}, {"id": 101, "seek": 70248, "start": 719.12, "end": 730.36, "text": " Okay so that worked that's not bad but perhaps the way I would tend to do it in practice", "tokens": [1033, 370, 300, 2732, 300, 311, 406, 1578, 457, 4317, 264, 636, 286, 576, 3928, 281, 360, 309, 294, 3124], "temperature": 0.0, "avg_logprob": -0.26850207646687824, "compression_ratio": 1.3333333333333333, "no_speech_prob": 9.972209227271378e-06}, {"id": 102, "seek": 73036, "start": 730.36, "end": 743.08, "text": " would be instead of a dot I might say everything except for a zero to nine so to create a set", "tokens": [576, 312, 2602, 295, 257, 5893, 286, 1062, 584, 1203, 3993, 337, 257, 4018, 281, 4949, 370, 281, 1884, 257, 992], "temperature": 0.0, "avg_logprob": -0.13271395862102509, "compression_ratio": 1.5964912280701755, "no_speech_prob": 8.530159902875312e-06}, {"id": 103, "seek": 73036, "start": 743.08, "end": 748.64, "text": " of possible things you put them in square brackets so that means a SDF and there's a", "tokens": [295, 1944, 721, 291, 829, 552, 294, 3732, 26179, 370, 300, 1355, 257, 14638, 37, 293, 456, 311, 257], "temperature": 0.0, "avg_logprob": -0.13271395862102509, "compression_ratio": 1.5964912280701755, "no_speech_prob": 8.530159902875312e-06}, {"id": 104, "seek": 73036, "start": 748.64, "end": 754.52, "text": " shortcut which is if you put something hyphen something you mean that means everything between", "tokens": [24822, 597, 307, 498, 291, 829, 746, 2477, 47059, 746, 291, 914, 300, 1355, 1203, 1296], "temperature": 0.0, "avg_logprob": -0.13271395862102509, "compression_ratio": 1.5964912280701755, "no_speech_prob": 8.530159902875312e-06}, {"id": 105, "seek": 75452, "start": 754.52, "end": 764.28, "text": " these two so these are all the digits or all the letters and then to mean everything except", "tokens": [613, 732, 370, 613, 366, 439, 264, 27011, 420, 439, 264, 7825, 293, 550, 281, 914, 1203, 3993], "temperature": 0.0, "avg_logprob": -0.09345951894434487, "compression_ratio": 1.4666666666666666, "no_speech_prob": 5.0936532716150396e-06}, {"id": 106, "seek": 75452, "start": 764.28, "end": 770.76, "text": " those in square brackets you pop a carrot symbol so this would be non digits as many", "tokens": [729, 294, 3732, 26179, 291, 1665, 257, 22767, 5986, 370, 341, 576, 312, 2107, 27011, 382, 867], "temperature": 0.0, "avg_logprob": -0.09345951894434487, "compression_ratio": 1.4666666666666666, "no_speech_prob": 5.0936532716150396e-06}, {"id": 107, "seek": 77076, "start": 770.76, "end": 792.92, "text": " as possible and so this would also fix the problem except it didn't let's see.", "tokens": [382, 1944, 293, 370, 341, 576, 611, 3191, 264, 1154, 3993, 309, 994, 380, 718, 311, 536, 13], "temperature": 0.0, "avg_logprob": -0.2299376834522594, "compression_ratio": 1.0684931506849316, "no_speech_prob": 3.8449124986073e-06}, {"id": 108, "seek": 79292, "start": 792.92, "end": 804.56, "text": " Okay so I'm checking I just searched for that and that is working so that's good.", "tokens": [1033, 370, 286, 478, 8568, 286, 445, 22961, 337, 300, 293, 300, 307, 1364, 370, 300, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.21432945945046164, "compression_ratio": 1.4172661870503598, "no_speech_prob": 9.972814950742759e-06}, {"id": 109, "seek": 79292, "start": 804.56, "end": 811.24, "text": " Oh I see the problem.", "tokens": [876, 286, 536, 264, 1154, 13], "temperature": 0.0, "avg_logprob": -0.21432945945046164, "compression_ratio": 1.4172661870503598, "no_speech_prob": 9.972814950742759e-06}, {"id": 110, "seek": 79292, "start": 811.24, "end": 818.9599999999999, "text": " Okay so again it's good that we're doing things interactively my logic's not right so I can't", "tokens": [1033, 370, 797, 309, 311, 665, 300, 321, 434, 884, 721, 4648, 3413, 452, 9952, 311, 406, 558, 370, 286, 393, 380], "temperature": 0.0, "avg_logprob": -0.21432945945046164, "compression_ratio": 1.4172661870503598, "no_speech_prob": 9.972814950742759e-06}, {"id": 111, "seek": 81896, "start": 818.96, "end": 827.72, "text": " search for non digits because there's lots of digits that aren't in phone numbers that", "tokens": [3164, 337, 2107, 27011, 570, 456, 311, 3195, 295, 27011, 300, 3212, 380, 294, 2593, 3547, 300], "temperature": 0.0, "avg_logprob": -0.17569454132564485, "compression_ratio": 1.5662650602409638, "no_speech_prob": 5.422153208201053e-06}, {"id": 112, "seek": 81896, "start": 827.72, "end": 840.32, "text": " aren't going to match so which reminds me people so when I'm running courses I did a", "tokens": [3212, 380, 516, 281, 2995, 370, 597, 12025, 385, 561, 370, 562, 286, 478, 2614, 7712, 286, 630, 257], "temperature": 0.0, "avg_logprob": -0.17569454132564485, "compression_ratio": 1.5662650602409638, "no_speech_prob": 5.422153208201053e-06}, {"id": 113, "seek": 81896, "start": 840.32, "end": 844.84, "text": " lot of students tend to hang out with me in the study room and we just work together and", "tokens": [688, 295, 1731, 3928, 281, 3967, 484, 365, 385, 294, 264, 2979, 1808, 293, 321, 445, 589, 1214, 293], "temperature": 0.0, "avg_logprob": -0.17569454132564485, "compression_ratio": 1.5662650602409638, "no_speech_prob": 5.422153208201053e-06}, {"id": 114, "seek": 84484, "start": 844.84, "end": 849.6, "text": " I tend to get a few comments about things people are surprised by when they're working", "tokens": [286, 3928, 281, 483, 257, 1326, 3053, 466, 721, 561, 366, 6100, 538, 562, 436, 434, 1364], "temperature": 0.0, "avg_logprob": -0.11230109650411724, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.1444133381010033e-05}, {"id": 115, "seek": 84484, "start": 849.6, "end": 856.94, "text": " with me maybe the main one is gosh I'm surprised how many mistakes you make except generally", "tokens": [365, 385, 1310, 264, 2135, 472, 307, 6502, 286, 478, 6100, 577, 867, 8038, 291, 652, 3993, 5101], "temperature": 0.0, "avg_logprob": -0.11230109650411724, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.1444133381010033e-05}, {"id": 116, "seek": 84484, "start": 856.94, "end": 865.32, "text": " phrased slightly more politely there's plenty of seats over here if you guys want seats", "tokens": [7636, 1937, 4748, 544, 1180, 1959, 456, 311, 7140, 295, 11069, 670, 510, 498, 291, 1074, 528, 11069], "temperature": 0.0, "avg_logprob": -0.11230109650411724, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.1444133381010033e-05}, {"id": 117, "seek": 84484, "start": 865.32, "end": 872.2800000000001, "text": " it's really useful to remember that the stuff that you see teachers do is stuff that we", "tokens": [309, 311, 534, 4420, 281, 1604, 300, 264, 1507, 300, 291, 536, 6023, 360, 307, 1507, 300, 321], "temperature": 0.0, "avg_logprob": -0.11230109650411724, "compression_ratio": 1.6435185185185186, "no_speech_prob": 2.1444133381010033e-05}, {"id": 118, "seek": 87228, "start": 872.28, "end": 878.52, "text": " generally spend quite a lot of time preparing one of my deep learning courses basically", "tokens": [5101, 3496, 1596, 257, 688, 295, 565, 10075, 472, 295, 452, 2452, 2539, 7712, 1936], "temperature": 0.0, "avg_logprob": -0.11715437726276677, "compression_ratio": 1.6272727272727272, "no_speech_prob": 1.983258334803395e-05}, {"id": 119, "seek": 87228, "start": 878.52, "end": 884.0799999999999, "text": " takes me six months full-time repair so by the time you see it hopefully I've got things", "tokens": [2516, 385, 2309, 2493, 1577, 12, 3766, 10535, 370, 538, 264, 565, 291, 536, 309, 4696, 286, 600, 658, 721], "temperature": 0.0, "avg_logprob": -0.11715437726276677, "compression_ratio": 1.6272727272727272, "no_speech_prob": 1.983258334803395e-05}, {"id": 120, "seek": 87228, "start": 884.0799999999999, "end": 892.9399999999999, "text": " working 99% of the time whatever I'm doing doesn't work and so I found the biggest difference", "tokens": [1364, 11803, 4, 295, 264, 565, 2035, 286, 478, 884, 1177, 380, 589, 293, 370, 286, 1352, 264, 3880, 2649], "temperature": 0.0, "avg_logprob": -0.11715437726276677, "compression_ratio": 1.6272727272727272, "no_speech_prob": 1.983258334803395e-05}, {"id": 121, "seek": 87228, "start": 892.9399999999999, "end": 900.6, "text": " between people who are successful at things in general and those who aren't seems to be", "tokens": [1296, 561, 567, 366, 4406, 412, 721, 294, 2674, 293, 729, 567, 3212, 380, 2544, 281, 312], "temperature": 0.0, "avg_logprob": -0.11715437726276677, "compression_ratio": 1.6272727272727272, "no_speech_prob": 1.983258334803395e-05}, {"id": 122, "seek": 90060, "start": 900.6, "end": 905.44, "text": " entirely about tenacity which is both something I've anecdotally found and also seems to be", "tokens": [7696, 466, 2064, 19008, 597, 307, 1293, 746, 286, 600, 26652, 310, 379, 1352, 293, 611, 2544, 281, 312], "temperature": 0.0, "avg_logprob": -0.05973992055776168, "compression_ratio": 1.8225806451612903, "no_speech_prob": 3.119939719908871e-05}, {"id": 123, "seek": 90060, "start": 905.44, "end": 912.2, "text": " something which some social science research finds as well and particularly for machine", "tokens": [746, 597, 512, 2093, 3497, 2132, 10704, 382, 731, 293, 4098, 337, 3479], "temperature": 0.0, "avg_logprob": -0.05973992055776168, "compression_ratio": 1.8225806451612903, "no_speech_prob": 3.119939719908871e-05}, {"id": 124, "seek": 90060, "start": 912.2, "end": 919.4, "text": " learning machine learning you have to be super tenacious for because it's something where", "tokens": [2539, 3479, 2539, 291, 362, 281, 312, 1687, 2064, 22641, 337, 570, 309, 311, 746, 689], "temperature": 0.0, "avg_logprob": -0.05973992055776168, "compression_ratio": 1.8225806451612903, "no_speech_prob": 3.119939719908871e-05}, {"id": 125, "seek": 90060, "start": 919.4, "end": 925.7, "text": " when things don't work they often don't work in kind of mysterious and hard to debug ways", "tokens": [562, 721, 500, 380, 589, 436, 2049, 500, 380, 589, 294, 733, 295, 13831, 293, 1152, 281, 24083, 2098], "temperature": 0.0, "avg_logprob": -0.05973992055776168, "compression_ratio": 1.8225806451612903, "no_speech_prob": 3.119939719908871e-05}, {"id": 126, "seek": 90060, "start": 925.7, "end": 930.32, "text": " it's not like kind of you're creating a web service or something and you need these specific", "tokens": [309, 311, 406, 411, 733, 295, 291, 434, 4084, 257, 3670, 2643, 420, 746, 293, 291, 643, 613, 2685], "temperature": 0.0, "avg_logprob": -0.05973992055776168, "compression_ratio": 1.8225806451612903, "no_speech_prob": 3.119939719908871e-05}, {"id": 127, "seek": 93032, "start": 930.32, "end": 935.8000000000001, "text": " steps to work and then each step you get it to work and check it off machine learning", "tokens": [4439, 281, 589, 293, 550, 1184, 1823, 291, 483, 309, 281, 589, 293, 1520, 309, 766, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.11210672882781632, "compression_ratio": 1.7277227722772277, "no_speech_prob": 2.5465149519732222e-05}, {"id": 128, "seek": 93032, "start": 935.8000000000001, "end": 943.62, "text": " is not at all like that and you're going to have to keep going regardless of you know", "tokens": [307, 406, 412, 439, 411, 300, 293, 291, 434, 516, 281, 362, 281, 1066, 516, 10060, 295, 291, 458], "temperature": 0.0, "avg_logprob": -0.11210672882781632, "compression_ratio": 1.7277227722772277, "no_speech_prob": 2.5465149519732222e-05}, {"id": 129, "seek": 93032, "start": 943.62, "end": 948.0400000000001, "text": " the fact that it didn't work the second thing I think I hear more than anything else is", "tokens": [264, 1186, 300, 309, 994, 380, 589, 264, 1150, 551, 286, 519, 286, 1568, 544, 813, 1340, 1646, 307], "temperature": 0.0, "avg_logprob": -0.11210672882781632, "compression_ratio": 1.7277227722772277, "no_speech_prob": 2.5465149519732222e-05}, {"id": 130, "seek": 93032, "start": 948.0400000000001, "end": 959.2800000000001, "text": " wow I'm surprised at how fast you are at using your tools so like I'm super fast with the", "tokens": [6076, 286, 478, 6100, 412, 577, 2370, 291, 366, 412, 1228, 428, 3873, 370, 411, 286, 478, 1687, 2370, 365, 264], "temperature": 0.0, "avg_logprob": -0.11210672882781632, "compression_ratio": 1.7277227722772277, "no_speech_prob": 2.5465149519732222e-05}, {"id": 131, "seek": 95928, "start": 959.28, "end": 964.92, "text": " shell and with the editors I use and stuff like that and again that's something I've", "tokens": [8720, 293, 365, 264, 31446, 286, 764, 293, 1507, 411, 300, 293, 797, 300, 311, 746, 286, 600], "temperature": 0.0, "avg_logprob": -0.06415227696865419, "compression_ratio": 1.6926829268292682, "no_speech_prob": 1.3419302376860287e-05}, {"id": 132, "seek": 95928, "start": 964.92, "end": 971.12, "text": " found a lot of people doing code-based stuff really well tend to be extremely familiar", "tokens": [1352, 257, 688, 295, 561, 884, 3089, 12, 6032, 1507, 534, 731, 3928, 281, 312, 4664, 4963], "temperature": 0.0, "avg_logprob": -0.06415227696865419, "compression_ratio": 1.6926829268292682, "no_speech_prob": 1.3419302376860287e-05}, {"id": 133, "seek": 95928, "start": 971.12, "end": 975.8399999999999, "text": " with all the keyboard shortcuts and all the little tricks so that as soon as something", "tokens": [365, 439, 264, 10186, 34620, 293, 439, 264, 707, 11733, 370, 300, 382, 2321, 382, 746], "temperature": 0.0, "avg_logprob": -0.06415227696865419, "compression_ratio": 1.6926829268292682, "no_speech_prob": 1.3419302376860287e-05}, {"id": 134, "seek": 95928, "start": 975.8399999999999, "end": 983.64, "text": " pops out of their head they can get it into their machine so getting to know your editor", "tokens": [16795, 484, 295, 641, 1378, 436, 393, 483, 309, 666, 641, 3479, 370, 1242, 281, 458, 428, 9839], "temperature": 0.0, "avg_logprob": -0.06415227696865419, "compression_ratio": 1.6926829268292682, "no_speech_prob": 1.3419302376860287e-05}, {"id": 135, "seek": 98364, "start": 983.64, "end": 994.28, "text": " and shell and stuff really well is a good idea okay so I think we'll go back to our", "tokens": [293, 8720, 293, 1507, 534, 731, 307, 257, 665, 1558, 1392, 370, 286, 519, 321, 603, 352, 646, 281, 527], "temperature": 0.0, "avg_logprob": -0.09958403250750374, "compression_ratio": 1.5847953216374269, "no_speech_prob": 1.7230631783604622e-05}, {"id": 136, "seek": 98364, "start": 994.28, "end": 1000.9, "text": " non-greedy version of this because that actually worked pretty well so the last thing to do", "tokens": [2107, 12, 33248, 6038, 3037, 295, 341, 570, 300, 767, 2732, 1238, 731, 370, 264, 1036, 551, 281, 360], "temperature": 0.0, "avg_logprob": -0.09958403250750374, "compression_ratio": 1.5847953216374269, "no_speech_prob": 1.7230631783604622e-05}, {"id": 137, "seek": 98364, "start": 1000.9, "end": 1011.8, "text": " here would be to reformat this and it's interesting it's actually showed us it's very clear now", "tokens": [510, 576, 312, 281, 8290, 267, 341, 293, 309, 311, 1880, 309, 311, 767, 4712, 505, 309, 311, 588, 1850, 586], "temperature": 0.0, "avg_logprob": -0.09958403250750374, "compression_ratio": 1.5847953216374269, "no_speech_prob": 1.7230631783604622e-05}, {"id": 138, "seek": 101180, "start": 1011.8, "end": 1016.04, "text": " that they're actually somebody had an error right so another good reason to do your data", "tokens": [300, 436, 434, 767, 2618, 632, 364, 6713, 558, 370, 1071, 665, 1778, 281, 360, 428, 1412], "temperature": 0.0, "avg_logprob": -0.09744583267763436, "compression_ratio": 1.6129032258064515, "no_speech_prob": 2.392215174040757e-05}, {"id": 139, "seek": 101180, "start": 1016.04, "end": 1021.64, "text": " munching very interactively is you can see mistakes clearly Austin must be a 5 1 12 area", "tokens": [275, 46079, 588, 4648, 3413, 307, 291, 393, 536, 8038, 4448, 15356, 1633, 312, 257, 1025, 502, 2272, 1859], "temperature": 0.0, "avg_logprob": -0.09744583267763436, "compression_ratio": 1.6129032258064515, "no_speech_prob": 2.392215174040757e-05}, {"id": 140, "seek": 101180, "start": 1021.64, "end": 1026.6, "text": " code so we can fix their mistake for them so if now we want to reformat this in the", "tokens": [3089, 370, 321, 393, 3191, 641, 6146, 337, 552, 370, 498, 586, 321, 528, 281, 8290, 267, 341, 294, 264], "temperature": 0.0, "avg_logprob": -0.09744583267763436, "compression_ratio": 1.6129032258064515, "no_speech_prob": 2.392215174040757e-05}, {"id": 141, "seek": 101180, "start": 1026.6, "end": 1033.08, "text": " format that was requested we can just go ahead and we've actually already got the basics", "tokens": [7877, 300, 390, 16436, 321, 393, 445, 352, 2286, 293, 321, 600, 767, 1217, 658, 264, 14688], "temperature": 0.0, "avg_logprob": -0.09744583267763436, "compression_ratio": 1.6129032258064515, "no_speech_prob": 2.392215174040757e-05}, {"id": 142, "seek": 103308, "start": 1033.08, "end": 1042.04, "text": " we need which was backslash d backslash plus so we'll capture that and then backslash b", "tokens": [321, 643, 597, 390, 646, 10418, 1299, 274, 646, 10418, 1299, 1804, 370, 321, 603, 7983, 300, 293, 550, 646, 10418, 1299, 272], "temperature": 0.0, "avg_logprob": -0.21987051122328816, "compression_ratio": 1.945054945054945, "no_speech_prob": 4.908391201752238e-05}, {"id": 143, "seek": 103308, "start": 1042.04, "end": 1048.6399999999999, "text": " backslash plus and we'll capture that backslash b plus capture that and so we're going to", "tokens": [646, 10418, 1299, 1804, 293, 321, 603, 7983, 300, 646, 10418, 1299, 272, 1804, 7983, 300, 293, 370, 321, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.21987051122328816, "compression_ratio": 1.945054945054945, "no_speech_prob": 4.908391201752238e-05}, {"id": 144, "seek": 104864, "start": 1048.64, "end": 1075.0, "text": " go backslash and then we're going to replace it with a slightly different format.", "tokens": [352, 646, 10418, 1299, 293, 550, 321, 434, 516, 281, 7406, 309, 365, 257, 4748, 819, 7877, 13], "temperature": 0.0, "avg_logprob": -0.32382785190235486, "compression_ratio": 1.0657894736842106, "no_speech_prob": 1.32106761157047e-05}, {"id": 145, "seek": 107500, "start": 1075.0, "end": 1086.28, "text": " We can now send that off when we finish doing our data munching so yeah question for debugging", "tokens": [492, 393, 586, 2845, 300, 766, 562, 321, 2413, 884, 527, 1412, 275, 46079, 370, 1338, 1168, 337, 45592], "temperature": 0.0, "avg_logprob": -0.15952764018889395, "compression_ratio": 1.5657142857142856, "no_speech_prob": 5.224264532444067e-05}, {"id": 146, "seek": 107500, "start": 1086.28, "end": 1093.8, "text": " regular expressions yeah the main trick is something that you one of the tricks is something", "tokens": [3890, 15277, 1338, 264, 2135, 4282, 307, 746, 300, 291, 472, 295, 264, 11733, 307, 746], "temperature": 0.0, "avg_logprob": -0.15952764018889395, "compression_ratio": 1.5657142857142856, "no_speech_prob": 5.224264532444067e-05}, {"id": 147, "seek": 107500, "start": 1093.8, "end": 1100.96, "text": " I showed I kind of did quickly earlier which is I was trying to figure out why my care", "tokens": [286, 4712, 286, 733, 295, 630, 2661, 3071, 597, 307, 286, 390, 1382, 281, 2573, 484, 983, 452, 1127], "temperature": 0.0, "avg_logprob": -0.15952764018889395, "compression_ratio": 1.5657142857142856, "no_speech_prob": 5.224264532444067e-05}, {"id": 148, "seek": 110096, "start": 1100.96, "end": 1107.52, "text": " at 0 to 9 star wasn't working so I got rid of a search from the place and I just wanted", "tokens": [412, 1958, 281, 1722, 3543, 2067, 380, 1364, 370, 286, 658, 3973, 295, 257, 3164, 490, 264, 1081, 293, 286, 445, 1415], "temperature": 0.0, "avg_logprob": -0.12377177435776283, "compression_ratio": 1.782258064516129, "no_speech_prob": 5.143907401361503e-05}, {"id": 149, "seek": 110096, "start": 1107.52, "end": 1114.76, "text": " to kind of take little pieces so the first thing was oh maybe the inverse of a set operator", "tokens": [281, 733, 295, 747, 707, 3755, 370, 264, 700, 551, 390, 1954, 1310, 264, 17340, 295, 257, 992, 12973], "temperature": 0.0, "avg_logprob": -0.12377177435776283, "compression_ratio": 1.782258064516129, "no_speech_prob": 5.143907401361503e-05}, {"id": 150, "seek": 110096, "start": 1114.76, "end": 1119.56, "text": " is different in Vim so I tried just so slash mean search in Vim so I just said search for", "tokens": [307, 819, 294, 691, 332, 370, 286, 3031, 445, 370, 17330, 914, 3164, 294, 691, 332, 370, 286, 445, 848, 3164, 337], "temperature": 0.0, "avg_logprob": -0.12377177435776283, "compression_ratio": 1.782258064516129, "no_speech_prob": 5.143907401361503e-05}, {"id": 151, "seek": 110096, "start": 1119.56, "end": 1124.52, "text": " a non 0 to 9 and then I started hitting n which means go to the next one and I just", "tokens": [257, 2107, 1958, 281, 1722, 293, 550, 286, 1409, 8850, 297, 597, 1355, 352, 281, 264, 958, 472, 293, 286, 445], "temperature": 0.0, "avg_logprob": -0.12377177435776283, "compression_ratio": 1.782258064516129, "no_speech_prob": 5.143907401361503e-05}, {"id": 152, "seek": 110096, "start": 1124.52, "end": 1130.18, "text": " made sure it seems to be going through the non digits right and so then it's just a case", "tokens": [1027, 988, 309, 2544, 281, 312, 516, 807, 264, 2107, 27011, 558, 293, 370, 550, 309, 311, 445, 257, 1389], "temperature": 0.0, "avg_logprob": -0.12377177435776283, "compression_ratio": 1.782258064516129, "no_speech_prob": 5.143907401361503e-05}, {"id": 153, "seek": 113018, "start": 1130.18, "end": 1138.8, "text": " of like checking each of your assumptions and then making your search smaller and smaller", "tokens": [295, 411, 8568, 1184, 295, 428, 17695, 293, 550, 1455, 428, 3164, 4356, 293, 4356], "temperature": 0.0, "avg_logprob": -0.11754365762074788, "compression_ratio": 1.6645569620253164, "no_speech_prob": 1.3211689292802475e-05}, {"id": 154, "seek": 113018, "start": 1138.8, "end": 1143.6000000000001, "text": " and smaller another thing is to do like less than each go so I could have actually done", "tokens": [293, 4356, 1071, 551, 307, 281, 360, 411, 1570, 813, 1184, 352, 370, 286, 727, 362, 767, 1096], "temperature": 0.0, "avg_logprob": -0.11754365762074788, "compression_ratio": 1.6645569620253164, "no_speech_prob": 1.3211689292802475e-05}, {"id": 155, "seek": 113018, "start": 1143.6000000000001, "end": 1157.24, "text": " the whole reformatting and finding straight from here right if I so once I you know I", "tokens": [264, 1379, 8290, 267, 783, 293, 5006, 2997, 490, 510, 558, 498, 286, 370, 1564, 286, 291, 458, 286], "temperature": 0.0, "avg_logprob": -0.11754365762074788, "compression_ratio": 1.6645569620253164, "no_speech_prob": 1.3211689292802475e-05}, {"id": 156, "seek": 115724, "start": 1157.24, "end": 1174.1200000000001, "text": " could have put straight from here I could have gone search for each group and replace", "tokens": [727, 362, 829, 2997, 490, 510, 286, 727, 362, 2780, 3164, 337, 1184, 1594, 293, 7406], "temperature": 0.0, "avg_logprob": -0.07984394411886891, "compression_ratio": 1.623456790123457, "no_speech_prob": 5.014644102629973e-06}, {"id": 157, "seek": 115724, "start": 1174.1200000000001, "end": 1177.6, "text": " and I could have done it in one go rather than two but like I kind of think splitting", "tokens": [293, 286, 727, 362, 1096, 309, 294, 472, 352, 2831, 813, 732, 457, 411, 286, 733, 295, 519, 30348], "temperature": 0.0, "avg_logprob": -0.07984394411886891, "compression_ratio": 1.623456790123457, "no_speech_prob": 5.014644102629973e-06}, {"id": 158, "seek": 115724, "start": 1177.6, "end": 1183.96, "text": " things up into multiple steps where you can see each step is a good idea I think in general", "tokens": [721, 493, 666, 3866, 4439, 689, 291, 393, 536, 1184, 1823, 307, 257, 665, 1558, 286, 519, 294, 2674], "temperature": 0.0, "avg_logprob": -0.07984394411886891, "compression_ratio": 1.623456790123457, "no_speech_prob": 5.014644102629973e-06}, {"id": 159, "seek": 118396, "start": 1183.96, "end": 1192.56, "text": " debugging anything the main trick is to once something doesn't work is to like find the", "tokens": [45592, 1340, 264, 2135, 4282, 307, 281, 1564, 746, 1177, 380, 589, 307, 281, 411, 915, 264], "temperature": 0.0, "avg_logprob": -0.10059317675503818, "compression_ratio": 1.9942196531791907, "no_speech_prob": 3.822770668193698e-05}, {"id": 160, "seek": 118396, "start": 1192.56, "end": 1198.4, "text": " smallest thing that doesn't work and then find the like keep going back from there to", "tokens": [16998, 551, 300, 1177, 380, 589, 293, 550, 915, 264, 411, 1066, 516, 646, 490, 456, 281], "temperature": 0.0, "avg_logprob": -0.10059317675503818, "compression_ratio": 1.9942196531791907, "no_speech_prob": 3.822770668193698e-05}, {"id": 161, "seek": 118396, "start": 1198.4, "end": 1203.3600000000001, "text": " find a small thing that does work and now once you know what the specific thing that", "tokens": [915, 257, 1359, 551, 300, 775, 589, 293, 586, 1564, 291, 458, 437, 264, 2685, 551, 300], "temperature": 0.0, "avg_logprob": -0.10059317675503818, "compression_ratio": 1.9942196531791907, "no_speech_prob": 3.822770668193698e-05}, {"id": 162, "seek": 118396, "start": 1203.3600000000001, "end": 1212.2, "text": " doesn't work is fixing it is normally pretty easy one of the challenges with debugging", "tokens": [1177, 380, 589, 307, 19442, 309, 307, 5646, 1238, 1858, 472, 295, 264, 4759, 365, 45592], "temperature": 0.0, "avg_logprob": -0.10059317675503818, "compression_ratio": 1.9942196531791907, "no_speech_prob": 3.822770668193698e-05}, {"id": 163, "seek": 121220, "start": 1212.2, "end": 1216.16, "text": " in general is that if something in your code isn't working it means that something that", "tokens": [294, 2674, 307, 300, 498, 746, 294, 428, 3089, 1943, 380, 1364, 309, 1355, 300, 746, 300], "temperature": 0.0, "avg_logprob": -0.08739363136938062, "compression_ratio": 1.8780487804878048, "no_speech_prob": 6.108504021540284e-05}, {"id": 164, "seek": 121220, "start": 1216.16, "end": 1220.4, "text": " you thought worked in a particular way is not working in that way so like you actually", "tokens": [291, 1194, 2732, 294, 257, 1729, 636, 307, 406, 1364, 294, 300, 636, 370, 411, 291, 767], "temperature": 0.0, "avg_logprob": -0.08739363136938062, "compression_ratio": 1.8780487804878048, "no_speech_prob": 6.108504021540284e-05}, {"id": 165, "seek": 121220, "start": 1220.4, "end": 1225.54, "text": " have to start with an understanding that you're wrong about something which can be quite hard", "tokens": [362, 281, 722, 365, 364, 3701, 300, 291, 434, 2085, 466, 746, 597, 393, 312, 1596, 1152], "temperature": 0.0, "avg_logprob": -0.08739363136938062, "compression_ratio": 1.8780487804878048, "no_speech_prob": 6.108504021540284e-05}, {"id": 166, "seek": 121220, "start": 1225.54, "end": 1229.28, "text": " for people so often like one of the challenges I have with newer programmers is to say okay", "tokens": [337, 561, 370, 2049, 411, 472, 295, 264, 4759, 286, 362, 365, 17628, 41504, 307, 281, 584, 1392], "temperature": 0.0, "avg_logprob": -0.08739363136938062, "compression_ratio": 1.8780487804878048, "no_speech_prob": 6.108504021540284e-05}, {"id": 167, "seek": 121220, "start": 1229.28, "end": 1232.88, "text": " we're going to go right back to the start and create the simplest possible thing and", "tokens": [321, 434, 516, 281, 352, 558, 646, 281, 264, 722, 293, 1884, 264, 22811, 1944, 551, 293], "temperature": 0.0, "avg_logprob": -0.08739363136938062, "compression_ratio": 1.8780487804878048, "no_speech_prob": 6.108504021540284e-05}, {"id": 168, "seek": 121220, "start": 1232.88, "end": 1237.2, "text": " then check every little step and new programmers are often like no no I already know this bit", "tokens": [550, 1520, 633, 707, 1823, 293, 777, 41504, 366, 2049, 411, 572, 572, 286, 1217, 458, 341, 857], "temperature": 0.0, "avg_logprob": -0.08739363136938062, "compression_ratio": 1.8780487804878048, "no_speech_prob": 6.108504021540284e-05}, {"id": 169, "seek": 123720, "start": 1237.2, "end": 1243.3600000000001, "text": " so we can jump to there I think the problem is X and debugging is never about I think", "tokens": [370, 321, 393, 3012, 281, 456, 286, 519, 264, 1154, 307, 1783, 293, 45592, 307, 1128, 466, 286, 519], "temperature": 0.0, "avg_logprob": -0.08012234848157494, "compression_ratio": 1.808, "no_speech_prob": 2.840907109202817e-05}, {"id": 170, "seek": 123720, "start": 1243.3600000000001, "end": 1246.96, "text": " the problem is X it's always about starting with I don't know what the problem is because", "tokens": [264, 1154, 307, 1783, 309, 311, 1009, 466, 2891, 365, 286, 500, 380, 458, 437, 264, 1154, 307, 570], "temperature": 0.0, "avg_logprob": -0.08012234848157494, "compression_ratio": 1.808, "no_speech_prob": 2.840907109202817e-05}, {"id": 171, "seek": 123720, "start": 1246.96, "end": 1253.1200000000001, "text": " I made a mistake and so you just like requires a lot of humility you go back you check everything", "tokens": [286, 1027, 257, 6146, 293, 370, 291, 445, 411, 7029, 257, 688, 295, 27106, 291, 352, 646, 291, 1520, 1203], "temperature": 0.0, "avg_logprob": -0.08012234848157494, "compression_ratio": 1.808, "no_speech_prob": 2.840907109202817e-05}, {"id": 172, "seek": 123720, "start": 1253.1200000000001, "end": 1259.24, "text": " and eventually we've all had this feeling when you find the bug oh I'm an idiot so don't", "tokens": [293, 4728, 321, 600, 439, 632, 341, 2633, 562, 291, 915, 264, 7426, 1954, 286, 478, 364, 14270, 370, 500, 380], "temperature": 0.0, "avg_logprob": -0.08012234848157494, "compression_ratio": 1.808, "no_speech_prob": 2.840907109202817e-05}, {"id": 173, "seek": 123720, "start": 1259.24, "end": 1264.28, "text": " wait to find out we you know I already know I'm an idiot right so let's just work on that", "tokens": [1699, 281, 915, 484, 321, 291, 458, 286, 1217, 458, 286, 478, 364, 14270, 558, 370, 718, 311, 445, 589, 322, 300], "temperature": 0.0, "avg_logprob": -0.08012234848157494, "compression_ratio": 1.808, "no_speech_prob": 2.840907109202817e-05}, {"id": 174, "seek": 126428, "start": 1264.28, "end": 1272.16, "text": " assumption when we start debugging okay so regular expressions things that not just that", "tokens": [15302, 562, 321, 722, 45592, 1392, 370, 3890, 15277, 721, 300, 406, 445, 300], "temperature": 0.0, "avg_logprob": -0.07018575971088713, "compression_ratio": 1.705521472392638, "no_speech_prob": 1.1299845027679112e-05}, {"id": 175, "seek": 126428, "start": 1272.16, "end": 1276.96, "text": " go in your code but they go in your day-to-day life they go in your editor a lot of the programs", "tokens": [352, 294, 428, 3089, 457, 436, 352, 294, 428, 786, 12, 1353, 12, 810, 993, 436, 352, 294, 428, 9839, 257, 688, 295, 264, 4268], "temperature": 0.0, "avg_logprob": -0.07018575971088713, "compression_ratio": 1.705521472392638, "no_speech_prob": 1.1299845027679112e-05}, {"id": 176, "seek": 126428, "start": 1276.96, "end": 1281.24, "text": " you use if you search the docs you'll find they probably already support regular expressions", "tokens": [291, 764, 498, 291, 3164, 264, 45623, 291, 603, 915, 436, 1391, 1217, 1406, 3890, 15277], "temperature": 0.0, "avg_logprob": -0.07018575971088713, "compression_ratio": 1.705521472392638, "no_speech_prob": 1.1299845027679112e-05}, {"id": 177, "seek": 128124, "start": 1281.24, "end": 1298.48, "text": " in lots of places so the other ones I wrote down here SVD so matrix decomposition is just", "tokens": [294, 3195, 295, 3190, 370, 264, 661, 2306, 286, 4114, 760, 510, 31910, 35, 370, 8141, 48356, 307, 445], "temperature": 0.0, "avg_logprob": -0.10081405417863713, "compression_ratio": 1.348148148148148, "no_speech_prob": 1.497058565291809e-05}, {"id": 178, "seek": 128124, "start": 1298.48, "end": 1306.72, "text": " a really powerful technique I certainly don't use it as much as rejects or transfer learning", "tokens": [257, 534, 4005, 6532, 286, 3297, 500, 380, 764, 309, 382, 709, 382, 8248, 82, 420, 5003, 2539], "temperature": 0.0, "avg_logprob": -0.10081405417863713, "compression_ratio": 1.348148148148148, "no_speech_prob": 1.497058565291809e-05}, {"id": 179, "seek": 130672, "start": 1306.72, "end": 1315.72, "text": " but it's definitely something that is really handy to know well the I'm obviously biased", "tokens": [457, 309, 311, 2138, 746, 300, 307, 534, 13239, 281, 458, 731, 264, 286, 478, 2745, 28035], "temperature": 0.0, "avg_logprob": -0.10341899148349104, "compression_ratio": 1.502857142857143, "no_speech_prob": 1.86304678209126e-05}, {"id": 180, "seek": 130672, "start": 1315.72, "end": 1323.04, "text": " but in my opinion Rachel's computational linear algebra course is the best place to learn", "tokens": [457, 294, 452, 4800, 14246, 311, 28270, 8213, 21989, 1164, 307, 264, 1151, 1081, 281, 1466], "temperature": 0.0, "avg_logprob": -0.10341899148349104, "compression_ratio": 1.502857142857143, "no_speech_prob": 1.86304678209126e-05}, {"id": 181, "seek": 130672, "start": 1323.04, "end": 1333.2, "text": " more about that so if you're interested in diving deeper this is the master's course", "tokens": [544, 466, 300, 370, 498, 291, 434, 3102, 294, 20241, 7731, 341, 307, 264, 4505, 311, 1164], "temperature": 0.0, "avg_logprob": -0.10341899148349104, "compression_ratio": 1.502857142857143, "no_speech_prob": 1.86304678209126e-05}, {"id": 182, "seek": 133320, "start": 1333.2, "end": 1339.96, "text": " that she taught in 2017 on this topic so it's just like this course that we're teaching", "tokens": [300, 750, 5928, 294, 6591, 322, 341, 4829, 370, 309, 311, 445, 411, 341, 1164, 300, 321, 434, 4571], "temperature": 0.0, "avg_logprob": -0.0813133300296844, "compression_ratio": 1.456043956043956, "no_speech_prob": 6.0487950577226e-06}, {"id": 183, "seek": 133320, "start": 1339.96, "end": 1345.92, "text": " you now it was a master's elective course so it's not something you'll zip through in", "tokens": [291, 586, 309, 390, 257, 4505, 311, 2185, 488, 1164, 370, 309, 311, 406, 746, 291, 603, 20730, 807, 294], "temperature": 0.0, "avg_logprob": -0.0813133300296844, "compression_ratio": 1.456043956043956, "no_speech_prob": 6.0487950577226e-06}, {"id": 184, "seek": 133320, "start": 1345.92, "end": 1355.28, "text": " an afternoon but you can certainly jump into the SVD notebooks for example and particularly", "tokens": [364, 6499, 457, 291, 393, 3297, 3012, 666, 264, 31910, 35, 43782, 337, 1365, 293, 4098], "temperature": 0.0, "avg_logprob": -0.0813133300296844, "compression_ratio": 1.456043956043956, "no_speech_prob": 6.0487950577226e-06}, {"id": 185, "seek": 135528, "start": 1355.28, "end": 1369.04, "text": " randomized SVD or just like randomized algorithms and data structures this is something that", "tokens": [38513, 31910, 35, 420, 445, 411, 38513, 14642, 293, 1412, 9227, 341, 307, 746, 300], "temperature": 0.0, "avg_logprob": -0.1035885317572232, "compression_ratio": 1.563953488372093, "no_speech_prob": 1.7777943867258728e-05}, {"id": 186, "seek": 135528, "start": 1369.04, "end": 1374.74, "text": " few people that you work with will be familiar with it's just something that hasn't been", "tokens": [1326, 561, 300, 291, 589, 365, 486, 312, 4963, 365, 309, 311, 445, 746, 300, 6132, 380, 668], "temperature": 0.0, "avg_logprob": -0.1035885317572232, "compression_ratio": 1.563953488372093, "no_speech_prob": 1.7777943867258728e-05}, {"id": 187, "seek": 135528, "start": 1374.74, "end": 1381.3999999999999, "text": " widely taught it's starting to change but the vast majority of people who are that kind", "tokens": [13371, 5928, 309, 311, 2891, 281, 1319, 457, 264, 8369, 6286, 295, 561, 567, 366, 300, 733], "temperature": 0.0, "avg_logprob": -0.1035885317572232, "compression_ratio": 1.563953488372093, "no_speech_prob": 1.7777943867258728e-05}, {"id": 188, "seek": 138140, "start": 1381.4, "end": 1385.92, "text": " of management level so they've been out of university for a few years probably won't", "tokens": [295, 4592, 1496, 370, 436, 600, 668, 484, 295, 5454, 337, 257, 1326, 924, 1391, 1582, 380], "temperature": 0.0, "avg_logprob": -0.06453007537049132, "compression_ratio": 1.6255707762557077, "no_speech_prob": 2.1444089725264348e-05}, {"id": 189, "seek": 138140, "start": 1385.92, "end": 1392.1200000000001, "text": " have come across randomized algorithms and data structures but the basic idea as Rachel", "tokens": [362, 808, 2108, 38513, 14642, 293, 1412, 9227, 457, 264, 3875, 1558, 382, 14246], "temperature": 0.0, "avg_logprob": -0.06453007537049132, "compression_ratio": 1.6255707762557077, "no_speech_prob": 2.1444089725264348e-05}, {"id": 190, "seek": 138140, "start": 1392.1200000000001, "end": 1399.92, "text": " mentioned is that you can take a matrix and replace it with one with far fewer columns", "tokens": [2835, 307, 300, 291, 393, 747, 257, 8141, 293, 7406, 309, 365, 472, 365, 1400, 13366, 13766], "temperature": 0.0, "avg_logprob": -0.06453007537049132, "compression_ratio": 1.6255707762557077, "no_speech_prob": 2.1444089725264348e-05}, {"id": 191, "seek": 138140, "start": 1399.92, "end": 1406.0400000000002, "text": " by multiplying it by a random matrix and then do whatever you're trying to do to that multiplied", "tokens": [538, 30955, 309, 538, 257, 4974, 8141, 293, 550, 360, 2035, 291, 434, 1382, 281, 360, 281, 300, 17207], "temperature": 0.0, "avg_logprob": -0.06453007537049132, "compression_ratio": 1.6255707762557077, "no_speech_prob": 2.1444089725264348e-05}, {"id": 192, "seek": 140604, "start": 1406.04, "end": 1412.6399999999999, "text": " out version and you'll get roughly the same result and there are ways to make it even", "tokens": [484, 3037, 293, 291, 603, 483, 9810, 264, 912, 1874, 293, 456, 366, 2098, 281, 652, 309, 754], "temperature": 0.0, "avg_logprob": -0.10802529288119957, "compression_ratio": 1.5739644970414202, "no_speech_prob": 3.763499989872798e-05}, {"id": 193, "seek": 140604, "start": 1412.6399999999999, "end": 1420.36, "text": " a little bit better than than just the random multiplication it's that it's a super surprising", "tokens": [257, 707, 857, 1101, 813, 813, 445, 264, 4974, 27290, 309, 311, 300, 309, 311, 257, 1687, 8830], "temperature": 0.0, "avg_logprob": -0.10802529288119957, "compression_ratio": 1.5739644970414202, "no_speech_prob": 3.763499989872798e-05}, {"id": 194, "seek": 140604, "start": 1420.36, "end": 1427.8999999999999, "text": " and counterintuitive result but something you can use to speed up many things by many", "tokens": [293, 5682, 686, 48314, 1874, 457, 746, 291, 393, 764, 281, 3073, 493, 867, 721, 538, 867], "temperature": 0.0, "avg_logprob": -0.10802529288119957, "compression_ratio": 1.5739644970414202, "no_speech_prob": 3.763499989872798e-05}, {"id": 195, "seek": 142790, "start": 1427.9, "end": 1437.0800000000002, "text": " orders of magnitude and in general there are many randomized algorithms and randomized", "tokens": [9470, 295, 15668, 293, 294, 2674, 456, 366, 867, 38513, 14642, 293, 38513], "temperature": 0.0, "avg_logprob": -0.08210289036786114, "compression_ratio": 1.5662650602409638, "no_speech_prob": 3.0415799301408697e-06}, {"id": 196, "seek": 142790, "start": 1437.0800000000002, "end": 1446.76, "text": " data structures probably the one that will be the most widely known and widely used is", "tokens": [1412, 9227, 1391, 264, 472, 300, 486, 312, 264, 881, 13371, 2570, 293, 13371, 1143, 307], "temperature": 0.0, "avg_logprob": -0.08210289036786114, "compression_ratio": 1.5662650602409638, "no_speech_prob": 3.0415799301408697e-06}, {"id": 197, "seek": 142790, "start": 1446.76, "end": 1453.3600000000001, "text": " called the bloom filter which is one of the things that Rachel covers but it's covered", "tokens": [1219, 264, 26899, 6608, 597, 307, 472, 295, 264, 721, 300, 14246, 10538, 457, 309, 311, 5343], "temperature": 0.0, "avg_logprob": -0.08210289036786114, "compression_ratio": 1.5662650602409638, "no_speech_prob": 3.0415799301408697e-06}, {"id": 198, "seek": 145336, "start": 1453.36, "end": 1460.8799999999999, "text": " in lots and lots of places bloom filters are used for example in your web browser they're", "tokens": [294, 3195, 293, 3195, 295, 3190, 26899, 15995, 366, 1143, 337, 1365, 294, 428, 3670, 11185, 436, 434], "temperature": 0.0, "avg_logprob": -0.11787553628285725, "compression_ratio": 1.65625, "no_speech_prob": 8.267752491519786e-06}, {"id": 199, "seek": 145336, "start": 1460.8799999999999, "end": 1469.24, "text": " a probabilistic so randomized data structure which tell you whether something is a member", "tokens": [257, 31959, 3142, 370, 38513, 1412, 3877, 597, 980, 291, 1968, 746, 307, 257, 4006], "temperature": 0.0, "avg_logprob": -0.11787553628285725, "compression_ratio": 1.65625, "no_speech_prob": 8.267752491519786e-06}, {"id": 200, "seek": 145336, "start": 1469.24, "end": 1477.12, "text": " of a set but they only reliably tell you if something is not in a set if something is", "tokens": [295, 257, 992, 457, 436, 787, 49927, 980, 291, 498, 746, 307, 406, 294, 257, 992, 498, 746, 307], "temperature": 0.0, "avg_logprob": -0.11787553628285725, "compression_ratio": 1.65625, "no_speech_prob": 8.267752491519786e-06}, {"id": 201, "seek": 147712, "start": 1477.12, "end": 1484.8799999999999, "text": " in the set it just returns a maybe and so your web browser uses it for things like oh", "tokens": [294, 264, 992, 309, 445, 11247, 257, 1310, 293, 370, 428, 3670, 11185, 4960, 309, 337, 721, 411, 1954], "temperature": 0.0, "avg_logprob": -0.11469074574912466, "compression_ratio": 1.7676767676767677, "no_speech_prob": 1.2411337593221106e-05}, {"id": 202, "seek": 147712, "start": 1484.8799999999999, "end": 1491.8, "text": " is this from a blocked domain and so it can very quickly use a really small approximate", "tokens": [307, 341, 490, 257, 15470, 9274, 293, 370, 309, 393, 588, 2661, 764, 257, 534, 1359, 30874], "temperature": 0.0, "avg_logprob": -0.11469074574912466, "compression_ratio": 1.7676767676767677, "no_speech_prob": 1.2411337593221106e-05}, {"id": 203, "seek": 147712, "start": 1491.8, "end": 1497.6399999999999, "text": " data structure which would return a response oh maybe this is a blocked domain and so like", "tokens": [1412, 3877, 597, 576, 2736, 257, 4134, 1954, 1310, 341, 307, 257, 15470, 9274, 293, 370, 411], "temperature": 0.0, "avg_logprob": -0.11469074574912466, "compression_ratio": 1.7676767676767677, "no_speech_prob": 1.2411337593221106e-05}, {"id": 204, "seek": 147712, "start": 1497.6399999999999, "end": 1501.54, "text": " ninety nine point nine nine percent of the time it's not and it's confident that it's", "tokens": [25063, 4949, 935, 4949, 4949, 3043, 295, 264, 565, 309, 311, 406, 293, 309, 311, 6679, 300, 309, 311], "temperature": 0.0, "avg_logprob": -0.11469074574912466, "compression_ratio": 1.7676767676767677, "no_speech_prob": 1.2411337593221106e-05}, {"id": 205, "seek": 150154, "start": 1501.54, "end": 1508.3, "text": " if it's not that a bloom filter tells you 100% certainly and if it is then it can check", "tokens": [498, 309, 311, 406, 300, 257, 26899, 6608, 5112, 291, 2319, 4, 3297, 293, 498, 309, 307, 550, 309, 393, 1520], "temperature": 0.0, "avg_logprob": -0.12050488687330677, "compression_ratio": 1.5081967213114753, "no_speech_prob": 5.338092250894988e-06}, {"id": 206, "seek": 150154, "start": 1508.3, "end": 1516.34, "text": " slowly you know through an online system whether it really is or not so probabilistic and randomized", "tokens": [5692, 291, 458, 807, 364, 2950, 1185, 1968, 309, 534, 307, 420, 406, 370, 31959, 3142, 293, 38513], "temperature": 0.0, "avg_logprob": -0.12050488687330677, "compression_ratio": 1.5081967213114753, "no_speech_prob": 5.338092250894988e-06}, {"id": 207, "seek": 150154, "start": 1516.34, "end": 1522.68, "text": " data structures and algorithms in general is super cool and randomized SVD is certainly", "tokens": [1412, 9227, 293, 14642, 294, 2674, 307, 1687, 1627, 293, 38513, 31910, 35, 307, 3297], "temperature": 0.0, "avg_logprob": -0.12050488687330677, "compression_ratio": 1.5081967213114753, "no_speech_prob": 5.338092250894988e-06}, {"id": 208, "seek": 152268, "start": 1522.68, "end": 1532.8, "text": " one of those super cool ones so then the third area is transfer learning and specifically", "tokens": [472, 295, 729, 1687, 1627, 2306, 370, 550, 264, 2636, 1859, 307, 5003, 2539, 293, 4682], "temperature": 0.0, "avg_logprob": -0.12175771352407094, "compression_ratio": 1.5789473684210527, "no_speech_prob": 4.495080247579608e-06}, {"id": 209, "seek": 152268, "start": 1532.8, "end": 1545.04, "text": " transfer learning for deep neural networks now it's a bit tricky because transfer learning", "tokens": [5003, 2539, 337, 2452, 18161, 9590, 586, 309, 311, 257, 857, 12414, 570, 5003, 2539], "temperature": 0.0, "avg_logprob": -0.12175771352407094, "compression_ratio": 1.5789473684210527, "no_speech_prob": 4.495080247579608e-06}, {"id": 210, "seek": 154504, "start": 1545.04, "end": 1553.08, "text": " in NLP is I think most easily taught by saying oh it's just the same as computer vision but", "tokens": [294, 426, 45196, 307, 286, 519, 881, 3612, 5928, 538, 1566, 1954, 309, 311, 445, 264, 912, 382, 3820, 5201, 457], "temperature": 0.0, "avg_logprob": -0.08324099522010953, "compression_ratio": 1.8189300411522633, "no_speech_prob": 2.796798071358353e-05}, {"id": 211, "seek": 154504, "start": 1553.08, "end": 1557.6399999999999, "text": " I know some of you haven't done computer vision transfer learning yet so I think the only", "tokens": [286, 458, 512, 295, 291, 2378, 380, 1096, 3820, 5201, 5003, 2539, 1939, 370, 286, 519, 264, 787], "temperature": 0.0, "avg_logprob": -0.08324099522010953, "compression_ratio": 1.8189300411522633, "no_speech_prob": 2.796798071358353e-05}, {"id": 212, "seek": 154504, "start": 1557.6399999999999, "end": 1560.92, "text": " way to solve this problem is to make sure you do all know how to do computer vision", "tokens": [636, 281, 5039, 341, 1154, 307, 281, 652, 988, 291, 360, 439, 458, 577, 281, 360, 3820, 5201], "temperature": 0.0, "avg_logprob": -0.08324099522010953, "compression_ratio": 1.8189300411522633, "no_speech_prob": 2.796798071358353e-05}, {"id": 213, "seek": 154504, "start": 1560.92, "end": 1565.96, "text": " transfer learning so we're actually going to start there so for those of you that already", "tokens": [5003, 2539, 370, 321, 434, 767, 516, 281, 722, 456, 370, 337, 729, 295, 291, 300, 1217], "temperature": 0.0, "avg_logprob": -0.08324099522010953, "compression_ratio": 1.8189300411522633, "no_speech_prob": 2.796798071358353e-05}, {"id": 214, "seek": 154504, "start": 1565.96, "end": 1571.0, "text": " did the deep learning certificate or have done the online deep learning MOOC this will", "tokens": [630, 264, 2452, 2539, 15953, 420, 362, 1096, 264, 2950, 2452, 2539, 49197, 34, 341, 486], "temperature": 0.0, "avg_logprob": -0.08324099522010953, "compression_ratio": 1.8189300411522633, "no_speech_prob": 2.796798071358353e-05}, {"id": 215, "seek": 157100, "start": 1571.0, "end": 1583.48, "text": " all be review for you so I've added a review CV transfer notebook to the repo which is", "tokens": [439, 312, 3131, 337, 291, 370, 286, 600, 3869, 257, 3131, 22995, 5003, 21060, 281, 264, 49040, 597, 307], "temperature": 0.0, "avg_logprob": -0.12792814345586867, "compression_ratio": 1.52, "no_speech_prob": 1.0783108336909208e-05}, {"id": 216, "seek": 157100, "start": 1583.48, "end": 1591.32, "text": " literally a copy of lesson one of course dot fast at AI which is the same as the University", "tokens": [3736, 257, 5055, 295, 6898, 472, 295, 1164, 5893, 2370, 412, 7318, 597, 307, 264, 912, 382, 264, 3535], "temperature": 0.0, "avg_logprob": -0.12792814345586867, "compression_ratio": 1.52, "no_speech_prob": 1.0783108336909208e-05}, {"id": 217, "seek": 157100, "start": 1591.32, "end": 1599.64, "text": " of San Francisco certificate course but it's kind of the minimal version so let's start", "tokens": [295, 5271, 12279, 15953, 1164, 457, 309, 311, 733, 295, 264, 13206, 3037, 370, 718, 311, 722], "temperature": 0.0, "avg_logprob": -0.12792814345586867, "compression_ratio": 1.52, "no_speech_prob": 1.0783108336909208e-05}, {"id": 218, "seek": 159964, "start": 1599.64, "end": 1605.3200000000002, "text": " by talking about computer vision transfer learning so the starting point to do to use", "tokens": [538, 1417, 466, 3820, 5201, 5003, 2539, 370, 264, 2891, 935, 281, 360, 281, 764], "temperature": 0.0, "avg_logprob": -0.12138575315475464, "compression_ratio": 1.366412213740458, "no_speech_prob": 1.078291461453773e-05}, {"id": 219, "seek": 159964, "start": 1605.3200000000002, "end": 1618.64, "text": " any of these deep learning notebooks as Rachel mentioned is to grab a GPU if you're a student", "tokens": [604, 295, 613, 2452, 2539, 43782, 382, 14246, 2835, 307, 281, 4444, 257, 18407, 498, 291, 434, 257, 3107], "temperature": 0.0, "avg_logprob": -0.12138575315475464, "compression_ratio": 1.366412213740458, "no_speech_prob": 1.078291461453773e-05}, {"id": 220, "seek": 161864, "start": 1618.64, "end": 1630.88, "text": " probably the easiest option is to and cheapest option is that there's a thing called the", "tokens": [1391, 264, 12889, 3614, 307, 281, 293, 29167, 3614, 307, 300, 456, 311, 257, 551, 1219, 264], "temperature": 0.0, "avg_logprob": -0.131006966937672, "compression_ratio": 1.4916666666666667, "no_speech_prob": 1.6962112567853183e-05}, {"id": 221, "seek": 161864, "start": 1630.88, "end": 1643.68, "text": " github student developer pack and if you click get your pack and you say yes I'm a student", "tokens": [290, 355, 836, 3107, 10754, 2844, 293, 498, 291, 2052, 483, 428, 2844, 293, 291, 584, 2086, 286, 478, 257, 3107], "temperature": 0.0, "avg_logprob": -0.131006966937672, "compression_ratio": 1.4916666666666667, "no_speech_prob": 1.6962112567853183e-05}, {"id": 222, "seek": 164368, "start": 1643.68, "end": 1654.0, "text": " just fill in your details then that will get you something like a hundred dollars worth", "tokens": [445, 2836, 294, 428, 4365, 550, 300, 486, 483, 291, 746, 411, 257, 3262, 3808, 3163], "temperature": 0.0, "avg_logprob": -0.11316530755225648, "compression_ratio": 1.435483870967742, "no_speech_prob": 1.4738385289092548e-05}, {"id": 223, "seek": 164368, "start": 1654.0, "end": 1665.04, "text": " or so of AWS credits and then what you can do is you can go to you can go to salamander.ai", "tokens": [420, 370, 295, 17650, 16816, 293, 550, 437, 291, 393, 360, 307, 291, 393, 352, 281, 291, 393, 352, 281, 1845, 335, 4483, 13, 1301], "temperature": 0.0, "avg_logprob": -0.11316530755225648, "compression_ratio": 1.435483870967742, "no_speech_prob": 1.4738385289092548e-05}, {"id": 224, "seek": 166504, "start": 1665.04, "end": 1674.52, "text": " which is a instant jupyter notebook system where you can use those AWS credits to get", "tokens": [597, 307, 257, 9836, 361, 1010, 88, 391, 21060, 1185, 689, 291, 393, 764, 729, 17650, 16816, 281, 483], "temperature": 0.0, "avg_logprob": -0.08498237246558779, "compression_ratio": 1.5146198830409356, "no_speech_prob": 5.338091796147637e-06}, {"id": 225, "seek": 166504, "start": 1674.52, "end": 1682.52, "text": " an instant jupyter notebook and so that's probably the easiest way another really good", "tokens": [364, 9836, 361, 1010, 88, 391, 21060, 293, 370, 300, 311, 1391, 264, 12889, 636, 1071, 534, 665], "temperature": 0.0, "avg_logprob": -0.08498237246558779, "compression_ratio": 1.5146198830409356, "no_speech_prob": 5.338091796147637e-06}, {"id": 226, "seek": 166504, "start": 1682.52, "end": 1692.58, "text": " option is one that we mentioned last time which is Google Cloud GCP and they will give", "tokens": [3614, 307, 472, 300, 321, 2835, 1036, 565, 597, 307, 3329, 8061, 460, 20049, 293, 436, 486, 976], "temperature": 0.0, "avg_logprob": -0.08498237246558779, "compression_ratio": 1.5146198830409356, "no_speech_prob": 5.338091796147637e-06}, {"id": 227, "seek": 169258, "start": 1692.58, "end": 1700.0, "text": " you three hundred dollars of credits everybody they require a little bit more setup but if", "tokens": [291, 1045, 3262, 3808, 295, 16816, 2201, 436, 3651, 257, 707, 857, 544, 8657, 457, 498], "temperature": 0.0, "avg_logprob": -0.1927032592969063, "compression_ratio": 1.3934426229508197, "no_speech_prob": 4.222713414492318e-06}, {"id": 228, "seek": 169258, "start": 1700.0, "end": 1714.9199999999998, "text": " you go to cost up faster AI and click on server setup and click on Google Cloud", "tokens": [291, 352, 281, 2063, 493, 4663, 7318, 293, 2052, 322, 7154, 8657, 293, 2052, 322, 3329, 8061], "temperature": 0.0, "avg_logprob": -0.1927032592969063, "compression_ratio": 1.3934426229508197, "no_speech_prob": 4.222713414492318e-06}, {"id": 229, "seek": 171492, "start": 1714.92, "end": 1723.96, "text": " it's actually still super easy basically you just copy and paste half a dozen lines I guess", "tokens": [309, 311, 767, 920, 1687, 1858, 1936, 291, 445, 5055, 293, 9163, 1922, 257, 16654, 3876, 286, 2041], "temperature": 0.0, "avg_logprob": -0.11444184809555243, "compression_ratio": 1.7183098591549295, "no_speech_prob": 8.139453711919487e-06}, {"id": 230, "seek": 171492, "start": 1723.96, "end": 1730.5600000000002, "text": " but one of the nice things about that is that it spins up a jupyter notebook automatically", "tokens": [457, 472, 295, 264, 1481, 721, 466, 300, 307, 300, 309, 31587, 493, 257, 361, 1010, 88, 391, 21060, 6772], "temperature": 0.0, "avg_logprob": -0.11444184809555243, "compression_ratio": 1.7183098591549295, "no_speech_prob": 8.139453711919487e-06}, {"id": 231, "seek": 171492, "start": 1730.5600000000002, "end": 1736.4, "text": " for you or the GPU drivers are installed automatically for you and even all the fast AI courses are", "tokens": [337, 291, 420, 264, 18407, 11590, 366, 8899, 6772, 337, 291, 293, 754, 439, 264, 2370, 7318, 7712, 366], "temperature": 0.0, "avg_logprob": -0.11444184809555243, "compression_ratio": 1.7183098591549295, "no_speech_prob": 8.139453711919487e-06}, {"id": 232, "seek": 171492, "start": 1736.4, "end": 1744.24, "text": " installed automatically by Google as part of their platform so that's super helpful", "tokens": [8899, 6772, 538, 3329, 382, 644, 295, 641, 3663, 370, 300, 311, 1687, 4961], "temperature": 0.0, "avg_logprob": -0.11444184809555243, "compression_ratio": 1.7183098591549295, "no_speech_prob": 8.139453711919487e-06}, {"id": 233, "seek": 174424, "start": 1744.24, "end": 1752.08, "text": " so those are the two options that I currently think are best it varies over time things", "tokens": [370, 729, 366, 264, 732, 3956, 300, 286, 4362, 519, 366, 1151, 309, 21716, 670, 565, 721], "temperature": 0.0, "avg_logprob": -0.09126804720970892, "compression_ratio": 1.5632183908045978, "no_speech_prob": 8.80082279763883e-06}, {"id": 234, "seek": 174424, "start": 1752.08, "end": 1760.56, "text": " come and go so you can always check cost up faster AI server setup to see what's available", "tokens": [808, 293, 352, 370, 291, 393, 1009, 1520, 2063, 493, 4663, 7318, 7154, 8657, 281, 536, 437, 311, 2435], "temperature": 0.0, "avg_logprob": -0.09126804720970892, "compression_ratio": 1.5632183908045978, "no_speech_prob": 8.80082279763883e-06}, {"id": 235, "seek": 174424, "start": 1760.56, "end": 1767.68, "text": " and you can also see in the using a GPU section our specific recommendations and you can also", "tokens": [293, 291, 393, 611, 536, 294, 264, 1228, 257, 18407, 3541, 527, 2685, 10434, 293, 291, 393, 611], "temperature": 0.0, "avg_logprob": -0.09126804720970892, "compression_ratio": 1.5632183908045978, "no_speech_prob": 8.80082279763883e-06}, {"id": 236, "seek": 176768, "start": 1767.68, "end": 1777.02, "text": " see the differences in pricing okay so so I've got jupyter notebook running and I loaded", "tokens": [536, 264, 7300, 294, 17621, 1392, 370, 370, 286, 600, 658, 361, 1010, 88, 391, 21060, 2614, 293, 286, 13210], "temperature": 0.0, "avg_logprob": -0.1383065195644603, "compression_ratio": 1.5232558139534884, "no_speech_prob": 8.397778401558753e-06}, {"id": 237, "seek": 176768, "start": 1777.02, "end": 1786.3200000000002, "text": " up reviews CP transfer on a GPU machine and I'll first of all give you the super high", "tokens": [493, 10229, 22431, 5003, 322, 257, 18407, 3479, 293, 286, 603, 700, 295, 439, 976, 291, 264, 1687, 1090], "temperature": 0.0, "avg_logprob": -0.1383065195644603, "compression_ratio": 1.5232558139534884, "no_speech_prob": 8.397778401558753e-06}, {"id": 238, "seek": 176768, "start": 1786.3200000000002, "end": 1794.5600000000002, "text": " level view of what we do what we're going to do is that we're going to try to recognize", "tokens": [1496, 1910, 295, 437, 321, 360, 437, 321, 434, 516, 281, 360, 307, 300, 321, 434, 516, 281, 853, 281, 5521], "temperature": 0.0, "avg_logprob": -0.1383065195644603, "compression_ratio": 1.5232558139534884, "no_speech_prob": 8.397778401558753e-06}, {"id": 239, "seek": 179456, "start": 1794.56, "end": 1807.76, "text": " the contents of the Oxford IIT pet data set and this data set contains pets and they are", "tokens": [264, 15768, 295, 264, 24786, 286, 3927, 3817, 1412, 992, 293, 341, 1412, 992, 8306, 19897, 293, 436, 366], "temperature": 0.0, "avg_logprob": -0.14817499559979105, "compression_ratio": 1.4754098360655739, "no_speech_prob": 1.4284979442891199e-05}, {"id": 240, "seek": 179456, "start": 1807.76, "end": 1818.9199999999998, "text": " grouped into these various groups of 37 types of dogs and cats and so when this was created", "tokens": [41877, 666, 613, 3683, 3935, 295, 13435, 3467, 295, 7197, 293, 11111, 293, 370, 562, 341, 390, 2942], "temperature": 0.0, "avg_logprob": -0.14817499559979105, "compression_ratio": 1.4754098360655739, "no_speech_prob": 1.4284979442891199e-05}, {"id": 241, "seek": 181892, "start": 1818.92, "end": 1830.7, "text": " this was considered a extremely brutally difficult data set and so the Oxford University researchers", "tokens": [341, 390, 4888, 257, 4664, 48476, 2252, 1412, 992, 293, 370, 264, 24786, 3535, 10309], "temperature": 0.0, "avg_logprob": -0.10678576586539285, "compression_ratio": 1.5025906735751295, "no_speech_prob": 5.682305527443532e-06}, {"id": 242, "seek": 181892, "start": 1830.7, "end": 1839.8400000000001, "text": " that studied it created a very pet specific model that used a lot of domain specific information", "tokens": [300, 9454, 309, 2942, 257, 588, 3817, 2685, 2316, 300, 1143, 257, 688, 295, 9274, 2685, 1589], "temperature": 0.0, "avg_logprob": -0.10678576586539285, "compression_ratio": 1.5025906735751295, "no_speech_prob": 5.682305527443532e-06}, {"id": 243, "seek": 181892, "start": 1839.8400000000001, "end": 1846.6000000000001, "text": " about animals and they were able to get slightly better than 50% accuracy at recognizing pet", "tokens": [466, 4882, 293, 436, 645, 1075, 281, 483, 4748, 1101, 813, 2625, 4, 14170, 412, 18538, 3817], "temperature": 0.0, "avg_logprob": -0.10678576586539285, "compression_ratio": 1.5025906735751295, "no_speech_prob": 5.682305527443532e-06}, {"id": 244, "seek": 184660, "start": 1846.6, "end": 1860.6799999999998, "text": " breeds this was I remember the except here let's see 2012 okay so that was in 2012 so", "tokens": [41609, 341, 390, 286, 1604, 264, 3993, 510, 718, 311, 536, 9125, 1392, 370, 300, 390, 294, 9125, 370], "temperature": 0.0, "avg_logprob": -0.12204703999989068, "compression_ratio": 1.5602409638554218, "no_speech_prob": 1.8057680790661834e-05}, {"id": 245, "seek": 184660, "start": 1860.6799999999998, "end": 1868.08, "text": " that's the data set we're going to use one of the things that's super helpful when you", "tokens": [300, 311, 264, 1412, 992, 321, 434, 516, 281, 764, 472, 295, 264, 721, 300, 311, 1687, 4961, 562, 291], "temperature": 0.0, "avg_logprob": -0.12204703999989068, "compression_ratio": 1.5602409638554218, "no_speech_prob": 1.8057680790661834e-05}, {"id": 246, "seek": 184660, "start": 1868.08, "end": 1874.32, "text": " use the fast AI library is that there's a lot of data sets built into it so using this", "tokens": [764, 264, 2370, 7318, 6405, 307, 300, 456, 311, 257, 688, 295, 1412, 6352, 3094, 666, 309, 370, 1228, 341], "temperature": 0.0, "avg_logprob": -0.12204703999989068, "compression_ratio": 1.5602409638554218, "no_speech_prob": 1.8057680790661834e-05}, {"id": 247, "seek": 187432, "start": 1874.32, "end": 1879.24, "text": " data set is as simple as using the fast AI and tar data command and passing in the fast", "tokens": [1412, 992, 307, 382, 2199, 382, 1228, 264, 2370, 7318, 293, 3112, 1412, 5622, 293, 8437, 294, 264, 2370], "temperature": 0.0, "avg_logprob": -0.13316749740432907, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.6685636839829385e-05}, {"id": 248, "seek": 187432, "start": 1879.24, "end": 1887.32, "text": " AI URL dot pets constant and you that's it that's all you need to do it or download and", "tokens": [7318, 12905, 5893, 19897, 5754, 293, 291, 300, 311, 309, 300, 311, 439, 291, 643, 281, 360, 309, 420, 5484, 293], "temperature": 0.0, "avg_logprob": -0.13316749740432907, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.6685636839829385e-05}, {"id": 249, "seek": 187432, "start": 1887.32, "end": 1896.0, "text": " unzip the data set for you the this particular data set as you'll find in the readme for", "tokens": [517, 27268, 264, 1412, 992, 337, 291, 264, 341, 1729, 1412, 992, 382, 291, 603, 915, 294, 264, 1401, 1398, 337], "temperature": 0.0, "avg_logprob": -0.13316749740432907, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.6685636839829385e-05}, {"id": 250, "seek": 187432, "start": 1896.0, "end": 1900.6399999999999, "text": " it has two things it's got annotations which is like whereabouts are the pets in it and", "tokens": [309, 575, 732, 721, 309, 311, 658, 25339, 763, 597, 307, 411, 689, 41620, 366, 264, 19897, 294, 309, 293], "temperature": 0.0, "avg_logprob": -0.13316749740432907, "compression_ratio": 1.6923076923076923, "no_speech_prob": 2.6685636839829385e-05}, {"id": 251, "seek": 190064, "start": 1900.64, "end": 1908.4, "text": " then the images themselves so we're just going to grab the images so fast AI has a get image", "tokens": [550, 264, 5267, 2969, 370, 321, 434, 445, 516, 281, 4444, 264, 5267, 370, 2370, 7318, 575, 257, 483, 3256], "temperature": 0.0, "avg_logprob": -0.08504153836158014, "compression_ratio": 1.5798816568047338, "no_speech_prob": 5.682316441379953e-06}, {"id": 252, "seek": 190064, "start": 1908.4, "end": 1917.48, "text": " files function that returns all the images so file names so here's an example so the", "tokens": [7098, 2445, 300, 11247, 439, 264, 5267, 370, 3991, 5288, 370, 510, 311, 364, 1365, 370, 264], "temperature": 0.0, "avg_logprob": -0.08504153836158014, "compression_ratio": 1.5798816568047338, "no_speech_prob": 5.682316441379953e-06}, {"id": 253, "seek": 190064, "start": 1917.48, "end": 1924.8400000000001, "text": " first thing you need to do to create a machine learning model of any kind well supervised", "tokens": [700, 551, 291, 643, 281, 360, 281, 1884, 257, 3479, 2539, 2316, 295, 604, 733, 731, 46533], "temperature": 0.0, "avg_logprob": -0.08504153836158014, "compression_ratio": 1.5798816568047338, "no_speech_prob": 5.682316441379953e-06}, {"id": 254, "seek": 192484, "start": 1924.84, "end": 1934.52, "text": " model so supervised model is a model that has labels as we need labels and in this case", "tokens": [2316, 370, 46533, 2316, 307, 257, 2316, 300, 575, 16949, 382, 321, 643, 16949, 293, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.07440398103099759, "compression_ratio": 1.7635135135135136, "no_speech_prob": 3.785290573432576e-06}, {"id": 255, "seek": 192484, "start": 1934.52, "end": 1945.72, "text": " the label is embedded in the file name so we need some way to label these files based", "tokens": [264, 7645, 307, 16741, 294, 264, 3991, 1315, 370, 321, 643, 512, 636, 281, 7645, 613, 7098, 2361], "temperature": 0.0, "avg_logprob": -0.07440398103099759, "compression_ratio": 1.7635135135135136, "no_speech_prob": 3.785290573432576e-06}, {"id": 256, "seek": 192484, "start": 1945.72, "end": 1954.28, "text": " on finding everything before underscore digit and after forward slash in a file name so", "tokens": [322, 5006, 1203, 949, 37556, 14293, 293, 934, 2128, 17330, 294, 257, 3991, 1315, 370], "temperature": 0.0, "avg_logprob": -0.07440398103099759, "compression_ratio": 1.7635135135135136, "no_speech_prob": 3.785290573432576e-06}, {"id": 257, "seek": 195428, "start": 1954.28, "end": 1962.72, "text": " what would be a good way to do that regular expression so here is the regular expression", "tokens": [437, 576, 312, 257, 665, 636, 281, 360, 300, 3890, 6114, 370, 510, 307, 264, 3890, 6114], "temperature": 0.0, "avg_logprob": -0.0682488203048706, "compression_ratio": 1.512396694214876, "no_speech_prob": 1.406384490110213e-05}, {"id": 258, "seek": 195428, "start": 1962.72, "end": 1976.0, "text": " right capture everything that's not a slash at least one and capture followed by an underscore", "tokens": [558, 7983, 1203, 300, 311, 406, 257, 17330, 412, 1935, 472, 293, 7983, 6263, 538, 364, 37556], "temperature": 0.0, "avg_logprob": -0.0682488203048706, "compression_ratio": 1.512396694214876, "no_speech_prob": 1.406384490110213e-05}, {"id": 259, "seek": 197600, "start": 1976.0, "end": 1988.88, "text": " followed by a digit one or more and this pattern of blah square bracket not blah plus is super", "tokens": [6263, 538, 257, 14293, 472, 420, 544, 293, 341, 5102, 295, 12288, 3732, 16904, 406, 12288, 1804, 307, 1687], "temperature": 0.0, "avg_logprob": -0.11381772207835364, "compression_ratio": 1.7388535031847134, "no_speech_prob": 5.862739271833561e-06}, {"id": 260, "seek": 197600, "start": 1988.88, "end": 1995.04, "text": " super common right because it basically means find the first slash and then find lots of", "tokens": [1687, 2689, 558, 570, 309, 1936, 1355, 915, 264, 700, 17330, 293, 550, 915, 3195, 295], "temperature": 0.0, "avg_logprob": -0.11381772207835364, "compression_ratio": 1.7388535031847134, "no_speech_prob": 5.862739271833561e-06}, {"id": 261, "seek": 197600, "start": 1995.04, "end": 1999.2, "text": " things that aren't slashes right or find a quote mark and then lots of things that aren't", "tokens": [721, 300, 3212, 380, 1061, 12808, 558, 420, 915, 257, 6513, 1491, 293, 550, 3195, 295, 721, 300, 3212, 380], "temperature": 0.0, "avg_logprob": -0.11381772207835364, "compression_ratio": 1.7388535031847134, "no_speech_prob": 5.862739271833561e-06}, {"id": 262, "seek": 199920, "start": 1999.2, "end": 2007.68, "text": " quote marks so this is a useful idiom to become familiar with the other thing to remember", "tokens": [6513, 10640, 370, 341, 307, 257, 4420, 18014, 298, 281, 1813, 4963, 365, 264, 661, 551, 281, 1604], "temperature": 0.0, "avg_logprob": -0.1254599268843488, "compression_ratio": 1.7451923076923077, "no_speech_prob": 7.76688102632761e-06}, {"id": 263, "seek": 199920, "start": 2007.68, "end": 2012.6200000000001, "text": " realize is that if you haven't done much with regular expressions you go there's seats over", "tokens": [4325, 307, 300, 498, 291, 2378, 380, 1096, 709, 365, 3890, 15277, 291, 352, 456, 311, 11069, 670], "temperature": 0.0, "avg_logprob": -0.1254599268843488, "compression_ratio": 1.7451923076923077, "no_speech_prob": 7.76688102632761e-06}, {"id": 264, "seek": 199920, "start": 2012.6200000000001, "end": 2017.8, "text": " here if you want one if you're not familiar with regular expressions is that often the", "tokens": [510, 498, 291, 528, 472, 498, 291, 434, 406, 4963, 365, 3890, 15277, 307, 300, 2049, 264], "temperature": 0.0, "avg_logprob": -0.1254599268843488, "compression_ratio": 1.7451923076923077, "no_speech_prob": 7.76688102632761e-06}, {"id": 265, "seek": 199920, "start": 2017.8, "end": 2026.32, "text": " first time you look at one you know they look confusing and like I'm never going to understand", "tokens": [700, 565, 291, 574, 412, 472, 291, 458, 436, 574, 13181, 293, 411, 286, 478, 1128, 516, 281, 1223], "temperature": 0.0, "avg_logprob": -0.1254599268843488, "compression_ratio": 1.7451923076923077, "no_speech_prob": 7.76688102632761e-06}, {"id": 266, "seek": 202632, "start": 2026.32, "end": 2032.6399999999999, "text": " that but the trick is just to like remember that this is kind of like 12 lines of code", "tokens": [300, 457, 264, 4282, 307, 445, 281, 411, 1604, 300, 341, 307, 733, 295, 411, 2272, 3876, 295, 3089], "temperature": 0.0, "avg_logprob": -0.09200329491586397, "compression_ratio": 1.5892857142857142, "no_speech_prob": 6.6433312895242125e-06}, {"id": 267, "seek": 202632, "start": 2032.6399999999999, "end": 2037.9399999999998, "text": " right so you look at every character one at a time and you just say what's that so a slash", "tokens": [558, 370, 291, 574, 412, 633, 2517, 472, 412, 257, 565, 293, 291, 445, 584, 437, 311, 300, 370, 257, 17330], "temperature": 0.0, "avg_logprob": -0.09200329491586397, "compression_ratio": 1.5892857142857142, "no_speech_prob": 6.6433312895242125e-06}, {"id": 268, "seek": 202632, "start": 2037.9399999999998, "end": 2045.0, "text": " start capturing a group containing not a slash one or more but just look at one letter at", "tokens": [722, 23384, 257, 1594, 19273, 406, 257, 17330, 472, 420, 544, 457, 445, 574, 412, 472, 5063, 412], "temperature": 0.0, "avg_logprob": -0.09200329491586397, "compression_ratio": 1.5892857142857142, "no_speech_prob": 6.6433312895242125e-06}, {"id": 269, "seek": 204500, "start": 2045.0, "end": 2060.28, "text": " a time and then the nice thing is in Jupyter Notebook in Jupyter Notebook you can start", "tokens": [257, 565, 293, 550, 264, 1481, 551, 307, 294, 22125, 88, 391, 11633, 2939, 294, 22125, 88, 391, 11633, 2939, 291, 393, 722], "temperature": 0.0, "avg_logprob": -0.13824991304047254, "compression_ratio": 1.4789915966386555, "no_speech_prob": 5.955044343863847e-06}, {"id": 270, "seek": 204500, "start": 2060.28, "end": 2066.48, "text": " playing right and so like what I would tend to do if I wanted to kind of build a regular", "tokens": [2433, 558, 293, 370, 411, 437, 286, 576, 3928, 281, 360, 498, 286, 1415, 281, 733, 295, 1322, 257, 3890], "temperature": 0.0, "avg_logprob": -0.13824991304047254, "compression_ratio": 1.4789915966386555, "no_speech_prob": 5.955044343863847e-06}, {"id": 271, "seek": 206648, "start": 2066.48, "end": 2075.28, "text": " expression like this or understand this one would be I would start by giving myself something", "tokens": [6114, 411, 341, 420, 1223, 341, 472, 576, 312, 286, 576, 722, 538, 2902, 2059, 746], "temperature": 0.0, "avg_logprob": -0.09757629273429749, "compression_ratio": 1.5847953216374269, "no_speech_prob": 1.3845637113263365e-05}, {"id": 272, "seek": 206648, "start": 2075.28, "end": 2083.76, "text": " to work with so let's grab a file name okay or maybe even turn that into a string rather", "tokens": [281, 589, 365, 370, 718, 311, 4444, 257, 3991, 1315, 1392, 420, 1310, 754, 1261, 300, 666, 257, 6798, 2831], "temperature": 0.0, "avg_logprob": -0.09757629273429749, "compression_ratio": 1.5847953216374269, "no_speech_prob": 1.3845637113263365e-05}, {"id": 273, "seek": 206648, "start": 2083.76, "end": 2088.86, "text": " than a path just to make it even simpler to look at and then we could start doing things", "tokens": [813, 257, 3100, 445, 281, 652, 309, 754, 18587, 281, 574, 412, 293, 550, 321, 727, 722, 884, 721], "temperature": 0.0, "avg_logprob": -0.09757629273429749, "compression_ratio": 1.5847953216374269, "no_speech_prob": 1.3845637113263365e-05}, {"id": 274, "seek": 208886, "start": 2088.86, "end": 2101.98, "text": " like saying re.match actually maybe re.find and then you can start like looking for things", "tokens": [411, 1566, 319, 13, 76, 852, 767, 1310, 319, 13, 35072, 293, 550, 291, 393, 722, 411, 1237, 337, 721], "temperature": 0.0, "avg_logprob": -0.10950977294171443, "compression_ratio": 1.567251461988304, "no_speech_prob": 7.646468475286383e-06}, {"id": 275, "seek": 208886, "start": 2101.98, "end": 2111.7200000000003, "text": " so anytime you look for a regular expression you should pretty much always use the r variant", "tokens": [370, 13038, 291, 574, 337, 257, 3890, 6114, 291, 820, 1238, 709, 1009, 764, 264, 367, 17501], "temperature": 0.0, "avg_logprob": -0.10950977294171443, "compression_ratio": 1.567251461988304, "no_speech_prob": 7.646468475286383e-06}, {"id": 276, "seek": 208886, "start": 2111.7200000000003, "end": 2117.52, "text": " of strings because in Python if you put r before your string it basically says treat", "tokens": [295, 13985, 570, 294, 15329, 498, 291, 829, 367, 949, 428, 6798, 309, 1936, 1619, 2387], "temperature": 0.0, "avg_logprob": -0.10950977294171443, "compression_ratio": 1.567251461988304, "no_speech_prob": 7.646468475286383e-06}, {"id": 277, "seek": 211752, "start": 2117.52, "end": 2132.36, "text": " backslashes as normal backslashes in normal strings in Python a backslash n for example", "tokens": [646, 10418, 12808, 382, 2710, 646, 10418, 12808, 294, 2710, 13985, 294, 15329, 257, 646, 10418, 1299, 297, 337, 1365], "temperature": 0.0, "avg_logprob": -0.1356495672197484, "compression_ratio": 1.6645962732919255, "no_speech_prob": 3.024133729923051e-05}, {"id": 278, "seek": 211752, "start": 2132.36, "end": 2137.98, "text": " means new line when you're working with regular expressions you generally want backslashes", "tokens": [1355, 777, 1622, 562, 291, 434, 1364, 365, 3890, 15277, 291, 5101, 528, 646, 10418, 12808], "temperature": 0.0, "avg_logprob": -0.1356495672197484, "compression_ratio": 1.6645962732919255, "no_speech_prob": 3.024133729923051e-05}, {"id": 279, "seek": 211752, "start": 2137.98, "end": 2145.96, "text": " just to be backslashes so that's what ah means so we could say oh find all the like let's", "tokens": [445, 281, 312, 646, 10418, 12808, 370, 300, 311, 437, 3716, 1355, 370, 321, 727, 584, 1954, 915, 439, 264, 411, 718, 311], "temperature": 0.0, "avg_logprob": -0.1356495672197484, "compression_ratio": 1.6645962732919255, "no_speech_prob": 3.024133729923051e-05}, {"id": 280, "seek": 214596, "start": 2145.96, "end": 2158.28, "text": " see what we find if we look for zero to nine for example that so you can start like exploring", "tokens": [536, 437, 321, 915, 498, 321, 574, 337, 4018, 281, 4949, 337, 1365, 300, 370, 291, 393, 722, 411, 12736], "temperature": 0.0, "avg_logprob": -0.13646494058462288, "compression_ratio": 1.567251461988304, "no_speech_prob": 1.6964160749921575e-05}, {"id": 281, "seek": 214596, "start": 2158.28, "end": 2166.2400000000002, "text": " there's lots of online regular expression tools but and some of them are worth using", "tokens": [456, 311, 3195, 295, 2950, 3890, 6114, 3873, 457, 293, 512, 295, 552, 366, 3163, 1228], "temperature": 0.0, "avg_logprob": -0.13646494058462288, "compression_ratio": 1.567251461988304, "no_speech_prob": 1.6964160749921575e-05}, {"id": 282, "seek": 214596, "start": 2166.2400000000002, "end": 2171.88, "text": " but I don't use any of them because I find Jupyter Notebook is a great regular expression", "tokens": [457, 286, 500, 380, 764, 604, 295, 552, 570, 286, 915, 22125, 88, 391, 11633, 2939, 307, 257, 869, 3890, 6114], "temperature": 0.0, "avg_logprob": -0.13646494058462288, "compression_ratio": 1.567251461988304, "no_speech_prob": 1.6964160749921575e-05}, {"id": 283, "seek": 217188, "start": 2171.88, "end": 2179.8, "text": " tool right so there's like oh is that the same as backslash D oh I guess it is what", "tokens": [2290, 558, 370, 456, 311, 411, 1954, 307, 300, 264, 912, 382, 646, 10418, 1299, 413, 1954, 286, 2041, 309, 307, 437], "temperature": 0.0, "avg_logprob": -0.12035169204076131, "compression_ratio": 1.4166666666666667, "no_speech_prob": 4.006121525890194e-05}, {"id": 284, "seek": 217188, "start": 2179.8, "end": 2186.6800000000003, "text": " if we have two backslash days oh okay you know and so then we can start exploring like", "tokens": [498, 321, 362, 732, 646, 10418, 1299, 1708, 1954, 1392, 291, 458, 293, 370, 550, 321, 393, 722, 12736, 411], "temperature": 0.0, "avg_logprob": -0.12035169204076131, "compression_ratio": 1.4166666666666667, "no_speech_prob": 4.006121525890194e-05}, {"id": 285, "seek": 218668, "start": 2186.68, "end": 2202.7599999999998, "text": " oh well what's what's this thing here finding oh okay all right so you can start to explore", "tokens": [1954, 731, 437, 311, 437, 311, 341, 551, 510, 5006, 1954, 1392, 439, 558, 370, 291, 393, 722, 281, 6839], "temperature": 0.0, "avg_logprob": -0.1409178816753885, "compression_ratio": 1.4833333333333334, "no_speech_prob": 0.00014423916582018137}, {"id": 286, "seek": 218668, "start": 2202.7599999999998, "end": 2213.6, "text": " so then it's like oh let's put a underscore oh looking even better right so by the way", "tokens": [370, 550, 309, 311, 411, 1954, 718, 311, 829, 257, 37556, 1954, 1237, 754, 1101, 558, 370, 538, 264, 636], "temperature": 0.0, "avg_logprob": -0.1409178816753885, "compression_ratio": 1.4833333333333334, "no_speech_prob": 0.00014423916582018137}, {"id": 287, "seek": 221360, "start": 2213.6, "end": 2218.7999999999997, "text": " a slash followed by a bunch of things that aren't a slash followed by underscore also", "tokens": [257, 17330, 6263, 538, 257, 3840, 295, 721, 300, 3212, 380, 257, 17330, 6263, 538, 37556, 611], "temperature": 0.0, "avg_logprob": -0.10175803538118855, "compression_ratio": 1.7563451776649746, "no_speech_prob": 2.840906563505996e-05}, {"id": 288, "seek": 221360, "start": 2218.7999999999997, "end": 2228.06, "text": " matches why is it matching great Pyrenees and not just great that's because it's greedy", "tokens": [10676, 983, 307, 309, 14324, 869, 9953, 32252, 279, 293, 406, 445, 869, 300, 311, 570, 309, 311, 28228], "temperature": 0.0, "avg_logprob": -0.10175803538118855, "compression_ratio": 1.7563451776649746, "no_speech_prob": 2.840906563505996e-05}, {"id": 289, "seek": 221360, "start": 2228.06, "end": 2235.3199999999997, "text": " remember so plus is a wild card and it's going to try and find as many as it can okay so", "tokens": [1604, 370, 1804, 307, 257, 4868, 2920, 293, 309, 311, 516, 281, 853, 293, 915, 382, 867, 382, 309, 393, 1392, 370], "temperature": 0.0, "avg_logprob": -0.10175803538118855, "compression_ratio": 1.7563451776649746, "no_speech_prob": 2.840906563505996e-05}, {"id": 290, "seek": 221360, "start": 2235.3199999999997, "end": 2241.92, "text": " in this case this is as many as it can so why did we put a bunch of digits and then", "tokens": [294, 341, 1389, 341, 307, 382, 867, 382, 309, 393, 370, 983, 630, 321, 829, 257, 3840, 295, 27011, 293, 550], "temperature": 0.0, "avg_logprob": -0.10175803538118855, "compression_ratio": 1.7563451776649746, "no_speech_prob": 2.840906563505996e-05}, {"id": 291, "seek": 224192, "start": 2241.92, "end": 2253.08, "text": " JPEG and then dollar means end of the string so why did we put all that here as well because", "tokens": [508, 5208, 38, 293, 550, 7241, 1355, 917, 295, 264, 6798, 370, 983, 630, 321, 829, 439, 300, 510, 382, 731, 570], "temperature": 0.0, "avg_logprob": -0.0748949470100822, "compression_ratio": 1.6527777777777777, "no_speech_prob": 5.014707312511746e-06}, {"id": 292, "seek": 224192, "start": 2253.08, "end": 2258.2000000000003, "text": " I think it's a good idea to like double check things are formatted the way you thought they", "tokens": [286, 519, 309, 311, 257, 665, 1558, 281, 411, 3834, 1520, 721, 366, 1254, 32509, 264, 636, 291, 1194, 436], "temperature": 0.0, "avg_logprob": -0.0748949470100822, "compression_ratio": 1.6527777777777777, "no_speech_prob": 5.014707312511746e-06}, {"id": 293, "seek": 224192, "start": 2258.2000000000003, "end": 2264.64, "text": " are so it would give us an error if it failed to find something so for example if one of", "tokens": [366, 370, 309, 576, 976, 505, 364, 6713, 498, 309, 7612, 281, 915, 746, 370, 337, 1365, 498, 472, 295], "temperature": 0.0, "avg_logprob": -0.0748949470100822, "compression_ratio": 1.6527777777777777, "no_speech_prob": 5.014707312511746e-06}, {"id": 294, "seek": 224192, "start": 2264.64, "end": 2270.04, "text": " the things was actually a PNG you know it would give us an error saying this didn't", "tokens": [264, 721, 390, 767, 257, 430, 30237, 291, 458, 309, 576, 976, 505, 364, 6713, 1566, 341, 994, 380], "temperature": 0.0, "avg_logprob": -0.0748949470100822, "compression_ratio": 1.6527777777777777, "no_speech_prob": 5.014707312511746e-06}, {"id": 295, "seek": 227004, "start": 2270.04, "end": 2277.2799999999997, "text": " match so it's a good idea to be you know as clear to Python as possible about what it", "tokens": [2995, 370, 309, 311, 257, 665, 1558, 281, 312, 291, 458, 382, 1850, 281, 15329, 382, 1944, 466, 437, 309], "temperature": 0.0, "avg_logprob": -0.08599463850259781, "compression_ratio": 1.4914285714285713, "no_speech_prob": 8.530076229362749e-06}, {"id": 296, "seek": 227004, "start": 2277.2799999999997, "end": 2286.7599999999998, "text": " is you're looking for so fast AI has a labeling thing which can find something from a name", "tokens": [307, 291, 434, 1237, 337, 370, 2370, 7318, 575, 257, 40244, 551, 597, 393, 915, 746, 490, 257, 1315], "temperature": 0.0, "avg_logprob": -0.08599463850259781, "compression_ratio": 1.4914285714285713, "no_speech_prob": 8.530076229362749e-06}, {"id": 297, "seek": 227004, "start": 2286.7599999999998, "end": 2293.92, "text": " using a regular expression and so you can just pass in the path where the images are", "tokens": [1228, 257, 3890, 6114, 293, 370, 291, 393, 445, 1320, 294, 264, 3100, 689, 264, 5267, 366], "temperature": 0.0, "avg_logprob": -0.08599463850259781, "compression_ratio": 1.4914285714285713, "no_speech_prob": 8.530076229362749e-06}, {"id": 298, "seek": 229392, "start": 2293.92, "end": 2301.36, "text": " stored the file names and the pattern to look for okay we won't talk about it now but you", "tokens": [12187, 264, 3991, 5288, 293, 264, 5102, 281, 574, 337, 1392, 321, 1582, 380, 751, 466, 309, 586, 457, 291], "temperature": 0.0, "avg_logprob": -0.07522511838087395, "compression_ratio": 1.5114942528735633, "no_speech_prob": 5.7718498283065856e-06}, {"id": 299, "seek": 229392, "start": 2301.36, "end": 2312.6, "text": " can also ask for image augmentation and you can also normalize so in as you'll see for", "tokens": [393, 611, 1029, 337, 3256, 14501, 19631, 293, 291, 393, 611, 2710, 1125, 370, 294, 382, 291, 603, 536, 337], "temperature": 0.0, "avg_logprob": -0.07522511838087395, "compression_ratio": 1.5114942528735633, "no_speech_prob": 5.7718498283065856e-06}, {"id": 300, "seek": 229392, "start": 2312.6, "end": 2319.7200000000003, "text": " both NLP and computer vision fast AI has a show batch which will display a bit of your", "tokens": [1293, 426, 45196, 293, 3820, 5201, 2370, 7318, 575, 257, 855, 15245, 597, 486, 4674, 257, 857, 295, 428], "temperature": 0.0, "avg_logprob": -0.07522511838087395, "compression_ratio": 1.5114942528735633, "no_speech_prob": 5.7718498283065856e-06}, {"id": 301, "seek": 231972, "start": 2319.72, "end": 2325.0, "text": " data for you and so this is in terms of my workflow this is the first thing I do after", "tokens": [1412, 337, 291, 293, 370, 341, 307, 294, 2115, 295, 452, 20993, 341, 307, 264, 700, 551, 286, 360, 934], "temperature": 0.0, "avg_logprob": -0.09619173859104965, "compression_ratio": 1.6125, "no_speech_prob": 1.4970680240367074e-05}, {"id": 302, "seek": 231972, "start": 2325.0, "end": 2338.12, "text": " I load some data is to look at it okay so basically what we do is we we grab this data", "tokens": [286, 3677, 512, 1412, 307, 281, 574, 412, 309, 1392, 370, 1936, 437, 321, 360, 307, 321, 321, 4444, 341, 1412], "temperature": 0.0, "avg_logprob": -0.09619173859104965, "compression_ratio": 1.6125, "no_speech_prob": 1.4970680240367074e-05}, {"id": 303, "seek": 231972, "start": 2338.12, "end": 2344.4399999999996, "text": " so it's stored in data which contains the training set and the validation set that's", "tokens": [370, 309, 311, 12187, 294, 1412, 597, 8306, 264, 3097, 992, 293, 264, 24071, 992, 300, 311], "temperature": 0.0, "avg_logprob": -0.09619173859104965, "compression_ratio": 1.6125, "no_speech_prob": 1.4970680240367074e-05}, {"id": 304, "seek": 234444, "start": 2344.44, "end": 2352.68, "text": " all done automatically by fast AI and we can create a model which the data plus the model", "tokens": [439, 1096, 6772, 538, 2370, 7318, 293, 321, 393, 1884, 257, 2316, 597, 264, 1412, 1804, 264, 2316], "temperature": 0.0, "avg_logprob": -0.09788484682981995, "compression_ratio": 1.8031088082901554, "no_speech_prob": 5.682388291461393e-06}, {"id": 305, "seek": 234444, "start": 2352.68, "end": 2359.52, "text": " together in fast AI according learner and you can fit the learner and you can fine-tune", "tokens": [1214, 294, 2370, 7318, 4650, 33347, 293, 291, 393, 3318, 264, 33347, 293, 291, 393, 2489, 12, 83, 2613], "temperature": 0.0, "avg_logprob": -0.09788484682981995, "compression_ratio": 1.8031088082901554, "no_speech_prob": 5.682388291461393e-06}, {"id": 306, "seek": 234444, "start": 2359.52, "end": 2366.32, "text": " the learner and at the end you get an error and you can see the error rate we got was", "tokens": [264, 33347, 293, 412, 264, 917, 291, 483, 364, 6713, 293, 291, 393, 536, 264, 6713, 3314, 321, 658, 390], "temperature": 0.0, "avg_logprob": -0.09788484682981995, "compression_ratio": 1.8031088082901554, "no_speech_prob": 5.682388291461393e-06}, {"id": 307, "seek": 234444, "start": 2366.32, "end": 2373.16, "text": " 6.2 percent and so the first thing to kind of note if you haven't done deep learning", "tokens": [1386, 13, 17, 3043, 293, 370, 264, 700, 551, 281, 733, 295, 3637, 498, 291, 2378, 380, 1096, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.09788484682981995, "compression_ratio": 1.8031088082901554, "no_speech_prob": 5.682388291461393e-06}, {"id": 308, "seek": 237316, "start": 2373.16, "end": 2380.92, "text": " before is how astonishingly world-changing it is just in terms of it it's the first thing", "tokens": [949, 307, 577, 35264, 356, 1002, 12, 27123, 309, 307, 445, 294, 2115, 295, 309, 309, 311, 264, 700, 551], "temperature": 0.0, "avg_logprob": -0.13190306723117828, "compression_ratio": 1.489247311827957, "no_speech_prob": 1.644207804929465e-05}, {"id": 309, "seek": 237316, "start": 2380.92, "end": 2386.3599999999997, "text": " that kind of works for complex tasks like this in 2012 the world's best Oxford researchers", "tokens": [300, 733, 295, 1985, 337, 3997, 9608, 411, 341, 294, 9125, 264, 1002, 311, 1151, 24786, 10309], "temperature": 0.0, "avg_logprob": -0.13190306723117828, "compression_ratio": 1.489247311827957, "no_speech_prob": 1.644207804929465e-05}, {"id": 310, "seek": 237316, "start": 2386.3599999999997, "end": 2395.48, "text": " got a little bit better than 50 percent accuracy we've got 90 93 plus percent accuracy 90 nearly", "tokens": [658, 257, 707, 857, 1101, 813, 2625, 3043, 14170, 321, 600, 658, 4289, 28876, 1804, 3043, 14170, 4289, 6217], "temperature": 0.0, "avg_logprob": -0.13190306723117828, "compression_ratio": 1.489247311827957, "no_speech_prob": 1.644207804929465e-05}, {"id": 311, "seek": 239548, "start": 2395.48, "end": 2405.16, "text": " 94 percent accuracy with basically no work and it took about a minute and a half the", "tokens": [30849, 3043, 14170, 365, 1936, 572, 589, 293, 309, 1890, 466, 257, 3456, 293, 257, 1922, 264], "temperature": 0.0, "avg_logprob": -0.10407632986704508, "compression_ratio": 1.4585635359116023, "no_speech_prob": 1.1478444321255665e-05}, {"id": 312, "seek": 239548, "start": 2405.16, "end": 2411.8, "text": " there's a couple of secrets to making this happen the first is obviously that we're using", "tokens": [456, 311, 257, 1916, 295, 14093, 281, 1455, 341, 1051, 264, 700, 307, 2745, 300, 321, 434, 1228], "temperature": 0.0, "avg_logprob": -0.10407632986704508, "compression_ratio": 1.4585635359116023, "no_speech_prob": 1.1478444321255665e-05}, {"id": 313, "seek": 239548, "start": 2411.8, "end": 2418.84, "text": " deep learning which is super flexible so I think you've you've all done confidence before", "tokens": [2452, 2539, 597, 307, 1687, 11358, 370, 286, 519, 291, 600, 291, 600, 439, 1096, 6687, 949], "temperature": 0.0, "avg_logprob": -0.10407632986704508, "compression_ratio": 1.4585635359116023, "no_speech_prob": 1.1478444321255665e-05}, {"id": 314, "seek": 241884, "start": 2418.84, "end": 2425.6400000000003, "text": " is that right anybody not done confidence yet okay so things like convolutional neural", "tokens": [307, 300, 558, 4472, 406, 1096, 6687, 1939, 1392, 370, 721, 411, 45216, 304, 18161], "temperature": 0.0, "avg_logprob": -0.165042164959485, "compression_ratio": 1.6168224299065421, "no_speech_prob": 1.2804998732462991e-05}, {"id": 315, "seek": 241884, "start": 2425.6400000000003, "end": 2430.48, "text": " networks are just really flexible they can have lots and lots of parameters and most", "tokens": [9590, 366, 445, 534, 11358, 436, 393, 362, 3195, 293, 3195, 295, 9834, 293, 881], "temperature": 0.0, "avg_logprob": -0.165042164959485, "compression_ratio": 1.6168224299065421, "no_speech_prob": 1.2804998732462991e-05}, {"id": 316, "seek": 241884, "start": 2430.48, "end": 2439.08, "text": " importantly you can regularize them so that they don't overfit we can run them on GPUs", "tokens": [8906, 291, 393, 3890, 1125, 552, 370, 300, 436, 500, 380, 670, 6845, 321, 393, 1190, 552, 322, 18407, 82], "temperature": 0.0, "avg_logprob": -0.165042164959485, "compression_ratio": 1.6168224299065421, "no_speech_prob": 1.2804998732462991e-05}, {"id": 317, "seek": 241884, "start": 2439.08, "end": 2444.08, "text": " so we can run them in a reasonable amount of time but the second trick going on here is", "tokens": [370, 321, 393, 1190, 552, 294, 257, 10585, 2372, 295, 565, 457, 264, 1150, 4282, 516, 322, 510, 307], "temperature": 0.0, "avg_logprob": -0.165042164959485, "compression_ratio": 1.6168224299065421, "no_speech_prob": 1.2804998732462991e-05}, {"id": 318, "seek": 244408, "start": 2444.08, "end": 2450.92, "text": " that this particular convolutional neural network we use is that by default fast AI", "tokens": [300, 341, 1729, 45216, 304, 18161, 3209, 321, 764, 307, 300, 538, 7576, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.11852565625818764, "compression_ratio": 1.605263157894737, "no_speech_prob": 1.061581315298099e-05}, {"id": 319, "seek": 244408, "start": 2450.92, "end": 2457.92, "text": " if you pass it an architecture that it recognizes like a resonant 34 will load a pre-trained", "tokens": [498, 291, 1320, 309, 364, 9482, 300, 309, 26564, 411, 257, 12544, 394, 12790, 486, 3677, 257, 659, 12, 17227, 2001], "temperature": 0.0, "avg_logprob": -0.11852565625818764, "compression_ratio": 1.605263157894737, "no_speech_prob": 1.061581315298099e-05}, {"id": 320, "seek": 244408, "start": 2457.92, "end": 2466.24, "text": " model so what people used to do in deep learning is that they would generally start with random", "tokens": [2316, 370, 437, 561, 1143, 281, 360, 294, 2452, 2539, 307, 300, 436, 576, 5101, 722, 365, 4974], "temperature": 0.0, "avg_logprob": -0.11852565625818764, "compression_ratio": 1.605263157894737, "no_speech_prob": 1.061581315298099e-05}, {"id": 321, "seek": 244408, "start": 2466.24, "end": 2471.92, "text": " weights right so a deep learning model remember is just you get some input you put it through", "tokens": [17443, 558, 370, 257, 2452, 2539, 2316, 1604, 307, 445, 291, 483, 512, 4846, 291, 829, 309, 807], "temperature": 0.0, "avg_logprob": -0.11852565625818764, "compression_ratio": 1.605263157894737, "no_speech_prob": 1.061581315298099e-05}, {"id": 322, "seek": 247192, "start": 2471.92, "end": 2476.8, "text": " a matrix multiply you replace the negatives with zeros you put it through another matrix", "tokens": [257, 8141, 12972, 291, 7406, 264, 40019, 365, 35193, 291, 829, 309, 807, 1071, 8141], "temperature": 0.0, "avg_logprob": -0.11729816290048453, "compression_ratio": 1.932642487046632, "no_speech_prob": 7.411181286443025e-06}, {"id": 323, "seek": 247192, "start": 2476.8, "end": 2484.8, "text": " multiply you replace the negatives with zeros you do that 18 times and then you do a softmax", "tokens": [12972, 291, 7406, 264, 40019, 365, 35193, 291, 360, 300, 2443, 1413, 293, 550, 291, 360, 257, 2787, 41167], "temperature": 0.0, "avg_logprob": -0.11729816290048453, "compression_ratio": 1.932642487046632, "no_speech_prob": 7.411181286443025e-06}, {"id": 324, "seek": 247192, "start": 2484.8, "end": 2492.2000000000003, "text": " and a loss function just normally cross entropy loss that would be classification right for", "tokens": [293, 257, 4470, 2445, 445, 5646, 3278, 30867, 4470, 300, 576, 312, 21538, 558, 337], "temperature": 0.0, "avg_logprob": -0.11729816290048453, "compression_ratio": 1.932642487046632, "no_speech_prob": 7.411181286443025e-06}, {"id": 325, "seek": 247192, "start": 2492.2000000000003, "end": 2500.4, "text": " vision we don't just use a normal matrix multiply we use one with tied weights called a convolution", "tokens": [5201, 321, 500, 380, 445, 764, 257, 2710, 8141, 12972, 321, 764, 472, 365, 9601, 17443, 1219, 257, 45216], "temperature": 0.0, "avg_logprob": -0.11729816290048453, "compression_ratio": 1.932642487046632, "no_speech_prob": 7.411181286443025e-06}, {"id": 326, "seek": 250040, "start": 2500.4, "end": 2511.1600000000003, "text": " but it's it's just a type of matrix multiplying when you look at it so the same basic idea", "tokens": [457, 309, 311, 309, 311, 445, 257, 2010, 295, 8141, 30955, 562, 291, 574, 412, 309, 370, 264, 912, 3875, 1558], "temperature": 0.0, "avg_logprob": -0.10065948601925012, "compression_ratio": 1.6047904191616766, "no_speech_prob": 1.4970860320318025e-05}, {"id": 327, "seek": 250040, "start": 2511.1600000000003, "end": 2517.8, "text": " and so what do we multiply by or what do we do a convolution with you know the the old", "tokens": [293, 370, 437, 360, 321, 12972, 538, 420, 437, 360, 321, 360, 257, 45216, 365, 291, 458, 264, 264, 1331], "temperature": 0.0, "avg_logprob": -0.10065948601925012, "compression_ratio": 1.6047904191616766, "no_speech_prob": 1.4970860320318025e-05}, {"id": 328, "seek": 250040, "start": 2517.8, "end": 2527.08, "text": " way to do it was with some randomly initialized weights nowadays we're realizing that this", "tokens": [636, 281, 360, 309, 390, 365, 512, 16979, 5883, 1602, 17443, 13434, 321, 434, 16734, 300, 341], "temperature": 0.0, "avg_logprob": -0.10065948601925012, "compression_ratio": 1.6047904191616766, "no_speech_prob": 1.4970860320318025e-05}, {"id": 329, "seek": 252708, "start": 2527.08, "end": 2533.68, "text": " is very rarely what we want randomly initialized weights by definition start out doing basically", "tokens": [307, 588, 13752, 437, 321, 528, 16979, 5883, 1602, 17443, 538, 7123, 722, 484, 884, 1936], "temperature": 0.0, "avg_logprob": -0.07130599021911621, "compression_ratio": 1.71875, "no_speech_prob": 3.089471874773153e-06}, {"id": 330, "seek": 252708, "start": 2533.68, "end": 2539.3199999999997, "text": " nothing useful at all so it takes a long time to train a model that starts with randomly", "tokens": [1825, 4420, 412, 439, 370, 309, 2516, 257, 938, 565, 281, 3847, 257, 2316, 300, 3719, 365, 16979], "temperature": 0.0, "avg_logprob": -0.07130599021911621, "compression_ratio": 1.71875, "no_speech_prob": 3.089471874773153e-06}, {"id": 331, "seek": 252708, "start": 2539.3199999999997, "end": 2549.3199999999997, "text": " initialized weights to do anything interesting so increasingly particularly starting with", "tokens": [5883, 1602, 17443, 281, 360, 1340, 1880, 370, 12980, 4098, 2891, 365], "temperature": 0.0, "avg_logprob": -0.07130599021911621, "compression_ratio": 1.71875, "no_speech_prob": 3.089471874773153e-06}, {"id": 332, "seek": 254932, "start": 2549.32, "end": 2557.32, "text": " research that came out in 2013 research started coming out in 2013 showed that if you start", "tokens": [2132, 300, 1361, 484, 294, 9012, 2132, 1409, 1348, 484, 294, 9012, 4712, 300, 498, 291, 722], "temperature": 0.0, "avg_logprob": -0.08038941621780396, "compression_ratio": 1.7122641509433962, "no_speech_prob": 5.255305950413458e-06}, {"id": 333, "seek": 254932, "start": 2557.32, "end": 2562.8, "text": " with non-random weights and specifically they looked at weights of models that have been", "tokens": [365, 2107, 12, 3699, 298, 17443, 293, 4682, 436, 2956, 412, 17443, 295, 5245, 300, 362, 668], "temperature": 0.0, "avg_logprob": -0.08038941621780396, "compression_ratio": 1.7122641509433962, "no_speech_prob": 5.255305950413458e-06}, {"id": 334, "seek": 254932, "start": 2562.8, "end": 2569.8, "text": " trained on a data set called image net which contains 1.3 million images covering a thousand", "tokens": [8895, 322, 257, 1412, 992, 1219, 3256, 2533, 597, 8306, 502, 13, 18, 2459, 5267, 10322, 257, 4714], "temperature": 0.0, "avg_logprob": -0.08038941621780396, "compression_ratio": 1.7122641509433962, "no_speech_prob": 5.255305950413458e-06}, {"id": 335, "seek": 254932, "start": 2569.8, "end": 2574.48, "text": " different types of object if you start with a model that's not trained with which doesn't", "tokens": [819, 3467, 295, 2657, 498, 291, 722, 365, 257, 2316, 300, 311, 406, 8895, 365, 597, 1177, 380], "temperature": 0.0, "avg_logprob": -0.08038941621780396, "compression_ratio": 1.7122641509433962, "no_speech_prob": 5.255305950413458e-06}, {"id": 336, "seek": 257448, "start": 2574.48, "end": 2581.0, "text": " have random weights but has weights that have already learned to recognize image net and", "tokens": [362, 4974, 17443, 457, 575, 17443, 300, 362, 1217, 3264, 281, 5521, 3256, 2533, 293], "temperature": 0.0, "avg_logprob": -0.09145917892456054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.240799393708585e-06}, {"id": 337, "seek": 257448, "start": 2581.0, "end": 2585.84, "text": " then just train in the normal way so it's literally you train a normal network but instead", "tokens": [550, 445, 3847, 294, 264, 2710, 636, 370, 309, 311, 3736, 291, 3847, 257, 2710, 3209, 457, 2602], "temperature": 0.0, "avg_logprob": -0.09145917892456054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.240799393708585e-06}, {"id": 338, "seek": 257448, "start": 2585.84, "end": 2591.2400000000002, "text": " of randomly initialized weights their weights that you just borrowed from an existing model", "tokens": [295, 16979, 5883, 1602, 17443, 641, 17443, 300, 291, 445, 26805, 490, 364, 6741, 2316], "temperature": 0.0, "avg_logprob": -0.09145917892456054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.240799393708585e-06}, {"id": 339, "seek": 257448, "start": 2591.2400000000002, "end": 2599.28, "text": " it turned out to give the state-of-the-art accuracy on all 13 data sets that the researchers", "tokens": [309, 3574, 484, 281, 976, 264, 1785, 12, 2670, 12, 3322, 12, 446, 14170, 322, 439, 3705, 1412, 6352, 300, 264, 10309], "temperature": 0.0, "avg_logprob": -0.09145917892456054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.240799393708585e-06}, {"id": 340, "seek": 259928, "start": 2599.28, "end": 2605.6800000000003, "text": " in 2013 tried it with and this was quite surprising to a lot of people because the data sets they", "tokens": [294, 9012, 3031, 309, 365, 293, 341, 390, 1596, 8830, 281, 257, 688, 295, 561, 570, 264, 1412, 6352, 436], "temperature": 0.0, "avg_logprob": -0.07766490777333578, "compression_ratio": 1.5777777777777777, "no_speech_prob": 9.818000762606971e-06}, {"id": 341, "seek": 259928, "start": 2605.6800000000003, "end": 2611.4, "text": " tried it with varied a lot they were everything from flower recognition to figuring out what", "tokens": [3031, 309, 365, 22877, 257, 688, 436, 645, 1203, 490, 8617, 11150, 281, 15213, 484, 437], "temperature": 0.0, "avg_logprob": -0.07766490777333578, "compression_ratio": 1.5777777777777777, "no_speech_prob": 9.818000762606971e-06}, {"id": 342, "seek": 259928, "start": 2611.4, "end": 2619.44, "text": " architect created a building to type of sculpture and artwork all kinds of different stuff so", "tokens": [6331, 2942, 257, 2390, 281, 2010, 295, 22972, 293, 15829, 439, 3685, 295, 819, 1507, 370], "temperature": 0.0, "avg_logprob": -0.07766490777333578, "compression_ratio": 1.5777777777777777, "no_speech_prob": 9.818000762606971e-06}, {"id": 343, "seek": 261944, "start": 2619.44, "end": 2630.96, "text": " I'd say the the overall kind of big leap in 2013 was people recognizing that transfer", "tokens": [286, 1116, 584, 264, 264, 4787, 733, 295, 955, 19438, 294, 9012, 390, 561, 18538, 300, 5003], "temperature": 0.0, "avg_logprob": -0.081364905834198, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.3930641620827373e-06}, {"id": 344, "seek": 261944, "start": 2630.96, "end": 2637.2000000000003, "text": " learning was useful even if you didn't have a model to start with which was in your domain", "tokens": [2539, 390, 4420, 754, 498, 291, 994, 380, 362, 257, 2316, 281, 722, 365, 597, 390, 294, 428, 9274], "temperature": 0.0, "avg_logprob": -0.081364905834198, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.3930641620827373e-06}, {"id": 345, "seek": 261944, "start": 2637.2000000000003, "end": 2643.16, "text": " so if you were trying to recognize artworks you didn't have to find somebody that had", "tokens": [370, 498, 291, 645, 1382, 281, 5521, 15829, 82, 291, 994, 380, 362, 281, 915, 2618, 300, 632], "temperature": 0.0, "avg_logprob": -0.081364905834198, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.3930641620827373e-06}, {"id": 346, "seek": 261944, "start": 2643.16, "end": 2647.44, "text": " already trained an artwork model you could start with an image net model and you would", "tokens": [1217, 8895, 364, 15829, 2316, 291, 727, 722, 365, 364, 3256, 2533, 2316, 293, 291, 576], "temperature": 0.0, "avg_logprob": -0.081364905834198, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.3930641620827373e-06}, {"id": 347, "seek": 264744, "start": 2647.44, "end": 2657.36, "text": " still get world-class results so that's why fast AI by default will will always give you", "tokens": [920, 483, 1002, 12, 11665, 3542, 370, 300, 311, 983, 2370, 7318, 538, 7576, 486, 486, 1009, 976, 291], "temperature": 0.0, "avg_logprob": -0.06603103970724439, "compression_ratio": 1.5680473372781065, "no_speech_prob": 6.540353297168622e-06}, {"id": 348, "seek": 264744, "start": 2657.36, "end": 2664.56, "text": " a pre-trained model when you start training so here when we say learn is a convolutional", "tokens": [257, 659, 12, 17227, 2001, 2316, 562, 291, 722, 3097, 370, 510, 562, 321, 584, 1466, 307, 257, 45216, 304], "temperature": 0.0, "avg_logprob": -0.06603103970724439, "compression_ratio": 1.5680473372781065, "no_speech_prob": 6.540353297168622e-06}, {"id": 349, "seek": 264744, "start": 2664.56, "end": 2670.6, "text": " neural network learner that's going to train on the data that we just provided training", "tokens": [18161, 3209, 33347, 300, 311, 516, 281, 3847, 322, 264, 1412, 300, 321, 445, 5649, 3097], "temperature": 0.0, "avg_logprob": -0.06603103970724439, "compression_ratio": 1.5680473372781065, "no_speech_prob": 6.540353297168622e-06}, {"id": 350, "seek": 267060, "start": 2670.6, "end": 2678.36, "text": " a resident 34 model the first thing it'll do is if you haven't run this before is it'll", "tokens": [257, 10832, 12790, 2316, 264, 700, 551, 309, 603, 360, 307, 498, 291, 2378, 380, 1190, 341, 949, 307, 309, 603], "temperature": 0.0, "avg_logprob": -0.09751337491548978, "compression_ratio": 1.592814371257485, "no_speech_prob": 1.6700756532372907e-05}, {"id": 351, "seek": 267060, "start": 2678.36, "end": 2684.04, "text": " go to the internet and download a set of weights that have been trained to make a resident", "tokens": [352, 281, 264, 4705, 293, 5484, 257, 992, 295, 17443, 300, 362, 668, 8895, 281, 652, 257, 10832], "temperature": 0.0, "avg_logprob": -0.09751337491548978, "compression_ratio": 1.592814371257485, "no_speech_prob": 1.6700756532372907e-05}, {"id": 352, "seek": 267060, "start": 2684.04, "end": 2695.8399999999997, "text": " 34 good at recognizing image net pictures and then when you say fit it's going to train", "tokens": [12790, 665, 412, 18538, 3256, 2533, 5242, 293, 550, 562, 291, 584, 3318, 309, 311, 516, 281, 3847], "temperature": 0.0, "avg_logprob": -0.09751337491548978, "compression_ratio": 1.592814371257485, "no_speech_prob": 1.6700756532372907e-05}, {"id": 353, "seek": 269584, "start": 2695.84, "end": 2702.7200000000003, "text": " a neural net in the usual way using stochastic gradient descent or a variant by default fast", "tokens": [257, 18161, 2533, 294, 264, 7713, 636, 1228, 342, 8997, 2750, 16235, 23475, 420, 257, 17501, 538, 7576, 2370], "temperature": 0.0, "avg_logprob": -0.09050641576927829, "compression_ratio": 1.6081081081081081, "no_speech_prob": 6.643309006904019e-06}, {"id": 354, "seek": 269584, "start": 2702.7200000000003, "end": 2711.32, "text": " AI uses a variant called Adam and so you can see that even after one epoch you're down", "tokens": [7318, 4960, 257, 17501, 1219, 7938, 293, 370, 291, 393, 536, 300, 754, 934, 472, 30992, 339, 291, 434, 760], "temperature": 0.0, "avg_logprob": -0.09050641576927829, "compression_ratio": 1.6081081081081081, "no_speech_prob": 6.643309006904019e-06}, {"id": 355, "seek": 269584, "start": 2711.32, "end": 2716.6000000000004, "text": " beneath a 10% error and in this case it's particularly good right from the start because", "tokens": [17149, 257, 1266, 4, 6713, 293, 294, 341, 1389, 309, 311, 4098, 665, 558, 490, 264, 722, 570], "temperature": 0.0, "avg_logprob": -0.09050641576927829, "compression_ratio": 1.6081081081081081, "no_speech_prob": 6.643309006904019e-06}, {"id": 356, "seek": 269584, "start": 2716.6000000000004, "end": 2723.78, "text": " image net actually does contain pictures of animals not all of the breeds of animal here", "tokens": [3256, 2533, 767, 775, 5304, 5242, 295, 4882, 406, 439, 295, 264, 41609, 295, 5496, 510], "temperature": 0.0, "avg_logprob": -0.09050641576927829, "compression_ratio": 1.6081081081081081, "no_speech_prob": 6.643309006904019e-06}, {"id": 357, "seek": 272378, "start": 2723.78, "end": 2732.1600000000003, "text": " but deep learning networks each layer tends to recognize increasingly specific features", "tokens": [457, 2452, 2539, 9590, 1184, 4583, 12258, 281, 5521, 12980, 2685, 4122], "temperature": 0.0, "avg_logprob": -0.1242746098836263, "compression_ratio": 1.6682692307692308, "no_speech_prob": 7.071656909829471e-06}, {"id": 358, "seek": 272378, "start": 2732.1600000000003, "end": 2738.1600000000003, "text": " and so the final layers of image net are very good at recognizing fur and ears and eyes", "tokens": [293, 370, 264, 2572, 7914, 295, 3256, 2533, 366, 588, 665, 412, 18538, 2687, 293, 8798, 293, 2575], "temperature": 0.0, "avg_logprob": -0.1242746098836263, "compression_ratio": 1.6682692307692308, "no_speech_prob": 7.071656909829471e-06}, {"id": 359, "seek": 272378, "start": 2738.1600000000003, "end": 2742.32, "text": " and tail shapes and stuff because it's had to recognize other kinds of animals so it", "tokens": [293, 6838, 10854, 293, 1507, 570, 309, 311, 632, 281, 5521, 661, 3685, 295, 4882, 370, 309], "temperature": 0.0, "avg_logprob": -0.1242746098836263, "compression_ratio": 1.6682692307692308, "no_speech_prob": 7.071656909829471e-06}, {"id": 360, "seek": 272378, "start": 2742.32, "end": 2752.28, "text": " doesn't take much fiddling to make it recognize these particular 37 pet breeds so then", "tokens": [1177, 380, 747, 709, 283, 14273, 1688, 281, 652, 309, 5521, 613, 1729, 13435, 3817, 41609, 370, 550], "temperature": 0.0, "avg_logprob": -0.1242746098836263, "compression_ratio": 1.6682692307692308, "no_speech_prob": 7.071656909829471e-06}, {"id": 361, "seek": 275228, "start": 2752.28, "end": 2763.76, "text": " since we started we being Rachel and I started fast AI a few years ago we actually decided", "tokens": [1670, 321, 1409, 321, 885, 14246, 293, 286, 1409, 2370, 7318, 257, 1326, 924, 2057, 321, 767, 3047], "temperature": 0.0, "avg_logprob": -0.10335165555359888, "compression_ratio": 1.5914634146341464, "no_speech_prob": 4.029422598250676e-06}, {"id": 362, "seek": 275228, "start": 2763.76, "end": 2771.1200000000003, "text": " to kind of focus on transfer learning from the start and one of the things that we got", "tokens": [281, 733, 295, 1879, 322, 5003, 2539, 490, 264, 722, 293, 472, 295, 264, 721, 300, 321, 658], "temperature": 0.0, "avg_logprob": -0.10335165555359888, "compression_ratio": 1.5914634146341464, "no_speech_prob": 4.029422598250676e-06}, {"id": 363, "seek": 275228, "start": 2771.1200000000003, "end": 2777.8, "text": " very interested in was like what what can we do to transfer learn well like there's", "tokens": [588, 3102, 294, 390, 411, 437, 437, 393, 321, 360, 281, 5003, 1466, 731, 411, 456, 311], "temperature": 0.0, "avg_logprob": -0.10335165555359888, "compression_ratio": 1.5914634146341464, "no_speech_prob": 4.029422598250676e-06}, {"id": 364, "seek": 277780, "start": 2777.8, "end": 2783.28, "text": " been very little academic research on that question because it's academic research generally", "tokens": [668, 588, 707, 7778, 2132, 322, 300, 1168, 570, 309, 311, 7778, 2132, 5101], "temperature": 0.0, "avg_logprob": -0.04239295891353062, "compression_ratio": 1.7596153846153846, "no_speech_prob": 8.013390470296144e-06}, {"id": 365, "seek": 277780, "start": 2783.28, "end": 2788.0800000000004, "text": " isn't particularly well aligned with practical realities of what actually matters because", "tokens": [1943, 380, 4098, 731, 17962, 365, 8496, 27785, 295, 437, 767, 7001, 570], "temperature": 0.0, "avg_logprob": -0.04239295891353062, "compression_ratio": 1.7596153846153846, "no_speech_prob": 8.013390470296144e-06}, {"id": 366, "seek": 277780, "start": 2788.0800000000004, "end": 2795.2400000000002, "text": " academics to get cited and stuff they kind of have to work in existing established research", "tokens": [25695, 281, 483, 30134, 293, 1507, 436, 733, 295, 362, 281, 589, 294, 6741, 7545, 2132], "temperature": 0.0, "avg_logprob": -0.04239295891353062, "compression_ratio": 1.7596153846153846, "no_speech_prob": 8.013390470296144e-06}, {"id": 367, "seek": 277780, "start": 2795.2400000000002, "end": 2802.0, "text": " question areas and transfer learning generally hasn't been one of those so we kind of found", "tokens": [1168, 3179, 293, 5003, 2539, 5101, 6132, 380, 668, 472, 295, 729, 370, 321, 733, 295, 1352], "temperature": 0.0, "avg_logprob": -0.04239295891353062, "compression_ratio": 1.7596153846153846, "no_speech_prob": 8.013390470296144e-06}, {"id": 368, "seek": 280200, "start": 2802.0, "end": 2809.76, "text": " the research a bit lacking but when we thought about it we thought it doesn't really make", "tokens": [264, 2132, 257, 857, 20889, 457, 562, 321, 1194, 466, 309, 321, 1194, 309, 1177, 380, 534, 652], "temperature": 0.0, "avg_logprob": -0.11402433309982073, "compression_ratio": 1.5549132947976878, "no_speech_prob": 4.356825229479e-06}, {"id": 369, "seek": 280200, "start": 2809.76, "end": 2815.76, "text": " any sense to train the whole model if you're doing fine-tuning of a pre-trained network", "tokens": [604, 2020, 281, 3847, 264, 1379, 2316, 498, 291, 434, 884, 2489, 12, 83, 37726, 295, 257, 659, 12, 17227, 2001, 3209], "temperature": 0.0, "avg_logprob": -0.11402433309982073, "compression_ratio": 1.5549132947976878, "no_speech_prob": 4.356825229479e-06}, {"id": 370, "seek": 280200, "start": 2815.76, "end": 2824.64, "text": " in the same way because we know that the first layers of a conv net are super super general", "tokens": [294, 264, 912, 636, 570, 321, 458, 300, 264, 700, 7914, 295, 257, 3754, 2533, 366, 1687, 1687, 2674], "temperature": 0.0, "avg_logprob": -0.11402433309982073, "compression_ratio": 1.5549132947976878, "no_speech_prob": 4.356825229479e-06}, {"id": 371, "seek": 282464, "start": 2824.64, "end": 2832.8799999999997, "text": " they find things like particular colors vertical or horizontal lines you know stuff like that", "tokens": [436, 915, 721, 411, 1729, 4577, 9429, 420, 12750, 3876, 291, 458, 1507, 411, 300], "temperature": 0.0, "avg_logprob": -0.09395745638254527, "compression_ratio": 1.704225352112676, "no_speech_prob": 5.422135927801719e-06}, {"id": 372, "seek": 282464, "start": 2832.8799999999997, "end": 2837.8799999999997, "text": " and the later layers are super super specific right the last layer has to find the exact", "tokens": [293, 264, 1780, 7914, 366, 1687, 1687, 2685, 558, 264, 1036, 4583, 575, 281, 915, 264, 1900], "temperature": 0.0, "avg_logprob": -0.09395745638254527, "compression_ratio": 1.704225352112676, "no_speech_prob": 5.422135927801719e-06}, {"id": 373, "seek": 282464, "start": 2837.8799999999997, "end": 2846.48, "text": " thousand categories that we need so we certainly were the only ones thinking this way but us", "tokens": [4714, 10479, 300, 321, 643, 370, 321, 3297, 645, 264, 787, 2306, 1953, 341, 636, 457, 505], "temperature": 0.0, "avg_logprob": -0.09395745638254527, "compression_ratio": 1.704225352112676, "no_speech_prob": 5.422135927801719e-06}, {"id": 374, "seek": 282464, "start": 2846.48, "end": 2851.64, "text": " and others started kind of wondering how do we take advantage of that knowledge because", "tokens": [293, 2357, 1409, 733, 295, 6359, 577, 360, 321, 747, 5002, 295, 300, 3601, 570], "temperature": 0.0, "avg_logprob": -0.09395745638254527, "compression_ratio": 1.704225352112676, "no_speech_prob": 5.422135927801719e-06}, {"id": 375, "seek": 285164, "start": 2851.64, "end": 2858.72, "text": " if we just take a pre-trained network and fine-tune it in the normal way we know that", "tokens": [498, 321, 445, 747, 257, 659, 12, 17227, 2001, 3209, 293, 2489, 12, 83, 2613, 309, 294, 264, 2710, 636, 321, 458, 300], "temperature": 0.0, "avg_logprob": -0.07788987026036343, "compression_ratio": 1.8666666666666667, "no_speech_prob": 9.972778570954688e-06}, {"id": 376, "seek": 285164, "start": 2858.72, "end": 2862.7599999999998, "text": " the last layers are going to be totally wrong for our new domain but the first layers are", "tokens": [264, 1036, 7914, 366, 516, 281, 312, 3879, 2085, 337, 527, 777, 9274, 457, 264, 700, 7914, 366], "temperature": 0.0, "avg_logprob": -0.07788987026036343, "compression_ratio": 1.8666666666666667, "no_speech_prob": 9.972778570954688e-06}, {"id": 377, "seek": 285164, "start": 2862.7599999999998, "end": 2867.2, "text": " probably really good for our new domain and so when the gradients come through it's going", "tokens": [1391, 534, 665, 337, 527, 777, 9274, 293, 370, 562, 264, 2771, 2448, 808, 807, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.07788987026036343, "compression_ratio": 1.8666666666666667, "no_speech_prob": 9.972778570954688e-06}, {"id": 378, "seek": 285164, "start": 2867.2, "end": 2873.68, "text": " to actually screw up the first layers because there's going to be a lot of gradient throughout", "tokens": [281, 767, 5630, 493, 264, 700, 7914, 570, 456, 311, 516, 281, 312, 257, 688, 295, 16235, 3710], "temperature": 0.0, "avg_logprob": -0.07788987026036343, "compression_ratio": 1.8666666666666667, "no_speech_prob": 9.972778570954688e-06}, {"id": 379, "seek": 285164, "start": 2873.68, "end": 2880.2, "text": " the network so one of the things that pretty obviously you might want to do is to train", "tokens": [264, 3209, 370, 472, 295, 264, 721, 300, 1238, 2745, 291, 1062, 528, 281, 360, 307, 281, 3847], "temperature": 0.0, "avg_logprob": -0.07788987026036343, "compression_ratio": 1.8666666666666667, "no_speech_prob": 9.972778570954688e-06}, {"id": 380, "seek": 288020, "start": 2880.2, "end": 2888.06, "text": " the last layers more and in fact there's one particular layer of a transfer learning network", "tokens": [264, 1036, 7914, 544, 293, 294, 1186, 456, 311, 472, 1729, 4583, 295, 257, 5003, 2539, 3209], "temperature": 0.0, "avg_logprob": -0.08390255978232936, "compression_ratio": 1.9944444444444445, "no_speech_prob": 9.223397682944778e-06}, {"id": 381, "seek": 288020, "start": 2888.06, "end": 2894.08, "text": " that's particularly important and that is the final layer and the reason the final layer", "tokens": [300, 311, 4098, 1021, 293, 300, 307, 264, 2572, 4583, 293, 264, 1778, 264, 2572, 4583], "temperature": 0.0, "avg_logprob": -0.08390255978232936, "compression_ratio": 1.9944444444444445, "no_speech_prob": 9.223397682944778e-06}, {"id": 382, "seek": 288020, "start": 2894.08, "end": 2899.56, "text": " is important is because that is the one that actually does have random weights why does", "tokens": [307, 1021, 307, 570, 300, 307, 264, 472, 300, 767, 775, 362, 4974, 17443, 983, 775], "temperature": 0.0, "avg_logprob": -0.08390255978232936, "compression_ratio": 1.9944444444444445, "no_speech_prob": 9.223397682944778e-06}, {"id": 383, "seek": 288020, "start": 2899.56, "end": 2906.2, "text": " it have random weights because the final layer of an image net network is a simple linear", "tokens": [309, 362, 4974, 17443, 570, 264, 2572, 4583, 295, 364, 3256, 2533, 3209, 307, 257, 2199, 8213], "temperature": 0.0, "avg_logprob": -0.08390255978232936, "compression_ratio": 1.9944444444444445, "no_speech_prob": 9.223397682944778e-06}, {"id": 384, "seek": 290620, "start": 2906.2, "end": 2911.9199999999996, "text": " model that takes the penultimate layer weights and projects them through a thousand dimensional", "tokens": [2316, 300, 2516, 264, 3435, 723, 2905, 4583, 17443, 293, 4455, 552, 807, 257, 4714, 18795], "temperature": 0.0, "avg_logprob": -0.13890307964664875, "compression_ratio": 1.9736842105263157, "no_speech_prob": 6.854244929854758e-06}, {"id": 385, "seek": 290620, "start": 2911.9199999999996, "end": 2918.3999999999996, "text": " space right one one vector element for every one of those thousand image net classes so", "tokens": [1901, 558, 472, 472, 8062, 4478, 337, 633, 472, 295, 729, 4714, 3256, 2533, 5359, 370], "temperature": 0.0, "avg_logprob": -0.13890307964664875, "compression_ratio": 1.9736842105263157, "no_speech_prob": 6.854244929854758e-06}, {"id": 386, "seek": 290620, "start": 2918.3999999999996, "end": 2922.8399999999997, "text": " it's like what's the probability that this is a hammer what's the probability that's", "tokens": [309, 311, 411, 437, 311, 264, 8482, 300, 341, 307, 257, 13017, 437, 311, 264, 8482, 300, 311], "temperature": 0.0, "avg_logprob": -0.13890307964664875, "compression_ratio": 1.9736842105263157, "no_speech_prob": 6.854244929854758e-06}, {"id": 387, "seek": 290620, "start": 2922.8399999999997, "end": 2928.2799999999997, "text": " an aeroplane what's the probability that's a sailboat so you get these a thousand activations", "tokens": [364, 11207, 33224, 1929, 437, 311, 264, 8482, 300, 311, 257, 15758, 31883, 370, 291, 483, 613, 257, 4714, 2430, 763], "temperature": 0.0, "avg_logprob": -0.13890307964664875, "compression_ratio": 1.9736842105263157, "no_speech_prob": 6.854244929854758e-06}, {"id": 388, "seek": 290620, "start": 2928.2799999999997, "end": 2934.74, "text": " in the final layer so the final layer of the image net network is useless to us because", "tokens": [294, 264, 2572, 4583, 370, 264, 2572, 4583, 295, 264, 3256, 2533, 3209, 307, 14115, 281, 505, 570], "temperature": 0.0, "avg_logprob": -0.13890307964664875, "compression_ratio": 1.9736842105263157, "no_speech_prob": 6.854244929854758e-06}, {"id": 389, "seek": 293474, "start": 2934.74, "end": 2941.7999999999997, "text": " we're doing 37 pet breeds so fast AI automatically when you're doing transfer learning deletes", "tokens": [321, 434, 884, 13435, 3817, 41609, 370, 2370, 7318, 6772, 562, 291, 434, 884, 5003, 2539, 1103, 37996], "temperature": 0.0, "avg_logprob": -0.08115869686927324, "compression_ratio": 1.6590909090909092, "no_speech_prob": 2.2124986571725458e-05}, {"id": 390, "seek": 293474, "start": 2941.7999999999997, "end": 2949.24, "text": " the last layer and replaces it with a new one and the new last layer has an appropriate", "tokens": [264, 1036, 4583, 293, 46734, 309, 365, 257, 777, 472, 293, 264, 777, 1036, 4583, 575, 364, 6854], "temperature": 0.0, "avg_logprob": -0.08115869686927324, "compression_ratio": 1.6590909090909092, "no_speech_prob": 2.2124986571725458e-05}, {"id": 391, "seek": 293474, "start": 2949.24, "end": 2955.12, "text": " number of outputs for our data which in this case is 37 outputs and it randomly initializes", "tokens": [1230, 295, 23930, 337, 527, 1412, 597, 294, 341, 1389, 307, 13435, 23930, 293, 309, 16979, 5883, 5660], "temperature": 0.0, "avg_logprob": -0.08115869686927324, "compression_ratio": 1.6590909090909092, "no_speech_prob": 2.2124986571725458e-05}, {"id": 392, "seek": 293474, "start": 2955.12, "end": 2962.72, "text": " them so the final layer actually fast AI adds a little mini neural network with two layers", "tokens": [552, 370, 264, 2572, 4583, 767, 2370, 7318, 10860, 257, 707, 8382, 18161, 3209, 365, 732, 7914], "temperature": 0.0, "avg_logprob": -0.08115869686927324, "compression_ratio": 1.6590909090909092, "no_speech_prob": 2.2124986571725458e-05}, {"id": 393, "seek": 296272, "start": 2962.72, "end": 2968.3599999999997, "text": " but same idea the final layer or the final layers are random so we should train them", "tokens": [457, 912, 1558, 264, 2572, 4583, 420, 264, 2572, 7914, 366, 4974, 370, 321, 820, 3847, 552], "temperature": 0.0, "avg_logprob": -0.0790049530739008, "compression_ratio": 1.6941747572815533, "no_speech_prob": 3.8448865780083e-06}, {"id": 394, "seek": 296272, "start": 2968.3599999999997, "end": 2975.24, "text": " first right because they're totally totally wrong to start with so what actually happens", "tokens": [700, 558, 570, 436, 434, 3879, 3879, 2085, 281, 722, 365, 370, 437, 767, 2314], "temperature": 0.0, "avg_logprob": -0.0790049530739008, "compression_ratio": 1.6941747572815533, "no_speech_prob": 3.8448865780083e-06}, {"id": 395, "seek": 296272, "start": 2975.24, "end": 2985.4199999999996, "text": " is when you create a learner in fast AI you can see pre-trained here defaults to true", "tokens": [307, 562, 291, 1884, 257, 33347, 294, 2370, 7318, 291, 393, 536, 659, 12, 17227, 2001, 510, 7576, 82, 281, 2074], "temperature": 0.0, "avg_logprob": -0.0790049530739008, "compression_ratio": 1.6941747572815533, "no_speech_prob": 3.8448865780083e-06}, {"id": 396, "seek": 296272, "start": 2985.4199999999996, "end": 2992.16, "text": " and if pre-trained is true then it will delete the last layer it'll put in a new layer of", "tokens": [293, 498, 659, 12, 17227, 2001, 307, 2074, 550, 309, 486, 12097, 264, 1036, 4583, 309, 603, 829, 294, 257, 777, 4583, 295], "temperature": 0.0, "avg_logprob": -0.0790049530739008, "compression_ratio": 1.6941747572815533, "no_speech_prob": 3.8448865780083e-06}, {"id": 397, "seek": 299216, "start": 2992.16, "end": 2998.3199999999997, "text": " random weights and it does what's called freezing it freezes every layer except the last one", "tokens": [4974, 17443, 293, 309, 775, 437, 311, 1219, 20200, 309, 1737, 12214, 633, 4583, 3993, 264, 1036, 472], "temperature": 0.0, "avg_logprob": -0.07706168248103215, "compression_ratio": 1.6047904191616766, "no_speech_prob": 3.966948042943841e-06}, {"id": 398, "seek": 299216, "start": 2998.3199999999997, "end": 3005.92, "text": " and what freezing does is during the SGD stage is it does not do a weight update for the", "tokens": [293, 437, 20200, 775, 307, 1830, 264, 34520, 35, 3233, 307, 309, 775, 406, 360, 257, 3364, 5623, 337, 264], "temperature": 0.0, "avg_logprob": -0.07706168248103215, "compression_ratio": 1.6047904191616766, "no_speech_prob": 3.966948042943841e-06}, {"id": 399, "seek": 299216, "start": 3005.92, "end": 3016.6, "text": " frozen layers so the in this case we've got say 34 layers right so layers 1 through 33", "tokens": [12496, 7914, 370, 264, 294, 341, 1389, 321, 600, 658, 584, 12790, 7914, 558, 370, 7914, 502, 807, 11816], "temperature": 0.0, "avg_logprob": -0.07706168248103215, "compression_ratio": 1.6047904191616766, "no_speech_prob": 3.966948042943841e-06}, {"id": 400, "seek": 301660, "start": 3016.6, "end": 3023.52, "text": " will not have their weights updated by SGD and layer 34 will and so the amazing thing", "tokens": [486, 406, 362, 641, 17443, 10588, 538, 34520, 35, 293, 4583, 12790, 486, 293, 370, 264, 2243, 551], "temperature": 0.0, "avg_logprob": -0.09326324345153054, "compression_ratio": 1.6064814814814814, "no_speech_prob": 2.6015882212959696e-06}, {"id": 401, "seek": 301660, "start": 3023.52, "end": 3029.48, "text": " is that this actual 15 seconds here that gets us better than 10% error is actually only", "tokens": [307, 300, 341, 3539, 2119, 3949, 510, 300, 2170, 505, 1101, 813, 1266, 4, 6713, 307, 767, 787], "temperature": 0.0, "avg_logprob": -0.09326324345153054, "compression_ratio": 1.6064814814814814, "no_speech_prob": 2.6015882212959696e-06}, {"id": 402, "seek": 301660, "start": 3029.48, "end": 3037.24, "text": " training the last layer right so depending on what system you use either that'll be a", "tokens": [3097, 264, 1036, 4583, 558, 370, 5413, 322, 437, 1185, 291, 764, 2139, 300, 603, 312, 257], "temperature": 0.0, "avg_logprob": -0.09326324345153054, "compression_ratio": 1.6064814814814814, "no_speech_prob": 2.6015882212959696e-06}, {"id": 403, "seek": 301660, "start": 3037.24, "end": 3044.64, "text": " linear layer or a little mini neural net with just one hidden layer so you can see that", "tokens": [8213, 4583, 420, 257, 707, 8382, 18161, 2533, 365, 445, 472, 7633, 4583, 370, 291, 393, 536, 300], "temperature": 0.0, "avg_logprob": -0.09326324345153054, "compression_ratio": 1.6064814814814814, "no_speech_prob": 2.6015882212959696e-06}, {"id": 404, "seek": 304464, "start": 3044.64, "end": 3050.96, "text": " all we need to do to get super good accuracy on this data set was to just train a new little", "tokens": [439, 321, 643, 281, 360, 281, 483, 1687, 665, 14170, 322, 341, 1412, 992, 390, 281, 445, 3847, 257, 777, 707], "temperature": 0.0, "avg_logprob": -0.1086849057397177, "compression_ratio": 1.646788990825688, "no_speech_prob": 2.857278559531551e-06}, {"id": 405, "seek": 304464, "start": 3050.96, "end": 3056.8399999999997, "text": " linear classifier from the existing image net weights for everything up to the penultimate", "tokens": [8213, 1508, 9902, 490, 264, 6741, 3256, 2533, 17443, 337, 1203, 493, 281, 264, 3435, 723, 2905], "temperature": 0.0, "avg_logprob": -0.1086849057397177, "compression_ratio": 1.646788990825688, "no_speech_prob": 2.857278559531551e-06}, {"id": 406, "seek": 304464, "start": 3056.8399999999997, "end": 3062.8799999999997, "text": " layer so that's also why these steps are a little bit faster they're only 15 14 or 15", "tokens": [4583, 370, 300, 311, 611, 983, 613, 4439, 366, 257, 707, 857, 4663, 436, 434, 787, 2119, 3499, 420, 2119], "temperature": 0.0, "avg_logprob": -0.1086849057397177, "compression_ratio": 1.646788990825688, "no_speech_prob": 2.857278559531551e-06}, {"id": 407, "seek": 304464, "start": 3062.8799999999997, "end": 3071.7999999999997, "text": " seconds per epoch so this is this is training the last layer and in transfer learning the", "tokens": [3949, 680, 30992, 339, 370, 341, 307, 341, 307, 3097, 264, 1036, 4583, 293, 294, 5003, 2539, 264], "temperature": 0.0, "avg_logprob": -0.1086849057397177, "compression_ratio": 1.646788990825688, "no_speech_prob": 2.857278559531551e-06}, {"id": 408, "seek": 307180, "start": 3071.8, "end": 3077.48, "text": " idea of kind of like freezing the features of some network and then just training one", "tokens": [1558, 295, 733, 295, 411, 20200, 264, 4122, 295, 512, 3209, 293, 550, 445, 3097, 472], "temperature": 0.0, "avg_logprob": -0.07530877806923607, "compression_ratio": 1.6495327102803738, "no_speech_prob": 5.338114533515181e-06}, {"id": 409, "seek": 307180, "start": 3077.48, "end": 3084.76, "text": " or two linear layers on top of it is pretty common it's pretty popular works pretty well", "tokens": [420, 732, 8213, 7914, 322, 1192, 295, 309, 307, 1238, 2689, 309, 311, 1238, 3743, 1985, 1238, 731], "temperature": 0.0, "avg_logprob": -0.07530877806923607, "compression_ratio": 1.6495327102803738, "no_speech_prob": 5.338114533515181e-06}, {"id": 410, "seek": 307180, "start": 3084.76, "end": 3092.1200000000003, "text": " but it's not as general as the next step which is here where we say unfreeze and what unfreeze", "tokens": [457, 309, 311, 406, 382, 2674, 382, 264, 958, 1823, 597, 307, 510, 689, 321, 584, 3971, 701, 1381, 293, 437, 3971, 701, 1381], "temperature": 0.0, "avg_logprob": -0.07530877806923607, "compression_ratio": 1.6495327102803738, "no_speech_prob": 5.338114533515181e-06}, {"id": 411, "seek": 307180, "start": 3092.1200000000003, "end": 3098.36, "text": " does is it says okay now I want to update the weights of all the layers with SGD so", "tokens": [775, 307, 309, 1619, 1392, 586, 286, 528, 281, 5623, 264, 17443, 295, 439, 264, 7914, 365, 34520, 35, 370], "temperature": 0.0, "avg_logprob": -0.07530877806923607, "compression_ratio": 1.6495327102803738, "no_speech_prob": 5.338114533515181e-06}, {"id": 412, "seek": 309836, "start": 3098.36, "end": 3104.2000000000003, "text": " when we fit now you can say it takes a little longer because it has to back prop through", "tokens": [562, 321, 3318, 586, 291, 393, 584, 309, 2516, 257, 707, 2854, 570, 309, 575, 281, 646, 2365, 807], "temperature": 0.0, "avg_logprob": -0.10903321036809607, "compression_ratio": 1.7868020304568528, "no_speech_prob": 2.332065378141124e-06}, {"id": 413, "seek": 309836, "start": 3104.2000000000003, "end": 3110.52, "text": " more layers and update more weights but it does let the error rate go even further down", "tokens": [544, 7914, 293, 5623, 544, 17443, 457, 309, 775, 718, 264, 6713, 3314, 352, 754, 3052, 760], "temperature": 0.0, "avg_logprob": -0.10903321036809607, "compression_ratio": 1.7868020304568528, "no_speech_prob": 2.332065378141124e-06}, {"id": 414, "seek": 309836, "start": 3110.52, "end": 3120.48, "text": " because it can now change the learning rate of the earlier layers as well so so that's", "tokens": [570, 309, 393, 586, 1319, 264, 2539, 3314, 295, 264, 3071, 7914, 382, 731, 370, 370, 300, 311], "temperature": 0.0, "avg_logprob": -0.10903321036809607, "compression_ratio": 1.7868020304568528, "no_speech_prob": 2.332065378141124e-06}, {"id": 415, "seek": 309836, "start": 3120.48, "end": 3128.32, "text": " trick number one for transfer learning trick number two for transfer learning is here so", "tokens": [4282, 1230, 472, 337, 5003, 2539, 4282, 1230, 732, 337, 5003, 2539, 307, 510, 370], "temperature": 0.0, "avg_logprob": -0.10903321036809607, "compression_ratio": 1.7868020304568528, "no_speech_prob": 2.332065378141124e-06}, {"id": 416, "seek": 312832, "start": 3128.32, "end": 3136.04, "text": " and it's this you know from what you studied already that the key hyperparameter in neural", "tokens": [293, 309, 311, 341, 291, 458, 490, 437, 291, 9454, 1217, 300, 264, 2141, 9848, 2181, 335, 2398, 294, 18161], "temperature": 0.0, "avg_logprob": -0.12549620036837422, "compression_ratio": 1.7918781725888324, "no_speech_prob": 6.643362667091424e-06}, {"id": 417, "seek": 312832, "start": 3136.04, "end": 3142.8, "text": " networks is the learning rate and if you think about it this thing we did where we froze", "tokens": [9590, 307, 264, 2539, 3314, 293, 498, 291, 519, 466, 309, 341, 551, 321, 630, 689, 321, 46077], "temperature": 0.0, "avg_logprob": -0.12549620036837422, "compression_ratio": 1.7918781725888324, "no_speech_prob": 6.643362667091424e-06}, {"id": 418, "seek": 312832, "start": 3142.8, "end": 3147.8, "text": " the first 33 layers was basically identical to setting the learning rate for the first", "tokens": [264, 700, 11816, 7914, 390, 1936, 14800, 281, 3287, 264, 2539, 3314, 337, 264, 700], "temperature": 0.0, "avg_logprob": -0.12549620036837422, "compression_ratio": 1.7918781725888324, "no_speech_prob": 6.643362667091424e-06}, {"id": 419, "seek": 312832, "start": 3147.8, "end": 3154.78, "text": " 33 layers to zero because the learning rate of zero remember the weight update rule is", "tokens": [11816, 7914, 281, 4018, 570, 264, 2539, 3314, 295, 4018, 1604, 264, 3364, 5623, 4978, 307], "temperature": 0.0, "avg_logprob": -0.12549620036837422, "compression_ratio": 1.7918781725888324, "no_speech_prob": 6.643362667091424e-06}, {"id": 420, "seek": 315478, "start": 3154.78, "end": 3162.96, "text": " weights at t plus one is weights at t plus learning rate times gradient the gradient", "tokens": [17443, 412, 256, 1804, 472, 307, 17443, 412, 256, 1804, 2539, 3314, 1413, 16235, 264, 16235], "temperature": 0.0, "avg_logprob": -0.11373279033563076, "compression_ratio": 1.8541666666666667, "no_speech_prob": 1.1911014325960423e-06}, {"id": 421, "seek": 315478, "start": 3162.96, "end": 3168.6400000000003, "text": " of the loss function with respect to the weights so with the learning rate of zero it does", "tokens": [295, 264, 4470, 2445, 365, 3104, 281, 264, 17443, 370, 365, 264, 2539, 3314, 295, 4018, 309, 775], "temperature": 0.0, "avg_logprob": -0.11373279033563076, "compression_ratio": 1.8541666666666667, "no_speech_prob": 1.1911014325960423e-06}, {"id": 422, "seek": 315478, "start": 3168.6400000000003, "end": 3172.94, "text": " nothing what's happening here is something we call discriminative learning rates which", "tokens": [1825, 437, 311, 2737, 510, 307, 746, 321, 818, 20828, 1166, 2539, 6846, 597], "temperature": 0.0, "avg_logprob": -0.11373279033563076, "compression_ratio": 1.8541666666666667, "no_speech_prob": 1.1911014325960423e-06}, {"id": 423, "seek": 315478, "start": 3172.94, "end": 3178.28, "text": " is the kind of next level of nuance over that the very first layer is going to get a learning", "tokens": [307, 264, 733, 295, 958, 1496, 295, 42625, 670, 300, 264, 588, 700, 4583, 307, 516, 281, 483, 257, 2539], "temperature": 0.0, "avg_logprob": -0.11373279033563076, "compression_ratio": 1.8541666666666667, "no_speech_prob": 1.1911014325960423e-06}, {"id": 424, "seek": 317828, "start": 3178.28, "end": 3184.94, "text": " rate of one in x6 because the very first layer needs very very little fine-tuning right it's", "tokens": [3314, 295, 472, 294, 2031, 21, 570, 264, 588, 700, 4583, 2203, 588, 588, 707, 2489, 12, 83, 37726, 558, 309, 311], "temperature": 0.0, "avg_logprob": -0.11574726284674879, "compression_ratio": 1.755813953488372, "no_speech_prob": 1.0952958291454706e-05}, {"id": 425, "seek": 317828, "start": 3184.94, "end": 3189.7200000000003, "text": " very unlikely that you need to find a different way of finding horizontal lines or patches", "tokens": [588, 17518, 300, 291, 643, 281, 915, 257, 819, 636, 295, 5006, 12750, 3876, 420, 26531], "temperature": 0.0, "avg_logprob": -0.11574726284674879, "compression_ratio": 1.755813953488372, "no_speech_prob": 1.0952958291454706e-05}, {"id": 426, "seek": 317828, "start": 3189.7200000000003, "end": 3194.86, "text": " of blue right the very very last layer is going to have a learning rate a hundred times", "tokens": [295, 3344, 558, 264, 588, 588, 1036, 4583, 307, 516, 281, 362, 257, 2539, 3314, 257, 3262, 1413], "temperature": 0.0, "avg_logprob": -0.11574726284674879, "compression_ratio": 1.755813953488372, "no_speech_prob": 1.0952958291454706e-05}, {"id": 427, "seek": 317828, "start": 3194.86, "end": 3202.2000000000003, "text": " higher than that one in x4 and then this particular notation when used in fast AI is how we tell", "tokens": [2946, 813, 300, 472, 294, 2031, 19, 293, 550, 341, 1729, 24657, 562, 1143, 294, 2370, 7318, 307, 577, 321, 980], "temperature": 0.0, "avg_logprob": -0.11574726284674879, "compression_ratio": 1.755813953488372, "no_speech_prob": 1.0952958291454706e-05}, {"id": 428, "seek": 317828, "start": 3202.2000000000003, "end": 3207.32, "text": " fast AI to train all of the layers using a sliding scale of learning rates where the", "tokens": [2370, 7318, 281, 3847, 439, 295, 264, 7914, 1228, 257, 21169, 4373, 295, 2539, 6846, 689, 264], "temperature": 0.0, "avg_logprob": -0.11574726284674879, "compression_ratio": 1.755813953488372, "no_speech_prob": 1.0952958291454706e-05}, {"id": 429, "seek": 320732, "start": 3207.32, "end": 3211.88, "text": " first layer gets this learning rate the last layer gets that learning rate and all the", "tokens": [700, 4583, 2170, 341, 2539, 3314, 264, 1036, 4583, 2170, 300, 2539, 3314, 293, 439, 264], "temperature": 0.0, "avg_logprob": -0.08538677994634064, "compression_ratio": 2.1204819277108435, "no_speech_prob": 4.936960067425389e-06}, {"id": 430, "seek": 320732, "start": 3211.88, "end": 3218.8, "text": " layers in between get equally geometrically spaced learning rates between them so that's", "tokens": [7914, 294, 1296, 483, 12309, 12956, 81, 984, 43766, 2539, 6846, 1296, 552, 370, 300, 311], "temperature": 0.0, "avg_logprob": -0.08538677994634064, "compression_ratio": 2.1204819277108435, "no_speech_prob": 4.936960067425389e-06}, {"id": 431, "seek": 320732, "start": 3218.8, "end": 3227.6000000000004, "text": " called discriminative discriminative learning rates so those are the two tricks right layer", "tokens": [1219, 20828, 1166, 20828, 1166, 2539, 6846, 370, 729, 366, 264, 732, 11733, 558, 4583], "temperature": 0.0, "avg_logprob": -0.08538677994634064, "compression_ratio": 2.1204819277108435, "no_speech_prob": 4.936960067425389e-06}, {"id": 432, "seek": 320732, "start": 3227.6000000000004, "end": 3234.0800000000004, "text": " freezing and discriminative learning rate and with those two things you're basically", "tokens": [20200, 293, 20828, 1166, 2539, 3314, 293, 365, 729, 732, 721, 291, 434, 1936], "temperature": 0.0, "avg_logprob": -0.08538677994634064, "compression_ratio": 2.1204819277108435, "no_speech_prob": 4.936960067425389e-06}, {"id": 433, "seek": 323408, "start": 3234.08, "end": 3243.04, "text": " going to be at the state of the art for transfer learning so what we'll do after the break", "tokens": [516, 281, 312, 412, 264, 1785, 295, 264, 1523, 337, 5003, 2539, 370, 437, 321, 603, 360, 934, 264, 1821], "temperature": 0.0, "avg_logprob": -0.13215069893078926, "compression_ratio": 1.6604651162790698, "no_speech_prob": 7.183158686530078e-06}, {"id": 434, "seek": 323408, "start": 3243.04, "end": 3252.16, "text": " as we'll see what happened when two years ago we tried using those tricks for an LP", "tokens": [382, 321, 603, 536, 437, 2011, 562, 732, 924, 2057, 321, 3031, 1228, 729, 11733, 337, 364, 38095], "temperature": 0.0, "avg_logprob": -0.13215069893078926, "compression_ratio": 1.6604651162790698, "no_speech_prob": 7.183158686530078e-06}, {"id": 435, "seek": 323408, "start": 3252.16, "end": 3256.12, "text": " because I mentioned in 2013 people started realizing from the computer vision the transfer", "tokens": [570, 286, 2835, 294, 9012, 561, 1409, 16734, 490, 264, 3820, 5201, 264, 5003], "temperature": 0.0, "avg_logprob": -0.13215069893078926, "compression_ratio": 1.6604651162790698, "no_speech_prob": 7.183158686530078e-06}, {"id": 436, "seek": 323408, "start": 3256.12, "end": 3262.52, "text": " learning was important and we you know started building as a community some of these tricks", "tokens": [2539, 390, 1021, 293, 321, 291, 458, 1409, 2390, 382, 257, 1768, 512, 295, 613, 11733], "temperature": 0.0, "avg_logprob": -0.13215069893078926, "compression_ratio": 1.6604651162790698, "no_speech_prob": 7.183158686530078e-06}, {"id": 437, "seek": 326252, "start": 3262.52, "end": 3273.7599999999998, "text": " as of two years ago it hadn't been done in NLP still which super super surprised me and", "tokens": [382, 295, 732, 924, 2057, 309, 8782, 380, 668, 1096, 294, 426, 45196, 920, 597, 1687, 1687, 6100, 385, 293], "temperature": 0.0, "avg_logprob": -0.09587788074574571, "compression_ratio": 1.3983739837398375, "no_speech_prob": 3.2190400816034526e-05}, {"id": 438, "seek": 326252, "start": 3273.7599999999998, "end": 3280.52, "text": " we tried it out and it turned out to work super well so let's have a break and let's", "tokens": [321, 3031, 309, 484, 293, 309, 3574, 484, 281, 589, 1687, 731, 370, 718, 311, 362, 257, 1821, 293, 718, 311], "temperature": 0.0, "avg_logprob": -0.09587788074574571, "compression_ratio": 1.3983739837398375, "no_speech_prob": 3.2190400816034526e-05}, {"id": 439, "seek": 328052, "start": 3280.52, "end": 3295.6, "text": " come back at 12.10. Okay let's keep going so I've had a request at the break for a to", "tokens": [808, 646, 412, 2272, 13, 3279, 13, 1033, 718, 311, 1066, 516, 370, 286, 600, 632, 257, 5308, 412, 264, 1821, 337, 257, 281], "temperature": 0.0, "avg_logprob": -0.16301604417654184, "compression_ratio": 1.3181818181818181, "no_speech_prob": 2.1444046069518663e-05}, {"id": 440, "seek": 328052, "start": 3295.6, "end": 3305.24, "text": " go over freezing and unfreezing in a bit more detail so to do that I'm going to refer to", "tokens": [352, 670, 20200, 293, 3971, 701, 8781, 294, 257, 857, 544, 2607, 370, 281, 360, 300, 286, 478, 516, 281, 2864, 281], "temperature": 0.0, "avg_logprob": -0.16301604417654184, "compression_ratio": 1.3181818181818181, "no_speech_prob": 2.1444046069518663e-05}, {"id": 441, "seek": 330524, "start": 3305.24, "end": 3313.2799999999997, "text": " the convolution example spreadsheet from the deep learning course so if you're for all", "tokens": [264, 45216, 1365, 27733, 490, 264, 2452, 2539, 1164, 370, 498, 291, 434, 337, 439], "temperature": 0.0, "avg_logprob": -0.13474397170238006, "compression_ratio": 1.7743589743589743, "no_speech_prob": 6.108141678851098e-05}, {"id": 442, "seek": 330524, "start": 3313.2799999999997, "end": 3317.3199999999997, "text": " of these things are interested in learning them more please check out the deep learning", "tokens": [295, 613, 721, 366, 3102, 294, 2539, 552, 544, 1767, 1520, 484, 264, 2452, 2539], "temperature": 0.0, "avg_logprob": -0.13474397170238006, "compression_ratio": 1.7743589743589743, "no_speech_prob": 6.108141678851098e-05}, {"id": 443, "seek": 330524, "start": 3317.3199999999997, "end": 3322.3999999999996, "text": " course because we can't possibly cover all of deep learning as well as all of NLP in", "tokens": [1164, 570, 321, 393, 380, 6264, 2060, 439, 295, 2452, 2539, 382, 731, 382, 439, 295, 426, 45196, 294], "temperature": 0.0, "avg_logprob": -0.13474397170238006, "compression_ratio": 1.7743589743589743, "no_speech_prob": 6.108141678851098e-05}, {"id": 444, "seek": 330524, "start": 3322.3999999999996, "end": 3328.16, "text": " this course but we're trying to give you a sense of the main pieces this is an example", "tokens": [341, 1164, 457, 321, 434, 1382, 281, 976, 291, 257, 2020, 295, 264, 2135, 3755, 341, 307, 364, 1365], "temperature": 0.0, "avg_logprob": -0.13474397170238006, "compression_ratio": 1.7743589743589743, "no_speech_prob": 6.108141678851098e-05}, {"id": 445, "seek": 332816, "start": 3328.16, "end": 3338.92, "text": " of a number seven from MNIST the popular handwriting recognition data set it contains lots of zeros", "tokens": [295, 257, 1230, 3407, 490, 376, 45, 19756, 264, 3743, 39179, 11150, 1412, 992, 309, 8306, 3195, 295, 35193], "temperature": 0.0, "avg_logprob": -0.1088545476236651, "compression_ratio": 1.536723163841808, "no_speech_prob": 3.647580888355151e-05}, {"id": 446, "seek": 332816, "start": 3338.92, "end": 3346.56, "text": " where the white is and ones where the drawing was and things between the two where it's", "tokens": [689, 264, 2418, 307, 293, 2306, 689, 264, 6316, 390, 293, 721, 1296, 264, 732, 689, 309, 311], "temperature": 0.0, "avg_logprob": -0.1088545476236651, "compression_ratio": 1.536723163841808, "no_speech_prob": 3.647580888355151e-05}, {"id": 447, "seek": 332816, "start": 3346.56, "end": 3351.92, "text": " on the edges and so if we use conditional formatting in Excel you can see the number", "tokens": [322, 264, 8819, 293, 370, 498, 321, 764, 27708, 39366, 294, 19060, 291, 393, 536, 264, 1230], "temperature": 0.0, "avg_logprob": -0.1088545476236651, "compression_ratio": 1.536723163841808, "no_speech_prob": 3.647580888355151e-05}, {"id": 448, "seek": 335192, "start": 3351.92, "end": 3359.64, "text": " seven pop out a convolution is something which simply has a three by three filter like this", "tokens": [3407, 1665, 484, 257, 45216, 307, 746, 597, 2935, 575, 257, 1045, 538, 1045, 6608, 411, 341], "temperature": 0.0, "avg_logprob": -0.12748462725908327, "compression_ratio": 1.6272727272727272, "no_speech_prob": 1.1478346095827874e-05}, {"id": 449, "seek": 335192, "start": 3359.64, "end": 3369.2000000000003, "text": " is a random three by three convolution filter and then the output of the convolution is", "tokens": [307, 257, 4974, 1045, 538, 1045, 45216, 6608, 293, 550, 264, 5598, 295, 264, 45216, 307], "temperature": 0.0, "avg_logprob": -0.12748462725908327, "compression_ratio": 1.6272727272727272, "no_speech_prob": 1.1478346095827874e-05}, {"id": 450, "seek": 336920, "start": 3369.2, "end": 3384.2799999999997, "text": " shown here and as you can see it is specifically it basically contains the result of a three", "tokens": [4898, 510, 293, 382, 291, 393, 536, 309, 307, 4682, 309, 1936, 8306, 264, 1874, 295, 257, 1045], "temperature": 0.0, "avg_logprob": -0.1367583155632019, "compression_ratio": 1.5478260869565217, "no_speech_prob": 9.223069355357438e-06}, {"id": 451, "seek": 336920, "start": 3384.2799999999997, "end": 3390.9199999999996, "text": " by three part of the image dot product with three three by three convolutional kernel", "tokens": [538, 1045, 644, 295, 264, 3256, 5893, 1674, 365, 1045, 1045, 538, 1045, 45216, 304, 28256], "temperature": 0.0, "avg_logprob": -0.1367583155632019, "compression_ratio": 1.5478260869565217, "no_speech_prob": 9.223069355357438e-06}, {"id": 452, "seek": 339092, "start": 3390.92, "end": 3409.6800000000003, "text": " like so so every pixel looks like that and then and then we generally have multiple ones", "tokens": [411, 370, 370, 633, 19261, 1542, 411, 300, 293, 550, 293, 550, 321, 5101, 362, 3866, 2306], "temperature": 0.0, "avg_logprob": -0.07119120084322415, "compression_ratio": 1.4830508474576272, "no_speech_prob": 4.565890776575543e-06}, {"id": 453, "seek": 339092, "start": 3409.6800000000003, "end": 3417.48, "text": " of these randomly created little kernels and each one creates its own output like this", "tokens": [295, 613, 16979, 2942, 707, 23434, 1625, 293, 1184, 472, 7829, 1080, 1065, 5598, 411, 341], "temperature": 0.0, "avg_logprob": -0.07119120084322415, "compression_ratio": 1.4830508474576272, "no_speech_prob": 4.565890776575543e-06}, {"id": 454, "seek": 341748, "start": 3417.48, "end": 3422.06, "text": " and then to make life easier we don't treat them as a bunch of three by three matrices", "tokens": [293, 550, 281, 652, 993, 3571, 321, 500, 380, 2387, 552, 382, 257, 3840, 295, 1045, 538, 1045, 32284], "temperature": 0.0, "avg_logprob": -0.11874095405020364, "compression_ratio": 1.697560975609756, "no_speech_prob": 2.0783263607881963e-05}, {"id": 455, "seek": 341748, "start": 3422.06, "end": 3430.2, "text": " we treat it instead as a three by three by K tensor and so the output then creates a", "tokens": [321, 2387, 309, 2602, 382, 257, 1045, 538, 1045, 538, 591, 40863, 293, 370, 264, 5598, 550, 7829, 257], "temperature": 0.0, "avg_logprob": -0.11874095405020364, "compression_ratio": 1.697560975609756, "no_speech_prob": 2.0783263607881963e-05}, {"id": 456, "seek": 341748, "start": 3430.2, "end": 3434.96, "text": " three dimensional tensor so each of these layers gets less damaged together or if we're", "tokens": [1045, 18795, 40863, 370, 1184, 295, 613, 7914, 2170, 1570, 14080, 1214, 420, 498, 321, 434], "temperature": 0.0, "avg_logprob": -0.11874095405020364, "compression_ratio": 1.697560975609756, "no_speech_prob": 2.0783263607881963e-05}, {"id": 457, "seek": 341748, "start": 3434.96, "end": 3441.08, "text": " doing RGB images rather than black and white we would have a rank four tensor so then we", "tokens": [884, 31231, 5267, 2831, 813, 2211, 293, 2418, 321, 576, 362, 257, 6181, 1451, 40863, 370, 550, 321], "temperature": 0.0, "avg_logprob": -0.11874095405020364, "compression_ratio": 1.697560975609756, "no_speech_prob": 2.0783263607881963e-05}, {"id": 458, "seek": 344108, "start": 3441.08, "end": 3448.88, "text": " take the these outputs and we put them through a non-linearity like relu relu means replace", "tokens": [747, 264, 613, 23930, 293, 321, 829, 552, 807, 257, 2107, 12, 1889, 17409, 411, 1039, 84, 1039, 84, 1355, 7406], "temperature": 0.0, "avg_logprob": -0.12883974611759186, "compression_ratio": 1.639751552795031, "no_speech_prob": 9.721472906676354e-07}, {"id": 459, "seek": 344108, "start": 3448.88, "end": 3456.92, "text": " the negatives with zeros and then we put it through another convolution so here's our", "tokens": [264, 40019, 365, 35193, 293, 550, 321, 829, 309, 807, 1071, 45216, 370, 510, 311, 527], "temperature": 0.0, "avg_logprob": -0.12883974611759186, "compression_ratio": 1.639751552795031, "no_speech_prob": 9.721472906676354e-07}, {"id": 460, "seek": 344108, "start": 3456.92, "end": 3461.4, "text": " second kernel now I'm in this case the input is a rank three tensor rather than a rank", "tokens": [1150, 28256, 586, 286, 478, 294, 341, 1389, 264, 4846, 307, 257, 6181, 1045, 40863, 2831, 813, 257, 6181], "temperature": 0.0, "avg_logprob": -0.12883974611759186, "compression_ratio": 1.639751552795031, "no_speech_prob": 9.721472906676354e-07}, {"id": 461, "seek": 346140, "start": 3461.4, "end": 3471.52, "text": " two tensor so our convolution requires two layers and we've got it's basically the same", "tokens": [732, 40863, 370, 527, 45216, 7029, 732, 7914, 293, 321, 600, 658, 309, 311, 1936, 264, 912], "temperature": 0.0, "avg_logprob": -0.13738063073927356, "compression_ratio": 1.6604938271604939, "no_speech_prob": 9.81818993750494e-06}, {"id": 462, "seek": 346140, "start": 3471.52, "end": 3478.94, "text": " deal so now we're doing a dot product with with this three by three with each of these", "tokens": [2028, 370, 586, 321, 434, 884, 257, 5893, 1674, 365, 365, 341, 1045, 538, 1045, 365, 1184, 295, 613], "temperature": 0.0, "avg_logprob": -0.13738063073927356, "compression_ratio": 1.6604938271604939, "no_speech_prob": 9.81818993750494e-06}, {"id": 463, "seek": 346140, "start": 3478.94, "end": 3489.36, "text": " and adding them together along with this three by three so if this is unclear then yeah please", "tokens": [293, 5127, 552, 1214, 2051, 365, 341, 1045, 538, 1045, 370, 498, 341, 307, 25636, 550, 1338, 1767], "temperature": 0.0, "avg_logprob": -0.13738063073927356, "compression_ratio": 1.6604938271604939, "no_speech_prob": 9.81818993750494e-06}, {"id": 464, "seek": 348936, "start": 3489.36, "end": 3495.52, "text": " check out the deep learning course but that's the basic idea from that we then we do max", "tokens": [1520, 484, 264, 2452, 2539, 1164, 457, 300, 311, 264, 3875, 1558, 490, 300, 321, 550, 321, 360, 11469], "temperature": 0.0, "avg_logprob": -0.07838232782151965, "compression_ratio": 1.835820895522388, "no_speech_prob": 9.97281586023746e-06}, {"id": 465, "seek": 348936, "start": 3495.52, "end": 3501.6, "text": " pooling which we want or we do strive to convolutions and then we do a matrix multiply and we end", "tokens": [7005, 278, 597, 321, 528, 420, 321, 360, 23829, 281, 3754, 15892, 293, 550, 321, 360, 257, 8141, 12972, 293, 321, 917], "temperature": 0.0, "avg_logprob": -0.07838232782151965, "compression_ratio": 1.835820895522388, "no_speech_prob": 9.97281586023746e-06}, {"id": 466, "seek": 348936, "start": 3501.6, "end": 3512.36, "text": " up with a number and the number is the loss we take the derivative of the loss with respect", "tokens": [493, 365, 257, 1230, 293, 264, 1230, 307, 264, 4470, 321, 747, 264, 13760, 295, 264, 4470, 365, 3104], "temperature": 0.0, "avg_logprob": -0.07838232782151965, "compression_ratio": 1.835820895522388, "no_speech_prob": 9.97281586023746e-06}, {"id": 467, "seek": 348936, "start": 3512.36, "end": 3518.92, "text": " to the weights and what that then lets us do is we then can go back and update the weights", "tokens": [281, 264, 17443, 293, 437, 300, 550, 6653, 505, 360, 307, 321, 550, 393, 352, 646, 293, 5623, 264, 17443], "temperature": 0.0, "avg_logprob": -0.07838232782151965, "compression_ratio": 1.835820895522388, "no_speech_prob": 9.97281586023746e-06}, {"id": 468, "seek": 351892, "start": 3518.92, "end": 3525.32, "text": " to be slightly better weights that's what SGD does and so that equation is new weights", "tokens": [281, 312, 4748, 1101, 17443, 300, 311, 437, 34520, 35, 775, 293, 370, 300, 5367, 307, 777, 17443], "temperature": 0.0, "avg_logprob": -0.08225814919722707, "compression_ratio": 1.5853658536585367, "no_speech_prob": 3.138122337986715e-06}, {"id": 469, "seek": 351892, "start": 3525.32, "end": 3532.88, "text": " is whatever the old weights were minus the learning rate times the gradient now the thing", "tokens": [307, 2035, 264, 1331, 17443, 645, 3175, 264, 2539, 3314, 1413, 264, 16235, 586, 264, 551], "temperature": 0.0, "avg_logprob": -0.08225814919722707, "compression_ratio": 1.5853658536585367, "no_speech_prob": 3.138122337986715e-06}, {"id": 470, "seek": 351892, "start": 3532.88, "end": 3544.44, "text": " is that the filter in layer one generally needs very little if any updating because", "tokens": [307, 300, 264, 6608, 294, 4583, 472, 5101, 2203, 588, 707, 498, 604, 25113, 570], "temperature": 0.0, "avg_logprob": -0.08225814919722707, "compression_ratio": 1.5853658536585367, "no_speech_prob": 3.138122337986715e-06}, {"id": 471, "seek": 354444, "start": 3544.44, "end": 3551.32, "text": " it's creates things that kind of find edges and colors and gradients things that are very", "tokens": [309, 311, 7829, 721, 300, 733, 295, 915, 8819, 293, 4577, 293, 2771, 2448, 721, 300, 366, 588], "temperature": 0.0, "avg_logprob": -0.09920592366913218, "compression_ratio": 1.7918781725888324, "no_speech_prob": 1.3925385928814649e-06}, {"id": 472, "seek": 354444, "start": 3551.32, "end": 3558.2000000000003, "text": " very general where else the filters in the later layers generally need lots of updating", "tokens": [588, 2674, 689, 1646, 264, 15995, 294, 264, 1780, 7914, 5101, 643, 3195, 295, 25113], "temperature": 0.0, "avg_logprob": -0.09920592366913218, "compression_ratio": 1.7918781725888324, "no_speech_prob": 1.3925385928814649e-06}, {"id": 473, "seek": 354444, "start": 3558.2000000000003, "end": 3561.68, "text": " because they're finding things that are very specific to the exact task they were trained", "tokens": [570, 436, 434, 5006, 721, 300, 366, 588, 2685, 281, 264, 1900, 5633, 436, 645, 8895], "temperature": 0.0, "avg_logprob": -0.09920592366913218, "compression_ratio": 1.7918781725888324, "no_speech_prob": 1.3925385928814649e-06}, {"id": 474, "seek": 354444, "start": 3561.68, "end": 3573.14, "text": " for so if we set the learning rate for this layer to be like one in x6 it's not going", "tokens": [337, 370, 498, 321, 992, 264, 2539, 3314, 337, 341, 4583, 281, 312, 411, 472, 294, 2031, 21, 309, 311, 406, 516], "temperature": 0.0, "avg_logprob": -0.09920592366913218, "compression_ratio": 1.7918781725888324, "no_speech_prob": 1.3925385928814649e-06}, {"id": 475, "seek": 357314, "start": 3573.14, "end": 3577.52, "text": " to change very much at all right it's going to change very very slowly and then if we", "tokens": [281, 1319, 588, 709, 412, 439, 558, 309, 311, 516, 281, 1319, 588, 588, 5692, 293, 550, 498, 321], "temperature": 0.0, "avg_logprob": -0.09376877169065838, "compression_ratio": 1.864864864864865, "no_speech_prob": 1.4510258552036248e-05}, {"id": 476, "seek": 357314, "start": 3577.52, "end": 3584.2799999999997, "text": " change this one to say make this learning rate say one in x2 for this layer then it's", "tokens": [1319, 341, 472, 281, 584, 652, 341, 2539, 3314, 584, 472, 294, 2031, 17, 337, 341, 4583, 550, 309, 311], "temperature": 0.0, "avg_logprob": -0.09376877169065838, "compression_ratio": 1.864864864864865, "no_speech_prob": 1.4510258552036248e-05}, {"id": 477, "seek": 357314, "start": 3584.2799999999997, "end": 3591.46, "text": " going to change much faster right so that's discriminative learning rates freezing is", "tokens": [516, 281, 1319, 709, 4663, 558, 370, 300, 311, 20828, 1166, 2539, 6846, 20200, 307], "temperature": 0.0, "avg_logprob": -0.09376877169065838, "compression_ratio": 1.864864864864865, "no_speech_prob": 1.4510258552036248e-05}, {"id": 478, "seek": 357314, "start": 3591.46, "end": 3596.52, "text": " just the extreme version of that freezing is basically saying for some subset of layers", "tokens": [445, 264, 8084, 3037, 295, 300, 20200, 307, 1936, 1566, 337, 512, 25993, 295, 7914], "temperature": 0.0, "avg_logprob": -0.09376877169065838, "compression_ratio": 1.864864864864865, "no_speech_prob": 1.4510258552036248e-05}, {"id": 479, "seek": 359652, "start": 3596.52, "end": 3603.96, "text": " let's set the learning rate to zero so they don't get updated at all and specifically", "tokens": [718, 311, 992, 264, 2539, 3314, 281, 4018, 370, 436, 500, 380, 483, 10588, 412, 439, 293, 4682], "temperature": 0.0, "avg_logprob": -0.08342101407605548, "compression_ratio": 1.6933962264150944, "no_speech_prob": 2.260308974655345e-06}, {"id": 480, "seek": 359652, "start": 3603.96, "end": 3612.44, "text": " generally for fine-tuning you want to initially train only the randomly generated new layers", "tokens": [5101, 337, 2489, 12, 83, 37726, 291, 528, 281, 9105, 3847, 787, 264, 16979, 10833, 777, 7914], "temperature": 0.0, "avg_logprob": -0.08342101407605548, "compression_ratio": 1.6933962264150944, "no_speech_prob": 2.260308974655345e-06}, {"id": 481, "seek": 359652, "start": 3612.44, "end": 3619.04, "text": " so that that one or two layers we put on the end train them first and so by default that's", "tokens": [370, 300, 300, 472, 420, 732, 7914, 321, 829, 322, 264, 917, 3847, 552, 700, 293, 370, 538, 7576, 300, 311], "temperature": 0.0, "avg_logprob": -0.08342101407605548, "compression_ratio": 1.6933962264150944, "no_speech_prob": 2.260308974655345e-06}, {"id": 482, "seek": 359652, "start": 3619.04, "end": 3624.68, "text": " what happens when you create a pre-trained model in fast AI is actually all of the layers", "tokens": [437, 2314, 562, 291, 1884, 257, 659, 12, 17227, 2001, 2316, 294, 2370, 7318, 307, 767, 439, 295, 264, 7914], "temperature": 0.0, "avg_logprob": -0.08342101407605548, "compression_ratio": 1.6933962264150944, "no_speech_prob": 2.260308974655345e-06}, {"id": 483, "seek": 362468, "start": 3624.68, "end": 3631.52, "text": " except the randomly the randomly generated ones start out frozen so that's why we didn't", "tokens": [3993, 264, 16979, 264, 16979, 10833, 2306, 722, 484, 12496, 370, 300, 311, 983, 321, 994, 380], "temperature": 0.0, "avg_logprob": -0.10079373253716363, "compression_ratio": 1.6497695852534562, "no_speech_prob": 1.4738557183591183e-05}, {"id": 484, "seek": 362468, "start": 3631.52, "end": 3638.56, "text": " have to say learn dot freeze because it assumes that's what you want okay any quest any more", "tokens": [362, 281, 584, 1466, 5893, 15959, 570, 309, 37808, 300, 311, 437, 291, 528, 1392, 604, 866, 604, 544], "temperature": 0.0, "avg_logprob": -0.10079373253716363, "compression_ratio": 1.6497695852534562, "no_speech_prob": 1.4738557183591183e-05}, {"id": 485, "seek": 362468, "start": 3638.56, "end": 3646.6, "text": " questions about the first half of this class so I apologize for attempting to cover vast", "tokens": [1651, 466, 264, 700, 1922, 295, 341, 1508, 370, 286, 12328, 337, 22001, 281, 2060, 8369], "temperature": 0.0, "avg_logprob": -0.10079373253716363, "compression_ratio": 1.6497695852534562, "no_speech_prob": 1.4738557183591183e-05}, {"id": 486, "seek": 362468, "start": 3646.6, "end": 3653.04, "text": " swaths of computer vision and deep learning in one hour but that's because there's good", "tokens": [1693, 998, 82, 295, 3820, 5201, 293, 2452, 2539, 294, 472, 1773, 457, 300, 311, 570, 456, 311, 665], "temperature": 0.0, "avg_logprob": -0.10079373253716363, "compression_ratio": 1.6497695852534562, "no_speech_prob": 1.4738557183591183e-05}, {"id": 487, "seek": 365304, "start": 3653.04, "end": 3660.96, "text": " materials you can use to learn them properly so a couple of years ago I started I really", "tokens": [5319, 291, 393, 764, 281, 1466, 552, 6108, 370, 257, 1916, 295, 924, 2057, 286, 1409, 286, 534], "temperature": 0.0, "avg_logprob": -0.10289631637872435, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.4063673916098196e-05}, {"id": 488, "seek": 365304, "start": 3660.96, "end": 3667.34, "text": " didn't have any NLP background myself and kind of I guess this is on the tenacity theme", "tokens": [994, 380, 362, 604, 426, 45196, 3678, 2059, 293, 733, 295, 286, 2041, 341, 307, 322, 264, 2064, 19008, 6314], "temperature": 0.0, "avg_logprob": -0.10289631637872435, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.4063673916098196e-05}, {"id": 489, "seek": 365304, "start": 3667.34, "end": 3671.8, "text": " I started wondering about what would happen if we use these same techniques for NLP or", "tokens": [286, 1409, 6359, 466, 437, 576, 1051, 498, 321, 764, 613, 912, 7512, 337, 426, 45196, 420], "temperature": 0.0, "avg_logprob": -0.10289631637872435, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.4063673916098196e-05}, {"id": 490, "seek": 365304, "start": 3671.8, "end": 3677.56, "text": " are they being used for NLP and so I started going to meetups and conferences and finding", "tokens": [366, 436, 885, 1143, 337, 426, 45196, 293, 370, 286, 1409, 516, 281, 1677, 7528, 293, 22032, 293, 5006], "temperature": 0.0, "avg_logprob": -0.10289631637872435, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.4063673916098196e-05}, {"id": 491, "seek": 365304, "start": 3677.56, "end": 3682.44, "text": " famous NLP people and asking them you know is transfer learning super important to lots", "tokens": [4618, 426, 45196, 561, 293, 3365, 552, 291, 458, 307, 5003, 2539, 1687, 1021, 281, 3195], "temperature": 0.0, "avg_logprob": -0.10289631637872435, "compression_ratio": 1.7027027027027026, "no_speech_prob": 1.4063673916098196e-05}, {"id": 492, "seek": 368244, "start": 3682.44, "end": 3688.48, "text": " of people working on it is it used all the time and the answer was no no no and I'd say", "tokens": [295, 561, 1364, 322, 309, 307, 309, 1143, 439, 264, 565, 293, 264, 1867, 390, 572, 572, 572, 293, 286, 1116, 584], "temperature": 0.0, "avg_logprob": -0.07570561869391079, "compression_ratio": 1.7578125, "no_speech_prob": 8.800911928119604e-06}, {"id": 493, "seek": 368244, "start": 3688.48, "end": 3695.56, "text": " what do you think it's a good idea is there an opportunity here and the answer also was", "tokens": [437, 360, 291, 519, 309, 311, 257, 665, 1558, 307, 456, 364, 2650, 510, 293, 264, 1867, 611, 390], "temperature": 0.0, "avg_logprob": -0.07570561869391079, "compression_ratio": 1.7578125, "no_speech_prob": 8.800911928119604e-06}, {"id": 494, "seek": 368244, "start": 3695.56, "end": 3703.16, "text": " no no no NLP is special you can't use computer vision techniques in NLP we're our own thing", "tokens": [572, 572, 572, 426, 45196, 307, 2121, 291, 393, 380, 764, 3820, 5201, 7512, 294, 426, 45196, 321, 434, 527, 1065, 551], "temperature": 0.0, "avg_logprob": -0.07570561869391079, "compression_ratio": 1.7578125, "no_speech_prob": 8.800911928119604e-06}, {"id": 495, "seek": 368244, "start": 3703.16, "end": 3709.04, "text": " you know go and learn proper NLP like a proper NLP person so it's always very dismaying when", "tokens": [291, 458, 352, 293, 1466, 2296, 426, 45196, 411, 257, 2296, 426, 45196, 954, 370, 309, 311, 1009, 588, 717, 10338, 278, 562], "temperature": 0.0, "avg_logprob": -0.07570561869391079, "compression_ratio": 1.7578125, "no_speech_prob": 8.800911928119604e-06}, {"id": 496, "seek": 368244, "start": 3709.04, "end": 3712.36, "text": " you try to kind of get into a new field and do something different because there are lots", "tokens": [291, 853, 281, 733, 295, 483, 666, 257, 777, 2519, 293, 360, 746, 819, 570, 456, 366, 3195], "temperature": 0.0, "avg_logprob": -0.07570561869391079, "compression_ratio": 1.7578125, "no_speech_prob": 8.800911928119604e-06}, {"id": 497, "seek": 371236, "start": 3712.36, "end": 3717.0, "text": " of people who have spent their whole lives in that field and they'll always be very dismissive", "tokens": [295, 561, 567, 362, 4418, 641, 1379, 2909, 294, 300, 2519, 293, 436, 603, 1009, 312, 588, 16974, 488], "temperature": 0.0, "avg_logprob": -0.08593870912279401, "compression_ratio": 1.6621004566210045, "no_speech_prob": 2.4298527932842262e-05}, {"id": 498, "seek": 371236, "start": 3717.0, "end": 3723.84, "text": " of new people wanting to try new things so you just kind of have to ignore it so I ignored", "tokens": [295, 777, 561, 7935, 281, 853, 777, 721, 370, 291, 445, 733, 295, 362, 281, 11200, 309, 370, 286, 19735], "temperature": 0.0, "avg_logprob": -0.08593870912279401, "compression_ratio": 1.6621004566210045, "no_speech_prob": 2.4298527932842262e-05}, {"id": 499, "seek": 371236, "start": 3723.84, "end": 3728.2400000000002, "text": " it just seemed like an obviously good idea to like the stuff I just described is not", "tokens": [309, 445, 6576, 411, 364, 2745, 665, 1558, 281, 411, 264, 1507, 286, 445, 7619, 307, 406], "temperature": 0.0, "avg_logprob": -0.08593870912279401, "compression_ratio": 1.6621004566210045, "no_speech_prob": 2.4298527932842262e-05}, {"id": 500, "seek": 371236, "start": 3728.2400000000002, "end": 3735.7200000000003, "text": " in any way specific to computer vision so I tried to think about like what was the equivalent", "tokens": [294, 604, 636, 2685, 281, 3820, 5201, 370, 286, 3031, 281, 519, 466, 411, 437, 390, 264, 10344], "temperature": 0.0, "avg_logprob": -0.08593870912279401, "compression_ratio": 1.6621004566210045, "no_speech_prob": 2.4298527932842262e-05}, {"id": 501, "seek": 373572, "start": 3735.72, "end": 3742.7999999999997, "text": " of something like pets or something but for computer vision and the data set that I thought", "tokens": [295, 746, 411, 19897, 420, 746, 457, 337, 3820, 5201, 293, 264, 1412, 992, 300, 286, 1194], "temperature": 0.0, "avg_logprob": -0.10020409798135563, "compression_ratio": 1.7903225806451613, "no_speech_prob": 1.9832268662867136e-05}, {"id": 502, "seek": 373572, "start": 3742.7999999999997, "end": 3747.16, "text": " was the most interesting is this one called IMDB that you've already briefly looked at", "tokens": [390, 264, 881, 1880, 307, 341, 472, 1219, 21463, 27735, 300, 291, 600, 1217, 10515, 2956, 412], "temperature": 0.0, "avg_logprob": -0.10020409798135563, "compression_ratio": 1.7903225806451613, "no_speech_prob": 1.9832268662867136e-05}, {"id": 503, "seek": 373572, "start": 3747.16, "end": 3751.52, "text": " I think it's super interesting because the documents in IMDB are quite long they're like", "tokens": [286, 519, 309, 311, 1687, 1880, 570, 264, 8512, 294, 21463, 27735, 366, 1596, 938, 436, 434, 411], "temperature": 0.0, "avg_logprob": -0.10020409798135563, "compression_ratio": 1.7903225806451613, "no_speech_prob": 1.9832268662867136e-05}, {"id": 504, "seek": 373572, "start": 3751.52, "end": 3755.72, "text": " two thousand words one thousand two thousand words long they're the kinds of things that", "tokens": [732, 4714, 2283, 472, 4714, 732, 4714, 2283, 938, 436, 434, 264, 3685, 295, 721, 300], "temperature": 0.0, "avg_logprob": -0.10020409798135563, "compression_ratio": 1.7903225806451613, "no_speech_prob": 1.9832268662867136e-05}, {"id": 505, "seek": 373572, "start": 3755.72, "end": 3764.68, "text": " NLP researchers a couple of years ago was saying were too long to like do useful things", "tokens": [426, 45196, 10309, 257, 1916, 295, 924, 2057, 390, 1566, 645, 886, 938, 281, 411, 360, 4420, 721], "temperature": 0.0, "avg_logprob": -0.10020409798135563, "compression_ratio": 1.7903225806451613, "no_speech_prob": 1.9832268662867136e-05}, {"id": 506, "seek": 376468, "start": 3764.68, "end": 3770.2999999999997, "text": " with other than the simple bag of words stuff kind of naive base and stuff that Rachel's", "tokens": [365, 661, 813, 264, 2199, 3411, 295, 2283, 1507, 733, 295, 29052, 3096, 293, 1507, 300, 14246, 311], "temperature": 0.0, "avg_logprob": -0.10508347780276568, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.49506569566438e-06}, {"id": 507, "seek": 376468, "start": 3770.2999999999997, "end": 3776.44, "text": " already taught you about really people at that time weren't doing much useful stuff", "tokens": [1217, 5928, 291, 466, 534, 561, 412, 300, 565, 4999, 380, 884, 709, 4420, 1507], "temperature": 0.0, "avg_logprob": -0.10508347780276568, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.49506569566438e-06}, {"id": 508, "seek": 376468, "start": 3776.44, "end": 3782.98, "text": " with longer documents so it was a couple of attempts but very very little so it seemed", "tokens": [365, 2854, 8512, 370, 309, 390, 257, 1916, 295, 15257, 457, 588, 588, 707, 370, 309, 6576], "temperature": 0.0, "avg_logprob": -0.10508347780276568, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.49506569566438e-06}, {"id": 509, "seek": 376468, "start": 3782.98, "end": 3790.3999999999996, "text": " like kind of a largely unsolved problem and so I just did the most dumb stupid obvious", "tokens": [411, 733, 295, 257, 11611, 2693, 29110, 1154, 293, 370, 286, 445, 630, 264, 881, 10316, 6631, 6322], "temperature": 0.0, "avg_logprob": -0.10508347780276568, "compression_ratio": 1.5944700460829493, "no_speech_prob": 4.49506569566438e-06}, {"id": 510, "seek": 379040, "start": 3790.4, "end": 3801.12, "text": " thing I could which was basically to do these steps but with NLP so I needed the equivalent", "tokens": [551, 286, 727, 597, 390, 1936, 281, 360, 613, 4439, 457, 365, 426, 45196, 370, 286, 2978, 264, 10344], "temperature": 0.0, "avg_logprob": -0.10780117123626, "compression_ratio": 1.7725118483412323, "no_speech_prob": 6.4388718783447985e-06}, {"id": 511, "seek": 379040, "start": 3801.12, "end": 3808.48, "text": " of an image net pre-trained model but for NLP so I tried to think like what's the equivalent", "tokens": [295, 364, 3256, 2533, 659, 12, 17227, 2001, 2316, 457, 337, 426, 45196, 370, 286, 3031, 281, 519, 411, 437, 311, 264, 10344], "temperature": 0.0, "avg_logprob": -0.10780117123626, "compression_ratio": 1.7725118483412323, "no_speech_prob": 6.4388718783447985e-06}, {"id": 512, "seek": 379040, "start": 3808.48, "end": 3813.92, "text": " like what we need something that kind of understands English under some definition of understands", "tokens": [411, 437, 321, 643, 746, 300, 733, 295, 15146, 3669, 833, 512, 7123, 295, 15146], "temperature": 0.0, "avg_logprob": -0.10780117123626, "compression_ratio": 1.7725118483412323, "no_speech_prob": 6.4388718783447985e-06}, {"id": 513, "seek": 379040, "start": 3813.92, "end": 3818.78, "text": " it kind of needs a sense of like what grammar looks like and what words there are and which", "tokens": [309, 733, 295, 2203, 257, 2020, 295, 411, 437, 22317, 1542, 411, 293, 437, 2283, 456, 366, 293, 597], "temperature": 0.0, "avg_logprob": -0.10780117123626, "compression_ratio": 1.7725118483412323, "no_speech_prob": 6.4388718783447985e-06}, {"id": 514, "seek": 381878, "start": 3818.78, "end": 3824.1800000000003, "text": " ones are kind of happy and sad words and kind of what words like not and don't mean and", "tokens": [2306, 366, 733, 295, 2055, 293, 4227, 2283, 293, 733, 295, 437, 2283, 411, 406, 293, 500, 380, 914, 293], "temperature": 0.0, "avg_logprob": -0.1240019022032272, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.339095762086799e-06}, {"id": 515, "seek": 381878, "start": 3824.1800000000003, "end": 3832.02, "text": " negatives and kind of try to get as much you know knowledge a bit of language as possible", "tokens": [40019, 293, 733, 295, 853, 281, 483, 382, 709, 291, 458, 3601, 257, 857, 295, 2856, 382, 1944], "temperature": 0.0, "avg_logprob": -0.1240019022032272, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.339095762086799e-06}, {"id": 516, "seek": 381878, "start": 3832.02, "end": 3839.2400000000002, "text": " into a model and so I thought what would be a good way to do that and turned out one of", "tokens": [666, 257, 2316, 293, 370, 286, 1194, 437, 576, 312, 257, 665, 636, 281, 360, 300, 293, 3574, 484, 472, 295], "temperature": 0.0, "avg_logprob": -0.1240019022032272, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.339095762086799e-06}, {"id": 517, "seek": 381878, "start": 3839.2400000000002, "end": 3844.46, "text": " my friends a guy called Stephen Meridy had recently been doing research on a kind of", "tokens": [452, 1855, 257, 2146, 1219, 13391, 6124, 38836, 632, 3938, 668, 884, 2132, 322, 257, 733, 295], "temperature": 0.0, "avg_logprob": -0.1240019022032272, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.339095762086799e-06}, {"id": 518, "seek": 384446, "start": 3844.46, "end": 3852.56, "text": " model called a language model and a language model is a model as you've learned which predicts", "tokens": [2316, 1219, 257, 2856, 2316, 293, 257, 2856, 2316, 307, 257, 2316, 382, 291, 600, 3264, 597, 6069, 82], "temperature": 0.0, "avg_logprob": -0.11106413735283746, "compression_ratio": 1.9109947643979057, "no_speech_prob": 3.7265613173076417e-06}, {"id": 519, "seek": 384446, "start": 3852.56, "end": 3859.16, "text": " the next word of a sentence or more generally the predicts the next word of a document and", "tokens": [264, 958, 1349, 295, 257, 8174, 420, 544, 5101, 264, 6069, 82, 264, 958, 1349, 295, 257, 4166, 293], "temperature": 0.0, "avg_logprob": -0.11106413735283746, "compression_ratio": 1.9109947643979057, "no_speech_prob": 3.7265613173076417e-06}, {"id": 520, "seek": 384446, "start": 3859.16, "end": 3863.56, "text": " Stephen Meridy had got a new state-of-the-art result for language modeling so state-of-the-art", "tokens": [13391, 6124, 38836, 632, 658, 257, 777, 1785, 12, 2670, 12, 3322, 12, 446, 1874, 337, 2856, 15983, 370, 1785, 12, 2670, 12, 3322, 12, 446], "temperature": 0.0, "avg_logprob": -0.11106413735283746, "compression_ratio": 1.9109947643979057, "no_speech_prob": 3.7265613173076417e-06}, {"id": 521, "seek": 384446, "start": 3863.56, "end": 3869.64, "text": " means he had got a more accurate language model than anybody had built before and it", "tokens": [1355, 415, 632, 658, 257, 544, 8559, 2856, 2316, 813, 4472, 632, 3094, 949, 293, 309], "temperature": 0.0, "avg_logprob": -0.11106413735283746, "compression_ratio": 1.9109947643979057, "no_speech_prob": 3.7265613173076417e-06}, {"id": 522, "seek": 386964, "start": 3869.64, "end": 3876.2799999999997, "text": " didn't take particularly long time to train and it was you know so it's pretty efficient", "tokens": [994, 380, 747, 4098, 938, 565, 281, 3847, 293, 309, 390, 291, 458, 370, 309, 311, 1238, 7148], "temperature": 0.0, "avg_logprob": -0.1132128357887268, "compression_ratio": 1.70935960591133, "no_speech_prob": 2.994410579049145e-06}, {"id": 523, "seek": 386964, "start": 3876.2799999999997, "end": 3883.3599999999997, "text": " pretty accurate and I started thinking about it and I started thinking like in order to", "tokens": [1238, 8559, 293, 286, 1409, 1953, 466, 309, 293, 286, 1409, 1953, 411, 294, 1668, 281], "temperature": 0.0, "avg_logprob": -0.1132128357887268, "compression_ratio": 1.70935960591133, "no_speech_prob": 2.994410579049145e-06}, {"id": 524, "seek": 386964, "start": 3883.3599999999997, "end": 3888.3599999999997, "text": " predict the next word of a sentence what would the model have to know what would it have", "tokens": [6069, 264, 958, 1349, 295, 257, 8174, 437, 576, 264, 2316, 362, 281, 458, 437, 576, 309, 362], "temperature": 0.0, "avg_logprob": -0.1132128357887268, "compression_ratio": 1.70935960591133, "no_speech_prob": 2.994410579049145e-06}, {"id": 525, "seek": 386964, "start": 3888.3599999999997, "end": 3899.6, "text": " to learn right so for example I went to the fair and I had a really delicious hot", "tokens": [281, 1466, 558, 370, 337, 1365, 286, 1437, 281, 264, 3143, 293, 286, 632, 257, 534, 4809, 2368], "temperature": 0.0, "avg_logprob": -0.1132128357887268, "compression_ratio": 1.70935960591133, "no_speech_prob": 2.994410579049145e-06}, {"id": 526, "seek": 389960, "start": 3899.6, "end": 3909.2799999999997, "text": " what probably a dog right oh I'm so sweaty it's a really hot probably a day not a dog", "tokens": [437, 1391, 257, 3000, 558, 1954, 286, 478, 370, 36044, 309, 311, 257, 534, 2368, 1391, 257, 786, 406, 257, 3000], "temperature": 0.0, "avg_logprob": -0.07164084079653718, "compression_ratio": 1.7461928934010151, "no_speech_prob": 1.9222656192141585e-05}, {"id": 527, "seek": 389960, "start": 3909.2799999999997, "end": 3914.88, "text": " right now so to be able to predict the next word of that sentence it's not enough just", "tokens": [558, 586, 370, 281, 312, 1075, 281, 6069, 264, 958, 1349, 295, 300, 8174, 309, 311, 406, 1547, 445], "temperature": 0.0, "avg_logprob": -0.07164084079653718, "compression_ratio": 1.7461928934010151, "no_speech_prob": 1.9222656192141585e-05}, {"id": 528, "seek": 389960, "start": 3914.88, "end": 3921.68, "text": " to know like n grams right because hot day and hot dog both come together right even", "tokens": [281, 458, 411, 297, 11899, 558, 570, 2368, 786, 293, 2368, 3000, 1293, 808, 1214, 558, 754], "temperature": 0.0, "avg_logprob": -0.07164084079653718, "compression_ratio": 1.7461928934010151, "no_speech_prob": 1.9222656192141585e-05}, {"id": 529, "seek": 389960, "start": 3921.68, "end": 3926.12, "text": " kind of context would not be enough because you might well go to the fair on a hot day", "tokens": [733, 295, 4319, 576, 406, 312, 1547, 570, 291, 1062, 731, 352, 281, 264, 3143, 322, 257, 2368, 786], "temperature": 0.0, "avg_logprob": -0.07164084079653718, "compression_ratio": 1.7461928934010151, "no_speech_prob": 1.9222656192141585e-05}, {"id": 530, "seek": 392612, "start": 3926.12, "end": 3929.96, "text": " you might well have a hot dog on a hot day right you need to know what kinds of things", "tokens": [291, 1062, 731, 362, 257, 2368, 3000, 322, 257, 2368, 786, 558, 291, 643, 281, 458, 437, 3685, 295, 721], "temperature": 0.0, "avg_logprob": -0.09160748466116483, "compression_ratio": 1.6047904191616766, "no_speech_prob": 3.555925559339812e-06}, {"id": 531, "seek": 392612, "start": 3929.96, "end": 3938.48, "text": " people eat versus what kinds of things make people sweat for example right or even more", "tokens": [561, 1862, 5717, 437, 3685, 295, 721, 652, 561, 11872, 337, 1365, 558, 420, 754, 544], "temperature": 0.0, "avg_logprob": -0.09160748466116483, "compression_ratio": 1.6047904191616766, "no_speech_prob": 3.555925559339812e-06}, {"id": 532, "seek": 392612, "start": 3938.48, "end": 3951.9, "text": " tricky like a really important element of the financial crisis was the Dodd-Frank legislation", "tokens": [12414, 411, 257, 534, 1021, 4478, 295, 264, 4669, 5869, 390, 264, 26904, 67, 12, 47566, 11329], "temperature": 0.0, "avg_logprob": -0.09160748466116483, "compression_ratio": 1.6047904191616766, "no_speech_prob": 3.555925559339812e-06}, {"id": 533, "seek": 395190, "start": 3951.9, "end": 3960.12, "text": " signed into law by President blah right which means you need to know either like when was", "tokens": [8175, 666, 2101, 538, 3117, 12288, 558, 597, 1355, 291, 643, 281, 458, 2139, 411, 562, 390], "temperature": 0.0, "avg_logprob": -0.09762300589145759, "compression_ratio": 1.755, "no_speech_prob": 1.2606518794200383e-05}, {"id": 534, "seek": 395190, "start": 3960.12, "end": 3964.6800000000003, "text": " the financial crisis and who was president then or who was the president who signed the", "tokens": [264, 4669, 5869, 293, 567, 390, 3868, 550, 420, 567, 390, 264, 3868, 567, 8175, 264], "temperature": 0.0, "avg_logprob": -0.09762300589145759, "compression_ratio": 1.755, "no_speech_prob": 1.2606518794200383e-05}, {"id": 535, "seek": 395190, "start": 3964.6800000000003, "end": 3969.88, "text": " Dodd-Frank legislation into law right you actually need to know something about not", "tokens": [26904, 67, 12, 47566, 11329, 666, 2101, 558, 291, 767, 643, 281, 458, 746, 466, 406], "temperature": 0.0, "avg_logprob": -0.09762300589145759, "compression_ratio": 1.755, "no_speech_prob": 1.2606518794200383e-05}, {"id": 536, "seek": 395190, "start": 3969.88, "end": 3974.7200000000003, "text": " just language but what's going on in the world and the concept of time and the concept of", "tokens": [445, 2856, 457, 437, 311, 516, 322, 294, 264, 1002, 293, 264, 3410, 295, 565, 293, 264, 3410, 295], "temperature": 0.0, "avg_logprob": -0.09762300589145759, "compression_ratio": 1.755, "no_speech_prob": 1.2606518794200383e-05}, {"id": 537, "seek": 397472, "start": 3974.72, "end": 3984.3599999999997, "text": " politicians right so I kind of realized a really really really good language model kind", "tokens": [14756, 558, 370, 286, 733, 295, 5334, 257, 534, 534, 534, 665, 2856, 2316, 733], "temperature": 0.0, "avg_logprob": -0.07343896006194639, "compression_ratio": 1.6919431279620853, "no_speech_prob": 3.7852728382858913e-06}, {"id": 538, "seek": 397472, "start": 3984.3599999999997, "end": 3988.8799999999997, "text": " of needs to know a lot about the world and actually this is something that philosophers", "tokens": [295, 2203, 281, 458, 257, 688, 466, 264, 1002, 293, 767, 341, 307, 746, 300, 36839], "temperature": 0.0, "avg_logprob": -0.07343896006194639, "compression_ratio": 1.6919431279620853, "no_speech_prob": 3.7852728382858913e-06}, {"id": 539, "seek": 397472, "start": 3988.8799999999997, "end": 3994.56, "text": " have been discussing for many many years there's a famous thought experiment called the Chinese", "tokens": [362, 668, 10850, 337, 867, 867, 924, 456, 311, 257, 4618, 1194, 5120, 1219, 264, 4649], "temperature": 0.0, "avg_logprob": -0.07343896006194639, "compression_ratio": 1.6919431279620853, "no_speech_prob": 3.7852728382858913e-06}, {"id": 540, "seek": 397472, "start": 3994.56, "end": 4001.7599999999998, "text": " room thought experiment from the philosophy of mind which is basically deals with the", "tokens": [1808, 1194, 5120, 490, 264, 10675, 295, 1575, 597, 307, 1936, 11215, 365, 264], "temperature": 0.0, "avg_logprob": -0.07343896006194639, "compression_ratio": 1.6919431279620853, "no_speech_prob": 3.7852728382858913e-06}, {"id": 541, "seek": 400176, "start": 4001.76, "end": 4011.6800000000003, "text": " hypothesis that a any advanced enough language model is indistinguishable from intelligence", "tokens": [17291, 300, 257, 604, 7339, 1547, 2856, 2316, 307, 1016, 468, 7050, 742, 712, 490, 7599], "temperature": 0.0, "avg_logprob": -0.12222311860423977, "compression_ratio": 1.6035502958579881, "no_speech_prob": 8.01339319878025e-06}, {"id": 542, "seek": 400176, "start": 4011.6800000000003, "end": 4017.5600000000004, "text": " so basically if something can like like if you know if the sequence if the thing to complete", "tokens": [370, 1936, 498, 746, 393, 411, 411, 498, 291, 458, 498, 264, 8310, 498, 264, 551, 281, 3566], "temperature": 0.0, "avg_logprob": -0.12222311860423977, "compression_ratio": 1.6035502958579881, "no_speech_prob": 8.01339319878025e-06}, {"id": 543, "seek": 400176, "start": 4017.5600000000004, "end": 4029.92, "text": " is the lot the prime factorization of this really large number is then to actually fix", "tokens": [307, 264, 688, 264, 5835, 5952, 2144, 295, 341, 534, 2416, 1230, 307, 550, 281, 767, 3191], "temperature": 0.0, "avg_logprob": -0.12222311860423977, "compression_ratio": 1.6035502958579881, "no_speech_prob": 8.01339319878025e-06}, {"id": 544, "seek": 402992, "start": 4029.92, "end": 4036.7200000000003, "text": " correct get that language model correctly you have to factor prime numbers for instance", "tokens": [3006, 483, 300, 2856, 2316, 8944, 291, 362, 281, 5952, 5835, 3547, 337, 5197], "temperature": 0.0, "avg_logprob": -0.1390154078855353, "compression_ratio": 1.8169934640522876, "no_speech_prob": 8.139572855725419e-06}, {"id": 545, "seek": 402992, "start": 4036.7200000000003, "end": 4040.28, "text": " and particularly once you start not just predicting the next word but then you can say well predict", "tokens": [293, 4098, 1564, 291, 722, 406, 445, 32884, 264, 958, 1349, 457, 550, 291, 393, 584, 731, 6069], "temperature": 0.0, "avg_logprob": -0.1390154078855353, "compression_ratio": 1.8169934640522876, "no_speech_prob": 8.139572855725419e-06}, {"id": 546, "seek": 402992, "start": 4040.28, "end": 4049.2400000000002, "text": " the word after that pick the word after that pick the word after that so it turns out that", "tokens": [264, 1349, 934, 300, 1888, 264, 1349, 934, 300, 1888, 264, 1349, 934, 300, 370, 309, 4523, 484, 300], "temperature": 0.0, "avg_logprob": -0.1390154078855353, "compression_ratio": 1.8169934640522876, "no_speech_prob": 8.139572855725419e-06}, {"id": 547, "seek": 404924, "start": 4049.24, "end": 4064.64, "text": " if you use a lot of parameters and a lot of data to create a really good language model", "tokens": [498, 291, 764, 257, 688, 295, 9834, 293, 257, 688, 295, 1412, 281, 1884, 257, 534, 665, 2856, 2316], "temperature": 0.0, "avg_logprob": -0.13683704963097207, "compression_ratio": 1.6024096385542168, "no_speech_prob": 8.013155820663087e-06}, {"id": 548, "seek": 404924, "start": 4064.64, "end": 4070.8799999999997, "text": " it's quite surprising what that can do and so you can start saying like don't just predict", "tokens": [309, 311, 1596, 8830, 437, 300, 393, 360, 293, 370, 291, 393, 722, 1566, 411, 500, 380, 445, 6069], "temperature": 0.0, "avg_logprob": -0.13683704963097207, "compression_ratio": 1.6024096385542168, "no_speech_prob": 8.013155820663087e-06}, {"id": 549, "seek": 404924, "start": 4070.8799999999997, "end": 4077.3999999999996, "text": " the next word but keep predicting the next word so a group called open AI I called Alec", "tokens": [264, 958, 1349, 457, 1066, 32884, 264, 958, 1349, 370, 257, 1594, 1219, 1269, 7318, 286, 1219, 9366, 66], "temperature": 0.0, "avg_logprob": -0.13683704963097207, "compression_ratio": 1.6024096385542168, "no_speech_prob": 8.013155820663087e-06}, {"id": 550, "seek": 407740, "start": 4077.4, "end": 4083.6, "text": " Radford in particular actually took the research that we had been doing on kind of single GPUs", "tokens": [9654, 7404, 294, 1729, 767, 1890, 264, 2132, 300, 321, 632, 668, 884, 322, 733, 295, 2167, 18407, 82], "temperature": 0.0, "avg_logprob": -0.13669384650464328, "compression_ratio": 1.7470817120622568, "no_speech_prob": 8.218349103117362e-05}, {"id": 551, "seek": 407740, "start": 4083.6, "end": 4089.8, "text": " and said I wonder what would happen if you scaled that up massively and open AI kind", "tokens": [293, 848, 286, 2441, 437, 576, 1051, 498, 291, 36039, 300, 493, 29379, 293, 1269, 7318, 733], "temperature": 0.0, "avg_logprob": -0.13669384650464328, "compression_ratio": 1.7470817120622568, "no_speech_prob": 8.218349103117362e-05}, {"id": 552, "seek": 407740, "start": 4089.8, "end": 4094.84, "text": " of created the supercharged version of the same thing called GPT and this one is GPT", "tokens": [295, 2942, 264, 1687, 25064, 3037, 295, 264, 912, 551, 1219, 26039, 51, 293, 341, 472, 307, 26039, 51], "temperature": 0.0, "avg_logprob": -0.13669384650464328, "compression_ratio": 1.7470817120622568, "no_speech_prob": 8.218349103117362e-05}, {"id": 553, "seek": 407740, "start": 4094.84, "end": 4099.12, "text": " 2 and so then they started saying what would happen if we just feed it text so they fed", "tokens": [568, 293, 370, 550, 436, 1409, 1566, 437, 576, 1051, 498, 321, 445, 3154, 309, 2487, 370, 436, 4636], "temperature": 0.0, "avg_logprob": -0.13669384650464328, "compression_ratio": 1.7470817120622568, "no_speech_prob": 8.218349103117362e-05}, {"id": 554, "seek": 407740, "start": 4099.12, "end": 4107.36, "text": " it so they trained it on you know a not insignificant subset of the web and then they trained it", "tokens": [309, 370, 436, 8895, 309, 322, 291, 458, 257, 406, 43685, 25993, 295, 264, 3670, 293, 550, 436, 8895, 309], "temperature": 0.0, "avg_logprob": -0.13669384650464328, "compression_ratio": 1.7470817120622568, "no_speech_prob": 8.218349103117362e-05}, {"id": 555, "seek": 410736, "start": 4107.36, "end": 4112.0, "text": " with they prompted it with in a shocking finding scientists discovered a herd of unicorns living", "tokens": [365, 436, 31042, 309, 365, 294, 257, 18776, 5006, 7708, 6941, 257, 29484, 295, 28122, 82, 2647], "temperature": 0.0, "avg_logprob": -0.13958332171806923, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.169138502329588e-05}, {"id": 556, "seek": 410736, "start": 4112.0, "end": 4117.2, "text": " in a remote previously unexplored valley in the Andes Mountains even more surprising to", "tokens": [294, 257, 8607, 8046, 11572, 564, 2769, 17636, 294, 264, 400, 279, 30970, 754, 544, 8830, 281], "temperature": 0.0, "avg_logprob": -0.13958332171806923, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.169138502329588e-05}, {"id": 557, "seek": 410736, "start": 4117.2, "end": 4121.599999999999, "text": " the researchers was the fact that the unicorn spoke perfect English so somebody wrote that", "tokens": [264, 10309, 390, 264, 1186, 300, 264, 28122, 7179, 2176, 3669, 370, 2618, 4114, 300], "temperature": 0.0, "avg_logprob": -0.13958332171806923, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.169138502329588e-05}, {"id": 558, "seek": 410736, "start": 4121.599999999999, "end": 4127.839999999999, "text": " person and then that was the input to a language model and the language model was this pre-trained", "tokens": [954, 293, 550, 300, 390, 264, 4846, 281, 257, 2856, 2316, 293, 264, 2856, 2316, 390, 341, 659, 12, 17227, 2001], "temperature": 0.0, "avg_logprob": -0.13958332171806923, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.169138502329588e-05}, {"id": 559, "seek": 410736, "start": 4127.839999999999, "end": 4133.08, "text": " GPT 2 model which had been pre-trained on for a very long time on a very large amount", "tokens": [26039, 51, 568, 2316, 597, 632, 668, 659, 12, 17227, 2001, 322, 337, 257, 588, 938, 565, 322, 257, 588, 2416, 2372], "temperature": 0.0, "avg_logprob": -0.13958332171806923, "compression_ratio": 1.7037037037037037, "no_speech_prob": 9.169138502329588e-05}, {"id": 560, "seek": 413308, "start": 4133.08, "end": 4139.68, "text": " of data and the the next word the language model predicted was the and then they said", "tokens": [295, 1412, 293, 264, 264, 958, 1349, 264, 2856, 2316, 19147, 390, 264, 293, 550, 436, 848], "temperature": 0.0, "avg_logprob": -0.19979626199473505, "compression_ratio": 1.8264462809917354, "no_speech_prob": 2.6272879040334374e-05}, {"id": 561, "seek": 413308, "start": 4139.68, "end": 4144.0, "text": " okay predict the word after that that was scientist predict the next word after that", "tokens": [1392, 6069, 264, 1349, 934, 300, 300, 390, 12662, 6069, 264, 958, 1349, 934, 300], "temperature": 0.0, "avg_logprob": -0.19979626199473505, "compression_ratio": 1.8264462809917354, "no_speech_prob": 2.6272879040334374e-05}, {"id": 562, "seek": 413308, "start": 4144.0, "end": 4149.0, "text": " it was named and ended up with this whole thing is made by a computer now the scientists", "tokens": [309, 390, 4926, 293, 4590, 493, 365, 341, 1379, 551, 307, 1027, 538, 257, 3820, 586, 264, 7708], "temperature": 0.0, "avg_logprob": -0.19979626199473505, "compression_ratio": 1.8264462809917354, "no_speech_prob": 2.6272879040334374e-05}, {"id": 563, "seek": 413308, "start": 4149.0, "end": 4154.08, "text": " named the population after their distinctive horn over its unicorn these four horns silver", "tokens": [4926, 264, 4415, 934, 641, 27766, 13482, 670, 1080, 28122, 613, 1451, 28818, 8753], "temperature": 0.0, "avg_logprob": -0.19979626199473505, "compression_ratio": 1.8264462809917354, "no_speech_prob": 2.6272879040334374e-05}, {"id": 564, "seek": 413308, "start": 4154.08, "end": 4161.24, "text": " white unicorns were previously unknown to science dr. Jorge Perez an evolutionary biologist", "tokens": [2418, 28122, 82, 645, 8046, 9841, 281, 3497, 1224, 13, 36875, 47317, 364, 27567, 3228, 9201], "temperature": 0.0, "avg_logprob": -0.19979626199473505, "compression_ratio": 1.8264462809917354, "no_speech_prob": 2.6272879040334374e-05}, {"id": 565, "seek": 416124, "start": 4161.24, "end": 4165.5199999999995, "text": " from the University of La Paz were exploring the Andes when they found a small valley Perez", "tokens": [490, 264, 3535, 295, 2369, 430, 921, 645, 12736, 264, 400, 279, 562, 436, 1352, 257, 1359, 17636, 47317], "temperature": 0.0, "avg_logprob": -0.10525744852393565, "compression_ratio": 1.7976653696498055, "no_speech_prob": 2.2472875571111217e-05}, {"id": 566, "seek": 416124, "start": 4165.5199999999995, "end": 4170.48, "text": " noticed the valley had what appeared to be a natural fountain Perez and the others ventured", "tokens": [5694, 264, 17636, 632, 437, 8516, 281, 312, 257, 3303, 29451, 47317, 293, 264, 2357, 6931, 3831], "temperature": 0.0, "avg_logprob": -0.10525744852393565, "compression_ratio": 1.7976653696498055, "no_speech_prob": 2.2472875571111217e-05}, {"id": 567, "seek": 416124, "start": 4170.48, "end": 4174.92, "text": " further into the valley by the time we reached the top the water looked blue they were astonished", "tokens": [3052, 666, 264, 17636, 538, 264, 565, 321, 6488, 264, 1192, 264, 1281, 2956, 3344, 436, 645, 25687, 4729], "temperature": 0.0, "avg_logprob": -0.10525744852393565, "compression_ratio": 1.7976653696498055, "no_speech_prob": 2.2472875571111217e-05}, {"id": 568, "seek": 416124, "start": 4174.92, "end": 4180.719999999999, "text": " to see the unicorn herd these creatures could be seen from the air they were so close they", "tokens": [281, 536, 264, 28122, 29484, 613, 12281, 727, 312, 1612, 490, 264, 1988, 436, 645, 370, 1998, 436], "temperature": 0.0, "avg_logprob": -0.10525744852393565, "compression_ratio": 1.7976653696498055, "no_speech_prob": 2.2472875571111217e-05}, {"id": 569, "seek": 416124, "start": 4180.719999999999, "end": 4185.16, "text": " could touch their horns they discovered that the creatures also spoke some fairly regular", "tokens": [727, 2557, 641, 28818, 436, 6941, 300, 264, 12281, 611, 7179, 512, 6457, 3890], "temperature": 0.0, "avg_logprob": -0.10525744852393565, "compression_ratio": 1.7976653696498055, "no_speech_prob": 2.2472875571111217e-05}, {"id": 570, "seek": 418516, "start": 4185.16, "end": 4193.4, "text": " English so oh well this while the unicorns still unclear some believe perhaps the creatures", "tokens": [3669, 370, 1954, 731, 341, 1339, 264, 28122, 82, 920, 25636, 512, 1697, 4317, 264, 12281], "temperature": 0.0, "avg_logprob": -0.15548516542483598, "compression_ratio": 1.6742081447963801, "no_speech_prob": 1.4738546269654762e-05}, {"id": 571, "seek": 418516, "start": 4193.4, "end": 4197.96, "text": " were created what a unicorn and a human and a unicorn met each other at a time before", "tokens": [645, 2942, 437, 257, 28122, 293, 257, 1952, 293, 257, 28122, 1131, 1184, 661, 412, 257, 565, 949], "temperature": 0.0, "avg_logprob": -0.15548516542483598, "compression_ratio": 1.6742081447963801, "no_speech_prob": 1.4738546269654762e-05}, {"id": 572, "seek": 418516, "start": 4197.96, "end": 4206.5599999999995, "text": " human civilization in South America such incidents seem to be quite common so you can see that", "tokens": [1952, 18036, 294, 4242, 3374, 1270, 21139, 1643, 281, 312, 1596, 2689, 370, 291, 393, 536, 300], "temperature": 0.0, "avg_logprob": -0.15548516542483598, "compression_ratio": 1.6742081447963801, "no_speech_prob": 1.4738546269654762e-05}, {"id": 573, "seek": 418516, "start": 4206.5599999999995, "end": 4214.08, "text": " a language model like to understand the capabilities of a large neural network trained on a large", "tokens": [257, 2856, 2316, 411, 281, 1223, 264, 10862, 295, 257, 2416, 18161, 3209, 8895, 322, 257, 2416], "temperature": 0.0, "avg_logprob": -0.15548516542483598, "compression_ratio": 1.6742081447963801, "no_speech_prob": 1.4738546269654762e-05}, {"id": 574, "seek": 421408, "start": 4214.08, "end": 4217.5199999999995, "text": " amount of data you kind of have to rethink your understanding of what a mathematical", "tokens": [2372, 295, 1412, 291, 733, 295, 362, 281, 34595, 428, 3701, 295, 437, 257, 18894], "temperature": 0.0, "avg_logprob": -0.05946370619761793, "compression_ratio": 1.7623762376237624, "no_speech_prob": 2.5070878109545447e-05}, {"id": 575, "seek": 421408, "start": 4217.5199999999995, "end": 4222.6, "text": " function can do this is a mathematical function right and this mathematical function has been", "tokens": [2445, 393, 360, 341, 307, 257, 18894, 2445, 558, 293, 341, 18894, 2445, 575, 668], "temperature": 0.0, "avg_logprob": -0.05946370619761793, "compression_ratio": 1.7623762376237624, "no_speech_prob": 2.5070878109545447e-05}, {"id": 576, "seek": 421408, "start": 4222.6, "end": 4229.04, "text": " trained to do nothing other than fill in the next word of a sentence but it's done it for", "tokens": [8895, 281, 360, 1825, 661, 813, 2836, 294, 264, 958, 1349, 295, 257, 8174, 457, 309, 311, 1096, 309, 337], "temperature": 0.0, "avg_logprob": -0.05946370619761793, "compression_ratio": 1.7623762376237624, "no_speech_prob": 2.5070878109545447e-05}, {"id": 577, "seek": 421408, "start": 4229.04, "end": 4235.12, "text": " a lot of sentences right and it has I think like I can't quite remember but hundreds of", "tokens": [257, 688, 295, 16579, 558, 293, 309, 575, 286, 519, 411, 286, 393, 380, 1596, 1604, 457, 6779, 295], "temperature": 0.0, "avg_logprob": -0.05946370619761793, "compression_ratio": 1.7623762376237624, "no_speech_prob": 2.5070878109545447e-05}, {"id": 578, "seek": 423512, "start": 4235.12, "end": 4247.08, "text": " millions or billions of parameters to two number of parameters see area yeah that's", "tokens": [6803, 420, 17375, 295, 9834, 281, 732, 1230, 295, 9834, 536, 1859, 1338, 300, 311], "temperature": 0.0, "avg_logprob": -0.18404185466277292, "compression_ratio": 1.5087719298245614, "no_speech_prob": 1.5935451301629655e-05}, {"id": 579, "seek": 423512, "start": 4247.08, "end": 4260.5199999999995, "text": " right I think it's so they've released the 345 million parameter version and the version", "tokens": [558, 286, 519, 309, 311, 370, 436, 600, 4736, 264, 805, 8465, 2459, 13075, 3037, 293, 264, 3037], "temperature": 0.0, "avg_logprob": -0.18404185466277292, "compression_ratio": 1.5087719298245614, "no_speech_prob": 1.5935451301629655e-05}, {"id": 580, "seek": 426052, "start": 4260.52, "end": 4279.92, "text": " I showed you is 1.5 billion so the yeah so with a with over a billion parameters", "tokens": [286, 4712, 291, 307, 502, 13, 20, 5218, 370, 264, 1338, 370, 365, 257, 365, 670, 257, 5218, 9834], "temperature": 0.0, "avg_logprob": -0.15984772854163998, "compression_ratio": 1.5679012345679013, "no_speech_prob": 1.670067649683915e-05}, {"id": 581, "seek": 426052, "start": 4279.92, "end": 4286.240000000001, "text": " and the extraordinary amount of data you you know our intuitions about what you can learn", "tokens": [293, 264, 10581, 2372, 295, 1412, 291, 291, 458, 527, 16224, 626, 466, 437, 291, 393, 1466], "temperature": 0.0, "avg_logprob": -0.15984772854163998, "compression_ratio": 1.5679012345679013, "no_speech_prob": 1.670067649683915e-05}, {"id": 582, "seek": 426052, "start": 4286.240000000001, "end": 4289.360000000001, "text": " just by learning to predict the next word of a sentence the intuitions not going to", "tokens": [445, 538, 2539, 281, 6069, 264, 958, 1349, 295, 257, 8174, 264, 16224, 626, 406, 516, 281], "temperature": 0.0, "avg_logprob": -0.15984772854163998, "compression_ratio": 1.5679012345679013, "no_speech_prob": 1.670067649683915e-05}, {"id": 583, "seek": 428936, "start": 4289.36, "end": 4293.96, "text": " be right okay you have to kind of think of it at the foundations and realize that a language", "tokens": [312, 558, 1392, 291, 362, 281, 733, 295, 519, 295, 309, 412, 264, 22467, 293, 4325, 300, 257, 2856], "temperature": 0.0, "avg_logprob": -0.1721236729385829, "compression_ratio": 1.7865612648221343, "no_speech_prob": 1.4063284652365837e-05}, {"id": 584, "seek": 428936, "start": 4293.96, "end": 4300.88, "text": " model if it's good has to learn a lot of things like like if you think about it that last", "tokens": [2316, 498, 309, 311, 665, 575, 281, 1466, 257, 688, 295, 721, 411, 411, 498, 291, 519, 466, 309, 300, 1036], "temperature": 0.0, "avg_logprob": -0.1721236729385829, "compression_ratio": 1.7865612648221343, "no_speech_prob": 1.4063284652365837e-05}, {"id": 585, "seek": 428936, "start": 4300.88, "end": 4306.96, "text": " one needed to know where lapas is for example because then the generated text talked about", "tokens": [472, 2978, 281, 458, 689, 13214, 296, 307, 337, 1365, 570, 550, 264, 10833, 2487, 2825, 466], "temperature": 0.0, "avg_logprob": -0.1721236729385829, "compression_ratio": 1.7865612648221343, "no_speech_prob": 1.4063284652365837e-05}, {"id": 586, "seek": 428936, "start": 4306.96, "end": 4311.12, "text": " well it used academics named Paul gay Perez that would be associate which be associated", "tokens": [731, 309, 1143, 25695, 4926, 4552, 9049, 47317, 300, 576, 312, 14644, 597, 312, 6615], "temperature": 0.0, "avg_logprob": -0.1721236729385829, "compression_ratio": 1.7865612648221343, "no_speech_prob": 1.4063284652365837e-05}, {"id": 587, "seek": 428936, "start": 4311.12, "end": 4315.759999999999, "text": " with that area and it talked about the Andes Mountains which are associated with that area", "tokens": [365, 300, 1859, 293, 309, 2825, 466, 264, 400, 279, 30970, 597, 366, 6615, 365, 300, 1859], "temperature": 0.0, "avg_logprob": -0.1721236729385829, "compression_ratio": 1.7865612648221343, "no_speech_prob": 1.4063284652365837e-05}, {"id": 588, "seek": 431576, "start": 4315.76, "end": 4324.08, "text": " and they picked a university in that area so it's it's really amazing what a language", "tokens": [293, 436, 6183, 257, 5454, 294, 300, 1859, 370, 309, 311, 309, 311, 534, 2243, 437, 257, 2856], "temperature": 0.0, "avg_logprob": -0.15806525586599326, "compression_ratio": 1.5676855895196506, "no_speech_prob": 2.1443263904075138e-05}, {"id": 589, "seek": 431576, "start": 4324.08, "end": 4330.88, "text": " model ends up being able to develop so when I created you 11 feet it was before all this", "tokens": [2316, 5314, 493, 885, 1075, 281, 1499, 370, 562, 286, 2942, 291, 2975, 3521, 309, 390, 949, 439, 341], "temperature": 0.0, "avg_logprob": -0.15806525586599326, "compression_ratio": 1.5676855895196506, "no_speech_prob": 2.1443263904075138e-05}, {"id": 590, "seek": 431576, "start": 4330.88, "end": 4336.72, "text": " had happened but it was clear that from first principles a good language model such as the", "tokens": [632, 2011, 457, 309, 390, 1850, 300, 490, 700, 9156, 257, 665, 2856, 2316, 1270, 382, 264], "temperature": 0.0, "avg_logprob": -0.15806525586599326, "compression_ratio": 1.5676855895196506, "no_speech_prob": 2.1443263904075138e-05}, {"id": 591, "seek": 431576, "start": 4336.72, "end": 4341.4400000000005, "text": " kind of thing that Stephen Merrity had recently been building ought to know quite a lot about", "tokens": [733, 295, 551, 300, 13391, 6124, 81, 507, 632, 3938, 668, 2390, 13416, 281, 458, 1596, 257, 688, 466], "temperature": 0.0, "avg_logprob": -0.15806525586599326, "compression_ratio": 1.5676855895196506, "no_speech_prob": 2.1443263904075138e-05}, {"id": 592, "seek": 434144, "start": 4341.44, "end": 4348.44, "text": " language and about the world and so I decided to use that as my image net version tree train", "tokens": [2856, 293, 466, 264, 1002, 293, 370, 286, 3047, 281, 764, 300, 382, 452, 3256, 2533, 3037, 4230, 3847], "temperature": 0.0, "avg_logprob": -0.12562194237342247, "compression_ratio": 1.5738636363636365, "no_speech_prob": 1.0952925549645443e-05}, {"id": 593, "seek": 434144, "start": 4348.44, "end": 4357.32, "text": " pre train model so from there one of the nice things about a language model is we don't", "tokens": [659, 3847, 2316, 370, 490, 456, 472, 295, 264, 1481, 721, 466, 257, 2856, 2316, 307, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.12562194237342247, "compression_ratio": 1.5738636363636365, "no_speech_prob": 1.0952925549645443e-05}, {"id": 594, "seek": 434144, "start": 4357.32, "end": 4363.839999999999, "text": " need any label data which is super great right so you could create a fan you know the equivalent", "tokens": [643, 604, 7645, 1412, 597, 307, 1687, 869, 558, 370, 291, 727, 1884, 257, 3429, 291, 458, 264, 10344], "temperature": 0.0, "avg_logprob": -0.12562194237342247, "compression_ratio": 1.5738636363636365, "no_speech_prob": 1.0952925549645443e-05}, {"id": 595, "seek": 436384, "start": 4363.84, "end": 4372.88, "text": " of GPT-2 but for medical texts by training on you know PubMed or medical journals or", "tokens": [295, 26039, 51, 12, 17, 457, 337, 4625, 15765, 538, 3097, 322, 291, 458, 21808, 42954, 420, 4625, 29621, 420], "temperature": 0.0, "avg_logprob": -0.10327820605542286, "compression_ratio": 1.6009174311926606, "no_speech_prob": 8.26756422611652e-06}, {"id": 596, "seek": 436384, "start": 4372.88, "end": 4379.28, "text": " whatever so in my case I just created a language model from Wikipedia because based on what", "tokens": [2035, 370, 294, 452, 1389, 286, 445, 2942, 257, 2856, 2316, 490, 28999, 570, 2361, 322, 437], "temperature": 0.0, "avg_logprob": -0.10327820605542286, "compression_ratio": 1.6009174311926606, "no_speech_prob": 8.26756422611652e-06}, {"id": 597, "seek": 436384, "start": 4379.28, "end": 4383.360000000001, "text": " we know from computer vision it didn't seem to matter too much like in computer vision", "tokens": [321, 458, 490, 3820, 5201, 309, 994, 380, 1643, 281, 1871, 886, 709, 411, 294, 3820, 5201], "temperature": 0.0, "avg_logprob": -0.10327820605542286, "compression_ratio": 1.6009174311926606, "no_speech_prob": 8.26756422611652e-06}, {"id": 598, "seek": 436384, "start": 4383.360000000001, "end": 4387.360000000001, "text": " what kind of images you pre train on so my guess was it wouldn't matter too much what", "tokens": [437, 733, 295, 5267, 291, 659, 3847, 322, 370, 452, 2041, 390, 309, 2759, 380, 1871, 886, 709, 437], "temperature": 0.0, "avg_logprob": -0.10327820605542286, "compression_ratio": 1.6009174311926606, "no_speech_prob": 8.26756422611652e-06}, {"id": 599, "seek": 438736, "start": 4387.36, "end": 4399.92, "text": " kind of texts they pre train on so in in fast AI if you go to docs dot fast AI you can find", "tokens": [733, 295, 15765, 436, 659, 3847, 322, 370, 294, 294, 2370, 7318, 498, 291, 352, 281, 45623, 5893, 2370, 7318, 291, 393, 915], "temperature": 0.0, "avg_logprob": -0.22976339128282336, "compression_ratio": 1.4878048780487805, "no_speech_prob": 1.4144113720249152e-06}, {"id": 600, "seek": 438736, "start": 4399.92, "end": 4414.12, "text": " applications text and one of the really nice things about fast AI is that the documentation", "tokens": [5821, 2487, 293, 472, 295, 264, 534, 1481, 721, 466, 2370, 7318, 307, 300, 264, 14333], "temperature": 0.0, "avg_logprob": -0.22976339128282336, "compression_ratio": 1.4878048780487805, "no_speech_prob": 1.4144113720249152e-06}, {"id": 601, "seek": 441412, "start": 4414.12, "end": 4422.84, "text": " is full of tutorials and all of the documentation is actually built directly out of Jupiter", "tokens": [307, 1577, 295, 17616, 293, 439, 295, 264, 14333, 307, 767, 3094, 3838, 484, 295, 24567], "temperature": 0.0, "avg_logprob": -0.09983555667371635, "compression_ratio": 1.75, "no_speech_prob": 3.6687888496089727e-06}, {"id": 602, "seek": 441412, "start": 4422.84, "end": 4428.28, "text": " notebooks and so you can actually open the Jupiter notebooks and so what I've done is", "tokens": [43782, 293, 370, 291, 393, 767, 1269, 264, 24567, 43782, 293, 370, 437, 286, 600, 1096, 307], "temperature": 0.0, "avg_logprob": -0.09983555667371635, "compression_ratio": 1.75, "no_speech_prob": 3.6687888496089727e-06}, {"id": 603, "seek": 441412, "start": 4428.28, "end": 4432.24, "text": " I've copied one of the Jupiter notebooks out of the fast AI repo and saved it into our", "tokens": [286, 600, 25365, 472, 295, 264, 24567, 43782, 484, 295, 264, 2370, 7318, 49040, 293, 6624, 309, 666, 527], "temperature": 0.0, "avg_logprob": -0.09983555667371635, "compression_ratio": 1.75, "no_speech_prob": 3.6687888496089727e-06}, {"id": 604, "seek": 441412, "start": 4432.24, "end": 4441.04, "text": " course as review NLP transfer and I kind of deleted some of it just to make it a bit smaller", "tokens": [1164, 382, 3131, 426, 45196, 5003, 293, 286, 733, 295, 22981, 512, 295, 309, 445, 281, 652, 309, 257, 857, 4356], "temperature": 0.0, "avg_logprob": -0.09983555667371635, "compression_ratio": 1.75, "no_speech_prob": 3.6687888496089727e-06}, {"id": 605, "seek": 444104, "start": 4441.04, "end": 4447.5199999999995, "text": " but here's the entire process copied straight from the fast AI docs for doing transfer learning", "tokens": [457, 510, 311, 264, 2302, 1399, 25365, 2997, 490, 264, 2370, 7318, 45623, 337, 884, 5003, 2539], "temperature": 0.0, "avg_logprob": -0.1544320366599343, "compression_ratio": 1.6334841628959276, "no_speech_prob": 5.338019491318846e-06}, {"id": 606, "seek": 444104, "start": 4447.5199999999995, "end": 4457.42, "text": " for text as the the the lines of code are nearly identical to what you saw in the computer", "tokens": [337, 2487, 382, 264, 264, 264, 3876, 295, 3089, 366, 6217, 14800, 281, 437, 291, 1866, 294, 264, 3820], "temperature": 0.0, "avg_logprob": -0.1544320366599343, "compression_ratio": 1.6334841628959276, "no_speech_prob": 5.338019491318846e-06}, {"id": 607, "seek": 444104, "start": 4457.42, "end": 4464.48, "text": " vision one but instead of untar data urls dot pets we've got untar data urls dot imdb", "tokens": [5201, 472, 457, 2602, 295, 1701, 289, 1412, 4038, 11784, 5893, 19897, 321, 600, 658, 1701, 289, 1412, 4038, 11784, 5893, 566, 67, 65], "temperature": 0.0, "avg_logprob": -0.1544320366599343, "compression_ratio": 1.6334841628959276, "no_speech_prob": 5.338019491318846e-06}, {"id": 608, "seek": 444104, "start": 4464.48, "end": 4470.48, "text": " and in this case I'm using a sample one of the most important workflow tricks for people", "tokens": [293, 294, 341, 1389, 286, 478, 1228, 257, 6889, 472, 295, 264, 881, 1021, 20993, 11733, 337, 561], "temperature": 0.0, "avg_logprob": -0.1544320366599343, "compression_ratio": 1.6334841628959276, "no_speech_prob": 5.338019491318846e-06}, {"id": 609, "seek": 447048, "start": 4470.48, "end": 4478.599999999999, "text": " doing machine learning is to do 99% of your work on 1% of your data take a really small", "tokens": [884, 3479, 2539, 307, 281, 360, 11803, 4, 295, 428, 589, 322, 502, 4, 295, 428, 1412, 747, 257, 534, 1359], "temperature": 0.0, "avg_logprob": -0.10277601650782994, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.520634577900637e-05}, {"id": 610, "seek": 447048, "start": 4478.599999999999, "end": 4484.799999999999, "text": " amount at random and do nearly all of your work on that you should at least be able to", "tokens": [2372, 412, 4974, 293, 360, 6217, 439, 295, 428, 589, 322, 300, 291, 820, 412, 1935, 312, 1075, 281], "temperature": 0.0, "avg_logprob": -0.10277601650782994, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.520634577900637e-05}, {"id": 611, "seek": 447048, "start": 4484.799999999999, "end": 4489.4, "text": " overfit to a training set really well on a tiny amount of data you can do lots of experiments", "tokens": [670, 6845, 281, 257, 3097, 992, 534, 731, 322, 257, 5870, 2372, 295, 1412, 291, 393, 360, 3195, 295, 12050], "temperature": 0.0, "avg_logprob": -0.10277601650782994, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.520634577900637e-05}, {"id": 612, "seek": 447048, "start": 4489.4, "end": 4494.5599999999995, "text": " in a tiny amount of data so one of the things that we have in fast AI is is sample sized", "tokens": [294, 257, 5870, 2372, 295, 1412, 370, 472, 295, 264, 721, 300, 321, 362, 294, 2370, 7318, 307, 307, 6889, 20004], "temperature": 0.0, "avg_logprob": -0.10277601650782994, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.520634577900637e-05}, {"id": 613, "seek": 447048, "start": 4494.5599999999995, "end": 4500.32, "text": " versions of pretty much all of our data sets and so when you start working with a new data", "tokens": [9606, 295, 1238, 709, 439, 295, 527, 1412, 6352, 293, 370, 562, 291, 722, 1364, 365, 257, 777, 1412], "temperature": 0.0, "avg_logprob": -0.10277601650782994, "compression_ratio": 1.7991967871485943, "no_speech_prob": 1.520634577900637e-05}, {"id": 614, "seek": 450032, "start": 4500.32, "end": 4508.28, "text": " set that that's always the first thing I do is to create a smallish random subset so we're", "tokens": [992, 300, 300, 311, 1009, 264, 700, 551, 286, 360, 307, 281, 1884, 257, 1359, 742, 4974, 25993, 370, 321, 434], "temperature": 0.0, "avg_logprob": -0.10571158727010091, "compression_ratio": 1.7378640776699028, "no_speech_prob": 1.4738721802132204e-05}, {"id": 615, "seek": 450032, "start": 4508.28, "end": 4513.5199999999995, "text": " going to start with a smallish random subset of IMDB and you can see it's basically got", "tokens": [516, 281, 722, 365, 257, 1359, 742, 4974, 25993, 295, 21463, 27735, 293, 291, 393, 536, 309, 311, 1936, 658], "temperature": 0.0, "avg_logprob": -0.10571158727010091, "compression_ratio": 1.7378640776699028, "no_speech_prob": 1.4738721802132204e-05}, {"id": 616, "seek": 450032, "start": 4513.5199999999995, "end": 4522.679999999999, "text": " the film reviews and that is valid but now so that's just in a data frame so we can actually", "tokens": [264, 2007, 10229, 293, 300, 307, 7363, 457, 586, 370, 300, 311, 445, 294, 257, 1412, 3920, 370, 321, 393, 767], "temperature": 0.0, "avg_logprob": -0.10571158727010091, "compression_ratio": 1.7378640776699028, "no_speech_prob": 1.4738721802132204e-05}, {"id": 617, "seek": 450032, "start": 4522.679999999999, "end": 4527.96, "text": " we didn't have to read the data frame we can just directly go text language model data", "tokens": [321, 994, 380, 362, 281, 1401, 264, 1412, 3920, 321, 393, 445, 3838, 352, 2487, 2856, 2316, 1412], "temperature": 0.0, "avg_logprob": -0.10571158727010091, "compression_ratio": 1.7378640776699028, "no_speech_prob": 1.4738721802132204e-05}, {"id": 618, "seek": 452796, "start": 4527.96, "end": 4539.84, "text": " bunch from CSP passing the CSP and we can then start using it for larger corpuses this step", "tokens": [3840, 490, 9460, 47, 8437, 264, 9460, 47, 293, 321, 393, 550, 722, 1228, 309, 337, 4833, 1181, 79, 8355, 341, 1823], "temperature": 0.0, "avg_logprob": -0.13973118277157054, "compression_ratio": 1.5307262569832403, "no_speech_prob": 8.139505553117488e-06}, {"id": 619, "seek": 452796, "start": 4539.84, "end": 4547.6, "text": " will take a few minutes so it can be useful to save the kind of pre tokenized numericalized", "tokens": [486, 747, 257, 1326, 2077, 370, 309, 393, 312, 4420, 281, 3155, 264, 733, 295, 659, 14862, 1602, 29054, 1602], "temperature": 0.0, "avg_logprob": -0.13973118277157054, "compression_ratio": 1.5307262569832403, "no_speech_prob": 8.139505553117488e-06}, {"id": 620, "seek": 452796, "start": 4547.6, "end": 4555.6, "text": " version as Rachel said this this one's actually so small it's not really that necessary so", "tokens": [3037, 382, 14246, 848, 341, 341, 472, 311, 767, 370, 1359, 309, 311, 406, 534, 300, 4818, 370], "temperature": 0.0, "avg_logprob": -0.13973118277157054, "compression_ratio": 1.5307262569832403, "no_speech_prob": 8.139505553117488e-06}, {"id": 621, "seek": 455560, "start": 4555.6, "end": 4566.360000000001, "text": " we have a smaller batch size of smaller GPUs so we load in our IMDB texts and we say do", "tokens": [321, 362, 257, 4356, 15245, 2744, 295, 4356, 18407, 82, 370, 321, 3677, 294, 527, 21463, 27735, 15765, 293, 321, 584, 360], "temperature": 0.0, "avg_logprob": -0.16799264258526742, "compression_ratio": 1.434108527131783, "no_speech_prob": 4.029380761494394e-06}, {"id": 622, "seek": 455560, "start": 4566.360000000001, "end": 4579.620000000001, "text": " it both in language model form and in classifier form and then we create a language model learner", "tokens": [309, 1293, 294, 2856, 2316, 1254, 293, 294, 1508, 9902, 1254, 293, 550, 321, 1884, 257, 2856, 2316, 33347], "temperature": 0.0, "avg_logprob": -0.16799264258526742, "compression_ratio": 1.434108527131783, "no_speech_prob": 4.029380761494394e-06}, {"id": 623, "seek": 457962, "start": 4579.62, "end": 4589.28, "text": " now this step it's actually optional but remember I told you the language model I created was", "tokens": [586, 341, 1823, 309, 311, 767, 17312, 457, 1604, 286, 1907, 291, 264, 2856, 2316, 286, 2942, 390], "temperature": 0.0, "avg_logprob": -0.07451446177595752, "compression_ratio": 1.6407185628742516, "no_speech_prob": 1.2679214478339418e-06}, {"id": 624, "seek": 457962, "start": 4589.28, "end": 4594.2, "text": " trained on Wikipedia right so what we could do is we could take that Wikipedia language", "tokens": [8895, 322, 28999, 558, 370, 437, 321, 727, 360, 307, 321, 727, 747, 300, 28999, 2856], "temperature": 0.0, "avg_logprob": -0.07451446177595752, "compression_ratio": 1.6407185628742516, "no_speech_prob": 1.2679214478339418e-06}, {"id": 625, "seek": 457962, "start": 4594.2, "end": 4604.48, "text": " model and just directly create a text classifier and load in the pre trained Wikipedia model", "tokens": [2316, 293, 445, 3838, 1884, 257, 2487, 1508, 9902, 293, 3677, 294, 264, 659, 8895, 28999, 2316], "temperature": 0.0, "avg_logprob": -0.07451446177595752, "compression_ratio": 1.6407185628742516, "no_speech_prob": 1.2679214478339418e-06}, {"id": 626, "seek": 460448, "start": 4604.48, "end": 4610.799999999999, "text": " and then we could start fitting and that would actually that actually works okay that would", "tokens": [293, 550, 321, 727, 722, 15669, 293, 300, 576, 767, 300, 767, 1985, 1392, 300, 576], "temperature": 0.0, "avg_logprob": -0.08796142602895761, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.1907703739998396e-06}, {"id": 627, "seek": 460448, "start": 4610.799999999999, "end": 4617.44, "text": " be the equivalent of the computer vision version but in LP transfer learning is even better", "tokens": [312, 264, 10344, 295, 264, 3820, 5201, 3037, 457, 294, 38095, 5003, 2539, 307, 754, 1101], "temperature": 0.0, "avg_logprob": -0.08796142602895761, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.1907703739998396e-06}, {"id": 628, "seek": 460448, "start": 4617.44, "end": 4622.08, "text": " because what we can do is whatever we were going to use for classification like in this", "tokens": [570, 437, 321, 393, 360, 307, 2035, 321, 645, 516, 281, 764, 337, 21538, 411, 294, 341], "temperature": 0.0, "avg_logprob": -0.08796142602895761, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.1907703739998396e-06}, {"id": 629, "seek": 460448, "start": 4622.08, "end": 4629.0599999999995, "text": " case movie reviews we can actually fine-tune the language model specifically so it's good", "tokens": [1389, 3169, 10229, 321, 393, 767, 2489, 12, 83, 2613, 264, 2856, 2316, 4682, 370, 309, 311, 665], "temperature": 0.0, "avg_logprob": -0.08796142602895761, "compression_ratio": 1.6869158878504673, "no_speech_prob": 2.1907703739998396e-06}, {"id": 630, "seek": 462906, "start": 4629.06, "end": 4638.56, "text": " at predicting the next word of a movie review so here when we say language model learner", "tokens": [412, 32884, 264, 958, 1349, 295, 257, 3169, 3131, 370, 510, 562, 321, 584, 2856, 2316, 33347], "temperature": 0.0, "avg_logprob": -0.09672741400889862, "compression_ratio": 1.8333333333333333, "no_speech_prob": 4.222783900331706e-06}, {"id": 631, "seek": 462906, "start": 4638.56, "end": 4644.400000000001, "text": " by default again pre trained is true and it knows that the language model that it wants", "tokens": [538, 7576, 797, 659, 8895, 307, 2074, 293, 309, 3255, 300, 264, 2856, 2316, 300, 309, 2738], "temperature": 0.0, "avg_logprob": -0.09672741400889862, "compression_ratio": 1.8333333333333333, "no_speech_prob": 4.222783900331706e-06}, {"id": 632, "seek": 462906, "start": 4644.400000000001, "end": 4649.280000000001, "text": " to use by default is a Wikipedia language model so it starts with something that's learned", "tokens": [281, 764, 538, 7576, 307, 257, 28999, 2856, 2316, 370, 309, 3719, 365, 746, 300, 311, 3264], "temperature": 0.0, "avg_logprob": -0.09672741400889862, "compression_ratio": 1.8333333333333333, "no_speech_prob": 4.222783900331706e-06}, {"id": 633, "seek": 462906, "start": 4649.280000000001, "end": 4655.400000000001, "text": " to predict the next word of Wikipedia well right but then we're passing in our movie", "tokens": [281, 6069, 264, 958, 1349, 295, 28999, 731, 558, 457, 550, 321, 434, 8437, 294, 527, 3169], "temperature": 0.0, "avg_logprob": -0.09672741400889862, "compression_ratio": 1.8333333333333333, "no_speech_prob": 4.222783900331706e-06}, {"id": 634, "seek": 465540, "start": 4655.4, "end": 4666.12, "text": " reviews so now when we say fit it fine-tunes the random you know the new randomly created", "tokens": [10229, 370, 586, 562, 321, 584, 3318, 309, 2489, 12, 83, 15001, 264, 4974, 291, 458, 264, 777, 16979, 2942], "temperature": 0.0, "avg_logprob": -0.10463723171962781, "compression_ratio": 1.6742081447963801, "no_speech_prob": 5.33809316038969e-06}, {"id": 635, "seek": 465540, "start": 4666.12, "end": 4671.44, "text": " weights which in this case are the word embeddings that aren't in the vocab and it starts training", "tokens": [17443, 597, 294, 341, 1389, 366, 264, 1349, 12240, 29432, 300, 3212, 380, 294, 264, 2329, 455, 293, 309, 3719, 3097], "temperature": 0.0, "avg_logprob": -0.10463723171962781, "compression_ratio": 1.6742081447963801, "no_speech_prob": 5.33809316038969e-06}, {"id": 636, "seek": 465540, "start": 4671.44, "end": 4679.44, "text": " those right and so then just like we did before for vision you then go unfreeze and then you", "tokens": [729, 558, 293, 370, 550, 445, 411, 321, 630, 949, 337, 5201, 291, 550, 352, 3971, 701, 1381, 293, 550, 291], "temperature": 0.0, "avg_logprob": -0.10463723171962781, "compression_ratio": 1.6742081447963801, "no_speech_prob": 5.33809316038969e-06}, {"id": 637, "seek": 465540, "start": 4679.44, "end": 4684.679999999999, "text": " fit some more with discriminative learning rates so as you can see the code is identical", "tokens": [3318, 512, 544, 365, 20828, 1166, 2539, 6846, 370, 382, 291, 393, 536, 264, 3089, 307, 14800], "temperature": 0.0, "avg_logprob": -0.10463723171962781, "compression_ratio": 1.6742081447963801, "no_speech_prob": 5.33809316038969e-06}, {"id": 638, "seek": 468468, "start": 4684.68, "end": 4689.88, "text": " and so what we end up with is a language model that's not just good at predicting the next", "tokens": [293, 370, 437, 321, 917, 493, 365, 307, 257, 2856, 2316, 300, 311, 406, 445, 665, 412, 32884, 264, 958], "temperature": 0.0, "avg_logprob": -0.0872229258219401, "compression_ratio": 1.9039301310043668, "no_speech_prob": 5.6823391787474975e-06}, {"id": 639, "seek": 468468, "start": 4689.88, "end": 4694.200000000001, "text": " word of the encyclopedia but it's good at predicting the next word of a movie review", "tokens": [1349, 295, 264, 465, 34080, 47795, 457, 309, 311, 665, 412, 32884, 264, 958, 1349, 295, 257, 3169, 3131], "temperature": 0.0, "avg_logprob": -0.0872229258219401, "compression_ratio": 1.9039301310043668, "no_speech_prob": 5.6823391787474975e-06}, {"id": 640, "seek": 468468, "start": 4694.200000000001, "end": 4698.0, "text": " and therefore it needs to know something about like who are actors and who are actresses", "tokens": [293, 4412, 309, 2203, 281, 458, 746, 466, 411, 567, 366, 10037, 293, 567, 366, 15410, 279], "temperature": 0.0, "avg_logprob": -0.0872229258219401, "compression_ratio": 1.9039301310043668, "no_speech_prob": 5.6823391787474975e-06}, {"id": 641, "seek": 468468, "start": 4698.0, "end": 4702.320000000001, "text": " and which ones are popular and which ones aren't and what kinds of words do people use", "tokens": [293, 597, 2306, 366, 3743, 293, 597, 2306, 3212, 380, 293, 437, 3685, 295, 2283, 360, 561, 764], "temperature": 0.0, "avg_logprob": -0.0872229258219401, "compression_ratio": 1.9039301310043668, "no_speech_prob": 5.6823391787474975e-06}, {"id": 642, "seek": 468468, "start": 4702.320000000001, "end": 4710.0, "text": " when they're excited about a movie versus not and so forth so what we can then do is", "tokens": [562, 436, 434, 2919, 466, 257, 3169, 5717, 406, 293, 370, 5220, 370, 437, 321, 393, 550, 360, 307], "temperature": 0.0, "avg_logprob": -0.0872229258219401, "compression_ratio": 1.9039301310043668, "no_speech_prob": 5.6823391787474975e-06}, {"id": 643, "seek": 471000, "start": 4710.0, "end": 4718.28, "text": " we can then create a text classifier and having saved the fine-tuned IMDB model we can load", "tokens": [321, 393, 550, 1884, 257, 2487, 1508, 9902, 293, 1419, 6624, 264, 2489, 12, 83, 43703, 21463, 27735, 2316, 321, 393, 3677], "temperature": 0.0, "avg_logprob": -0.06417773709152684, "compression_ratio": 1.6094674556213018, "no_speech_prob": 3.6119370179221733e-06}, {"id": 644, "seek": 471000, "start": 4718.28, "end": 4728.4, "text": " that into the classifier and so use that right so we now have the language model with a set", "tokens": [300, 666, 264, 1508, 9902, 293, 370, 764, 300, 558, 370, 321, 586, 362, 264, 2856, 2316, 365, 257, 992], "temperature": 0.0, "avg_logprob": -0.06417773709152684, "compression_ratio": 1.6094674556213018, "no_speech_prob": 3.6119370179221733e-06}, {"id": 645, "seek": 471000, "start": 4728.4, "end": 4733.24, "text": " of random weights on top with two activations because we have negative or positive movie", "tokens": [295, 4974, 17443, 322, 1192, 365, 732, 2430, 763, 570, 321, 362, 3671, 420, 3353, 3169], "temperature": 0.0, "avg_logprob": -0.06417773709152684, "compression_ratio": 1.6094674556213018, "no_speech_prob": 3.6119370179221733e-06}, {"id": 646, "seek": 473324, "start": 4733.24, "end": 4741.24, "text": " reviews and now we can fit that and then we can unfreeze and then we can fit some more", "tokens": [10229, 293, 586, 321, 393, 3318, 300, 293, 550, 321, 393, 3971, 701, 1381, 293, 550, 321, 393, 3318, 512, 544], "temperature": 0.0, "avg_logprob": -0.11556550589474765, "compression_ratio": 1.5495495495495495, "no_speech_prob": 1.8738645621851902e-06}, {"id": 647, "seek": 473324, "start": 4741.24, "end": 4759.5199999999995, "text": " so if we remove the descriptive stuff okay so the actual amount of code we needed was", "tokens": [370, 498, 321, 4159, 264, 42585, 1507, 1392, 370, 264, 3539, 2372, 295, 3089, 321, 2978, 390], "temperature": 0.0, "avg_logprob": -0.11556550589474765, "compression_ratio": 1.5495495495495495, "no_speech_prob": 1.8738645621851902e-06}, {"id": 648, "seek": 475952, "start": 4759.52, "end": 4768.400000000001, "text": " tell it where the path is create the language model and classifier data bunches fit the", "tokens": [980, 309, 689, 264, 3100, 307, 1884, 264, 2856, 2316, 293, 1508, 9902, 1412, 3840, 279, 3318, 264], "temperature": 0.0, "avg_logprob": -0.12935946537898138, "compression_ratio": 2.094488188976378, "no_speech_prob": 2.3320451418840094e-06}, {"id": 649, "seek": 475952, "start": 4768.400000000001, "end": 4777.4800000000005, "text": " language model fine-tune the language model save the language model create the classifier", "tokens": [2856, 2316, 2489, 12, 83, 2613, 264, 2856, 2316, 3155, 264, 2856, 2316, 1884, 264, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.12935946537898138, "compression_ratio": 2.094488188976378, "no_speech_prob": 2.3320451418840094e-06}, {"id": 650, "seek": 475952, "start": 4777.4800000000005, "end": 4784.68, "text": " load the pre-trained weights into it fit the classifier fine-tune the classifier okay so", "tokens": [3677, 264, 659, 12, 17227, 2001, 17443, 666, 309, 3318, 264, 1508, 9902, 2489, 12, 83, 2613, 264, 1508, 9902, 1392, 370], "temperature": 0.0, "avg_logprob": -0.12935946537898138, "compression_ratio": 2.094488188976378, "no_speech_prob": 2.3320451418840094e-06}, {"id": 651, "seek": 478468, "start": 4784.68, "end": 4791.240000000001, "text": " there's actually maybe a dozen lines of code required and the lines of code are almost", "tokens": [456, 311, 767, 1310, 257, 16654, 3876, 295, 3089, 4739, 293, 264, 3876, 295, 3089, 366, 1920], "temperature": 0.0, "avg_logprob": -0.07247100225309046, "compression_ratio": 1.435483870967742, "no_speech_prob": 2.2958759018365527e-06}, {"id": 652, "seek": 478468, "start": 4791.240000000001, "end": 4811.4800000000005, "text": " identical to the vision ones as I was going through this I was kind of interested in things", "tokens": [14800, 281, 264, 5201, 2306, 382, 286, 390, 516, 807, 341, 286, 390, 733, 295, 3102, 294, 721], "temperature": 0.0, "avg_logprob": -0.07247100225309046, "compression_ratio": 1.435483870967742, "no_speech_prob": 2.2958759018365527e-06}, {"id": 653, "seek": 481148, "start": 4811.48, "end": 4826.24, "text": " like so what are the kind of the nice things about using a higher level framework like", "tokens": [411, 370, 437, 366, 264, 733, 295, 264, 1481, 721, 466, 1228, 257, 2946, 1496, 8388, 411], "temperature": 0.0, "avg_logprob": -0.09725956762990644, "compression_ratio": 1.5411764705882354, "no_speech_prob": 1.0782953722809907e-05}, {"id": 654, "seek": 481148, "start": 4826.24, "end": 4831.32, "text": " fast AI is you can do things super quickly you can understand the concepts but then it's", "tokens": [2370, 7318, 307, 291, 393, 360, 721, 1687, 2661, 291, 393, 1223, 264, 10392, 457, 550, 309, 311], "temperature": 0.0, "avg_logprob": -0.09725956762990644, "compression_ratio": 1.5411764705882354, "no_speech_prob": 1.0782953722809907e-05}, {"id": 655, "seek": 481148, "start": 4831.32, "end": 4837.919999999999, "text": " important that you know how to dig into the details so one of the best ways to do that", "tokens": [1021, 300, 291, 458, 577, 281, 2528, 666, 264, 4365, 370, 472, 295, 264, 1151, 2098, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.09725956762990644, "compression_ratio": 1.5411764705882354, "no_speech_prob": 1.0782953722809907e-05}, {"id": 656, "seek": 483792, "start": 4837.92, "end": 4843.76, "text": " is to read the source code I mean obviously at least read the documentation but then also", "tokens": [307, 281, 1401, 264, 4009, 3089, 286, 914, 2745, 412, 1935, 1401, 264, 14333, 457, 550, 611], "temperature": 0.0, "avg_logprob": -0.08145965112222207, "compression_ratio": 1.75, "no_speech_prob": 9.972790394385811e-06}, {"id": 657, "seek": 483792, "start": 4843.76, "end": 4851.28, "text": " read the source code so the documentation you just type doc as Rachel mentioned gives", "tokens": [1401, 264, 4009, 3089, 370, 264, 14333, 291, 445, 2010, 3211, 382, 14246, 2835, 2709], "temperature": 0.0, "avg_logprob": -0.08145965112222207, "compression_ratio": 1.75, "no_speech_prob": 9.972790394385811e-06}, {"id": 658, "seek": 483792, "start": 4851.28, "end": 4858.4400000000005, "text": " you the brief version but more importantly if you click show in docs then you'll get", "tokens": [291, 264, 5353, 3037, 457, 544, 8906, 498, 291, 2052, 855, 294, 45623, 550, 291, 603, 483], "temperature": 0.0, "avg_logprob": -0.08145965112222207, "compression_ratio": 1.75, "no_speech_prob": 9.972790394385811e-06}, {"id": 659, "seek": 483792, "start": 4858.4400000000005, "end": 4865.16, "text": " the full details including links to the papers that are being implemented and sample code", "tokens": [264, 1577, 4365, 3009, 6123, 281, 264, 10577, 300, 366, 885, 12270, 293, 6889, 3089], "temperature": 0.0, "avg_logprob": -0.08145965112222207, "compression_ratio": 1.75, "no_speech_prob": 9.972790394385811e-06}, {"id": 660, "seek": 486516, "start": 4865.16, "end": 4874.0, "text": " that you can run and so forth so that's doc that only works with fast AI the equivalent", "tokens": [300, 291, 393, 1190, 293, 370, 5220, 370, 300, 311, 3211, 300, 787, 1985, 365, 2370, 7318, 264, 10344], "temperature": 0.0, "avg_logprob": -0.08864135008591872, "compression_ratio": 1.5722543352601157, "no_speech_prob": 9.972782208933495e-06}, {"id": 661, "seek": 486516, "start": 4874.0, "end": 4881.44, "text": " for normal Python is help but it has a lot less information but what you can do for anything", "tokens": [337, 2710, 15329, 307, 854, 457, 309, 575, 257, 688, 1570, 1589, 457, 437, 291, 393, 360, 337, 1340], "temperature": 0.0, "avg_logprob": -0.08864135008591872, "compression_ratio": 1.5722543352601157, "no_speech_prob": 9.972782208933495e-06}, {"id": 662, "seek": 486516, "start": 4881.44, "end": 4890.04, "text": " in Python in Jupiter is put two question marks and then you'll get the source code okay and", "tokens": [294, 15329, 294, 24567, 307, 829, 732, 1168, 10640, 293, 550, 291, 603, 483, 264, 4009, 3089, 1392, 293], "temperature": 0.0, "avg_logprob": -0.08864135008591872, "compression_ratio": 1.5722543352601157, "no_speech_prob": 9.972782208933495e-06}, {"id": 663, "seek": 489004, "start": 4890.04, "end": 4895.5199999999995, "text": " so if we want to know what exactly what is get language what language model learning", "tokens": [370, 498, 321, 528, 281, 458, 437, 2293, 437, 307, 483, 2856, 437, 2856, 2316, 2539], "temperature": 0.0, "avg_logprob": -0.15166750298925194, "compression_ratio": 1.627906976744186, "no_speech_prob": 4.092838025826495e-06}, {"id": 664, "seek": 489004, "start": 4895.5199999999995, "end": 4901.16, "text": " doing then we can create the source code now in this case I was interested in thinking", "tokens": [884, 550, 321, 393, 1884, 264, 4009, 3089, 586, 294, 341, 1389, 286, 390, 3102, 294, 1953], "temperature": 0.0, "avg_logprob": -0.15166750298925194, "compression_ratio": 1.627906976744186, "no_speech_prob": 4.092838025826495e-06}, {"id": 665, "seek": 489004, "start": 4901.16, "end": 4907.28, "text": " like well how does it deal with the fact that the vocab for Wikipedia is different for the", "tokens": [411, 731, 577, 775, 309, 2028, 365, 264, 1186, 300, 264, 2329, 455, 337, 28999, 307, 819, 337, 264], "temperature": 0.0, "avg_logprob": -0.15166750298925194, "compression_ratio": 1.627906976744186, "no_speech_prob": 4.092838025826495e-06}, {"id": 666, "seek": 489004, "start": 4907.28, "end": 4913.56, "text": " vocab to IMDB and so Rachel told you about how that happens in the last course so I was", "tokens": [2329, 455, 281, 21463, 27735, 293, 370, 14246, 1907, 291, 466, 577, 300, 2314, 294, 264, 1036, 1164, 370, 286, 390], "temperature": 0.0, "avg_logprob": -0.15166750298925194, "compression_ratio": 1.627906976744186, "no_speech_prob": 4.092838025826495e-06}, {"id": 667, "seek": 491356, "start": 4913.56, "end": 4920.96, "text": " thinking well where does that happen so I saw that language model learner call something", "tokens": [1953, 731, 689, 775, 300, 1051, 370, 286, 1866, 300, 2856, 2316, 33347, 818, 746], "temperature": 0.0, "avg_logprob": -0.14515398810891544, "compression_ratio": 1.9944751381215469, "no_speech_prob": 8.939551662479062e-06}, {"id": 668, "seek": 491356, "start": 4920.96, "end": 4929.0, "text": " called load pre-trained so I thought oh okay well let's look at load pre-trained so here's", "tokens": [1219, 3677, 659, 12, 17227, 2001, 370, 286, 1194, 1954, 1392, 731, 718, 311, 574, 412, 3677, 659, 12, 17227, 2001, 370, 510, 311], "temperature": 0.0, "avg_logprob": -0.14515398810891544, "compression_ratio": 1.9944751381215469, "no_speech_prob": 8.939551662479062e-06}, {"id": 669, "seek": 491356, "start": 4929.0, "end": 4934.160000000001, "text": " the definition of load pre-trained that calls something called convert weights so that must", "tokens": [264, 7123, 295, 3677, 659, 12, 17227, 2001, 300, 5498, 746, 1219, 7620, 17443, 370, 300, 1633], "temperature": 0.0, "avg_logprob": -0.14515398810891544, "compression_ratio": 1.9944751381215469, "no_speech_prob": 8.939551662479062e-06}, {"id": 670, "seek": 491356, "start": 4934.160000000001, "end": 4941.160000000001, "text": " be the thing that actually converts the vocab so here's convert weights and so here's the", "tokens": [312, 264, 551, 300, 767, 38874, 264, 2329, 455, 370, 510, 311, 7620, 17443, 293, 370, 510, 311, 264], "temperature": 0.0, "avg_logprob": -0.14515398810891544, "compression_ratio": 1.9944751381215469, "no_speech_prob": 8.939551662479062e-06}, {"id": 671, "seek": 494116, "start": 4941.16, "end": 4952.68, "text": " algorithm that Rachel was talking about which takes the that random randomly initializes", "tokens": [9284, 300, 14246, 390, 1417, 466, 597, 2516, 264, 300, 4974, 16979, 5883, 5660], "temperature": 0.0, "avg_logprob": -0.1004857469777592, "compression_ratio": 1.5, "no_speech_prob": 1.750231058395002e-05}, {"id": 672, "seek": 494116, "start": 4952.68, "end": 4959.84, "text": " words that are in the IMDB vocab that weren't in the Wikipedia vocab as you can see once", "tokens": [2283, 300, 366, 294, 264, 21463, 27735, 2329, 455, 300, 4999, 380, 294, 264, 28999, 2329, 455, 382, 291, 393, 536, 1564], "temperature": 0.0, "avg_logprob": -0.1004857469777592, "compression_ratio": 1.5, "no_speech_prob": 1.750231058395002e-05}, {"id": 673, "seek": 494116, "start": 4959.84, "end": 4965.599999999999, "text": " you start kind of trying to dig through multiple layers of code in Jupiter notebooks it gets", "tokens": [291, 722, 733, 295, 1382, 281, 2528, 807, 3866, 7914, 295, 3089, 294, 24567, 43782, 309, 2170], "temperature": 0.0, "avg_logprob": -0.1004857469777592, "compression_ratio": 1.5, "no_speech_prob": 1.750231058395002e-05}, {"id": 674, "seek": 496560, "start": 4965.6, "end": 4972.0, "text": " a little bit unwieldy so in terms of like tools which are useful to know one that I", "tokens": [257, 707, 857, 14853, 1789, 88, 370, 294, 2115, 295, 411, 3873, 597, 366, 4420, 281, 458, 472, 300, 286], "temperature": 0.0, "avg_logprob": -0.09468432068824768, "compression_ratio": 1.5855855855855856, "no_speech_prob": 8.013370461412705e-06}, {"id": 675, "seek": 496560, "start": 4972.0, "end": 4979.92, "text": " strongly recommend is visual studio code and that makes it really easy to dig through code", "tokens": [10613, 2748, 307, 5056, 6811, 3089, 293, 300, 1669, 309, 534, 1858, 281, 2528, 807, 3089], "temperature": 0.0, "avg_logprob": -0.09468432068824768, "compression_ratio": 1.5855855855855856, "no_speech_prob": 8.013370461412705e-06}, {"id": 676, "seek": 496560, "start": 4979.92, "end": 4986.0, "text": " like what I just described and in particular a new thing that just came out a couple of", "tokens": [411, 437, 286, 445, 7619, 293, 294, 1729, 257, 777, 551, 300, 445, 1361, 484, 257, 1916, 295], "temperature": 0.0, "avg_logprob": -0.09468432068824768, "compression_ratio": 1.5855855855855856, "no_speech_prob": 8.013370461412705e-06}, {"id": 677, "seek": 496560, "start": 4986.0, "end": 4995.160000000001, "text": " weeks ago is something called VS code remote development because both probably at USF for", "tokens": [3259, 2057, 307, 746, 1219, 25091, 3089, 8607, 3250, 570, 1293, 1391, 412, 2546, 37, 337], "temperature": 0.0, "avg_logprob": -0.09468432068824768, "compression_ratio": 1.5855855855855856, "no_speech_prob": 8.013370461412705e-06}, {"id": 678, "seek": 499516, "start": 4995.16, "end": 5003.68, "text": " your anytime you're using a GPU here and most likely in your workplace after you're finished", "tokens": [428, 13038, 291, 434, 1228, 257, 18407, 510, 293, 881, 3700, 294, 428, 15328, 934, 291, 434, 4335], "temperature": 0.0, "avg_logprob": -0.08731416024659809, "compression_ratio": 1.6272727272727272, "no_speech_prob": 3.120096152997576e-05}, {"id": 679, "seek": 499516, "start": 5003.68, "end": 5009.28, "text": " with your course you'll spend nearly all of your time working on a remote server that's", "tokens": [365, 428, 1164, 291, 603, 3496, 6217, 439, 295, 428, 565, 1364, 322, 257, 8607, 7154, 300, 311], "temperature": 0.0, "avg_logprob": -0.08731416024659809, "compression_ratio": 1.6272727272727272, "no_speech_prob": 3.120096152997576e-05}, {"id": 680, "seek": 499516, "start": 5009.28, "end": 5014.599999999999, "text": " the reality of most particularly deep learning based development which is increasingly what", "tokens": [264, 4103, 295, 881, 4098, 2452, 2539, 2361, 3250, 597, 307, 12980, 437], "temperature": 0.0, "avg_logprob": -0.08731416024659809, "compression_ratio": 1.6272727272727272, "no_speech_prob": 3.120096152997576e-05}, {"id": 681, "seek": 499516, "start": 5014.599999999999, "end": 5021.16, "text": " most machine learning is since we need to use high quality GPUs which aren't normally", "tokens": [881, 3479, 2539, 307, 1670, 321, 643, 281, 764, 1090, 3125, 18407, 82, 597, 3212, 380, 5646], "temperature": 0.0, "avg_logprob": -0.08731416024659809, "compression_ratio": 1.6272727272727272, "no_speech_prob": 3.120096152997576e-05}, {"id": 682, "seek": 502116, "start": 5021.16, "end": 5026.28, "text": " in laptops and also you need to use the data in the organization which is unlikely to be", "tokens": [294, 27642, 293, 611, 291, 643, 281, 764, 264, 1412, 294, 264, 4475, 597, 307, 17518, 281, 312], "temperature": 0.0, "avg_logprob": -0.10575685621816901, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.3630936336994637e-05}, {"id": 683, "seek": 502116, "start": 5026.28, "end": 5038.16, "text": " sitting on your laptop so one approach to this is to work remotely", "tokens": [3798, 322, 428, 10732, 370, 472, 3109, 281, 341, 307, 281, 589, 20824], "temperature": 0.0, "avg_logprob": -0.10575685621816901, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.3630936336994637e-05}, {"id": 684, "seek": 502116, "start": 5038.16, "end": 5044.2, "text": " work remotely through something like Vim which is actually a great approach to doing it so", "tokens": [589, 20824, 807, 746, 411, 691, 332, 597, 307, 767, 257, 869, 3109, 281, 884, 309, 370], "temperature": 0.0, "avg_logprob": -0.10575685621816901, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.3630936336994637e-05}, {"id": 685, "seek": 502116, "start": 5044.2, "end": 5048.72, "text": " if I was using Vim the way I would have done this what I would have been said okay language", "tokens": [498, 286, 390, 1228, 691, 332, 264, 636, 286, 576, 362, 1096, 341, 437, 286, 576, 362, 668, 848, 1392, 2856], "temperature": 0.0, "avg_logprob": -0.10575685621816901, "compression_ratio": 1.7244897959183674, "no_speech_prob": 1.3630936336994637e-05}, {"id": 686, "seek": 504872, "start": 5048.72, "end": 5053.280000000001, "text": " model learner is what I want to know about so in Vim there's these things called tags", "tokens": [2316, 33347, 307, 437, 286, 528, 281, 458, 466, 370, 294, 691, 332, 456, 311, 613, 721, 1219, 18632], "temperature": 0.0, "avg_logprob": -0.10918357997264677, "compression_ratio": 1.8040816326530613, "no_speech_prob": 6.921464228071272e-05}, {"id": 687, "seek": 504872, "start": 5053.280000000001, "end": 5058.4800000000005, "text": " so you can go tag and you can start typing language and then you can hit tab and it'll", "tokens": [370, 291, 393, 352, 6162, 293, 291, 393, 722, 18444, 2856, 293, 550, 291, 393, 2045, 4421, 293, 309, 603], "temperature": 0.0, "avg_logprob": -0.10918357997264677, "compression_ratio": 1.8040816326530613, "no_speech_prob": 6.921464228071272e-05}, {"id": 688, "seek": 504872, "start": 5058.4800000000005, "end": 5065.280000000001, "text": " find any symbols that start with language and it'll take you straight to their definition", "tokens": [915, 604, 16944, 300, 722, 365, 2856, 293, 309, 603, 747, 291, 2997, 281, 641, 7123], "temperature": 0.0, "avg_logprob": -0.10918357997264677, "compression_ratio": 1.8040816326530613, "no_speech_prob": 6.921464228071272e-05}, {"id": 689, "seek": 504872, "start": 5065.280000000001, "end": 5072.52, "text": " in the code and I could start reading through and I'd say oh load pre-trained that looks", "tokens": [294, 264, 3089, 293, 286, 727, 722, 3760, 807, 293, 286, 1116, 584, 1954, 3677, 659, 12, 17227, 2001, 300, 1542], "temperature": 0.0, "avg_logprob": -0.10918357997264677, "compression_ratio": 1.8040816326530613, "no_speech_prob": 6.921464228071272e-05}, {"id": 690, "seek": 504872, "start": 5072.52, "end": 5076.52, "text": " interesting and then you hit control right square bracket and that would take you straight", "tokens": [1880, 293, 550, 291, 2045, 1969, 558, 3732, 16904, 293, 300, 576, 747, 291, 2997], "temperature": 0.0, "avg_logprob": -0.10918357997264677, "compression_ratio": 1.8040816326530613, "no_speech_prob": 6.921464228071272e-05}, {"id": 691, "seek": 507652, "start": 5076.52, "end": 5082.4400000000005, "text": " to the definition of that convert weights okay right square bracket takes you straight", "tokens": [281, 264, 7123, 295, 300, 7620, 17443, 1392, 558, 3732, 16904, 2516, 291, 2997], "temperature": 0.0, "avg_logprob": -0.15981197357177734, "compression_ratio": 1.6418604651162791, "no_speech_prob": 7.296151579794241e-06}, {"id": 692, "seek": 507652, "start": 5082.4400000000005, "end": 5085.6, "text": " to the definition of that so you can certainly do all this stuff in Vim it works super well", "tokens": [281, 264, 7123, 295, 300, 370, 291, 393, 3297, 360, 439, 341, 1507, 294, 691, 332, 309, 1985, 1687, 731], "temperature": 0.0, "avg_logprob": -0.15981197357177734, "compression_ratio": 1.6418604651162791, "no_speech_prob": 7.296151579794241e-06}, {"id": 693, "seek": 507652, "start": 5085.6, "end": 5096.4800000000005, "text": " control t to go back to where I was and so forth but perhaps a easier choice nowadays", "tokens": [1969, 256, 281, 352, 646, 281, 689, 286, 390, 293, 370, 5220, 457, 4317, 257, 3571, 3922, 13434], "temperature": 0.0, "avg_logprob": -0.15981197357177734, "compression_ratio": 1.6418604651162791, "no_speech_prob": 7.296151579794241e-06}, {"id": 694, "seek": 507652, "start": 5096.4800000000005, "end": 5100.76, "text": " particularly with this new remote development system is Visual Studio Code where you can", "tokens": [4098, 365, 341, 777, 8607, 3250, 1185, 307, 23187, 13500, 15549, 689, 291, 393], "temperature": 0.0, "avg_logprob": -0.15981197357177734, "compression_ratio": 1.6418604651162791, "no_speech_prob": 7.296151579794241e-06}, {"id": 695, "seek": 510076, "start": 5100.76, "end": 5109.0, "text": " do the same thing in Visual Studio Code like so basically you can say file open folder", "tokens": [360, 264, 912, 551, 294, 23187, 13500, 15549, 411, 370, 1936, 291, 393, 584, 3991, 1269, 10820], "temperature": 0.0, "avg_logprob": -0.21763541963365343, "compression_ratio": 1.5082872928176796, "no_speech_prob": 7.766676390019711e-06}, {"id": 696, "seek": 510076, "start": 5109.0, "end": 5119.24, "text": " after connecting to your SSH machine and you'll literally see this is my this is the directory", "tokens": [934, 11015, 281, 428, 12238, 39, 3479, 293, 291, 603, 3736, 536, 341, 307, 452, 341, 307, 264, 21120], "temperature": 0.0, "avg_logprob": -0.21763541963365343, "compression_ratio": 1.5082872928176796, "no_speech_prob": 7.766676390019711e-06}, {"id": 697, "seek": 510076, "start": 5119.24, "end": 5126.88, "text": " of the box I have SSH'd into you can see here home jhoward git fastai ls-home slash jhoward", "tokens": [295, 264, 2424, 286, 362, 12238, 39, 1116, 666, 291, 393, 536, 510, 1280, 361, 4286, 515, 18331, 2370, 1301, 287, 82, 12, 25336, 17330, 361, 4286, 515], "temperature": 0.0, "avg_logprob": -0.21763541963365343, "compression_ratio": 1.5082872928176796, "no_speech_prob": 7.766676390019711e-06}, {"id": 698, "seek": 512688, "start": 5126.88, "end": 5134.04, "text": " git so it's actually showing me the contents of my remote machine right and so then I've", "tokens": [18331, 370, 309, 311, 767, 4099, 385, 264, 15768, 295, 452, 8607, 3479, 558, 293, 370, 550, 286, 600], "temperature": 0.0, "avg_logprob": -0.11020521963796308, "compression_ratio": 1.6521739130434783, "no_speech_prob": 4.289277967473026e-06}, {"id": 699, "seek": 512688, "start": 5134.04, "end": 5145.52, "text": " opened up that directory on my remote machine and so I can for example I could go straight", "tokens": [5625, 493, 300, 21120, 322, 452, 8607, 3479, 293, 370, 286, 393, 337, 1365, 286, 727, 352, 2997], "temperature": 0.0, "avg_logprob": -0.11020521963796308, "compression_ratio": 1.6521739130434783, "no_speech_prob": 4.289277967473026e-06}, {"id": 700, "seek": 512688, "start": 5145.52, "end": 5155.88, "text": " to I can start typing length so control t and then start typing language and hit enter", "tokens": [281, 286, 393, 722, 18444, 4641, 370, 1969, 256, 293, 550, 722, 18444, 2856, 293, 2045, 3242], "temperature": 0.0, "avg_logprob": -0.11020521963796308, "compression_ratio": 1.6521739130434783, "no_speech_prob": 4.289277967473026e-06}, {"id": 701, "seek": 515588, "start": 5155.88, "end": 5161.04, "text": " and it takes me straight to the code and so I can do things like oh load pre-trained I", "tokens": [293, 309, 2516, 385, 2997, 281, 264, 3089, 293, 370, 286, 393, 360, 721, 411, 1954, 3677, 659, 12, 17227, 2001, 286], "temperature": 0.0, "avg_logprob": -0.1309288413123747, "compression_ratio": 1.9866071428571428, "no_speech_prob": 2.6687745048548095e-05}, {"id": 702, "seek": 515588, "start": 5161.04, "end": 5166.6, "text": " could just wave my mouse over it and it'll pop up a definition or I can hit control and", "tokens": [727, 445, 5772, 452, 9719, 670, 309, 293, 309, 603, 1665, 493, 257, 7123, 420, 286, 393, 2045, 1969, 293], "temperature": 0.0, "avg_logprob": -0.1309288413123747, "compression_ratio": 1.9866071428571428, "no_speech_prob": 2.6687745048548095e-05}, {"id": 703, "seek": 515588, "start": 5166.6, "end": 5172.32, "text": " click on it and it'll take me straight there I'll convert weights well that sounds interesting", "tokens": [2052, 322, 309, 293, 309, 603, 747, 385, 2997, 456, 286, 603, 7620, 17443, 731, 300, 3263, 1880], "temperature": 0.0, "avg_logprob": -0.1309288413123747, "compression_ratio": 1.9866071428571428, "no_speech_prob": 2.6687745048548095e-05}, {"id": 704, "seek": 515588, "start": 5172.32, "end": 5177.2, "text": " control click on it take me straight there I want to go back I can hit the back button", "tokens": [1969, 2052, 322, 309, 747, 385, 2997, 456, 286, 528, 281, 352, 646, 286, 393, 2045, 264, 646, 2960], "temperature": 0.0, "avg_logprob": -0.1309288413123747, "compression_ratio": 1.9866071428571428, "no_speech_prob": 2.6687745048548095e-05}, {"id": 705, "seek": 515588, "start": 5177.2, "end": 5185.4400000000005, "text": " on my mouse or I can hit alt left either will take me back to where I was before or it's", "tokens": [322, 452, 9719, 420, 286, 393, 2045, 4955, 1411, 2139, 486, 747, 385, 646, 281, 689, 286, 390, 949, 420, 309, 311], "temperature": 0.0, "avg_logprob": -0.1309288413123747, "compression_ratio": 1.9866071428571428, "no_speech_prob": 2.6687745048548095e-05}, {"id": 706, "seek": 518544, "start": 5185.44, "end": 5203.599999999999, "text": " like oh what else what else uses load pre-trained so I can find everything that uses it by", "tokens": [411, 1954, 437, 1646, 437, 1646, 4960, 3677, 659, 12, 17227, 2001, 370, 286, 393, 915, 1203, 300, 4960, 309, 538], "temperature": 0.0, "avg_logprob": -0.15772834737250147, "compression_ratio": 1.4146341463414633, "no_speech_prob": 6.747917723259889e-06}, {"id": 707, "seek": 518544, "start": 5203.599999999999, "end": 5209.759999999999, "text": " hitting alt shift f12 and so here all now I can jump to every part of the code that", "tokens": [8850, 4955, 5513, 283, 4762, 293, 370, 510, 439, 586, 286, 393, 3012, 281, 633, 644, 295, 264, 3089, 300], "temperature": 0.0, "avg_logprob": -0.15772834737250147, "compression_ratio": 1.4146341463414633, "no_speech_prob": 6.747917723259889e-06}, {"id": 708, "seek": 520976, "start": 5209.76, "end": 5221.72, "text": " calls that method or I can open up the sidebar and I can immediately see here's all of the", "tokens": [5498, 300, 3170, 420, 286, 393, 1269, 493, 264, 1252, 5356, 293, 286, 393, 4258, 536, 510, 311, 439, 295, 264], "temperature": 0.0, "avg_logprob": -0.09704495966434479, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.646360245416872e-06}, {"id": 709, "seek": 520976, "start": 5221.72, "end": 5226.92, "text": " methods that are defined in this class and I could jump straight to any of them and so", "tokens": [7150, 300, 366, 7642, 294, 341, 1508, 293, 286, 727, 3012, 2997, 281, 604, 295, 552, 293, 370], "temperature": 0.0, "avg_logprob": -0.09704495966434479, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.646360245416872e-06}, {"id": 710, "seek": 520976, "start": 5226.92, "end": 5235.280000000001, "text": " forth so Visual Studio code is a really nice way of jumping around through a code base", "tokens": [5220, 370, 23187, 13500, 3089, 307, 257, 534, 1481, 636, 295, 11233, 926, 807, 257, 3089, 3096], "temperature": 0.0, "avg_logprob": -0.09704495966434479, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.646360245416872e-06}, {"id": 711, "seek": 523528, "start": 5235.28, "end": 5242.96, "text": " and getting to understand it and now that you can use it on an SSH machine just as easily", "tokens": [293, 1242, 281, 1223, 309, 293, 586, 300, 291, 393, 764, 309, 322, 364, 12238, 39, 3479, 445, 382, 3612], "temperature": 0.0, "avg_logprob": -0.08989901909461388, "compression_ratio": 1.6325301204819278, "no_speech_prob": 5.682337814505445e-06}, {"id": 712, "seek": 523528, "start": 5242.96, "end": 5253.08, "text": " as you can on your own machine it's to me it's the clear clear winner for wanting to", "tokens": [382, 291, 393, 322, 428, 1065, 3479, 309, 311, 281, 385, 309, 311, 264, 1850, 1850, 8507, 337, 7935, 281], "temperature": 0.0, "avg_logprob": -0.08989901909461388, "compression_ratio": 1.6325301204819278, "no_speech_prob": 5.682337814505445e-06}, {"id": 713, "seek": 523528, "start": 5253.08, "end": 5260.36, "text": " understand what's going on and it works particularly well when combined with things like fast AI", "tokens": [1223, 437, 311, 516, 322, 293, 309, 1985, 4098, 731, 562, 9354, 365, 721, 411, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.08989901909461388, "compression_ratio": 1.6325301204819278, "no_speech_prob": 5.682337814505445e-06}, {"id": 714, "seek": 526036, "start": 5260.36, "end": 5265.88, "text": " which are going to design to give you this very layered API where you can understand", "tokens": [597, 366, 516, 281, 1715, 281, 976, 291, 341, 588, 34666, 9362, 689, 291, 393, 1223], "temperature": 0.0, "avg_logprob": -0.16105112433433533, "compression_ratio": 1.5454545454545454, "no_speech_prob": 8.397867532039527e-06}, {"id": 715, "seek": 526036, "start": 5265.88, "end": 5276.4, "text": " just the top layer and then gradually go down down down to the pie torch underneath so that", "tokens": [445, 264, 1192, 4583, 293, 550, 13145, 352, 760, 760, 760, 281, 264, 1730, 27822, 7223, 370, 300], "temperature": 0.0, "avg_logprob": -0.16105112433433533, "compression_ratio": 1.5454545454545454, "no_speech_prob": 8.397867532039527e-06}, {"id": 716, "seek": 526036, "start": 5276.4, "end": 5284.04, "text": " was review CV transfer and review NLP transfer so in both cases we start out with a pre-trained", "tokens": [390, 3131, 22995, 5003, 293, 3131, 426, 45196, 5003, 370, 294, 1293, 3331, 321, 722, 484, 365, 257, 659, 12, 17227, 2001], "temperature": 0.0, "avg_logprob": -0.16105112433433533, "compression_ratio": 1.5454545454545454, "no_speech_prob": 8.397867532039527e-06}, {"id": 717, "seek": 528404, "start": 5284.04, "end": 5291.84, "text": " model we fine-tune it well we first of all we train the new randomly out of weights and", "tokens": [2316, 321, 2489, 12, 83, 2613, 309, 731, 321, 700, 295, 439, 321, 3847, 264, 777, 16979, 484, 295, 17443, 293], "temperature": 0.0, "avg_logprob": -0.11248138103079289, "compression_ratio": 1.6894977168949772, "no_speech_prob": 1.2805086953449063e-05}, {"id": 718, "seek": 528404, "start": 5291.84, "end": 5297.72, "text": " then we find you in the whole thing with discriminative learning rates and for NLP there was one other", "tokens": [550, 321, 915, 291, 294, 264, 1379, 551, 365, 20828, 1166, 2539, 6846, 293, 337, 426, 45196, 456, 390, 472, 661], "temperature": 0.0, "avg_logprob": -0.11248138103079289, "compression_ratio": 1.6894977168949772, "no_speech_prob": 1.2805086953449063e-05}, {"id": 719, "seek": 528404, "start": 5297.72, "end": 5303.08, "text": " optional step which is a really good idea which is to fine-tune the language model before", "tokens": [17312, 1823, 597, 307, 257, 534, 665, 1558, 597, 307, 281, 2489, 12, 83, 2613, 264, 2856, 2316, 949], "temperature": 0.0, "avg_logprob": -0.11248138103079289, "compression_ratio": 1.6894977168949772, "no_speech_prob": 1.2805086953449063e-05}, {"id": 720, "seek": 528404, "start": 5303.08, "end": 5313.0, "text": " you fine-tune the classifier I'm not sure if Rachel's going to get into it in this course", "tokens": [291, 2489, 12, 83, 2613, 264, 1508, 9902, 286, 478, 406, 988, 498, 14246, 311, 516, 281, 483, 666, 309, 294, 341, 1164], "temperature": 0.0, "avg_logprob": -0.11248138103079289, "compression_ratio": 1.6894977168949772, "no_speech_prob": 1.2805086953449063e-05}, {"id": 721, "seek": 531300, "start": 5313.0, "end": 5321.56, "text": " or not but there is one other key difference which is for vision we normally use convolutional", "tokens": [420, 406, 457, 456, 307, 472, 661, 2141, 2649, 597, 307, 337, 5201, 321, 5646, 764, 45216, 304], "temperature": 0.0, "avg_logprob": -0.10524238389113853, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.8924489268101752e-05}, {"id": 722, "seek": 531300, "start": 5321.56, "end": 5329.24, "text": " neural networks which are already familiar with but for language we normally use either", "tokens": [18161, 9590, 597, 366, 1217, 4963, 365, 457, 337, 2856, 321, 5646, 764, 2139], "temperature": 0.0, "avg_logprob": -0.10524238389113853, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.8924489268101752e-05}, {"id": 723, "seek": 531300, "start": 5329.24, "end": 5335.84, "text": " a recurrent neural network or a transformer and I know Rachel's going to be teaching about", "tokens": [257, 18680, 1753, 18161, 3209, 420, 257, 31782, 293, 286, 458, 14246, 311, 516, 281, 312, 4571, 466], "temperature": 0.0, "avg_logprob": -0.10524238389113853, "compression_ratio": 1.6347305389221556, "no_speech_prob": 1.8924489268101752e-05}, {"id": 724, "seek": 533584, "start": 5335.84, "end": 5343.28, "text": " transformers later in the course I don't know if she's going to do RNNs or not but as you", "tokens": [4088, 433, 1780, 294, 264, 1164, 286, 500, 380, 458, 498, 750, 311, 516, 281, 360, 45702, 45, 82, 420, 406, 457, 382, 291], "temperature": 0.0, "avg_logprob": -0.06893070200656323, "compression_ratio": 1.6619718309859155, "no_speech_prob": 1.3419768038147595e-05}, {"id": 725, "seek": 533584, "start": 5343.28, "end": 5348.08, "text": " can see as a kind of a practitioner you don't have to care too much about that difference", "tokens": [393, 536, 382, 257, 733, 295, 257, 32125, 291, 500, 380, 362, 281, 1127, 886, 709, 466, 300, 2649], "temperature": 0.0, "avg_logprob": -0.06893070200656323, "compression_ratio": 1.6619718309859155, "no_speech_prob": 1.3419768038147595e-05}, {"id": 726, "seek": 533584, "start": 5348.08, "end": 5355.4800000000005, "text": " it's it's not really that important right to me it's just like I don't know I'm called", "tokens": [309, 311, 309, 311, 406, 534, 300, 1021, 558, 281, 385, 309, 311, 445, 411, 286, 500, 380, 458, 286, 478, 1219], "temperature": 0.0, "avg_logprob": -0.06893070200656323, "compression_ratio": 1.6619718309859155, "no_speech_prob": 1.3419768038147595e-05}, {"id": 727, "seek": 533584, "start": 5355.4800000000005, "end": 5360.76, "text": " using the sine function or the tan function on my computer I don't really care how it's", "tokens": [1228, 264, 18609, 2445, 420, 264, 7603, 2445, 322, 452, 3820, 286, 500, 380, 534, 1127, 577, 309, 311], "temperature": 0.0, "avg_logprob": -0.06893070200656323, "compression_ratio": 1.6619718309859155, "no_speech_prob": 1.3419768038147595e-05}, {"id": 728, "seek": 536076, "start": 5360.76, "end": 5367.16, "text": " implemented or exactly those minor details it's just a part of the toolkit that I use", "tokens": [12270, 420, 2293, 729, 6696, 4365, 309, 311, 445, 257, 644, 295, 264, 40167, 300, 286, 764], "temperature": 0.0, "avg_logprob": -0.11363278060662942, "compression_ratio": 1.4064171122994653, "no_speech_prob": 2.0580248474288965e-06}, {"id": 729, "seek": 536076, "start": 5367.16, "end": 5374.88, "text": " unless you're doing research into architectures and stuff in which case obviously you need", "tokens": [5969, 291, 434, 884, 2132, 666, 6331, 1303, 293, 1507, 294, 597, 1389, 2745, 291, 643], "temperature": 0.0, "avg_logprob": -0.11363278060662942, "compression_ratio": 1.4064171122994653, "no_speech_prob": 2.0580248474288965e-06}, {"id": 730, "seek": 536076, "start": 5374.88, "end": 5389.34, "text": " to know those details so so finally coming back to 5NNIMDB this is what Rachel started", "tokens": [281, 458, 729, 4365, 370, 370, 2721, 1348, 646, 281, 1025, 45, 45, 6324, 27735, 341, 307, 437, 14246, 1409], "temperature": 0.0, "avg_logprob": -0.11363278060662942, "compression_ratio": 1.4064171122994653, "no_speech_prob": 2.0580248474288965e-06}, {"id": 731, "seek": 538934, "start": 5389.34, "end": 5399.96, "text": " going through in the last lesson this is just really showing you in a much slower step-by-step", "tokens": [516, 807, 294, 264, 1036, 6898, 341, 307, 445, 534, 4099, 291, 294, 257, 709, 14009, 1823, 12, 2322, 12, 16792], "temperature": 0.0, "avg_logprob": -0.07744419959283644, "compression_ratio": 1.630952380952381, "no_speech_prob": 5.955067535978742e-06}, {"id": 732, "seek": 538934, "start": 5399.96, "end": 5409.16, "text": " process all of those all of those steps right and particularly understanding this idea that", "tokens": [1399, 439, 295, 729, 439, 295, 729, 4439, 558, 293, 4098, 3701, 341, 1558, 300], "temperature": 0.0, "avg_logprob": -0.07744419959283644, "compression_ratio": 1.630952380952381, "no_speech_prob": 5.955067535978742e-06}, {"id": 733, "seek": 538934, "start": 5409.16, "end": 5417.0, "text": " there's a vocabulary and that that vocabulary will differ when you use a new corpus and", "tokens": [456, 311, 257, 19864, 293, 300, 300, 19864, 486, 743, 562, 291, 764, 257, 777, 1181, 31624, 293], "temperature": 0.0, "avg_logprob": -0.07744419959283644, "compression_ratio": 1.630952380952381, "no_speech_prob": 5.955067535978742e-06}, {"id": 734, "seek": 541700, "start": 5417.0, "end": 5430.84, "text": " you're fine-tuning is super important but I trained this model for a while and so first", "tokens": [291, 434, 2489, 12, 83, 37726, 307, 1687, 1021, 457, 286, 8895, 341, 2316, 337, 257, 1339, 293, 370, 700], "temperature": 0.0, "avg_logprob": -0.08612748980522156, "compression_ratio": 1.43801652892562, "no_speech_prob": 3.6477049434324726e-05}, {"id": 735, "seek": 541700, "start": 5430.84, "end": 5440.4, "text": " of all fine-tuned I fine-tuned the language model then I loaded that into a classifier", "tokens": [295, 439, 2489, 12, 83, 43703, 286, 2489, 12, 83, 43703, 264, 2856, 2316, 550, 286, 13210, 300, 666, 257, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.08612748980522156, "compression_ratio": 1.43801652892562, "no_speech_prob": 3.6477049434324726e-05}, {"id": 736, "seek": 544040, "start": 5440.4, "end": 5457.48, "text": " and fine-tuned the classifier and here it is here we are lower encoder and so I just", "tokens": [293, 2489, 12, 83, 43703, 264, 1508, 9902, 293, 510, 309, 307, 510, 321, 366, 3126, 2058, 19866, 293, 370, 286, 445], "temperature": 0.0, "avg_logprob": -0.13135241099766323, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.289258868084289e-06}, {"id": 737, "seek": 544040, "start": 5457.48, "end": 5461.799999999999, "text": " gave it so once you've fine-tuned the language model the classifier generally you can train", "tokens": [2729, 309, 370, 1564, 291, 600, 2489, 12, 83, 43703, 264, 2856, 2316, 264, 1508, 9902, 5101, 291, 393, 3847], "temperature": 0.0, "avg_logprob": -0.13135241099766323, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.289258868084289e-06}, {"id": 738, "seek": 544040, "start": 5461.799999999999, "end": 5466.839999999999, "text": " pretty quickly so it took me about a minute to fine-tune the to train the newly added", "tokens": [1238, 2661, 370, 309, 1890, 385, 466, 257, 3456, 281, 2489, 12, 83, 2613, 264, 281, 3847, 264, 15109, 3869], "temperature": 0.0, "avg_logprob": -0.13135241099766323, "compression_ratio": 1.6582278481012658, "no_speech_prob": 4.289258868084289e-06}, {"id": 739, "seek": 546684, "start": 5466.84, "end": 5471.24, "text": " weights so that was after freezing and then I unfroze and train for another two or three", "tokens": [17443, 370, 300, 390, 934, 20200, 293, 550, 286, 3971, 340, 1381, 293, 3847, 337, 1071, 732, 420, 1045], "temperature": 0.0, "avg_logprob": -0.1318149675022472, "compression_ratio": 1.6116071428571428, "no_speech_prob": 5.954995231149951e-06}, {"id": 740, "seek": 546684, "start": 5471.24, "end": 5481.360000000001, "text": " minutes per epoch or for epochs and the accuracy I got was 94.1% so this is on a single GPU", "tokens": [2077, 680, 30992, 339, 420, 337, 30992, 28346, 293, 264, 14170, 286, 658, 390, 30849, 13, 16, 4, 370, 341, 307, 322, 257, 2167, 18407], "temperature": 0.0, "avg_logprob": -0.1318149675022472, "compression_ratio": 1.6116071428571428, "no_speech_prob": 5.954995231149951e-06}, {"id": 741, "seek": 546684, "start": 5481.360000000001, "end": 5488.08, "text": " training for not very long and to give you a sense of like what does that mean I checked", "tokens": [3097, 337, 406, 588, 938, 293, 281, 976, 291, 257, 2020, 295, 411, 437, 775, 300, 914, 286, 10033], "temperature": 0.0, "avg_logprob": -0.1318149675022472, "compression_ratio": 1.6116071428571428, "no_speech_prob": 5.954995231149951e-06}, {"id": 742, "seek": 546684, "start": 5488.08, "end": 5492.76, "text": " up the literature and before you will answer this this transfer learning approach is called", "tokens": [493, 264, 10394, 293, 949, 291, 486, 1867, 341, 341, 5003, 2539, 3109, 307, 1219], "temperature": 0.0, "avg_logprob": -0.1318149675022472, "compression_ratio": 1.6116071428571428, "no_speech_prob": 5.954995231149951e-06}, {"id": 743, "seek": 549276, "start": 5492.76, "end": 5497.0, "text": " ULM fit that's a paper we released a couple of years ago before we released this paper", "tokens": [624, 43, 44, 3318, 300, 311, 257, 3035, 321, 4736, 257, 1916, 295, 924, 2057, 949, 321, 4736, 341, 3035], "temperature": 0.0, "avg_logprob": -0.13208250565962357, "compression_ratio": 1.6330275229357798, "no_speech_prob": 3.4465235785319237e-06}, {"id": 744, "seek": 549276, "start": 5497.0, "end": 5505.76, "text": " 94.1 was the best result that had ever been achieved for this data set right so this process", "tokens": [30849, 13, 16, 390, 264, 1151, 1874, 300, 632, 1562, 668, 11042, 337, 341, 1412, 992, 558, 370, 341, 1399], "temperature": 0.0, "avg_logprob": -0.13208250565962357, "compression_ratio": 1.6330275229357798, "no_speech_prob": 3.4465235785319237e-06}, {"id": 745, "seek": 549276, "start": 5505.76, "end": 5514.72, "text": " is not showing you like an okay way to kind of get by it NLP this is literally matching", "tokens": [307, 406, 4099, 291, 411, 364, 1392, 636, 281, 733, 295, 483, 538, 309, 426, 45196, 341, 307, 3736, 14324], "temperature": 0.0, "avg_logprob": -0.13208250565962357, "compression_ratio": 1.6330275229357798, "no_speech_prob": 3.4465235785319237e-06}, {"id": 746, "seek": 549276, "start": 5514.72, "end": 5520.64, "text": " what before this was the best result anybody had gotten and it's super easy to get quite", "tokens": [437, 949, 341, 390, 264, 1151, 1874, 4472, 632, 5768, 293, 309, 311, 1687, 1858, 281, 483, 1596], "temperature": 0.0, "avg_logprob": -0.13208250565962357, "compression_ratio": 1.6330275229357798, "no_speech_prob": 3.4465235785319237e-06}, {"id": 747, "seek": 552064, "start": 5520.64, "end": 5529.84, "text": " a bit better than this we got to 95% plus just training a little bit longer and doing", "tokens": [257, 857, 1101, 813, 341, 321, 658, 281, 13420, 4, 1804, 445, 3097, 257, 707, 857, 2854, 293, 884], "temperature": 0.0, "avg_logprob": -0.0982004137181524, "compression_ratio": 1.5172413793103448, "no_speech_prob": 5.014675025449833e-06}, {"id": 748, "seek": 552064, "start": 5529.84, "end": 5539.0, "text": " a reverse model and stuff as well and like even the the language model although it's", "tokens": [257, 9943, 2316, 293, 1507, 382, 731, 293, 411, 754, 264, 264, 2856, 2316, 4878, 309, 311], "temperature": 0.0, "avg_logprob": -0.0982004137181524, "compression_ratio": 1.5172413793103448, "no_speech_prob": 5.014675025449833e-06}, {"id": 749, "seek": 552064, "start": 5539.0, "end": 5548.240000000001, "text": " like nothing nearly as big or trained as long or with as much data as GPT-2 it's still making", "tokens": [411, 1825, 6217, 382, 955, 420, 8895, 382, 938, 420, 365, 382, 709, 1412, 382, 26039, 51, 12, 17, 309, 311, 920, 1455], "temperature": 0.0, "avg_logprob": -0.0982004137181524, "compression_ratio": 1.5172413793103448, "no_speech_prob": 5.014675025449833e-06}, {"id": 750, "seek": 554824, "start": 5548.24, "end": 5564.16, "text": " perfectly adequate text generation as you can see okay so I think that's all I wanted", "tokens": [6239, 20927, 2487, 5125, 382, 291, 393, 536, 1392, 370, 286, 519, 300, 311, 439, 286, 1415], "temperature": 0.0, "avg_logprob": -0.07344316181383635, "compression_ratio": 1.3076923076923077, "no_speech_prob": 6.339050742099062e-06}, {"id": 751, "seek": 554824, "start": 5564.16, "end": 5575.32, "text": " to cover today definitely encourage people to get involved in the NLP community this", "tokens": [281, 2060, 965, 2138, 5373, 561, 281, 483, 3288, 294, 264, 426, 45196, 1768, 341], "temperature": 0.0, "avg_logprob": -0.07344316181383635, "compression_ratio": 1.3076923076923077, "no_speech_prob": 6.339050742099062e-06}, {"id": 752, "seek": 557532, "start": 5575.32, "end": 5587.5599999999995, "text": " idea of transfer learning and fine-tuning for NLP is super super new nobody had heard", "tokens": [1558, 295, 5003, 2539, 293, 2489, 12, 83, 37726, 337, 426, 45196, 307, 1687, 1687, 777, 5079, 632, 2198], "temperature": 0.0, "avg_logprob": -0.07627661087933708, "compression_ratio": 1.4887640449438202, "no_speech_prob": 3.905368885170901e-06}, {"id": 753, "seek": 557532, "start": 5587.5599999999995, "end": 5594.639999999999, "text": " of it until I don't know a couple of years ago it's people are vaguely aware of it now", "tokens": [295, 309, 1826, 286, 500, 380, 458, 257, 1916, 295, 924, 2057, 309, 311, 561, 366, 13501, 48863, 3650, 295, 309, 586], "temperature": 0.0, "avg_logprob": -0.07627661087933708, "compression_ratio": 1.4887640449438202, "no_speech_prob": 3.905368885170901e-06}, {"id": 754, "seek": 557532, "start": 5594.639999999999, "end": 5600.48, "text": " because the open AI work got a lot of publicity but even that people are very focused on the", "tokens": [570, 264, 1269, 7318, 589, 658, 257, 688, 295, 37264, 457, 754, 300, 561, 366, 588, 5178, 322, 264], "temperature": 0.0, "avg_logprob": -0.07627661087933708, "compression_ratio": 1.4887640449438202, "no_speech_prob": 3.905368885170901e-06}, {"id": 755, "seek": 560048, "start": 5600.48, "end": 5607.32, "text": " actual language model itself the text generation not many people have noticed that that's just", "tokens": [3539, 2856, 2316, 2564, 264, 2487, 5125, 406, 867, 561, 362, 5694, 300, 300, 311, 445], "temperature": 0.0, "avg_logprob": -0.09266968369483948, "compression_ratio": 1.5973451327433628, "no_speech_prob": 1.045124554366339e-05}, {"id": 756, "seek": 560048, "start": 5607.32, "end": 5614.36, "text": " a side effect and what actually matters is that we can create replace the language modeling", "tokens": [257, 1252, 1802, 293, 437, 767, 7001, 307, 300, 321, 393, 1884, 7406, 264, 2856, 15983], "temperature": 0.0, "avg_logprob": -0.09266968369483948, "compression_ratio": 1.5973451327433628, "no_speech_prob": 1.045124554366339e-05}, {"id": 757, "seek": 560048, "start": 5614.36, "end": 5621.78, "text": " layer with a classifier or a sequence label or a translator or whatever and like pretty", "tokens": [4583, 365, 257, 1508, 9902, 420, 257, 8310, 7645, 420, 257, 35223, 420, 2035, 293, 411, 1238], "temperature": 0.0, "avg_logprob": -0.09266968369483948, "compression_ratio": 1.5973451327433628, "no_speech_prob": 1.045124554366339e-05}, {"id": 758, "seek": 560048, "start": 5621.78, "end": 5627.839999999999, "text": " much instantly get state-of-the-art results on almost any NLP task you can come across", "tokens": [709, 13518, 483, 1785, 12, 2670, 12, 3322, 12, 446, 3542, 322, 1920, 604, 426, 45196, 5633, 291, 393, 808, 2108], "temperature": 0.0, "avg_logprob": -0.09266968369483948, "compression_ratio": 1.5973451327433628, "no_speech_prob": 1.045124554366339e-05}, {"id": 759, "seek": 562784, "start": 5627.84, "end": 5631.96, "text": " so you know in terms of thinking like what do you do next post-university for those of", "tokens": [370, 291, 458, 294, 2115, 295, 1953, 411, 437, 360, 291, 360, 958, 2183, 12, 409, 2550, 337, 729, 295], "temperature": 0.0, "avg_logprob": -0.11070266962051392, "compression_ratio": 1.6713615023474178, "no_speech_prob": 2.769364527921425e-06}, {"id": 760, "seek": 562784, "start": 5631.96, "end": 5640.360000000001, "text": " you through in the USF course there's this wide open opportunity to take like anywhere", "tokens": [291, 807, 294, 264, 2546, 37, 1164, 456, 311, 341, 4874, 1269, 2650, 281, 747, 411, 4992], "temperature": 0.0, "avg_logprob": -0.11070266962051392, "compression_ratio": 1.6713615023474178, "no_speech_prob": 2.769364527921425e-06}, {"id": 761, "seek": 562784, "start": 5640.360000000001, "end": 5650.0, "text": " you see people analyzing text or or gathering text as part of their business model there's", "tokens": [291, 536, 561, 23663, 2487, 420, 420, 13519, 2487, 382, 644, 295, 641, 1606, 2316, 456, 311], "temperature": 0.0, "avg_logprob": -0.11070266962051392, "compression_ratio": 1.6713615023474178, "no_speech_prob": 2.769364527921425e-06}, {"id": 762, "seek": 562784, "start": 5650.0, "end": 5656.5, "text": " an opportunity to do that far far better well for areas where people are currently manually", "tokens": [364, 2650, 281, 360, 300, 1400, 1400, 1101, 731, 337, 3179, 689, 561, 366, 4362, 16945], "temperature": 0.0, "avg_logprob": -0.11070266962051392, "compression_ratio": 1.6713615023474178, "no_speech_prob": 2.769364527921425e-06}, {"id": 763, "seek": 565650, "start": 5656.5, "end": 5662.22, "text": " reading and processing text you can quite likely automate that now so we're kind of in one", "tokens": [3760, 293, 9007, 2487, 291, 393, 1596, 3700, 31605, 300, 586, 370, 321, 434, 733, 295, 294, 472], "temperature": 0.0, "avg_logprob": -0.05709300814448176, "compression_ratio": 1.7313432835820894, "no_speech_prob": 1.4738489880983252e-05}, {"id": 764, "seek": 565650, "start": 5662.22, "end": 5669.2, "text": " of these really nice little periods of time between like technology invented here and", "tokens": [295, 613, 534, 1481, 707, 13804, 295, 565, 1296, 411, 2899, 14479, 510, 293], "temperature": 0.0, "avg_logprob": -0.05709300814448176, "compression_ratio": 1.7313432835820894, "no_speech_prob": 1.4738489880983252e-05}, {"id": 765, "seek": 565650, "start": 5669.2, "end": 5674.52, "text": " technology used everywhere there and that bit in the middle is the bit where people", "tokens": [2899, 1143, 5315, 456, 293, 300, 857, 294, 264, 2808, 307, 264, 857, 689, 561], "temperature": 0.0, "avg_logprob": -0.05709300814448176, "compression_ratio": 1.7313432835820894, "no_speech_prob": 1.4738489880983252e-05}, {"id": 766, "seek": 565650, "start": 5674.52, "end": 5680.5, "text": " like you can go and create new businesses and products and stuff like that which didn't", "tokens": [411, 291, 393, 352, 293, 1884, 777, 6011, 293, 3383, 293, 1507, 411, 300, 597, 994, 380], "temperature": 0.0, "avg_logprob": -0.05709300814448176, "compression_ratio": 1.7313432835820894, "no_speech_prob": 1.4738489880983252e-05}, {"id": 767, "seek": 568050, "start": 5680.5, "end": 5687.16, "text": " exist before and so it's a really good really good time to do that or if you're looking", "tokens": [2514, 949, 293, 370, 309, 311, 257, 534, 665, 534, 665, 565, 281, 360, 300, 420, 498, 291, 434, 1237], "temperature": 0.0, "avg_logprob": -0.09057973909981643, "compression_ratio": 1.644859813084112, "no_speech_prob": 6.339061201288132e-06}, {"id": 768, "seek": 568050, "start": 5687.16, "end": 5692.84, "text": " to join an existing startup looking for startups that are taking advantage of NLP transfer", "tokens": [281, 3917, 364, 6741, 18578, 1237, 337, 28041, 300, 366, 1940, 5002, 295, 426, 45196, 5003], "temperature": 0.0, "avg_logprob": -0.09057973909981643, "compression_ratio": 1.644859813084112, "no_speech_prob": 6.339061201288132e-06}, {"id": 769, "seek": 568050, "start": 5692.84, "end": 5698.52, "text": " learning to do something that was previously not done at all or was done badly would be", "tokens": [2539, 281, 360, 746, 300, 390, 8046, 406, 1096, 412, 439, 420, 390, 1096, 13425, 576, 312], "temperature": 0.0, "avg_logprob": -0.09057973909981643, "compression_ratio": 1.644859813084112, "no_speech_prob": 6.339061201288132e-06}, {"id": 770, "seek": 568050, "start": 5698.52, "end": 5709.16, "text": " a great opportunity as well okay so anybody have any questions before we wrap up okay", "tokens": [257, 869, 2650, 382, 731, 1392, 370, 4472, 362, 604, 1651, 949, 321, 7019, 493, 1392], "temperature": 0.0, "avg_logprob": -0.09057973909981643, "compression_ratio": 1.644859813084112, "no_speech_prob": 6.339061201288132e-06}, {"id": 771, "seek": 570916, "start": 5709.16, "end": 5712.48, "text": " thanks everybody and next time we'll be back with Rachel", "tokens": [50364, 3231, 2201, 293, 958, 565, 321, 603, 312, 646, 365, 14246, 50530], "temperature": 0.0, "avg_logprob": -0.12455429349626813, "compression_ratio": 0.9032258064516129, "no_speech_prob": 0.00018686044495552778}], "language": "en"}