{"text": " Welcome again everybody. Some really fun stuff appearing on the forums this week. One of the really great projects which was created by I believe our sole Bulgarian participant in the course, Slav Ivanov, wrote a great post about picking an optimizer for style optimizer. This post came from a forum discussion in which I made an offhand remark about how I didn't know that in theory BFGS is a deterministic optimizer, it uses a line search, it approximates the Hessian, it ought to work on this kind of deterministic problem better. But I hadn't tried it myself and I hadn't seen anybody try it, so maybe somebody should try it. I don't know if you've noticed, but pretty much every week I say something like that a number of times and every time I do I'm always hoping that somebody might go, I wonder as well. So Slav did wonder and he posted a really interesting blog post about that exact question. I was thrilled to see that the blog post got a lot of pick-up. On the Machine Learning Reddit it got 55 upvotes which for that subreddit put it in second place on the front page. It also got picked up by the WildML mailing list weekly summary of interesting things in AI as the second post that was listed. So that was great. For those of you that have looked at it and wondered what is it about this post that causes it to get noticed whereas other ones don't, I'm not sure I know the secret, but as soon as I read it I thought okay, I think a lot of people are going to read this. It gives some background. It assumes an intelligent reader, but it assumes an intelligent reader who doesn't necessarily know all about this. Something like you guys 6 months ago. So it types like this is what it is and this is where this kind of thing is used and gives some examples. And then goes ahead and sets up the question of different optimization algorithms and then shows lots of examples of both learning curves as well as pictures that come out of these different experiments. I think hopefully it's been a great experience for Slav as well because in the Reddit thread there's all kinds of folks pointing out other things that he could try, questions that weren't quite clear. So now there's a whole list of things that could be done next. So it opened up a whole interesting question. Another post which I'm not even sure if it's officially posted yet, I got the early bird version from Brad, is this crazy thing. Here is Kanye drawn using a brush of Captain John Luke Picard. In case you're wondering is that really him, I will show you a zoomed in version. It really is John Luke Picard. This is a really interesting idea because he points out that generally speaking, when you try to use a non-artwork as your style image, it doesn't actually give very good results. It's another example of a non-artwork, it doesn't give good results. It's kind of interesting but it's not quite what I was looking for. But if you tile it, you totally get it. So here's Kanye using a Nintendo game controller brush. So then he tried out this John Luke Picard and got okay results and kind of realized that actually the size of the texture is pretty critical. I've never seen anybody do this before. I think when this image gets shared on Twitter, it's going to go everywhere because it's just the freakiest thing. Freaky's good. I think I warned you guys about your projects when I first mentioned them as being something that's very easy to overshoot a little bit and spend weeks and weeks talking about what you're eventually going to do. You've had a couple of weeks, really it would have been nice to have something done by now rather than spending a couple of weeks wondering about what to do. So if your team's being a bit slow agreeing on something, just start working on something yourself. Or as a team, just pick something that you can do by next Monday and write up something brief about it. So for example, if you're thinking, okay we might do the $1 million data science bowl, that's fine. You're not going to finish it by Monday. But maybe by Monday you could have written a blog post introducing what you can learn in a week about medical imaging. Oh it turns out it uses something called DICOM. Here are the Python DICOM libraries and we tried to use them. These are the things that got us kind of confused and these are the ways that we solved them. And here's a Python notebook which shows you some of the main ways you can look at these DICOM for instance. So split up your project into little pieces. It's like when you enter a Kaggle competition, I always tell people, submit every single day and try and put in at least half an hour a day to make it slightly better than yesterday. So how do you put in the first day submission? So what I always do on the first day is to submit the benchmark script, which is generally like all zeros. And then the next day I try to improve it, so I'll put in like all 0.5s. The next day I try to improve it, I'll be like okay what's the average for cats, the average for dogs, I'll submit that. And if you do that every day for 90 days, you'll be amazed at how much you can achieve. Or else if you wait two months and spend all that time reading papers and theorizing and thinking about the best possible approach, you'll discover that you don't get any submissions in. Or you finally get your perfect submission in and it goes terribly and now you don't have time to make it better. I think those tips are equally useful for Kaggle competitions as well as for making sure that at the end of this part of the course, you have something that you're proud of, something that you feel you did a good job in a small amount of time. If you try and publish something every week on the same kind of topic, you'll be able to keep going further and further on that thing. I don't know what Slav's plans are, but maybe next week he'll follow up on some of the interesting research angles that came up on Reddit. Or maybe Brad will follow up on some of his additional ideas from his post. There's a Lesson 10 Wiki up already which has the notebooks. Just do a git pull on the GitHub repo to get the most up-to-date. Another thing that I wanted to point out is that in study group, so we've been having study groups each Friday here, and I know some of you have had study groups elsewhere around the Bay Area. One of you asked me, I don't understand this gray matrix stuff. I don't get it. What's going on? I understand the symbols, I understand the math, but what's going on? And I said, maybe if you had a spreadsheet, it would all make sense. And he was kind of like, I'm doing it in Python, Python's nice. Maybe if you had a spreadsheet, it would all make sense. Maybe I'll create a spreadsheet. Yes, do that. And 20 minutes later, I turned to him and I said, so how do you feel about gray matrices now? And he goes, I totally understand them. And I looked over and he had created a spreadsheet. This was the spreadsheet he created. It's a very simple spreadsheet where it's like here's an image where the pixels are just like 1, minus 1, and 0. It has two filters that are either 1 or minus 1. He has the flattened convolutions next to each other, and then he's created the dot product matrix. So I haven't been doing so much Excel stuff myself, but I think you learn a lot more by trying it yourself. Particularly if you try it yourself and can't figure out how to do it in Excel, then we have the forums. I love Excel, so if you ask me questions about Excel, I will have a great time. I'm not going to put that one on the forum for now because I think it's so easy to create and you'd get so much more out of doing it yourself for anybody who's still not quite understanding what gray matrices are doing. So last week we talked about the idea of learning with larger datasets. Our goal was to try and replicate the devise paper. And to remind you, the devise paper is the one where we do a regular CNN, but the thing that we're trying to predict is not a one-hot encoding of the category, but it's the word vector for the category. So it's an interesting problem, but one of the things that's interesting about it is we have to use all of ImageNet, which has its own challenges. So last week we got to the point where we had created the word vectors. And remember the word vectors, we then had to map them to ImageNet categories. There were 1000 ImageNet categories so we had to create the word vector for each one. We didn't quite get all of them to match, but something like 2-thirds of them matched, so we're working on 2-thirds of ImageNet. We've got as far as reading all the file names for ImageNet, and then we're going to resize our images to 224x224. I think it's a good idea to do some of this preprocessing up front. Something that TensorFlow and PyTorch both do and Keras recently started doing is that if you use a generator, it actually does the image preprocessing in a number of separate threads in parallel behind the scenes. And so some of this is a little less important than it was 6 months ago when Keras didn't do that. It used to be that we had to spend a long time waiting for our data to get processed before it could get into the CNN. Having said that, particularly image resizing, when you've got large JPEGs, just reading them off the hard disk and resizing them can take quite a long time. I always like to put it into do all that resizing up front and end up with something in a nice convenient B-collerate. Amongst other things, it means that unless you have enough money to have a huge NVMe or SSD drive, which you can put the entirety of ImageNet on, you probably have your big data sets on some kind of pretty slow spinning disk or slow rate array. So one of the nice things about doing the resizing first is that it makes it a lot smaller and you probably can then fit it on your SSD. There's lots of reasons that I think this is good. So I'm going to resize all of the ImageNet images, put them in a big holes array on my SSD. So here's the path, and dpath is the path to my fast SSD mount point. And we talked briefly about the things that actually do the resizing, and we're going to do a different kind of resizing. In the past we've done the same kind of resizing that Keras does, which is to add a black border. Like if you start with something that's not square and you make it square, you resize the largest axis to be the size of your square, which means you're left with a black border. I was concerned that any model where you have that is going to have to learn to model the black border, and b, that you're kind of throwing away information, you're not using the full size of the image. And indeed, every other library or pretty much paper I've seen uses a different approach, which is to resize the smaller side of the image to the square. Now the larger size is now too big for your square, so you crop off the top and bottom, or crop off the left and right. So this is called center cropping approach. Question asked. That's true. What you're doing is throwing away compute. With the one where you do center crop, you have a complete 224 thing full of meaningful pixels. Whereas with a black border, you have a 180x224 bit with meaningful pixels and a whole bunch of black pixels. That can be a problem. It works well for ImageNet because ImageNet things are generally somewhat centered. You may need to do some kind of initial step to do a heatmap or something like we did in Lesson 7 to figure out roughly where the thing is before you decide where to center the crop. So these things are all compromises. But I've got to say, since I switched to using this approach, I feel like my models have trained a lot faster and given better results, certainly the super resolution. Now I said last week that we were going to start looking at parallel processing. If you're wondering about last week's homework, we're going to get there. But some of the techniques we're about to learn, we're going to use to do last week's homework even better. So don't worry. So what I want to do is I've got a CPU with something like 10 cores on it, and then each of those cores have hyperthreading, so it means each of those cores can do kind of two things at once. So I really want to be able to have a couple of dozen processors going on, each one resizing an image. That's called parallel processing. And just to remind you, this is as opposed to vectorization or SIMD, which is where a single thread operates on a bunch of things at a time. So we learned that to get SIMD working you just have to install HelloSIMD. Now we're going to, as well as the 600% speedup, also get another 10 or 20x speedup by doing parallel processing. The basic approach to parallel processing in Python 3 is to set up something called either a process pool or a thread pool. So the idea here is that we've got a number of little programs running, threads or processes, and when we set up that pool, we say how many of those little programs do we want to fire up. And then what we do is we say, now I want you to use all of those workers to do something. And the easiest way to do a thing in Python 3 is to use map. How many of you have used map before? So for those of you who haven't, map is a very common functional programming construct that's found its way into lots of other languages, which simply says loop through a collection and call a function on everything in that collection and return a new collection, which is a result of calling that function on that thing. In our case, the function is resize and the collection is ImageNet images. Well, in fact the collection is a bunch of numbers, 0, 1, 2, 3, 4 and so forth, and what the resize image is going to do is it's going to open that image off disk. So it's turning the number 3 into the third image resized to 224x224 and it will return that. So the general approach here, this is basically what it looks like to do parallel processing in Python. It may look a bit weird. We're going result equals exec.map. This is a function I want, this is the thing to map over. And then I'm saying for each thing in that list, do something. Now this might make you think, well wait, does that mean this list has to have enough memory for every single resized image? And the answer is no, no it doesn't. One of the things that Python 3 uses a lot more is using these things they call generators. Which is basically, it's something that looks like a list, but it's lazy. It only creates that thing when you ask for it. So as I append each image, it's going to give me that image. And if this mapping is not yet finished creating it, it'll wait. So this approach looks like it's going to use heaps of memory, but it doesn't. It uses only the minimum amount of memory necessary and it does everything in parallel. So resized image is something which is going to open up the image, it's going to turn it into a NumPy array, and then it's going to resize it. So then the resize does the center cropping we just mentioned. And then after it's resized, it's going to get appended. What does append image do? So this is a bit weird. What's going on here? What it does is it's going to actually stick it into what we call a pre-allocated array. So we're learning a lot of computer science concepts here. Anybody that's done computer science before will be familiar with all of this already. If you haven't, you probably won't. But it's important to know that the slowest thing in your computer, generally speaking, is allocating memory. It's finding some memory, it's reading stuff from that memory, it's writing to that memory, unless of course it's like cache or something. And generally speaking, if you create lots and lots of arrays and then throw them away again, that's likely to be really, really slow. So what I wanted to do was to create a single 224x224 array, which is going to contain my resized image, and then I'm going to append that to my beak-holes tensor. So the way you do that in Python, it's wonderfully easy. You can create a variable from this thing called threading.local. Now TL is now just basically something that looks a bit like a dictionary, but it's a very special kind of dictionary. It's going to create a separate copy of it for every thread or process. So normally when you've got lots of things happening at once, it's going to be a real pain because if two things try to use it at the same time, you get bad results or even crashes. But if you allocate a variable like this, it automatically creates a separate copy in every thread. You don't have to worry about locks, you don't have to worry about race conditions, whatever. So once I've created this special threading local variable, I then create a placeholder inside it which is just an array of zeros of size 224x224x3. So then later on, I create my beak-holes array, which is where I'm going to put everything eventually. And to append the image, I grab the bit of the image that I want and I put it into that pre-allocated thread local variable and then I append that to my beak-holes array. So there's lots of detail here in terms of using parallel processing effectively. I wanted to briefly mention it, not because I think somebody who hasn't studied computer science is now going to go, Okay, I totally understood all that. But to give you some of the things to search for and learn about over the next week if you haven't done any parallel programming before, you're going to need to understand thread local storage and race conditions. In Python, there's something called the global interpreter lock, which is one of the many awful things about Python, possibly the most awful thing, which is that in theory two things can't happen at the same time because Python wasn't really written in a thread-safe way. The good news is that lots of libraries are written in a thread-safe way. So if you're using a library where most of its work is being done in C, as is the case with PILO and SIMD, actually you don't have to worry about that. I can prove it to you even because I drew a little picture. Here is the result of Serial vs Parallel. Now the Serial without SIMD version is 6 times bigger than this. So the kind of default Python code you would have written maybe before today's course would have been 120 seconds, process 2000 images. With SIMD, it's 25 seconds. With the process pool, it's 8 seconds for 3 workers, for 6 workers it's 5 seconds, so on and so forth. The thread pool is even better, 3.6 seconds for 12 workers, 3.2 seconds for 16 workers. Your mileage will vary depending on what CPU you have. Given that probably quite a lot of you are using the P2 still, unless you've got your deep learning box up and running, you'll have the same performance as other people using the P2. You should try something like this, which is to try different numbers of workers and see what's the optimal for that particular CPU. And now once you've done that, you know. Once I went beyond 16, I didn't really get improvements. So I know that on that computer, a thread pool of size 16 is a pretty good choice. And as you can see, once you get into the right general vicinity, it doesn't vary too much. So that's the general approach here, is run through something in parallel, each time append it to my becals array, and at the end of that, I've got a becal's array which I can use again and again. So I don't rerun that code very often anymore. I've got all of the ImageNet resized into each of 72x72, 224, and 288. I give them different names and I just use them. In fact, I think that's what Keras does. I think it squishes. So here's one of these things. I'm not quite sure. My guess was that I don't think it's a good idea, because you are now going to have dogs of various different squish levels, and your CNN is going to have to learn that thing. It's got another type of symmetry to learn about, level of squishiness. If we keep everything the same kind of aspect ratio, I think it's going to be easier to learn so we'll get better results with less epochs of training. That's my theory and I'd be fascinated for somebody to do a really in-depth analysis of black borders versus center cropping versus squishing with ImageNet. So from now on we can just open the becal's array. We're now ready to create our model. I'll run through this pretty quickly because most of it's pretty boring. The basic idea here is that we need to create an array of labels which are called vex, which contains for every image in my becal's array, it needs to contain the target word vector for that image. Just to remind you, last week we randomly ordered the filenames, so this becal's array is in random order. So we've got our labels, which is the word vectors for every image. We need to do our normal preprocessing. This is a handy way to preprocess in the new version of Keras. We're using the normal Keras resnet model, the one that comes in Keras.applications. It doesn't do the preprocessing for you, but if you create a lambda layer that does the preprocessing, then you can use that lambda layer as the input tensor. So this whole thing now will do the preprocessing automatically without you having to worry about it. So that's a good little trick. I'm not sure it's quite as neat as what we did in part 1 where we put it in the model itself. But at least this way we don't have to maintain a whole separate version of all of the models. So that's kind of what I'm doing nowadays. When you're working on really big datasets, you don't want to process things any more than necessary and any more times than necessary. I know ahead of time that I'm going to want to do some fine-tuning. So what I decided to do was, this is the particular layer where I'm going to do my fine-tuning. So I decided to first of all create a model which started at the input and went as far as this layer. So my first step was to create that model and save the results of that. And then the next step will be to take that intermediate step and take it to the next stage I want to fine-tune to and save that. So it's a little shortcut. There's a couple of really important intricacies to be aware of here though. The first one is you'll notice that ResNet and Inception are not used very often for transfer learning. And again, this is something which I've not seen studied and I actually think this is a really important thing to study, which of these things work best for transfer learning. But I think one of the difficulties is just ResNet and Inception are harder. And the reason they're harder is that if you look at ResNet, you've got lots and lots of layers which make no sense on their own, ditto for Inception, because they keep on splitting into two bits and then merging again. So what I did was I looked at the Keras source code to find out how is each block named. Because what I wanted to do was to say, we've got a ResNet block, we've just had a merge, and then it goes out and it does a couple of convolutions, and then it comes back and does an addition. And basically I want to get one of these. Unfortunately for some reason Keras does not name these merge cells. So what I had to do was get the next cell and then go back by one. So it kind of shows you how little people have been working with ResNet with transfer learning, is that literally the only bits of it that make sense to transfer learning from are nameless in one of the most popular, probably the most popular thing for transfer learning I suspect, Keras. There's a second complexity when working with ResNet. We haven't discussed this much, but ResNet actually has two kinds of ResNet blocks. One is this kind, which is an identity block, and the second time is a ResNet convolution block, which they also call a bottleneck block. And what this is, is it's pretty similar. You've got one thing that's going up through a couple of convolutions and then goes and gets added together, but the other side is not an identity. The other side is a single convolution. In ResNet they throw in one of these every half a dozen blocks or so. Why is that? The reason is that if you only have identity blocks, then all it can really do is to continually fine-tune where it's at so far. We've learned quite a few times now that these identity blocks basically map to the residual, but they keep trying to fine-tune the types of features that we have so far. Whereas these bottleneck blocks actually force it from time to time to create a whole different type of features because there is no identity path through here. The shortest path still goes through a single convolution. So when you think about transfer learning from ResNet, you kind of need to think about, should I transfer learn from an identity block before or after, or from a bottleneck block before or after. Again, I don't think anybody's studied this, or at least I haven't seen anybody write it down. I've played around with it a bit and I'm not sure I have a totally decisive suggestion for you. Clearly, my guess is that the best point to grab in ResNet is the end of the block immediately before a bottleneck block. And the reason for that is that at that level of receptive field, because each bottleneck block is changing the receptive field, and at that level of semantic complexity, this is the most sophisticated version of it because it's been through a whole bunch of identity blocks to get there. Fine-tune, fine-tune, fine-tune, bottleneck. So my belief is that you want to get just before that bottleneck is the best place to transfer learn from. So that's what this is. This is the spot just before the last bottleneck layer in ResNet. So it's pretty late, and so as we know very well from part 1 with transfer learning, when you're doing something which is not too different, and in this case we're switching from one-part encoding to word vectors which is not too different, you probably don't want to transfer learn from too early. So that's why I picked this fairly late stage, which is just before the final bottleneck block. So the second complexity here is that this bottleneck block has these dimensions. The output is 14x14x1024. So we have about a million images. So a million by 14x14x1024, the output is more than I wanted to deal with. So I did something very simple, which was I popped in one more layer after this, which is an average pooling layer, 7x7. So that's going to take my 14x14 output and turn it into a 2x2 output. So let's say one of those activations was looking for bird's eyeballs, then it's saying in each of the 14x14 spots how likely is it that this is a bird's eyeball. And so after this it's now saying in each of these four spots on average how much were those cells looking like bird's eyeballs. So this is losing information. If I had a bigger SSD and more time, I wouldn't have done this. But it's a good trick when you're working with these fully convolutional architectures. You can pop an average pooling layer anywhere and decrease the resolution to something that you feel like you can deal with. So in this case, my decision was to go to 2x2x1024. Question from the audience. Have we talked about why we do the merge operation in some of these more complex models? We have quite a few times, which is basically the merge was the thing which does the plus. That's the trick to making it into a ResNet block, is having the addition of the identity with the result of a couple of convolutions. So recently I was trying to go from many filters. So you kind of just talked about downsizing the size of the geometry. Is there a good best practice on going from 512 filters down to less? Or is it just as simple as doing a convolution with less filters? There's not exactly a best practice for that. But in a sense, every single successful architecture gets you some insights about that. Because every one of them eventually has to end up with a thousand categories if it's ImageNet or three channels of not 255 continuous if it's generative. So the best thing you can really do is, well, there's two things. One is to kind of look at the successful architectures. Another thing is, although this week is kind of the last week we're mainly going to be looking at images, I am going to briefly next week open with a quick run through some of the things that you could look at to learn more. And one of them is going to be a paper. We've got two different papers which have like best practices, you know, really nice kind of descriptions of we did these hundred different things and here's the hundred different results. But all this stuff is still pretty artisanal. Good question. So initially you said the image is 224, right? It ended up being as a big calls in a way, right? So a couple, it's like 50 gig data or something. Can we look at the images? Yes, and that's compressed and uncompressed, it's like a couple of hundred gig. So that's exactly the right segue I was looking for, so thank you. So what we're going to do now is we want to run this model we just built, just called basically dot predict on it and save the predictions. The problem is that the size of those predictions is going to be bigger than the amount of RAM I have, so I need to do it a batch at a time and save it a batch at a time. They've got a million things, each one with this many activations. And this is going to happen quite often, right? You're either working on a smaller computer or you're working with a bigger dataset or you're working with a dataset where you're using a larger number of activations. This is actually very easy to handle. You just create your big calls array where you're going to store it. And then all I do is I go through from 0 to the length of my array, my source array, a batch at a time. So this is creating the numbers 0, 0 plus 128, 128 plus 128, so on and so forth. And then I take the slice of my source array from originally 0 to 128, then from 128 to 256 and so forth. So this is now going to contain a slice of my source big calls array. And then, well actually this is going to create a generator which is going to have all of those slices. And of course being a generator it's going to be lazy. So I can then enumerate through each of those slices and I can append to my big calls array the result of predicting just on that one batch. So you've seen like predict and evaluate and fit and so forth and the generator versions. Also in Keras there's generally an on-batch version. So there's a train on-batch and a predict on-batch. And what these do is they basically have no smarts to them at all. This is like the most basic thing. So this is just going to take whatever you give it and call predict on this thing. It won't shuffle it, it won't batch it, it's just going to throw it directly into the computation graph. So this is going to take that model, it's going to call predict, adjust this batch of data. And then from time to time I print out how far I've got, just so that I know how I'm going. Also from time to time I call.flush, that's the thing in big calls that actually writes it to disk. That's to make sure it's continuously written to disk. So this thing doesn't actually take very long to run. And one of the nice things I can do here is I can do some data augmentation as well. I've added a direction parameter and what I'm going to do is I'm going to have a second copy of all of my images, which is to flip things horizontally. To flip things horizontally, you've got batch, byte, and then this is columns. If we pass in a minus 1 here, then it's going to flip it horizontally. That explains why some of my results haven't been quite as good as I hoped. So when you run this, we're going to end up with a big, big calls array that's going to contain two copies of every Resites ImageNet image, the activations at the layer before this. So I call it once with direction forwards and one with direction backwards. So at the end of that I've now got nearly 2 million images or activations of 2x2x1024. So that's pretty close to the end of ResNet. I've then just copied and pasted from the Keras code the last few steps of ResNet. So this is the last few blocks. I added in one extra identity block just because I had a feeling that might help things along a little bit. Again, people have not really studied this yet, so I haven't had a chance to properly experiment, but it seemed to work quite well. This is basically copied and pasted from Keras' code. I then need to copy the weights from Keras for those last few layers of ResNet. So now I'm going to repeat the same process again which is to call predict on these last few layers. The input will be the output from the previous one. So we went like 2 thirds of the way into ResNet and got those activations and put those activations into the last few stages of ResNet to get those activations. Now the outputs from this are actually just a vector of length 2048 which does fit in my RAM. If you try this at home and you don't have enough memory, you can use the predict on batch trick again. Anytime you run out of memory when calling predict, you can always just use this pattern. So at the end of all that, I've now got the activations from the penultimate layer of ResNet. So I can do our usual transfer learning trick of creating a linear model. My linear model is now going to try to use the number of dimensions in my word vectors as its output. You'll see it doesn't have any activation function. That's because I'm not doing one hot encoding. My word vectors could be any size numbers, so I just leave it as linear. And then I compile it and then I fit it. So this linear model is now my very first. This is almost the same as what we did in lesson 1, dog vs. cats. We're fine-tuning a model to a slightly different target to what it was originally trained with. It's just that we're doing it with a lot more data, so we have to be a bit more thoughtful. There's one other difference here, which is I'm using a custom loss function. The loss function I'm using is cosine distance. You can lock that up at home if you're not familiar with it, but basically cosine distance says for these two points in space, what's the angle between them rather than how far away are they. The reason we're doing that is because we're about to start using k nearest neighbors. So k nearest neighbors, we're going to basically say here's the word vector we predicted, which is the word vector which is closest to it. It turns out that in really, really high dimensional space, the concept of how far away something is is nearly meaningless. And the reason why is that in really, really high dimensional space, everything sits on the edge of that space. Basically because you can imagine as you add each additional dimension, the probability that something's on the edge in that dimension, let's say the probability it's right on the edge is like 1 tenth, then if you've only got one dimension, you've got a probability of 1 tenth that's on the edge in one dimension. If you've got two dimensions, it's basically multiplicatively decreasing the probability that that happens. So in a few hundred dimensional space, everything is on the edge. And when everything's on the edge, everything is kind of an equal distance away from each other, more or less, and so distances aren't very helpful. But the angle between things still separates. So when you're doing anything with trying to find nearest neighbors, it's a really good idea to train things using cosine distance. And this is the formula for cosine distance. Again, this is one of these things where I'm skipping over something that you'd probably spend a week in undergrad studying. There's heaps of information about cosine distance on the web, so for those of you already familiar with it, I won't waste your time. For those of you not, it's a very, very good idea to become familiar with this. And feel free to ask on the forums if you can't find any material that makes sense. So we've fitted our linear model as per usual. We save our weights and we can see how we're going. So what we've got now is something where we can feed in an image and it will spit out a word vector. But it's something that looks like a word vector. It has the same dimensionality as a word vector, but it's very unlikely that it's going to be the exact same vector as one of our thousand target word vectors. So if the word vector for a pug is this list of 200 floats, even if we have a perfectly puggy pug, we're not going to get that exact list of 2,000 floats. We'll have something that is similar. And when we say similar, we probably mean that the cosine distance between the perfect platonic pug and our pug is pretty small. So that's why after we get our predictions, we then have to use nearest neighbors as a second step to basically say, for each of those predictions, what are the three word vectors that are the closest to that prediction. So we can now take those nearest neighbors and find out for a bunch of our images what are the three things it thinks it might be. So for example, for this image here, its best guess was trombone, next was flute, and third was cello. So this gives us some hope that this approach seems to be working okay. It's not great yet, but it's recognized these things are musical instruments, and its third guess was in fact the correct musical instrument. So we know what to do next. What we do next is to fine-tune more layers. And because we have already saved the intermediate results from an earlier layer, that fine-tuning is going to be much faster to do. Two more things I'll briefly mention. One is that there's a couple of different ways to do nearest neighbors. One is what's called the brute force approach, which is literally okay what's the nearest word vector to this word vector, and to go through every one and see how far away it is. There's another approach which is approximate nearest neighbors. And when you've got lots and lots of things, you're trying to look for nearest neighbors, the brute force approach is going to be n squared time, it's going to be super slow. Where else would approximate nearest neighbors are generally n log n time. So orders of magnitude faster if you've got a large data set. The particular approach I'm using here is something called locality-sensitive hashing. It's a fascinating and wonderful algorithm. Anybody who's interested in algorithms, I strongly recommend you go read about it. Let me know if you need a hand with it. My favorite kind of algorithms are these approximate algorithms. In data science, you almost never need to know something exactly, yet nearly every algorithm that people learn at university and certainly at high school are exact. We learn exact nearest neighbor algorithms, exact indexing algorithms, exact median algorithms. Pretty much for every algorithm out there, there's an approximate version that runs an order of n or log n over n faster. And one of the cool things is that once you start realizing that, you suddenly discover that all of the libraries you've been using for ages were written by people who didn't know this. And then you realize that like every sub-algorithm they've written, they could have used an approximate version. The next thing you know, you've got something that runs 1000 times faster. The other cool thing about approximate algorithms is that they're generally written to provably be accurate to within so close. And like it can tell you with your parameters how close is so close. Which means that if you want to make it more accurate, you run it more times with different random seeds. So this thing called LSH forest is a locality-sensitive hashing forest, which means it creates a bunch of these locality-sensitive hashes. And the amazingly great thing about approximate algorithms is that each time you create another version of it, you're exponentially increasing the accuracy, or multiplicatively increasing the accuracy, but only linearly increasing the time. So if the error on one call of LSH was e, then the error on two calls is 1-e\u00b2. And three calls is 1-e\u00b3. And the time you're taking though, if the time for one call was n, is now 2n and 3n. So when you've got something where you can make it as accurate as you like with only linear increase in time, this is incredibly powerful. So this is a great approximation algorithm. I wish we had more time, so I'd love to tell you all about it. So I generally use LSH forest when I'm doing nearest neighbors because it's arbitrarily close and much faster when you've got lots of word vectors. The time that becomes important is when I move beyond dimensionnet, which I'm going to do now. So let's say I've got a picture, and I don't just want to say which one of the 1000 image net categories is it, but which one of the 100,000 word net nouns is it. Now that's a much harder thing to do. And that's something that no previous model could do. When you're trained in image net model, the only thing you could do is recognize pictures of things that were in image net. But now we've got a word vector model, so we can put in an image that spits out a word vector. And that word vector could be closer to things that are not in image net at all. Or it could be some higher level of the hierarchy. So we could look for a dog rather than a pug, or a plane rather than a 747. So here we bring in the entire set of word vectors. I have to remember to share these with you because these are actually quite hard to create. And this is where I definitely want LSH forest because this is going to be pretty slow. And we can now do the same thing. And not surprisingly, it's got worse. The thing that was actually cello, now cello is not even in the top 3. So this is a harder problem. So let's try fine-tuning. Fine-tuning is the final trick I'm going to show you. Question asked. You might remember last week we looked at creating our word vectors. And what we did was we actually created a list. I went to WordNet and I downloaded the whole of WordNet. And then I figured out which things were nouns, and then I used a regex to parse out those, and then I saved that. So we actually have the entirety of WordNet nouns. Question asked. Because it's not a good enough model yet. So now that there's 80,000 nouns, there's a lot more ways to be wrong. So when it only has to say, which of these thousand things is it, that's pretty easy. Which of these 80,000 things is it, it's pretty hard. So to fine-tune it, it looks very similar to our usual way of fine-tuning things, which is that we take our two models and stick them back to back. And we're now going to train the whole thing rather than just the linear model. Now the problem is that the input to this model is too big to fit in RAM. So how are we going to call fit or fit-generator when we have an array that's too big to fit in RAM? Well one obvious thing to do would be to pass in the beak-holes array. Because to most things in Python, a beak-holes array looks just like a regular array. It doesn't really look any different. The way a beak-holes array is actually stored is actually stored in a directory, as I'm sure you've noticed. And in that directory, it's got something called chunk length. I set it to 32 when I created these beak-holes arrays. What it does is it takes every 32 images and it puts them into a separate file. So each one of these has 32 images in it, or 32 of the leading axis of the array. Now if you then try to take this whole array and pass it to.fit in Keras with shuffle, it's going to try and grab one thing from here and one thing from here and then one thing from here. Here's the bad news. For beak-holes to get one thing out of a chunk, it has to read and decompress the whole thing. So it has to read and decompress 32 images in order to give you the one image you asked for. That'd be a disaster. That'd be ridiculously horribly slow. We didn't have to worry about that when we called predict on batch, because we were going not shuffling, but we were going in order. It was never grabbing a single image out of a chunk. But now that we want to shuffle, it would. What we've done is somebody very helpfully actually on a Kaggle forum provided something called a beak-holes array iterator. The beak-holes array iterator, which was kindly discovered on the forums actually by somebody named MP Janssen, originally written by this fellow, what it does is it provides a Keras compatible generator which grabs an entire chunk at a time. So it's a little bit less random, but given that if this has got 2 million images in and the chunk length is 32, then it's going to basically create a batch of chunks rather than a batch of images. So that means we have none of the performance problems, and particularly because we remember originally we randomly shuffled our files, so this whole thing is randomly shuffled anyway. So this is a good trick. So you'll find the beak-holes array iterator on GitHub. Feel free to take a look at the code, it's pretty straightforward. There were a few issues with the original version, so MP Janssen and I have tried to fix it up and I've written some tests for it and he's written some documentation for it. But if you just want to use it, then it's as simple as writing this. La equals beak-holes array iterator, this is your data, these are your labels, shuffle equals true, batch size equals whatever, and then you can just call fit generator as per usual passing in that iterator and that iterator's number of items. So to all of you guys who have been asking how do I deal with data that's bigger than memory, this is how you do it. So hopefully that will make life easier for a lot of people. So we fine-tune it for a while, we do some learning and annealing for a while. And this basically runs overnight for me, takes about 6 hours to run. So I come back the next morning and I just copy and paste my k nearest neighbors, so I call predict, I get my predicted word vectors. For each word vector, I then pass it into nearest neighbors, this is my just thousand categories. And lo and behold, we now have Kelo in the top spot as we hoped. How did it go in the harder problem of looking at the 100,000 or so nouns in English? Pretty good. I got this one right, and just to pick another one at random, let's pick the first one, it said throne, that sure looks like a throne. So looking pretty good. So here's something interesting. Now that we have brought images and words into the same space, let's play with that some more. So why don't we use nearest neighbors with those predictions. To the word vector which Google created, but the subset of those which are nouns according to wordnet mapped to their sense set IDs. So the word vectors are just the word2vec vectors that we can download off the internet. They were pre-trained by Google. They're embeddings. So we're comparing the proximity of word to image. Yes, exactly. So we're saying this image spits out a vector from the thing we just trained. We have 100,000 word vectors for all the nouns in English. Which one of those is the closest to the thing that came out of our model? And the answer was throne. Hold that thought, we'll be doing language translation starting next week. So let's do something interesting. Let's create a nearest neighbors not for all of the word2vec vectors, but for all of our image predicted vectors. And now we can do the opposite. Let's take a word, pick it random, let's look it up in our word2vec dictionary, and let's find the nearest neighbors for that in our images. So this is pretty interesting. You can now find the images that are the most like whatever word you come up with. So that's crazy, but we can do crazier. Here is a random thing I picked. Now notice I picked it from the validation set of ImageNet, so we've never seen this image before. Honestly when I opened it up, my heart sank because I don't know what it is. So this is a problem. What is that? So what we can do is we can call.predict on that image, and we can then do a nearest neighbors of all of our other images. And there's the first, there's the second, and the third one is even somebody putting their hand on it, which is slightly crazy, but that was what the original one looked like. In fact, I ran it again on a different image. I took this one, which is like pretty, I actually looked around for something weird. This is pretty weird, right? Is this a net or is it a fish? So when we then ask for nearest neighbors, we get fish in nets. So it's like, I don't know, sometimes deep learning is so magic, you just kind of go out there. Only a little bit, and maybe in a future course we might look at Dask, and I think maybe even in your numerical and your algebra course you might be looking at Dask. I don't think we'll cover this course. But do look at Dask, D-A-S-K, it's super cool. Question asked. These were actually labeled as this particular kind of fish. In fact that's the other thing, it's not only found fish in nets, but it's actually found more or less the same breed of fish in the nets. But when we called.predict on those, it created a word vector which was probably like halfway between that kind of fish and a net because it doesn't know what to do. So sometimes when it sees things like that, it would have been marked in the image net as a net, and sometimes it would have been a fish. So the best way to minimize the loss function would have been to kind of hedge. So it hedged and as a result the images that were closest were the ones which actually were halfway between the two themselves. So it's kind of a convenient accident. Question asked. You absolutely can and I have, but really for nearest neighbors, I haven't found anything nearly as good as cosine, and that's true in all of the things I looked up as well. By the way, I should mention, when you use locality-sensitive hashing in Python, by default it uses something that's equivalent to the cosine metric, so that's why the nearest neighbors work. Starting next week, we're going to be learning about sequence-to-sequence models and memory and attention methods. They're going to show us how we can take an input such as a sentence in English and spit out an output such as a sentence in French, which is the particular case study we're going to be spending 2 or 3 weeks on. When you combine that with this, you get image captioning. I'm not sure if we're going to have time to do it ourselves, but it will literally be trivial for you guys to take the two things and combine them and do image captioning. It's just those two techniques together. So we're now going to switch to the homework. Hopefully you guys noticed I gave you some tips because it was a really challenging one. Even though in a sense it was kind of straightforward, which was take everything that we've already learned about super resolution and slightly change the loss function so that it does perceptual losses for style transfer instead, the details were tricky. I'm going to quickly show you two things. First, we're going to show you how I did the homework because I actually hadn't done it last week. Luckily I have enough RAM that I could read the two things all into memory, so don't forget you can just do that with a bcalls array to turn it into a NumPy array in memory. So one thing I did was I created my upsampling block to get rid of the checkerboard patterns. That was literally as simple as saying upsampling 2D and then a 1x1 conv. So that got rid of my checkerboard patterns. The next thing I did was I changed my loss function and I decided before I tried to do style transfer with perceptual losses, let's try and do super resolution with multiple content loss layers. Because that's one thing that I'm going to have to do for style transfer, is be able to use multiple layers. So I always like to start with something that works and make small little changes so it keeps working at every point. So in this case, I thought, okay, let's first of all slightly change the loss function for super resolution so that it uses multiple layers. So here's how I did that. I changed my bgg content so it created a list of outputs, conv1 from each of the first, second and third blocks. Then I changed my loss function so it went through and added the mean square difference for each of those three layers. I also decided to add a weight just for fun. So I decided to go.1,.8,.1. Because this is the layer that they used in the paper. But let's have a little bit of more precise super resolution and a little bit of more semantic super resolution and see how it goes. I created this function to do kind of a more general mean squared error. And that was basically it. So other than that line and that line, everything else was the same. So that gave me super resolution working on multiple layers. One of the things I found fascinating is that this is the original low res and it's done a good job of upscaling it, but it's also fixed up the weird white balance, which really surprised me. It's taken this obviously over-yellow shot and this is what the ceramic should look like, it should be white. And somehow it's kind of adjusted everything. So the Viet or whatever it is in the background has gone from a yellowy-brown to a nice white, as have these cups here. It's figured out that these slightly pixelated things are actually meant to be upside down handles. This is on only 20,000 images. So I'm very surprised that it's fixing the color, because we never asked it to. But I guess it knows what a cup is meant to look like, and so this is what it's decided to do, to make a cup the way it thinks it's meant to look. So that was pretty cool. So then to go from there to style transfer was pretty straightforward. I had to read in my style as before. This is the code to do the special kind of resnet block where we use valid convolutions, which means we lose two pixels each time, and so therefore we have to do a center crop. But don't forget, lambda layers are great for this kind of thing. Whatever code you can write, chuck it in a lambda layer, and suddenly it's a Keras layer. So do my center crop. So this is now a resnet block which does valid comms. So this is basically all exactly the same. We have to do a few downsamplings, then the computation, then our upsamplings, just like the supplemental paper. So the loss function looks a lot like the loss function did before, but we've got two extra things. One is the grand matrix. So here is a version of the grand matrix which works a batch at a time. If any of you tried to do this a single image at a time, you would have gone crazy with how slow it took. I saw a few of you trying to do that. So here's the batch-wise version of grand matrix. And then the second thing I needed to do was somehow feed in my style target. So another thing I saw some of you do was feed in the style target every time, feed in that array into your loss function. Now you can obviously calculate your style target by just calling.predict with the thing which gives you all your different style target layers. But the problem is this thing here returns a NumPy array. It's a pretty big NumPy array, which means that then when you want to use it as a style target in training, it has to copy that back to the GPU. And copying to the GPU is very, very, very slow. And this is a really big thing to copy to the GPU. So any of you who tried this, I saw some of you try it, it took forever. So here's the trick. Call.variable on it. Turning something into a variable, fix it on the GPU for you. So once you've done that, you can now treat this as a list of symbolic entities which are the GPU versions of this. So I can now use this inside my GPU code. So here are my style targets I can use inside my loss function. And it doesn't have to do any copying backwards and forwards. So there's a subtlety, but if you don't get that subtlety right, you're going to be waiting for a week or so for your code to finish. So those were the little subtleties which were necessary to get this to work. And once you get it to work, it does exactly the same thing basically as before. So where this gets combined with Devise is I wanted to try something interesting, which is in the original Perceptual Losses paper, they trained it on the Cocoa dataset which has 80,000 images, which didn't seem like many. I wanted to know what would happen if we trained it on all of ImageNet. So I did. So I decided to train a super resolution network on all of ImageNet. And the code's all identical, so I'm not going to explain it, other than you'll notice we don't have the square bracket colon square bracket here anymore because we don't want to try and read in the entirety of ImageNet into RAM. So these are still B cols arrays. All the other code is identical until we get to here. So I use a B cols array iterator. I can't just call.fit because.fit or.fit generator assumes that your iterator is returning your data and your labels. In our case, we don't have data and labels. We have two things that both get fed in as two inputs, and our labels are just a list of zeros. So here's a good trick, and this answers your earlier question about how do you do multi-input models on large datasets. And the answer is, create your own training loop. Create your own training loop which loops through a bunch of iterations, and then you can grab as many batches of data from as many different iterators as you like, and then call train on batch. So in my case, my B cols array iterator is going to return my high resolution and low resolution batch of images. So I go through a bunch of iterations, grab one batch of high res and low res images, and pass them as my two inputs, the train on batch. So this is the only code I changed other than changing.fit generator to actually calling train. So as you can see, this took me 4.5 hours to train, and I then decreased the learning rate and I trained for another 4.5 hours. Actually I did it overnight last night and I only had enough time to do about half of ImageNet, so this isn't even the whole thing. Check this out. So check that model and we're going to call.predict on the original high res image. Here's the low res version and here's the version that we've created. And as you can see, it's done a pretty extraordinarily good job. When you look at the original ball, there was this kind of vague yellow thing here, it's kind of turned into a nice little inscription. You can see that her eyes were like two gray blobs, it's kind of turned into some eyes. You can see that her, you could just tell that that's an A, maybe if you look carefully. Now it's very clearly an A. So you can see it does an amazing job of upscaling this. Cooler still is this is a fully convolutional net and therefore is not specific to any particular input resolution. So what I can do is I can create another version of the model using our high res as the input. So now we're going to call.predict with the high res input and that's what we get back. So look at that, we can now see all of this detail on the basketball, which simply none of that really existed here. It was there, but pretty hard to see what it was. Look at her hair, this kind of gray blob here. Here you can see it knows, it's like little bits of pulled back hair. So we can take any sized image and make it bigger. This to me is one of the most amazing results I've seen in deep learning. When we train something on nearly all of ImageNet, it's a single epoch, so there's definitely no overfitting, and it's able to recognize what hair is meant to look like when pulled back into a bun is a pretty extraordinary result. Something else which I only realized later is that it's all a bit fuzzy, right? There's this arm in the background that's a bit fuzzy. The model knows that that bit is meant to stay fuzzy. It knows what out-of-focus things look like. Equally cool is not just how that A is now incredibly precise and accurate, but the fact that it knows that blurry things need to stay blurry. I don't know if you're as amazed at this as I am, but I thought this was a pretty cool result. We could run this over a 24-hour period on maybe two epochs of all of ImageNet and presumably it would get even better still. So let's take a 7-minute break and see you back here at 5 past 8. We're going to do something else fun. Actually before I continue, I did want to mention one thing in the homework that I changed, which is I realized in my manually created loss function I was already doing a mean squared error in the loss function. But then when I told Keras to make that thing as close to 0 as possible, I had to also give it a loss function, and I was giving it MSE. Effectively that was like undersquaring my squared errors, it seemed wrong. So I've changed it to MAE, mean absolute error. So when you look back over the notebooks, that's why. It's because this is just to say, hey, get the loss as close to 0 as possible. I didn't really want to re-square it, that didn't make any sense. So that's why you'll see that minor change. The other thing to mention is I did notice that when I re-trained my super resolution on my new images that didn't have the black border, it gave good results much, much faster. So I really think that thing of learning to put the black border back in seemed to take quite a lot of effort for it. So again, hopefully some of you are going to look into that in more detail. So we're going to learn about generative adversarial networks. This will kind of close off our deep dive into generative models as applied to images. And just to remind you, the purpose of this has been to learn about generative models, not to specifically learn about super resolution or artistic style. But remember, these things can be used to create all kinds of images. So one of the groups is interested in taking a 2D photo and trying to turn it into something that you can rotate in 3D or at least show a different angle of that 2D photo. And that's a great example of something that this should totally work for. It's just a mapping from one image to some different image, which is like what would this image look like from above versus from the front. So keep in mind the purpose of this is just like in part 1, we learned about classification, which you can use for a thousand things. Now we're learning about generative models that you can use for a different thousand things. Now any generative model you build, you can make it better by adding on top of it a GAN, a generative adversarial network. And this is something I don't really feel like it's been fully appreciated. People I've seen generally treat GANs as a different way of creating a generative model. But I think of this more as like, why not create your generative model using the kind of techniques we've been talking about. But then, think of it this way. Think of all the artistic style stuff we were doing, like my terrible attempt at a Simpsons cartoon version of a picture. It looked nothing like the Simpsons. So what would be one way to improve that? One way to improve that would be to create two networks. There would be one network that takes our picture, which is actually not the Simpsons, and takes another picture that actually is the Simpsons, and maybe we can train a neural network that takes those two images and spits out something saying, is that a real Simpsons image or not. And this thing we'll call the discriminator. So we could easily train a discriminator right now. It's just a classification network, just use the same techniques we used in part 1. We feed it the two images, and it's going to spit out a 1 if it's a real Simpsons cartoon, and a 0 if it's Jeremy's crappy generative model of Simpsons. That's easy, we know how to do that right now. Go and build another model. There's two images as inputs. You would feed it one thing that's the Simpsons and one thing that's a generative output. It's up to you to feed it one of each. Or alternatively, you could feed it one thing. In fact, probably easier is to just feed it one thing and it spits out is it the Simpsons or isn't it the Simpsons. And you could just mix and match them. Actually, it's the latter that we're going to do, so that's probably easier. We're going to have one thing which is either not a Simpsons or it is a Simpsons, and we're going to have a mix of 50-50 of those two, and we're going to have something come out saying, what do you think, is it real or not. So this discriminator from now on will probably be calling it D. And we can think of that as a function. D is a function that takes some input x, which is an image, and spits out a 1 or a 0, or maybe a probability. So what we could now do is create another neural network. And what this neural network is going to do is it's going to take as input some random noise, just like all of our generators have so far, and it's going to spit out an image. And the loss function is going to be if you take that image and stick it through D, did you manage to fool it? So could you create something where in fact we wanted to say, oh yeah, totally, that's a real Simpsons. So if that was our loss function, we're going to call the generator G. It's just something exactly like our perceptual losses style transfer model. But the loss function is now going to be take the output of that and stick it through D, the discriminator, and try to trick it. So the generator's doing well if the discriminator's getting it wrong. So one way to do this would be to take our discriminator and train it as best as we can to recognize the difference between our crappy Simpsons and real Simpsons, and then get a generator and train it to trick that discriminator. But now at the end of that, it's probably still not very good because you realize that actually the discriminator didn't have to be very good before because my Simpsons generators were so bad. So I could now go back and retrain the discriminator based on my better generated images, and then I could go back and retrain the generator, and back and forth I go. And that is the general approach of a GAN, is to keep going back between two things, which is training a discriminator and training a generator using a discriminator as a loss function. So we've got one thing which is discriminator on some image, and another thing which is a discriminator on a generator on some noise. So in practice, these things are going to spit out probabilities. So that's the general idea. In practice, they found it very difficult to do this, like train the discriminator as best as we can, stop, train the generator as best as we can, so instead what the original GAN paper is called Generative Adversarial Nets. And what they did was to, and here you can see they've actually specified this loss function, so here it is in notation, is to call it minimizing the generator whilst maximizing the discriminator. This is what min-max is referring to. What they do in practice is they do it a batch at a time. So they have a loop, and we're going to go through a loop and do a single batch, put it through the discriminator, that same batch, stick it through the generator. So we're going to do it a batch at a time. So let's look at that. So here's the original GAN from that paper, and we're going to do it on MNIST. And what we're going to do is we're going to see if we can start from scratch to create something which can create images which the discriminator cannot tell whether they're real or fake. It's a discriminator that has learned to be good at discriminating real from fake pictures of MNIST images. So load in MNIST, and the first thing they do in the paper is to just use a standard multilayer perceptron. So here's our generator, it's just a standard multilayer perceptron, and here's our discriminator, which is also a standard multilayer perceptron. The generator has a sigmoid activation, so in other words we're going to spit out an image where all of the pixels are between 0 and 1, so if you want to print it out, we'll just multiply it by 255. So there's our generator, there's our discriminator. So there's then the combination of the two. So take the generator and stick it into the discriminator, so we can just use sequential for that. And this is actually therefore the loss function that I want on my generator. Just generate something and see if you can fool the discriminator. So there's all my architectures set up. So the next thing I need to do is set up this thing called train, which is going to do this adversarial training. Let's go back and have a look at train. So what train is going to do is go through a bunch of epochs. And notice here I wrap it in this TQDM, this is the thing that creates a nice little poke progress bar. It doesn't do anything else, it just creates a little progress bar. We learned about that last week. So the first thing I need to do is to generate some data to feed the discriminator. So I've created a little function for that, and here's my little function. So it's going to create a little bit of data that's real and a little bit of data that's fake. So my real data is going to go into my actual training set and grab some randomly selected MNIST digits. And then let's create some fake. So noise is a function that I've just created up here, which creates some 100 random numbers. So let's create some noise called g.predict. And so then I'll concatenate the two together. So now I've got some real data and some fake data. So this is going to try and predict whether or not something is fake. So 1 means fake, 0 means real. So I'm going to return my data and my labels, which is a bunch of zeros to say they're all real and a bunch of ones to say they're all fake. So there's my discriminator's data. So go ahead and create a set of data for the discriminator and then do one batch of training. Now I'm going to do the same thing for the generator, but when I train the generator, I don't want to change the discriminator's weights. So make trainable simply goes through each layer and says it's not trainable. So make my discriminator non-trainable and do one batch of training where I'm taking noise as my inputs and my goal is to get the discriminator to think that they are actually real. So that's why I'm passing in a bunch of zeros, because remember 0 means real. And that's it. And then make discriminator trainable again. So keep looping through this. Train the discriminator on a batch of half real, half fake, and then train the generator to try and trick the discriminator using all fake. Repeat. So that's the training loop. That's the basic GAN. Because we use TQDM, we get a nice little progress bar. We can plot out the loss at each step. So there's our loss for the discriminator and there's our loss for the generator. So the question is, what do these loss curves mean? Are they good or bad? How do we know? And the answer is, for this kind of GAN, they mean nothing at all. The generator could get fantastic, but it could be because the discriminator is terrible. And they don't really know whether each one is good or not, so even the order of magnitude of both of them is meaningless. So these curves mean nothing. The direction of the curves mean nothing. And this is one of the real difficulties with training GANs. And here's what happens when I plot 12 randomly selected random noise vectors stuck through there and we have not got things that look terribly like MS digits and they also don't look terribly much like they have a lot of variety. This is called mode class. Very common problem when training GANs. And what it means is that the generator and the discriminator have kind of reached a stalemate where neither of them basically knows how to go from here. And in terms of optimization, we've basically found a local minimum. So that was not very successful. Can we do better? So the next major paper that came along was this one, Unsupervised Representation Learning with Deep Convolutional Gerative Adversarial Networks. So this created something that they called DC GANs. And the main page that you want to look at here is page 3 where they say core to our approach is doing these 3 things. And basically what they do is they just do exactly the same thing as GANs, but they do 3 things. One is to use the kinds of, all of them is to learn the tricks that we've been learning for generative models. Use an all-convolutional net, get rid of max pooling and use strata convolutions instead, get rid of fully connected layers and use lots of convolutional features instead, and add in batch norm. And then use a CNN rather than MLP. So here is that. This will all look very familiar, it looks just like last lesson stuff. So the generator is going to take in a random grid of inputs, it's going to do a batch norm, upsample. You'll notice that I'm doing even newer than this paper, I'm doing the upsampling approach because we know that's better. Upsample, 1x1 conv, batch norm, upsample, 1x1 conv, batch norm, and then a final conv layer. Discriminator basically does the opposite, which is some 2x2 subsamplings, so downsampling in the discriminator. Another trick that they mention, I think it's mentioned in the paper, is to, before you do the back and forth batch for the discriminator and a batch for the generator, is to train the discriminator for a fraction of an epoch, like do a few batches through the discriminator so at least it knows how to recognize the difference between a random image and a real image a little bit. So you can see here I actually just start by calling discriminator.fit with just a very small amount of data. So this is kind of like bootstrapping the discriminator. And then I just go ahead and call the same train as we had before with my better architectures. And again, these curves are totally meaningless, but we have something which if you squint, you could almost convince yourself that that's a 5. So until a week or two before this course started, this was kind of about as good as we had. People were much better at the artisanal details of this than I was, and indeed there's a whole page called GAN Hacks, which had lots of tips. But then, a couple of weeks before this class started, as I mentioned in the first class, along came the Wasserstein GAN. And the Wasserstein GAN got rid of all of these problems. And here is the Wasserstein GAN paper. And this paper is quite an extraordinary paper. It's particularly extraordinary because, I think I mentioned this in the first class of this part, most papers tend to either be math theory that goes nowhere, or nice experiments in engineering where the theory bits are kind of hacked on at the end and kind of meaningless. This paper is entirely driven by theory, and then the theory they go on to show this is what the theory means, this is what we do, and suddenly all the problems go away. The loss curves are going to actually mean something, and we're going to be able to do what I said we wanted to do right at the start of this GAN section, which is to train the discriminator a whole bunch of steps and then do a generator, and then discriminator a whole bunch of steps and do the generator. And all that is going to suddenly start working. How do we get it to work? So in fact, despite the fact that this paper is both long and full of equations and theorems and proofs, and there's a whole bunch of appendices at the back with more theorems and proofs, there's actually only two things we need to do. One is remove the log from the loss function. So rather than using cross-entropy loss, we're just going to use mean squared error. That's one change. And the second change is we're going to constrain the weights so that they lie between negative.01 and positive.01. We're going to constrain the weights to make them small. Now in the process of saying that's all we're going to do is to not give credit to this paper. This paper is that they figured out that that's what we need to do. And on the forums, some of you have been reading through this paper and I've already given you some tips as to some really great walkthroughs. I put it on our wiki. It explains all the math from scratch. But basically what the math says is this. Again, the loss function for again is not really the loss function you put into Keras. We thought we were just putting in a cross-entropy loss function. But in fact, again, what we really care about is the difference between two distributions, the difference between the discriminator and the generator. And the difference between two loss functions has a very different shape for the loss function on its own. So it turns out that the difference between the two loss functions, the two cross-entropy loss functions, is something called the Jensen-Shannon distance. And this paper shows that that loss function is hideous. It is not differentiable and it does not have a nice smooth shape at all. So it kind of explains why it is that we kept getting this mode collapse and failing to find nice minimums. It's basically that mathematically this loss function does not behave the way a good loss function should. And previously we've not come across anything like this because we've been training a single function at a time. We really understand those loss functions, mean squared error, cross-entropy. Even though we haven't always derived the math in detail, plenty of people have. We know that they're nice and smooth and that they have pretty nice shapes and they do what we want them to do. In this case, by training two things adversarially to each other, we're actually doing something quite different. This paper just absolutely fantastically shows with both examples and with theory why that's just never going to work. Then the cosine distance. So the cosine distance is the difference between two things, whereas these distances that we're talking about here are the distances between two distributions, which is a much more tricky problem to deal with. The cosine distance, actually if you look at the notebook during the week, you'll see it's basically the same as the Euclidean distance, but you normalize the data first. So it has all the same nice properties that the Euclidean distance did. So one thing that's fun is that the authors of this paper released their code in PyTorch. And luckily PyTorch, the first kind of pre-release came out in mid-January. You won't be surprised to hear that one of the authors of the paper is the main author of PyTorch. So he was writing this before he even released the code. There's lots of reasons we want to learn PyTorch anyway, so here's a good reason. So let's look at the Wasserstein GAN in PyTorch. Most of the code, in fact other than this pretty much all the code I'm showing you in this part of the course, is very loosely based on lots of bits of other code, which I had to massively rewrite because all of it was wrong and hideous. This code actually I only did some minor refactoring to simplify things, so this is actually very close to their code. So it's a very nice paper with very nice code. So that's a great thing. So before we look at the Wasserstein GAN in PyTorch, let's look briefly at PyTorch. Basically what you're going to see is that PyTorch looks a lot like NumPy, which is nice. We don't have to create a computational graph using variables and placeholders and later on run it in a session. I'm sure you've seen by now with Keras, with TensorFlow, you try to print something out with some intermediate output and it just prints out like tensor and tells you how many dimensions it has. That's because all that thing is is a symbolic part of a computational graph. PyTorch doesn't work that way. PyTorch is what's called a define-by-run framework. It's basically designed to be so fast to take your code and compile it that you don't have to create that graph in advance. Every time you run a piece of code, it puts it on the GPU, runs it, sends it back all in one go. So it makes things look very simple. So this is a slightly cut-down version of the PyTorch tutorial that PyTorch provides on their website. So rather than creating np.array, you create torch.tensor. But other than that, it's identical. So here's a random torch.tensor. So the API is a little bit different. Rather than dot shape, it's dot size. But you can see it looks very similar. And so unlike in TensorFlow or Theano, we can just say x plus y and there it is. We don't have to say z equals x plus y, f equals function, x and y as inputs, z as output, and function dot of vowel. No, we just go x plus y and there it is. So you can see why it's called define-by-run. We just provide the code and it just runs it. Generally speaking, most operations in torch, as well as having this prefix version, this is exactly the same thing. You can often add, in fact, nearly always add an out equals and that puts the result in this pre-allocated memory. We've already talked about why it's really important to pre-allocate memory. It's particularly important on GPUs. So if you write your own algorithms in PyTorch, you'll need to be very careful of this. Perhaps the best trick is that you can stick an underscore on the end of most things and it causes it to do in place. This is basically y plus equals x. That's what this underscore at the end means. So there's some good little tricks. You can do slicing just like NumPy. You can turn NumPy stuff into torch tensors and vice versa by simply going dot NumPy. One thing to be very aware of is that A and B are now referring to the same thing. So if I now add underscore, so in place, A plus equals 1, it also changes B. Vice versa, you can turn NumPy into torch by calling torch from NumPy. And again, same thing, if you change the NumPy, it changes the torch. All of that so far has been running on the CPU. To turn anything into something that runs on the GPU, you chuck.cooter at the end of it. So this x plus y just ran on the GPU. So where things get cool is that something like this knows not just how to do that piece of arithmetic, but it also knows how to take the gradient of that. To make anything into something which calculates gradients, you just take your torch tensor, wrap it in variable, and add this parameter to it. And now from now on, anything I do to x, it's going to remember what I did so that it can take the gradient of it. So for example, x plus 2, I get back 3, just like a normal tensor. So a variable and a tensor have the same API, except that I can keep doing things to it, squared times 3,.mean. Later on I can go.backward and.grad and I can get the gradient. So that's the critical difference between a tensor and a variable. They have exactly the same API except variable also has.backward and that gets you the gradient. So when I say.gradient, the reason that this is dout dx is because I typed out.backward. So this is the thing, the derivative is respect to. So this is kind of crazy. You can do things like while loops and get the gradients of them. So this kind of thing is pretty tricky to do with TensorFlow or Theano or these kind of computation graph approaches. So it gives you a whole lot of flexibility to define things in much more natural ways. So you can really write PyTorch just like you're writing regular old NumPy stuff. It has plenty of libraries, so if you want to create a neural network, here's how you do a CNN. I warned you early on that if you don't know about OO in Python, you need to learn it, so here's why. Because in PyTorch, everything's kind of done using OO. I really like this, because in TensorFlow, they kind of invent their own weird way of programming rather than use Python OO. Where else PyTorch just goes, oh, we already have these features in the language, let's just use them. So it's way easier in my opinion. So to create a neural net, you create a new class, you derive from module, and then in the constructor, you create all of the things that have weights. So Conv1 is now something that has some weights, 2D conv, conv2 is something with some weights, polyconnected1 is something with some weights. So there's all of your layers, and then you get to say exactly what happens in your forward pass. Now because MaxPool2D doesn't have any weights and ReLU doesn't have any weights, there's no need to define them in the initializer. You can just call them as functions. But these things have weights, so they need to be stateful and persistent. So in my forward pass, you literally just define what are the things that happen..view is the same as reshape. The whole API has different names for everything, which is mildly annoying for the first week, but you kind of get used to it. So.reshape is called.view. During the week, if you try to use PyTorch and you're like, how do you say blah in PyTorch and you can't find it, feel free to post on the forum. Having said that, PyTorch has its own discourse-based forums. And as you can see, it is just as busy and friendly as our forums. People are posting on these all the time. So I find it a really great, helpful community. So feel free to ask over there or over here. You can then put all of that computation onto the GPU by calling.cuda. You can then take some input, put that on the GPU with.cuda. You can then calculate your derivatives, calculate your loss, and then later on you can optimize it. This is just one step of the optimizer, so we have to put that in the loop. So there's the basic pieces. At the end here, there's a complete process, but I think more fun will be to see the process in the Wasserstein GAN. So here it is. I've kind of got this TorchUtils thing which you'll find in GitHub, which has the basic stuff you'll want for Torch all there, so you can just import that. So let's get the Wasserstein GAN working. So we set up the batch size, the size of each image, the size of our noise vector. And look how cool it is, I really like this. This is how you import datasets. It has a datasets module already in the TorchVision library. Here's the CyPhar 10 dataset. It will automatically download it to this path for you if you say download=\"true\". And rather than having to figure out how to do the preprocessing, you can create a list of transforms. So I think this is a really lovely API. The reason that this is so new yet has such a nice API is because this comes from a lower library called Torch that's been around for many years, and so these guys are basically started off by copying what they already had and what already works well. So I think this is very elegant. So I've got two different things you can look at here. They're both from the paper. Mine is CyPhar 10, which are these tiny little images. Another is something we haven't seen before, which is called Lsun, which is a really nice dataset. It's a huge dataset with millions of images, 3 million bedroom images for example. So we can use either one. This is pretty cool. We can then create a data loader, say how many workers to use. We already know what workers are. This is all built into the framework. So now that you know how many workers your CPU likes to use, you can just go ahead and put that number in here. Use your CPU to load in this data in parallel in the background. So we're going to start with CyPhar 10, so we've got 47,000 of those images. Put the definitions of the discriminator and the generator architectures into a separate Python file, bcgan.py. We're going to skip over very quickly because it's really straightforward. Here's a conv block that consists of a conv2d, batchnorm2d, and a leaky relu. So in my initializer, I can go ahead and say we'll start with a conv block, optionally have a few extra conv blocks. This is really nice. Here's a while loop that says keep adding more downsampling blocks until you've got as many as you need. So that's really nice kind of use of a while loop to simplify our architecture. And then a final conv block at the end to actually create the thing we want. And then this is pretty nifty. If you pass in ngpu greater than 1, then it will call parallel.data.parallel passing in those GPU IDs and it will do automatic multi-GPU training. So this is by far the easiest multi-GPU training I've ever seen. So that's it, that's the forward pass. We'll learn more about this over the next couple of weeks. In fact, given we're a little short of time, let's discuss that next week and let me know if you don't think we cover it. Here's the generator, looks very, very similar. Again there's a while loop to make sure we've gone through the right number of decon blocks. So this is actually interesting. This would probably be better off with an upsampling block followed by a one-by-one convolution. So maybe at home you could try this and see if you get better results because this has probably got the checkerboard pattern problem. So there's our generator and our discriminator. It's only 75 lines of code, nice and easy. Everything's a little bit different in PyTorch. If we want to say what initializer to use, again we're going to use a little bit more decoupled, maybe at first it's a little more complex but there's less things you have to learn. In this case we can call something called apply, which takes some function and passes it to everything in our architecture. So this function is something that says, oh is this a conv2d or conv transpose 2d, if so use this initialization function. Or if it's a batch norm, use this initialization function. So again, everything's a little bit different, there isn't a separate initializer parameter. This is in my opinion much more flexible, I really like it. As before, we need something that creates some noise. Let's go ahead and create some fixed noise. We're going to have an optimizer for the discriminator, we've got an optimizer for the generator. Here is something that does one step of the discriminator. So we're going to call the forward pass, and then we call the backward pass, and then we return the error. Just like before, we've got something called makeTrainable. So this is how we make something trainable or not trainable in PyTorch. And just like before, we have a train loop. The train loop has got a little bit more going on, partly because of the Wasserstein GAN, partly because of PyTorch, but the basic idea is the same. For each epoch, for each batch, make the discriminator trainable. And then this is the number of iterations to train the discriminator for. So remember I told you one of the nice things about the Wasserstein GAN is that we don't have to do one batch discriminator, one batch generator, one batch discriminator, one batch generator, but we can actually train the discriminator properly for a bunch of batches. And in the paper, they suggest using 5 iterations or 5 batches of discriminator training each time through the loop, unless you're still in the first 25 iterations. They say if you're in the first 25 iterations, do 100 batches. And then they also say from time to time, do 100 batches. So it's kind of nice by having the flexibility here to really change things, we can do exactly what the paper wants us to do. So basically at first we're going to train the discriminator carefully, and we'll also from time to time train the discriminator very carefully. Otherwise we'll just do 5 batches. So this is where we go ahead and train the discriminator. And you'll see here we clamp the weights in the discriminator to fall in this range. And if you're interested in reading the paper, the paper explains that basically the reason for this is that their assumptions are only true in this kind of small area. So that's why we have to make sure that the weights stay in this small area. So then we go ahead and do a single step with the discriminator. Then we create some noise and do a single step with the generator. We get our fake data for the discriminator that we can subtract the fake from the real to get our error for the discriminator. So there's one step with the discriminator. We do that either 5 or 100 times. Make our discriminator not trainable and then do one step of the generator. You can see here we call the generator with some noise and then pass it into the discriminator to see if we tricked it or not. So during the week you can look at these two different versions and you're going to see basically the PyTorch and the Keras version are basically the same thing. The only difference is in the two things. One is the presence of this clamping and the second is that the loss function is mean squared error rather than cross-entropy. So let's see what happens. Here are some examples from CyPhar 10. They're certainly a lot better than our crappy vsegan MNIST examples, but they're not great. Why are they not great? So probably the reason they're not great is because CyPhar 10 has quite a few different kinds of categories of different kinds of things. So it doesn't really know what it's meant to be drawing a picture of. Sometimes I guess it kind of figures it out, like this must be a plane I think. But a lot of the time it's kind of, it hedges and kind of draws a picture of something that looks like it might be a reasonable picture, but it's not a picture of anything in particular. On the other hand, the Lsun dataset has 3 million bedrooms. So we would hope that when we train the Vassarstein GAN on Lsun bedrooms, we might get better results. Here's the real CyPhar 10, by the way. So here are our fake bedrooms. And they are pretty freaking awesome. So literally these started out as random noise and everyone has been turned in. And here are the real bedrooms. You can kind of see here that, imagine if you took this and stuck it on the end of any kind of generator. You could really use this to make your generator much more believable. Like anytime you kind of look at it and you say, Oh, that doesn't look like the real X, maybe you could try using a W again to try to make it look more like a real X. So this paper is so new and so important. The loss function for these actually makes sense. Like the discriminator and the generator loss functions actually decrease as they get better. So you can actually tell if your thing is training properly. You can't exactly compare two different architectures to each other still, but you can certainly see that the training curves are working. So now that we have, in my opinion, a GAN that actually really works reliably for the first time ever, I feel like this changes the equation for what generators can and can't do. This has not been applied to anything yet. So you can take any old paper that produces 3D outputs or segmentations or depth outputs or colorization or whatever and add this and it would be great to see what happens. None of that's been done before. It's not been done before because we haven't had a good way to train GANs before. This is kind of something where anybody who's interested in a project, this would be a great project and something that maybe you can do reasonably quickly. Another thing you could do as a project is to convert this into Keras. So you can take the Keras DCGAN notebook that we've already got and change the loss function at the weight clipping, try training on this Lsun bedroom dataset and you should get the same results. And then you can add this on top of any of your Keras stuff. There's so much you could do this week. I don't feel like I want to give you an assignment per se because there's a thousand assignments you could do. As per usual, you should go back and look at the papers. The original GAN paper is a fairly easy read. There's a section called Theoretical Results, which is kind of like the pointless math bit. Here are some theoretical stuff. It's actually interesting to read this now because you go back and you look at this stuff where they prove various nice things about their GAN. They're talking about how the generative model perfectly replicates the data generating process. It's interesting to go back and look and say, okay, so they've proved these things, but it turned out to be totally pointless. It still didn't work. It didn't really work. It's kind of interesting to look back and say, this isn't a good paper, it is a good paper, but it is interesting to see when is the theoretical stuff useful and when not. Then you look at the Wasserstein GAN theoretical sections and it spends a lot of time talking about why their theory actually matters. So they have this really cool example, for example, where they say, that's creating something really simple. What if you want to learn just parallel lines? And they show why it is that the old way of doing GANs can't learn parallel lines. And then they show how their different objective function can learn parallel lines. So I think anybody who's interested in getting into the theory a little bit, it's very interesting to look at why the proof of convergence showed something that didn't show something that really turned out to matter. Where else in this paper, the theory turned out to be super important and basically created something that allowed GANs to work for the first time. So there's lots of stuff you can get out of these papers if you're interested. In terms of the notation, we might look at some of the notation a little bit more next week. But if we look for example at the algorithm sections, I think in general the most important part, the bit I find the most useful not being a math guy, is the bit where they actually write the pseudocode. Even that it's useful to learn some kind of nomenclature. So for each iteration, what does this mean? Sample, noise samples from noise prior. There's a lot of probability nomenclature which you can very quickly translate. A prior simply means np.random.something. So in this case, we're probably like np.random.normal. So this just means some random number generator that you get to pick. This one here, sample from a data-generating distribution, that means randomly pick some stuff from your array. So these are the two steps. Generate some random numbers and then randomly select some things from your array. And then the bit where it talks about the gradient you can largely ignore, except the bit in the middle is your loss function. You can see here, these things here is your noise. So noise, generator on noise, discriminator on generator on noise. So there's the bit where we're trying to fool the discriminator. And we're trying to make that trick it, so that's why we do 1-. And then here's getting the discriminator to be accurate, because these x's is the real data. So that's the math version of what we just learned. The Wasserstein GAN also has an algorithm section, so it's kind of interesting to compare the two. Here we go, here's the Wasserstein GAN, here's the algorithm. And basically this says exactly the same thing as the last one said, but I actually find this one a bit clearer. Sample from the real data, sample from your priors. Hopefully that's enough to get going. I look forward to talking on the forums and see how everybody gets along. Thanks everybody.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.44, "text": " Welcome again everybody. Some really fun stuff appearing on the forums this week. One of", "tokens": [4027, 797, 2201, 13, 2188, 534, 1019, 1507, 19870, 322, 264, 26998, 341, 1243, 13, 1485, 295], "temperature": 0.0, "avg_logprob": -0.2081128438313802, "compression_ratio": 1.4207650273224044, "no_speech_prob": 0.048814889043569565}, {"id": 1, "seek": 0, "start": 10.44, "end": 16.52, "text": " the really great projects which was created by I believe our sole Bulgarian participant", "tokens": [264, 534, 869, 4455, 597, 390, 2942, 538, 286, 1697, 527, 12321, 31125, 952, 24950], "temperature": 0.0, "avg_logprob": -0.2081128438313802, "compression_ratio": 1.4207650273224044, "no_speech_prob": 0.048814889043569565}, {"id": 2, "seek": 0, "start": 16.52, "end": 23.32, "text": " in the course, Slav Ivanov, wrote a great post about picking an optimizer for style", "tokens": [294, 264, 1164, 11, 6187, 706, 26546, 38990, 11, 4114, 257, 869, 2183, 466, 8867, 364, 5028, 6545, 337, 3758], "temperature": 0.0, "avg_logprob": -0.2081128438313802, "compression_ratio": 1.4207650273224044, "no_speech_prob": 0.048814889043569565}, {"id": 3, "seek": 2332, "start": 23.32, "end": 31.84, "text": " optimizer. This post came from a forum discussion in which I made an offhand remark about how", "tokens": [5028, 6545, 13, 639, 2183, 1361, 490, 257, 17542, 5017, 294, 597, 286, 1027, 364, 766, 5543, 7942, 466, 577], "temperature": 0.0, "avg_logprob": -0.15946789276905549, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.00023034894547890872}, {"id": 4, "seek": 2332, "start": 31.84, "end": 39.400000000000006, "text": " I didn't know that in theory BFGS is a deterministic optimizer, it uses a line search, it approximates", "tokens": [286, 994, 380, 458, 300, 294, 5261, 363, 37, 24446, 307, 257, 15957, 3142, 5028, 6545, 11, 309, 4960, 257, 1622, 3164, 11, 309, 8542, 1024], "temperature": 0.0, "avg_logprob": -0.15946789276905549, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.00023034894547890872}, {"id": 5, "seek": 2332, "start": 39.400000000000006, "end": 44.64, "text": " the Hessian, it ought to work on this kind of deterministic problem better. But I hadn't", "tokens": [264, 35960, 952, 11, 309, 13416, 281, 589, 322, 341, 733, 295, 15957, 3142, 1154, 1101, 13, 583, 286, 8782, 380], "temperature": 0.0, "avg_logprob": -0.15946789276905549, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.00023034894547890872}, {"id": 6, "seek": 2332, "start": 44.64, "end": 49.519999999999996, "text": " tried it myself and I hadn't seen anybody try it, so maybe somebody should try it.", "tokens": [3031, 309, 2059, 293, 286, 8782, 380, 1612, 4472, 853, 309, 11, 370, 1310, 2618, 820, 853, 309, 13], "temperature": 0.0, "avg_logprob": -0.15946789276905549, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.00023034894547890872}, {"id": 7, "seek": 2332, "start": 49.519999999999996, "end": 52.519999999999996, "text": " I don't know if you've noticed, but pretty much every week I say something like that", "tokens": [286, 500, 380, 458, 498, 291, 600, 5694, 11, 457, 1238, 709, 633, 1243, 286, 584, 746, 411, 300], "temperature": 0.0, "avg_logprob": -0.15946789276905549, "compression_ratio": 1.6178571428571429, "no_speech_prob": 0.00023034894547890872}, {"id": 8, "seek": 5252, "start": 52.52, "end": 56.32, "text": " a number of times and every time I do I'm always hoping that somebody might go, I wonder", "tokens": [257, 1230, 295, 1413, 293, 633, 565, 286, 360, 286, 478, 1009, 7159, 300, 2618, 1062, 352, 11, 286, 2441], "temperature": 0.0, "avg_logprob": -0.1937703953848945, "compression_ratio": 1.478494623655914, "no_speech_prob": 9.913546819007024e-05}, {"id": 9, "seek": 5252, "start": 56.32, "end": 63.92, "text": " as well. So Slav did wonder and he posted a really interesting blog post about that", "tokens": [382, 731, 13, 407, 6187, 706, 630, 2441, 293, 415, 9437, 257, 534, 1880, 6968, 2183, 466, 300], "temperature": 0.0, "avg_logprob": -0.1937703953848945, "compression_ratio": 1.478494623655914, "no_speech_prob": 9.913546819007024e-05}, {"id": 10, "seek": 5252, "start": 63.92, "end": 66.80000000000001, "text": " exact question.", "tokens": [1900, 1168, 13], "temperature": 0.0, "avg_logprob": -0.1937703953848945, "compression_ratio": 1.478494623655914, "no_speech_prob": 9.913546819007024e-05}, {"id": 11, "seek": 5252, "start": 66.80000000000001, "end": 74.48, "text": " I was thrilled to see that the blog post got a lot of pick-up. On the Machine Learning", "tokens": [286, 390, 18744, 281, 536, 300, 264, 6968, 2183, 658, 257, 688, 295, 1888, 12, 1010, 13, 1282, 264, 22155, 15205], "temperature": 0.0, "avg_logprob": -0.1937703953848945, "compression_ratio": 1.478494623655914, "no_speech_prob": 9.913546819007024e-05}, {"id": 12, "seek": 7448, "start": 74.48, "end": 85.28, "text": " Reddit it got 55 upvotes which for that subreddit put it in second place on the front page.", "tokens": [32210, 309, 658, 12330, 493, 85, 17251, 597, 337, 300, 1422, 986, 17975, 829, 309, 294, 1150, 1081, 322, 264, 1868, 3028, 13], "temperature": 0.0, "avg_logprob": -0.1698776368171938, "compression_ratio": 1.4337349397590362, "no_speech_prob": 4.331620948505588e-05}, {"id": 13, "seek": 7448, "start": 85.28, "end": 94.56, "text": " It also got picked up by the WildML mailing list weekly summary of interesting things", "tokens": [467, 611, 658, 6183, 493, 538, 264, 10904, 12683, 41612, 1329, 12460, 12691, 295, 1880, 721], "temperature": 0.0, "avg_logprob": -0.1698776368171938, "compression_ratio": 1.4337349397590362, "no_speech_prob": 4.331620948505588e-05}, {"id": 14, "seek": 7448, "start": 94.56, "end": 103.4, "text": " in AI as the second post that was listed. So that was great.", "tokens": [294, 7318, 382, 264, 1150, 2183, 300, 390, 10052, 13, 407, 300, 390, 869, 13], "temperature": 0.0, "avg_logprob": -0.1698776368171938, "compression_ratio": 1.4337349397590362, "no_speech_prob": 4.331620948505588e-05}, {"id": 15, "seek": 10340, "start": 103.4, "end": 108.52000000000001, "text": " For those of you that have looked at it and wondered what is it about this post that causes", "tokens": [1171, 729, 295, 291, 300, 362, 2956, 412, 309, 293, 17055, 437, 307, 309, 466, 341, 2183, 300, 7700], "temperature": 0.0, "avg_logprob": -0.19309479599698967, "compression_ratio": 1.7401574803149606, "no_speech_prob": 1.6700971173122525e-05}, {"id": 16, "seek": 10340, "start": 108.52000000000001, "end": 114.72, "text": " it to get noticed whereas other ones don't, I'm not sure I know the secret, but as soon", "tokens": [309, 281, 483, 5694, 9735, 661, 2306, 500, 380, 11, 286, 478, 406, 988, 286, 458, 264, 4054, 11, 457, 382, 2321], "temperature": 0.0, "avg_logprob": -0.19309479599698967, "compression_ratio": 1.7401574803149606, "no_speech_prob": 1.6700971173122525e-05}, {"id": 17, "seek": 10340, "start": 114.72, "end": 118.16000000000001, "text": " as I read it I thought okay, I think a lot of people are going to read this. It gives", "tokens": [382, 286, 1401, 309, 286, 1194, 1392, 11, 286, 519, 257, 688, 295, 561, 366, 516, 281, 1401, 341, 13, 467, 2709], "temperature": 0.0, "avg_logprob": -0.19309479599698967, "compression_ratio": 1.7401574803149606, "no_speech_prob": 1.6700971173122525e-05}, {"id": 18, "seek": 10340, "start": 118.16000000000001, "end": 123.64000000000001, "text": " some background. It assumes an intelligent reader, but it assumes an intelligent reader", "tokens": [512, 3678, 13, 467, 37808, 364, 13232, 15149, 11, 457, 309, 37808, 364, 13232, 15149], "temperature": 0.0, "avg_logprob": -0.19309479599698967, "compression_ratio": 1.7401574803149606, "no_speech_prob": 1.6700971173122525e-05}, {"id": 19, "seek": 10340, "start": 123.64000000000001, "end": 131.4, "text": " who doesn't necessarily know all about this. Something like you guys 6 months ago. So it", "tokens": [567, 1177, 380, 4725, 458, 439, 466, 341, 13, 6595, 411, 291, 1074, 1386, 2493, 2057, 13, 407, 309], "temperature": 0.0, "avg_logprob": -0.19309479599698967, "compression_ratio": 1.7401574803149606, "no_speech_prob": 1.6700971173122525e-05}, {"id": 20, "seek": 13140, "start": 131.4, "end": 136.28, "text": " types like this is what it is and this is where this kind of thing is used and gives", "tokens": [3467, 411, 341, 307, 437, 309, 307, 293, 341, 307, 689, 341, 733, 295, 551, 307, 1143, 293, 2709], "temperature": 0.0, "avg_logprob": -0.2148671506056145, "compression_ratio": 1.6927374301675977, "no_speech_prob": 2.840918386937119e-05}, {"id": 21, "seek": 13140, "start": 136.28, "end": 145.36, "text": " some examples. And then goes ahead and sets up the question of different optimization", "tokens": [512, 5110, 13, 400, 550, 1709, 2286, 293, 6352, 493, 264, 1168, 295, 819, 19618], "temperature": 0.0, "avg_logprob": -0.2148671506056145, "compression_ratio": 1.6927374301675977, "no_speech_prob": 2.840918386937119e-05}, {"id": 22, "seek": 13140, "start": 145.36, "end": 153.20000000000002, "text": " algorithms and then shows lots of examples of both learning curves as well as pictures", "tokens": [14642, 293, 550, 3110, 3195, 295, 5110, 295, 1293, 2539, 19490, 382, 731, 382, 5242], "temperature": 0.0, "avg_logprob": -0.2148671506056145, "compression_ratio": 1.6927374301675977, "no_speech_prob": 2.840918386937119e-05}, {"id": 23, "seek": 13140, "start": 153.20000000000002, "end": 156.64000000000001, "text": " that come out of these different experiments.", "tokens": [300, 808, 484, 295, 613, 819, 12050, 13], "temperature": 0.0, "avg_logprob": -0.2148671506056145, "compression_ratio": 1.6927374301675977, "no_speech_prob": 2.840918386937119e-05}, {"id": 24, "seek": 15664, "start": 156.64, "end": 162.16, "text": " I think hopefully it's been a great experience for Slav as well because in the Reddit thread", "tokens": [286, 519, 4696, 309, 311, 668, 257, 869, 1752, 337, 6187, 706, 382, 731, 570, 294, 264, 32210, 7207], "temperature": 0.0, "avg_logprob": -0.2033492660522461, "compression_ratio": 1.592783505154639, "no_speech_prob": 1.2029497156618163e-05}, {"id": 25, "seek": 15664, "start": 162.16, "end": 169.76, "text": " there's all kinds of folks pointing out other things that he could try, questions that weren't", "tokens": [456, 311, 439, 3685, 295, 4024, 12166, 484, 661, 721, 300, 415, 727, 853, 11, 1651, 300, 4999, 380], "temperature": 0.0, "avg_logprob": -0.2033492660522461, "compression_ratio": 1.592783505154639, "no_speech_prob": 1.2029497156618163e-05}, {"id": 26, "seek": 15664, "start": 169.76, "end": 179.88, "text": " quite clear. So now there's a whole list of things that could be done next. So it opened", "tokens": [1596, 1850, 13, 407, 586, 456, 311, 257, 1379, 1329, 295, 721, 300, 727, 312, 1096, 958, 13, 407, 309, 5625], "temperature": 0.0, "avg_logprob": -0.2033492660522461, "compression_ratio": 1.592783505154639, "no_speech_prob": 1.2029497156618163e-05}, {"id": 27, "seek": 15664, "start": 179.88, "end": 183.51999999999998, "text": " up a whole interesting question.", "tokens": [493, 257, 1379, 1880, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2033492660522461, "compression_ratio": 1.592783505154639, "no_speech_prob": 1.2029497156618163e-05}, {"id": 28, "seek": 18352, "start": 183.52, "end": 189.48000000000002, "text": " Another post which I'm not even sure if it's officially posted yet, I got the early bird", "tokens": [3996, 2183, 597, 286, 478, 406, 754, 988, 498, 309, 311, 12053, 9437, 1939, 11, 286, 658, 264, 2440, 5255], "temperature": 0.0, "avg_logprob": -0.17077736232591711, "compression_ratio": 1.5598290598290598, "no_speech_prob": 4.006269955425523e-05}, {"id": 29, "seek": 18352, "start": 189.48000000000002, "end": 197.96, "text": " version from Brad, is this crazy thing. Here is Kanye drawn using a brush of Captain John", "tokens": [3037, 490, 11895, 11, 307, 341, 3219, 551, 13, 1692, 307, 37654, 10117, 1228, 257, 5287, 295, 10873, 2619], "temperature": 0.0, "avg_logprob": -0.17077736232591711, "compression_ratio": 1.5598290598290598, "no_speech_prob": 4.006269955425523e-05}, {"id": 30, "seek": 18352, "start": 197.96, "end": 206.48000000000002, "text": " Luke Picard. In case you're wondering is that really him, I will show you a zoomed in version.", "tokens": [13044, 25895, 515, 13, 682, 1389, 291, 434, 6359, 307, 300, 534, 796, 11, 286, 486, 855, 291, 257, 8863, 292, 294, 3037, 13], "temperature": 0.0, "avg_logprob": -0.17077736232591711, "compression_ratio": 1.5598290598290598, "no_speech_prob": 4.006269955425523e-05}, {"id": 31, "seek": 18352, "start": 206.48000000000002, "end": 213.48000000000002, "text": " It really is John Luke Picard. This is a really interesting idea because he points out that", "tokens": [467, 534, 307, 2619, 13044, 25895, 515, 13, 639, 307, 257, 534, 1880, 1558, 570, 415, 2793, 484, 300], "temperature": 0.0, "avg_logprob": -0.17077736232591711, "compression_ratio": 1.5598290598290598, "no_speech_prob": 4.006269955425523e-05}, {"id": 32, "seek": 21348, "start": 213.48, "end": 223.67999999999998, "text": " generally speaking, when you try to use a non-artwork as your style image, it doesn't", "tokens": [5101, 4124, 11, 562, 291, 853, 281, 764, 257, 2107, 12, 446, 1902, 382, 428, 3758, 3256, 11, 309, 1177, 380], "temperature": 0.0, "avg_logprob": -0.1504946027483259, "compression_ratio": 1.5987654320987654, "no_speech_prob": 1.2218985830259044e-05}, {"id": 33, "seek": 21348, "start": 223.67999999999998, "end": 229.23999999999998, "text": " actually give very good results. It's another example of a non-artwork, it doesn't give", "tokens": [767, 976, 588, 665, 3542, 13, 467, 311, 1071, 1365, 295, 257, 2107, 12, 446, 1902, 11, 309, 1177, 380, 976], "temperature": 0.0, "avg_logprob": -0.1504946027483259, "compression_ratio": 1.5987654320987654, "no_speech_prob": 1.2218985830259044e-05}, {"id": 34, "seek": 21348, "start": 229.23999999999998, "end": 236.35999999999999, "text": " good results. It's kind of interesting but it's not quite what I was looking for. But", "tokens": [665, 3542, 13, 467, 311, 733, 295, 1880, 457, 309, 311, 406, 1596, 437, 286, 390, 1237, 337, 13, 583], "temperature": 0.0, "avg_logprob": -0.1504946027483259, "compression_ratio": 1.5987654320987654, "no_speech_prob": 1.2218985830259044e-05}, {"id": 35, "seek": 23636, "start": 236.36, "end": 248.04000000000002, "text": " if you tile it, you totally get it. So here's Kanye using a Nintendo game controller brush.", "tokens": [498, 291, 20590, 309, 11, 291, 3879, 483, 309, 13, 407, 510, 311, 37654, 1228, 257, 11578, 1216, 10561, 5287, 13], "temperature": 0.0, "avg_logprob": -0.17755421858567458, "compression_ratio": 1.4301075268817205, "no_speech_prob": 9.516181307844818e-06}, {"id": 36, "seek": 23636, "start": 248.04000000000002, "end": 256.68, "text": " So then he tried out this John Luke Picard and got okay results and kind of realized", "tokens": [407, 550, 415, 3031, 484, 341, 2619, 13044, 25895, 515, 293, 658, 1392, 3542, 293, 733, 295, 5334], "temperature": 0.0, "avg_logprob": -0.17755421858567458, "compression_ratio": 1.4301075268817205, "no_speech_prob": 9.516181307844818e-06}, {"id": 37, "seek": 23636, "start": 256.68, "end": 262.56, "text": " that actually the size of the texture is pretty critical. I've never seen anybody do this", "tokens": [300, 767, 264, 2744, 295, 264, 8091, 307, 1238, 4924, 13, 286, 600, 1128, 1612, 4472, 360, 341], "temperature": 0.0, "avg_logprob": -0.17755421858567458, "compression_ratio": 1.4301075268817205, "no_speech_prob": 9.516181307844818e-06}, {"id": 38, "seek": 26256, "start": 262.56, "end": 269.52, "text": " before. I think when this image gets shared on Twitter, it's going to go everywhere because", "tokens": [949, 13, 286, 519, 562, 341, 3256, 2170, 5507, 322, 5794, 11, 309, 311, 516, 281, 352, 5315, 570], "temperature": 0.0, "avg_logprob": -0.19963044005554992, "compression_ratio": 1.5820895522388059, "no_speech_prob": 8.219967276090756e-05}, {"id": 39, "seek": 26256, "start": 269.52, "end": 277.48, "text": " it's just the freakiest thing. Freaky's good.", "tokens": [309, 311, 445, 264, 21853, 6495, 551, 13, 6142, 15681, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.19963044005554992, "compression_ratio": 1.5820895522388059, "no_speech_prob": 8.219967276090756e-05}, {"id": 40, "seek": 26256, "start": 277.48, "end": 282.52, "text": " I think I warned you guys about your projects when I first mentioned them as being something", "tokens": [286, 519, 286, 21284, 291, 1074, 466, 428, 4455, 562, 286, 700, 2835, 552, 382, 885, 746], "temperature": 0.0, "avg_logprob": -0.19963044005554992, "compression_ratio": 1.5820895522388059, "no_speech_prob": 8.219967276090756e-05}, {"id": 41, "seek": 26256, "start": 282.52, "end": 288.36, "text": " that's very easy to overshoot a little bit and spend weeks and weeks talking about what", "tokens": [300, 311, 588, 1858, 281, 15488, 24467, 257, 707, 857, 293, 3496, 3259, 293, 3259, 1417, 466, 437], "temperature": 0.0, "avg_logprob": -0.19963044005554992, "compression_ratio": 1.5820895522388059, "no_speech_prob": 8.219967276090756e-05}, {"id": 42, "seek": 28836, "start": 288.36, "end": 295.44, "text": " you're eventually going to do. You've had a couple of weeks, really it would have been", "tokens": [291, 434, 4728, 516, 281, 360, 13, 509, 600, 632, 257, 1916, 295, 3259, 11, 534, 309, 576, 362, 668], "temperature": 0.0, "avg_logprob": -0.13878502092863385, "compression_ratio": 1.757847533632287, "no_speech_prob": 2.2473663193522952e-05}, {"id": 43, "seek": 28836, "start": 295.44, "end": 298.48, "text": " nice to have something done by now rather than spending a couple of weeks wondering", "tokens": [1481, 281, 362, 746, 1096, 538, 586, 2831, 813, 6434, 257, 1916, 295, 3259, 6359], "temperature": 0.0, "avg_logprob": -0.13878502092863385, "compression_ratio": 1.757847533632287, "no_speech_prob": 2.2473663193522952e-05}, {"id": 44, "seek": 28836, "start": 298.48, "end": 303.24, "text": " about what to do. So if your team's being a bit slow agreeing on something, just start", "tokens": [466, 437, 281, 360, 13, 407, 498, 428, 1469, 311, 885, 257, 857, 2964, 36900, 322, 746, 11, 445, 722], "temperature": 0.0, "avg_logprob": -0.13878502092863385, "compression_ratio": 1.757847533632287, "no_speech_prob": 2.2473663193522952e-05}, {"id": 45, "seek": 28836, "start": 303.24, "end": 309.92, "text": " working on something yourself. Or as a team, just pick something that you can do by next", "tokens": [1364, 322, 746, 1803, 13, 1610, 382, 257, 1469, 11, 445, 1888, 746, 300, 291, 393, 360, 538, 958], "temperature": 0.0, "avg_logprob": -0.13878502092863385, "compression_ratio": 1.757847533632287, "no_speech_prob": 2.2473663193522952e-05}, {"id": 46, "seek": 28836, "start": 309.92, "end": 314.72, "text": " Monday and write up something brief about it.", "tokens": [8138, 293, 2464, 493, 746, 5353, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.13878502092863385, "compression_ratio": 1.757847533632287, "no_speech_prob": 2.2473663193522952e-05}, {"id": 47, "seek": 31472, "start": 314.72, "end": 320.32000000000005, "text": " So for example, if you're thinking, okay we might do the $1 million data science bowl,", "tokens": [407, 337, 1365, 11, 498, 291, 434, 1953, 11, 1392, 321, 1062, 360, 264, 1848, 16, 2459, 1412, 3497, 6571, 11], "temperature": 0.0, "avg_logprob": -0.17835346857706705, "compression_ratio": 1.64576802507837, "no_speech_prob": 2.0784966181963682e-05}, {"id": 48, "seek": 31472, "start": 320.32000000000005, "end": 324.24, "text": " that's fine. You're not going to finish it by Monday. But maybe by Monday you could have", "tokens": [300, 311, 2489, 13, 509, 434, 406, 516, 281, 2413, 309, 538, 8138, 13, 583, 1310, 538, 8138, 291, 727, 362], "temperature": 0.0, "avg_logprob": -0.17835346857706705, "compression_ratio": 1.64576802507837, "no_speech_prob": 2.0784966181963682e-05}, {"id": 49, "seek": 31472, "start": 324.24, "end": 330.68, "text": " written a blog post introducing what you can learn in a week about medical imaging. Oh", "tokens": [3720, 257, 6968, 2183, 15424, 437, 291, 393, 1466, 294, 257, 1243, 466, 4625, 25036, 13, 876], "temperature": 0.0, "avg_logprob": -0.17835346857706705, "compression_ratio": 1.64576802507837, "no_speech_prob": 2.0784966181963682e-05}, {"id": 50, "seek": 31472, "start": 330.68, "end": 334.44000000000005, "text": " it turns out it uses something called DICOM. Here are the Python DICOM libraries and we", "tokens": [309, 4523, 484, 309, 4960, 746, 1219, 413, 2532, 5251, 13, 1692, 366, 264, 15329, 413, 2532, 5251, 15148, 293, 321], "temperature": 0.0, "avg_logprob": -0.17835346857706705, "compression_ratio": 1.64576802507837, "no_speech_prob": 2.0784966181963682e-05}, {"id": 51, "seek": 31472, "start": 334.44000000000005, "end": 338.44000000000005, "text": " tried to use them. These are the things that got us kind of confused and these are the", "tokens": [3031, 281, 764, 552, 13, 1981, 366, 264, 721, 300, 658, 505, 733, 295, 9019, 293, 613, 366, 264], "temperature": 0.0, "avg_logprob": -0.17835346857706705, "compression_ratio": 1.64576802507837, "no_speech_prob": 2.0784966181963682e-05}, {"id": 52, "seek": 31472, "start": 338.44000000000005, "end": 343.32000000000005, "text": " ways that we solved them. And here's a Python notebook which shows you some of the main", "tokens": [2098, 300, 321, 13041, 552, 13, 400, 510, 311, 257, 15329, 21060, 597, 3110, 291, 512, 295, 264, 2135], "temperature": 0.0, "avg_logprob": -0.17835346857706705, "compression_ratio": 1.64576802507837, "no_speech_prob": 2.0784966181963682e-05}, {"id": 53, "seek": 34332, "start": 343.32, "end": 346.92, "text": " ways you can look at these DICOM for instance.", "tokens": [2098, 291, 393, 574, 412, 613, 413, 2532, 5251, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.1710663026976354, "compression_ratio": 1.609375, "no_speech_prob": 1.1125456694571767e-05}, {"id": 54, "seek": 34332, "start": 346.92, "end": 353.32, "text": " So split up your project into little pieces. It's like when you enter a Kaggle competition,", "tokens": [407, 7472, 493, 428, 1716, 666, 707, 3755, 13, 467, 311, 411, 562, 291, 3242, 257, 48751, 22631, 6211, 11], "temperature": 0.0, "avg_logprob": -0.1710663026976354, "compression_ratio": 1.609375, "no_speech_prob": 1.1125456694571767e-05}, {"id": 55, "seek": 34332, "start": 353.32, "end": 360.0, "text": " I always tell people, submit every single day and try and put in at least half an hour", "tokens": [286, 1009, 980, 561, 11, 10315, 633, 2167, 786, 293, 853, 293, 829, 294, 412, 1935, 1922, 364, 1773], "temperature": 0.0, "avg_logprob": -0.1710663026976354, "compression_ratio": 1.609375, "no_speech_prob": 1.1125456694571767e-05}, {"id": 56, "seek": 34332, "start": 360.0, "end": 365.64, "text": " a day to make it slightly better than yesterday. So how do you put in the first day submission?", "tokens": [257, 786, 281, 652, 309, 4748, 1101, 813, 5186, 13, 407, 577, 360, 291, 829, 294, 264, 700, 786, 23689, 30], "temperature": 0.0, "avg_logprob": -0.1710663026976354, "compression_ratio": 1.609375, "no_speech_prob": 1.1125456694571767e-05}, {"id": 57, "seek": 34332, "start": 365.64, "end": 371.4, "text": " So what I always do on the first day is to submit the benchmark script, which is generally", "tokens": [407, 437, 286, 1009, 360, 322, 264, 700, 786, 307, 281, 10315, 264, 18927, 5755, 11, 597, 307, 5101], "temperature": 0.0, "avg_logprob": -0.1710663026976354, "compression_ratio": 1.609375, "no_speech_prob": 1.1125456694571767e-05}, {"id": 58, "seek": 37140, "start": 371.4, "end": 376.28, "text": " like all zeros. And then the next day I try to improve it, so I'll put in like all 0.5s.", "tokens": [411, 439, 35193, 13, 400, 550, 264, 958, 786, 286, 853, 281, 3470, 309, 11, 370, 286, 603, 829, 294, 411, 439, 1958, 13, 20, 82, 13], "temperature": 0.0, "avg_logprob": -0.18038140172543732, "compression_ratio": 1.8235294117647058, "no_speech_prob": 1.544597398606129e-05}, {"id": 59, "seek": 37140, "start": 376.28, "end": 380.32, "text": " The next day I try to improve it, I'll be like okay what's the average for cats, the", "tokens": [440, 958, 786, 286, 853, 281, 3470, 309, 11, 286, 603, 312, 411, 1392, 437, 311, 264, 4274, 337, 11111, 11, 264], "temperature": 0.0, "avg_logprob": -0.18038140172543732, "compression_ratio": 1.8235294117647058, "no_speech_prob": 1.544597398606129e-05}, {"id": 60, "seek": 37140, "start": 380.32, "end": 386.2, "text": " average for dogs, I'll submit that. And if you do that every day for 90 days, you'll", "tokens": [4274, 337, 7197, 11, 286, 603, 10315, 300, 13, 400, 498, 291, 360, 300, 633, 786, 337, 4289, 1708, 11, 291, 603], "temperature": 0.0, "avg_logprob": -0.18038140172543732, "compression_ratio": 1.8235294117647058, "no_speech_prob": 1.544597398606129e-05}, {"id": 61, "seek": 37140, "start": 386.2, "end": 391.03999999999996, "text": " be amazed at how much you can achieve. Or else if you wait two months and spend all", "tokens": [312, 20507, 412, 577, 709, 291, 393, 4584, 13, 1610, 1646, 498, 291, 1699, 732, 2493, 293, 3496, 439], "temperature": 0.0, "avg_logprob": -0.18038140172543732, "compression_ratio": 1.8235294117647058, "no_speech_prob": 1.544597398606129e-05}, {"id": 62, "seek": 37140, "start": 391.03999999999996, "end": 395.12, "text": " that time reading papers and theorizing and thinking about the best possible approach,", "tokens": [300, 565, 3760, 10577, 293, 27423, 3319, 293, 1953, 466, 264, 1151, 1944, 3109, 11], "temperature": 0.0, "avg_logprob": -0.18038140172543732, "compression_ratio": 1.8235294117647058, "no_speech_prob": 1.544597398606129e-05}, {"id": 63, "seek": 37140, "start": 395.12, "end": 399.47999999999996, "text": " you'll discover that you don't get any submissions in. Or you finally get your perfect submission", "tokens": [291, 603, 4411, 300, 291, 500, 380, 483, 604, 40429, 294, 13, 1610, 291, 2721, 483, 428, 2176, 23689], "temperature": 0.0, "avg_logprob": -0.18038140172543732, "compression_ratio": 1.8235294117647058, "no_speech_prob": 1.544597398606129e-05}, {"id": 64, "seek": 39948, "start": 399.48, "end": 406.12, "text": " in and it goes terribly and now you don't have time to make it better.", "tokens": [294, 293, 309, 1709, 22903, 293, 586, 291, 500, 380, 362, 565, 281, 652, 309, 1101, 13], "temperature": 0.0, "avg_logprob": -0.08304557689400606, "compression_ratio": 1.6523809523809523, "no_speech_prob": 1.1842964340758044e-05}, {"id": 65, "seek": 39948, "start": 406.12, "end": 411.12, "text": " I think those tips are equally useful for Kaggle competitions as well as for making", "tokens": [286, 519, 729, 6082, 366, 12309, 4420, 337, 48751, 22631, 26185, 382, 731, 382, 337, 1455], "temperature": 0.0, "avg_logprob": -0.08304557689400606, "compression_ratio": 1.6523809523809523, "no_speech_prob": 1.1842964340758044e-05}, {"id": 66, "seek": 39948, "start": 411.12, "end": 418.32, "text": " sure that at the end of this part of the course, you have something that you're proud of, something", "tokens": [988, 300, 412, 264, 917, 295, 341, 644, 295, 264, 1164, 11, 291, 362, 746, 300, 291, 434, 4570, 295, 11, 746], "temperature": 0.0, "avg_logprob": -0.08304557689400606, "compression_ratio": 1.6523809523809523, "no_speech_prob": 1.1842964340758044e-05}, {"id": 67, "seek": 39948, "start": 418.32, "end": 425.94, "text": " that you feel you did a good job in a small amount of time. If you try and publish something", "tokens": [300, 291, 841, 291, 630, 257, 665, 1691, 294, 257, 1359, 2372, 295, 565, 13, 759, 291, 853, 293, 11374, 746], "temperature": 0.0, "avg_logprob": -0.08304557689400606, "compression_ratio": 1.6523809523809523, "no_speech_prob": 1.1842964340758044e-05}, {"id": 68, "seek": 42594, "start": 425.94, "end": 430.52, "text": " every week on the same kind of topic, you'll be able to keep going further and further", "tokens": [633, 1243, 322, 264, 912, 733, 295, 4829, 11, 291, 603, 312, 1075, 281, 1066, 516, 3052, 293, 3052], "temperature": 0.0, "avg_logprob": -0.13920135262571734, "compression_ratio": 1.58, "no_speech_prob": 2.429928099445533e-05}, {"id": 69, "seek": 42594, "start": 430.52, "end": 436.36, "text": " on that thing. I don't know what Slav's plans are, but maybe next week he'll follow up on", "tokens": [322, 300, 551, 13, 286, 500, 380, 458, 437, 6187, 706, 311, 5482, 366, 11, 457, 1310, 958, 1243, 415, 603, 1524, 493, 322], "temperature": 0.0, "avg_logprob": -0.13920135262571734, "compression_ratio": 1.58, "no_speech_prob": 2.429928099445533e-05}, {"id": 70, "seek": 42594, "start": 436.36, "end": 440.88, "text": " some of the interesting research angles that came up on Reddit. Or maybe Brad will follow", "tokens": [512, 295, 264, 1880, 2132, 14708, 300, 1361, 493, 322, 32210, 13, 1610, 1310, 11895, 486, 1524], "temperature": 0.0, "avg_logprob": -0.13920135262571734, "compression_ratio": 1.58, "no_speech_prob": 2.429928099445533e-05}, {"id": 71, "seek": 42594, "start": 440.88, "end": 448.52, "text": " up on some of his additional ideas from his post.", "tokens": [493, 322, 512, 295, 702, 4497, 3487, 490, 702, 2183, 13], "temperature": 0.0, "avg_logprob": -0.13920135262571734, "compression_ratio": 1.58, "no_speech_prob": 2.429928099445533e-05}, {"id": 72, "seek": 44852, "start": 448.52, "end": 457.03999999999996, "text": " There's a Lesson 10 Wiki up already which has the notebooks. Just do a git pull on the", "tokens": [821, 311, 257, 18649, 266, 1266, 35892, 493, 1217, 597, 575, 264, 43782, 13, 1449, 360, 257, 18331, 2235, 322, 264], "temperature": 0.0, "avg_logprob": -0.22914674010457872, "compression_ratio": 1.4752475247524752, "no_speech_prob": 2.212465915363282e-05}, {"id": 73, "seek": 44852, "start": 457.03999999999996, "end": 460.64, "text": " GitHub repo to get the most up-to-date.", "tokens": [23331, 49040, 281, 483, 264, 881, 493, 12, 1353, 12, 17393, 13], "temperature": 0.0, "avg_logprob": -0.22914674010457872, "compression_ratio": 1.4752475247524752, "no_speech_prob": 2.212465915363282e-05}, {"id": 74, "seek": 44852, "start": 460.64, "end": 467.56, "text": " Another thing that I wanted to point out is that in study group, so we've been having", "tokens": [3996, 551, 300, 286, 1415, 281, 935, 484, 307, 300, 294, 2979, 1594, 11, 370, 321, 600, 668, 1419], "temperature": 0.0, "avg_logprob": -0.22914674010457872, "compression_ratio": 1.4752475247524752, "no_speech_prob": 2.212465915363282e-05}, {"id": 75, "seek": 44852, "start": 467.56, "end": 471.91999999999996, "text": " study groups each Friday here, and I know some of you have had study groups elsewhere", "tokens": [2979, 3935, 1184, 6984, 510, 11, 293, 286, 458, 512, 295, 291, 362, 632, 2979, 3935, 14517], "temperature": 0.0, "avg_logprob": -0.22914674010457872, "compression_ratio": 1.4752475247524752, "no_speech_prob": 2.212465915363282e-05}, {"id": 76, "seek": 47192, "start": 471.92, "end": 478.72, "text": " around the Bay Area. One of you asked me, I don't understand this gray matrix stuff.", "tokens": [926, 264, 7840, 19405, 13, 1485, 295, 291, 2351, 385, 11, 286, 500, 380, 1223, 341, 10855, 8141, 1507, 13], "temperature": 0.0, "avg_logprob": -0.2045600367527382, "compression_ratio": 1.7804878048780488, "no_speech_prob": 2.468261300236918e-05}, {"id": 77, "seek": 47192, "start": 478.72, "end": 483.16, "text": " I don't get it. What's going on? I understand the symbols, I understand the math, but what's", "tokens": [286, 500, 380, 483, 309, 13, 708, 311, 516, 322, 30, 286, 1223, 264, 16944, 11, 286, 1223, 264, 5221, 11, 457, 437, 311], "temperature": 0.0, "avg_logprob": -0.2045600367527382, "compression_ratio": 1.7804878048780488, "no_speech_prob": 2.468261300236918e-05}, {"id": 78, "seek": 47192, "start": 483.16, "end": 490.88, "text": " going on? And I said, maybe if you had a spreadsheet, it would all make sense. And he was kind of", "tokens": [516, 322, 30, 400, 286, 848, 11, 1310, 498, 291, 632, 257, 27733, 11, 309, 576, 439, 652, 2020, 13, 400, 415, 390, 733, 295], "temperature": 0.0, "avg_logprob": -0.2045600367527382, "compression_ratio": 1.7804878048780488, "no_speech_prob": 2.468261300236918e-05}, {"id": 79, "seek": 47192, "start": 490.88, "end": 496.72, "text": " like, I'm doing it in Python, Python's nice. Maybe if you had a spreadsheet, it would all", "tokens": [411, 11, 286, 478, 884, 309, 294, 15329, 11, 15329, 311, 1481, 13, 2704, 498, 291, 632, 257, 27733, 11, 309, 576, 439], "temperature": 0.0, "avg_logprob": -0.2045600367527382, "compression_ratio": 1.7804878048780488, "no_speech_prob": 2.468261300236918e-05}, {"id": 80, "seek": 49672, "start": 496.72, "end": 503.32000000000005, "text": " make sense. Maybe I'll create a spreadsheet. Yes, do that. And 20 minutes later, I turned", "tokens": [652, 2020, 13, 2704, 286, 603, 1884, 257, 27733, 13, 1079, 11, 360, 300, 13, 400, 945, 2077, 1780, 11, 286, 3574], "temperature": 0.0, "avg_logprob": -0.20404903577721636, "compression_ratio": 1.6988416988416988, "no_speech_prob": 1.4063960406929255e-05}, {"id": 81, "seek": 49672, "start": 503.32000000000005, "end": 507.28000000000003, "text": " to him and I said, so how do you feel about gray matrices now? And he goes, I totally", "tokens": [281, 796, 293, 286, 848, 11, 370, 577, 360, 291, 841, 466, 10855, 32284, 586, 30, 400, 415, 1709, 11, 286, 3879], "temperature": 0.0, "avg_logprob": -0.20404903577721636, "compression_ratio": 1.6988416988416988, "no_speech_prob": 1.4063960406929255e-05}, {"id": 82, "seek": 49672, "start": 507.28000000000003, "end": 511.0, "text": " understand them. And I looked over and he had created a spreadsheet. This was the spreadsheet", "tokens": [1223, 552, 13, 400, 286, 2956, 670, 293, 415, 632, 2942, 257, 27733, 13, 639, 390, 264, 27733], "temperature": 0.0, "avg_logprob": -0.20404903577721636, "compression_ratio": 1.6988416988416988, "no_speech_prob": 1.4063960406929255e-05}, {"id": 83, "seek": 49672, "start": 511.0, "end": 517.24, "text": " he created. It's a very simple spreadsheet where it's like here's an image where the", "tokens": [415, 2942, 13, 467, 311, 257, 588, 2199, 27733, 689, 309, 311, 411, 510, 311, 364, 3256, 689, 264], "temperature": 0.0, "avg_logprob": -0.20404903577721636, "compression_ratio": 1.6988416988416988, "no_speech_prob": 1.4063960406929255e-05}, {"id": 84, "seek": 49672, "start": 517.24, "end": 521.8000000000001, "text": " pixels are just like 1, minus 1, and 0. It has two filters that are either 1 or minus", "tokens": [18668, 366, 445, 411, 502, 11, 3175, 502, 11, 293, 1958, 13, 467, 575, 732, 15995, 300, 366, 2139, 502, 420, 3175], "temperature": 0.0, "avg_logprob": -0.20404903577721636, "compression_ratio": 1.6988416988416988, "no_speech_prob": 1.4063960406929255e-05}, {"id": 85, "seek": 52180, "start": 521.8, "end": 531.16, "text": " 1. He has the flattened convolutions next to each other, and then he's created the dot", "tokens": [502, 13, 634, 575, 264, 24183, 292, 3754, 15892, 958, 281, 1184, 661, 11, 293, 550, 415, 311, 2942, 264, 5893], "temperature": 0.0, "avg_logprob": -0.17915289742606028, "compression_ratio": 1.5974025974025974, "no_speech_prob": 1.6187426808755845e-05}, {"id": 86, "seek": 52180, "start": 531.16, "end": 532.92, "text": " product matrix.", "tokens": [1674, 8141, 13], "temperature": 0.0, "avg_logprob": -0.17915289742606028, "compression_ratio": 1.5974025974025974, "no_speech_prob": 1.6187426808755845e-05}, {"id": 87, "seek": 52180, "start": 532.92, "end": 540.8, "text": " So I haven't been doing so much Excel stuff myself, but I think you learn a lot more by", "tokens": [407, 286, 2378, 380, 668, 884, 370, 709, 19060, 1507, 2059, 11, 457, 286, 519, 291, 1466, 257, 688, 544, 538], "temperature": 0.0, "avg_logprob": -0.17915289742606028, "compression_ratio": 1.5974025974025974, "no_speech_prob": 1.6187426808755845e-05}, {"id": 88, "seek": 52180, "start": 540.8, "end": 545.92, "text": " trying it yourself. Particularly if you try it yourself and can't figure out how to do", "tokens": [1382, 309, 1803, 13, 32281, 498, 291, 853, 309, 1803, 293, 393, 380, 2573, 484, 577, 281, 360], "temperature": 0.0, "avg_logprob": -0.17915289742606028, "compression_ratio": 1.5974025974025974, "no_speech_prob": 1.6187426808755845e-05}, {"id": 89, "seek": 52180, "start": 545.92, "end": 551.16, "text": " it in Excel, then we have the forums. I love Excel, so if you ask me questions about Excel,", "tokens": [309, 294, 19060, 11, 550, 321, 362, 264, 26998, 13, 286, 959, 19060, 11, 370, 498, 291, 1029, 385, 1651, 466, 19060, 11], "temperature": 0.0, "avg_logprob": -0.17915289742606028, "compression_ratio": 1.5974025974025974, "no_speech_prob": 1.6187426808755845e-05}, {"id": 90, "seek": 55116, "start": 551.16, "end": 553.8, "text": " I will have a great time.", "tokens": [286, 486, 362, 257, 869, 565, 13], "temperature": 0.0, "avg_logprob": -0.1708591314462515, "compression_ratio": 1.4939024390243902, "no_speech_prob": 7.88915713201277e-06}, {"id": 91, "seek": 55116, "start": 553.8, "end": 560.04, "text": " I'm not going to put that one on the forum for now because I think it's so easy to create", "tokens": [286, 478, 406, 516, 281, 829, 300, 472, 322, 264, 17542, 337, 586, 570, 286, 519, 309, 311, 370, 1858, 281, 1884], "temperature": 0.0, "avg_logprob": -0.1708591314462515, "compression_ratio": 1.4939024390243902, "no_speech_prob": 7.88915713201277e-06}, {"id": 92, "seek": 55116, "start": 560.04, "end": 564.16, "text": " and you'd get so much more out of doing it yourself for anybody who's still not quite", "tokens": [293, 291, 1116, 483, 370, 709, 544, 484, 295, 884, 309, 1803, 337, 4472, 567, 311, 920, 406, 1596], "temperature": 0.0, "avg_logprob": -0.1708591314462515, "compression_ratio": 1.4939024390243902, "no_speech_prob": 7.88915713201277e-06}, {"id": 93, "seek": 55116, "start": 564.16, "end": 569.48, "text": " understanding what gray matrices are doing.", "tokens": [3701, 437, 10855, 32284, 366, 884, 13], "temperature": 0.0, "avg_logprob": -0.1708591314462515, "compression_ratio": 1.4939024390243902, "no_speech_prob": 7.88915713201277e-06}, {"id": 94, "seek": 56948, "start": 569.48, "end": 586.36, "text": " So last week we talked about the idea of learning with larger datasets. Our goal was to try", "tokens": [407, 1036, 1243, 321, 2825, 466, 264, 1558, 295, 2539, 365, 4833, 42856, 13, 2621, 3387, 390, 281, 853], "temperature": 0.0, "avg_logprob": -0.13936796395674997, "compression_ratio": 1.3984375, "no_speech_prob": 5.77185210204334e-06}, {"id": 95, "seek": 56948, "start": 586.36, "end": 593.64, "text": " and replicate the devise paper. And to remind you, the devise paper is the one where we", "tokens": [293, 25356, 264, 1905, 908, 3035, 13, 400, 281, 4160, 291, 11, 264, 1905, 908, 3035, 307, 264, 472, 689, 321], "temperature": 0.0, "avg_logprob": -0.13936796395674997, "compression_ratio": 1.3984375, "no_speech_prob": 5.77185210204334e-06}, {"id": 96, "seek": 59364, "start": 593.64, "end": 600.8, "text": " do a regular CNN, but the thing that we're trying to predict is not a one-hot encoding", "tokens": [360, 257, 3890, 24859, 11, 457, 264, 551, 300, 321, 434, 1382, 281, 6069, 307, 406, 257, 472, 12, 12194, 43430], "temperature": 0.0, "avg_logprob": -0.17372635083320814, "compression_ratio": 1.5923913043478262, "no_speech_prob": 1.1125484888907522e-05}, {"id": 97, "seek": 59364, "start": 600.8, "end": 607.5, "text": " of the category, but it's the word vector for the category.", "tokens": [295, 264, 7719, 11, 457, 309, 311, 264, 1349, 8062, 337, 264, 7719, 13], "temperature": 0.0, "avg_logprob": -0.17372635083320814, "compression_ratio": 1.5923913043478262, "no_speech_prob": 1.1125484888907522e-05}, {"id": 98, "seek": 59364, "start": 607.5, "end": 612.36, "text": " So it's an interesting problem, but one of the things that's interesting about it is", "tokens": [407, 309, 311, 364, 1880, 1154, 11, 457, 472, 295, 264, 721, 300, 311, 1880, 466, 309, 307], "temperature": 0.0, "avg_logprob": -0.17372635083320814, "compression_ratio": 1.5923913043478262, "no_speech_prob": 1.1125484888907522e-05}, {"id": 99, "seek": 59364, "start": 612.36, "end": 617.96, "text": " we have to use all of ImageNet, which has its own challenges.", "tokens": [321, 362, 281, 764, 439, 295, 29903, 31890, 11, 597, 575, 1080, 1065, 4759, 13], "temperature": 0.0, "avg_logprob": -0.17372635083320814, "compression_ratio": 1.5923913043478262, "no_speech_prob": 1.1125484888907522e-05}, {"id": 100, "seek": 61796, "start": 617.96, "end": 624.9000000000001, "text": " So last week we got to the point where we had created the word vectors. And remember", "tokens": [407, 1036, 1243, 321, 658, 281, 264, 935, 689, 321, 632, 2942, 264, 1349, 18875, 13, 400, 1604], "temperature": 0.0, "avg_logprob": -0.17228838737974775, "compression_ratio": 1.7804878048780488, "no_speech_prob": 5.594303274847334e-06}, {"id": 101, "seek": 61796, "start": 624.9000000000001, "end": 630.36, "text": " the word vectors, we then had to map them to ImageNet categories. There were 1000 ImageNet", "tokens": [264, 1349, 18875, 11, 321, 550, 632, 281, 4471, 552, 281, 29903, 31890, 10479, 13, 821, 645, 9714, 29903, 31890], "temperature": 0.0, "avg_logprob": -0.17228838737974775, "compression_ratio": 1.7804878048780488, "no_speech_prob": 5.594303274847334e-06}, {"id": 102, "seek": 61796, "start": 630.36, "end": 634.76, "text": " categories so we had to create the word vector for each one. We didn't quite get all of them", "tokens": [10479, 370, 321, 632, 281, 1884, 264, 1349, 8062, 337, 1184, 472, 13, 492, 994, 380, 1596, 483, 439, 295, 552], "temperature": 0.0, "avg_logprob": -0.17228838737974775, "compression_ratio": 1.7804878048780488, "no_speech_prob": 5.594303274847334e-06}, {"id": 103, "seek": 61796, "start": 634.76, "end": 642.0400000000001, "text": " to match, but something like 2-thirds of them matched, so we're working on 2-thirds of ImageNet.", "tokens": [281, 2995, 11, 457, 746, 411, 568, 12, 38507, 295, 552, 21447, 11, 370, 321, 434, 1364, 322, 568, 12, 38507, 295, 29903, 31890, 13], "temperature": 0.0, "avg_logprob": -0.17228838737974775, "compression_ratio": 1.7804878048780488, "no_speech_prob": 5.594303274847334e-06}, {"id": 104, "seek": 64204, "start": 642.04, "end": 650.04, "text": " We've got as far as reading all the file names for ImageNet, and then we're going to resize", "tokens": [492, 600, 658, 382, 1400, 382, 3760, 439, 264, 3991, 5288, 337, 29903, 31890, 11, 293, 550, 321, 434, 516, 281, 50069], "temperature": 0.0, "avg_logprob": -0.18190690337634477, "compression_ratio": 1.3594771241830066, "no_speech_prob": 6.7479859353625216e-06}, {"id": 105, "seek": 64204, "start": 650.04, "end": 658.68, "text": " our images to 224x224.", "tokens": [527, 5267, 281, 5853, 19, 87, 7490, 19, 13], "temperature": 0.0, "avg_logprob": -0.18190690337634477, "compression_ratio": 1.3594771241830066, "no_speech_prob": 6.7479859353625216e-06}, {"id": 106, "seek": 64204, "start": 658.68, "end": 666.76, "text": " I think it's a good idea to do some of this preprocessing up front. Something that TensorFlow", "tokens": [286, 519, 309, 311, 257, 665, 1558, 281, 360, 512, 295, 341, 2666, 340, 780, 278, 493, 1868, 13, 6595, 300, 37624], "temperature": 0.0, "avg_logprob": -0.18190690337634477, "compression_ratio": 1.3594771241830066, "no_speech_prob": 6.7479859353625216e-06}, {"id": 107, "seek": 66676, "start": 666.76, "end": 674.52, "text": " and PyTorch both do and Keras recently started doing is that if you use a generator, it actually", "tokens": [293, 9953, 51, 284, 339, 1293, 360, 293, 591, 6985, 3938, 1409, 884, 307, 300, 498, 291, 764, 257, 19265, 11, 309, 767], "temperature": 0.0, "avg_logprob": -0.10654989543714022, "compression_ratio": 1.5696202531645569, "no_speech_prob": 4.71087059850106e-06}, {"id": 108, "seek": 66676, "start": 674.52, "end": 680.92, "text": " does the image preprocessing in a number of separate threads in parallel behind the scenes.", "tokens": [775, 264, 3256, 2666, 340, 780, 278, 294, 257, 1230, 295, 4994, 19314, 294, 8952, 2261, 264, 8026, 13], "temperature": 0.0, "avg_logprob": -0.10654989543714022, "compression_ratio": 1.5696202531645569, "no_speech_prob": 4.71087059850106e-06}, {"id": 109, "seek": 66676, "start": 680.92, "end": 685.56, "text": " And so some of this is a little less important than it was 6 months ago when Keras didn't", "tokens": [400, 370, 512, 295, 341, 307, 257, 707, 1570, 1021, 813, 309, 390, 1386, 2493, 2057, 562, 591, 6985, 994, 380], "temperature": 0.0, "avg_logprob": -0.10654989543714022, "compression_ratio": 1.5696202531645569, "no_speech_prob": 4.71087059850106e-06}, {"id": 110, "seek": 66676, "start": 685.56, "end": 692.76, "text": " do that. It used to be that we had to spend a long time waiting for our data to get processed", "tokens": [360, 300, 13, 467, 1143, 281, 312, 300, 321, 632, 281, 3496, 257, 938, 565, 3806, 337, 527, 1412, 281, 483, 18846], "temperature": 0.0, "avg_logprob": -0.10654989543714022, "compression_ratio": 1.5696202531645569, "no_speech_prob": 4.71087059850106e-06}, {"id": 111, "seek": 69276, "start": 692.76, "end": 696.96, "text": " before it could get into the CNN.", "tokens": [949, 309, 727, 483, 666, 264, 24859, 13], "temperature": 0.0, "avg_logprob": -0.11262997713955966, "compression_ratio": 1.4702970297029703, "no_speech_prob": 1.3006981134822126e-05}, {"id": 112, "seek": 69276, "start": 696.96, "end": 706.2, "text": " Having said that, particularly image resizing, when you've got large JPEGs, just reading", "tokens": [10222, 848, 300, 11, 4098, 3256, 725, 3319, 11, 562, 291, 600, 658, 2416, 508, 5208, 33715, 11, 445, 3760], "temperature": 0.0, "avg_logprob": -0.11262997713955966, "compression_ratio": 1.4702970297029703, "no_speech_prob": 1.3006981134822126e-05}, {"id": 113, "seek": 69276, "start": 706.2, "end": 711.56, "text": " them off the hard disk and resizing them can take quite a long time. I always like to put", "tokens": [552, 766, 264, 1152, 12355, 293, 725, 3319, 552, 393, 747, 1596, 257, 938, 565, 13, 286, 1009, 411, 281, 829], "temperature": 0.0, "avg_logprob": -0.11262997713955966, "compression_ratio": 1.4702970297029703, "no_speech_prob": 1.3006981134822126e-05}, {"id": 114, "seek": 69276, "start": 711.56, "end": 716.3199999999999, "text": " it into do all that resizing up front and end up with something in a nice convenient", "tokens": [309, 666, 360, 439, 300, 725, 3319, 493, 1868, 293, 917, 493, 365, 746, 294, 257, 1481, 10851], "temperature": 0.0, "avg_logprob": -0.11262997713955966, "compression_ratio": 1.4702970297029703, "no_speech_prob": 1.3006981134822126e-05}, {"id": 115, "seek": 71632, "start": 716.32, "end": 724.0, "text": " B-collerate. Amongst other things, it means that unless you have enough money to have", "tokens": [363, 12, 1291, 4658, 473, 13, 16119, 372, 661, 721, 11, 309, 1355, 300, 5969, 291, 362, 1547, 1460, 281, 362], "temperature": 0.0, "avg_logprob": -0.19541651407877605, "compression_ratio": 1.5263157894736843, "no_speech_prob": 9.66600146057317e-06}, {"id": 116, "seek": 71632, "start": 724.0, "end": 731.48, "text": " a huge NVMe or SSD drive, which you can put the entirety of ImageNet on, you probably", "tokens": [257, 2603, 46512, 12671, 420, 30262, 3332, 11, 597, 291, 393, 829, 264, 31557, 295, 29903, 31890, 322, 11, 291, 1391], "temperature": 0.0, "avg_logprob": -0.19541651407877605, "compression_ratio": 1.5263157894736843, "no_speech_prob": 9.66600146057317e-06}, {"id": 117, "seek": 71632, "start": 731.48, "end": 738.7600000000001, "text": " have your big data sets on some kind of pretty slow spinning disk or slow rate array.", "tokens": [362, 428, 955, 1412, 6352, 322, 512, 733, 295, 1238, 2964, 15640, 12355, 420, 2964, 3314, 10225, 13], "temperature": 0.0, "avg_logprob": -0.19541651407877605, "compression_ratio": 1.5263157894736843, "no_speech_prob": 9.66600146057317e-06}, {"id": 118, "seek": 71632, "start": 738.7600000000001, "end": 742.36, "text": " So one of the nice things about doing the resizing first is that it makes it a lot smaller", "tokens": [407, 472, 295, 264, 1481, 721, 466, 884, 264, 725, 3319, 700, 307, 300, 309, 1669, 309, 257, 688, 4356], "temperature": 0.0, "avg_logprob": -0.19541651407877605, "compression_ratio": 1.5263157894736843, "no_speech_prob": 9.66600146057317e-06}, {"id": 119, "seek": 74236, "start": 742.36, "end": 746.32, "text": " and you probably can then fit it on your SSD. There's lots of reasons that I think this", "tokens": [293, 291, 1391, 393, 550, 3318, 309, 322, 428, 30262, 13, 821, 311, 3195, 295, 4112, 300, 286, 519, 341], "temperature": 0.0, "avg_logprob": -0.1784073829650879, "compression_ratio": 1.587719298245614, "no_speech_prob": 1.0616025065246504e-05}, {"id": 120, "seek": 74236, "start": 746.32, "end": 747.32, "text": " is good.", "tokens": [307, 665, 13], "temperature": 0.0, "avg_logprob": -0.1784073829650879, "compression_ratio": 1.587719298245614, "no_speech_prob": 1.0616025065246504e-05}, {"id": 121, "seek": 74236, "start": 747.32, "end": 755.04, "text": " So I'm going to resize all of the ImageNet images, put them in a big holes array on my", "tokens": [407, 286, 478, 516, 281, 50069, 439, 295, 264, 29903, 31890, 5267, 11, 829, 552, 294, 257, 955, 8118, 10225, 322, 452], "temperature": 0.0, "avg_logprob": -0.1784073829650879, "compression_ratio": 1.587719298245614, "no_speech_prob": 1.0616025065246504e-05}, {"id": 122, "seek": 74236, "start": 755.04, "end": 765.24, "text": " SSD. So here's the path, and dpath is the path to my fast SSD mount point. And we talked", "tokens": [30262, 13, 407, 510, 311, 264, 3100, 11, 293, 274, 31852, 307, 264, 3100, 281, 452, 2370, 30262, 3746, 935, 13, 400, 321, 2825], "temperature": 0.0, "avg_logprob": -0.1784073829650879, "compression_ratio": 1.587719298245614, "no_speech_prob": 1.0616025065246504e-05}, {"id": 123, "seek": 74236, "start": 765.24, "end": 771.76, "text": " briefly about the things that actually do the resizing, and we're going to do a different", "tokens": [10515, 466, 264, 721, 300, 767, 360, 264, 725, 3319, 11, 293, 321, 434, 516, 281, 360, 257, 819], "temperature": 0.0, "avg_logprob": -0.1784073829650879, "compression_ratio": 1.587719298245614, "no_speech_prob": 1.0616025065246504e-05}, {"id": 124, "seek": 77176, "start": 771.76, "end": 772.76, "text": " kind of resizing.", "tokens": [733, 295, 725, 3319, 13], "temperature": 0.0, "avg_logprob": -0.11165400505065919, "compression_ratio": 1.794392523364486, "no_speech_prob": 1.1659445590339601e-05}, {"id": 125, "seek": 77176, "start": 772.76, "end": 778.4399999999999, "text": " In the past we've done the same kind of resizing that Keras does, which is to add a black border.", "tokens": [682, 264, 1791, 321, 600, 1096, 264, 912, 733, 295, 725, 3319, 300, 591, 6985, 775, 11, 597, 307, 281, 909, 257, 2211, 7838, 13], "temperature": 0.0, "avg_logprob": -0.11165400505065919, "compression_ratio": 1.794392523364486, "no_speech_prob": 1.1659445590339601e-05}, {"id": 126, "seek": 77176, "start": 778.4399999999999, "end": 781.8, "text": " Like if you start with something that's not square and you make it square, you resize", "tokens": [1743, 498, 291, 722, 365, 746, 300, 311, 406, 3732, 293, 291, 652, 309, 3732, 11, 291, 50069], "temperature": 0.0, "avg_logprob": -0.11165400505065919, "compression_ratio": 1.794392523364486, "no_speech_prob": 1.1659445590339601e-05}, {"id": 127, "seek": 77176, "start": 781.8, "end": 790.68, "text": " the largest axis to be the size of your square, which means you're left with a black border.", "tokens": [264, 6443, 10298, 281, 312, 264, 2744, 295, 428, 3732, 11, 597, 1355, 291, 434, 1411, 365, 257, 2211, 7838, 13], "temperature": 0.0, "avg_logprob": -0.11165400505065919, "compression_ratio": 1.794392523364486, "no_speech_prob": 1.1659445590339601e-05}, {"id": 128, "seek": 77176, "start": 790.68, "end": 798.4, "text": " I was concerned that any model where you have that is going to have to learn to model the", "tokens": [286, 390, 5922, 300, 604, 2316, 689, 291, 362, 300, 307, 516, 281, 362, 281, 1466, 281, 2316, 264], "temperature": 0.0, "avg_logprob": -0.11165400505065919, "compression_ratio": 1.794392523364486, "no_speech_prob": 1.1659445590339601e-05}, {"id": 129, "seek": 79840, "start": 798.4, "end": 803.92, "text": " black border, and b, that you're kind of throwing away information, you're not using the full", "tokens": [2211, 7838, 11, 293, 272, 11, 300, 291, 434, 733, 295, 10238, 1314, 1589, 11, 291, 434, 406, 1228, 264, 1577], "temperature": 0.0, "avg_logprob": -0.17594732697477045, "compression_ratio": 1.6550218340611353, "no_speech_prob": 9.666060577728786e-06}, {"id": 130, "seek": 79840, "start": 803.92, "end": 805.4399999999999, "text": " size of the image.", "tokens": [2744, 295, 264, 3256, 13], "temperature": 0.0, "avg_logprob": -0.17594732697477045, "compression_ratio": 1.6550218340611353, "no_speech_prob": 9.666060577728786e-06}, {"id": 131, "seek": 79840, "start": 805.4399999999999, "end": 812.6, "text": " And indeed, every other library or pretty much paper I've seen uses a different approach,", "tokens": [400, 6451, 11, 633, 661, 6405, 420, 1238, 709, 3035, 286, 600, 1612, 4960, 257, 819, 3109, 11], "temperature": 0.0, "avg_logprob": -0.17594732697477045, "compression_ratio": 1.6550218340611353, "no_speech_prob": 9.666060577728786e-06}, {"id": 132, "seek": 79840, "start": 812.6, "end": 820.48, "text": " which is to resize the smaller side of the image to the square. Now the larger size is", "tokens": [597, 307, 281, 50069, 264, 4356, 1252, 295, 264, 3256, 281, 264, 3732, 13, 823, 264, 4833, 2744, 307], "temperature": 0.0, "avg_logprob": -0.17594732697477045, "compression_ratio": 1.6550218340611353, "no_speech_prob": 9.666060577728786e-06}, {"id": 133, "seek": 79840, "start": 820.48, "end": 825.8, "text": " now too big for your square, so you crop off the top and bottom, or crop off the left and", "tokens": [586, 886, 955, 337, 428, 3732, 11, 370, 291, 9086, 766, 264, 1192, 293, 2767, 11, 420, 9086, 766, 264, 1411, 293], "temperature": 0.0, "avg_logprob": -0.17594732697477045, "compression_ratio": 1.6550218340611353, "no_speech_prob": 9.666060577728786e-06}, {"id": 134, "seek": 82580, "start": 825.8, "end": 832.8, "text": " right. So this is called center cropping approach.", "tokens": [558, 13, 407, 341, 307, 1219, 3056, 4848, 3759, 3109, 13], "temperature": 0.0, "avg_logprob": -0.6059675216674805, "compression_ratio": 1.0, "no_speech_prob": 9.22338313102955e-06}, {"id": 135, "seek": 82580, "start": 832.8, "end": 837.8, "text": " Question asked.", "tokens": [14464, 2351, 13], "temperature": 0.0, "avg_logprob": -0.6059675216674805, "compression_ratio": 1.0, "no_speech_prob": 9.22338313102955e-06}, {"id": 136, "seek": 83780, "start": 837.8, "end": 856.5999999999999, "text": " That's true. What you're doing is throwing away compute. With the one where you do center", "tokens": [663, 311, 2074, 13, 708, 291, 434, 884, 307, 10238, 1314, 14722, 13, 2022, 264, 472, 689, 291, 360, 3056], "temperature": 0.0, "avg_logprob": -0.2255572443423064, "compression_ratio": 1.3308823529411764, "no_speech_prob": 2.9479908789653564e-06}, {"id": 137, "seek": 83780, "start": 856.5999999999999, "end": 861.3199999999999, "text": " crop, you have a complete 224 thing full of meaningful pixels. Whereas with a black border,", "tokens": [9086, 11, 291, 362, 257, 3566, 5853, 19, 551, 1577, 295, 10995, 18668, 13, 13813, 365, 257, 2211, 7838, 11], "temperature": 0.0, "avg_logprob": -0.2255572443423064, "compression_ratio": 1.3308823529411764, "no_speech_prob": 2.9479908789653564e-06}, {"id": 138, "seek": 86132, "start": 861.32, "end": 872.88, "text": " you have a 180x224 bit with meaningful pixels and a whole bunch of black pixels. That can", "tokens": [291, 362, 257, 11971, 87, 7490, 19, 857, 365, 10995, 18668, 293, 257, 1379, 3840, 295, 2211, 18668, 13, 663, 393], "temperature": 0.0, "avg_logprob": -0.18148071178491565, "compression_ratio": 1.4450261780104712, "no_speech_prob": 4.289307071303483e-06}, {"id": 139, "seek": 86132, "start": 872.88, "end": 881.84, "text": " be a problem. It works well for ImageNet because ImageNet things are generally somewhat centered.", "tokens": [312, 257, 1154, 13, 467, 1985, 731, 337, 29903, 31890, 570, 29903, 31890, 721, 366, 5101, 8344, 18988, 13], "temperature": 0.0, "avg_logprob": -0.18148071178491565, "compression_ratio": 1.4450261780104712, "no_speech_prob": 4.289307071303483e-06}, {"id": 140, "seek": 86132, "start": 881.84, "end": 886.48, "text": " You may need to do some kind of initial step to do a heatmap or something like we did in", "tokens": [509, 815, 643, 281, 360, 512, 733, 295, 5883, 1823, 281, 360, 257, 3738, 24223, 420, 746, 411, 321, 630, 294], "temperature": 0.0, "avg_logprob": -0.18148071178491565, "compression_ratio": 1.4450261780104712, "no_speech_prob": 4.289307071303483e-06}, {"id": 141, "seek": 88648, "start": 886.48, "end": 891.9200000000001, "text": " Lesson 7 to figure out roughly where the thing is before you decide where to center the crop.", "tokens": [18649, 266, 1614, 281, 2573, 484, 9810, 689, 264, 551, 307, 949, 291, 4536, 689, 281, 3056, 264, 9086, 13], "temperature": 0.0, "avg_logprob": -0.15059250541355299, "compression_ratio": 1.6382252559726962, "no_speech_prob": 2.9310967875062488e-05}, {"id": 142, "seek": 88648, "start": 891.9200000000001, "end": 895.96, "text": " So these things are all compromises. But I've got to say, since I switched to using this", "tokens": [407, 613, 721, 366, 439, 11482, 3598, 13, 583, 286, 600, 658, 281, 584, 11, 1670, 286, 16858, 281, 1228, 341], "temperature": 0.0, "avg_logprob": -0.15059250541355299, "compression_ratio": 1.6382252559726962, "no_speech_prob": 2.9310967875062488e-05}, {"id": 143, "seek": 88648, "start": 895.96, "end": 900.44, "text": " approach, I feel like my models have trained a lot faster and given better results, certainly", "tokens": [3109, 11, 286, 841, 411, 452, 5245, 362, 8895, 257, 688, 4663, 293, 2212, 1101, 3542, 11, 3297], "temperature": 0.0, "avg_logprob": -0.15059250541355299, "compression_ratio": 1.6382252559726962, "no_speech_prob": 2.9310967875062488e-05}, {"id": 144, "seek": 88648, "start": 900.44, "end": 903.32, "text": " the super resolution.", "tokens": [264, 1687, 8669, 13], "temperature": 0.0, "avg_logprob": -0.15059250541355299, "compression_ratio": 1.6382252559726962, "no_speech_prob": 2.9310967875062488e-05}, {"id": 145, "seek": 88648, "start": 903.32, "end": 909.04, "text": " Now I said last week that we were going to start looking at parallel processing. If you're", "tokens": [823, 286, 848, 1036, 1243, 300, 321, 645, 516, 281, 722, 1237, 412, 8952, 9007, 13, 759, 291, 434], "temperature": 0.0, "avg_logprob": -0.15059250541355299, "compression_ratio": 1.6382252559726962, "no_speech_prob": 2.9310967875062488e-05}, {"id": 146, "seek": 88648, "start": 909.04, "end": 912.6800000000001, "text": " wondering about last week's homework, we're going to get there. But some of the techniques", "tokens": [6359, 466, 1036, 1243, 311, 14578, 11, 321, 434, 516, 281, 483, 456, 13, 583, 512, 295, 264, 7512], "temperature": 0.0, "avg_logprob": -0.15059250541355299, "compression_ratio": 1.6382252559726962, "no_speech_prob": 2.9310967875062488e-05}, {"id": 147, "seek": 91268, "start": 912.68, "end": 918.64, "text": " we're about to learn, we're going to use to do last week's homework even better. So don't", "tokens": [321, 434, 466, 281, 1466, 11, 321, 434, 516, 281, 764, 281, 360, 1036, 1243, 311, 14578, 754, 1101, 13, 407, 500, 380], "temperature": 0.0, "avg_logprob": -0.14961349602901575, "compression_ratio": 1.6026785714285714, "no_speech_prob": 1.1843036190839484e-05}, {"id": 148, "seek": 91268, "start": 918.64, "end": 919.64, "text": " worry.", "tokens": [3292, 13], "temperature": 0.0, "avg_logprob": -0.14961349602901575, "compression_ratio": 1.6026785714285714, "no_speech_prob": 1.1843036190839484e-05}, {"id": 149, "seek": 91268, "start": 919.64, "end": 928.4799999999999, "text": " So what I want to do is I've got a CPU with something like 10 cores on it, and then each", "tokens": [407, 437, 286, 528, 281, 360, 307, 286, 600, 658, 257, 13199, 365, 746, 411, 1266, 24826, 322, 309, 11, 293, 550, 1184], "temperature": 0.0, "avg_logprob": -0.14961349602901575, "compression_ratio": 1.6026785714285714, "no_speech_prob": 1.1843036190839484e-05}, {"id": 150, "seek": 91268, "start": 928.4799999999999, "end": 932.1999999999999, "text": " of those cores have hyperthreading, so it means each of those cores can do kind of two", "tokens": [295, 729, 24826, 362, 9848, 392, 35908, 11, 370, 309, 1355, 1184, 295, 729, 24826, 393, 360, 733, 295, 732], "temperature": 0.0, "avg_logprob": -0.14961349602901575, "compression_ratio": 1.6026785714285714, "no_speech_prob": 1.1843036190839484e-05}, {"id": 151, "seek": 91268, "start": 932.1999999999999, "end": 937.8399999999999, "text": " things at once. So I really want to be able to have a couple of dozen processors going", "tokens": [721, 412, 1564, 13, 407, 286, 534, 528, 281, 312, 1075, 281, 362, 257, 1916, 295, 16654, 27751, 516], "temperature": 0.0, "avg_logprob": -0.14961349602901575, "compression_ratio": 1.6026785714285714, "no_speech_prob": 1.1843036190839484e-05}, {"id": 152, "seek": 93784, "start": 937.84, "end": 944.32, "text": " on, each one resizing an image. That's called parallel processing.", "tokens": [322, 11, 1184, 472, 725, 3319, 364, 3256, 13, 663, 311, 1219, 8952, 9007, 13], "temperature": 0.0, "avg_logprob": -0.19028454241545303, "compression_ratio": 1.445414847161572, "no_speech_prob": 1.863151919678785e-05}, {"id": 153, "seek": 93784, "start": 944.32, "end": 949.1600000000001, "text": " And just to remind you, this is as opposed to vectorization or SIMD, which is where a", "tokens": [400, 445, 281, 4160, 291, 11, 341, 307, 382, 8851, 281, 8062, 2144, 420, 24738, 35, 11, 597, 307, 689, 257], "temperature": 0.0, "avg_logprob": -0.19028454241545303, "compression_ratio": 1.445414847161572, "no_speech_prob": 1.863151919678785e-05}, {"id": 154, "seek": 93784, "start": 949.1600000000001, "end": 954.12, "text": " single thread operates on a bunch of things at a time. So we learned that to get SIMD", "tokens": [2167, 7207, 22577, 322, 257, 3840, 295, 721, 412, 257, 565, 13, 407, 321, 3264, 300, 281, 483, 24738, 35], "temperature": 0.0, "avg_logprob": -0.19028454241545303, "compression_ratio": 1.445414847161572, "no_speech_prob": 1.863151919678785e-05}, {"id": 155, "seek": 93784, "start": 954.12, "end": 966.12, "text": " working you just have to install HelloSIMD. Now we're going to, as well as the 600% speedup,", "tokens": [1364, 291, 445, 362, 281, 3625, 2425, 50, 6324, 35, 13, 823, 321, 434, 516, 281, 11, 382, 731, 382, 264, 11849, 4, 3073, 1010, 11], "temperature": 0.0, "avg_logprob": -0.19028454241545303, "compression_ratio": 1.445414847161572, "no_speech_prob": 1.863151919678785e-05}, {"id": 156, "seek": 96612, "start": 966.12, "end": 972.32, "text": " also get another 10 or 20x speedup by doing parallel processing.", "tokens": [611, 483, 1071, 1266, 420, 945, 87, 3073, 1010, 538, 884, 8952, 9007, 13], "temperature": 0.0, "avg_logprob": -0.10265783071517945, "compression_ratio": 1.6157635467980296, "no_speech_prob": 2.7264536583970767e-06}, {"id": 157, "seek": 96612, "start": 972.32, "end": 979.08, "text": " The basic approach to parallel processing in Python 3 is to set up something called", "tokens": [440, 3875, 3109, 281, 8952, 9007, 294, 15329, 805, 307, 281, 992, 493, 746, 1219], "temperature": 0.0, "avg_logprob": -0.10265783071517945, "compression_ratio": 1.6157635467980296, "no_speech_prob": 2.7264536583970767e-06}, {"id": 158, "seek": 96612, "start": 979.08, "end": 984.36, "text": " either a process pool or a thread pool. So the idea here is that we've got a number of", "tokens": [2139, 257, 1399, 7005, 420, 257, 7207, 7005, 13, 407, 264, 1558, 510, 307, 300, 321, 600, 658, 257, 1230, 295], "temperature": 0.0, "avg_logprob": -0.10265783071517945, "compression_ratio": 1.6157635467980296, "no_speech_prob": 2.7264536583970767e-06}, {"id": 159, "seek": 96612, "start": 984.36, "end": 991.16, "text": " little programs running, threads or processes, and when we set up that pool, we say how many", "tokens": [707, 4268, 2614, 11, 19314, 420, 7555, 11, 293, 562, 321, 992, 493, 300, 7005, 11, 321, 584, 577, 867], "temperature": 0.0, "avg_logprob": -0.10265783071517945, "compression_ratio": 1.6157635467980296, "no_speech_prob": 2.7264536583970767e-06}, {"id": 160, "seek": 99116, "start": 991.16, "end": 998.16, "text": " of those little programs do we want to fire up. And then what we do is we say, now I want", "tokens": [295, 729, 707, 4268, 360, 321, 528, 281, 2610, 493, 13, 400, 550, 437, 321, 360, 307, 321, 584, 11, 586, 286, 528], "temperature": 0.0, "avg_logprob": -0.17527946206026299, "compression_ratio": 1.5960591133004927, "no_speech_prob": 6.540411959576886e-06}, {"id": 161, "seek": 99116, "start": 998.16, "end": 1007.9599999999999, "text": " you to use all of those workers to do something. And the easiest way to do a thing in Python", "tokens": [291, 281, 764, 439, 295, 729, 5600, 281, 360, 746, 13, 400, 264, 12889, 636, 281, 360, 257, 551, 294, 15329], "temperature": 0.0, "avg_logprob": -0.17527946206026299, "compression_ratio": 1.5960591133004927, "no_speech_prob": 6.540411959576886e-06}, {"id": 162, "seek": 99116, "start": 1007.9599999999999, "end": 1013.4399999999999, "text": " 3 is to use map. How many of you have used map before?", "tokens": [805, 307, 281, 764, 4471, 13, 1012, 867, 295, 291, 362, 1143, 4471, 949, 30], "temperature": 0.0, "avg_logprob": -0.17527946206026299, "compression_ratio": 1.5960591133004927, "no_speech_prob": 6.540411959576886e-06}, {"id": 163, "seek": 99116, "start": 1013.4399999999999, "end": 1018.48, "text": " So for those of you who haven't, map is a very common functional programming construct", "tokens": [407, 337, 729, 295, 291, 567, 2378, 380, 11, 4471, 307, 257, 588, 2689, 11745, 9410, 7690], "temperature": 0.0, "avg_logprob": -0.17527946206026299, "compression_ratio": 1.5960591133004927, "no_speech_prob": 6.540411959576886e-06}, {"id": 164, "seek": 101848, "start": 1018.48, "end": 1023.6800000000001, "text": " that's found its way into lots of other languages, which simply says loop through a collection", "tokens": [300, 311, 1352, 1080, 636, 666, 3195, 295, 661, 8650, 11, 597, 2935, 1619, 6367, 807, 257, 5765], "temperature": 0.0, "avg_logprob": -0.1692069435119629, "compression_ratio": 1.7533039647577093, "no_speech_prob": 1.6701154891052283e-05}, {"id": 165, "seek": 101848, "start": 1023.6800000000001, "end": 1029.3600000000001, "text": " and call a function on everything in that collection and return a new collection, which", "tokens": [293, 818, 257, 2445, 322, 1203, 294, 300, 5765, 293, 2736, 257, 777, 5765, 11, 597], "temperature": 0.0, "avg_logprob": -0.1692069435119629, "compression_ratio": 1.7533039647577093, "no_speech_prob": 1.6701154891052283e-05}, {"id": 166, "seek": 101848, "start": 1029.3600000000001, "end": 1034.1200000000001, "text": " is a result of calling that function on that thing. In our case, the function is resize", "tokens": [307, 257, 1874, 295, 5141, 300, 2445, 322, 300, 551, 13, 682, 527, 1389, 11, 264, 2445, 307, 50069], "temperature": 0.0, "avg_logprob": -0.1692069435119629, "compression_ratio": 1.7533039647577093, "no_speech_prob": 1.6701154891052283e-05}, {"id": 167, "seek": 101848, "start": 1034.1200000000001, "end": 1037.24, "text": " and the collection is ImageNet images.", "tokens": [293, 264, 5765, 307, 29903, 31890, 5267, 13], "temperature": 0.0, "avg_logprob": -0.1692069435119629, "compression_ratio": 1.7533039647577093, "no_speech_prob": 1.6701154891052283e-05}, {"id": 168, "seek": 101848, "start": 1037.24, "end": 1045.2, "text": " Well, in fact the collection is a bunch of numbers, 0, 1, 2, 3, 4 and so forth, and what", "tokens": [1042, 11, 294, 1186, 264, 5765, 307, 257, 3840, 295, 3547, 11, 1958, 11, 502, 11, 568, 11, 805, 11, 1017, 293, 370, 5220, 11, 293, 437], "temperature": 0.0, "avg_logprob": -0.1692069435119629, "compression_ratio": 1.7533039647577093, "no_speech_prob": 1.6701154891052283e-05}, {"id": 169, "seek": 104520, "start": 1045.2, "end": 1052.5800000000002, "text": " the resize image is going to do is it's going to open that image off disk. So it's turning", "tokens": [264, 50069, 3256, 307, 516, 281, 360, 307, 309, 311, 516, 281, 1269, 300, 3256, 766, 12355, 13, 407, 309, 311, 6246], "temperature": 0.0, "avg_logprob": -0.15161621955133253, "compression_ratio": 1.5784753363228698, "no_speech_prob": 4.029441697639413e-06}, {"id": 170, "seek": 104520, "start": 1052.5800000000002, "end": 1059.92, "text": " the number 3 into the third image resized to 224x224 and it will return that.", "tokens": [264, 1230, 805, 666, 264, 2636, 3256, 725, 1602, 281, 5853, 19, 87, 7490, 19, 293, 309, 486, 2736, 300, 13], "temperature": 0.0, "avg_logprob": -0.15161621955133253, "compression_ratio": 1.5784753363228698, "no_speech_prob": 4.029441697639413e-06}, {"id": 171, "seek": 104520, "start": 1059.92, "end": 1066.46, "text": " So the general approach here, this is basically what it looks like to do parallel processing", "tokens": [407, 264, 2674, 3109, 510, 11, 341, 307, 1936, 437, 309, 1542, 411, 281, 360, 8952, 9007], "temperature": 0.0, "avg_logprob": -0.15161621955133253, "compression_ratio": 1.5784753363228698, "no_speech_prob": 4.029441697639413e-06}, {"id": 172, "seek": 104520, "start": 1066.46, "end": 1075.02, "text": " in Python. It may look a bit weird. We're going result equals exec.map. This is a function", "tokens": [294, 15329, 13, 467, 815, 574, 257, 857, 3657, 13, 492, 434, 516, 1874, 6915, 4454, 13, 24223, 13, 639, 307, 257, 2445], "temperature": 0.0, "avg_logprob": -0.15161621955133253, "compression_ratio": 1.5784753363228698, "no_speech_prob": 4.029441697639413e-06}, {"id": 173, "seek": 107502, "start": 1075.02, "end": 1080.08, "text": " I want, this is the thing to map over. And then I'm saying for each thing in that list,", "tokens": [286, 528, 11, 341, 307, 264, 551, 281, 4471, 670, 13, 400, 550, 286, 478, 1566, 337, 1184, 551, 294, 300, 1329, 11], "temperature": 0.0, "avg_logprob": -0.156185166589145, "compression_ratio": 1.6920152091254752, "no_speech_prob": 7.8892244346207e-06}, {"id": 174, "seek": 107502, "start": 1080.08, "end": 1085.52, "text": " do something. Now this might make you think, well wait, does that mean this list has to", "tokens": [360, 746, 13, 823, 341, 1062, 652, 291, 519, 11, 731, 1699, 11, 775, 300, 914, 341, 1329, 575, 281], "temperature": 0.0, "avg_logprob": -0.156185166589145, "compression_ratio": 1.6920152091254752, "no_speech_prob": 7.8892244346207e-06}, {"id": 175, "seek": 107502, "start": 1085.52, "end": 1092.56, "text": " have enough memory for every single resized image? And the answer is no, no it doesn't.", "tokens": [362, 1547, 4675, 337, 633, 2167, 725, 1602, 3256, 30, 400, 264, 1867, 307, 572, 11, 572, 309, 1177, 380, 13], "temperature": 0.0, "avg_logprob": -0.156185166589145, "compression_ratio": 1.6920152091254752, "no_speech_prob": 7.8892244346207e-06}, {"id": 176, "seek": 107502, "start": 1092.56, "end": 1099.8799999999999, "text": " One of the things that Python 3 uses a lot more is using these things they call generators.", "tokens": [1485, 295, 264, 721, 300, 15329, 805, 4960, 257, 688, 544, 307, 1228, 613, 721, 436, 818, 38662, 13], "temperature": 0.0, "avg_logprob": -0.156185166589145, "compression_ratio": 1.6920152091254752, "no_speech_prob": 7.8892244346207e-06}, {"id": 177, "seek": 107502, "start": 1099.8799999999999, "end": 1104.84, "text": " Which is basically, it's something that looks like a list, but it's lazy. It only creates", "tokens": [3013, 307, 1936, 11, 309, 311, 746, 300, 1542, 411, 257, 1329, 11, 457, 309, 311, 14847, 13, 467, 787, 7829], "temperature": 0.0, "avg_logprob": -0.156185166589145, "compression_ratio": 1.6920152091254752, "no_speech_prob": 7.8892244346207e-06}, {"id": 178, "seek": 110484, "start": 1104.84, "end": 1110.9399999999998, "text": " that thing when you ask for it. So as I append each image, it's going to give me that image.", "tokens": [300, 551, 562, 291, 1029, 337, 309, 13, 407, 382, 286, 34116, 1184, 3256, 11, 309, 311, 516, 281, 976, 385, 300, 3256, 13], "temperature": 0.0, "avg_logprob": -0.09901473101447611, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.8448181435815059e-06}, {"id": 179, "seek": 110484, "start": 1110.9399999999998, "end": 1117.1399999999999, "text": " And if this mapping is not yet finished creating it, it'll wait. So this approach looks like", "tokens": [400, 498, 341, 18350, 307, 406, 1939, 4335, 4084, 309, 11, 309, 603, 1699, 13, 407, 341, 3109, 1542, 411], "temperature": 0.0, "avg_logprob": -0.09901473101447611, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.8448181435815059e-06}, {"id": 180, "seek": 110484, "start": 1117.1399999999999, "end": 1122.4399999999998, "text": " it's going to use heaps of memory, but it doesn't. It uses only the minimum amount of", "tokens": [309, 311, 516, 281, 764, 415, 2382, 295, 4675, 11, 457, 309, 1177, 380, 13, 467, 4960, 787, 264, 7285, 2372, 295], "temperature": 0.0, "avg_logprob": -0.09901473101447611, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.8448181435815059e-06}, {"id": 181, "seek": 110484, "start": 1122.4399999999998, "end": 1127.32, "text": " memory necessary and it does everything in parallel.", "tokens": [4675, 4818, 293, 309, 775, 1203, 294, 8952, 13], "temperature": 0.0, "avg_logprob": -0.09901473101447611, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.8448181435815059e-06}, {"id": 182, "seek": 112732, "start": 1127.32, "end": 1136.08, "text": " So resized image is something which is going to open up the image, it's going to turn it", "tokens": [407, 725, 1602, 3256, 307, 746, 597, 307, 516, 281, 1269, 493, 264, 3256, 11, 309, 311, 516, 281, 1261, 309], "temperature": 0.0, "avg_logprob": -0.12960867979088608, "compression_ratio": 1.831578947368421, "no_speech_prob": 1.5294098147933255e-06}, {"id": 183, "seek": 112732, "start": 1136.08, "end": 1141.8, "text": " into a NumPy array, and then it's going to resize it. So then the resize does the center", "tokens": [666, 257, 22592, 47, 88, 10225, 11, 293, 550, 309, 311, 516, 281, 50069, 309, 13, 407, 550, 264, 50069, 775, 264, 3056], "temperature": 0.0, "avg_logprob": -0.12960867979088608, "compression_ratio": 1.831578947368421, "no_speech_prob": 1.5294098147933255e-06}, {"id": 184, "seek": 112732, "start": 1141.8, "end": 1147.56, "text": " cropping we just mentioned. And then after it's resized, it's going to get appended.", "tokens": [4848, 3759, 321, 445, 2835, 13, 400, 550, 934, 309, 311, 725, 1602, 11, 309, 311, 516, 281, 483, 724, 3502, 13], "temperature": 0.0, "avg_logprob": -0.12960867979088608, "compression_ratio": 1.831578947368421, "no_speech_prob": 1.5294098147933255e-06}, {"id": 185, "seek": 112732, "start": 1147.56, "end": 1155.62, "text": " What does append image do? So this is a bit weird. What's going on here? What it does", "tokens": [708, 775, 34116, 3256, 360, 30, 407, 341, 307, 257, 857, 3657, 13, 708, 311, 516, 322, 510, 30, 708, 309, 775], "temperature": 0.0, "avg_logprob": -0.12960867979088608, "compression_ratio": 1.831578947368421, "no_speech_prob": 1.5294098147933255e-06}, {"id": 186, "seek": 115562, "start": 1155.62, "end": 1163.1599999999999, "text": " is it's going to actually stick it into what we call a pre-allocated array. So we're learning", "tokens": [307, 309, 311, 516, 281, 767, 2897, 309, 666, 437, 321, 818, 257, 659, 12, 336, 905, 770, 10225, 13, 407, 321, 434, 2539], "temperature": 0.0, "avg_logprob": -0.11114606069862296, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.801041076367255e-06}, {"id": 187, "seek": 115562, "start": 1163.1599999999999, "end": 1166.84, "text": " a lot of computer science concepts here. Anybody that's done computer science before will be", "tokens": [257, 688, 295, 3820, 3497, 10392, 510, 13, 19082, 300, 311, 1096, 3820, 3497, 949, 486, 312], "temperature": 0.0, "avg_logprob": -0.11114606069862296, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.801041076367255e-06}, {"id": 188, "seek": 115562, "start": 1166.84, "end": 1170.8, "text": " familiar with all of this already. If you haven't, you probably won't.", "tokens": [4963, 365, 439, 295, 341, 1217, 13, 759, 291, 2378, 380, 11, 291, 1391, 1582, 380, 13], "temperature": 0.0, "avg_logprob": -0.11114606069862296, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.801041076367255e-06}, {"id": 189, "seek": 115562, "start": 1170.8, "end": 1177.56, "text": " But it's important to know that the slowest thing in your computer, generally speaking,", "tokens": [583, 309, 311, 1021, 281, 458, 300, 264, 2964, 377, 551, 294, 428, 3820, 11, 5101, 4124, 11], "temperature": 0.0, "avg_logprob": -0.11114606069862296, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.801041076367255e-06}, {"id": 190, "seek": 115562, "start": 1177.56, "end": 1182.56, "text": " is allocating memory. It's finding some memory, it's reading stuff from that memory, it's", "tokens": [307, 12660, 990, 4675, 13, 467, 311, 5006, 512, 4675, 11, 309, 311, 3760, 1507, 490, 300, 4675, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.11114606069862296, "compression_ratio": 1.686046511627907, "no_speech_prob": 8.801041076367255e-06}, {"id": 191, "seek": 118256, "start": 1182.56, "end": 1188.12, "text": " writing to that memory, unless of course it's like cache or something. And generally speaking,", "tokens": [3579, 281, 300, 4675, 11, 5969, 295, 1164, 309, 311, 411, 19459, 420, 746, 13, 400, 5101, 4124, 11], "temperature": 0.0, "avg_logprob": -0.14556169046939, "compression_ratio": 1.606694560669456, "no_speech_prob": 4.289320258976659e-06}, {"id": 192, "seek": 118256, "start": 1188.12, "end": 1193.22, "text": " if you create lots and lots of arrays and then throw them away again, that's likely", "tokens": [498, 291, 1884, 3195, 293, 3195, 295, 41011, 293, 550, 3507, 552, 1314, 797, 11, 300, 311, 3700], "temperature": 0.0, "avg_logprob": -0.14556169046939, "compression_ratio": 1.606694560669456, "no_speech_prob": 4.289320258976659e-06}, {"id": 193, "seek": 118256, "start": 1193.22, "end": 1195.44, "text": " to be really, really slow.", "tokens": [281, 312, 534, 11, 534, 2964, 13], "temperature": 0.0, "avg_logprob": -0.14556169046939, "compression_ratio": 1.606694560669456, "no_speech_prob": 4.289320258976659e-06}, {"id": 194, "seek": 118256, "start": 1195.44, "end": 1201.12, "text": " So what I wanted to do was to create a single 224x224 array, which is going to contain my", "tokens": [407, 437, 286, 1415, 281, 360, 390, 281, 1884, 257, 2167, 5853, 19, 87, 7490, 19, 10225, 11, 597, 307, 516, 281, 5304, 452], "temperature": 0.0, "avg_logprob": -0.14556169046939, "compression_ratio": 1.606694560669456, "no_speech_prob": 4.289320258976659e-06}, {"id": 195, "seek": 118256, "start": 1201.12, "end": 1211.4199999999998, "text": " resized image, and then I'm going to append that to my beak-holes tensor. So the way you", "tokens": [725, 1602, 3256, 11, 293, 550, 286, 478, 516, 281, 34116, 300, 281, 452, 48663, 12, 37894, 40863, 13, 407, 264, 636, 291], "temperature": 0.0, "avg_logprob": -0.14556169046939, "compression_ratio": 1.606694560669456, "no_speech_prob": 4.289320258976659e-06}, {"id": 196, "seek": 121142, "start": 1211.42, "end": 1221.0, "text": " do that in Python, it's wonderfully easy. You can create a variable from this thing", "tokens": [360, 300, 294, 15329, 11, 309, 311, 38917, 1858, 13, 509, 393, 1884, 257, 7006, 490, 341, 551], "temperature": 0.0, "avg_logprob": -0.1377308343046455, "compression_ratio": 1.58008658008658, "no_speech_prob": 5.173896624910412e-06}, {"id": 197, "seek": 121142, "start": 1221.0, "end": 1222.44, "text": " called threading.local.", "tokens": [1219, 7207, 278, 13, 5842, 304, 13], "temperature": 0.0, "avg_logprob": -0.1377308343046455, "compression_ratio": 1.58008658008658, "no_speech_prob": 5.173896624910412e-06}, {"id": 198, "seek": 121142, "start": 1222.44, "end": 1228.88, "text": " Now TL is now just basically something that looks a bit like a dictionary, but it's a", "tokens": [823, 40277, 307, 586, 445, 1936, 746, 300, 1542, 257, 857, 411, 257, 25890, 11, 457, 309, 311, 257], "temperature": 0.0, "avg_logprob": -0.1377308343046455, "compression_ratio": 1.58008658008658, "no_speech_prob": 5.173896624910412e-06}, {"id": 199, "seek": 121142, "start": 1228.88, "end": 1233.3200000000002, "text": " very special kind of dictionary. It's going to create a separate copy of it for every", "tokens": [588, 2121, 733, 295, 25890, 13, 467, 311, 516, 281, 1884, 257, 4994, 5055, 295, 309, 337, 633], "temperature": 0.0, "avg_logprob": -0.1377308343046455, "compression_ratio": 1.58008658008658, "no_speech_prob": 5.173896624910412e-06}, {"id": 200, "seek": 121142, "start": 1233.3200000000002, "end": 1239.28, "text": " thread or process. So normally when you've got lots of things happening at once, it's", "tokens": [7207, 420, 1399, 13, 407, 5646, 562, 291, 600, 658, 3195, 295, 721, 2737, 412, 1564, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.1377308343046455, "compression_ratio": 1.58008658008658, "no_speech_prob": 5.173896624910412e-06}, {"id": 201, "seek": 123928, "start": 1239.28, "end": 1245.08, "text": " going to be a real pain because if two things try to use it at the same time, you get bad", "tokens": [516, 281, 312, 257, 957, 1822, 570, 498, 732, 721, 853, 281, 764, 309, 412, 264, 912, 565, 11, 291, 483, 1578], "temperature": 0.0, "avg_logprob": -0.15265296660747724, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.2377524803450797e-06}, {"id": 202, "seek": 123928, "start": 1245.08, "end": 1251.78, "text": " results or even crashes. But if you allocate a variable like this, it automatically creates", "tokens": [3542, 420, 754, 28642, 13, 583, 498, 291, 35713, 257, 7006, 411, 341, 11, 309, 6772, 7829], "temperature": 0.0, "avg_logprob": -0.15265296660747724, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.2377524803450797e-06}, {"id": 203, "seek": 123928, "start": 1251.78, "end": 1255.84, "text": " a separate copy in every thread. You don't have to worry about locks, you don't have", "tokens": [257, 4994, 5055, 294, 633, 7207, 13, 509, 500, 380, 362, 281, 3292, 466, 20703, 11, 291, 500, 380, 362], "temperature": 0.0, "avg_logprob": -0.15265296660747724, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.2377524803450797e-06}, {"id": 204, "seek": 123928, "start": 1255.84, "end": 1258.52, "text": " to worry about race conditions, whatever.", "tokens": [281, 3292, 466, 4569, 4487, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.15265296660747724, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.2377524803450797e-06}, {"id": 205, "seek": 123928, "start": 1258.52, "end": 1266.5, "text": " So once I've created this special threading local variable, I then create a placeholder", "tokens": [407, 1564, 286, 600, 2942, 341, 2121, 7207, 278, 2654, 7006, 11, 286, 550, 1884, 257, 1081, 20480], "temperature": 0.0, "avg_logprob": -0.15265296660747724, "compression_ratio": 1.6851063829787234, "no_speech_prob": 3.2377524803450797e-06}, {"id": 206, "seek": 126650, "start": 1266.5, "end": 1274.28, "text": " inside it which is just an array of zeros of size 224x224x3. So then later on, I create", "tokens": [1854, 309, 597, 307, 445, 364, 10225, 295, 35193, 295, 2744, 5853, 19, 87, 7490, 19, 87, 18, 13, 407, 550, 1780, 322, 11, 286, 1884], "temperature": 0.0, "avg_logprob": -0.16628553928473058, "compression_ratio": 1.4480874316939891, "no_speech_prob": 3.0415897072089138e-06}, {"id": 207, "seek": 126650, "start": 1274.28, "end": 1278.76, "text": " my beak-holes array, which is where I'm going to put everything eventually. And to append", "tokens": [452, 48663, 12, 37894, 10225, 11, 597, 307, 689, 286, 478, 516, 281, 829, 1203, 4728, 13, 400, 281, 34116], "temperature": 0.0, "avg_logprob": -0.16628553928473058, "compression_ratio": 1.4480874316939891, "no_speech_prob": 3.0415897072089138e-06}, {"id": 208, "seek": 126650, "start": 1278.76, "end": 1288.84, "text": " the image, I grab the bit of the image that I want and I put it into that pre-allocated", "tokens": [264, 3256, 11, 286, 4444, 264, 857, 295, 264, 3256, 300, 286, 528, 293, 286, 829, 309, 666, 300, 659, 12, 336, 905, 770], "temperature": 0.0, "avg_logprob": -0.16628553928473058, "compression_ratio": 1.4480874316939891, "no_speech_prob": 3.0415897072089138e-06}, {"id": 209, "seek": 128884, "start": 1288.84, "end": 1297.52, "text": " thread local variable and then I append that to my beak-holes array. So there's lots of", "tokens": [7207, 2654, 7006, 293, 550, 286, 34116, 300, 281, 452, 48663, 12, 37894, 10225, 13, 407, 456, 311, 3195, 295], "temperature": 0.0, "avg_logprob": -0.17354362124488468, "compression_ratio": 1.6156583629893237, "no_speech_prob": 3.446562232056749e-06}, {"id": 210, "seek": 128884, "start": 1297.52, "end": 1305.28, "text": " detail here in terms of using parallel processing effectively. I wanted to briefly mention it,", "tokens": [2607, 510, 294, 2115, 295, 1228, 8952, 9007, 8659, 13, 286, 1415, 281, 10515, 2152, 309, 11], "temperature": 0.0, "avg_logprob": -0.17354362124488468, "compression_ratio": 1.6156583629893237, "no_speech_prob": 3.446562232056749e-06}, {"id": 211, "seek": 128884, "start": 1305.28, "end": 1308.3999999999999, "text": " not because I think somebody who hasn't studied computer science is now going to go, Okay,", "tokens": [406, 570, 286, 519, 2618, 567, 6132, 380, 9454, 3820, 3497, 307, 586, 516, 281, 352, 11, 1033, 11], "temperature": 0.0, "avg_logprob": -0.17354362124488468, "compression_ratio": 1.6156583629893237, "no_speech_prob": 3.446562232056749e-06}, {"id": 212, "seek": 128884, "start": 1308.3999999999999, "end": 1313.32, "text": " I totally understood all that. But to give you some of the things to search for and learn", "tokens": [286, 3879, 7320, 439, 300, 13, 583, 281, 976, 291, 512, 295, 264, 721, 281, 3164, 337, 293, 1466], "temperature": 0.0, "avg_logprob": -0.17354362124488468, "compression_ratio": 1.6156583629893237, "no_speech_prob": 3.446562232056749e-06}, {"id": 213, "seek": 128884, "start": 1313.32, "end": 1318.12, "text": " about over the next week if you haven't done any parallel programming before, you're going", "tokens": [466, 670, 264, 958, 1243, 498, 291, 2378, 380, 1096, 604, 8952, 9410, 949, 11, 291, 434, 516], "temperature": 0.0, "avg_logprob": -0.17354362124488468, "compression_ratio": 1.6156583629893237, "no_speech_prob": 3.446562232056749e-06}, {"id": 214, "seek": 131812, "start": 1318.12, "end": 1325.12, "text": " to need to understand thread local storage and race conditions.", "tokens": [281, 643, 281, 1223, 7207, 2654, 6725, 293, 4569, 4487, 13], "temperature": 0.0, "avg_logprob": -0.3367323466709682, "compression_ratio": 1.2857142857142858, "no_speech_prob": 2.885596768464893e-05}, {"id": 215, "seek": 131812, "start": 1325.12, "end": 1342.12, "text": " In Python, there's something called the global interpreter lock, which is one of the many", "tokens": [682, 15329, 11, 456, 311, 746, 1219, 264, 4338, 34132, 4017, 11, 597, 307, 472, 295, 264, 867], "temperature": 0.0, "avg_logprob": -0.3367323466709682, "compression_ratio": 1.2857142857142858, "no_speech_prob": 2.885596768464893e-05}, {"id": 216, "seek": 134212, "start": 1342.12, "end": 1348.0, "text": " awful things about Python, possibly the most awful thing, which is that in theory two things", "tokens": [11232, 721, 466, 15329, 11, 6264, 264, 881, 11232, 551, 11, 597, 307, 300, 294, 5261, 732, 721], "temperature": 0.0, "avg_logprob": -0.158818111624769, "compression_ratio": 1.6761904761904762, "no_speech_prob": 5.0145927161793225e-06}, {"id": 217, "seek": 134212, "start": 1348.0, "end": 1355.08, "text": " can't happen at the same time because Python wasn't really written in a thread-safe way.", "tokens": [393, 380, 1051, 412, 264, 912, 565, 570, 15329, 2067, 380, 534, 3720, 294, 257, 7207, 12, 5790, 2106, 636, 13], "temperature": 0.0, "avg_logprob": -0.158818111624769, "compression_ratio": 1.6761904761904762, "no_speech_prob": 5.0145927161793225e-06}, {"id": 218, "seek": 134212, "start": 1355.08, "end": 1361.4799999999998, "text": " The good news is that lots of libraries are written in a thread-safe way. So if you're", "tokens": [440, 665, 2583, 307, 300, 3195, 295, 15148, 366, 3720, 294, 257, 7207, 12, 5790, 2106, 636, 13, 407, 498, 291, 434], "temperature": 0.0, "avg_logprob": -0.158818111624769, "compression_ratio": 1.6761904761904762, "no_speech_prob": 5.0145927161793225e-06}, {"id": 219, "seek": 134212, "start": 1361.4799999999998, "end": 1367.0, "text": " using a library where most of its work is being done in C, as is the case with PILO", "tokens": [1228, 257, 6405, 689, 881, 295, 1080, 589, 307, 885, 1096, 294, 383, 11, 382, 307, 264, 1389, 365, 430, 4620, 46], "temperature": 0.0, "avg_logprob": -0.158818111624769, "compression_ratio": 1.6761904761904762, "no_speech_prob": 5.0145927161793225e-06}, {"id": 220, "seek": 136700, "start": 1367.0, "end": 1372.36, "text": " and SIMD, actually you don't have to worry about that. I can prove it to you even because", "tokens": [293, 24738, 35, 11, 767, 291, 500, 380, 362, 281, 3292, 466, 300, 13, 286, 393, 7081, 309, 281, 291, 754, 570], "temperature": 0.0, "avg_logprob": -0.191883385181427, "compression_ratio": 1.4423076923076923, "no_speech_prob": 1.0451407433720306e-05}, {"id": 221, "seek": 136700, "start": 1372.36, "end": 1375.12, "text": " I drew a little picture.", "tokens": [286, 12804, 257, 707, 3036, 13], "temperature": 0.0, "avg_logprob": -0.191883385181427, "compression_ratio": 1.4423076923076923, "no_speech_prob": 1.0451407433720306e-05}, {"id": 222, "seek": 136700, "start": 1375.12, "end": 1384.38, "text": " Here is the result of Serial vs Parallel. Now the Serial without SIMD version is 6 times", "tokens": [1692, 307, 264, 1874, 295, 4210, 831, 12041, 3457, 336, 338, 13, 823, 264, 4210, 831, 1553, 24738, 35, 3037, 307, 1386, 1413], "temperature": 0.0, "avg_logprob": -0.191883385181427, "compression_ratio": 1.4423076923076923, "no_speech_prob": 1.0451407433720306e-05}, {"id": 223, "seek": 136700, "start": 1384.38, "end": 1390.48, "text": " bigger than this. So the kind of default Python code you would have written maybe before today's", "tokens": [3801, 813, 341, 13, 407, 264, 733, 295, 7576, 15329, 3089, 291, 576, 362, 3720, 1310, 949, 965, 311], "temperature": 0.0, "avg_logprob": -0.191883385181427, "compression_ratio": 1.4423076923076923, "no_speech_prob": 1.0451407433720306e-05}, {"id": 224, "seek": 139048, "start": 1390.48, "end": 1401.24, "text": " course would have been 120 seconds, process 2000 images. With SIMD, it's 25 seconds. With", "tokens": [1164, 576, 362, 668, 10411, 3949, 11, 1399, 8132, 5267, 13, 2022, 24738, 35, 11, 309, 311, 3552, 3949, 13, 2022], "temperature": 0.0, "avg_logprob": -0.17488128260562294, "compression_ratio": 1.6319018404907975, "no_speech_prob": 5.422173217084492e-06}, {"id": 225, "seek": 139048, "start": 1401.24, "end": 1407.16, "text": " the process pool, it's 8 seconds for 3 workers, for 6 workers it's 5 seconds, so on and so", "tokens": [264, 1399, 7005, 11, 309, 311, 1649, 3949, 337, 805, 5600, 11, 337, 1386, 5600, 309, 311, 1025, 3949, 11, 370, 322, 293, 370], "temperature": 0.0, "avg_logprob": -0.17488128260562294, "compression_ratio": 1.6319018404907975, "no_speech_prob": 5.422173217084492e-06}, {"id": 226, "seek": 139048, "start": 1407.16, "end": 1415.0, "text": " forth. The thread pool is even better, 3.6 seconds for 12 workers, 3.2 seconds for 16", "tokens": [5220, 13, 440, 7207, 7005, 307, 754, 1101, 11, 805, 13, 21, 3949, 337, 2272, 5600, 11, 805, 13, 17, 3949, 337, 3165], "temperature": 0.0, "avg_logprob": -0.17488128260562294, "compression_ratio": 1.6319018404907975, "no_speech_prob": 5.422173217084492e-06}, {"id": 227, "seek": 141500, "start": 1415.0, "end": 1421.76, "text": " workers. Your mileage will vary depending on what CPU you have. Given that probably", "tokens": [5600, 13, 2260, 43121, 486, 10559, 5413, 322, 437, 13199, 291, 362, 13, 18600, 300, 1391], "temperature": 0.0, "avg_logprob": -0.13629145761138028, "compression_ratio": 1.6216216216216217, "no_speech_prob": 2.3187127226265147e-05}, {"id": 228, "seek": 141500, "start": 1421.76, "end": 1425.04, "text": " quite a lot of you are using the P2 still, unless you've got your deep learning box up", "tokens": [1596, 257, 688, 295, 291, 366, 1228, 264, 430, 17, 920, 11, 5969, 291, 600, 658, 428, 2452, 2539, 2424, 493], "temperature": 0.0, "avg_logprob": -0.13629145761138028, "compression_ratio": 1.6216216216216217, "no_speech_prob": 2.3187127226265147e-05}, {"id": 229, "seek": 141500, "start": 1425.04, "end": 1429.88, "text": " and running, you'll have the same performance as other people using the P2. You should try", "tokens": [293, 2614, 11, 291, 603, 362, 264, 912, 3389, 382, 661, 561, 1228, 264, 430, 17, 13, 509, 820, 853], "temperature": 0.0, "avg_logprob": -0.13629145761138028, "compression_ratio": 1.6216216216216217, "no_speech_prob": 2.3187127226265147e-05}, {"id": 230, "seek": 141500, "start": 1429.88, "end": 1435.88, "text": " something like this, which is to try different numbers of workers and see what's the optimal", "tokens": [746, 411, 341, 11, 597, 307, 281, 853, 819, 3547, 295, 5600, 293, 536, 437, 311, 264, 16252], "temperature": 0.0, "avg_logprob": -0.13629145761138028, "compression_ratio": 1.6216216216216217, "no_speech_prob": 2.3187127226265147e-05}, {"id": 231, "seek": 141500, "start": 1435.88, "end": 1440.2, "text": " for that particular CPU. And now once you've done that, you know.", "tokens": [337, 300, 1729, 13199, 13, 400, 586, 1564, 291, 600, 1096, 300, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.13629145761138028, "compression_ratio": 1.6216216216216217, "no_speech_prob": 2.3187127226265147e-05}, {"id": 232, "seek": 144020, "start": 1440.2, "end": 1446.0, "text": " Once I went beyond 16, I didn't really get improvements. So I know that on that computer,", "tokens": [3443, 286, 1437, 4399, 3165, 11, 286, 994, 380, 534, 483, 13797, 13, 407, 286, 458, 300, 322, 300, 3820, 11], "temperature": 0.0, "avg_logprob": -0.1886163526965726, "compression_ratio": 1.5085470085470085, "no_speech_prob": 9.22340404940769e-06}, {"id": 233, "seek": 144020, "start": 1446.0, "end": 1450.72, "text": " a thread pool of size 16 is a pretty good choice. And as you can see, once you get into", "tokens": [257, 7207, 7005, 295, 2744, 3165, 307, 257, 1238, 665, 3922, 13, 400, 382, 291, 393, 536, 11, 1564, 291, 483, 666], "temperature": 0.0, "avg_logprob": -0.1886163526965726, "compression_ratio": 1.5085470085470085, "no_speech_prob": 9.22340404940769e-06}, {"id": 234, "seek": 144020, "start": 1450.72, "end": 1464.48, "text": " the right general vicinity, it doesn't vary too much. So that's the general approach here,", "tokens": [264, 558, 2674, 42387, 11, 309, 1177, 380, 10559, 886, 709, 13, 407, 300, 311, 264, 2674, 3109, 510, 11], "temperature": 0.0, "avg_logprob": -0.1886163526965726, "compression_ratio": 1.5085470085470085, "no_speech_prob": 9.22340404940769e-06}, {"id": 235, "seek": 144020, "start": 1464.48, "end": 1469.88, "text": " is run through something in parallel, each time append it to my becals array, and at", "tokens": [307, 1190, 807, 746, 294, 8952, 11, 1184, 565, 34116, 309, 281, 452, 312, 66, 1124, 10225, 11, 293, 412], "temperature": 0.0, "avg_logprob": -0.1886163526965726, "compression_ratio": 1.5085470085470085, "no_speech_prob": 9.22340404940769e-06}, {"id": 236, "seek": 146988, "start": 1469.88, "end": 1474.16, "text": " the end of that, I've got a becal's array which I can use again and again. So I don't", "tokens": [264, 917, 295, 300, 11, 286, 600, 658, 257, 312, 9895, 311, 10225, 597, 286, 393, 764, 797, 293, 797, 13, 407, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.26381231609143707, "compression_ratio": 1.409356725146199, "no_speech_prob": 3.169205956510268e-05}, {"id": 237, "seek": 146988, "start": 1474.16, "end": 1480.8000000000002, "text": " rerun that code very often anymore. I've got all of the ImageNet resized into each of 72x72,", "tokens": [43819, 409, 300, 3089, 588, 2049, 3602, 13, 286, 600, 658, 439, 295, 264, 29903, 31890, 725, 1602, 666, 1184, 295, 18731, 87, 28890, 11], "temperature": 0.0, "avg_logprob": -0.26381231609143707, "compression_ratio": 1.409356725146199, "no_speech_prob": 3.169205956510268e-05}, {"id": 238, "seek": 146988, "start": 1480.8000000000002, "end": 1486.96, "text": " 224, and 288. I give them different names and I just use them.", "tokens": [5853, 19, 11, 293, 7562, 23, 13, 286, 976, 552, 819, 5288, 293, 286, 445, 764, 552, 13], "temperature": 0.0, "avg_logprob": -0.26381231609143707, "compression_ratio": 1.409356725146199, "no_speech_prob": 3.169205956510268e-05}, {"id": 239, "seek": 148696, "start": 1486.96, "end": 1510.8, "text": " In fact, I think that's what Keras does. I think it squishes. So here's one of these", "tokens": [682, 1186, 11, 286, 519, 300, 311, 437, 591, 6985, 775, 13, 286, 519, 309, 2339, 16423, 13, 407, 510, 311, 472, 295, 613], "temperature": 0.0, "avg_logprob": -0.23944854736328125, "compression_ratio": 1.359375, "no_speech_prob": 4.6107161324471235e-05}, {"id": 240, "seek": 148696, "start": 1510.8, "end": 1516.92, "text": " things. I'm not quite sure. My guess was that I don't think it's a good idea, because you", "tokens": [721, 13, 286, 478, 406, 1596, 988, 13, 1222, 2041, 390, 300, 286, 500, 380, 519, 309, 311, 257, 665, 1558, 11, 570, 291], "temperature": 0.0, "avg_logprob": -0.23944854736328125, "compression_ratio": 1.359375, "no_speech_prob": 4.6107161324471235e-05}, {"id": 241, "seek": 151692, "start": 1516.92, "end": 1521.72, "text": " are now going to have dogs of various different squish levels, and your CNN is going to have", "tokens": [366, 586, 516, 281, 362, 7197, 295, 3683, 819, 31379, 4358, 11, 293, 428, 24859, 307, 516, 281, 362], "temperature": 0.0, "avg_logprob": -0.16991431372506277, "compression_ratio": 1.61244019138756, "no_speech_prob": 3.2191779610002413e-05}, {"id": 242, "seek": 151692, "start": 1521.72, "end": 1532.3600000000001, "text": " to learn that thing. It's got another type of symmetry to learn about, level of squishiness.", "tokens": [281, 1466, 300, 551, 13, 467, 311, 658, 1071, 2010, 295, 25440, 281, 1466, 466, 11, 1496, 295, 31379, 1324, 13], "temperature": 0.0, "avg_logprob": -0.16991431372506277, "compression_ratio": 1.61244019138756, "no_speech_prob": 3.2191779610002413e-05}, {"id": 243, "seek": 151692, "start": 1532.3600000000001, "end": 1540.92, "text": " If we keep everything the same kind of aspect ratio, I think it's going to be easier to", "tokens": [759, 321, 1066, 1203, 264, 912, 733, 295, 4171, 8509, 11, 286, 519, 309, 311, 516, 281, 312, 3571, 281], "temperature": 0.0, "avg_logprob": -0.16991431372506277, "compression_ratio": 1.61244019138756, "no_speech_prob": 3.2191779610002413e-05}, {"id": 244, "seek": 151692, "start": 1540.92, "end": 1546.0, "text": " learn so we'll get better results with less epochs of training.", "tokens": [1466, 370, 321, 603, 483, 1101, 3542, 365, 1570, 30992, 28346, 295, 3097, 13], "temperature": 0.0, "avg_logprob": -0.16991431372506277, "compression_ratio": 1.61244019138756, "no_speech_prob": 3.2191779610002413e-05}, {"id": 245, "seek": 154600, "start": 1546.0, "end": 1549.2, "text": " That's my theory and I'd be fascinated for somebody to do a really in-depth analysis", "tokens": [663, 311, 452, 5261, 293, 286, 1116, 312, 24597, 337, 2618, 281, 360, 257, 534, 294, 12, 25478, 5215], "temperature": 0.0, "avg_logprob": -0.1870149884905134, "compression_ratio": 1.5692883895131087, "no_speech_prob": 1.6187386790988967e-05}, {"id": 246, "seek": 154600, "start": 1549.2, "end": 1557.64, "text": " of black borders versus center cropping versus squishing with ImageNet.", "tokens": [295, 2211, 16287, 5717, 3056, 4848, 3759, 5717, 2339, 3807, 365, 29903, 31890, 13], "temperature": 0.0, "avg_logprob": -0.1870149884905134, "compression_ratio": 1.5692883895131087, "no_speech_prob": 1.6187386790988967e-05}, {"id": 247, "seek": 154600, "start": 1557.64, "end": 1565.0, "text": " So from now on we can just open the becal's array. We're now ready to create our model.", "tokens": [407, 490, 586, 322, 321, 393, 445, 1269, 264, 312, 9895, 311, 10225, 13, 492, 434, 586, 1919, 281, 1884, 527, 2316, 13], "temperature": 0.0, "avg_logprob": -0.1870149884905134, "compression_ratio": 1.5692883895131087, "no_speech_prob": 1.6187386790988967e-05}, {"id": 248, "seek": 154600, "start": 1565.0, "end": 1569.0, "text": " I'll run through this pretty quickly because most of it's pretty boring. The basic idea", "tokens": [286, 603, 1190, 807, 341, 1238, 2661, 570, 881, 295, 309, 311, 1238, 9989, 13, 440, 3875, 1558], "temperature": 0.0, "avg_logprob": -0.1870149884905134, "compression_ratio": 1.5692883895131087, "no_speech_prob": 1.6187386790988967e-05}, {"id": 249, "seek": 154600, "start": 1569.0, "end": 1575.16, "text": " here is that we need to create an array of labels which are called vex, which contains", "tokens": [510, 307, 300, 321, 643, 281, 1884, 364, 10225, 295, 16949, 597, 366, 1219, 1241, 87, 11, 597, 8306], "temperature": 0.0, "avg_logprob": -0.1870149884905134, "compression_ratio": 1.5692883895131087, "no_speech_prob": 1.6187386790988967e-05}, {"id": 250, "seek": 157516, "start": 1575.16, "end": 1584.44, "text": " for every image in my becal's array, it needs to contain the target word vector for that", "tokens": [337, 633, 3256, 294, 452, 312, 9895, 311, 10225, 11, 309, 2203, 281, 5304, 264, 3779, 1349, 8062, 337, 300], "temperature": 0.0, "avg_logprob": -0.17496893856976484, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.4285405086411629e-05}, {"id": 251, "seek": 157516, "start": 1584.44, "end": 1585.44, "text": " image.", "tokens": [3256, 13], "temperature": 0.0, "avg_logprob": -0.17496893856976484, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.4285405086411629e-05}, {"id": 252, "seek": 157516, "start": 1585.44, "end": 1595.44, "text": " Just to remind you, last week we randomly ordered the filenames, so this becal's array", "tokens": [1449, 281, 4160, 291, 11, 1036, 1243, 321, 16979, 8866, 264, 1387, 268, 1632, 11, 370, 341, 312, 9895, 311, 10225], "temperature": 0.0, "avg_logprob": -0.17496893856976484, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.4285405086411629e-05}, {"id": 253, "seek": 157516, "start": 1595.44, "end": 1604.38, "text": " is in random order. So we've got our labels, which is the word vectors for every image.", "tokens": [307, 294, 4974, 1668, 13, 407, 321, 600, 658, 527, 16949, 11, 597, 307, 264, 1349, 18875, 337, 633, 3256, 13], "temperature": 0.0, "avg_logprob": -0.17496893856976484, "compression_ratio": 1.588235294117647, "no_speech_prob": 1.4285405086411629e-05}, {"id": 254, "seek": 160438, "start": 1604.38, "end": 1613.6000000000001, "text": " We need to do our normal preprocessing. This is a handy way to preprocess in the new version", "tokens": [492, 643, 281, 360, 527, 2710, 2666, 340, 780, 278, 13, 639, 307, 257, 13239, 636, 281, 2666, 340, 780, 294, 264, 777, 3037], "temperature": 0.0, "avg_logprob": -0.11995421515570746, "compression_ratio": 1.5988372093023255, "no_speech_prob": 1.4510248547594529e-05}, {"id": 255, "seek": 160438, "start": 1613.6000000000001, "end": 1622.0, "text": " of Keras. We're using the normal Keras resnet model, the one that comes in Keras.applications.", "tokens": [295, 591, 6985, 13, 492, 434, 1228, 264, 2710, 591, 6985, 725, 7129, 2316, 11, 264, 472, 300, 1487, 294, 591, 6985, 13, 1746, 1050, 763, 13], "temperature": 0.0, "avg_logprob": -0.11995421515570746, "compression_ratio": 1.5988372093023255, "no_speech_prob": 1.4510248547594529e-05}, {"id": 256, "seek": 160438, "start": 1622.0, "end": 1628.3600000000001, "text": " It doesn't do the preprocessing for you, but if you create a lambda layer that does the", "tokens": [467, 1177, 380, 360, 264, 2666, 340, 780, 278, 337, 291, 11, 457, 498, 291, 1884, 257, 13607, 4583, 300, 775, 264], "temperature": 0.0, "avg_logprob": -0.11995421515570746, "compression_ratio": 1.5988372093023255, "no_speech_prob": 1.4510248547594529e-05}, {"id": 257, "seek": 162836, "start": 1628.36, "end": 1636.12, "text": " preprocessing, then you can use that lambda layer as the input tensor. So this whole thing", "tokens": [2666, 340, 780, 278, 11, 550, 291, 393, 764, 300, 13607, 4583, 382, 264, 4846, 40863, 13, 407, 341, 1379, 551], "temperature": 0.0, "avg_logprob": -0.11176047117813774, "compression_ratio": 1.5825688073394495, "no_speech_prob": 1.0129931069968734e-05}, {"id": 258, "seek": 162836, "start": 1636.12, "end": 1641.6799999999998, "text": " now will do the preprocessing automatically without you having to worry about it.", "tokens": [586, 486, 360, 264, 2666, 340, 780, 278, 6772, 1553, 291, 1419, 281, 3292, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.11176047117813774, "compression_ratio": 1.5825688073394495, "no_speech_prob": 1.0129931069968734e-05}, {"id": 259, "seek": 162836, "start": 1641.6799999999998, "end": 1645.84, "text": " So that's a good little trick. I'm not sure it's quite as neat as what we did in part", "tokens": [407, 300, 311, 257, 665, 707, 4282, 13, 286, 478, 406, 988, 309, 311, 1596, 382, 10654, 382, 437, 321, 630, 294, 644], "temperature": 0.0, "avg_logprob": -0.11176047117813774, "compression_ratio": 1.5825688073394495, "no_speech_prob": 1.0129931069968734e-05}, {"id": 260, "seek": 162836, "start": 1645.84, "end": 1651.8, "text": " 1 where we put it in the model itself. But at least this way we don't have to maintain", "tokens": [502, 689, 321, 829, 309, 294, 264, 2316, 2564, 13, 583, 412, 1935, 341, 636, 321, 500, 380, 362, 281, 6909], "temperature": 0.0, "avg_logprob": -0.11176047117813774, "compression_ratio": 1.5825688073394495, "no_speech_prob": 1.0129931069968734e-05}, {"id": 261, "seek": 165180, "start": 1651.8, "end": 1664.86, "text": " a whole separate version of all of the models. So that's kind of what I'm doing nowadays.", "tokens": [257, 1379, 4994, 3037, 295, 439, 295, 264, 5245, 13, 407, 300, 311, 733, 295, 437, 286, 478, 884, 13434, 13], "temperature": 0.0, "avg_logprob": -0.11034320005730017, "compression_ratio": 1.563953488372093, "no_speech_prob": 1.0129915608558804e-05}, {"id": 262, "seek": 165180, "start": 1664.86, "end": 1670.6, "text": " When you're working on really big datasets, you don't want to process things any more", "tokens": [1133, 291, 434, 1364, 322, 534, 955, 42856, 11, 291, 500, 380, 528, 281, 1399, 721, 604, 544], "temperature": 0.0, "avg_logprob": -0.11034320005730017, "compression_ratio": 1.563953488372093, "no_speech_prob": 1.0129915608558804e-05}, {"id": 263, "seek": 165180, "start": 1670.6, "end": 1675.6399999999999, "text": " than necessary and any more times than necessary. I know ahead of time that I'm going to want", "tokens": [813, 4818, 293, 604, 544, 1413, 813, 4818, 13, 286, 458, 2286, 295, 565, 300, 286, 478, 516, 281, 528], "temperature": 0.0, "avg_logprob": -0.11034320005730017, "compression_ratio": 1.563953488372093, "no_speech_prob": 1.0129915608558804e-05}, {"id": 264, "seek": 167564, "start": 1675.64, "end": 1684.44, "text": " to do some fine-tuning. So what I decided to do was, this is the particular layer where", "tokens": [281, 360, 512, 2489, 12, 83, 37726, 13, 407, 437, 286, 3047, 281, 360, 390, 11, 341, 307, 264, 1729, 4583, 689], "temperature": 0.0, "avg_logprob": -0.13813618437884606, "compression_ratio": 1.6335403726708075, "no_speech_prob": 5.338119990483392e-06}, {"id": 265, "seek": 167564, "start": 1684.44, "end": 1690.1200000000001, "text": " I'm going to do my fine-tuning. So I decided to first of all create a model which started", "tokens": [286, 478, 516, 281, 360, 452, 2489, 12, 83, 37726, 13, 407, 286, 3047, 281, 700, 295, 439, 1884, 257, 2316, 597, 1409], "temperature": 0.0, "avg_logprob": -0.13813618437884606, "compression_ratio": 1.6335403726708075, "no_speech_prob": 5.338119990483392e-06}, {"id": 266, "seek": 167564, "start": 1690.1200000000001, "end": 1700.64, "text": " at the input and went as far as this layer. So my first step was to create that model", "tokens": [412, 264, 4846, 293, 1437, 382, 1400, 382, 341, 4583, 13, 407, 452, 700, 1823, 390, 281, 1884, 300, 2316], "temperature": 0.0, "avg_logprob": -0.13813618437884606, "compression_ratio": 1.6335403726708075, "no_speech_prob": 5.338119990483392e-06}, {"id": 267, "seek": 170064, "start": 1700.64, "end": 1706.3600000000001, "text": " and save the results of that. And then the next step will be to take that intermediate", "tokens": [293, 3155, 264, 3542, 295, 300, 13, 400, 550, 264, 958, 1823, 486, 312, 281, 747, 300, 19376], "temperature": 0.0, "avg_logprob": -0.14520596955951892, "compression_ratio": 1.6311111111111112, "no_speech_prob": 1.5534917565673823e-06}, {"id": 268, "seek": 170064, "start": 1706.3600000000001, "end": 1711.5200000000002, "text": " step and take it to the next stage I want to fine-tune to and save that. So it's a little", "tokens": [1823, 293, 747, 309, 281, 264, 958, 3233, 286, 528, 281, 2489, 12, 83, 2613, 281, 293, 3155, 300, 13, 407, 309, 311, 257, 707], "temperature": 0.0, "avg_logprob": -0.14520596955951892, "compression_ratio": 1.6311111111111112, "no_speech_prob": 1.5534917565673823e-06}, {"id": 269, "seek": 170064, "start": 1711.5200000000002, "end": 1712.5200000000002, "text": " shortcut.", "tokens": [24822, 13], "temperature": 0.0, "avg_logprob": -0.14520596955951892, "compression_ratio": 1.6311111111111112, "no_speech_prob": 1.5534917565673823e-06}, {"id": 270, "seek": 170064, "start": 1712.5200000000002, "end": 1719.48, "text": " There's a couple of really important intricacies to be aware of here though. The first one", "tokens": [821, 311, 257, 1916, 295, 534, 1021, 30242, 20330, 281, 312, 3650, 295, 510, 1673, 13, 440, 700, 472], "temperature": 0.0, "avg_logprob": -0.14520596955951892, "compression_ratio": 1.6311111111111112, "no_speech_prob": 1.5534917565673823e-06}, {"id": 271, "seek": 170064, "start": 1719.48, "end": 1729.3200000000002, "text": " is you'll notice that ResNet and Inception are not used very often for transfer learning.", "tokens": [307, 291, 603, 3449, 300, 5015, 31890, 293, 682, 7311, 366, 406, 1143, 588, 2049, 337, 5003, 2539, 13], "temperature": 0.0, "avg_logprob": -0.14520596955951892, "compression_ratio": 1.6311111111111112, "no_speech_prob": 1.5534917565673823e-06}, {"id": 272, "seek": 172932, "start": 1729.32, "end": 1733.6, "text": " And again, this is something which I've not seen studied and I actually think this is", "tokens": [400, 797, 11, 341, 307, 746, 597, 286, 600, 406, 1612, 9454, 293, 286, 767, 519, 341, 307], "temperature": 0.0, "avg_logprob": -0.14009724188288417, "compression_ratio": 1.703422053231939, "no_speech_prob": 6.786715971429658e-07}, {"id": 273, "seek": 172932, "start": 1733.6, "end": 1738.9199999999998, "text": " a really important thing to study, which of these things work best for transfer learning.", "tokens": [257, 534, 1021, 551, 281, 2979, 11, 597, 295, 613, 721, 589, 1151, 337, 5003, 2539, 13], "temperature": 0.0, "avg_logprob": -0.14009724188288417, "compression_ratio": 1.703422053231939, "no_speech_prob": 6.786715971429658e-07}, {"id": 274, "seek": 172932, "start": 1738.9199999999998, "end": 1744.04, "text": " But I think one of the difficulties is just ResNet and Inception are harder. And the reason", "tokens": [583, 286, 519, 472, 295, 264, 14399, 307, 445, 5015, 31890, 293, 682, 7311, 366, 6081, 13, 400, 264, 1778], "temperature": 0.0, "avg_logprob": -0.14009724188288417, "compression_ratio": 1.703422053231939, "no_speech_prob": 6.786715971429658e-07}, {"id": 275, "seek": 172932, "start": 1744.04, "end": 1750.6, "text": " they're harder is that if you look at ResNet, you've got lots and lots of layers which make", "tokens": [436, 434, 6081, 307, 300, 498, 291, 574, 412, 5015, 31890, 11, 291, 600, 658, 3195, 293, 3195, 295, 7914, 597, 652], "temperature": 0.0, "avg_logprob": -0.14009724188288417, "compression_ratio": 1.703422053231939, "no_speech_prob": 6.786715971429658e-07}, {"id": 276, "seek": 172932, "start": 1750.6, "end": 1754.6399999999999, "text": " no sense on their own, ditto for Inception, because they keep on splitting into two bits", "tokens": [572, 2020, 322, 641, 1065, 11, 274, 34924, 337, 682, 7311, 11, 570, 436, 1066, 322, 30348, 666, 732, 9239], "temperature": 0.0, "avg_logprob": -0.14009724188288417, "compression_ratio": 1.703422053231939, "no_speech_prob": 6.786715971429658e-07}, {"id": 277, "seek": 175464, "start": 1754.64, "end": 1765.3600000000001, "text": " and then merging again. So what I did was I looked at the Keras source code to find", "tokens": [293, 550, 44559, 797, 13, 407, 437, 286, 630, 390, 286, 2956, 412, 264, 591, 6985, 4009, 3089, 281, 915], "temperature": 0.0, "avg_logprob": -0.15156587394508156, "compression_ratio": 1.4829545454545454, "no_speech_prob": 1.5534945987383253e-06}, {"id": 278, "seek": 175464, "start": 1765.3600000000001, "end": 1774.0400000000002, "text": " out how is each block named. Because what I wanted to do was to say, we've got a ResNet", "tokens": [484, 577, 307, 1184, 3461, 4926, 13, 1436, 437, 286, 1415, 281, 360, 390, 281, 584, 11, 321, 600, 658, 257, 5015, 31890], "temperature": 0.0, "avg_logprob": -0.15156587394508156, "compression_ratio": 1.4829545454545454, "no_speech_prob": 1.5534945987383253e-06}, {"id": 279, "seek": 175464, "start": 1774.0400000000002, "end": 1781.4, "text": " block, we've just had a merge, and then it goes out and it does a couple of convolutions,", "tokens": [3461, 11, 321, 600, 445, 632, 257, 22183, 11, 293, 550, 309, 1709, 484, 293, 309, 775, 257, 1916, 295, 3754, 15892, 11], "temperature": 0.0, "avg_logprob": -0.15156587394508156, "compression_ratio": 1.4829545454545454, "no_speech_prob": 1.5534945987383253e-06}, {"id": 280, "seek": 178140, "start": 1781.4, "end": 1790.2800000000002, "text": " and then it comes back and does an addition. And basically I want to get one of these.", "tokens": [293, 550, 309, 1487, 646, 293, 775, 364, 4500, 13, 400, 1936, 286, 528, 281, 483, 472, 295, 613, 13], "temperature": 0.0, "avg_logprob": -0.14285393648369368, "compression_ratio": 1.5625, "no_speech_prob": 6.643384949711617e-06}, {"id": 281, "seek": 178140, "start": 1790.2800000000002, "end": 1797.76, "text": " Unfortunately for some reason Keras does not name these merge cells. So what I had to do", "tokens": [8590, 337, 512, 1778, 591, 6985, 775, 406, 1315, 613, 22183, 5438, 13, 407, 437, 286, 632, 281, 360], "temperature": 0.0, "avg_logprob": -0.14285393648369368, "compression_ratio": 1.5625, "no_speech_prob": 6.643384949711617e-06}, {"id": 282, "seek": 178140, "start": 1797.76, "end": 1805.96, "text": " was get the next cell and then go back by one. So it kind of shows you how little people", "tokens": [390, 483, 264, 958, 2815, 293, 550, 352, 646, 538, 472, 13, 407, 309, 733, 295, 3110, 291, 577, 707, 561], "temperature": 0.0, "avg_logprob": -0.14285393648369368, "compression_ratio": 1.5625, "no_speech_prob": 6.643384949711617e-06}, {"id": 283, "seek": 178140, "start": 1805.96, "end": 1810.16, "text": " have been working with ResNet with transfer learning, is that literally the only bits", "tokens": [362, 668, 1364, 365, 5015, 31890, 365, 5003, 2539, 11, 307, 300, 3736, 264, 787, 9239], "temperature": 0.0, "avg_logprob": -0.14285393648369368, "compression_ratio": 1.5625, "no_speech_prob": 6.643384949711617e-06}, {"id": 284, "seek": 181016, "start": 1810.16, "end": 1817.3600000000001, "text": " of it that make sense to transfer learning from are nameless in one of the most popular,", "tokens": [295, 309, 300, 652, 2020, 281, 5003, 2539, 490, 366, 8835, 4272, 294, 472, 295, 264, 881, 3743, 11], "temperature": 0.0, "avg_logprob": -0.15679813566662015, "compression_ratio": 1.6, "no_speech_prob": 9.97288225335069e-06}, {"id": 285, "seek": 181016, "start": 1817.3600000000001, "end": 1823.8400000000001, "text": " probably the most popular thing for transfer learning I suspect, Keras.", "tokens": [1391, 264, 881, 3743, 551, 337, 5003, 2539, 286, 9091, 11, 591, 6985, 13], "temperature": 0.0, "avg_logprob": -0.15679813566662015, "compression_ratio": 1.6, "no_speech_prob": 9.97288225335069e-06}, {"id": 286, "seek": 181016, "start": 1823.8400000000001, "end": 1830.0, "text": " There's a second complexity when working with ResNet. We haven't discussed this much, but", "tokens": [821, 311, 257, 1150, 14024, 562, 1364, 365, 5015, 31890, 13, 492, 2378, 380, 7152, 341, 709, 11, 457], "temperature": 0.0, "avg_logprob": -0.15679813566662015, "compression_ratio": 1.6, "no_speech_prob": 9.97288225335069e-06}, {"id": 287, "seek": 181016, "start": 1830.0, "end": 1839.72, "text": " ResNet actually has two kinds of ResNet blocks. One is this kind, which is an identity block,", "tokens": [5015, 31890, 767, 575, 732, 3685, 295, 5015, 31890, 8474, 13, 1485, 307, 341, 733, 11, 597, 307, 364, 6575, 3461, 11], "temperature": 0.0, "avg_logprob": -0.15679813566662015, "compression_ratio": 1.6, "no_speech_prob": 9.97288225335069e-06}, {"id": 288, "seek": 183972, "start": 1839.72, "end": 1851.68, "text": " and the second time is a ResNet convolution block, which they also call a bottleneck block.", "tokens": [293, 264, 1150, 565, 307, 257, 5015, 31890, 45216, 3461, 11, 597, 436, 611, 818, 257, 44641, 547, 3461, 13], "temperature": 0.0, "avg_logprob": -0.16089281395300112, "compression_ratio": 1.5085714285714287, "no_speech_prob": 1.1659441042866092e-05}, {"id": 289, "seek": 183972, "start": 1851.68, "end": 1857.04, "text": " And what this is, is it's pretty similar. You've got one thing that's going up through", "tokens": [400, 437, 341, 307, 11, 307, 309, 311, 1238, 2531, 13, 509, 600, 658, 472, 551, 300, 311, 516, 493, 807], "temperature": 0.0, "avg_logprob": -0.16089281395300112, "compression_ratio": 1.5085714285714287, "no_speech_prob": 1.1659441042866092e-05}, {"id": 290, "seek": 183972, "start": 1857.04, "end": 1860.76, "text": " a couple of convolutions and then goes and gets added together, but the other side is", "tokens": [257, 1916, 295, 3754, 15892, 293, 550, 1709, 293, 2170, 3869, 1214, 11, 457, 264, 661, 1252, 307], "temperature": 0.0, "avg_logprob": -0.16089281395300112, "compression_ratio": 1.5085714285714287, "no_speech_prob": 1.1659441042866092e-05}, {"id": 291, "seek": 186076, "start": 1860.76, "end": 1870.4, "text": " not an identity. The other side is a single convolution. In ResNet they throw in one of", "tokens": [406, 364, 6575, 13, 440, 661, 1252, 307, 257, 2167, 45216, 13, 682, 5015, 31890, 436, 3507, 294, 472, 295], "temperature": 0.0, "avg_logprob": -0.11164800671563632, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.561273504397832e-06}, {"id": 292, "seek": 186076, "start": 1870.4, "end": 1878.68, "text": " these every half a dozen blocks or so. Why is that? The reason is that if you only have", "tokens": [613, 633, 1922, 257, 16654, 8474, 420, 370, 13, 1545, 307, 300, 30, 440, 1778, 307, 300, 498, 291, 787, 362], "temperature": 0.0, "avg_logprob": -0.11164800671563632, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.561273504397832e-06}, {"id": 293, "seek": 186076, "start": 1878.68, "end": 1886.4, "text": " identity blocks, then all it can really do is to continually fine-tune where it's at", "tokens": [6575, 8474, 11, 550, 439, 309, 393, 534, 360, 307, 281, 22277, 2489, 12, 83, 2613, 689, 309, 311, 412], "temperature": 0.0, "avg_logprob": -0.11164800671563632, "compression_ratio": 1.4857142857142858, "no_speech_prob": 2.561273504397832e-06}, {"id": 294, "seek": 188640, "start": 1886.4, "end": 1892.8000000000002, "text": " so far. We've learned quite a few times now that these identity blocks basically map to", "tokens": [370, 1400, 13, 492, 600, 3264, 1596, 257, 1326, 1413, 586, 300, 613, 6575, 8474, 1936, 4471, 281], "temperature": 0.0, "avg_logprob": -0.14636106376188346, "compression_ratio": 1.665137614678899, "no_speech_prob": 5.682410574081587e-06}, {"id": 295, "seek": 188640, "start": 1892.8000000000002, "end": 1899.4, "text": " the residual, but they keep trying to fine-tune the types of features that we have so far.", "tokens": [264, 27980, 11, 457, 436, 1066, 1382, 281, 2489, 12, 83, 2613, 264, 3467, 295, 4122, 300, 321, 362, 370, 1400, 13], "temperature": 0.0, "avg_logprob": -0.14636106376188346, "compression_ratio": 1.665137614678899, "no_speech_prob": 5.682410574081587e-06}, {"id": 296, "seek": 188640, "start": 1899.4, "end": 1905.2800000000002, "text": " Whereas these bottleneck blocks actually force it from time to time to create a whole different", "tokens": [13813, 613, 44641, 547, 8474, 767, 3464, 309, 490, 565, 281, 565, 281, 1884, 257, 1379, 819], "temperature": 0.0, "avg_logprob": -0.14636106376188346, "compression_ratio": 1.665137614678899, "no_speech_prob": 5.682410574081587e-06}, {"id": 297, "seek": 188640, "start": 1905.2800000000002, "end": 1911.2800000000002, "text": " type of features because there is no identity path through here. The shortest path still", "tokens": [2010, 295, 4122, 570, 456, 307, 572, 6575, 3100, 807, 510, 13, 440, 31875, 3100, 920], "temperature": 0.0, "avg_logprob": -0.14636106376188346, "compression_ratio": 1.665137614678899, "no_speech_prob": 5.682410574081587e-06}, {"id": 298, "seek": 191128, "start": 1911.28, "end": 1917.36, "text": " goes through a single convolution. So when you think about transfer learning from ResNet,", "tokens": [1709, 807, 257, 2167, 45216, 13, 407, 562, 291, 519, 466, 5003, 2539, 490, 5015, 31890, 11], "temperature": 0.0, "avg_logprob": -0.14847768651376855, "compression_ratio": 1.6680161943319838, "no_speech_prob": 2.225271146016894e-06}, {"id": 299, "seek": 191128, "start": 1917.36, "end": 1922.92, "text": " you kind of need to think about, should I transfer learn from an identity block before", "tokens": [291, 733, 295, 643, 281, 519, 466, 11, 820, 286, 5003, 1466, 490, 364, 6575, 3461, 949], "temperature": 0.0, "avg_logprob": -0.14847768651376855, "compression_ratio": 1.6680161943319838, "no_speech_prob": 2.225271146016894e-06}, {"id": 300, "seek": 191128, "start": 1922.92, "end": 1929.92, "text": " or after, or from a bottleneck block before or after. Again, I don't think anybody's studied", "tokens": [420, 934, 11, 420, 490, 257, 44641, 547, 3461, 949, 420, 934, 13, 3764, 11, 286, 500, 380, 519, 4472, 311, 9454], "temperature": 0.0, "avg_logprob": -0.14847768651376855, "compression_ratio": 1.6680161943319838, "no_speech_prob": 2.225271146016894e-06}, {"id": 301, "seek": 191128, "start": 1929.92, "end": 1933.6399999999999, "text": " this, or at least I haven't seen anybody write it down.", "tokens": [341, 11, 420, 412, 1935, 286, 2378, 380, 1612, 4472, 2464, 309, 760, 13], "temperature": 0.0, "avg_logprob": -0.14847768651376855, "compression_ratio": 1.6680161943319838, "no_speech_prob": 2.225271146016894e-06}, {"id": 302, "seek": 191128, "start": 1933.6399999999999, "end": 1939.2, "text": " I've played around with it a bit and I'm not sure I have a totally decisive suggestion", "tokens": [286, 600, 3737, 926, 365, 309, 257, 857, 293, 286, 478, 406, 988, 286, 362, 257, 3879, 34998, 16541], "temperature": 0.0, "avg_logprob": -0.14847768651376855, "compression_ratio": 1.6680161943319838, "no_speech_prob": 2.225271146016894e-06}, {"id": 303, "seek": 193920, "start": 1939.2, "end": 1952.68, "text": " for you. Clearly, my guess is that the best point to grab in ResNet is the end of the", "tokens": [337, 291, 13, 24120, 11, 452, 2041, 307, 300, 264, 1151, 935, 281, 4444, 294, 5015, 31890, 307, 264, 917, 295, 264], "temperature": 0.0, "avg_logprob": -0.13669347763061523, "compression_ratio": 1.603658536585366, "no_speech_prob": 6.854269486211706e-06}, {"id": 304, "seek": 193920, "start": 1952.68, "end": 1960.8400000000001, "text": " block immediately before a bottleneck block. And the reason for that is that at that level", "tokens": [3461, 4258, 949, 257, 44641, 547, 3461, 13, 400, 264, 1778, 337, 300, 307, 300, 412, 300, 1496], "temperature": 0.0, "avg_logprob": -0.13669347763061523, "compression_ratio": 1.603658536585366, "no_speech_prob": 6.854269486211706e-06}, {"id": 305, "seek": 193920, "start": 1960.8400000000001, "end": 1967.2, "text": " of receptive field, because each bottleneck block is changing the receptive field, and", "tokens": [295, 45838, 2519, 11, 570, 1184, 44641, 547, 3461, 307, 4473, 264, 45838, 2519, 11, 293], "temperature": 0.0, "avg_logprob": -0.13669347763061523, "compression_ratio": 1.603658536585366, "no_speech_prob": 6.854269486211706e-06}, {"id": 306, "seek": 196720, "start": 1967.2, "end": 1973.3600000000001, "text": " at that level of semantic complexity, this is the most sophisticated version of it because", "tokens": [412, 300, 1496, 295, 47982, 14024, 11, 341, 307, 264, 881, 16950, 3037, 295, 309, 570], "temperature": 0.0, "avg_logprob": -0.16585282926206235, "compression_ratio": 1.5906735751295338, "no_speech_prob": 3.7266247545630904e-06}, {"id": 307, "seek": 196720, "start": 1973.3600000000001, "end": 1978.2, "text": " it's been through a whole bunch of identity blocks to get there. Fine-tune, fine-tune,", "tokens": [309, 311, 668, 807, 257, 1379, 3840, 295, 6575, 8474, 281, 483, 456, 13, 12024, 12, 83, 2613, 11, 2489, 12, 83, 2613, 11], "temperature": 0.0, "avg_logprob": -0.16585282926206235, "compression_ratio": 1.5906735751295338, "no_speech_prob": 3.7266247545630904e-06}, {"id": 308, "seek": 196720, "start": 1978.2, "end": 1986.88, "text": " fine-tune, bottleneck. So my belief is that you want to get just before that bottleneck", "tokens": [2489, 12, 83, 2613, 11, 44641, 547, 13, 407, 452, 7107, 307, 300, 291, 528, 281, 483, 445, 949, 300, 44641, 547], "temperature": 0.0, "avg_logprob": -0.16585282926206235, "compression_ratio": 1.5906735751295338, "no_speech_prob": 3.7266247545630904e-06}, {"id": 309, "seek": 196720, "start": 1986.88, "end": 1991.0, "text": " is the best place to transfer learn from.", "tokens": [307, 264, 1151, 1081, 281, 5003, 1466, 490, 13], "temperature": 0.0, "avg_logprob": -0.16585282926206235, "compression_ratio": 1.5906735751295338, "no_speech_prob": 3.7266247545630904e-06}, {"id": 310, "seek": 199100, "start": 1991.0, "end": 2001.64, "text": " So that's what this is. This is the spot just before the last bottleneck layer in ResNet.", "tokens": [407, 300, 311, 437, 341, 307, 13, 639, 307, 264, 4008, 445, 949, 264, 1036, 44641, 547, 4583, 294, 5015, 31890, 13], "temperature": 0.0, "avg_logprob": -0.14249884427248777, "compression_ratio": 1.6561085972850678, "no_speech_prob": 7.29631528884056e-06}, {"id": 311, "seek": 199100, "start": 2001.64, "end": 2009.12, "text": " So it's pretty late, and so as we know very well from part 1 with transfer learning, when", "tokens": [407, 309, 311, 1238, 3469, 11, 293, 370, 382, 321, 458, 588, 731, 490, 644, 502, 365, 5003, 2539, 11, 562], "temperature": 0.0, "avg_logprob": -0.14249884427248777, "compression_ratio": 1.6561085972850678, "no_speech_prob": 7.29631528884056e-06}, {"id": 312, "seek": 199100, "start": 2009.12, "end": 2013.24, "text": " you're doing something which is not too different, and in this case we're switching from one-part", "tokens": [291, 434, 884, 746, 597, 307, 406, 886, 819, 11, 293, 294, 341, 1389, 321, 434, 16493, 490, 472, 12, 6971], "temperature": 0.0, "avg_logprob": -0.14249884427248777, "compression_ratio": 1.6561085972850678, "no_speech_prob": 7.29631528884056e-06}, {"id": 313, "seek": 199100, "start": 2013.24, "end": 2018.44, "text": " encoding to word vectors which is not too different, you probably don't want to transfer", "tokens": [43430, 281, 1349, 18875, 597, 307, 406, 886, 819, 11, 291, 1391, 500, 380, 528, 281, 5003], "temperature": 0.0, "avg_logprob": -0.14249884427248777, "compression_ratio": 1.6561085972850678, "no_speech_prob": 7.29631528884056e-06}, {"id": 314, "seek": 201844, "start": 2018.44, "end": 2025.88, "text": " learn from too early. So that's why I picked this fairly late stage, which is just before", "tokens": [1466, 490, 886, 2440, 13, 407, 300, 311, 983, 286, 6183, 341, 6457, 3469, 3233, 11, 597, 307, 445, 949], "temperature": 0.0, "avg_logprob": -0.18567774935466488, "compression_ratio": 1.5654450261780104, "no_speech_prob": 4.4951666495762765e-06}, {"id": 315, "seek": 201844, "start": 2025.88, "end": 2030.92, "text": " the final bottleneck block.", "tokens": [264, 2572, 44641, 547, 3461, 13], "temperature": 0.0, "avg_logprob": -0.18567774935466488, "compression_ratio": 1.5654450261780104, "no_speech_prob": 4.4951666495762765e-06}, {"id": 316, "seek": 201844, "start": 2030.92, "end": 2037.92, "text": " So the second complexity here is that this bottleneck block has these dimensions. The", "tokens": [407, 264, 1150, 14024, 510, 307, 300, 341, 44641, 547, 3461, 575, 613, 12819, 13, 440], "temperature": 0.0, "avg_logprob": -0.18567774935466488, "compression_ratio": 1.5654450261780104, "no_speech_prob": 4.4951666495762765e-06}, {"id": 317, "seek": 201844, "start": 2037.92, "end": 2048.36, "text": " output is 14x14x1024. So we have about a million images. So a million by 14x14x1024, the output", "tokens": [5598, 307, 3499, 87, 7271, 87, 3279, 7911, 13, 407, 321, 362, 466, 257, 2459, 5267, 13, 407, 257, 2459, 538, 3499, 87, 7271, 87, 3279, 7911, 11, 264, 5598], "temperature": 0.0, "avg_logprob": -0.18567774935466488, "compression_ratio": 1.5654450261780104, "no_speech_prob": 4.4951666495762765e-06}, {"id": 318, "seek": 204836, "start": 2048.36, "end": 2056.7200000000003, "text": " is more than I wanted to deal with. So I did something very simple, which was I popped", "tokens": [307, 544, 813, 286, 1415, 281, 2028, 365, 13, 407, 286, 630, 746, 588, 2199, 11, 597, 390, 286, 21545], "temperature": 0.0, "avg_logprob": -0.09879324171278211, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.04888236921397e-06}, {"id": 319, "seek": 204836, "start": 2056.7200000000003, "end": 2066.0, "text": " in one more layer after this, which is an average pooling layer, 7x7. So that's going", "tokens": [294, 472, 544, 4583, 934, 341, 11, 597, 307, 364, 4274, 7005, 278, 4583, 11, 1614, 87, 22, 13, 407, 300, 311, 516], "temperature": 0.0, "avg_logprob": -0.09879324171278211, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.04888236921397e-06}, {"id": 320, "seek": 204836, "start": 2066.0, "end": 2071.6, "text": " to take my 14x14 output and turn it into a 2x2 output.", "tokens": [281, 747, 452, 3499, 87, 7271, 5598, 293, 1261, 309, 666, 257, 568, 87, 17, 5598, 13], "temperature": 0.0, "avg_logprob": -0.09879324171278211, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.04888236921397e-06}, {"id": 321, "seek": 204836, "start": 2071.6, "end": 2077.96, "text": " So let's say one of those activations was looking for bird's eyeballs, then it's saying", "tokens": [407, 718, 311, 584, 472, 295, 729, 2430, 763, 390, 1237, 337, 5255, 311, 43758, 11, 550, 309, 311, 1566], "temperature": 0.0, "avg_logprob": -0.09879324171278211, "compression_ratio": 1.5217391304347827, "no_speech_prob": 6.04888236921397e-06}, {"id": 322, "seek": 207796, "start": 2077.96, "end": 2084.04, "text": " in each of the 14x14 spots how likely is it that this is a bird's eyeball. And so after", "tokens": [294, 1184, 295, 264, 3499, 87, 7271, 10681, 577, 3700, 307, 309, 300, 341, 307, 257, 5255, 311, 38868, 13, 400, 370, 934], "temperature": 0.0, "avg_logprob": -0.19632604598999023, "compression_ratio": 1.6016597510373445, "no_speech_prob": 1.644241638132371e-05}, {"id": 323, "seek": 207796, "start": 2084.04, "end": 2090.76, "text": " this it's now saying in each of these four spots on average how much were those cells", "tokens": [341, 309, 311, 586, 1566, 294, 1184, 295, 613, 1451, 10681, 322, 4274, 577, 709, 645, 729, 5438], "temperature": 0.0, "avg_logprob": -0.19632604598999023, "compression_ratio": 1.6016597510373445, "no_speech_prob": 1.644241638132371e-05}, {"id": 324, "seek": 207796, "start": 2090.76, "end": 2093.48, "text": " looking like bird's eyeballs.", "tokens": [1237, 411, 5255, 311, 43758, 13], "temperature": 0.0, "avg_logprob": -0.19632604598999023, "compression_ratio": 1.6016597510373445, "no_speech_prob": 1.644241638132371e-05}, {"id": 325, "seek": 207796, "start": 2093.48, "end": 2103.2400000000002, "text": " So this is losing information. If I had a bigger SSD and more time, I wouldn't have", "tokens": [407, 341, 307, 7027, 1589, 13, 759, 286, 632, 257, 3801, 30262, 293, 544, 565, 11, 286, 2759, 380, 362], "temperature": 0.0, "avg_logprob": -0.19632604598999023, "compression_ratio": 1.6016597510373445, "no_speech_prob": 1.644241638132371e-05}, {"id": 326, "seek": 207796, "start": 2103.2400000000002, "end": 2107.88, "text": " done this. But it's a good trick when you're working with these fully convolutional architectures.", "tokens": [1096, 341, 13, 583, 309, 311, 257, 665, 4282, 562, 291, 434, 1364, 365, 613, 4498, 45216, 304, 6331, 1303, 13], "temperature": 0.0, "avg_logprob": -0.19632604598999023, "compression_ratio": 1.6016597510373445, "no_speech_prob": 1.644241638132371e-05}, {"id": 327, "seek": 210788, "start": 2107.88, "end": 2114.8, "text": " You can pop an average pooling layer anywhere and decrease the resolution to something that", "tokens": [509, 393, 1665, 364, 4274, 7005, 278, 4583, 4992, 293, 11514, 264, 8669, 281, 746, 300], "temperature": 0.0, "avg_logprob": -0.3054131062825521, "compression_ratio": 1.465, "no_speech_prob": 7.368402293650433e-05}, {"id": 328, "seek": 210788, "start": 2114.8, "end": 2121.4, "text": " you feel like you can deal with. So in this case, my decision was to go to 2x2x1024.", "tokens": [291, 841, 411, 291, 393, 2028, 365, 13, 407, 294, 341, 1389, 11, 452, 3537, 390, 281, 352, 281, 568, 87, 17, 87, 3279, 7911, 13], "temperature": 0.0, "avg_logprob": -0.3054131062825521, "compression_ratio": 1.465, "no_speech_prob": 7.368402293650433e-05}, {"id": 329, "seek": 210788, "start": 2121.4, "end": 2129.4, "text": " Question from the audience. Have we talked about why we do the merge operation in some", "tokens": [14464, 490, 264, 4034, 13, 3560, 321, 2825, 466, 983, 321, 360, 264, 22183, 6916, 294, 512], "temperature": 0.0, "avg_logprob": -0.3054131062825521, "compression_ratio": 1.465, "no_speech_prob": 7.368402293650433e-05}, {"id": 330, "seek": 210788, "start": 2129.4, "end": 2132.0, "text": " of these more complex models?", "tokens": [295, 613, 544, 3997, 5245, 30], "temperature": 0.0, "avg_logprob": -0.3054131062825521, "compression_ratio": 1.465, "no_speech_prob": 7.368402293650433e-05}, {"id": 331, "seek": 213200, "start": 2132.0, "end": 2138.36, "text": " We have quite a few times, which is basically the merge was the thing which does the plus.", "tokens": [492, 362, 1596, 257, 1326, 1413, 11, 597, 307, 1936, 264, 22183, 390, 264, 551, 597, 775, 264, 1804, 13], "temperature": 0.0, "avg_logprob": -0.2872878074645996, "compression_ratio": 1.5263157894736843, "no_speech_prob": 5.059905015514232e-05}, {"id": 332, "seek": 213200, "start": 2138.36, "end": 2146.48, "text": " That's the trick to making it into a ResNet block, is having the addition of the identity", "tokens": [663, 311, 264, 4282, 281, 1455, 309, 666, 257, 5015, 31890, 3461, 11, 307, 1419, 264, 4500, 295, 264, 6575], "temperature": 0.0, "avg_logprob": -0.2872878074645996, "compression_ratio": 1.5263157894736843, "no_speech_prob": 5.059905015514232e-05}, {"id": 333, "seek": 213200, "start": 2146.48, "end": 2155.56, "text": " with the result of a couple of convolutions.", "tokens": [365, 264, 1874, 295, 257, 1916, 295, 3754, 15892, 13], "temperature": 0.0, "avg_logprob": -0.2872878074645996, "compression_ratio": 1.5263157894736843, "no_speech_prob": 5.059905015514232e-05}, {"id": 334, "seek": 213200, "start": 2155.56, "end": 2161.72, "text": " So recently I was trying to go from many filters. So you kind of just talked about downsizing", "tokens": [407, 3938, 286, 390, 1382, 281, 352, 490, 867, 15995, 13, 407, 291, 733, 295, 445, 2825, 466, 21554, 3319], "temperature": 0.0, "avg_logprob": -0.2872878074645996, "compression_ratio": 1.5263157894736843, "no_speech_prob": 5.059905015514232e-05}, {"id": 335, "seek": 216172, "start": 2161.72, "end": 2168.2799999999997, "text": " the size of the geometry. Is there a good best practice on going from 512 filters down", "tokens": [264, 2744, 295, 264, 18426, 13, 1119, 456, 257, 665, 1151, 3124, 322, 516, 490, 1025, 4762, 15995, 760], "temperature": 0.0, "avg_logprob": -0.253741082691011, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.609013922163285e-05}, {"id": 336, "seek": 216172, "start": 2168.2799999999997, "end": 2179.16, "text": " to less? Or is it just as simple as doing a convolution with less filters?", "tokens": [281, 1570, 30, 1610, 307, 309, 445, 382, 2199, 382, 884, 257, 45216, 365, 1570, 15995, 30], "temperature": 0.0, "avg_logprob": -0.253741082691011, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.609013922163285e-05}, {"id": 337, "seek": 216172, "start": 2179.16, "end": 2189.08, "text": " There's not exactly a best practice for that. But in a sense, every single successful architecture", "tokens": [821, 311, 406, 2293, 257, 1151, 3124, 337, 300, 13, 583, 294, 257, 2020, 11, 633, 2167, 4406, 9482], "temperature": 0.0, "avg_logprob": -0.253741082691011, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.609013922163285e-05}, {"id": 338, "seek": 218908, "start": 2189.08, "end": 2192.56, "text": " gets you some insights about that. Because every one of them eventually has to end up", "tokens": [2170, 291, 512, 14310, 466, 300, 13, 1436, 633, 472, 295, 552, 4728, 575, 281, 917, 493], "temperature": 0.0, "avg_logprob": -0.2521603844382546, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0002774573222268373}, {"id": 339, "seek": 218908, "start": 2192.56, "end": 2201.68, "text": " with a thousand categories if it's ImageNet or three channels of not 255 continuous if", "tokens": [365, 257, 4714, 10479, 498, 309, 311, 29903, 31890, 420, 1045, 9235, 295, 406, 3552, 20, 10957, 498], "temperature": 0.0, "avg_logprob": -0.2521603844382546, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0002774573222268373}, {"id": 340, "seek": 218908, "start": 2201.68, "end": 2206.56, "text": " it's generative. So the best thing you can really do is, well, there's two things. One", "tokens": [309, 311, 1337, 1166, 13, 407, 264, 1151, 551, 291, 393, 534, 360, 307, 11, 731, 11, 456, 311, 732, 721, 13, 1485], "temperature": 0.0, "avg_logprob": -0.2521603844382546, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0002774573222268373}, {"id": 341, "seek": 218908, "start": 2206.56, "end": 2212.12, "text": " is to kind of look at the successful architectures. Another thing is, although this week is kind", "tokens": [307, 281, 733, 295, 574, 412, 264, 4406, 6331, 1303, 13, 3996, 551, 307, 11, 4878, 341, 1243, 307, 733], "temperature": 0.0, "avg_logprob": -0.2521603844382546, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0002774573222268373}, {"id": 342, "seek": 218908, "start": 2212.12, "end": 2216.52, "text": " of the last week we're mainly going to be looking at images, I am going to briefly next", "tokens": [295, 264, 1036, 1243, 321, 434, 8704, 516, 281, 312, 1237, 412, 5267, 11, 286, 669, 516, 281, 10515, 958], "temperature": 0.0, "avg_logprob": -0.2521603844382546, "compression_ratio": 1.6263736263736264, "no_speech_prob": 0.0002774573222268373}, {"id": 343, "seek": 221652, "start": 2216.52, "end": 2221.28, "text": " week open with a quick run through some of the things that you could look at to learn", "tokens": [1243, 1269, 365, 257, 1702, 1190, 807, 512, 295, 264, 721, 300, 291, 727, 574, 412, 281, 1466], "temperature": 0.0, "avg_logprob": -0.2856913148687127, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.00025172336609102786}, {"id": 344, "seek": 221652, "start": 2221.28, "end": 2226.04, "text": " more. And one of them is going to be a paper. We've got two different papers which have", "tokens": [544, 13, 400, 472, 295, 552, 307, 516, 281, 312, 257, 3035, 13, 492, 600, 658, 732, 819, 10577, 597, 362], "temperature": 0.0, "avg_logprob": -0.2856913148687127, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.00025172336609102786}, {"id": 345, "seek": 221652, "start": 2226.04, "end": 2230.72, "text": " like best practices, you know, really nice kind of descriptions of we did these hundred", "tokens": [411, 1151, 7525, 11, 291, 458, 11, 534, 1481, 733, 295, 24406, 295, 321, 630, 613, 3262], "temperature": 0.0, "avg_logprob": -0.2856913148687127, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.00025172336609102786}, {"id": 346, "seek": 221652, "start": 2230.72, "end": 2235.8, "text": " different things and here's the hundred different results. But all this stuff is still pretty", "tokens": [819, 721, 293, 510, 311, 264, 3262, 819, 3542, 13, 583, 439, 341, 1507, 307, 920, 1238], "temperature": 0.0, "avg_logprob": -0.2856913148687127, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.00025172336609102786}, {"id": 347, "seek": 221652, "start": 2235.8, "end": 2236.8, "text": " artisanal.", "tokens": [1523, 14804, 304, 13], "temperature": 0.0, "avg_logprob": -0.2856913148687127, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.00025172336609102786}, {"id": 348, "seek": 223680, "start": 2236.8, "end": 2253.0, "text": " Good question. So initially you said the image is 224, right? It ended up being as a big", "tokens": [2205, 1168, 13, 407, 9105, 291, 848, 264, 3256, 307, 5853, 19, 11, 558, 30, 467, 4590, 493, 885, 382, 257, 955], "temperature": 0.0, "avg_logprob": -0.6074974327756647, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.0005005807615816593}, {"id": 349, "seek": 223680, "start": 2253.0, "end": 2260.6800000000003, "text": " calls in a way, right? So a couple, it's like 50 gig data or something. Can we look at the", "tokens": [5498, 294, 257, 636, 11, 558, 30, 407, 257, 1916, 11, 309, 311, 411, 2625, 8741, 1412, 420, 746, 13, 1664, 321, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.6074974327756647, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.0005005807615816593}, {"id": 350, "seek": 223680, "start": 2260.6800000000003, "end": 2261.6800000000003, "text": " images?", "tokens": [5267, 30], "temperature": 0.0, "avg_logprob": -0.6074974327756647, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.0005005807615816593}, {"id": 351, "seek": 226168, "start": 2261.68, "end": 2279.56, "text": " Yes, and that's compressed and uncompressed, it's like a couple of hundred gig.", "tokens": [1079, 11, 293, 300, 311, 30353, 293, 8585, 79, 3805, 11, 309, 311, 411, 257, 1916, 295, 3262, 8741, 13], "temperature": 0.0, "avg_logprob": -0.20188646731169327, "compression_ratio": 1.494186046511628, "no_speech_prob": 2.2124730094219558e-05}, {"id": 352, "seek": 226168, "start": 2279.56, "end": 2284.08, "text": " So that's exactly the right segue I was looking for, so thank you. So what we're going to", "tokens": [407, 300, 311, 2293, 264, 558, 33850, 286, 390, 1237, 337, 11, 370, 1309, 291, 13, 407, 437, 321, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.20188646731169327, "compression_ratio": 1.494186046511628, "no_speech_prob": 2.2124730094219558e-05}, {"id": 353, "seek": 226168, "start": 2284.08, "end": 2290.4199999999996, "text": " do now is we want to run this model we just built, just called basically dot predict on", "tokens": [360, 586, 307, 321, 528, 281, 1190, 341, 2316, 321, 445, 3094, 11, 445, 1219, 1936, 5893, 6069, 322], "temperature": 0.0, "avg_logprob": -0.20188646731169327, "compression_ratio": 1.494186046511628, "no_speech_prob": 2.2124730094219558e-05}, {"id": 354, "seek": 229042, "start": 2290.42, "end": 2296.2400000000002, "text": " it and save the predictions. The problem is that the size of those predictions is going", "tokens": [309, 293, 3155, 264, 21264, 13, 440, 1154, 307, 300, 264, 2744, 295, 729, 21264, 307, 516], "temperature": 0.0, "avg_logprob": -0.11205278975622994, "compression_ratio": 1.8577405857740585, "no_speech_prob": 2.3922844775370322e-05}, {"id": 355, "seek": 229042, "start": 2296.2400000000002, "end": 2301.8, "text": " to be bigger than the amount of RAM I have, so I need to do it a batch at a time and save", "tokens": [281, 312, 3801, 813, 264, 2372, 295, 14561, 286, 362, 11, 370, 286, 643, 281, 360, 309, 257, 15245, 412, 257, 565, 293, 3155], "temperature": 0.0, "avg_logprob": -0.11205278975622994, "compression_ratio": 1.8577405857740585, "no_speech_prob": 2.3922844775370322e-05}, {"id": 356, "seek": 229042, "start": 2301.8, "end": 2309.28, "text": " it a batch at a time. They've got a million things, each one with this many activations.", "tokens": [309, 257, 15245, 412, 257, 565, 13, 814, 600, 658, 257, 2459, 721, 11, 1184, 472, 365, 341, 867, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.11205278975622994, "compression_ratio": 1.8577405857740585, "no_speech_prob": 2.3922844775370322e-05}, {"id": 357, "seek": 229042, "start": 2309.28, "end": 2312.88, "text": " And this is going to happen quite often, right? You're either working on a smaller computer", "tokens": [400, 341, 307, 516, 281, 1051, 1596, 2049, 11, 558, 30, 509, 434, 2139, 1364, 322, 257, 4356, 3820], "temperature": 0.0, "avg_logprob": -0.11205278975622994, "compression_ratio": 1.8577405857740585, "no_speech_prob": 2.3922844775370322e-05}, {"id": 358, "seek": 229042, "start": 2312.88, "end": 2316.54, "text": " or you're working with a bigger dataset or you're working with a dataset where you're", "tokens": [420, 291, 434, 1364, 365, 257, 3801, 28872, 420, 291, 434, 1364, 365, 257, 28872, 689, 291, 434], "temperature": 0.0, "avg_logprob": -0.11205278975622994, "compression_ratio": 1.8577405857740585, "no_speech_prob": 2.3922844775370322e-05}, {"id": 359, "seek": 231654, "start": 2316.54, "end": 2323.38, "text": " using a larger number of activations. This is actually very easy to handle. You just", "tokens": [1228, 257, 4833, 1230, 295, 2430, 763, 13, 639, 307, 767, 588, 1858, 281, 4813, 13, 509, 445], "temperature": 0.0, "avg_logprob": -0.14119618375536422, "compression_ratio": 1.4806629834254144, "no_speech_prob": 5.093675099487882e-06}, {"id": 360, "seek": 231654, "start": 2323.38, "end": 2332.36, "text": " create your big calls array where you're going to store it. And then all I do is I go through", "tokens": [1884, 428, 955, 5498, 10225, 689, 291, 434, 516, 281, 3531, 309, 13, 400, 550, 439, 286, 360, 307, 286, 352, 807], "temperature": 0.0, "avg_logprob": -0.14119618375536422, "compression_ratio": 1.4806629834254144, "no_speech_prob": 5.093675099487882e-06}, {"id": 361, "seek": 231654, "start": 2332.36, "end": 2338.84, "text": " from 0 to the length of my array, my source array, a batch at a time. So this is creating", "tokens": [490, 1958, 281, 264, 4641, 295, 452, 10225, 11, 452, 4009, 10225, 11, 257, 15245, 412, 257, 565, 13, 407, 341, 307, 4084], "temperature": 0.0, "avg_logprob": -0.14119618375536422, "compression_ratio": 1.4806629834254144, "no_speech_prob": 5.093675099487882e-06}, {"id": 362, "seek": 233884, "start": 2338.84, "end": 2347.1800000000003, "text": " the numbers 0, 0 plus 128, 128 plus 128, so on and so forth. And then I take the slice", "tokens": [264, 3547, 1958, 11, 1958, 1804, 29810, 11, 29810, 1804, 29810, 11, 370, 322, 293, 370, 5220, 13, 400, 550, 286, 747, 264, 13153], "temperature": 0.0, "avg_logprob": -0.14288423278115012, "compression_ratio": 1.7248677248677249, "no_speech_prob": 5.771901669504587e-06}, {"id": 363, "seek": 233884, "start": 2347.1800000000003, "end": 2355.7200000000003, "text": " of my source array from originally 0 to 128, then from 128 to 256 and so forth. So this", "tokens": [295, 452, 4009, 10225, 490, 7993, 1958, 281, 29810, 11, 550, 490, 29810, 281, 38882, 293, 370, 5220, 13, 407, 341], "temperature": 0.0, "avg_logprob": -0.14288423278115012, "compression_ratio": 1.7248677248677249, "no_speech_prob": 5.771901669504587e-06}, {"id": 364, "seek": 233884, "start": 2355.7200000000003, "end": 2363.6800000000003, "text": " is now going to contain a slice of my source big calls array.", "tokens": [307, 586, 516, 281, 5304, 257, 13153, 295, 452, 4009, 955, 5498, 10225, 13], "temperature": 0.0, "avg_logprob": -0.14288423278115012, "compression_ratio": 1.7248677248677249, "no_speech_prob": 5.771901669504587e-06}, {"id": 365, "seek": 233884, "start": 2363.6800000000003, "end": 2367.6400000000003, "text": " And then, well actually this is going to create a generator which is going to have all of", "tokens": [400, 550, 11, 731, 767, 341, 307, 516, 281, 1884, 257, 19265, 597, 307, 516, 281, 362, 439, 295], "temperature": 0.0, "avg_logprob": -0.14288423278115012, "compression_ratio": 1.7248677248677249, "no_speech_prob": 5.771901669504587e-06}, {"id": 366, "seek": 236764, "start": 2367.64, "end": 2373.6, "text": " those slices. And of course being a generator it's going to be lazy. So I can then enumerate", "tokens": [729, 19793, 13, 400, 295, 1164, 885, 257, 19265, 309, 311, 516, 281, 312, 14847, 13, 407, 286, 393, 550, 465, 15583, 473], "temperature": 0.0, "avg_logprob": -0.12355388641357422, "compression_ratio": 1.5904255319148937, "no_speech_prob": 2.9944328616693383e-06}, {"id": 367, "seek": 236764, "start": 2373.6, "end": 2381.24, "text": " through each of those slices and I can append to my big calls array the result of predicting", "tokens": [807, 1184, 295, 729, 19793, 293, 286, 393, 34116, 281, 452, 955, 5498, 10225, 264, 1874, 295, 32884], "temperature": 0.0, "avg_logprob": -0.12355388641357422, "compression_ratio": 1.5904255319148937, "no_speech_prob": 2.9944328616693383e-06}, {"id": 368, "seek": 236764, "start": 2381.24, "end": 2385.2599999999998, "text": " just on that one batch.", "tokens": [445, 322, 300, 472, 15245, 13], "temperature": 0.0, "avg_logprob": -0.12355388641357422, "compression_ratio": 1.5904255319148937, "no_speech_prob": 2.9944328616693383e-06}, {"id": 369, "seek": 236764, "start": 2385.2599999999998, "end": 2395.3199999999997, "text": " So you've seen like predict and evaluate and fit and so forth and the generator versions.", "tokens": [407, 291, 600, 1612, 411, 6069, 293, 13059, 293, 3318, 293, 370, 5220, 293, 264, 19265, 9606, 13], "temperature": 0.0, "avg_logprob": -0.12355388641357422, "compression_ratio": 1.5904255319148937, "no_speech_prob": 2.9944328616693383e-06}, {"id": 370, "seek": 239532, "start": 2395.32, "end": 2401.32, "text": " Also in Keras there's generally an on-batch version. So there's a train on-batch and a", "tokens": [2743, 294, 591, 6985, 456, 311, 5101, 364, 322, 12, 65, 852, 3037, 13, 407, 456, 311, 257, 3847, 322, 12, 65, 852, 293, 257], "temperature": 0.0, "avg_logprob": -0.13750929398970171, "compression_ratio": 1.7668161434977578, "no_speech_prob": 2.4060902887867996e-06}, {"id": 371, "seek": 239532, "start": 2401.32, "end": 2407.2400000000002, "text": " predict on-batch. And what these do is they basically have no smarts to them at all. This", "tokens": [6069, 322, 12, 65, 852, 13, 400, 437, 613, 360, 307, 436, 1936, 362, 572, 4069, 82, 281, 552, 412, 439, 13, 639], "temperature": 0.0, "avg_logprob": -0.13750929398970171, "compression_ratio": 1.7668161434977578, "no_speech_prob": 2.4060902887867996e-06}, {"id": 372, "seek": 239532, "start": 2407.2400000000002, "end": 2411.28, "text": " is like the most basic thing. So this is just going to take whatever you give it and call", "tokens": [307, 411, 264, 881, 3875, 551, 13, 407, 341, 307, 445, 516, 281, 747, 2035, 291, 976, 309, 293, 818], "temperature": 0.0, "avg_logprob": -0.13750929398970171, "compression_ratio": 1.7668161434977578, "no_speech_prob": 2.4060902887867996e-06}, {"id": 373, "seek": 239532, "start": 2411.28, "end": 2416.2400000000002, "text": " predict on this thing. It won't shuffle it, it won't batch it, it's just going to throw", "tokens": [6069, 322, 341, 551, 13, 467, 1582, 380, 39426, 309, 11, 309, 1582, 380, 15245, 309, 11, 309, 311, 445, 516, 281, 3507], "temperature": 0.0, "avg_logprob": -0.13750929398970171, "compression_ratio": 1.7668161434977578, "no_speech_prob": 2.4060902887867996e-06}, {"id": 374, "seek": 239532, "start": 2416.2400000000002, "end": 2418.32, "text": " it directly into the computation graph.", "tokens": [309, 3838, 666, 264, 24903, 4295, 13], "temperature": 0.0, "avg_logprob": -0.13750929398970171, "compression_ratio": 1.7668161434977578, "no_speech_prob": 2.4060902887867996e-06}, {"id": 375, "seek": 241832, "start": 2418.32, "end": 2425.52, "text": " So this is going to take that model, it's going to call predict, adjust this batch of", "tokens": [407, 341, 307, 516, 281, 747, 300, 2316, 11, 309, 311, 516, 281, 818, 6069, 11, 4369, 341, 15245, 295], "temperature": 0.0, "avg_logprob": -0.2252834026630108, "compression_ratio": 1.7833333333333334, "no_speech_prob": 5.8627870203054044e-06}, {"id": 376, "seek": 241832, "start": 2425.52, "end": 2429.44, "text": " data. And then from time to time I print out how far I've got, just so that I know how", "tokens": [1412, 13, 400, 550, 490, 565, 281, 565, 286, 4482, 484, 577, 1400, 286, 600, 658, 11, 445, 370, 300, 286, 458, 577], "temperature": 0.0, "avg_logprob": -0.2252834026630108, "compression_ratio": 1.7833333333333334, "no_speech_prob": 5.8627870203054044e-06}, {"id": 377, "seek": 241832, "start": 2429.44, "end": 2435.92, "text": " I'm going. Also from time to time I call.flush, that's the thing in big calls that actually", "tokens": [286, 478, 516, 13, 2743, 490, 565, 281, 565, 286, 818, 2411, 3423, 1498, 11, 300, 311, 264, 551, 294, 955, 5498, 300, 767], "temperature": 0.0, "avg_logprob": -0.2252834026630108, "compression_ratio": 1.7833333333333334, "no_speech_prob": 5.8627870203054044e-06}, {"id": 378, "seek": 241832, "start": 2435.92, "end": 2440.04, "text": " writes it to disk. That's to make sure it's continuously written to disk.", "tokens": [13657, 309, 281, 12355, 13, 663, 311, 281, 652, 988, 309, 311, 15684, 3720, 281, 12355, 13], "temperature": 0.0, "avg_logprob": -0.2252834026630108, "compression_ratio": 1.7833333333333334, "no_speech_prob": 5.8627870203054044e-06}, {"id": 379, "seek": 241832, "start": 2440.04, "end": 2444.7200000000003, "text": " So this thing doesn't actually take very long to run. And one of the nice things I can do", "tokens": [407, 341, 551, 1177, 380, 767, 747, 588, 938, 281, 1190, 13, 400, 472, 295, 264, 1481, 721, 286, 393, 360], "temperature": 0.0, "avg_logprob": -0.2252834026630108, "compression_ratio": 1.7833333333333334, "no_speech_prob": 5.8627870203054044e-06}, {"id": 380, "seek": 244472, "start": 2444.72, "end": 2451.3599999999997, "text": " here is I can do some data augmentation as well. I've added a direction parameter and", "tokens": [510, 307, 286, 393, 360, 512, 1412, 14501, 19631, 382, 731, 13, 286, 600, 3869, 257, 3513, 13075, 293], "temperature": 0.0, "avg_logprob": -0.11882352828979492, "compression_ratio": 1.3902439024390243, "no_speech_prob": 4.6838500566082075e-05}, {"id": 381, "seek": 244472, "start": 2451.3599999999997, "end": 2455.7599999999998, "text": " what I'm going to do is I'm going to have a second copy of all of my images, which is", "tokens": [437, 286, 478, 516, 281, 360, 307, 286, 478, 516, 281, 362, 257, 1150, 5055, 295, 439, 295, 452, 5267, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.11882352828979492, "compression_ratio": 1.3902439024390243, "no_speech_prob": 4.6838500566082075e-05}, {"id": 382, "seek": 245576, "start": 2455.76, "end": 2479.1600000000003, "text": " to flip things horizontally. To flip things horizontally, you've got batch, byte, and", "tokens": [281, 7929, 721, 33796, 13, 1407, 7929, 721, 33796, 11, 291, 600, 658, 15245, 11, 40846, 11, 293], "temperature": 0.0, "avg_logprob": -0.30915245142850006, "compression_ratio": 1.2318840579710144, "no_speech_prob": 1.5689427527831867e-05}, {"id": 383, "seek": 247916, "start": 2479.16, "end": 2491.2, "text": " then this is columns. If we pass in a minus 1 here, then it's going to flip it horizontally.", "tokens": [550, 341, 307, 13766, 13, 759, 321, 1320, 294, 257, 3175, 502, 510, 11, 550, 309, 311, 516, 281, 7929, 309, 33796, 13], "temperature": 0.0, "avg_logprob": -0.15710837404492875, "compression_ratio": 1.4382022471910112, "no_speech_prob": 3.966953045164701e-06}, {"id": 384, "seek": 247916, "start": 2491.2, "end": 2496.3199999999997, "text": " That explains why some of my results haven't been quite as good as I hoped.", "tokens": [663, 13948, 983, 512, 295, 452, 3542, 2378, 380, 668, 1596, 382, 665, 382, 286, 19737, 13], "temperature": 0.0, "avg_logprob": -0.15710837404492875, "compression_ratio": 1.4382022471910112, "no_speech_prob": 3.966953045164701e-06}, {"id": 385, "seek": 247916, "start": 2496.3199999999997, "end": 2501.6, "text": " So when you run this, we're going to end up with a big, big calls array that's going to", "tokens": [407, 562, 291, 1190, 341, 11, 321, 434, 516, 281, 917, 493, 365, 257, 955, 11, 955, 5498, 10225, 300, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.15710837404492875, "compression_ratio": 1.4382022471910112, "no_speech_prob": 3.966953045164701e-06}, {"id": 386, "seek": 250160, "start": 2501.6, "end": 2511.24, "text": " contain two copies of every Resites ImageNet image, the activations at the layer before", "tokens": [5304, 732, 14341, 295, 633, 5015, 3324, 29903, 31890, 3256, 11, 264, 2430, 763, 412, 264, 4583, 949], "temperature": 0.0, "avg_logprob": -0.2641140250272529, "compression_ratio": 1.4206349206349207, "no_speech_prob": 2.6425746000313666e-06}, {"id": 387, "seek": 250160, "start": 2511.24, "end": 2519.4, "text": " this. So I call it once with direction forwards and one with direction backwards. So at the", "tokens": [341, 13, 407, 286, 818, 309, 1564, 365, 3513, 30126, 293, 472, 365, 3513, 12204, 13, 407, 412, 264], "temperature": 0.0, "avg_logprob": -0.2641140250272529, "compression_ratio": 1.4206349206349207, "no_speech_prob": 2.6425746000313666e-06}, {"id": 388, "seek": 251940, "start": 2519.4, "end": 2533.8, "text": " end of that I've now got nearly 2 million images or activations of 2x2x1024.", "tokens": [917, 295, 300, 286, 600, 586, 658, 6217, 568, 2459, 5267, 420, 2430, 763, 295, 568, 87, 17, 87, 3279, 7911, 13], "temperature": 0.0, "avg_logprob": -0.10420478185017903, "compression_ratio": 1.494047619047619, "no_speech_prob": 2.2959111447562464e-06}, {"id": 389, "seek": 251940, "start": 2533.8, "end": 2541.12, "text": " So that's pretty close to the end of ResNet. I've then just copied and pasted from the", "tokens": [407, 300, 311, 1238, 1998, 281, 264, 917, 295, 5015, 31890, 13, 286, 600, 550, 445, 25365, 293, 1791, 292, 490, 264], "temperature": 0.0, "avg_logprob": -0.10420478185017903, "compression_ratio": 1.494047619047619, "no_speech_prob": 2.2959111447562464e-06}, {"id": 390, "seek": 251940, "start": 2541.12, "end": 2548.7200000000003, "text": " Keras code the last few steps of ResNet. So this is the last few blocks. I added in one", "tokens": [591, 6985, 3089, 264, 1036, 1326, 4439, 295, 5015, 31890, 13, 407, 341, 307, 264, 1036, 1326, 8474, 13, 286, 3869, 294, 472], "temperature": 0.0, "avg_logprob": -0.10420478185017903, "compression_ratio": 1.494047619047619, "no_speech_prob": 2.2959111447562464e-06}, {"id": 391, "seek": 254872, "start": 2548.72, "end": 2553.12, "text": " extra identity block just because I had a feeling that might help things along a little", "tokens": [2857, 6575, 3461, 445, 570, 286, 632, 257, 2633, 300, 1062, 854, 721, 2051, 257, 707], "temperature": 0.0, "avg_logprob": -0.12800292213364403, "compression_ratio": 1.534351145038168, "no_speech_prob": 1.4738824575033505e-05}, {"id": 392, "seek": 254872, "start": 2553.12, "end": 2557.8399999999997, "text": " bit. Again, people have not really studied this yet, so I haven't had a chance to properly", "tokens": [857, 13, 3764, 11, 561, 362, 406, 534, 9454, 341, 1939, 11, 370, 286, 2378, 380, 632, 257, 2931, 281, 6108], "temperature": 0.0, "avg_logprob": -0.12800292213364403, "compression_ratio": 1.534351145038168, "no_speech_prob": 1.4738824575033505e-05}, {"id": 393, "seek": 254872, "start": 2557.8399999999997, "end": 2562.08, "text": " experiment, but it seemed to work quite well.", "tokens": [5120, 11, 457, 309, 6576, 281, 589, 1596, 731, 13], "temperature": 0.0, "avg_logprob": -0.12800292213364403, "compression_ratio": 1.534351145038168, "no_speech_prob": 1.4738824575033505e-05}, {"id": 394, "seek": 254872, "start": 2562.08, "end": 2568.6, "text": " This is basically copied and pasted from Keras' code. I then need to copy the weights from", "tokens": [639, 307, 1936, 25365, 293, 1791, 292, 490, 591, 6985, 6, 3089, 13, 286, 550, 643, 281, 5055, 264, 17443, 490], "temperature": 0.0, "avg_logprob": -0.12800292213364403, "compression_ratio": 1.534351145038168, "no_speech_prob": 1.4738824575033505e-05}, {"id": 395, "seek": 254872, "start": 2568.6, "end": 2574.24, "text": " Keras for those last few layers of ResNet. So now I'm going to repeat the same process", "tokens": [591, 6985, 337, 729, 1036, 1326, 7914, 295, 5015, 31890, 13, 407, 586, 286, 478, 516, 281, 7149, 264, 912, 1399], "temperature": 0.0, "avg_logprob": -0.12800292213364403, "compression_ratio": 1.534351145038168, "no_speech_prob": 1.4738824575033505e-05}, {"id": 396, "seek": 257424, "start": 2574.24, "end": 2581.24, "text": " again which is to call predict on these last few layers. The input will be the output from", "tokens": [797, 597, 307, 281, 818, 6069, 322, 613, 1036, 1326, 7914, 13, 440, 4846, 486, 312, 264, 5598, 490], "temperature": 0.0, "avg_logprob": -0.15843604927632346, "compression_ratio": 1.6503067484662577, "no_speech_prob": 7.296341209439561e-06}, {"id": 397, "seek": 257424, "start": 2581.24, "end": 2587.8999999999996, "text": " the previous one. So we went like 2 thirds of the way into ResNet and got those activations", "tokens": [264, 3894, 472, 13, 407, 321, 1437, 411, 568, 34552, 295, 264, 636, 666, 5015, 31890, 293, 658, 729, 2430, 763], "temperature": 0.0, "avg_logprob": -0.15843604927632346, "compression_ratio": 1.6503067484662577, "no_speech_prob": 7.296341209439561e-06}, {"id": 398, "seek": 257424, "start": 2587.8999999999996, "end": 2594.04, "text": " and put those activations into the last few stages of ResNet to get those activations.", "tokens": [293, 829, 729, 2430, 763, 666, 264, 1036, 1326, 10232, 295, 5015, 31890, 281, 483, 729, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.15843604927632346, "compression_ratio": 1.6503067484662577, "no_speech_prob": 7.296341209439561e-06}, {"id": 399, "seek": 259404, "start": 2594.04, "end": 2604.4, "text": " Now the outputs from this are actually just a vector of length 2048 which does fit in", "tokens": [823, 264, 23930, 490, 341, 366, 767, 445, 257, 8062, 295, 4641, 945, 13318, 597, 775, 3318, 294], "temperature": 0.0, "avg_logprob": -0.18707896178623415, "compression_ratio": 1.2960526315789473, "no_speech_prob": 1.4510386790789198e-05}, {"id": 400, "seek": 259404, "start": 2604.4, "end": 2613.36, "text": " my RAM. If you try this at home and you don't have enough memory, you can use the predict", "tokens": [452, 14561, 13, 759, 291, 853, 341, 412, 1280, 293, 291, 500, 380, 362, 1547, 4675, 11, 291, 393, 764, 264, 6069], "temperature": 0.0, "avg_logprob": -0.18707896178623415, "compression_ratio": 1.2960526315789473, "no_speech_prob": 1.4510386790789198e-05}, {"id": 401, "seek": 259404, "start": 2613.36, "end": 2616.3, "text": " on batch trick again.", "tokens": [322, 15245, 4282, 797, 13], "temperature": 0.0, "avg_logprob": -0.18707896178623415, "compression_ratio": 1.2960526315789473, "no_speech_prob": 1.4510386790789198e-05}, {"id": 402, "seek": 261630, "start": 2616.3, "end": 2627.6000000000004, "text": " Anytime you run out of memory when calling predict, you can always just use this pattern.", "tokens": [39401, 291, 1190, 484, 295, 4675, 562, 5141, 6069, 11, 291, 393, 1009, 445, 764, 341, 5102, 13], "temperature": 0.0, "avg_logprob": -0.11623705835903392, "compression_ratio": 1.451086956521739, "no_speech_prob": 8.446217520940991e-07}, {"id": 403, "seek": 261630, "start": 2627.6000000000004, "end": 2634.48, "text": " So at the end of all that, I've now got the activations from the penultimate layer of", "tokens": [407, 412, 264, 917, 295, 439, 300, 11, 286, 600, 586, 658, 264, 2430, 763, 490, 264, 3435, 723, 2905, 4583, 295], "temperature": 0.0, "avg_logprob": -0.11623705835903392, "compression_ratio": 1.451086956521739, "no_speech_prob": 8.446217520940991e-07}, {"id": 404, "seek": 261630, "start": 2634.48, "end": 2644.2000000000003, "text": " ResNet. So I can do our usual transfer learning trick of creating a linear model. My linear", "tokens": [5015, 31890, 13, 407, 286, 393, 360, 527, 7713, 5003, 2539, 4282, 295, 4084, 257, 8213, 2316, 13, 1222, 8213], "temperature": 0.0, "avg_logprob": -0.11623705835903392, "compression_ratio": 1.451086956521739, "no_speech_prob": 8.446217520940991e-07}, {"id": 405, "seek": 264420, "start": 2644.2, "end": 2652.64, "text": " model is now going to try to use the number of dimensions in my word vectors as its output.", "tokens": [2316, 307, 586, 516, 281, 853, 281, 764, 264, 1230, 295, 12819, 294, 452, 1349, 18875, 382, 1080, 5598, 13], "temperature": 0.0, "avg_logprob": -0.165172115787045, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.014715043216711e-06}, {"id": 406, "seek": 264420, "start": 2652.64, "end": 2658.56, "text": " You'll see it doesn't have any activation function. That's because I'm not doing one", "tokens": [509, 603, 536, 309, 1177, 380, 362, 604, 24433, 2445, 13, 663, 311, 570, 286, 478, 406, 884, 472], "temperature": 0.0, "avg_logprob": -0.165172115787045, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.014715043216711e-06}, {"id": 407, "seek": 264420, "start": 2658.56, "end": 2665.96, "text": " hot encoding. My word vectors could be any size numbers, so I just leave it as linear.", "tokens": [2368, 43430, 13, 1222, 1349, 18875, 727, 312, 604, 2744, 3547, 11, 370, 286, 445, 1856, 309, 382, 8213, 13], "temperature": 0.0, "avg_logprob": -0.165172115787045, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.014715043216711e-06}, {"id": 408, "seek": 264420, "start": 2665.96, "end": 2673.12, "text": " And then I compile it and then I fit it. So this linear model is now my very first. This", "tokens": [400, 550, 286, 31413, 309, 293, 550, 286, 3318, 309, 13, 407, 341, 8213, 2316, 307, 586, 452, 588, 700, 13, 639], "temperature": 0.0, "avg_logprob": -0.165172115787045, "compression_ratio": 1.592760180995475, "no_speech_prob": 5.014715043216711e-06}, {"id": 409, "seek": 267312, "start": 2673.12, "end": 2679.92, "text": " is almost the same as what we did in lesson 1, dog vs. cats. We're fine-tuning a model", "tokens": [307, 1920, 264, 912, 382, 437, 321, 630, 294, 6898, 502, 11, 3000, 12041, 13, 11111, 13, 492, 434, 2489, 12, 83, 37726, 257, 2316], "temperature": 0.0, "avg_logprob": -0.16644506140069648, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6187437722692266e-05}, {"id": 410, "seek": 267312, "start": 2679.92, "end": 2688.4, "text": " to a slightly different target to what it was originally trained with. It's just that", "tokens": [281, 257, 4748, 819, 3779, 281, 437, 309, 390, 7993, 8895, 365, 13, 467, 311, 445, 300], "temperature": 0.0, "avg_logprob": -0.16644506140069648, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6187437722692266e-05}, {"id": 411, "seek": 267312, "start": 2688.4, "end": 2694.48, "text": " we're doing it with a lot more data, so we have to be a bit more thoughtful.", "tokens": [321, 434, 884, 309, 365, 257, 688, 544, 1412, 11, 370, 321, 362, 281, 312, 257, 857, 544, 21566, 13], "temperature": 0.0, "avg_logprob": -0.16644506140069648, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6187437722692266e-05}, {"id": 412, "seek": 267312, "start": 2694.48, "end": 2698.72, "text": " There's one other difference here, which is I'm using a custom loss function. The loss", "tokens": [821, 311, 472, 661, 2649, 510, 11, 597, 307, 286, 478, 1228, 257, 2375, 4470, 2445, 13, 440, 4470], "temperature": 0.0, "avg_logprob": -0.16644506140069648, "compression_ratio": 1.5555555555555556, "no_speech_prob": 1.6187437722692266e-05}, {"id": 413, "seek": 269872, "start": 2698.72, "end": 2704.68, "text": " function I'm using is cosine distance. You can lock that up at home if you're not familiar", "tokens": [2445, 286, 478, 1228, 307, 23565, 4560, 13, 509, 393, 4017, 300, 493, 412, 1280, 498, 291, 434, 406, 4963], "temperature": 0.0, "avg_logprob": -0.1280095861592424, "compression_ratio": 1.7674418604651163, "no_speech_prob": 5.014718226448167e-06}, {"id": 414, "seek": 269872, "start": 2704.68, "end": 2709.8799999999997, "text": " with it, but basically cosine distance says for these two points in space, what's the", "tokens": [365, 309, 11, 457, 1936, 23565, 4560, 1619, 337, 613, 732, 2793, 294, 1901, 11, 437, 311, 264], "temperature": 0.0, "avg_logprob": -0.1280095861592424, "compression_ratio": 1.7674418604651163, "no_speech_prob": 5.014718226448167e-06}, {"id": 415, "seek": 269872, "start": 2709.8799999999997, "end": 2715.0, "text": " angle between them rather than how far away are they. The reason we're doing that is because", "tokens": [5802, 1296, 552, 2831, 813, 577, 1400, 1314, 366, 436, 13, 440, 1778, 321, 434, 884, 300, 307, 570], "temperature": 0.0, "avg_logprob": -0.1280095861592424, "compression_ratio": 1.7674418604651163, "no_speech_prob": 5.014718226448167e-06}, {"id": 416, "seek": 269872, "start": 2715.0, "end": 2719.8799999999997, "text": " we're about to start using k nearest neighbors. So k nearest neighbors, we're going to basically", "tokens": [321, 434, 466, 281, 722, 1228, 350, 23831, 12512, 13, 407, 350, 23831, 12512, 11, 321, 434, 516, 281, 1936], "temperature": 0.0, "avg_logprob": -0.1280095861592424, "compression_ratio": 1.7674418604651163, "no_speech_prob": 5.014718226448167e-06}, {"id": 417, "seek": 269872, "start": 2719.8799999999997, "end": 2726.7999999999997, "text": " say here's the word vector we predicted, which is the word vector which is closest to it.", "tokens": [584, 510, 311, 264, 1349, 8062, 321, 19147, 11, 597, 307, 264, 1349, 8062, 597, 307, 13699, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.1280095861592424, "compression_ratio": 1.7674418604651163, "no_speech_prob": 5.014718226448167e-06}, {"id": 418, "seek": 272680, "start": 2726.8, "end": 2732.2000000000003, "text": " It turns out that in really, really high dimensional space, the concept of how far away something", "tokens": [467, 4523, 484, 300, 294, 534, 11, 534, 1090, 18795, 1901, 11, 264, 3410, 295, 577, 1400, 1314, 746], "temperature": 0.0, "avg_logprob": -0.1880651620718149, "compression_ratio": 1.96137339055794, "no_speech_prob": 4.2228211896144785e-06}, {"id": 419, "seek": 272680, "start": 2732.2000000000003, "end": 2737.0800000000004, "text": " is is nearly meaningless. And the reason why is that in really, really high dimensional", "tokens": [307, 307, 6217, 33232, 13, 400, 264, 1778, 983, 307, 300, 294, 534, 11, 534, 1090, 18795], "temperature": 0.0, "avg_logprob": -0.1880651620718149, "compression_ratio": 1.96137339055794, "no_speech_prob": 4.2228211896144785e-06}, {"id": 420, "seek": 272680, "start": 2737.0800000000004, "end": 2744.92, "text": " space, everything sits on the edge of that space. Basically because you can imagine as", "tokens": [1901, 11, 1203, 12696, 322, 264, 4691, 295, 300, 1901, 13, 8537, 570, 291, 393, 3811, 382], "temperature": 0.0, "avg_logprob": -0.1880651620718149, "compression_ratio": 1.96137339055794, "no_speech_prob": 4.2228211896144785e-06}, {"id": 421, "seek": 272680, "start": 2744.92, "end": 2751.76, "text": " you add each additional dimension, the probability that something's on the edge in that dimension,", "tokens": [291, 909, 1184, 4497, 10139, 11, 264, 8482, 300, 746, 311, 322, 264, 4691, 294, 300, 10139, 11], "temperature": 0.0, "avg_logprob": -0.1880651620718149, "compression_ratio": 1.96137339055794, "no_speech_prob": 4.2228211896144785e-06}, {"id": 422, "seek": 272680, "start": 2751.76, "end": 2755.32, "text": " let's say the probability it's right on the edge is like 1 tenth, then if you've only", "tokens": [718, 311, 584, 264, 8482, 309, 311, 558, 322, 264, 4691, 307, 411, 502, 27269, 11, 550, 498, 291, 600, 787], "temperature": 0.0, "avg_logprob": -0.1880651620718149, "compression_ratio": 1.96137339055794, "no_speech_prob": 4.2228211896144785e-06}, {"id": 423, "seek": 275532, "start": 2755.32, "end": 2759.2400000000002, "text": " got one dimension, you've got a probability of 1 tenth that's on the edge in one dimension.", "tokens": [658, 472, 10139, 11, 291, 600, 658, 257, 8482, 295, 502, 27269, 300, 311, 322, 264, 4691, 294, 472, 10139, 13], "temperature": 0.0, "avg_logprob": -0.21923406307513899, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.190776285715401e-06}, {"id": 424, "seek": 275532, "start": 2759.2400000000002, "end": 2765.04, "text": " If you've got two dimensions, it's basically multiplicatively decreasing the probability", "tokens": [759, 291, 600, 658, 732, 12819, 11, 309, 311, 1936, 17596, 19020, 23223, 264, 8482], "temperature": 0.0, "avg_logprob": -0.21923406307513899, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.190776285715401e-06}, {"id": 425, "seek": 275532, "start": 2765.04, "end": 2770.92, "text": " that that happens. So in a few hundred dimensional space, everything is on the edge. And when", "tokens": [300, 300, 2314, 13, 407, 294, 257, 1326, 3262, 18795, 1901, 11, 1203, 307, 322, 264, 4691, 13, 400, 562], "temperature": 0.0, "avg_logprob": -0.21923406307513899, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.190776285715401e-06}, {"id": 426, "seek": 275532, "start": 2770.92, "end": 2775.96, "text": " everything's on the edge, everything is kind of an equal distance away from each other,", "tokens": [1203, 311, 322, 264, 4691, 11, 1203, 307, 733, 295, 364, 2681, 4560, 1314, 490, 1184, 661, 11], "temperature": 0.0, "avg_logprob": -0.21923406307513899, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.190776285715401e-06}, {"id": 427, "seek": 275532, "start": 2775.96, "end": 2781.48, "text": " more or less, and so distances aren't very helpful. But the angle between things still", "tokens": [544, 420, 1570, 11, 293, 370, 22182, 3212, 380, 588, 4961, 13, 583, 264, 5802, 1296, 721, 920], "temperature": 0.0, "avg_logprob": -0.21923406307513899, "compression_ratio": 1.8032128514056225, "no_speech_prob": 2.190776285715401e-06}, {"id": 428, "seek": 278148, "start": 2781.48, "end": 2788.64, "text": " separates. So when you're doing anything with trying to find nearest neighbors, it's a really", "tokens": [34149, 13, 407, 562, 291, 434, 884, 1340, 365, 1382, 281, 915, 23831, 12512, 11, 309, 311, 257, 534], "temperature": 0.0, "avg_logprob": -0.15896930334702977, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.5867144358926453e-05}, {"id": 429, "seek": 278148, "start": 2788.64, "end": 2796.36, "text": " good idea to train things using cosine distance. And this is the formula for cosine distance.", "tokens": [665, 1558, 281, 3847, 721, 1228, 23565, 4560, 13, 400, 341, 307, 264, 8513, 337, 23565, 4560, 13], "temperature": 0.0, "avg_logprob": -0.15896930334702977, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.5867144358926453e-05}, {"id": 430, "seek": 278148, "start": 2796.36, "end": 2800.92, "text": " Again, this is one of these things where I'm skipping over something that you'd probably", "tokens": [3764, 11, 341, 307, 472, 295, 613, 721, 689, 286, 478, 31533, 670, 746, 300, 291, 1116, 1391], "temperature": 0.0, "avg_logprob": -0.15896930334702977, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.5867144358926453e-05}, {"id": 431, "seek": 278148, "start": 2800.92, "end": 2806.7, "text": " spend a week in undergrad studying. There's heaps of information about cosine distance", "tokens": [3496, 257, 1243, 294, 14295, 7601, 13, 821, 311, 415, 2382, 295, 1589, 466, 23565, 4560], "temperature": 0.0, "avg_logprob": -0.15896930334702977, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.5867144358926453e-05}, {"id": 432, "seek": 278148, "start": 2806.7, "end": 2810.68, "text": " on the web, so for those of you already familiar with it, I won't waste your time. For those", "tokens": [322, 264, 3670, 11, 370, 337, 729, 295, 291, 1217, 4963, 365, 309, 11, 286, 1582, 380, 5964, 428, 565, 13, 1171, 729], "temperature": 0.0, "avg_logprob": -0.15896930334702977, "compression_ratio": 1.7014925373134329, "no_speech_prob": 2.5867144358926453e-05}, {"id": 433, "seek": 281068, "start": 2810.68, "end": 2816.3999999999996, "text": " of you not, it's a very, very good idea to become familiar with this. And feel free to", "tokens": [295, 291, 406, 11, 309, 311, 257, 588, 11, 588, 665, 1558, 281, 1813, 4963, 365, 341, 13, 400, 841, 1737, 281], "temperature": 0.0, "avg_logprob": -0.1526572195331702, "compression_ratio": 1.5446009389671362, "no_speech_prob": 1.406395767844515e-05}, {"id": 434, "seek": 281068, "start": 2816.3999999999996, "end": 2822.06, "text": " ask on the forums if you can't find any material that makes sense.", "tokens": [1029, 322, 264, 26998, 498, 291, 393, 380, 915, 604, 2527, 300, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.1526572195331702, "compression_ratio": 1.5446009389671362, "no_speech_prob": 1.406395767844515e-05}, {"id": 435, "seek": 281068, "start": 2822.06, "end": 2828.0, "text": " So we've fitted our linear model as per usual. We save our weights and we can see how we're", "tokens": [407, 321, 600, 26321, 527, 8213, 2316, 382, 680, 7713, 13, 492, 3155, 527, 17443, 293, 321, 393, 536, 577, 321, 434], "temperature": 0.0, "avg_logprob": -0.1526572195331702, "compression_ratio": 1.5446009389671362, "no_speech_prob": 1.406395767844515e-05}, {"id": 436, "seek": 281068, "start": 2828.0, "end": 2834.74, "text": " going. So what we've got now is something where we can feed in an image and it will", "tokens": [516, 13, 407, 437, 321, 600, 658, 586, 307, 746, 689, 321, 393, 3154, 294, 364, 3256, 293, 309, 486], "temperature": 0.0, "avg_logprob": -0.1526572195331702, "compression_ratio": 1.5446009389671362, "no_speech_prob": 1.406395767844515e-05}, {"id": 437, "seek": 283474, "start": 2834.74, "end": 2840.64, "text": " spit out a word vector. But it's something that looks like a word vector. It has the", "tokens": [22127, 484, 257, 1349, 8062, 13, 583, 309, 311, 746, 300, 1542, 411, 257, 1349, 8062, 13, 467, 575, 264], "temperature": 0.0, "avg_logprob": -0.11350831880674257, "compression_ratio": 1.7058823529411764, "no_speech_prob": 1.4970952179282904e-05}, {"id": 438, "seek": 283474, "start": 2840.64, "end": 2845.16, "text": " same dimensionality as a word vector, but it's very unlikely that it's going to be the", "tokens": [912, 10139, 1860, 382, 257, 1349, 8062, 11, 457, 309, 311, 588, 17518, 300, 309, 311, 516, 281, 312, 264], "temperature": 0.0, "avg_logprob": -0.11350831880674257, "compression_ratio": 1.7058823529411764, "no_speech_prob": 1.4970952179282904e-05}, {"id": 439, "seek": 283474, "start": 2845.16, "end": 2852.8799999999997, "text": " exact same vector as one of our thousand target word vectors. So if the word vector for a", "tokens": [1900, 912, 8062, 382, 472, 295, 527, 4714, 3779, 1349, 18875, 13, 407, 498, 264, 1349, 8062, 337, 257], "temperature": 0.0, "avg_logprob": -0.11350831880674257, "compression_ratio": 1.7058823529411764, "no_speech_prob": 1.4970952179282904e-05}, {"id": 440, "seek": 283474, "start": 2852.8799999999997, "end": 2860.68, "text": " pug is this list of 200 floats, even if we have a perfectly puggy pug, we're not going", "tokens": [47900, 307, 341, 1329, 295, 2331, 37878, 11, 754, 498, 321, 362, 257, 6239, 47900, 1480, 47900, 11, 321, 434, 406, 516], "temperature": 0.0, "avg_logprob": -0.11350831880674257, "compression_ratio": 1.7058823529411764, "no_speech_prob": 1.4970952179282904e-05}, {"id": 441, "seek": 286068, "start": 2860.68, "end": 2866.12, "text": " to get that exact list of 2,000 floats. We'll have something that is similar. And when we", "tokens": [281, 483, 300, 1900, 1329, 295, 568, 11, 1360, 37878, 13, 492, 603, 362, 746, 300, 307, 2531, 13, 400, 562, 321], "temperature": 0.0, "avg_logprob": -0.15651433532302444, "compression_ratio": 1.4873096446700507, "no_speech_prob": 8.66457776282914e-06}, {"id": 442, "seek": 286068, "start": 2866.12, "end": 2871.56, "text": " say similar, we probably mean that the cosine distance between the perfect platonic pug", "tokens": [584, 2531, 11, 321, 1391, 914, 300, 264, 23565, 4560, 1296, 264, 2176, 3403, 11630, 47900], "temperature": 0.0, "avg_logprob": -0.15651433532302444, "compression_ratio": 1.4873096446700507, "no_speech_prob": 8.66457776282914e-06}, {"id": 443, "seek": 286068, "start": 2871.56, "end": 2874.16, "text": " and our pug is pretty small.", "tokens": [293, 527, 47900, 307, 1238, 1359, 13], "temperature": 0.0, "avg_logprob": -0.15651433532302444, "compression_ratio": 1.4873096446700507, "no_speech_prob": 8.66457776282914e-06}, {"id": 444, "seek": 286068, "start": 2874.16, "end": 2887.9199999999996, "text": " So that's why after we get our predictions, we then have to use nearest neighbors as a", "tokens": [407, 300, 311, 983, 934, 321, 483, 527, 21264, 11, 321, 550, 362, 281, 764, 23831, 12512, 382, 257], "temperature": 0.0, "avg_logprob": -0.15651433532302444, "compression_ratio": 1.4873096446700507, "no_speech_prob": 8.66457776282914e-06}, {"id": 445, "seek": 288792, "start": 2887.92, "end": 2893.7200000000003, "text": " second step to basically say, for each of those predictions, what are the three word", "tokens": [1150, 1823, 281, 1936, 584, 11, 337, 1184, 295, 729, 21264, 11, 437, 366, 264, 1045, 1349], "temperature": 0.0, "avg_logprob": -0.16996298165156923, "compression_ratio": 1.7198067632850242, "no_speech_prob": 9.81826724455459e-06}, {"id": 446, "seek": 288792, "start": 2893.7200000000003, "end": 2900.88, "text": " vectors that are the closest to that prediction. So we can now take those nearest neighbors", "tokens": [18875, 300, 366, 264, 13699, 281, 300, 17630, 13, 407, 321, 393, 586, 747, 729, 23831, 12512], "temperature": 0.0, "avg_logprob": -0.16996298165156923, "compression_ratio": 1.7198067632850242, "no_speech_prob": 9.81826724455459e-06}, {"id": 447, "seek": 288792, "start": 2900.88, "end": 2906.92, "text": " and find out for a bunch of our images what are the three things it thinks it might be.", "tokens": [293, 915, 484, 337, 257, 3840, 295, 527, 5267, 437, 366, 264, 1045, 721, 309, 7309, 309, 1062, 312, 13], "temperature": 0.0, "avg_logprob": -0.16996298165156923, "compression_ratio": 1.7198067632850242, "no_speech_prob": 9.81826724455459e-06}, {"id": 448, "seek": 288792, "start": 2906.92, "end": 2915.48, "text": " So for example, for this image here, its best guess was trombone, next was flute, and third", "tokens": [407, 337, 1365, 11, 337, 341, 3256, 510, 11, 1080, 1151, 2041, 390, 504, 3548, 546, 11, 958, 390, 33088, 11, 293, 2636], "temperature": 0.0, "avg_logprob": -0.16996298165156923, "compression_ratio": 1.7198067632850242, "no_speech_prob": 9.81826724455459e-06}, {"id": 449, "seek": 291548, "start": 2915.48, "end": 2922.36, "text": " was cello. So this gives us some hope that this approach seems to be working okay. It's", "tokens": [390, 2815, 78, 13, 407, 341, 2709, 505, 512, 1454, 300, 341, 3109, 2544, 281, 312, 1364, 1392, 13, 467, 311], "temperature": 0.0, "avg_logprob": -0.11746716932816939, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.2805360711354297e-05}, {"id": 450, "seek": 291548, "start": 2922.36, "end": 2926.76, "text": " not great yet, but it's recognized these things are musical instruments, and its third guess", "tokens": [406, 869, 1939, 11, 457, 309, 311, 9823, 613, 721, 366, 9165, 12190, 11, 293, 1080, 2636, 2041], "temperature": 0.0, "avg_logprob": -0.11746716932816939, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.2805360711354297e-05}, {"id": 451, "seek": 291548, "start": 2926.76, "end": 2929.32, "text": " was in fact the correct musical instrument.", "tokens": [390, 294, 1186, 264, 3006, 9165, 7198, 13], "temperature": 0.0, "avg_logprob": -0.11746716932816939, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.2805360711354297e-05}, {"id": 452, "seek": 291548, "start": 2929.32, "end": 2935.2400000000002, "text": " So we know what to do next. What we do next is to fine-tune more layers. And because we", "tokens": [407, 321, 458, 437, 281, 360, 958, 13, 708, 321, 360, 958, 307, 281, 2489, 12, 83, 2613, 544, 7914, 13, 400, 570, 321], "temperature": 0.0, "avg_logprob": -0.11746716932816939, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.2805360711354297e-05}, {"id": 453, "seek": 291548, "start": 2935.2400000000002, "end": 2940.64, "text": " have already saved the intermediate results from an earlier layer, that fine-tuning is", "tokens": [362, 1217, 6624, 264, 19376, 3542, 490, 364, 3071, 4583, 11, 300, 2489, 12, 83, 37726, 307], "temperature": 0.0, "avg_logprob": -0.11746716932816939, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.2805360711354297e-05}, {"id": 454, "seek": 291548, "start": 2940.64, "end": 2944.96, "text": " going to be much faster to do.", "tokens": [516, 281, 312, 709, 4663, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.11746716932816939, "compression_ratio": 1.6538461538461537, "no_speech_prob": 1.2805360711354297e-05}, {"id": 455, "seek": 294496, "start": 2944.96, "end": 2948.82, "text": " Two more things I'll briefly mention. One is that there's a couple of different ways", "tokens": [4453, 544, 721, 286, 603, 10515, 2152, 13, 1485, 307, 300, 456, 311, 257, 1916, 295, 819, 2098], "temperature": 0.0, "avg_logprob": -0.17491229829334076, "compression_ratio": 1.788, "no_speech_prob": 3.0241539207054302e-05}, {"id": 456, "seek": 294496, "start": 2948.82, "end": 2953.78, "text": " to do nearest neighbors. One is what's called the brute force approach, which is literally", "tokens": [281, 360, 23831, 12512, 13, 1485, 307, 437, 311, 1219, 264, 47909, 3464, 3109, 11, 597, 307, 3736], "temperature": 0.0, "avg_logprob": -0.17491229829334076, "compression_ratio": 1.788, "no_speech_prob": 3.0241539207054302e-05}, {"id": 457, "seek": 294496, "start": 2953.78, "end": 2959.2, "text": " okay what's the nearest word vector to this word vector, and to go through every one and", "tokens": [1392, 437, 311, 264, 23831, 1349, 8062, 281, 341, 1349, 8062, 11, 293, 281, 352, 807, 633, 472, 293], "temperature": 0.0, "avg_logprob": -0.17491229829334076, "compression_ratio": 1.788, "no_speech_prob": 3.0241539207054302e-05}, {"id": 458, "seek": 294496, "start": 2959.2, "end": 2966.4, "text": " see how far away it is. There's another approach which is approximate nearest neighbors. And", "tokens": [536, 577, 1400, 1314, 309, 307, 13, 821, 311, 1071, 3109, 597, 307, 30874, 23831, 12512, 13, 400], "temperature": 0.0, "avg_logprob": -0.17491229829334076, "compression_ratio": 1.788, "no_speech_prob": 3.0241539207054302e-05}, {"id": 459, "seek": 294496, "start": 2966.4, "end": 2970.76, "text": " when you've got lots and lots of things, you're trying to look for nearest neighbors, the", "tokens": [562, 291, 600, 658, 3195, 293, 3195, 295, 721, 11, 291, 434, 1382, 281, 574, 337, 23831, 12512, 11, 264], "temperature": 0.0, "avg_logprob": -0.17491229829334076, "compression_ratio": 1.788, "no_speech_prob": 3.0241539207054302e-05}, {"id": 460, "seek": 297076, "start": 2970.76, "end": 2976.6000000000004, "text": " brute force approach is going to be n squared time, it's going to be super slow. Where else", "tokens": [47909, 3464, 3109, 307, 516, 281, 312, 297, 8889, 565, 11, 309, 311, 516, 281, 312, 1687, 2964, 13, 2305, 1646], "temperature": 0.0, "avg_logprob": -0.19471299129983652, "compression_ratio": 1.5789473684210527, "no_speech_prob": 2.1907774225837784e-06}, {"id": 461, "seek": 297076, "start": 2976.6000000000004, "end": 2984.5400000000004, "text": " would approximate nearest neighbors are generally n log n time. So orders of magnitude faster", "tokens": [576, 30874, 23831, 12512, 366, 5101, 297, 3565, 297, 565, 13, 407, 9470, 295, 15668, 4663], "temperature": 0.0, "avg_logprob": -0.19471299129983652, "compression_ratio": 1.5789473684210527, "no_speech_prob": 2.1907774225837784e-06}, {"id": 462, "seek": 297076, "start": 2984.5400000000004, "end": 2988.4, "text": " if you've got a large data set.", "tokens": [498, 291, 600, 658, 257, 2416, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.19471299129983652, "compression_ratio": 1.5789473684210527, "no_speech_prob": 2.1907774225837784e-06}, {"id": 463, "seek": 297076, "start": 2988.4, "end": 2993.1600000000003, "text": " The particular approach I'm using here is something called locality-sensitive hashing.", "tokens": [440, 1729, 3109, 286, 478, 1228, 510, 307, 746, 1219, 1628, 1860, 12, 82, 34465, 575, 571, 13], "temperature": 0.0, "avg_logprob": -0.19471299129983652, "compression_ratio": 1.5789473684210527, "no_speech_prob": 2.1907774225837784e-06}, {"id": 464, "seek": 297076, "start": 2993.1600000000003, "end": 2997.96, "text": " It's a fascinating and wonderful algorithm. Anybody who's interested in algorithms, I", "tokens": [467, 311, 257, 10343, 293, 3715, 9284, 13, 19082, 567, 311, 3102, 294, 14642, 11, 286], "temperature": 0.0, "avg_logprob": -0.19471299129983652, "compression_ratio": 1.5789473684210527, "no_speech_prob": 2.1907774225837784e-06}, {"id": 465, "seek": 299796, "start": 2997.96, "end": 3004.36, "text": " strongly recommend you go read about it. Let me know if you need a hand with it.", "tokens": [10613, 2748, 291, 352, 1401, 466, 309, 13, 961, 385, 458, 498, 291, 643, 257, 1011, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.10232093736722872, "compression_ratio": 1.6901408450704225, "no_speech_prob": 8.939666258811485e-06}, {"id": 466, "seek": 299796, "start": 3004.36, "end": 3012.96, "text": " My favorite kind of algorithms are these approximate algorithms. In data science, you almost never", "tokens": [1222, 2954, 733, 295, 14642, 366, 613, 30874, 14642, 13, 682, 1412, 3497, 11, 291, 1920, 1128], "temperature": 0.0, "avg_logprob": -0.10232093736722872, "compression_ratio": 1.6901408450704225, "no_speech_prob": 8.939666258811485e-06}, {"id": 467, "seek": 299796, "start": 3012.96, "end": 3018.08, "text": " need to know something exactly, yet nearly every algorithm that people learn at university", "tokens": [643, 281, 458, 746, 2293, 11, 1939, 6217, 633, 9284, 300, 561, 1466, 412, 5454], "temperature": 0.0, "avg_logprob": -0.10232093736722872, "compression_ratio": 1.6901408450704225, "no_speech_prob": 8.939666258811485e-06}, {"id": 468, "seek": 299796, "start": 3018.08, "end": 3023.44, "text": " and certainly at high school are exact. We learn exact nearest neighbor algorithms, exact", "tokens": [293, 3297, 412, 1090, 1395, 366, 1900, 13, 492, 1466, 1900, 23831, 5987, 14642, 11, 1900], "temperature": 0.0, "avg_logprob": -0.10232093736722872, "compression_ratio": 1.6901408450704225, "no_speech_prob": 8.939666258811485e-06}, {"id": 469, "seek": 302344, "start": 3023.44, "end": 3028.7200000000003, "text": " indexing algorithms, exact median algorithms. Pretty much for every algorithm out there,", "tokens": [8186, 278, 14642, 11, 1900, 26779, 14642, 13, 10693, 709, 337, 633, 9284, 484, 456, 11], "temperature": 0.0, "avg_logprob": -0.19155742327372233, "compression_ratio": 1.8220640569395017, "no_speech_prob": 6.643404958595056e-06}, {"id": 470, "seek": 302344, "start": 3028.7200000000003, "end": 3037.56, "text": " there's an approximate version that runs an order of n or log n over n faster.", "tokens": [456, 311, 364, 30874, 3037, 300, 6676, 364, 1668, 295, 297, 420, 3565, 297, 670, 297, 4663, 13], "temperature": 0.0, "avg_logprob": -0.19155742327372233, "compression_ratio": 1.8220640569395017, "no_speech_prob": 6.643404958595056e-06}, {"id": 471, "seek": 302344, "start": 3037.56, "end": 3040.78, "text": " And one of the cool things is that once you start realizing that, you suddenly discover", "tokens": [400, 472, 295, 264, 1627, 721, 307, 300, 1564, 291, 722, 16734, 300, 11, 291, 5800, 4411], "temperature": 0.0, "avg_logprob": -0.19155742327372233, "compression_ratio": 1.8220640569395017, "no_speech_prob": 6.643404958595056e-06}, {"id": 472, "seek": 302344, "start": 3040.78, "end": 3044.56, "text": " that all of the libraries you've been using for ages were written by people who didn't", "tokens": [300, 439, 295, 264, 15148, 291, 600, 668, 1228, 337, 12357, 645, 3720, 538, 561, 567, 994, 380], "temperature": 0.0, "avg_logprob": -0.19155742327372233, "compression_ratio": 1.8220640569395017, "no_speech_prob": 6.643404958595056e-06}, {"id": 473, "seek": 302344, "start": 3044.56, "end": 3049.2400000000002, "text": " know this. And then you realize that like every sub-algorithm they've written, they", "tokens": [458, 341, 13, 400, 550, 291, 4325, 300, 411, 633, 1422, 12, 20422, 6819, 76, 436, 600, 3720, 11, 436], "temperature": 0.0, "avg_logprob": -0.19155742327372233, "compression_ratio": 1.8220640569395017, "no_speech_prob": 6.643404958595056e-06}, {"id": 474, "seek": 302344, "start": 3049.2400000000002, "end": 3052.36, "text": " could have used an approximate version. The next thing you know, you've got something", "tokens": [727, 362, 1143, 364, 30874, 3037, 13, 440, 958, 551, 291, 458, 11, 291, 600, 658, 746], "temperature": 0.0, "avg_logprob": -0.19155742327372233, "compression_ratio": 1.8220640569395017, "no_speech_prob": 6.643404958595056e-06}, {"id": 475, "seek": 305236, "start": 3052.36, "end": 3055.1200000000003, "text": " that runs 1000 times faster.", "tokens": [300, 6676, 9714, 1413, 4663, 13], "temperature": 0.0, "avg_logprob": -0.1597253239673117, "compression_ratio": 1.6125, "no_speech_prob": 1.2411392162903212e-05}, {"id": 476, "seek": 305236, "start": 3055.1200000000003, "end": 3060.52, "text": " The other cool thing about approximate algorithms is that they're generally written to provably", "tokens": [440, 661, 1627, 551, 466, 30874, 14642, 307, 300, 436, 434, 5101, 3720, 281, 1439, 1188], "temperature": 0.0, "avg_logprob": -0.1597253239673117, "compression_ratio": 1.6125, "no_speech_prob": 1.2411392162903212e-05}, {"id": 477, "seek": 305236, "start": 3060.52, "end": 3065.6400000000003, "text": " be accurate to within so close. And like it can tell you with your parameters how close", "tokens": [312, 8559, 281, 1951, 370, 1998, 13, 400, 411, 309, 393, 980, 291, 365, 428, 9834, 577, 1998], "temperature": 0.0, "avg_logprob": -0.1597253239673117, "compression_ratio": 1.6125, "no_speech_prob": 1.2411392162903212e-05}, {"id": 478, "seek": 305236, "start": 3065.6400000000003, "end": 3071.28, "text": " is so close. Which means that if you want to make it more accurate, you run it more", "tokens": [307, 370, 1998, 13, 3013, 1355, 300, 498, 291, 528, 281, 652, 309, 544, 8559, 11, 291, 1190, 309, 544], "temperature": 0.0, "avg_logprob": -0.1597253239673117, "compression_ratio": 1.6125, "no_speech_prob": 1.2411392162903212e-05}, {"id": 479, "seek": 305236, "start": 3071.28, "end": 3078.4, "text": " times with different random seeds. So this thing called LSH forest is a locality-sensitive", "tokens": [1413, 365, 819, 4974, 9203, 13, 407, 341, 551, 1219, 441, 17308, 6719, 307, 257, 1628, 1860, 12, 82, 34465], "temperature": 0.0, "avg_logprob": -0.1597253239673117, "compression_ratio": 1.6125, "no_speech_prob": 1.2411392162903212e-05}, {"id": 480, "seek": 307840, "start": 3078.4, "end": 3083.32, "text": " hashing forest, which means it creates a bunch of these locality-sensitive hashes.", "tokens": [575, 571, 6719, 11, 597, 1355, 309, 7829, 257, 3840, 295, 613, 1628, 1860, 12, 82, 34465, 575, 8076, 13], "temperature": 0.0, "avg_logprob": -0.10834105014801025, "compression_ratio": 1.6651162790697673, "no_speech_prob": 4.2893216232187115e-06}, {"id": 481, "seek": 307840, "start": 3083.32, "end": 3088.0, "text": " And the amazingly great thing about approximate algorithms is that each time you create another", "tokens": [400, 264, 31762, 869, 551, 466, 30874, 14642, 307, 300, 1184, 565, 291, 1884, 1071], "temperature": 0.0, "avg_logprob": -0.10834105014801025, "compression_ratio": 1.6651162790697673, "no_speech_prob": 4.2893216232187115e-06}, {"id": 482, "seek": 307840, "start": 3088.0, "end": 3094.12, "text": " version of it, you're exponentially increasing the accuracy, or multiplicatively increasing", "tokens": [3037, 295, 309, 11, 291, 434, 37330, 5662, 264, 14170, 11, 420, 17596, 19020, 5662], "temperature": 0.0, "avg_logprob": -0.10834105014801025, "compression_ratio": 1.6651162790697673, "no_speech_prob": 4.2893216232187115e-06}, {"id": 483, "seek": 307840, "start": 3094.12, "end": 3103.44, "text": " the accuracy, but only linearly increasing the time. So if the error on one call of LSH", "tokens": [264, 14170, 11, 457, 787, 43586, 5662, 264, 565, 13, 407, 498, 264, 6713, 322, 472, 818, 295, 441, 17308], "temperature": 0.0, "avg_logprob": -0.10834105014801025, "compression_ratio": 1.6651162790697673, "no_speech_prob": 4.2893216232187115e-06}, {"id": 484, "seek": 310344, "start": 3103.44, "end": 3113.64, "text": " was e, then the error on two calls is 1-e\u00b2. And three calls is 1-e\u00b3. And the time you're", "tokens": [390, 308, 11, 550, 264, 6713, 322, 732, 5498, 307, 502, 12, 68, 27643, 13, 400, 1045, 5498, 307, 502, 12, 68, 126, 111, 13, 400, 264, 565, 291, 434], "temperature": 0.0, "avg_logprob": -0.17518977324167886, "compression_ratio": 1.572093023255814, "no_speech_prob": 2.5215679215762066e-06}, {"id": 485, "seek": 310344, "start": 3113.64, "end": 3119.2400000000002, "text": " taking though, if the time for one call was n, is now 2n and 3n. So when you've got something", "tokens": [1940, 1673, 11, 498, 264, 565, 337, 472, 818, 390, 297, 11, 307, 586, 568, 77, 293, 805, 77, 13, 407, 562, 291, 600, 658, 746], "temperature": 0.0, "avg_logprob": -0.17518977324167886, "compression_ratio": 1.572093023255814, "no_speech_prob": 2.5215679215762066e-06}, {"id": 486, "seek": 310344, "start": 3119.2400000000002, "end": 3125.64, "text": " where you can make it as accurate as you like with only linear increase in time, this is", "tokens": [689, 291, 393, 652, 309, 382, 8559, 382, 291, 411, 365, 787, 8213, 3488, 294, 565, 11, 341, 307], "temperature": 0.0, "avg_logprob": -0.17518977324167886, "compression_ratio": 1.572093023255814, "no_speech_prob": 2.5215679215762066e-06}, {"id": 487, "seek": 310344, "start": 3125.64, "end": 3131.2400000000002, "text": " incredibly powerful. So this is a great approximation algorithm.", "tokens": [6252, 4005, 13, 407, 341, 307, 257, 869, 28023, 9284, 13], "temperature": 0.0, "avg_logprob": -0.17518977324167886, "compression_ratio": 1.572093023255814, "no_speech_prob": 2.5215679215762066e-06}, {"id": 488, "seek": 313124, "start": 3131.24, "end": 3138.8399999999997, "text": " I wish we had more time, so I'd love to tell you all about it. So I generally use LSH forest", "tokens": [286, 3172, 321, 632, 544, 565, 11, 370, 286, 1116, 959, 281, 980, 291, 439, 466, 309, 13, 407, 286, 5101, 764, 441, 17308, 6719], "temperature": 0.0, "avg_logprob": -0.13111556306177255, "compression_ratio": 1.555084745762712, "no_speech_prob": 3.9669694160693325e-06}, {"id": 489, "seek": 313124, "start": 3138.8399999999997, "end": 3144.04, "text": " when I'm doing nearest neighbors because it's arbitrarily close and much faster when you've", "tokens": [562, 286, 478, 884, 23831, 12512, 570, 309, 311, 19071, 3289, 1998, 293, 709, 4663, 562, 291, 600], "temperature": 0.0, "avg_logprob": -0.13111556306177255, "compression_ratio": 1.555084745762712, "no_speech_prob": 3.9669694160693325e-06}, {"id": 490, "seek": 313124, "start": 3144.04, "end": 3152.64, "text": " got lots of word vectors. The time that becomes important is when I move beyond dimensionnet,", "tokens": [658, 3195, 295, 1349, 18875, 13, 440, 565, 300, 3643, 1021, 307, 562, 286, 1286, 4399, 10139, 7129, 11], "temperature": 0.0, "avg_logprob": -0.13111556306177255, "compression_ratio": 1.555084745762712, "no_speech_prob": 3.9669694160693325e-06}, {"id": 491, "seek": 313124, "start": 3152.64, "end": 3159.52, "text": " which I'm going to do now. So let's say I've got a picture, and I don't just want to say", "tokens": [597, 286, 478, 516, 281, 360, 586, 13, 407, 718, 311, 584, 286, 600, 658, 257, 3036, 11, 293, 286, 500, 380, 445, 528, 281, 584], "temperature": 0.0, "avg_logprob": -0.13111556306177255, "compression_ratio": 1.555084745762712, "no_speech_prob": 3.9669694160693325e-06}, {"id": 492, "seek": 315952, "start": 3159.52, "end": 3165.56, "text": " which one of the 1000 image net categories is it, but which one of the 100,000 word net", "tokens": [597, 472, 295, 264, 9714, 3256, 2533, 10479, 307, 309, 11, 457, 597, 472, 295, 264, 2319, 11, 1360, 1349, 2533], "temperature": 0.0, "avg_logprob": -0.1493837053530684, "compression_ratio": 1.7675438596491229, "no_speech_prob": 6.144158305687597e-06}, {"id": 493, "seek": 315952, "start": 3165.56, "end": 3172.44, "text": " nouns is it. Now that's a much harder thing to do. And that's something that no previous", "tokens": [48184, 307, 309, 13, 823, 300, 311, 257, 709, 6081, 551, 281, 360, 13, 400, 300, 311, 746, 300, 572, 3894], "temperature": 0.0, "avg_logprob": -0.1493837053530684, "compression_ratio": 1.7675438596491229, "no_speech_prob": 6.144158305687597e-06}, {"id": 494, "seek": 315952, "start": 3172.44, "end": 3177.16, "text": " model could do. When you're trained in image net model, the only thing you could do is", "tokens": [2316, 727, 360, 13, 1133, 291, 434, 8895, 294, 3256, 2533, 2316, 11, 264, 787, 551, 291, 727, 360, 307], "temperature": 0.0, "avg_logprob": -0.1493837053530684, "compression_ratio": 1.7675438596491229, "no_speech_prob": 6.144158305687597e-06}, {"id": 495, "seek": 315952, "start": 3177.16, "end": 3180.72, "text": " recognize pictures of things that were in image net.", "tokens": [5521, 5242, 295, 721, 300, 645, 294, 3256, 2533, 13], "temperature": 0.0, "avg_logprob": -0.1493837053530684, "compression_ratio": 1.7675438596491229, "no_speech_prob": 6.144158305687597e-06}, {"id": 496, "seek": 315952, "start": 3180.72, "end": 3187.8, "text": " But now we've got a word vector model, so we can put in an image that spits out a word", "tokens": [583, 586, 321, 600, 658, 257, 1349, 8062, 2316, 11, 370, 321, 393, 829, 294, 364, 3256, 300, 637, 1208, 484, 257, 1349], "temperature": 0.0, "avg_logprob": -0.1493837053530684, "compression_ratio": 1.7675438596491229, "no_speech_prob": 6.144158305687597e-06}, {"id": 497, "seek": 318780, "start": 3187.8, "end": 3193.48, "text": " vector. And that word vector could be closer to things that are not in image net at all.", "tokens": [8062, 13, 400, 300, 1349, 8062, 727, 312, 4966, 281, 721, 300, 366, 406, 294, 3256, 2533, 412, 439, 13], "temperature": 0.0, "avg_logprob": -0.14016674041748048, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.748020496161189e-06}, {"id": 498, "seek": 318780, "start": 3193.48, "end": 3199.6000000000004, "text": " Or it could be some higher level of the hierarchy. So we could look for a dog rather than a pug,", "tokens": [1610, 309, 727, 312, 512, 2946, 1496, 295, 264, 22333, 13, 407, 321, 727, 574, 337, 257, 3000, 2831, 813, 257, 47900, 11], "temperature": 0.0, "avg_logprob": -0.14016674041748048, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.748020496161189e-06}, {"id": 499, "seek": 318780, "start": 3199.6000000000004, "end": 3204.26, "text": " or a plane rather than a 747.", "tokens": [420, 257, 5720, 2831, 813, 257, 1614, 14060, 13], "temperature": 0.0, "avg_logprob": -0.14016674041748048, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.748020496161189e-06}, {"id": 500, "seek": 318780, "start": 3204.26, "end": 3210.6400000000003, "text": " So here we bring in the entire set of word vectors. I have to remember to share these", "tokens": [407, 510, 321, 1565, 294, 264, 2302, 992, 295, 1349, 18875, 13, 286, 362, 281, 1604, 281, 2073, 613], "temperature": 0.0, "avg_logprob": -0.14016674041748048, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.748020496161189e-06}, {"id": 501, "seek": 318780, "start": 3210.6400000000003, "end": 3216.0600000000004, "text": " with you because these are actually quite hard to create. And this is where I definitely", "tokens": [365, 291, 570, 613, 366, 767, 1596, 1152, 281, 1884, 13, 400, 341, 307, 689, 286, 2138], "temperature": 0.0, "avg_logprob": -0.14016674041748048, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.748020496161189e-06}, {"id": 502, "seek": 321606, "start": 3216.06, "end": 3223.32, "text": " want LSH forest because this is going to be pretty slow. And we can now do the same thing.", "tokens": [528, 441, 17308, 6719, 570, 341, 307, 516, 281, 312, 1238, 2964, 13, 400, 321, 393, 586, 360, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.21291277958796576, "compression_ratio": 1.5247524752475248, "no_speech_prob": 1.0289450983691495e-05}, {"id": 503, "seek": 321606, "start": 3223.32, "end": 3227.56, "text": " And not surprisingly, it's got worse. The thing that was actually cello, now cello is", "tokens": [400, 406, 17600, 11, 309, 311, 658, 5324, 13, 440, 551, 300, 390, 767, 2815, 78, 11, 586, 2815, 78, 307], "temperature": 0.0, "avg_logprob": -0.21291277958796576, "compression_ratio": 1.5247524752475248, "no_speech_prob": 1.0289450983691495e-05}, {"id": 504, "seek": 321606, "start": 3227.56, "end": 3231.7999999999997, "text": " not even in the top 3. So this is a harder problem.", "tokens": [406, 754, 294, 264, 1192, 805, 13, 407, 341, 307, 257, 6081, 1154, 13], "temperature": 0.0, "avg_logprob": -0.21291277958796576, "compression_ratio": 1.5247524752475248, "no_speech_prob": 1.0289450983691495e-05}, {"id": 505, "seek": 321606, "start": 3231.7999999999997, "end": 3240.36, "text": " So let's try fine-tuning. Fine-tuning is the final trick I'm going to show you.", "tokens": [407, 718, 311, 853, 2489, 12, 83, 37726, 13, 12024, 12, 83, 37726, 307, 264, 2572, 4282, 286, 478, 516, 281, 855, 291, 13], "temperature": 0.0, "avg_logprob": -0.21291277958796576, "compression_ratio": 1.5247524752475248, "no_speech_prob": 1.0289450983691495e-05}, {"id": 506, "seek": 324036, "start": 3240.36, "end": 3251.48, "text": " Question asked.", "tokens": [14464, 2351, 13], "temperature": 0.0, "avg_logprob": -0.3660582395700308, "compression_ratio": 1.1111111111111112, "no_speech_prob": 2.2473366698250175e-05}, {"id": 507, "seek": 324036, "start": 3251.48, "end": 3257.84, "text": " You might remember last week we looked at creating our word vectors. And what we did", "tokens": [509, 1062, 1604, 1036, 1243, 321, 2956, 412, 4084, 527, 1349, 18875, 13, 400, 437, 321, 630], "temperature": 0.0, "avg_logprob": -0.3660582395700308, "compression_ratio": 1.1111111111111112, "no_speech_prob": 2.2473366698250175e-05}, {"id": 508, "seek": 325784, "start": 3257.84, "end": 3272.6800000000003, "text": " was we actually created a list. I went to WordNet and I downloaded the whole of WordNet.", "tokens": [390, 321, 767, 2942, 257, 1329, 13, 286, 1437, 281, 8725, 31890, 293, 286, 21748, 264, 1379, 295, 8725, 31890, 13], "temperature": 0.0, "avg_logprob": -0.2461990135303442, "compression_ratio": 1.6282051282051282, "no_speech_prob": 1.2218904885230586e-05}, {"id": 509, "seek": 325784, "start": 3272.6800000000003, "end": 3277.76, "text": " And then I figured out which things were nouns, and then I used a regex to parse out those,", "tokens": [400, 550, 286, 8932, 484, 597, 721, 645, 48184, 11, 293, 550, 286, 1143, 257, 319, 432, 87, 281, 48377, 484, 729, 11], "temperature": 0.0, "avg_logprob": -0.2461990135303442, "compression_ratio": 1.6282051282051282, "no_speech_prob": 1.2218904885230586e-05}, {"id": 510, "seek": 325784, "start": 3277.76, "end": 3286.4, "text": " and then I saved that. So we actually have the entirety of WordNet nouns.", "tokens": [293, 550, 286, 6624, 300, 13, 407, 321, 767, 362, 264, 31557, 295, 8725, 31890, 48184, 13], "temperature": 0.0, "avg_logprob": -0.2461990135303442, "compression_ratio": 1.6282051282051282, "no_speech_prob": 1.2218904885230586e-05}, {"id": 511, "seek": 328640, "start": 3286.4, "end": 3292.0, "text": " Question asked.", "tokens": [14464, 2351, 13], "temperature": 0.0, "avg_logprob": -0.17494172687771953, "compression_ratio": 1.5857988165680474, "no_speech_prob": 2.6274192350683734e-05}, {"id": 512, "seek": 328640, "start": 3292.0, "end": 3298.52, "text": " Because it's not a good enough model yet. So now that there's 80,000 nouns, there's", "tokens": [1436, 309, 311, 406, 257, 665, 1547, 2316, 1939, 13, 407, 586, 300, 456, 311, 4688, 11, 1360, 48184, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.17494172687771953, "compression_ratio": 1.5857988165680474, "no_speech_prob": 2.6274192350683734e-05}, {"id": 513, "seek": 328640, "start": 3298.52, "end": 3304.64, "text": " a lot more ways to be wrong. So when it only has to say, which of these thousand things", "tokens": [257, 688, 544, 2098, 281, 312, 2085, 13, 407, 562, 309, 787, 575, 281, 584, 11, 597, 295, 613, 4714, 721], "temperature": 0.0, "avg_logprob": -0.17494172687771953, "compression_ratio": 1.5857988165680474, "no_speech_prob": 2.6274192350683734e-05}, {"id": 514, "seek": 328640, "start": 3304.64, "end": 3316.1600000000003, "text": " is it, that's pretty easy. Which of these 80,000 things is it, it's pretty hard.", "tokens": [307, 309, 11, 300, 311, 1238, 1858, 13, 3013, 295, 613, 4688, 11, 1360, 721, 307, 309, 11, 309, 311, 1238, 1152, 13], "temperature": 0.0, "avg_logprob": -0.17494172687771953, "compression_ratio": 1.5857988165680474, "no_speech_prob": 2.6274192350683734e-05}, {"id": 515, "seek": 331616, "start": 3316.16, "end": 3323.7999999999997, "text": " So to fine-tune it, it looks very similar to our usual way of fine-tuning things, which", "tokens": [407, 281, 2489, 12, 83, 2613, 309, 11, 309, 1542, 588, 2531, 281, 527, 7713, 636, 295, 2489, 12, 83, 37726, 721, 11, 597], "temperature": 0.0, "avg_logprob": -0.12850204346671937, "compression_ratio": 1.474025974025974, "no_speech_prob": 5.33812408320955e-06}, {"id": 516, "seek": 331616, "start": 3323.7999999999997, "end": 3333.8799999999997, "text": " is that we take our two models and stick them back to back. And we're now going to train", "tokens": [307, 300, 321, 747, 527, 732, 5245, 293, 2897, 552, 646, 281, 646, 13, 400, 321, 434, 586, 516, 281, 3847], "temperature": 0.0, "avg_logprob": -0.12850204346671937, "compression_ratio": 1.474025974025974, "no_speech_prob": 5.33812408320955e-06}, {"id": 517, "seek": 331616, "start": 3333.8799999999997, "end": 3337.2599999999998, "text": " the whole thing rather than just the linear model.", "tokens": [264, 1379, 551, 2831, 813, 445, 264, 8213, 2316, 13], "temperature": 0.0, "avg_logprob": -0.12850204346671937, "compression_ratio": 1.474025974025974, "no_speech_prob": 5.33812408320955e-06}, {"id": 518, "seek": 333726, "start": 3337.26, "end": 3346.44, "text": " Now the problem is that the input to this model is too big to fit in RAM. So how are", "tokens": [823, 264, 1154, 307, 300, 264, 4846, 281, 341, 2316, 307, 886, 955, 281, 3318, 294, 14561, 13, 407, 577, 366], "temperature": 0.0, "avg_logprob": -0.16568030307167456, "compression_ratio": 1.6462264150943395, "no_speech_prob": 1.7061776134141837e-06}, {"id": 519, "seek": 333726, "start": 3346.44, "end": 3353.1600000000003, "text": " we going to call fit or fit-generator when we have an array that's too big to fit in", "tokens": [321, 516, 281, 818, 3318, 420, 3318, 12, 21848, 1639, 562, 321, 362, 364, 10225, 300, 311, 886, 955, 281, 3318, 294], "temperature": 0.0, "avg_logprob": -0.16568030307167456, "compression_ratio": 1.6462264150943395, "no_speech_prob": 1.7061776134141837e-06}, {"id": 520, "seek": 333726, "start": 3353.1600000000003, "end": 3359.6400000000003, "text": " RAM? Well one obvious thing to do would be to pass in the beak-holes array. Because to", "tokens": [14561, 30, 1042, 472, 6322, 551, 281, 360, 576, 312, 281, 1320, 294, 264, 48663, 12, 37894, 10225, 13, 1436, 281], "temperature": 0.0, "avg_logprob": -0.16568030307167456, "compression_ratio": 1.6462264150943395, "no_speech_prob": 1.7061776134141837e-06}, {"id": 521, "seek": 333726, "start": 3359.6400000000003, "end": 3364.48, "text": " most things in Python, a beak-holes array looks just like a regular array. It doesn't really", "tokens": [881, 721, 294, 15329, 11, 257, 48663, 12, 37894, 10225, 1542, 445, 411, 257, 3890, 10225, 13, 467, 1177, 380, 534], "temperature": 0.0, "avg_logprob": -0.16568030307167456, "compression_ratio": 1.6462264150943395, "no_speech_prob": 1.7061776134141837e-06}, {"id": 522, "seek": 336448, "start": 3364.48, "end": 3380.6, "text": " look any different. The way a beak-holes array is actually stored is actually stored in a", "tokens": [574, 604, 819, 13, 440, 636, 257, 48663, 12, 37894, 10225, 307, 767, 12187, 307, 767, 12187, 294, 257], "temperature": 0.0, "avg_logprob": -0.23556787702772353, "compression_ratio": 1.4047619047619047, "no_speech_prob": 6.048891464160988e-06}, {"id": 523, "seek": 336448, "start": 3380.6, "end": 3388.44, "text": " directory, as I'm sure you've noticed. And in that directory, it's got something called", "tokens": [21120, 11, 382, 286, 478, 988, 291, 600, 5694, 13, 400, 294, 300, 21120, 11, 309, 311, 658, 746, 1219], "temperature": 0.0, "avg_logprob": -0.23556787702772353, "compression_ratio": 1.4047619047619047, "no_speech_prob": 6.048891464160988e-06}, {"id": 524, "seek": 338844, "start": 3388.44, "end": 3397.68, "text": " chunk length. I set it to 32 when I created these beak-holes arrays. What it does is it", "tokens": [16635, 4641, 13, 286, 992, 309, 281, 8858, 562, 286, 2942, 613, 48663, 12, 37894, 41011, 13, 708, 309, 775, 307, 309], "temperature": 0.0, "avg_logprob": -0.10545155342589034, "compression_ratio": 1.3206106870229009, "no_speech_prob": 3.785312628679094e-06}, {"id": 525, "seek": 338844, "start": 3397.68, "end": 3407.52, "text": " takes every 32 images and it puts them into a separate file. So each one of these has", "tokens": [2516, 633, 8858, 5267, 293, 309, 8137, 552, 666, 257, 4994, 3991, 13, 407, 1184, 472, 295, 613, 575], "temperature": 0.0, "avg_logprob": -0.10545155342589034, "compression_ratio": 1.3206106870229009, "no_speech_prob": 3.785312628679094e-06}, {"id": 526, "seek": 340752, "start": 3407.52, "end": 3418.44, "text": " 32 images in it, or 32 of the leading axis of the array.", "tokens": [8858, 5267, 294, 309, 11, 420, 8858, 295, 264, 5775, 10298, 295, 264, 10225, 13], "temperature": 0.0, "avg_logprob": -0.1376093178987503, "compression_ratio": 1.5655172413793104, "no_speech_prob": 1.7330472701360122e-06}, {"id": 527, "seek": 340752, "start": 3418.44, "end": 3428.64, "text": " Now if you then try to take this whole array and pass it to.fit in Keras with shuffle,", "tokens": [823, 498, 291, 550, 853, 281, 747, 341, 1379, 10225, 293, 1320, 309, 281, 2411, 6845, 294, 591, 6985, 365, 39426, 11], "temperature": 0.0, "avg_logprob": -0.1376093178987503, "compression_ratio": 1.5655172413793104, "no_speech_prob": 1.7330472701360122e-06}, {"id": 528, "seek": 340752, "start": 3428.64, "end": 3432.6, "text": " it's going to try and grab one thing from here and one thing from here and then one", "tokens": [309, 311, 516, 281, 853, 293, 4444, 472, 551, 490, 510, 293, 472, 551, 490, 510, 293, 550, 472], "temperature": 0.0, "avg_logprob": -0.1376093178987503, "compression_ratio": 1.5655172413793104, "no_speech_prob": 1.7330472701360122e-06}, {"id": 529, "seek": 343260, "start": 3432.6, "end": 3439.56, "text": " thing from here. Here's the bad news. For beak-holes to get one thing out of a chunk,", "tokens": [551, 490, 510, 13, 1692, 311, 264, 1578, 2583, 13, 1171, 48663, 12, 37894, 281, 483, 472, 551, 484, 295, 257, 16635, 11], "temperature": 0.0, "avg_logprob": -0.13763259887695312, "compression_ratio": 1.6519823788546255, "no_speech_prob": 6.144153303466737e-06}, {"id": 530, "seek": 343260, "start": 3439.56, "end": 3445.36, "text": " it has to read and decompress the whole thing. So it has to read and decompress 32 images", "tokens": [309, 575, 281, 1401, 293, 22867, 735, 264, 1379, 551, 13, 407, 309, 575, 281, 1401, 293, 22867, 735, 8858, 5267], "temperature": 0.0, "avg_logprob": -0.13763259887695312, "compression_ratio": 1.6519823788546255, "no_speech_prob": 6.144153303466737e-06}, {"id": 531, "seek": 343260, "start": 3445.36, "end": 3450.68, "text": " in order to give you the one image you asked for. That'd be a disaster. That'd be ridiculously", "tokens": [294, 1668, 281, 976, 291, 264, 472, 3256, 291, 2351, 337, 13, 663, 1116, 312, 257, 11293, 13, 663, 1116, 312, 41358], "temperature": 0.0, "avg_logprob": -0.13763259887695312, "compression_ratio": 1.6519823788546255, "no_speech_prob": 6.144153303466737e-06}, {"id": 532, "seek": 343260, "start": 3450.68, "end": 3452.92, "text": " horribly slow.", "tokens": [45028, 2964, 13], "temperature": 0.0, "avg_logprob": -0.13763259887695312, "compression_ratio": 1.6519823788546255, "no_speech_prob": 6.144153303466737e-06}, {"id": 533, "seek": 343260, "start": 3452.92, "end": 3460.8399999999997, "text": " We didn't have to worry about that when we called predict on batch, because we were going", "tokens": [492, 994, 380, 362, 281, 3292, 466, 300, 562, 321, 1219, 6069, 322, 15245, 11, 570, 321, 645, 516], "temperature": 0.0, "avg_logprob": -0.13763259887695312, "compression_ratio": 1.6519823788546255, "no_speech_prob": 6.144153303466737e-06}, {"id": 534, "seek": 346084, "start": 3460.84, "end": 3472.92, "text": " not shuffling, but we were going in order. It was never grabbing a single image out of", "tokens": [406, 402, 1245, 1688, 11, 457, 321, 645, 516, 294, 1668, 13, 467, 390, 1128, 23771, 257, 2167, 3256, 484, 295], "temperature": 0.0, "avg_logprob": -0.16244484583536783, "compression_ratio": 1.4099378881987579, "no_speech_prob": 2.6016111860371893e-06}, {"id": 535, "seek": 346084, "start": 3472.92, "end": 3479.96, "text": " a chunk. But now that we want to shuffle, it would.", "tokens": [257, 16635, 13, 583, 586, 300, 321, 528, 281, 39426, 11, 309, 576, 13], "temperature": 0.0, "avg_logprob": -0.16244484583536783, "compression_ratio": 1.4099378881987579, "no_speech_prob": 2.6016111860371893e-06}, {"id": 536, "seek": 346084, "start": 3479.96, "end": 3487.1200000000003, "text": " What we've done is somebody very helpfully actually on a Kaggle forum provided something", "tokens": [708, 321, 600, 1096, 307, 2618, 588, 854, 2277, 767, 322, 257, 48751, 22631, 17542, 5649, 746], "temperature": 0.0, "avg_logprob": -0.16244484583536783, "compression_ratio": 1.4099378881987579, "no_speech_prob": 2.6016111860371893e-06}, {"id": 537, "seek": 348712, "start": 3487.12, "end": 3497.12, "text": " called a beak-holes array iterator. The beak-holes array iterator, which was kindly discovered", "tokens": [1219, 257, 48663, 12, 37894, 10225, 17138, 1639, 13, 440, 48663, 12, 37894, 10225, 17138, 1639, 11, 597, 390, 29736, 6941], "temperature": 0.0, "avg_logprob": -0.16347552405463325, "compression_ratio": 1.4108527131782946, "no_speech_prob": 5.422205049399054e-06}, {"id": 538, "seek": 348712, "start": 3497.12, "end": 3507.2, "text": " on the forums actually by somebody named MP Janssen, originally written by this fellow,", "tokens": [322, 264, 26998, 767, 538, 2618, 4926, 14146, 508, 599, 6748, 11, 7993, 3720, 538, 341, 7177, 11], "temperature": 0.0, "avg_logprob": -0.16347552405463325, "compression_ratio": 1.4108527131782946, "no_speech_prob": 5.422205049399054e-06}, {"id": 539, "seek": 350720, "start": 3507.2, "end": 3519.16, "text": " what it does is it provides a Keras compatible generator which grabs an entire chunk at a", "tokens": [437, 309, 775, 307, 309, 6417, 257, 591, 6985, 18218, 19265, 597, 30028, 364, 2302, 16635, 412, 257], "temperature": 0.0, "avg_logprob": -0.1504100970367887, "compression_ratio": 1.5027932960893855, "no_speech_prob": 1.9638009689515457e-06}, {"id": 540, "seek": 350720, "start": 3519.16, "end": 3526.2799999999997, "text": " time. So it's a little bit less random, but given that if this has got 2 million images", "tokens": [565, 13, 407, 309, 311, 257, 707, 857, 1570, 4974, 11, 457, 2212, 300, 498, 341, 575, 658, 568, 2459, 5267], "temperature": 0.0, "avg_logprob": -0.1504100970367887, "compression_ratio": 1.5027932960893855, "no_speech_prob": 1.9638009689515457e-06}, {"id": 541, "seek": 350720, "start": 3526.2799999999997, "end": 3533.56, "text": " in and the chunk length is 32, then it's going to basically create a batch of chunks rather", "tokens": [294, 293, 264, 16635, 4641, 307, 8858, 11, 550, 309, 311, 516, 281, 1936, 1884, 257, 15245, 295, 24004, 2831], "temperature": 0.0, "avg_logprob": -0.1504100970367887, "compression_ratio": 1.5027932960893855, "no_speech_prob": 1.9638009689515457e-06}, {"id": 542, "seek": 353356, "start": 3533.56, "end": 3540.36, "text": " than a batch of images. So that means we have none of the performance problems, and particularly", "tokens": [813, 257, 15245, 295, 5267, 13, 407, 300, 1355, 321, 362, 6022, 295, 264, 3389, 2740, 11, 293, 4098], "temperature": 0.0, "avg_logprob": -0.14118835594080673, "compression_ratio": 1.5432692307692308, "no_speech_prob": 2.090454245262663e-06}, {"id": 543, "seek": 353356, "start": 3540.36, "end": 3545.48, "text": " because we remember originally we randomly shuffled our files, so this whole thing is", "tokens": [570, 321, 1604, 7993, 321, 16979, 402, 33974, 527, 7098, 11, 370, 341, 1379, 551, 307], "temperature": 0.0, "avg_logprob": -0.14118835594080673, "compression_ratio": 1.5432692307692308, "no_speech_prob": 2.090454245262663e-06}, {"id": 544, "seek": 353356, "start": 3545.48, "end": 3550.2, "text": " randomly shuffled anyway. So this is a good trick.", "tokens": [16979, 402, 33974, 4033, 13, 407, 341, 307, 257, 665, 4282, 13], "temperature": 0.0, "avg_logprob": -0.14118835594080673, "compression_ratio": 1.5432692307692308, "no_speech_prob": 2.090454245262663e-06}, {"id": 545, "seek": 353356, "start": 3550.2, "end": 3556.56, "text": " So you'll find the beak-holes array iterator on GitHub. Feel free to take a look at the", "tokens": [407, 291, 603, 915, 264, 48663, 12, 37894, 10225, 17138, 1639, 322, 23331, 13, 14113, 1737, 281, 747, 257, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.14118835594080673, "compression_ratio": 1.5432692307692308, "no_speech_prob": 2.090454245262663e-06}, {"id": 546, "seek": 355656, "start": 3556.56, "end": 3564.44, "text": " code, it's pretty straightforward. There were a few issues with the original version, so", "tokens": [3089, 11, 309, 311, 1238, 15325, 13, 821, 645, 257, 1326, 2663, 365, 264, 3380, 3037, 11, 370], "temperature": 0.0, "avg_logprob": -0.17104644775390626, "compression_ratio": 1.481283422459893, "no_speech_prob": 1.4285430552263279e-05}, {"id": 547, "seek": 355656, "start": 3564.44, "end": 3569.36, "text": " MP Janssen and I have tried to fix it up and I've written some tests for it and he's written", "tokens": [14146, 508, 599, 6748, 293, 286, 362, 3031, 281, 3191, 309, 493, 293, 286, 600, 3720, 512, 6921, 337, 309, 293, 415, 311, 3720], "temperature": 0.0, "avg_logprob": -0.17104644775390626, "compression_ratio": 1.481283422459893, "no_speech_prob": 1.4285430552263279e-05}, {"id": 548, "seek": 355656, "start": 3569.36, "end": 3576.64, "text": " some documentation for it. But if you just want to use it, then it's as simple as writing", "tokens": [512, 14333, 337, 309, 13, 583, 498, 291, 445, 528, 281, 764, 309, 11, 550, 309, 311, 382, 2199, 382, 3579], "temperature": 0.0, "avg_logprob": -0.17104644775390626, "compression_ratio": 1.481283422459893, "no_speech_prob": 1.4285430552263279e-05}, {"id": 549, "seek": 355656, "start": 3576.64, "end": 3577.64, "text": " this.", "tokens": [341, 13], "temperature": 0.0, "avg_logprob": -0.17104644775390626, "compression_ratio": 1.481283422459893, "no_speech_prob": 1.4285430552263279e-05}, {"id": 550, "seek": 357764, "start": 3577.64, "end": 3587.44, "text": " La equals beak-holes array iterator, this is your data, these are your labels, shuffle", "tokens": [2369, 6915, 48663, 12, 37894, 10225, 17138, 1639, 11, 341, 307, 428, 1412, 11, 613, 366, 428, 16949, 11, 39426], "temperature": 0.0, "avg_logprob": -0.23011487937835326, "compression_ratio": 1.5970873786407767, "no_speech_prob": 6.43900102659245e-06}, {"id": 551, "seek": 357764, "start": 3587.44, "end": 3589.68, "text": " equals true, batch size equals whatever, and then you can just call fit generator as per", "tokens": [6915, 2074, 11, 15245, 2744, 6915, 2035, 11, 293, 550, 291, 393, 445, 818, 3318, 19265, 382, 680], "temperature": 0.0, "avg_logprob": -0.23011487937835326, "compression_ratio": 1.5970873786407767, "no_speech_prob": 6.43900102659245e-06}, {"id": 552, "seek": 357764, "start": 3589.68, "end": 3598.24, "text": " usual passing in that iterator and that iterator's number of items.", "tokens": [7713, 8437, 294, 300, 17138, 1639, 293, 300, 17138, 1639, 311, 1230, 295, 4754, 13], "temperature": 0.0, "avg_logprob": -0.23011487937835326, "compression_ratio": 1.5970873786407767, "no_speech_prob": 6.43900102659245e-06}, {"id": 553, "seek": 357764, "start": 3598.24, "end": 3603.3599999999997, "text": " So to all of you guys who have been asking how do I deal with data that's bigger than", "tokens": [407, 281, 439, 295, 291, 1074, 567, 362, 668, 3365, 577, 360, 286, 2028, 365, 1412, 300, 311, 3801, 813], "temperature": 0.0, "avg_logprob": -0.23011487937835326, "compression_ratio": 1.5970873786407767, "no_speech_prob": 6.43900102659245e-06}, {"id": 554, "seek": 360336, "start": 3603.36, "end": 3614.04, "text": " memory, this is how you do it. So hopefully that will make life easier for a lot of people.", "tokens": [4675, 11, 341, 307, 577, 291, 360, 309, 13, 407, 4696, 300, 486, 652, 993, 3571, 337, 257, 688, 295, 561, 13], "temperature": 0.0, "avg_logprob": -0.12963363286611196, "compression_ratio": 1.4945054945054945, "no_speech_prob": 2.046248846454546e-05}, {"id": 555, "seek": 360336, "start": 3614.04, "end": 3621.52, "text": " So we fine-tune it for a while, we do some learning and annealing for a while. And this", "tokens": [407, 321, 2489, 12, 83, 2613, 309, 337, 257, 1339, 11, 321, 360, 512, 2539, 293, 22256, 4270, 337, 257, 1339, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.12963363286611196, "compression_ratio": 1.4945054945054945, "no_speech_prob": 2.046248846454546e-05}, {"id": 556, "seek": 360336, "start": 3621.52, "end": 3629.32, "text": " basically runs overnight for me, takes about 6 hours to run. So I come back the next morning", "tokens": [1936, 6676, 13935, 337, 385, 11, 2516, 466, 1386, 2496, 281, 1190, 13, 407, 286, 808, 646, 264, 958, 2446], "temperature": 0.0, "avg_logprob": -0.12963363286611196, "compression_ratio": 1.4945054945054945, "no_speech_prob": 2.046248846454546e-05}, {"id": 557, "seek": 362932, "start": 3629.32, "end": 3635.76, "text": " and I just copy and paste my k nearest neighbors, so I call predict, I get my predicted word", "tokens": [293, 286, 445, 5055, 293, 9163, 452, 350, 23831, 12512, 11, 370, 286, 818, 6069, 11, 286, 483, 452, 19147, 1349], "temperature": 0.0, "avg_logprob": -0.23122108623545656, "compression_ratio": 1.59375, "no_speech_prob": 8.749929838813841e-05}, {"id": 558, "seek": 362932, "start": 3635.76, "end": 3641.92, "text": " vectors. For each word vector, I then pass it into nearest neighbors, this is my just", "tokens": [18875, 13, 1171, 1184, 1349, 8062, 11, 286, 550, 1320, 309, 666, 23831, 12512, 11, 341, 307, 452, 445], "temperature": 0.0, "avg_logprob": -0.23122108623545656, "compression_ratio": 1.59375, "no_speech_prob": 8.749929838813841e-05}, {"id": 559, "seek": 362932, "start": 3641.92, "end": 3650.92, "text": " thousand categories. And lo and behold, we now have Kelo in the top spot as we hoped.", "tokens": [4714, 10479, 13, 400, 450, 293, 27234, 11, 321, 586, 362, 591, 10590, 294, 264, 1192, 4008, 382, 321, 19737, 13], "temperature": 0.0, "avg_logprob": -0.23122108623545656, "compression_ratio": 1.59375, "no_speech_prob": 8.749929838813841e-05}, {"id": 560, "seek": 362932, "start": 3650.92, "end": 3656.6000000000004, "text": " How did it go in the harder problem of looking at the 100,000 or so nouns in English? Pretty", "tokens": [1012, 630, 309, 352, 294, 264, 6081, 1154, 295, 1237, 412, 264, 2319, 11, 1360, 420, 370, 48184, 294, 3669, 30, 10693], "temperature": 0.0, "avg_logprob": -0.23122108623545656, "compression_ratio": 1.59375, "no_speech_prob": 8.749929838813841e-05}, {"id": 561, "seek": 365660, "start": 3656.6, "end": 3662.0, "text": " good. I got this one right, and just to pick another one at random, let's pick the first", "tokens": [665, 13, 286, 658, 341, 472, 558, 11, 293, 445, 281, 1888, 1071, 472, 412, 4974, 11, 718, 311, 1888, 264, 700], "temperature": 0.0, "avg_logprob": -0.15683957033379134, "compression_ratio": 1.6105769230769231, "no_speech_prob": 8.139582860167138e-06}, {"id": 562, "seek": 365660, "start": 3662.0, "end": 3669.16, "text": " one, it said throne, that sure looks like a throne. So looking pretty good.", "tokens": [472, 11, 309, 848, 17678, 11, 300, 988, 1542, 411, 257, 17678, 13, 407, 1237, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.15683957033379134, "compression_ratio": 1.6105769230769231, "no_speech_prob": 8.139582860167138e-06}, {"id": 563, "seek": 365660, "start": 3669.16, "end": 3674.44, "text": " So here's something interesting. Now that we have brought images and words into the", "tokens": [407, 510, 311, 746, 1880, 13, 823, 300, 321, 362, 3038, 5267, 293, 2283, 666, 264], "temperature": 0.0, "avg_logprob": -0.15683957033379134, "compression_ratio": 1.6105769230769231, "no_speech_prob": 8.139582860167138e-06}, {"id": 564, "seek": 365660, "start": 3674.44, "end": 3682.44, "text": " same space, let's play with that some more. So why don't we use nearest neighbors with", "tokens": [912, 1901, 11, 718, 311, 862, 365, 300, 512, 544, 13, 407, 983, 500, 380, 321, 764, 23831, 12512, 365], "temperature": 0.0, "avg_logprob": -0.15683957033379134, "compression_ratio": 1.6105769230769231, "no_speech_prob": 8.139582860167138e-06}, {"id": 565, "seek": 368244, "start": 3682.44, "end": 3689.44, "text": " those predictions.", "tokens": [729, 21264, 13], "temperature": 0.0, "avg_logprob": -0.3534405781672551, "compression_ratio": 1.1473684210526316, "no_speech_prob": 0.00012147590314270929}, {"id": 566, "seek": 368244, "start": 3689.44, "end": 3709.2400000000002, "text": " To the word vector which Google created, but the subset of those which are nouns according", "tokens": [1407, 264, 1349, 8062, 597, 3329, 2942, 11, 457, 264, 25993, 295, 729, 597, 366, 48184, 4650], "temperature": 0.0, "avg_logprob": -0.3534405781672551, "compression_ratio": 1.1473684210526316, "no_speech_prob": 0.00012147590314270929}, {"id": 567, "seek": 370924, "start": 3709.24, "end": 3719.24, "text": " to wordnet mapped to their sense set IDs.", "tokens": [281, 1349, 7129, 33318, 281, 641, 2020, 992, 48212, 13], "temperature": 0.0, "avg_logprob": -0.40400805840125453, "compression_ratio": 1.3555555555555556, "no_speech_prob": 4.469319901545532e-05}, {"id": 568, "seek": 370924, "start": 3719.24, "end": 3725.68, "text": " So the word vectors are just the word2vec vectors that we can download off the internet.", "tokens": [407, 264, 1349, 18875, 366, 445, 264, 1349, 17, 303, 66, 18875, 300, 321, 393, 5484, 766, 264, 4705, 13], "temperature": 0.0, "avg_logprob": -0.40400805840125453, "compression_ratio": 1.3555555555555556, "no_speech_prob": 4.469319901545532e-05}, {"id": 569, "seek": 370924, "start": 3725.68, "end": 3732.12, "text": " They were pre-trained by Google. They're embeddings.", "tokens": [814, 645, 659, 12, 17227, 2001, 538, 3329, 13, 814, 434, 12240, 29432, 13], "temperature": 0.0, "avg_logprob": -0.40400805840125453, "compression_ratio": 1.3555555555555556, "no_speech_prob": 4.469319901545532e-05}, {"id": 570, "seek": 373212, "start": 3732.12, "end": 3742.16, "text": " So we're comparing the proximity of word to image.", "tokens": [407, 321, 434, 15763, 264, 27632, 295, 1349, 281, 3256, 13], "temperature": 0.0, "avg_logprob": -0.25037880866758283, "compression_ratio": 1.4242424242424243, "no_speech_prob": 4.356860245025018e-06}, {"id": 571, "seek": 373212, "start": 3742.16, "end": 3752.24, "text": " Yes, exactly. So we're saying this image spits out a vector from the thing we just trained.", "tokens": [1079, 11, 2293, 13, 407, 321, 434, 1566, 341, 3256, 637, 1208, 484, 257, 8062, 490, 264, 551, 321, 445, 8895, 13], "temperature": 0.0, "avg_logprob": -0.25037880866758283, "compression_ratio": 1.4242424242424243, "no_speech_prob": 4.356860245025018e-06}, {"id": 572, "seek": 373212, "start": 3752.24, "end": 3761.52, "text": " We have 100,000 word vectors for all the nouns in English. Which one of those is the closest", "tokens": [492, 362, 2319, 11, 1360, 1349, 18875, 337, 439, 264, 48184, 294, 3669, 13, 3013, 472, 295, 729, 307, 264, 13699], "temperature": 0.0, "avg_logprob": -0.25037880866758283, "compression_ratio": 1.4242424242424243, "no_speech_prob": 4.356860245025018e-06}, {"id": 573, "seek": 376152, "start": 3761.52, "end": 3775.36, "text": " to the thing that came out of our model? And the answer was throne.", "tokens": [281, 264, 551, 300, 1361, 484, 295, 527, 2316, 30, 400, 264, 1867, 390, 17678, 13], "temperature": 0.0, "avg_logprob": -0.2651454556372858, "compression_ratio": 1.436046511627907, "no_speech_prob": 5.06434626004193e-05}, {"id": 574, "seek": 376152, "start": 3775.36, "end": 3783.8, "text": " Hold that thought, we'll be doing language translation starting next week. So let's do", "tokens": [6962, 300, 1194, 11, 321, 603, 312, 884, 2856, 12853, 2891, 958, 1243, 13, 407, 718, 311, 360], "temperature": 0.0, "avg_logprob": -0.2651454556372858, "compression_ratio": 1.436046511627907, "no_speech_prob": 5.06434626004193e-05}, {"id": 575, "seek": 376152, "start": 3783.8, "end": 3791.44, "text": " something interesting. Let's create a nearest neighbors not for all of the word2vec vectors,", "tokens": [746, 1880, 13, 961, 311, 1884, 257, 23831, 12512, 406, 337, 439, 295, 264, 1349, 17, 303, 66, 18875, 11], "temperature": 0.0, "avg_logprob": -0.2651454556372858, "compression_ratio": 1.436046511627907, "no_speech_prob": 5.06434626004193e-05}, {"id": 576, "seek": 379144, "start": 3791.44, "end": 3797.52, "text": " but for all of our image predicted vectors. And now we can do the opposite. Let's take", "tokens": [457, 337, 439, 295, 527, 3256, 19147, 18875, 13, 400, 586, 321, 393, 360, 264, 6182, 13, 961, 311, 747], "temperature": 0.0, "avg_logprob": -0.16936827487632877, "compression_ratio": 1.4304635761589404, "no_speech_prob": 1.012992379401112e-05}, {"id": 577, "seek": 379144, "start": 3797.52, "end": 3803.94, "text": " a word, pick it random, let's look it up in our word2vec dictionary, and let's find the", "tokens": [257, 1349, 11, 1888, 309, 4974, 11, 718, 311, 574, 309, 493, 294, 527, 1349, 17, 303, 66, 25890, 11, 293, 718, 311, 915, 264], "temperature": 0.0, "avg_logprob": -0.16936827487632877, "compression_ratio": 1.4304635761589404, "no_speech_prob": 1.012992379401112e-05}, {"id": 578, "seek": 379144, "start": 3803.94, "end": 3814.28, "text": " nearest neighbors for that in our images.", "tokens": [23831, 12512, 337, 300, 294, 527, 5267, 13], "temperature": 0.0, "avg_logprob": -0.16936827487632877, "compression_ratio": 1.4304635761589404, "no_speech_prob": 1.012992379401112e-05}, {"id": 579, "seek": 381428, "start": 3814.28, "end": 3824.2400000000002, "text": " So this is pretty interesting. You can now find the images that are the most like whatever", "tokens": [407, 341, 307, 1238, 1880, 13, 509, 393, 586, 915, 264, 5267, 300, 366, 264, 881, 411, 2035], "temperature": 0.0, "avg_logprob": -0.18918489039629355, "compression_ratio": 1.5248868778280542, "no_speech_prob": 1.280539345316356e-05}, {"id": 580, "seek": 381428, "start": 3824.2400000000002, "end": 3830.5600000000004, "text": " word you come up with. So that's crazy, but we can do crazier.", "tokens": [1349, 291, 808, 493, 365, 13, 407, 300, 311, 3219, 11, 457, 321, 393, 360, 2094, 33352, 13], "temperature": 0.0, "avg_logprob": -0.18918489039629355, "compression_ratio": 1.5248868778280542, "no_speech_prob": 1.280539345316356e-05}, {"id": 581, "seek": 381428, "start": 3830.5600000000004, "end": 3834.6000000000004, "text": " Here is a random thing I picked. Now notice I picked it from the validation set of ImageNet,", "tokens": [1692, 307, 257, 4974, 551, 286, 6183, 13, 823, 3449, 286, 6183, 309, 490, 264, 24071, 992, 295, 29903, 31890, 11], "temperature": 0.0, "avg_logprob": -0.18918489039629355, "compression_ratio": 1.5248868778280542, "no_speech_prob": 1.280539345316356e-05}, {"id": 582, "seek": 381428, "start": 3834.6000000000004, "end": 3839.1600000000003, "text": " so we've never seen this image before. Honestly when I opened it up, my heart sank because", "tokens": [370, 321, 600, 1128, 1612, 341, 3256, 949, 13, 12348, 562, 286, 5625, 309, 493, 11, 452, 1917, 43746, 570], "temperature": 0.0, "avg_logprob": -0.18918489039629355, "compression_ratio": 1.5248868778280542, "no_speech_prob": 1.280539345316356e-05}, {"id": 583, "seek": 383916, "start": 3839.16, "end": 3852.08, "text": " I don't know what it is. So this is a problem. What is that? So what we can do is we can", "tokens": [286, 500, 380, 458, 437, 309, 307, 13, 407, 341, 307, 257, 1154, 13, 708, 307, 300, 30, 407, 437, 321, 393, 360, 307, 321, 393], "temperature": 0.0, "avg_logprob": -0.16679047902425131, "compression_ratio": 1.544378698224852, "no_speech_prob": 1.0289405508956406e-05}, {"id": 584, "seek": 383916, "start": 3852.08, "end": 3857.72, "text": " call.predict on that image, and we can then do a nearest neighbors of all of our other", "tokens": [818, 2411, 79, 24945, 322, 300, 3256, 11, 293, 321, 393, 550, 360, 257, 23831, 12512, 295, 439, 295, 527, 661], "temperature": 0.0, "avg_logprob": -0.16679047902425131, "compression_ratio": 1.544378698224852, "no_speech_prob": 1.0289405508956406e-05}, {"id": 585, "seek": 383916, "start": 3857.72, "end": 3865.2799999999997, "text": " images. And there's the first, there's the second, and the third one is even somebody", "tokens": [5267, 13, 400, 456, 311, 264, 700, 11, 456, 311, 264, 1150, 11, 293, 264, 2636, 472, 307, 754, 2618], "temperature": 0.0, "avg_logprob": -0.16679047902425131, "compression_ratio": 1.544378698224852, "no_speech_prob": 1.0289405508956406e-05}, {"id": 586, "seek": 386528, "start": 3865.28, "end": 3871.7200000000003, "text": " putting their hand on it, which is slightly crazy, but that was what the original one", "tokens": [3372, 641, 1011, 322, 309, 11, 597, 307, 4748, 3219, 11, 457, 300, 390, 437, 264, 3380, 472], "temperature": 0.0, "avg_logprob": -0.21088871865902306, "compression_ratio": 1.4264705882352942, "no_speech_prob": 3.269887747592293e-05}, {"id": 587, "seek": 386528, "start": 3871.7200000000003, "end": 3873.84, "text": " looked like.", "tokens": [2956, 411, 13], "temperature": 0.0, "avg_logprob": -0.21088871865902306, "compression_ratio": 1.4264705882352942, "no_speech_prob": 3.269887747592293e-05}, {"id": 588, "seek": 386528, "start": 3873.84, "end": 3892.6800000000003, "text": " In fact, I ran it again on a different image. I took this one, which is like pretty, I actually", "tokens": [682, 1186, 11, 286, 5872, 309, 797, 322, 257, 819, 3256, 13, 286, 1890, 341, 472, 11, 597, 307, 411, 1238, 11, 286, 767], "temperature": 0.0, "avg_logprob": -0.21088871865902306, "compression_ratio": 1.4264705882352942, "no_speech_prob": 3.269887747592293e-05}, {"id": 589, "seek": 389268, "start": 3892.68, "end": 3895.56, "text": " looked around for something weird. This is pretty weird, right? Is this a net or is it", "tokens": [2956, 926, 337, 746, 3657, 13, 639, 307, 1238, 3657, 11, 558, 30, 1119, 341, 257, 2533, 420, 307, 309], "temperature": 0.0, "avg_logprob": -0.23938569155606357, "compression_ratio": 1.3166666666666667, "no_speech_prob": 3.373608706169762e-05}, {"id": 590, "seek": 389268, "start": 3895.56, "end": 3903.12, "text": " a fish? So when we then ask for nearest neighbors, we get fish in nets.", "tokens": [257, 3506, 30, 407, 562, 321, 550, 1029, 337, 23831, 12512, 11, 321, 483, 3506, 294, 36170, 13], "temperature": 0.0, "avg_logprob": -0.23938569155606357, "compression_ratio": 1.3166666666666667, "no_speech_prob": 3.373608706169762e-05}, {"id": 591, "seek": 390312, "start": 3903.12, "end": 3923.44, "text": " So it's like, I don't know, sometimes deep learning is so magic, you just kind of go", "tokens": [407, 309, 311, 411, 11, 286, 500, 380, 458, 11, 2171, 2452, 2539, 307, 370, 5585, 11, 291, 445, 733, 295, 352], "temperature": 0.0, "avg_logprob": -0.4503500538487588, "compression_ratio": 1.0919540229885059, "no_speech_prob": 4.5395547203952447e-05}, {"id": 592, "seek": 390312, "start": 3923.44, "end": 3927.6, "text": " out there.", "tokens": [484, 456, 13], "temperature": 0.0, "avg_logprob": -0.4503500538487588, "compression_ratio": 1.0919540229885059, "no_speech_prob": 4.5395547203952447e-05}, {"id": 593, "seek": 392760, "start": 3927.6, "end": 3933.04, "text": " Only a little bit, and maybe in a future course we might look at Dask, and I think maybe even", "tokens": [5686, 257, 707, 857, 11, 293, 1310, 294, 257, 2027, 1164, 321, 1062, 574, 412, 2846, 74, 11, 293, 286, 519, 1310, 754], "temperature": 0.0, "avg_logprob": -0.26034129293341385, "compression_ratio": 1.539877300613497, "no_speech_prob": 1.952552884176839e-05}, {"id": 594, "seek": 392760, "start": 3933.04, "end": 3937.04, "text": " in your numerical and your algebra course you might be looking at Dask. I don't think", "tokens": [294, 428, 29054, 293, 428, 21989, 1164, 291, 1062, 312, 1237, 412, 2846, 74, 13, 286, 500, 380, 519], "temperature": 0.0, "avg_logprob": -0.26034129293341385, "compression_ratio": 1.539877300613497, "no_speech_prob": 1.952552884176839e-05}, {"id": 595, "seek": 392760, "start": 3937.04, "end": 3944.92, "text": " we'll cover this course. But do look at Dask, D-A-S-K, it's super cool.", "tokens": [321, 603, 2060, 341, 1164, 13, 583, 360, 574, 412, 2846, 74, 11, 413, 12, 32, 12, 50, 12, 42, 11, 309, 311, 1687, 1627, 13], "temperature": 0.0, "avg_logprob": -0.26034129293341385, "compression_ratio": 1.539877300613497, "no_speech_prob": 1.952552884176839e-05}, {"id": 596, "seek": 394492, "start": 3944.92, "end": 3957.6800000000003, "text": " Question asked.", "tokens": [14464, 2351, 13], "temperature": 0.0, "avg_logprob": -0.26645498275756835, "compression_ratio": 1.4057971014492754, "no_speech_prob": 3.647719495347701e-05}, {"id": 597, "seek": 394492, "start": 3957.6800000000003, "end": 3962.52, "text": " These were actually labeled as this particular kind of fish. In fact that's the other thing,", "tokens": [1981, 645, 767, 21335, 382, 341, 1729, 733, 295, 3506, 13, 682, 1186, 300, 311, 264, 661, 551, 11], "temperature": 0.0, "avg_logprob": -0.26645498275756835, "compression_ratio": 1.4057971014492754, "no_speech_prob": 3.647719495347701e-05}, {"id": 598, "seek": 394492, "start": 3962.52, "end": 3966.96, "text": " it's not only found fish in nets, but it's actually found more or less the same breed", "tokens": [309, 311, 406, 787, 1352, 3506, 294, 36170, 11, 457, 309, 311, 767, 1352, 544, 420, 1570, 264, 912, 18971], "temperature": 0.0, "avg_logprob": -0.26645498275756835, "compression_ratio": 1.4057971014492754, "no_speech_prob": 3.647719495347701e-05}, {"id": 599, "seek": 396696, "start": 3966.96, "end": 3979.8, "text": " of fish in the nets. But when we called.predict on those, it created a word vector which was", "tokens": [295, 3506, 294, 264, 36170, 13, 583, 562, 321, 1219, 2411, 79, 24945, 322, 729, 11, 309, 2942, 257, 1349, 8062, 597, 390], "temperature": 0.0, "avg_logprob": -0.16896179744175502, "compression_ratio": 1.6635514018691588, "no_speech_prob": 6.540393769682851e-06}, {"id": 600, "seek": 396696, "start": 3979.8, "end": 3987.84, "text": " probably like halfway between that kind of fish and a net because it doesn't know what", "tokens": [1391, 411, 15461, 1296, 300, 733, 295, 3506, 293, 257, 2533, 570, 309, 1177, 380, 458, 437], "temperature": 0.0, "avg_logprob": -0.16896179744175502, "compression_ratio": 1.6635514018691588, "no_speech_prob": 6.540393769682851e-06}, {"id": 601, "seek": 396696, "start": 3987.84, "end": 3991.8, "text": " to do. So sometimes when it sees things like that, it would have been marked in the image", "tokens": [281, 360, 13, 407, 2171, 562, 309, 8194, 721, 411, 300, 11, 309, 576, 362, 668, 12658, 294, 264, 3256], "temperature": 0.0, "avg_logprob": -0.16896179744175502, "compression_ratio": 1.6635514018691588, "no_speech_prob": 6.540393769682851e-06}, {"id": 602, "seek": 396696, "start": 3991.8, "end": 3996.08, "text": " net as a net, and sometimes it would have been a fish. So the best way to minimize the", "tokens": [2533, 382, 257, 2533, 11, 293, 2171, 309, 576, 362, 668, 257, 3506, 13, 407, 264, 1151, 636, 281, 17522, 264], "temperature": 0.0, "avg_logprob": -0.16896179744175502, "compression_ratio": 1.6635514018691588, "no_speech_prob": 6.540393769682851e-06}, {"id": 603, "seek": 399608, "start": 3996.08, "end": 4001.4, "text": " loss function would have been to kind of hedge. So it hedged and as a result the images that", "tokens": [4470, 2445, 576, 362, 668, 281, 733, 295, 25304, 13, 407, 309, 33653, 3004, 293, 382, 257, 1874, 264, 5267, 300], "temperature": 0.0, "avg_logprob": -0.24335173460153434, "compression_ratio": 1.4965034965034965, "no_speech_prob": 1.5689414794906043e-05}, {"id": 604, "seek": 399608, "start": 4001.4, "end": 4006.7999999999997, "text": " were closest were the ones which actually were halfway between the two themselves. So", "tokens": [645, 13699, 645, 264, 2306, 597, 767, 645, 15461, 1296, 264, 732, 2969, 13, 407], "temperature": 0.0, "avg_logprob": -0.24335173460153434, "compression_ratio": 1.4965034965034965, "no_speech_prob": 1.5689414794906043e-05}, {"id": 605, "seek": 399608, "start": 4006.7999999999997, "end": 4009.6, "text": " it's kind of a convenient accident.", "tokens": [309, 311, 733, 295, 257, 10851, 6398, 13], "temperature": 0.0, "avg_logprob": -0.24335173460153434, "compression_ratio": 1.4965034965034965, "no_speech_prob": 1.5689414794906043e-05}, {"id": 606, "seek": 400960, "start": 4009.6, "end": 4033.8399999999997, "text": " Question asked.", "tokens": [14464, 2351, 13], "temperature": 0.0, "avg_logprob": -0.20165863743534795, "compression_ratio": 1.1290322580645162, "no_speech_prob": 2.3187074475572444e-05}, {"id": 607, "seek": 400960, "start": 4033.8399999999997, "end": 4038.8399999999997, "text": " You absolutely can and I have, but really for nearest neighbors, I haven't found anything", "tokens": [509, 3122, 393, 293, 286, 362, 11, 457, 534, 337, 23831, 12512, 11, 286, 2378, 380, 1352, 1340], "temperature": 0.0, "avg_logprob": -0.20165863743534795, "compression_ratio": 1.1290322580645162, "no_speech_prob": 2.3187074475572444e-05}, {"id": 608, "seek": 403884, "start": 4038.84, "end": 4045.6400000000003, "text": " nearly as good as cosine, and that's true in all of the things I looked up as well.", "tokens": [6217, 382, 665, 382, 23565, 11, 293, 300, 311, 2074, 294, 439, 295, 264, 721, 286, 2956, 493, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.16865268913475243, "compression_ratio": 1.4864864864864864, "no_speech_prob": 2.54657534242142e-05}, {"id": 609, "seek": 403884, "start": 4045.6400000000003, "end": 4051.44, "text": " By the way, I should mention, when you use locality-sensitive hashing in Python, by default", "tokens": [3146, 264, 636, 11, 286, 820, 2152, 11, 562, 291, 764, 1628, 1860, 12, 82, 34465, 575, 571, 294, 15329, 11, 538, 7576], "temperature": 0.0, "avg_logprob": -0.16865268913475243, "compression_ratio": 1.4864864864864864, "no_speech_prob": 2.54657534242142e-05}, {"id": 610, "seek": 403884, "start": 4051.44, "end": 4055.76, "text": " it uses something that's equivalent to the cosine metric, so that's why the nearest neighbors", "tokens": [309, 4960, 746, 300, 311, 10344, 281, 264, 23565, 20678, 11, 370, 300, 311, 983, 264, 23831, 12512], "temperature": 0.0, "avg_logprob": -0.16865268913475243, "compression_ratio": 1.4864864864864864, "no_speech_prob": 2.54657534242142e-05}, {"id": 611, "seek": 403884, "start": 4055.76, "end": 4058.76, "text": " work.", "tokens": [589, 13], "temperature": 0.0, "avg_logprob": -0.16865268913475243, "compression_ratio": 1.4864864864864864, "no_speech_prob": 2.54657534242142e-05}, {"id": 612, "seek": 405876, "start": 4058.76, "end": 4070.92, "text": " Starting next week, we're going to be learning about sequence-to-sequence models and memory", "tokens": [16217, 958, 1243, 11, 321, 434, 516, 281, 312, 2539, 466, 8310, 12, 1353, 12, 11834, 655, 5245, 293, 4675], "temperature": 0.0, "avg_logprob": -0.09456083747778046, "compression_ratio": 1.6775700934579438, "no_speech_prob": 1.0289278179698158e-05}, {"id": 613, "seek": 405876, "start": 4070.92, "end": 4077.0, "text": " and attention methods. They're going to show us how we can take an input such as a sentence", "tokens": [293, 3202, 7150, 13, 814, 434, 516, 281, 855, 505, 577, 321, 393, 747, 364, 4846, 1270, 382, 257, 8174], "temperature": 0.0, "avg_logprob": -0.09456083747778046, "compression_ratio": 1.6775700934579438, "no_speech_prob": 1.0289278179698158e-05}, {"id": 614, "seek": 405876, "start": 4077.0, "end": 4081.82, "text": " in English and spit out an output such as a sentence in French, which is the particular", "tokens": [294, 3669, 293, 22127, 484, 364, 5598, 1270, 382, 257, 8174, 294, 5522, 11, 597, 307, 264, 1729], "temperature": 0.0, "avg_logprob": -0.09456083747778046, "compression_ratio": 1.6775700934579438, "no_speech_prob": 1.0289278179698158e-05}, {"id": 615, "seek": 405876, "start": 4081.82, "end": 4087.36, "text": " case study we're going to be spending 2 or 3 weeks on. When you combine that with this,", "tokens": [1389, 2979, 321, 434, 516, 281, 312, 6434, 568, 420, 805, 3259, 322, 13, 1133, 291, 10432, 300, 365, 341, 11], "temperature": 0.0, "avg_logprob": -0.09456083747778046, "compression_ratio": 1.6775700934579438, "no_speech_prob": 1.0289278179698158e-05}, {"id": 616, "seek": 408736, "start": 4087.36, "end": 4091.84, "text": " you get image captioning. I'm not sure if we're going to have time to do it ourselves,", "tokens": [291, 483, 3256, 31974, 278, 13, 286, 478, 406, 988, 498, 321, 434, 516, 281, 362, 565, 281, 360, 309, 4175, 11], "temperature": 0.0, "avg_logprob": -0.1349492151229108, "compression_ratio": 1.5063291139240507, "no_speech_prob": 1.8342636394663714e-05}, {"id": 617, "seek": 408736, "start": 4091.84, "end": 4098.4400000000005, "text": " but it will literally be trivial for you guys to take the two things and combine them and", "tokens": [457, 309, 486, 3736, 312, 26703, 337, 291, 1074, 281, 747, 264, 732, 721, 293, 10432, 552, 293], "temperature": 0.0, "avg_logprob": -0.1349492151229108, "compression_ratio": 1.5063291139240507, "no_speech_prob": 1.8342636394663714e-05}, {"id": 618, "seek": 408736, "start": 4098.4400000000005, "end": 4106.0, "text": " do image captioning. It's just those two techniques together.", "tokens": [360, 3256, 31974, 278, 13, 467, 311, 445, 729, 732, 7512, 1214, 13], "temperature": 0.0, "avg_logprob": -0.1349492151229108, "compression_ratio": 1.5063291139240507, "no_speech_prob": 1.8342636394663714e-05}, {"id": 619, "seek": 410600, "start": 4106.0, "end": 4121.68, "text": " So we're now going to switch to the homework. Hopefully you guys noticed I gave you some", "tokens": [407, 321, 434, 586, 516, 281, 3679, 281, 264, 14578, 13, 10429, 291, 1074, 5694, 286, 2729, 291, 512], "temperature": 0.0, "avg_logprob": -0.19408555890693038, "compression_ratio": 1.455497382198953, "no_speech_prob": 3.426790135563351e-05}, {"id": 620, "seek": 410600, "start": 4121.68, "end": 4127.88, "text": " tips because it was a really challenging one. Even though in a sense it was kind of straightforward,", "tokens": [6082, 570, 309, 390, 257, 534, 7595, 472, 13, 2754, 1673, 294, 257, 2020, 309, 390, 733, 295, 15325, 11], "temperature": 0.0, "avg_logprob": -0.19408555890693038, "compression_ratio": 1.455497382198953, "no_speech_prob": 3.426790135563351e-05}, {"id": 621, "seek": 410600, "start": 4127.88, "end": 4131.52, "text": " which was take everything that we've already learned about super resolution and slightly", "tokens": [597, 390, 747, 1203, 300, 321, 600, 1217, 3264, 466, 1687, 8669, 293, 4748], "temperature": 0.0, "avg_logprob": -0.19408555890693038, "compression_ratio": 1.455497382198953, "no_speech_prob": 3.426790135563351e-05}, {"id": 622, "seek": 413152, "start": 4131.52, "end": 4136.8, "text": " change the loss function so that it does perceptual losses for style transfer instead, the details", "tokens": [1319, 264, 4470, 2445, 370, 300, 309, 775, 43276, 901, 15352, 337, 3758, 5003, 2602, 11, 264, 4365], "temperature": 0.0, "avg_logprob": -0.1669741793795749, "compression_ratio": 1.6197718631178708, "no_speech_prob": 1.0451390153320972e-05}, {"id": 623, "seek": 413152, "start": 4136.8, "end": 4137.8, "text": " were tricky.", "tokens": [645, 12414, 13], "temperature": 0.0, "avg_logprob": -0.1669741793795749, "compression_ratio": 1.6197718631178708, "no_speech_prob": 1.0451390153320972e-05}, {"id": 624, "seek": 413152, "start": 4137.8, "end": 4141.88, "text": " I'm going to quickly show you two things. First, we're going to show you how I did the", "tokens": [286, 478, 516, 281, 2661, 855, 291, 732, 721, 13, 2386, 11, 321, 434, 516, 281, 855, 291, 577, 286, 630, 264], "temperature": 0.0, "avg_logprob": -0.1669741793795749, "compression_ratio": 1.6197718631178708, "no_speech_prob": 1.0451390153320972e-05}, {"id": 625, "seek": 413152, "start": 4141.88, "end": 4147.8, "text": " homework because I actually hadn't done it last week. Luckily I have enough RAM that", "tokens": [14578, 570, 286, 767, 8782, 380, 1096, 309, 1036, 1243, 13, 19726, 286, 362, 1547, 14561, 300], "temperature": 0.0, "avg_logprob": -0.1669741793795749, "compression_ratio": 1.6197718631178708, "no_speech_prob": 1.0451390153320972e-05}, {"id": 626, "seek": 413152, "start": 4147.8, "end": 4151.8, "text": " I could read the two things all into memory, so don't forget you can just do that with", "tokens": [286, 727, 1401, 264, 732, 721, 439, 666, 4675, 11, 370, 500, 380, 2870, 291, 393, 445, 360, 300, 365], "temperature": 0.0, "avg_logprob": -0.1669741793795749, "compression_ratio": 1.6197718631178708, "no_speech_prob": 1.0451390153320972e-05}, {"id": 627, "seek": 413152, "start": 4151.8, "end": 4157.52, "text": " a bcalls array to turn it into a NumPy array in memory.", "tokens": [257, 272, 66, 39655, 10225, 281, 1261, 309, 666, 257, 22592, 47, 88, 10225, 294, 4675, 13], "temperature": 0.0, "avg_logprob": -0.1669741793795749, "compression_ratio": 1.6197718631178708, "no_speech_prob": 1.0451390153320972e-05}, {"id": 628, "seek": 415752, "start": 4157.52, "end": 4162.96, "text": " So one thing I did was I created my upsampling block to get rid of the checkerboard patterns.", "tokens": [407, 472, 551, 286, 630, 390, 286, 2942, 452, 15497, 335, 11970, 3461, 281, 483, 3973, 295, 264, 1520, 260, 3787, 8294, 13], "temperature": 0.0, "avg_logprob": -0.16004573867981692, "compression_ratio": 1.670391061452514, "no_speech_prob": 1.3211849363869987e-05}, {"id": 629, "seek": 415752, "start": 4162.96, "end": 4169.0, "text": " That was literally as simple as saying upsampling 2D and then a 1x1 conv. So that got rid of", "tokens": [663, 390, 3736, 382, 2199, 382, 1566, 15497, 335, 11970, 568, 35, 293, 550, 257, 502, 87, 16, 3754, 13, 407, 300, 658, 3973, 295], "temperature": 0.0, "avg_logprob": -0.16004573867981692, "compression_ratio": 1.670391061452514, "no_speech_prob": 1.3211849363869987e-05}, {"id": 630, "seek": 415752, "start": 4169.0, "end": 4174.92, "text": " my checkerboard patterns.", "tokens": [452, 1520, 260, 3787, 8294, 13], "temperature": 0.0, "avg_logprob": -0.16004573867981692, "compression_ratio": 1.670391061452514, "no_speech_prob": 1.3211849363869987e-05}, {"id": 631, "seek": 415752, "start": 4174.92, "end": 4180.4400000000005, "text": " The next thing I did was I changed my loss function and I decided before I tried to do", "tokens": [440, 958, 551, 286, 630, 390, 286, 3105, 452, 4470, 2445, 293, 286, 3047, 949, 286, 3031, 281, 360], "temperature": 0.0, "avg_logprob": -0.16004573867981692, "compression_ratio": 1.670391061452514, "no_speech_prob": 1.3211849363869987e-05}, {"id": 632, "seek": 418044, "start": 4180.44, "end": 4187.719999999999, "text": " style transfer with perceptual losses, let's try and do super resolution with multiple", "tokens": [3758, 5003, 365, 43276, 901, 15352, 11, 718, 311, 853, 293, 360, 1687, 8669, 365, 3866], "temperature": 0.0, "avg_logprob": -0.16587714393540184, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.801050171314273e-06}, {"id": 633, "seek": 418044, "start": 4187.719999999999, "end": 4192.599999999999, "text": " content loss layers. Because that's one thing that I'm going to have to do for style transfer,", "tokens": [2701, 4470, 7914, 13, 1436, 300, 311, 472, 551, 300, 286, 478, 516, 281, 362, 281, 360, 337, 3758, 5003, 11], "temperature": 0.0, "avg_logprob": -0.16587714393540184, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.801050171314273e-06}, {"id": 634, "seek": 418044, "start": 4192.599999999999, "end": 4197.759999999999, "text": " is be able to use multiple layers. So I always like to start with something that works and", "tokens": [307, 312, 1075, 281, 764, 3866, 7914, 13, 407, 286, 1009, 411, 281, 722, 365, 746, 300, 1985, 293], "temperature": 0.0, "avg_logprob": -0.16587714393540184, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.801050171314273e-06}, {"id": 635, "seek": 418044, "start": 4197.759999999999, "end": 4201.679999999999, "text": " make small little changes so it keeps working at every point.", "tokens": [652, 1359, 707, 2962, 370, 309, 5965, 1364, 412, 633, 935, 13], "temperature": 0.0, "avg_logprob": -0.16587714393540184, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.801050171314273e-06}, {"id": 636, "seek": 418044, "start": 4201.679999999999, "end": 4208.799999999999, "text": " So in this case, I thought, okay, let's first of all slightly change the loss function for", "tokens": [407, 294, 341, 1389, 11, 286, 1194, 11, 1392, 11, 718, 311, 700, 295, 439, 4748, 1319, 264, 4470, 2445, 337], "temperature": 0.0, "avg_logprob": -0.16587714393540184, "compression_ratio": 1.7206477732793521, "no_speech_prob": 8.801050171314273e-06}, {"id": 637, "seek": 420880, "start": 4208.8, "end": 4218.400000000001, "text": " super resolution so that it uses multiple layers. So here's how I did that. I changed", "tokens": [1687, 8669, 370, 300, 309, 4960, 3866, 7914, 13, 407, 510, 311, 577, 286, 630, 300, 13, 286, 3105], "temperature": 0.0, "avg_logprob": -0.18621172223772323, "compression_ratio": 1.4759358288770053, "no_speech_prob": 7.411251772282412e-06}, {"id": 638, "seek": 420880, "start": 4218.400000000001, "end": 4227.84, "text": " my bgg content so it created a list of outputs, conv1 from each of the first, second and third", "tokens": [452, 272, 1615, 2701, 370, 309, 2942, 257, 1329, 295, 23930, 11, 3754, 16, 490, 1184, 295, 264, 700, 11, 1150, 293, 2636], "temperature": 0.0, "avg_logprob": -0.18621172223772323, "compression_ratio": 1.4759358288770053, "no_speech_prob": 7.411251772282412e-06}, {"id": 639, "seek": 420880, "start": 4227.84, "end": 4228.84, "text": " blocks.", "tokens": [8474, 13], "temperature": 0.0, "avg_logprob": -0.18621172223772323, "compression_ratio": 1.4759358288770053, "no_speech_prob": 7.411251772282412e-06}, {"id": 640, "seek": 420880, "start": 4228.84, "end": 4237.08, "text": " Then I changed my loss function so it went through and added the mean square difference", "tokens": [1396, 286, 3105, 452, 4470, 2445, 370, 309, 1437, 807, 293, 3869, 264, 914, 3732, 2649], "temperature": 0.0, "avg_logprob": -0.18621172223772323, "compression_ratio": 1.4759358288770053, "no_speech_prob": 7.411251772282412e-06}, {"id": 641, "seek": 423708, "start": 4237.08, "end": 4242.48, "text": " for each of those three layers. I also decided to add a weight just for fun. So I decided", "tokens": [337, 1184, 295, 729, 1045, 7914, 13, 286, 611, 3047, 281, 909, 257, 3364, 445, 337, 1019, 13, 407, 286, 3047], "temperature": 0.0, "avg_logprob": -0.19209596222522213, "compression_ratio": 1.6724137931034482, "no_speech_prob": 2.1233715870039305e-06}, {"id": 642, "seek": 423708, "start": 4242.48, "end": 4249.68, "text": " to go.1,.8,.1. Because this is the layer that they used in the paper. But let's have", "tokens": [281, 352, 2411, 16, 11, 2411, 23, 11, 2411, 16, 13, 1436, 341, 307, 264, 4583, 300, 436, 1143, 294, 264, 3035, 13, 583, 718, 311, 362], "temperature": 0.0, "avg_logprob": -0.19209596222522213, "compression_ratio": 1.6724137931034482, "no_speech_prob": 2.1233715870039305e-06}, {"id": 643, "seek": 423708, "start": 4249.68, "end": 4255.42, "text": " a little bit of more precise super resolution and a little bit of more semantic super resolution", "tokens": [257, 707, 857, 295, 544, 13600, 1687, 8669, 293, 257, 707, 857, 295, 544, 47982, 1687, 8669], "temperature": 0.0, "avg_logprob": -0.19209596222522213, "compression_ratio": 1.6724137931034482, "no_speech_prob": 2.1233715870039305e-06}, {"id": 644, "seek": 423708, "start": 4255.42, "end": 4258.88, "text": " and see how it goes.", "tokens": [293, 536, 577, 309, 1709, 13], "temperature": 0.0, "avg_logprob": -0.19209596222522213, "compression_ratio": 1.6724137931034482, "no_speech_prob": 2.1233715870039305e-06}, {"id": 645, "seek": 423708, "start": 4258.88, "end": 4265.04, "text": " I created this function to do kind of a more general mean squared error. And that was basically", "tokens": [286, 2942, 341, 2445, 281, 360, 733, 295, 257, 544, 2674, 914, 8889, 6713, 13, 400, 300, 390, 1936], "temperature": 0.0, "avg_logprob": -0.19209596222522213, "compression_ratio": 1.6724137931034482, "no_speech_prob": 2.1233715870039305e-06}, {"id": 646, "seek": 426504, "start": 4265.04, "end": 4271.12, "text": " it. So other than that line and that line, everything else was the same. So that gave", "tokens": [309, 13, 407, 661, 813, 300, 1622, 293, 300, 1622, 11, 1203, 1646, 390, 264, 912, 13, 407, 300, 2729], "temperature": 0.0, "avg_logprob": -0.14725789836808748, "compression_ratio": 1.6491935483870968, "no_speech_prob": 9.972885891329497e-06}, {"id": 647, "seek": 426504, "start": 4271.12, "end": 4276.0, "text": " me super resolution working on multiple layers.", "tokens": [385, 1687, 8669, 1364, 322, 3866, 7914, 13], "temperature": 0.0, "avg_logprob": -0.14725789836808748, "compression_ratio": 1.6491935483870968, "no_speech_prob": 9.972885891329497e-06}, {"id": 648, "seek": 426504, "start": 4276.0, "end": 4282.6, "text": " One of the things I found fascinating is that this is the original low res and it's done", "tokens": [1485, 295, 264, 721, 286, 1352, 10343, 307, 300, 341, 307, 264, 3380, 2295, 725, 293, 309, 311, 1096], "temperature": 0.0, "avg_logprob": -0.14725789836808748, "compression_ratio": 1.6491935483870968, "no_speech_prob": 9.972885891329497e-06}, {"id": 649, "seek": 426504, "start": 4282.6, "end": 4287.9, "text": " a good job of upscaling it, but it's also fixed up the weird white balance, which really", "tokens": [257, 665, 1691, 295, 493, 4417, 4270, 309, 11, 457, 309, 311, 611, 6806, 493, 264, 3657, 2418, 4772, 11, 597, 534], "temperature": 0.0, "avg_logprob": -0.14725789836808748, "compression_ratio": 1.6491935483870968, "no_speech_prob": 9.972885891329497e-06}, {"id": 650, "seek": 426504, "start": 4287.9, "end": 4294.88, "text": " surprised me. It's taken this obviously over-yellow shot and this is what the ceramic should look", "tokens": [6100, 385, 13, 467, 311, 2726, 341, 2745, 670, 12, 88, 21348, 3347, 293, 341, 307, 437, 264, 29996, 820, 574], "temperature": 0.0, "avg_logprob": -0.14725789836808748, "compression_ratio": 1.6491935483870968, "no_speech_prob": 9.972885891329497e-06}, {"id": 651, "seek": 429488, "start": 4294.88, "end": 4299.88, "text": " like, it should be white. And somehow it's kind of adjusted everything. So the Viet or", "tokens": [411, 11, 309, 820, 312, 2418, 13, 400, 6063, 309, 311, 733, 295, 19871, 1203, 13, 407, 264, 691, 1684, 420], "temperature": 0.0, "avg_logprob": -0.20236048875031648, "compression_ratio": 1.5338345864661653, "no_speech_prob": 1.5689389329054393e-05}, {"id": 652, "seek": 429488, "start": 4299.88, "end": 4303.84, "text": " whatever it is in the background has gone from a yellowy-brown to a nice white, as have", "tokens": [2035, 309, 307, 294, 264, 3678, 575, 2780, 490, 257, 5566, 88, 12, 1443, 648, 281, 257, 1481, 2418, 11, 382, 362], "temperature": 0.0, "avg_logprob": -0.20236048875031648, "compression_ratio": 1.5338345864661653, "no_speech_prob": 1.5689389329054393e-05}, {"id": 653, "seek": 429488, "start": 4303.84, "end": 4308.12, "text": " these cups here. It's figured out that these slightly pixelated things are actually meant", "tokens": [613, 13381, 510, 13, 467, 311, 8932, 484, 300, 613, 4748, 19261, 770, 721, 366, 767, 4140], "temperature": 0.0, "avg_logprob": -0.20236048875031648, "compression_ratio": 1.5338345864661653, "no_speech_prob": 1.5689389329054393e-05}, {"id": 654, "seek": 429488, "start": 4308.12, "end": 4313.6, "text": " to be upside down handles. This is on only 20,000 images.", "tokens": [281, 312, 14119, 760, 18722, 13, 639, 307, 322, 787, 945, 11, 1360, 5267, 13], "temperature": 0.0, "avg_logprob": -0.20236048875031648, "compression_ratio": 1.5338345864661653, "no_speech_prob": 1.5689389329054393e-05}, {"id": 655, "seek": 429488, "start": 4313.6, "end": 4323.6, "text": " So I'm very surprised that it's fixing the color, because we never asked it to. But I", "tokens": [407, 286, 478, 588, 6100, 300, 309, 311, 19442, 264, 2017, 11, 570, 321, 1128, 2351, 309, 281, 13, 583, 286], "temperature": 0.0, "avg_logprob": -0.20236048875031648, "compression_ratio": 1.5338345864661653, "no_speech_prob": 1.5689389329054393e-05}, {"id": 656, "seek": 432360, "start": 4323.6, "end": 4328.72, "text": " guess it knows what a cup is meant to look like, and so this is what it's decided to", "tokens": [2041, 309, 3255, 437, 257, 4414, 307, 4140, 281, 574, 411, 11, 293, 370, 341, 307, 437, 309, 311, 3047, 281], "temperature": 0.0, "avg_logprob": -0.1350574493408203, "compression_ratio": 1.675, "no_speech_prob": 8.801021976978518e-06}, {"id": 657, "seek": 432360, "start": 4328.72, "end": 4338.68, "text": " do, to make a cup the way it thinks it's meant to look. So that was pretty cool.", "tokens": [360, 11, 281, 652, 257, 4414, 264, 636, 309, 7309, 309, 311, 4140, 281, 574, 13, 407, 300, 390, 1238, 1627, 13], "temperature": 0.0, "avg_logprob": -0.1350574493408203, "compression_ratio": 1.675, "no_speech_prob": 8.801021976978518e-06}, {"id": 658, "seek": 432360, "start": 4338.68, "end": 4343.08, "text": " So then to go from there to style transfer was pretty straightforward. I had to read", "tokens": [407, 550, 281, 352, 490, 456, 281, 3758, 5003, 390, 1238, 15325, 13, 286, 632, 281, 1401], "temperature": 0.0, "avg_logprob": -0.1350574493408203, "compression_ratio": 1.675, "no_speech_prob": 8.801021976978518e-06}, {"id": 659, "seek": 432360, "start": 4343.08, "end": 4350.6, "text": " in my style as before. This is the code to do the special kind of resnet block where", "tokens": [294, 452, 3758, 382, 949, 13, 639, 307, 264, 3089, 281, 360, 264, 2121, 733, 295, 725, 7129, 3461, 689], "temperature": 0.0, "avg_logprob": -0.1350574493408203, "compression_ratio": 1.675, "no_speech_prob": 8.801021976978518e-06}, {"id": 660, "seek": 435060, "start": 4350.6, "end": 4356.92, "text": " we use valid convolutions, which means we lose two pixels each time, and so therefore", "tokens": [321, 764, 7363, 3754, 15892, 11, 597, 1355, 321, 3624, 732, 18668, 1184, 565, 11, 293, 370, 4412], "temperature": 0.0, "avg_logprob": -0.2050923179177677, "compression_ratio": 1.6437768240343347, "no_speech_prob": 2.9772869311273098e-05}, {"id": 661, "seek": 435060, "start": 4356.92, "end": 4364.120000000001, "text": " we have to do a center crop. But don't forget, lambda layers are great for this kind of thing.", "tokens": [321, 362, 281, 360, 257, 3056, 9086, 13, 583, 500, 380, 2870, 11, 13607, 7914, 366, 869, 337, 341, 733, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.2050923179177677, "compression_ratio": 1.6437768240343347, "no_speech_prob": 2.9772869311273098e-05}, {"id": 662, "seek": 435060, "start": 4364.120000000001, "end": 4367.64, "text": " Whatever code you can write, chuck it in a lambda layer, and suddenly it's a Keras layer.", "tokens": [8541, 3089, 291, 393, 2464, 11, 20870, 309, 294, 257, 13607, 4583, 11, 293, 5800, 309, 311, 257, 591, 6985, 4583, 13], "temperature": 0.0, "avg_logprob": -0.2050923179177677, "compression_ratio": 1.6437768240343347, "no_speech_prob": 2.9772869311273098e-05}, {"id": 663, "seek": 435060, "start": 4367.64, "end": 4368.64, "text": " So do my center crop.", "tokens": [407, 360, 452, 3056, 9086, 13], "temperature": 0.0, "avg_logprob": -0.2050923179177677, "compression_ratio": 1.6437768240343347, "no_speech_prob": 2.9772869311273098e-05}, {"id": 664, "seek": 435060, "start": 4368.64, "end": 4375.6, "text": " So this is now a resnet block which does valid comms. So this is basically all exactly the", "tokens": [407, 341, 307, 586, 257, 725, 7129, 3461, 597, 775, 7363, 800, 82, 13, 407, 341, 307, 1936, 439, 2293, 264], "temperature": 0.0, "avg_logprob": -0.2050923179177677, "compression_ratio": 1.6437768240343347, "no_speech_prob": 2.9772869311273098e-05}, {"id": 665, "seek": 437560, "start": 4375.6, "end": 4381.72, "text": " same. We have to do a few downsamplings, then the computation, then our upsamplings, just", "tokens": [912, 13, 492, 362, 281, 360, 257, 1326, 760, 19988, 26921, 11, 550, 264, 24903, 11, 550, 527, 15497, 335, 26921, 11, 445], "temperature": 0.0, "avg_logprob": -0.15847697500455177, "compression_ratio": 1.7529411764705882, "no_speech_prob": 7.766914677631576e-06}, {"id": 666, "seek": 437560, "start": 4381.72, "end": 4389.68, "text": " like the supplemental paper. So the loss function looks a lot like the loss function did before,", "tokens": [411, 264, 48604, 3035, 13, 407, 264, 4470, 2445, 1542, 257, 688, 411, 264, 4470, 2445, 630, 949, 11], "temperature": 0.0, "avg_logprob": -0.15847697500455177, "compression_ratio": 1.7529411764705882, "no_speech_prob": 7.766914677631576e-06}, {"id": 667, "seek": 437560, "start": 4389.68, "end": 4395.52, "text": " but we've got two extra things. One is the grand matrix. So here is a version of the", "tokens": [457, 321, 600, 658, 732, 2857, 721, 13, 1485, 307, 264, 2697, 8141, 13, 407, 510, 307, 257, 3037, 295, 264], "temperature": 0.0, "avg_logprob": -0.15847697500455177, "compression_ratio": 1.7529411764705882, "no_speech_prob": 7.766914677631576e-06}, {"id": 668, "seek": 437560, "start": 4395.52, "end": 4400.72, "text": " grand matrix which works a batch at a time. If any of you tried to do this a single image", "tokens": [2697, 8141, 597, 1985, 257, 15245, 412, 257, 565, 13, 759, 604, 295, 291, 3031, 281, 360, 341, 257, 2167, 3256], "temperature": 0.0, "avg_logprob": -0.15847697500455177, "compression_ratio": 1.7529411764705882, "no_speech_prob": 7.766914677631576e-06}, {"id": 669, "seek": 437560, "start": 4400.72, "end": 4404.320000000001, "text": " at a time, you would have gone crazy with how slow it took. I saw a few of you trying", "tokens": [412, 257, 565, 11, 291, 576, 362, 2780, 3219, 365, 577, 2964, 309, 1890, 13, 286, 1866, 257, 1326, 295, 291, 1382], "temperature": 0.0, "avg_logprob": -0.15847697500455177, "compression_ratio": 1.7529411764705882, "no_speech_prob": 7.766914677631576e-06}, {"id": 670, "seek": 440432, "start": 4404.32, "end": 4410.08, "text": " to do that. So here's the batch-wise version of grand matrix.", "tokens": [281, 360, 300, 13, 407, 510, 311, 264, 15245, 12, 3711, 3037, 295, 2697, 8141, 13], "temperature": 0.0, "avg_logprob": -0.13341430381492334, "compression_ratio": 1.6649746192893402, "no_speech_prob": 9.368678547616582e-06}, {"id": 671, "seek": 440432, "start": 4410.08, "end": 4415.16, "text": " And then the second thing I needed to do was somehow feed in my style target. So another", "tokens": [400, 550, 264, 1150, 551, 286, 2978, 281, 360, 390, 6063, 3154, 294, 452, 3758, 3779, 13, 407, 1071], "temperature": 0.0, "avg_logprob": -0.13341430381492334, "compression_ratio": 1.6649746192893402, "no_speech_prob": 9.368678547616582e-06}, {"id": 672, "seek": 440432, "start": 4415.16, "end": 4425.08, "text": " thing I saw some of you do was feed in the style target every time, feed in that array", "tokens": [551, 286, 1866, 512, 295, 291, 360, 390, 3154, 294, 264, 3758, 3779, 633, 565, 11, 3154, 294, 300, 10225], "temperature": 0.0, "avg_logprob": -0.13341430381492334, "compression_ratio": 1.6649746192893402, "no_speech_prob": 9.368678547616582e-06}, {"id": 673, "seek": 440432, "start": 4425.08, "end": 4430.679999999999, "text": " into your loss function. Now you can obviously calculate your style target by just calling", "tokens": [666, 428, 4470, 2445, 13, 823, 291, 393, 2745, 8873, 428, 3758, 3779, 538, 445, 5141], "temperature": 0.0, "avg_logprob": -0.13341430381492334, "compression_ratio": 1.6649746192893402, "no_speech_prob": 9.368678547616582e-06}, {"id": 674, "seek": 443068, "start": 4430.68, "end": 4438.360000000001, "text": ".predict with the thing which gives you all your different style target layers. But the", "tokens": [2411, 79, 24945, 365, 264, 551, 597, 2709, 291, 439, 428, 819, 3758, 3779, 7914, 13, 583, 264], "temperature": 0.0, "avg_logprob": -0.1480068842569987, "compression_ratio": 1.7207207207207207, "no_speech_prob": 1.2411439456627704e-05}, {"id": 675, "seek": 443068, "start": 4438.360000000001, "end": 4443.84, "text": " problem is this thing here returns a NumPy array. It's a pretty big NumPy array, which", "tokens": [1154, 307, 341, 551, 510, 11247, 257, 22592, 47, 88, 10225, 13, 467, 311, 257, 1238, 955, 22592, 47, 88, 10225, 11, 597], "temperature": 0.0, "avg_logprob": -0.1480068842569987, "compression_ratio": 1.7207207207207207, "no_speech_prob": 1.2411439456627704e-05}, {"id": 676, "seek": 443068, "start": 4443.84, "end": 4448.68, "text": " means that then when you want to use it as a style target in training, it has to copy", "tokens": [1355, 300, 550, 562, 291, 528, 281, 764, 309, 382, 257, 3758, 3779, 294, 3097, 11, 309, 575, 281, 5055], "temperature": 0.0, "avg_logprob": -0.1480068842569987, "compression_ratio": 1.7207207207207207, "no_speech_prob": 1.2411439456627704e-05}, {"id": 677, "seek": 443068, "start": 4448.68, "end": 4454.84, "text": " that back to the GPU. And copying to the GPU is very, very, very slow. And this is a really", "tokens": [300, 646, 281, 264, 18407, 13, 400, 27976, 281, 264, 18407, 307, 588, 11, 588, 11, 588, 2964, 13, 400, 341, 307, 257, 534], "temperature": 0.0, "avg_logprob": -0.1480068842569987, "compression_ratio": 1.7207207207207207, "no_speech_prob": 1.2411439456627704e-05}, {"id": 678, "seek": 443068, "start": 4454.84, "end": 4456.16, "text": " big thing to copy to the GPU.", "tokens": [955, 551, 281, 5055, 281, 264, 18407, 13], "temperature": 0.0, "avg_logprob": -0.1480068842569987, "compression_ratio": 1.7207207207207207, "no_speech_prob": 1.2411439456627704e-05}, {"id": 679, "seek": 445616, "start": 4456.16, "end": 4462.16, "text": " So any of you who tried this, I saw some of you try it, it took forever. So here's the", "tokens": [407, 604, 295, 291, 567, 3031, 341, 11, 286, 1866, 512, 295, 291, 853, 309, 11, 309, 1890, 5680, 13, 407, 510, 311, 264], "temperature": 0.0, "avg_logprob": -0.14598569354495486, "compression_ratio": 1.4555555555555555, "no_speech_prob": 6.14415966992965e-06}, {"id": 680, "seek": 445616, "start": 4462.16, "end": 4471.92, "text": " trick. Call.variable on it. Turning something into a variable, fix it on the GPU for you.", "tokens": [4282, 13, 7807, 2411, 34033, 712, 322, 309, 13, 39660, 746, 666, 257, 7006, 11, 3191, 309, 322, 264, 18407, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.14598569354495486, "compression_ratio": 1.4555555555555555, "no_speech_prob": 6.14415966992965e-06}, {"id": 681, "seek": 445616, "start": 4471.92, "end": 4478.599999999999, "text": " So once you've done that, you can now treat this as a list of symbolic entities which", "tokens": [407, 1564, 291, 600, 1096, 300, 11, 291, 393, 586, 2387, 341, 382, 257, 1329, 295, 25755, 16667, 597], "temperature": 0.0, "avg_logprob": -0.14598569354495486, "compression_ratio": 1.4555555555555555, "no_speech_prob": 6.14415966992965e-06}, {"id": 682, "seek": 447860, "start": 4478.6, "end": 4486.92, "text": " are the GPU versions of this. So I can now use this inside my GPU code. So here are my", "tokens": [366, 264, 18407, 9606, 295, 341, 13, 407, 286, 393, 586, 764, 341, 1854, 452, 18407, 3089, 13, 407, 510, 366, 452], "temperature": 0.0, "avg_logprob": -0.14862826029459636, "compression_ratio": 1.5027932960893855, "no_speech_prob": 2.4300037694047205e-05}, {"id": 683, "seek": 447860, "start": 4486.92, "end": 4499.4800000000005, "text": " style targets I can use inside my loss function. And it doesn't have to do any copying backwards", "tokens": [3758, 12911, 286, 393, 764, 1854, 452, 4470, 2445, 13, 400, 309, 1177, 380, 362, 281, 360, 604, 27976, 12204], "temperature": 0.0, "avg_logprob": -0.14862826029459636, "compression_ratio": 1.5027932960893855, "no_speech_prob": 2.4300037694047205e-05}, {"id": 684, "seek": 447860, "start": 4499.4800000000005, "end": 4504.52, "text": " and forwards. So there's a subtlety, but if you don't get that subtlety right, you're", "tokens": [293, 30126, 13, 407, 456, 311, 257, 7257, 75, 2210, 11, 457, 498, 291, 500, 380, 483, 300, 7257, 75, 2210, 558, 11, 291, 434], "temperature": 0.0, "avg_logprob": -0.14862826029459636, "compression_ratio": 1.5027932960893855, "no_speech_prob": 2.4300037694047205e-05}, {"id": 685, "seek": 450452, "start": 4504.52, "end": 4510.040000000001, "text": " going to be waiting for a week or so for your code to finish.", "tokens": [516, 281, 312, 3806, 337, 257, 1243, 420, 370, 337, 428, 3089, 281, 2413, 13], "temperature": 0.0, "avg_logprob": -0.13376177750624618, "compression_ratio": 1.5794871794871794, "no_speech_prob": 6.540395588672254e-06}, {"id": 686, "seek": 450452, "start": 4510.040000000001, "end": 4515.4400000000005, "text": " So those were the little subtleties which were necessary to get this to work. And once", "tokens": [407, 729, 645, 264, 707, 7257, 2631, 530, 597, 645, 4818, 281, 483, 341, 281, 589, 13, 400, 1564], "temperature": 0.0, "avg_logprob": -0.13376177750624618, "compression_ratio": 1.5794871794871794, "no_speech_prob": 6.540395588672254e-06}, {"id": 687, "seek": 450452, "start": 4515.4400000000005, "end": 4520.240000000001, "text": " you get it to work, it does exactly the same thing basically as before.", "tokens": [291, 483, 309, 281, 589, 11, 309, 775, 2293, 264, 912, 551, 1936, 382, 949, 13], "temperature": 0.0, "avg_logprob": -0.13376177750624618, "compression_ratio": 1.5794871794871794, "no_speech_prob": 6.540395588672254e-06}, {"id": 688, "seek": 450452, "start": 4520.240000000001, "end": 4526.96, "text": " So where this gets combined with Devise is I wanted to try something interesting, which", "tokens": [407, 689, 341, 2170, 9354, 365, 9096, 908, 307, 286, 1415, 281, 853, 746, 1880, 11, 597], "temperature": 0.0, "avg_logprob": -0.13376177750624618, "compression_ratio": 1.5794871794871794, "no_speech_prob": 6.540395588672254e-06}, {"id": 689, "seek": 452696, "start": 4526.96, "end": 4534.52, "text": " is in the original Perceptual Losses paper, they trained it on the Cocoa dataset which", "tokens": [307, 294, 264, 3380, 3026, 1336, 901, 441, 772, 279, 3035, 11, 436, 8895, 309, 322, 264, 29787, 64, 28872, 597], "temperature": 0.0, "avg_logprob": -0.1487315625560527, "compression_ratio": 1.6053811659192825, "no_speech_prob": 1.8738631979431375e-06}, {"id": 690, "seek": 452696, "start": 4534.52, "end": 4539.72, "text": " has 80,000 images, which didn't seem like many. I wanted to know what would happen if", "tokens": [575, 4688, 11, 1360, 5267, 11, 597, 994, 380, 1643, 411, 867, 13, 286, 1415, 281, 458, 437, 576, 1051, 498], "temperature": 0.0, "avg_logprob": -0.1487315625560527, "compression_ratio": 1.6053811659192825, "no_speech_prob": 1.8738631979431375e-06}, {"id": 691, "seek": 452696, "start": 4539.72, "end": 4549.16, "text": " we trained it on all of ImageNet. So I did. So I decided to train a super resolution network", "tokens": [321, 8895, 309, 322, 439, 295, 29903, 31890, 13, 407, 286, 630, 13, 407, 286, 3047, 281, 3847, 257, 1687, 8669, 3209], "temperature": 0.0, "avg_logprob": -0.1487315625560527, "compression_ratio": 1.6053811659192825, "no_speech_prob": 1.8738631979431375e-06}, {"id": 692, "seek": 452696, "start": 4549.16, "end": 4556.92, "text": " on all of ImageNet. And the code's all identical, so I'm not going to explain it, other than", "tokens": [322, 439, 295, 29903, 31890, 13, 400, 264, 3089, 311, 439, 14800, 11, 370, 286, 478, 406, 516, 281, 2903, 309, 11, 661, 813], "temperature": 0.0, "avg_logprob": -0.1487315625560527, "compression_ratio": 1.6053811659192825, "no_speech_prob": 1.8738631979431375e-06}, {"id": 693, "seek": 455692, "start": 4556.92, "end": 4562.52, "text": " you'll notice we don't have the square bracket colon square bracket here anymore because", "tokens": [291, 603, 3449, 321, 500, 380, 362, 264, 3732, 16904, 8255, 3732, 16904, 510, 3602, 570], "temperature": 0.0, "avg_logprob": -0.20849601684078092, "compression_ratio": 1.5061728395061729, "no_speech_prob": 1.5206707757897675e-05}, {"id": 694, "seek": 455692, "start": 4562.52, "end": 4566.68, "text": " we don't want to try and read in the entirety of ImageNet into RAM. So these are still B", "tokens": [321, 500, 380, 528, 281, 853, 293, 1401, 294, 264, 31557, 295, 29903, 31890, 666, 14561, 13, 407, 613, 366, 920, 363], "temperature": 0.0, "avg_logprob": -0.20849601684078092, "compression_ratio": 1.5061728395061729, "no_speech_prob": 1.5206707757897675e-05}, {"id": 695, "seek": 455692, "start": 4566.68, "end": 4577.08, "text": " cols arrays. All the other code is identical until we get to here.", "tokens": [1173, 82, 41011, 13, 1057, 264, 661, 3089, 307, 14800, 1826, 321, 483, 281, 510, 13], "temperature": 0.0, "avg_logprob": -0.20849601684078092, "compression_ratio": 1.5061728395061729, "no_speech_prob": 1.5206707757897675e-05}, {"id": 696, "seek": 457708, "start": 4577.08, "end": 4591.0, "text": " So I use a B cols array iterator. I can't just call.fit because.fit or.fit generator", "tokens": [407, 286, 764, 257, 363, 1173, 82, 10225, 17138, 1639, 13, 286, 393, 380, 445, 818, 2411, 6845, 570, 2411, 6845, 420, 2411, 6845, 19265], "temperature": 0.0, "avg_logprob": -0.11223026224084802, "compression_ratio": 1.6459627329192548, "no_speech_prob": 4.495157099881908e-06}, {"id": 697, "seek": 457708, "start": 4591.0, "end": 4599.8, "text": " assumes that your iterator is returning your data and your labels. In our case, we don't", "tokens": [37808, 300, 428, 17138, 1639, 307, 12678, 428, 1412, 293, 428, 16949, 13, 682, 527, 1389, 11, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.11223026224084802, "compression_ratio": 1.6459627329192548, "no_speech_prob": 4.495157099881908e-06}, {"id": 698, "seek": 457708, "start": 4599.8, "end": 4605.96, "text": " have data and labels. We have two things that both get fed in as two inputs, and our labels", "tokens": [362, 1412, 293, 16949, 13, 492, 362, 732, 721, 300, 1293, 483, 4636, 294, 382, 732, 15743, 11, 293, 527, 16949], "temperature": 0.0, "avg_logprob": -0.11223026224084802, "compression_ratio": 1.6459627329192548, "no_speech_prob": 4.495157099881908e-06}, {"id": 699, "seek": 460596, "start": 4605.96, "end": 4608.96, "text": " are just a list of zeros.", "tokens": [366, 445, 257, 1329, 295, 35193, 13], "temperature": 0.0, "avg_logprob": -0.17995090484619142, "compression_ratio": 1.5989304812834224, "no_speech_prob": 1.7603373407837353e-06}, {"id": 700, "seek": 460596, "start": 4608.96, "end": 4616.64, "text": " So here's a good trick, and this answers your earlier question about how do you do multi-input", "tokens": [407, 510, 311, 257, 665, 4282, 11, 293, 341, 6338, 428, 3071, 1168, 466, 577, 360, 291, 360, 4825, 12, 259, 2582], "temperature": 0.0, "avg_logprob": -0.17995090484619142, "compression_ratio": 1.5989304812834224, "no_speech_prob": 1.7603373407837353e-06}, {"id": 701, "seek": 460596, "start": 4616.64, "end": 4623.16, "text": " models on large datasets. And the answer is, create your own training loop. Create your", "tokens": [5245, 322, 2416, 42856, 13, 400, 264, 1867, 307, 11, 1884, 428, 1065, 3097, 6367, 13, 20248, 428], "temperature": 0.0, "avg_logprob": -0.17995090484619142, "compression_ratio": 1.5989304812834224, "no_speech_prob": 1.7603373407837353e-06}, {"id": 702, "seek": 460596, "start": 4623.16, "end": 4629.4800000000005, "text": " own training loop which loops through a bunch of iterations, and then you can grab as many", "tokens": [1065, 3097, 6367, 597, 16121, 807, 257, 3840, 295, 36540, 11, 293, 550, 291, 393, 4444, 382, 867], "temperature": 0.0, "avg_logprob": -0.17995090484619142, "compression_ratio": 1.5989304812834224, "no_speech_prob": 1.7603373407837353e-06}, {"id": 703, "seek": 462948, "start": 4629.48, "end": 4636.0, "text": " batches of data from as many different iterators as you like, and then call train on batch.", "tokens": [15245, 279, 295, 1412, 490, 382, 867, 819, 17138, 3391, 382, 291, 411, 11, 293, 550, 818, 3847, 322, 15245, 13], "temperature": 0.0, "avg_logprob": -0.10158286624484592, "compression_ratio": 1.758974358974359, "no_speech_prob": 1.933354724314995e-06}, {"id": 704, "seek": 462948, "start": 4636.0, "end": 4640.879999999999, "text": " So in my case, my B cols array iterator is going to return my high resolution and low", "tokens": [407, 294, 452, 1389, 11, 452, 363, 1173, 82, 10225, 17138, 1639, 307, 516, 281, 2736, 452, 1090, 8669, 293, 2295], "temperature": 0.0, "avg_logprob": -0.10158286624484592, "compression_ratio": 1.758974358974359, "no_speech_prob": 1.933354724314995e-06}, {"id": 705, "seek": 462948, "start": 4640.879999999999, "end": 4646.5599999999995, "text": " resolution batch of images. So I go through a bunch of iterations, grab one batch of high", "tokens": [8669, 15245, 295, 5267, 13, 407, 286, 352, 807, 257, 3840, 295, 36540, 11, 4444, 472, 15245, 295, 1090], "temperature": 0.0, "avg_logprob": -0.10158286624484592, "compression_ratio": 1.758974358974359, "no_speech_prob": 1.933354724314995e-06}, {"id": 706, "seek": 462948, "start": 4646.5599999999995, "end": 4654.959999999999, "text": " res and low res images, and pass them as my two inputs, the train on batch.", "tokens": [725, 293, 2295, 725, 5267, 11, 293, 1320, 552, 382, 452, 732, 15743, 11, 264, 3847, 322, 15245, 13], "temperature": 0.0, "avg_logprob": -0.10158286624484592, "compression_ratio": 1.758974358974359, "no_speech_prob": 1.933354724314995e-06}, {"id": 707, "seek": 465496, "start": 4654.96, "end": 4664.64, "text": " So this is the only code I changed other than changing.fit generator to actually calling", "tokens": [407, 341, 307, 264, 787, 3089, 286, 3105, 661, 813, 4473, 2411, 6845, 19265, 281, 767, 5141], "temperature": 0.0, "avg_logprob": -0.15162411980007007, "compression_ratio": 1.628440366972477, "no_speech_prob": 2.4824735191941727e-06}, {"id": 708, "seek": 465496, "start": 4664.64, "end": 4675.52, "text": " train. So as you can see, this took me 4.5 hours to train, and I then decreased the learning", "tokens": [3847, 13, 407, 382, 291, 393, 536, 11, 341, 1890, 385, 1017, 13, 20, 2496, 281, 3847, 11, 293, 286, 550, 24436, 264, 2539], "temperature": 0.0, "avg_logprob": -0.15162411980007007, "compression_ratio": 1.628440366972477, "no_speech_prob": 2.4824735191941727e-06}, {"id": 709, "seek": 465496, "start": 4675.52, "end": 4679.88, "text": " rate and I trained for another 4.5 hours. Actually I did it overnight last night and", "tokens": [3314, 293, 286, 8895, 337, 1071, 1017, 13, 20, 2496, 13, 5135, 286, 630, 309, 13935, 1036, 1818, 293], "temperature": 0.0, "avg_logprob": -0.15162411980007007, "compression_ratio": 1.628440366972477, "no_speech_prob": 2.4824735191941727e-06}, {"id": 710, "seek": 465496, "start": 4679.88, "end": 4684.2, "text": " I only had enough time to do about half of ImageNet, so this isn't even the whole thing.", "tokens": [286, 787, 632, 1547, 565, 281, 360, 466, 1922, 295, 29903, 31890, 11, 370, 341, 1943, 380, 754, 264, 1379, 551, 13], "temperature": 0.0, "avg_logprob": -0.15162411980007007, "compression_ratio": 1.628440366972477, "no_speech_prob": 2.4824735191941727e-06}, {"id": 711, "seek": 468420, "start": 4684.2, "end": 4686.12, "text": " Check this out.", "tokens": [6881, 341, 484, 13], "temperature": 0.0, "avg_logprob": -0.21009588241577148, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.883049066644162e-05}, {"id": 712, "seek": 468420, "start": 4686.12, "end": 4696.28, "text": " So check that model and we're going to call.predict on the original high res image. Here's", "tokens": [407, 1520, 300, 2316, 293, 321, 434, 516, 281, 818, 2411, 79, 24945, 322, 264, 3380, 1090, 725, 3256, 13, 1692, 311], "temperature": 0.0, "avg_logprob": -0.21009588241577148, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.883049066644162e-05}, {"id": 713, "seek": 468420, "start": 4696.28, "end": 4703.12, "text": " the low res version and here's the version that we've created. And as you can see, it's", "tokens": [264, 2295, 725, 3037, 293, 510, 311, 264, 3037, 300, 321, 600, 2942, 13, 400, 382, 291, 393, 536, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.21009588241577148, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.883049066644162e-05}, {"id": 714, "seek": 468420, "start": 4703.12, "end": 4710.12, "text": " done a pretty extraordinarily good job. When you look at the original ball, there was this", "tokens": [1096, 257, 1238, 34557, 665, 1691, 13, 1133, 291, 574, 412, 264, 3380, 2594, 11, 456, 390, 341], "temperature": 0.0, "avg_logprob": -0.21009588241577148, "compression_ratio": 1.548913043478261, "no_speech_prob": 3.883049066644162e-05}, {"id": 715, "seek": 471012, "start": 4710.12, "end": 4715.48, "text": " kind of vague yellow thing here, it's kind of turned into a nice little inscription.", "tokens": [733, 295, 24247, 5566, 551, 510, 11, 309, 311, 733, 295, 3574, 666, 257, 1481, 707, 49882, 13], "temperature": 0.0, "avg_logprob": -0.22288376657586348, "compression_ratio": 1.6796116504854368, "no_speech_prob": 1.1300754522380885e-05}, {"id": 716, "seek": 471012, "start": 4715.48, "end": 4723.08, "text": " You can see that her eyes were like two gray blobs, it's kind of turned into some eyes.", "tokens": [509, 393, 536, 300, 720, 2575, 645, 411, 732, 10855, 1749, 929, 11, 309, 311, 733, 295, 3574, 666, 512, 2575, 13], "temperature": 0.0, "avg_logprob": -0.22288376657586348, "compression_ratio": 1.6796116504854368, "no_speech_prob": 1.1300754522380885e-05}, {"id": 717, "seek": 471012, "start": 4723.08, "end": 4728.4, "text": " You can see that her, you could just tell that that's an A, maybe if you look carefully.", "tokens": [509, 393, 536, 300, 720, 11, 291, 727, 445, 980, 300, 300, 311, 364, 316, 11, 1310, 498, 291, 574, 7500, 13], "temperature": 0.0, "avg_logprob": -0.22288376657586348, "compression_ratio": 1.6796116504854368, "no_speech_prob": 1.1300754522380885e-05}, {"id": 718, "seek": 471012, "start": 4728.4, "end": 4738.2, "text": " Now it's very clearly an A. So you can see it does an amazing job of upscaling this.", "tokens": [823, 309, 311, 588, 4448, 364, 316, 13, 407, 291, 393, 536, 309, 775, 364, 2243, 1691, 295, 493, 4417, 4270, 341, 13], "temperature": 0.0, "avg_logprob": -0.22288376657586348, "compression_ratio": 1.6796116504854368, "no_speech_prob": 1.1300754522380885e-05}, {"id": 719, "seek": 473820, "start": 4738.2, "end": 4743.72, "text": " Cooler still is this is a fully convolutional net and therefore is not specific to any particular", "tokens": [8561, 260, 920, 307, 341, 307, 257, 4498, 45216, 304, 2533, 293, 4412, 307, 406, 2685, 281, 604, 1729], "temperature": 0.0, "avg_logprob": -0.1594667154199937, "compression_ratio": 1.5337078651685394, "no_speech_prob": 7.889219887147192e-06}, {"id": 720, "seek": 473820, "start": 4743.72, "end": 4751.32, "text": " input resolution. So what I can do is I can create another version of the model using", "tokens": [4846, 8669, 13, 407, 437, 286, 393, 360, 307, 286, 393, 1884, 1071, 3037, 295, 264, 2316, 1228], "temperature": 0.0, "avg_logprob": -0.1594667154199937, "compression_ratio": 1.5337078651685394, "no_speech_prob": 7.889219887147192e-06}, {"id": 721, "seek": 473820, "start": 4751.32, "end": 4761.599999999999, "text": " our high res as the input. So now we're going to call.predict with the high res input and", "tokens": [527, 1090, 725, 382, 264, 4846, 13, 407, 586, 321, 434, 516, 281, 818, 2411, 79, 24945, 365, 264, 1090, 725, 4846, 293], "temperature": 0.0, "avg_logprob": -0.1594667154199937, "compression_ratio": 1.5337078651685394, "no_speech_prob": 7.889219887147192e-06}, {"id": 722, "seek": 476160, "start": 4761.6, "end": 4772.4400000000005, "text": " that's what we get back. So look at that, we can now see all of this detail on the basketball,", "tokens": [300, 311, 437, 321, 483, 646, 13, 407, 574, 412, 300, 11, 321, 393, 586, 536, 439, 295, 341, 2607, 322, 264, 11767, 11], "temperature": 0.0, "avg_logprob": -0.1898740662468804, "compression_ratio": 1.3941605839416058, "no_speech_prob": 3.5008347367693204e-06}, {"id": 723, "seek": 476160, "start": 4772.4400000000005, "end": 4779.360000000001, "text": " which simply none of that really existed here. It was there, but pretty hard to see what", "tokens": [597, 2935, 6022, 295, 300, 534, 13135, 510, 13, 467, 390, 456, 11, 457, 1238, 1152, 281, 536, 437], "temperature": 0.0, "avg_logprob": -0.1898740662468804, "compression_ratio": 1.3941605839416058, "no_speech_prob": 3.5008347367693204e-06}, {"id": 724, "seek": 476160, "start": 4779.360000000001, "end": 4780.360000000001, "text": " it was.", "tokens": [309, 390, 13], "temperature": 0.0, "avg_logprob": -0.1898740662468804, "compression_ratio": 1.3941605839416058, "no_speech_prob": 3.5008347367693204e-06}, {"id": 725, "seek": 478036, "start": 4780.36, "end": 4792.759999999999, "text": " Look at her hair, this kind of gray blob here. Here you can see it knows, it's like little", "tokens": [2053, 412, 720, 2578, 11, 341, 733, 295, 10855, 46115, 510, 13, 1692, 291, 393, 536, 309, 3255, 11, 309, 311, 411, 707], "temperature": 0.0, "avg_logprob": -0.1360884802682059, "compression_ratio": 1.424731182795699, "no_speech_prob": 3.96696304960642e-06}, {"id": 726, "seek": 478036, "start": 4792.759999999999, "end": 4802.92, "text": " bits of pulled back hair. So we can take any sized image and make it bigger. This to me", "tokens": [9239, 295, 7373, 646, 2578, 13, 407, 321, 393, 747, 604, 20004, 3256, 293, 652, 309, 3801, 13, 639, 281, 385], "temperature": 0.0, "avg_logprob": -0.1360884802682059, "compression_ratio": 1.424731182795699, "no_speech_prob": 3.96696304960642e-06}, {"id": 727, "seek": 478036, "start": 4802.92, "end": 4808.92, "text": " is one of the most amazing results I've seen in deep learning. When we train something", "tokens": [307, 472, 295, 264, 881, 2243, 3542, 286, 600, 1612, 294, 2452, 2539, 13, 1133, 321, 3847, 746], "temperature": 0.0, "avg_logprob": -0.1360884802682059, "compression_ratio": 1.424731182795699, "no_speech_prob": 3.96696304960642e-06}, {"id": 728, "seek": 480892, "start": 4808.92, "end": 4814.72, "text": " on nearly all of ImageNet, it's a single epoch, so there's definitely no overfitting, and", "tokens": [322, 6217, 439, 295, 29903, 31890, 11, 309, 311, 257, 2167, 30992, 339, 11, 370, 456, 311, 2138, 572, 670, 69, 2414, 11, 293], "temperature": 0.0, "avg_logprob": -0.17605237471751678, "compression_ratio": 1.4923857868020305, "no_speech_prob": 2.9772676498396322e-05}, {"id": 729, "seek": 480892, "start": 4814.72, "end": 4820.28, "text": " it's able to recognize what hair is meant to look like when pulled back into a bun is", "tokens": [309, 311, 1075, 281, 5521, 437, 2578, 307, 4140, 281, 574, 411, 562, 7373, 646, 666, 257, 6702, 307], "temperature": 0.0, "avg_logprob": -0.17605237471751678, "compression_ratio": 1.4923857868020305, "no_speech_prob": 2.9772676498396322e-05}, {"id": 730, "seek": 480892, "start": 4820.28, "end": 4824.2, "text": " a pretty extraordinary result.", "tokens": [257, 1238, 10581, 1874, 13], "temperature": 0.0, "avg_logprob": -0.17605237471751678, "compression_ratio": 1.4923857868020305, "no_speech_prob": 2.9772676498396322e-05}, {"id": 731, "seek": 480892, "start": 4824.2, "end": 4834.52, "text": " Something else which I only realized later is that it's all a bit fuzzy, right? There's", "tokens": [6595, 1646, 597, 286, 787, 5334, 1780, 307, 300, 309, 311, 439, 257, 857, 34710, 11, 558, 30, 821, 311], "temperature": 0.0, "avg_logprob": -0.17605237471751678, "compression_ratio": 1.4923857868020305, "no_speech_prob": 2.9772676498396322e-05}, {"id": 732, "seek": 483452, "start": 4834.52, "end": 4840.820000000001, "text": " this arm in the background that's a bit fuzzy. The model knows that that bit is meant to", "tokens": [341, 3726, 294, 264, 3678, 300, 311, 257, 857, 34710, 13, 440, 2316, 3255, 300, 300, 857, 307, 4140, 281], "temperature": 0.0, "avg_logprob": -0.14515558042024312, "compression_ratio": 1.565217391304348, "no_speech_prob": 5.507577043317724e-06}, {"id": 733, "seek": 483452, "start": 4840.820000000001, "end": 4852.4800000000005, "text": " stay fuzzy. It knows what out-of-focus things look like. Equally cool is not just how that", "tokens": [1754, 34710, 13, 467, 3255, 437, 484, 12, 2670, 12, 69, 15206, 721, 574, 411, 13, 15624, 379, 1627, 307, 406, 445, 577, 300], "temperature": 0.0, "avg_logprob": -0.14515558042024312, "compression_ratio": 1.565217391304348, "no_speech_prob": 5.507577043317724e-06}, {"id": 734, "seek": 483452, "start": 4852.4800000000005, "end": 4857.080000000001, "text": " A is now incredibly precise and accurate, but the fact that it knows that blurry things", "tokens": [316, 307, 586, 6252, 13600, 293, 8559, 11, 457, 264, 1186, 300, 309, 3255, 300, 37644, 721], "temperature": 0.0, "avg_logprob": -0.14515558042024312, "compression_ratio": 1.565217391304348, "no_speech_prob": 5.507577043317724e-06}, {"id": 735, "seek": 483452, "start": 4857.080000000001, "end": 4858.080000000001, "text": " need to stay blurry.", "tokens": [643, 281, 1754, 37644, 13], "temperature": 0.0, "avg_logprob": -0.14515558042024312, "compression_ratio": 1.565217391304348, "no_speech_prob": 5.507577043317724e-06}, {"id": 736, "seek": 485808, "start": 4858.08, "end": 4864.72, "text": " I don't know if you're as amazed at this as I am, but I thought this was a pretty cool", "tokens": [286, 500, 380, 458, 498, 291, 434, 382, 20507, 412, 341, 382, 286, 669, 11, 457, 286, 1194, 341, 390, 257, 1238, 1627], "temperature": 0.0, "avg_logprob": -0.19568655567784463, "compression_ratio": 1.3580246913580247, "no_speech_prob": 2.1112096874276176e-05}, {"id": 737, "seek": 485808, "start": 4864.72, "end": 4871.6, "text": " result. We could run this over a 24-hour period on maybe two epochs of all of ImageNet and", "tokens": [1874, 13, 492, 727, 1190, 341, 670, 257, 4022, 12, 18048, 2896, 322, 1310, 732, 30992, 28346, 295, 439, 295, 29903, 31890, 293], "temperature": 0.0, "avg_logprob": -0.19568655567784463, "compression_ratio": 1.3580246913580247, "no_speech_prob": 2.1112096874276176e-05}, {"id": 738, "seek": 485808, "start": 4871.6, "end": 4876.12, "text": " presumably it would get even better still.", "tokens": [26742, 309, 576, 483, 754, 1101, 920, 13], "temperature": 0.0, "avg_logprob": -0.19568655567784463, "compression_ratio": 1.3580246913580247, "no_speech_prob": 2.1112096874276176e-05}, {"id": 739, "seek": 487612, "start": 4876.12, "end": 4895.24, "text": " So let's take a 7-minute break and see you back here at 5 past 8.", "tokens": [407, 718, 311, 747, 257, 1614, 12, 18256, 1821, 293, 536, 291, 646, 510, 412, 1025, 1791, 1649, 13], "temperature": 0.0, "avg_logprob": -0.24126724574876868, "compression_ratio": 0.9285714285714286, "no_speech_prob": 7.368228398263454e-05}, {"id": 740, "seek": 489524, "start": 4895.24, "end": 4909.599999999999, "text": " We're going to do something else fun. Actually before I continue, I did want to mention one", "tokens": [492, 434, 516, 281, 360, 746, 1646, 1019, 13, 5135, 949, 286, 2354, 11, 286, 630, 528, 281, 2152, 472], "temperature": 0.0, "avg_logprob": -0.194237842116245, "compression_ratio": 1.3409090909090908, "no_speech_prob": 9.027793566929176e-05}, {"id": 741, "seek": 489524, "start": 4909.599999999999, "end": 4922.719999999999, "text": " thing in the homework that I changed, which is I realized in my manually created loss", "tokens": [551, 294, 264, 14578, 300, 286, 3105, 11, 597, 307, 286, 5334, 294, 452, 16945, 2942, 4470], "temperature": 0.0, "avg_logprob": -0.194237842116245, "compression_ratio": 1.3409090909090908, "no_speech_prob": 9.027793566929176e-05}, {"id": 742, "seek": 492272, "start": 4922.72, "end": 4931.64, "text": " function I was already doing a mean squared error in the loss function. But then when", "tokens": [2445, 286, 390, 1217, 884, 257, 914, 8889, 6713, 294, 264, 4470, 2445, 13, 583, 550, 562], "temperature": 0.0, "avg_logprob": -0.16958063206774124, "compression_ratio": 1.5945945945945945, "no_speech_prob": 9.914542897604406e-05}, {"id": 743, "seek": 492272, "start": 4931.64, "end": 4938.56, "text": " I told Keras to make that thing as close to 0 as possible, I had to also give it a loss", "tokens": [286, 1907, 591, 6985, 281, 652, 300, 551, 382, 1998, 281, 1958, 382, 1944, 11, 286, 632, 281, 611, 976, 309, 257, 4470], "temperature": 0.0, "avg_logprob": -0.16958063206774124, "compression_ratio": 1.5945945945945945, "no_speech_prob": 9.914542897604406e-05}, {"id": 744, "seek": 492272, "start": 4938.56, "end": 4944.12, "text": " function, and I was giving it MSE. Effectively that was like undersquaring my squared errors,", "tokens": [2445, 11, 293, 286, 390, 2902, 309, 376, 5879, 13, 17764, 3413, 300, 390, 411, 16692, 358, 1921, 452, 8889, 13603, 11], "temperature": 0.0, "avg_logprob": -0.16958063206774124, "compression_ratio": 1.5945945945945945, "no_speech_prob": 9.914542897604406e-05}, {"id": 745, "seek": 492272, "start": 4944.12, "end": 4950.16, "text": " it seemed wrong. So I've changed it to MAE, mean absolute error. So when you look back", "tokens": [309, 6576, 2085, 13, 407, 286, 600, 3105, 309, 281, 12191, 36, 11, 914, 8236, 6713, 13, 407, 562, 291, 574, 646], "temperature": 0.0, "avg_logprob": -0.16958063206774124, "compression_ratio": 1.5945945945945945, "no_speech_prob": 9.914542897604406e-05}, {"id": 746, "seek": 495016, "start": 4950.16, "end": 4956.48, "text": " over the notebooks, that's why. It's because this is just to say, hey, get the loss as", "tokens": [670, 264, 43782, 11, 300, 311, 983, 13, 467, 311, 570, 341, 307, 445, 281, 584, 11, 4177, 11, 483, 264, 4470, 382], "temperature": 0.0, "avg_logprob": -0.144334077835083, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.2125252144178376e-05}, {"id": 747, "seek": 495016, "start": 4956.48, "end": 4963.08, "text": " close to 0 as possible. I didn't really want to re-square it, that didn't make any sense.", "tokens": [1998, 281, 1958, 382, 1944, 13, 286, 994, 380, 534, 528, 281, 319, 12, 33292, 543, 309, 11, 300, 994, 380, 652, 604, 2020, 13], "temperature": 0.0, "avg_logprob": -0.144334077835083, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.2125252144178376e-05}, {"id": 748, "seek": 495016, "start": 4963.08, "end": 4968.48, "text": " So that's why you'll see that minor change.", "tokens": [407, 300, 311, 983, 291, 603, 536, 300, 6696, 1319, 13], "temperature": 0.0, "avg_logprob": -0.144334077835083, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.2125252144178376e-05}, {"id": 749, "seek": 495016, "start": 4968.48, "end": 4975.08, "text": " The other thing to mention is I did notice that when I re-trained my super resolution", "tokens": [440, 661, 551, 281, 2152, 307, 286, 630, 3449, 300, 562, 286, 319, 12, 17227, 2001, 452, 1687, 8669], "temperature": 0.0, "avg_logprob": -0.144334077835083, "compression_ratio": 1.5454545454545454, "no_speech_prob": 2.2125252144178376e-05}, {"id": 750, "seek": 497508, "start": 4975.08, "end": 4982.0, "text": " on my new images that didn't have the black border, it gave good results much, much faster.", "tokens": [322, 452, 777, 5267, 300, 994, 380, 362, 264, 2211, 7838, 11, 309, 2729, 665, 3542, 709, 11, 709, 4663, 13], "temperature": 0.0, "avg_logprob": -0.14875479539235434, "compression_ratio": 1.645021645021645, "no_speech_prob": 9.368638529849704e-06}, {"id": 751, "seek": 497508, "start": 4982.0, "end": 4986.0, "text": " So I really think that thing of learning to put the black border back in seemed to take", "tokens": [407, 286, 534, 519, 300, 551, 295, 2539, 281, 829, 264, 2211, 7838, 646, 294, 6576, 281, 747], "temperature": 0.0, "avg_logprob": -0.14875479539235434, "compression_ratio": 1.645021645021645, "no_speech_prob": 9.368638529849704e-06}, {"id": 752, "seek": 497508, "start": 4986.0, "end": 4991.84, "text": " quite a lot of effort for it. So again, hopefully some of you are going to look into that in", "tokens": [1596, 257, 688, 295, 4630, 337, 309, 13, 407, 797, 11, 4696, 512, 295, 291, 366, 516, 281, 574, 666, 300, 294], "temperature": 0.0, "avg_logprob": -0.14875479539235434, "compression_ratio": 1.645021645021645, "no_speech_prob": 9.368638529849704e-06}, {"id": 753, "seek": 497508, "start": 4991.84, "end": 4996.24, "text": " more detail.", "tokens": [544, 2607, 13], "temperature": 0.0, "avg_logprob": -0.14875479539235434, "compression_ratio": 1.645021645021645, "no_speech_prob": 9.368638529849704e-06}, {"id": 754, "seek": 497508, "start": 4996.24, "end": 5002.68, "text": " So we're going to learn about generative adversarial networks. This will kind of close off our", "tokens": [407, 321, 434, 516, 281, 1466, 466, 1337, 1166, 17641, 44745, 9590, 13, 639, 486, 733, 295, 1998, 766, 527], "temperature": 0.0, "avg_logprob": -0.14875479539235434, "compression_ratio": 1.645021645021645, "no_speech_prob": 9.368638529849704e-06}, {"id": 755, "seek": 500268, "start": 5002.68, "end": 5010.92, "text": " deep dive into generative models as applied to images. And just to remind you, the purpose", "tokens": [2452, 9192, 666, 1337, 1166, 5245, 382, 6456, 281, 5267, 13, 400, 445, 281, 4160, 291, 11, 264, 4334], "temperature": 0.0, "avg_logprob": -0.10519444374811082, "compression_ratio": 1.6081081081081081, "no_speech_prob": 4.785048076882958e-06}, {"id": 756, "seek": 500268, "start": 5010.92, "end": 5015.92, "text": " of this has been to learn about generative models, not to specifically learn about super", "tokens": [295, 341, 575, 668, 281, 1466, 466, 1337, 1166, 5245, 11, 406, 281, 4682, 1466, 466, 1687], "temperature": 0.0, "avg_logprob": -0.10519444374811082, "compression_ratio": 1.6081081081081081, "no_speech_prob": 4.785048076882958e-06}, {"id": 757, "seek": 500268, "start": 5015.92, "end": 5022.64, "text": " resolution or artistic style. But remember, these things can be used to create all kinds", "tokens": [8669, 420, 17090, 3758, 13, 583, 1604, 11, 613, 721, 393, 312, 1143, 281, 1884, 439, 3685], "temperature": 0.0, "avg_logprob": -0.10519444374811082, "compression_ratio": 1.6081081081081081, "no_speech_prob": 4.785048076882958e-06}, {"id": 758, "seek": 500268, "start": 5022.64, "end": 5028.320000000001, "text": " of images. So one of the groups is interested in taking a 2D photo and trying to turn it", "tokens": [295, 5267, 13, 407, 472, 295, 264, 3935, 307, 3102, 294, 1940, 257, 568, 35, 5052, 293, 1382, 281, 1261, 309], "temperature": 0.0, "avg_logprob": -0.10519444374811082, "compression_ratio": 1.6081081081081081, "no_speech_prob": 4.785048076882958e-06}, {"id": 759, "seek": 502832, "start": 5028.32, "end": 5033.2, "text": " into something that you can rotate in 3D or at least show a different angle of that 2D", "tokens": [666, 746, 300, 291, 393, 13121, 294, 805, 35, 420, 412, 1935, 855, 257, 819, 5802, 295, 300, 568, 35], "temperature": 0.0, "avg_logprob": -0.1988030288179042, "compression_ratio": 1.7314487632508835, "no_speech_prob": 5.771848464064533e-06}, {"id": 760, "seek": 502832, "start": 5033.2, "end": 5038.5599999999995, "text": " photo. And that's a great example of something that this should totally work for. It's just", "tokens": [5052, 13, 400, 300, 311, 257, 869, 1365, 295, 746, 300, 341, 820, 3879, 589, 337, 13, 467, 311, 445], "temperature": 0.0, "avg_logprob": -0.1988030288179042, "compression_ratio": 1.7314487632508835, "no_speech_prob": 5.771848464064533e-06}, {"id": 761, "seek": 502832, "start": 5038.5599999999995, "end": 5042.84, "text": " a mapping from one image to some different image, which is like what would this image", "tokens": [257, 18350, 490, 472, 3256, 281, 512, 819, 3256, 11, 597, 307, 411, 437, 576, 341, 3256], "temperature": 0.0, "avg_logprob": -0.1988030288179042, "compression_ratio": 1.7314487632508835, "no_speech_prob": 5.771848464064533e-06}, {"id": 762, "seek": 502832, "start": 5042.84, "end": 5047.08, "text": " look like from above versus from the front.", "tokens": [574, 411, 490, 3673, 5717, 490, 264, 1868, 13], "temperature": 0.0, "avg_logprob": -0.1988030288179042, "compression_ratio": 1.7314487632508835, "no_speech_prob": 5.771848464064533e-06}, {"id": 763, "seek": 502832, "start": 5047.08, "end": 5054.32, "text": " So keep in mind the purpose of this is just like in part 1, we learned about classification,", "tokens": [407, 1066, 294, 1575, 264, 4334, 295, 341, 307, 445, 411, 294, 644, 502, 11, 321, 3264, 466, 21538, 11], "temperature": 0.0, "avg_logprob": -0.1988030288179042, "compression_ratio": 1.7314487632508835, "no_speech_prob": 5.771848464064533e-06}, {"id": 764, "seek": 502832, "start": 5054.32, "end": 5058.08, "text": " which you can use for a thousand things. Now we're learning about generative models that", "tokens": [597, 291, 393, 764, 337, 257, 4714, 721, 13, 823, 321, 434, 2539, 466, 1337, 1166, 5245, 300], "temperature": 0.0, "avg_logprob": -0.1988030288179042, "compression_ratio": 1.7314487632508835, "no_speech_prob": 5.771848464064533e-06}, {"id": 765, "seek": 505808, "start": 5058.08, "end": 5064.5599999999995, "text": " you can use for a different thousand things. Now any generative model you build, you can", "tokens": [291, 393, 764, 337, 257, 819, 4714, 721, 13, 823, 604, 1337, 1166, 2316, 291, 1322, 11, 291, 393], "temperature": 0.0, "avg_logprob": -0.10503793614251274, "compression_ratio": 1.7279693486590038, "no_speech_prob": 2.3552462153020315e-05}, {"id": 766, "seek": 505808, "start": 5064.5599999999995, "end": 5071.76, "text": " make it better by adding on top of it a GAN, a generative adversarial network. And this", "tokens": [652, 309, 1101, 538, 5127, 322, 1192, 295, 309, 257, 460, 1770, 11, 257, 1337, 1166, 17641, 44745, 3209, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.10503793614251274, "compression_ratio": 1.7279693486590038, "no_speech_prob": 2.3552462153020315e-05}, {"id": 767, "seek": 505808, "start": 5071.76, "end": 5076.12, "text": " is something I don't really feel like it's been fully appreciated. People I've seen generally", "tokens": [307, 746, 286, 500, 380, 534, 841, 411, 309, 311, 668, 4498, 17169, 13, 3432, 286, 600, 1612, 5101], "temperature": 0.0, "avg_logprob": -0.10503793614251274, "compression_ratio": 1.7279693486590038, "no_speech_prob": 2.3552462153020315e-05}, {"id": 768, "seek": 505808, "start": 5076.12, "end": 5083.36, "text": " treat GANs as a different way of creating a generative model. But I think of this more", "tokens": [2387, 460, 1770, 82, 382, 257, 819, 636, 295, 4084, 257, 1337, 1166, 2316, 13, 583, 286, 519, 295, 341, 544], "temperature": 0.0, "avg_logprob": -0.10503793614251274, "compression_ratio": 1.7279693486590038, "no_speech_prob": 2.3552462153020315e-05}, {"id": 769, "seek": 505808, "start": 5083.36, "end": 5087.4, "text": " as like, why not create your generative model using the kind of techniques we've been talking", "tokens": [382, 411, 11, 983, 406, 1884, 428, 1337, 1166, 2316, 1228, 264, 733, 295, 7512, 321, 600, 668, 1417], "temperature": 0.0, "avg_logprob": -0.10503793614251274, "compression_ratio": 1.7279693486590038, "no_speech_prob": 2.3552462153020315e-05}, {"id": 770, "seek": 508740, "start": 5087.4, "end": 5088.4, "text": " about.", "tokens": [466, 13], "temperature": 0.0, "avg_logprob": -0.1488584147559272, "compression_ratio": 1.563953488372093, "no_speech_prob": 8.530258128303103e-06}, {"id": 771, "seek": 508740, "start": 5088.4, "end": 5096.599999999999, "text": " But then, think of it this way. Think of all the artistic style stuff we were doing, like", "tokens": [583, 550, 11, 519, 295, 309, 341, 636, 13, 6557, 295, 439, 264, 17090, 3758, 1507, 321, 645, 884, 11, 411], "temperature": 0.0, "avg_logprob": -0.1488584147559272, "compression_ratio": 1.563953488372093, "no_speech_prob": 8.530258128303103e-06}, {"id": 772, "seek": 508740, "start": 5096.599999999999, "end": 5104.08, "text": " my terrible attempt at a Simpsons cartoon version of a picture. It looked nothing like", "tokens": [452, 6237, 5217, 412, 257, 3998, 1878, 892, 18569, 3037, 295, 257, 3036, 13, 467, 2956, 1825, 411], "temperature": 0.0, "avg_logprob": -0.1488584147559272, "compression_ratio": 1.563953488372093, "no_speech_prob": 8.530258128303103e-06}, {"id": 773, "seek": 508740, "start": 5104.08, "end": 5111.759999999999, "text": " the Simpsons. So what would be one way to improve that? One way to improve that would", "tokens": [264, 3998, 1878, 892, 13, 407, 437, 576, 312, 472, 636, 281, 3470, 300, 30, 1485, 636, 281, 3470, 300, 576], "temperature": 0.0, "avg_logprob": -0.1488584147559272, "compression_ratio": 1.563953488372093, "no_speech_prob": 8.530258128303103e-06}, {"id": 774, "seek": 511176, "start": 5111.76, "end": 5121.2, "text": " be to create two networks. There would be one network that takes our picture, which", "tokens": [312, 281, 1884, 732, 9590, 13, 821, 576, 312, 472, 3209, 300, 2516, 527, 3036, 11, 597], "temperature": 0.0, "avg_logprob": -0.11377931741567758, "compression_ratio": 1.7197452229299364, "no_speech_prob": 3.4465665521565825e-06}, {"id": 775, "seek": 511176, "start": 5121.2, "end": 5127.04, "text": " is actually not the Simpsons, and takes another picture that actually is the Simpsons, and", "tokens": [307, 767, 406, 264, 3998, 1878, 892, 11, 293, 2516, 1071, 3036, 300, 767, 307, 264, 3998, 1878, 892, 11, 293], "temperature": 0.0, "avg_logprob": -0.11377931741567758, "compression_ratio": 1.7197452229299364, "no_speech_prob": 3.4465665521565825e-06}, {"id": 776, "seek": 511176, "start": 5127.04, "end": 5135.2, "text": " maybe we can train a neural network that takes those two images and spits out something saying,", "tokens": [1310, 321, 393, 3847, 257, 18161, 3209, 300, 2516, 729, 732, 5267, 293, 637, 1208, 484, 746, 1566, 11], "temperature": 0.0, "avg_logprob": -0.11377931741567758, "compression_ratio": 1.7197452229299364, "no_speech_prob": 3.4465665521565825e-06}, {"id": 777, "seek": 513520, "start": 5135.2, "end": 5148.98, "text": " is that a real Simpsons image or not. And this thing we'll call the discriminator.", "tokens": [307, 300, 257, 957, 3998, 1878, 892, 3256, 420, 406, 13, 400, 341, 551, 321, 603, 818, 264, 20828, 1639, 13], "temperature": 0.0, "avg_logprob": -0.1047022377235302, "compression_ratio": 1.4772727272727273, "no_speech_prob": 2.4439873413939495e-06}, {"id": 778, "seek": 513520, "start": 5148.98, "end": 5154.2, "text": " So we could easily train a discriminator right now. It's just a classification network, just", "tokens": [407, 321, 727, 3612, 3847, 257, 20828, 1639, 558, 586, 13, 467, 311, 445, 257, 21538, 3209, 11, 445], "temperature": 0.0, "avg_logprob": -0.1047022377235302, "compression_ratio": 1.4772727272727273, "no_speech_prob": 2.4439873413939495e-06}, {"id": 779, "seek": 513520, "start": 5154.2, "end": 5160.12, "text": " use the same techniques we used in part 1. We feed it the two images, and it's going", "tokens": [764, 264, 912, 7512, 321, 1143, 294, 644, 502, 13, 492, 3154, 309, 264, 732, 5267, 11, 293, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.1047022377235302, "compression_ratio": 1.4772727272727273, "no_speech_prob": 2.4439873413939495e-06}, {"id": 780, "seek": 516012, "start": 5160.12, "end": 5166.72, "text": " to spit out a 1 if it's a real Simpsons cartoon, and a 0 if it's Jeremy's crappy generative", "tokens": [281, 22127, 484, 257, 502, 498, 309, 311, 257, 957, 3998, 1878, 892, 18569, 11, 293, 257, 1958, 498, 309, 311, 17809, 311, 36531, 1337, 1166], "temperature": 0.0, "avg_logprob": -0.16710743249631396, "compression_ratio": 1.2975206611570247, "no_speech_prob": 7.889230801083613e-06}, {"id": 781, "seek": 516012, "start": 5166.72, "end": 5176.36, "text": " model of Simpsons. That's easy, we know how to do that right now.", "tokens": [2316, 295, 3998, 1878, 892, 13, 663, 311, 1858, 11, 321, 458, 577, 281, 360, 300, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.16710743249631396, "compression_ratio": 1.2975206611570247, "no_speech_prob": 7.889230801083613e-06}, {"id": 782, "seek": 517636, "start": 5176.36, "end": 5198.0, "text": " Go and build another model. There's two images as inputs. You would feed it one thing that's", "tokens": [1037, 293, 1322, 1071, 2316, 13, 821, 311, 732, 5267, 382, 15743, 13, 509, 576, 3154, 309, 472, 551, 300, 311], "temperature": 0.0, "avg_logprob": -0.14985340118408202, "compression_ratio": 1.0823529411764705, "no_speech_prob": 9.368644896312617e-06}, {"id": 783, "seek": 519800, "start": 5198.0, "end": 5208.08, "text": " the Simpsons and one thing that's a generative output. It's up to you to feed it one of each.", "tokens": [264, 3998, 1878, 892, 293, 472, 551, 300, 311, 257, 1337, 1166, 5598, 13, 467, 311, 493, 281, 291, 281, 3154, 309, 472, 295, 1184, 13], "temperature": 0.0, "avg_logprob": -0.1563636873975212, "compression_ratio": 1.6975308641975309, "no_speech_prob": 9.368599421577528e-06}, {"id": 784, "seek": 519800, "start": 5208.08, "end": 5212.84, "text": " Or alternatively, you could feed it one thing. In fact, probably easier is to just feed it", "tokens": [1610, 8535, 356, 11, 291, 727, 3154, 309, 472, 551, 13, 682, 1186, 11, 1391, 3571, 307, 281, 445, 3154, 309], "temperature": 0.0, "avg_logprob": -0.1563636873975212, "compression_ratio": 1.6975308641975309, "no_speech_prob": 9.368599421577528e-06}, {"id": 785, "seek": 519800, "start": 5212.84, "end": 5218.26, "text": " one thing and it spits out is it the Simpsons or isn't it the Simpsons. And you could just", "tokens": [472, 551, 293, 309, 637, 1208, 484, 307, 309, 264, 3998, 1878, 892, 420, 1943, 380, 309, 264, 3998, 1878, 892, 13, 400, 291, 727, 445], "temperature": 0.0, "avg_logprob": -0.1563636873975212, "compression_ratio": 1.6975308641975309, "no_speech_prob": 9.368599421577528e-06}, {"id": 786, "seek": 521826, "start": 5218.26, "end": 5228.4400000000005, "text": " mix and match them. Actually, it's the latter that we're going to do, so that's probably", "tokens": [2890, 293, 2995, 552, 13, 5135, 11, 309, 311, 264, 18481, 300, 321, 434, 516, 281, 360, 11, 370, 300, 311, 1391], "temperature": 0.0, "avg_logprob": -0.18704207902102127, "compression_ratio": 1.675392670157068, "no_speech_prob": 1.3845819921698421e-05}, {"id": 787, "seek": 521826, "start": 5228.4400000000005, "end": 5229.4400000000005, "text": " easier.", "tokens": [3571, 13], "temperature": 0.0, "avg_logprob": -0.18704207902102127, "compression_ratio": 1.675392670157068, "no_speech_prob": 1.3845819921698421e-05}, {"id": 788, "seek": 521826, "start": 5229.4400000000005, "end": 5234.0, "text": " We're going to have one thing which is either not a Simpsons or it is a Simpsons, and we're", "tokens": [492, 434, 516, 281, 362, 472, 551, 597, 307, 2139, 406, 257, 3998, 1878, 892, 420, 309, 307, 257, 3998, 1878, 892, 11, 293, 321, 434], "temperature": 0.0, "avg_logprob": -0.18704207902102127, "compression_ratio": 1.675392670157068, "no_speech_prob": 1.3845819921698421e-05}, {"id": 789, "seek": 521826, "start": 5234.0, "end": 5239.64, "text": " going to have a mix of 50-50 of those two, and we're going to have something come out", "tokens": [516, 281, 362, 257, 2890, 295, 2625, 12, 2803, 295, 729, 732, 11, 293, 321, 434, 516, 281, 362, 746, 808, 484], "temperature": 0.0, "avg_logprob": -0.18704207902102127, "compression_ratio": 1.675392670157068, "no_speech_prob": 1.3845819921698421e-05}, {"id": 790, "seek": 521826, "start": 5239.64, "end": 5244.320000000001, "text": " saying, what do you think, is it real or not.", "tokens": [1566, 11, 437, 360, 291, 519, 11, 307, 309, 957, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.18704207902102127, "compression_ratio": 1.675392670157068, "no_speech_prob": 1.3845819921698421e-05}, {"id": 791, "seek": 524432, "start": 5244.32, "end": 5252.04, "text": " So this discriminator from now on will probably be calling it D. And we can think of that", "tokens": [407, 341, 20828, 1639, 490, 586, 322, 486, 1391, 312, 5141, 309, 413, 13, 400, 321, 393, 519, 295, 300], "temperature": 0.0, "avg_logprob": -0.16471985847719253, "compression_ratio": 1.4172185430463575, "no_speech_prob": 3.905474841303658e-06}, {"id": 792, "seek": 524432, "start": 5252.04, "end": 5260.92, "text": " as a function. D is a function that takes some input x, which is an image, and spits", "tokens": [382, 257, 2445, 13, 413, 307, 257, 2445, 300, 2516, 512, 4846, 2031, 11, 597, 307, 364, 3256, 11, 293, 637, 1208], "temperature": 0.0, "avg_logprob": -0.16471985847719253, "compression_ratio": 1.4172185430463575, "no_speech_prob": 3.905474841303658e-06}, {"id": 793, "seek": 524432, "start": 5260.92, "end": 5268.4, "text": " out a 1 or a 0, or maybe a probability.", "tokens": [484, 257, 502, 420, 257, 1958, 11, 420, 1310, 257, 8482, 13], "temperature": 0.0, "avg_logprob": -0.16471985847719253, "compression_ratio": 1.4172185430463575, "no_speech_prob": 3.905474841303658e-06}, {"id": 794, "seek": 526840, "start": 5268.4, "end": 5275.24, "text": " So what we could now do is create another neural network. And what this neural network", "tokens": [407, 437, 321, 727, 586, 360, 307, 1884, 1071, 18161, 3209, 13, 400, 437, 341, 18161, 3209], "temperature": 0.0, "avg_logprob": -0.10051855142565741, "compression_ratio": 1.646341463414634, "no_speech_prob": 3.747988159830129e-07}, {"id": 795, "seek": 526840, "start": 5275.24, "end": 5283.5, "text": " is going to do is it's going to take as input some random noise, just like all of our generators", "tokens": [307, 516, 281, 360, 307, 309, 311, 516, 281, 747, 382, 4846, 512, 4974, 5658, 11, 445, 411, 439, 295, 527, 38662], "temperature": 0.0, "avg_logprob": -0.10051855142565741, "compression_ratio": 1.646341463414634, "no_speech_prob": 3.747988159830129e-07}, {"id": 796, "seek": 526840, "start": 5283.5, "end": 5294.2, "text": " have so far, and it's going to spit out an image. And the loss function is going to be", "tokens": [362, 370, 1400, 11, 293, 309, 311, 516, 281, 22127, 484, 364, 3256, 13, 400, 264, 4470, 2445, 307, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.10051855142565741, "compression_ratio": 1.646341463414634, "no_speech_prob": 3.747988159830129e-07}, {"id": 797, "seek": 529420, "start": 5294.2, "end": 5304.36, "text": " if you take that image and stick it through D, did you manage to fool it? So could you", "tokens": [498, 291, 747, 300, 3256, 293, 2897, 309, 807, 413, 11, 630, 291, 3067, 281, 7979, 309, 30, 407, 727, 291], "temperature": 0.0, "avg_logprob": -0.1451927995028561, "compression_ratio": 1.46448087431694, "no_speech_prob": 2.482475792930927e-06}, {"id": 798, "seek": 529420, "start": 5304.36, "end": 5312.2, "text": " create something where in fact we wanted to say, oh yeah, totally, that's a real Simpsons.", "tokens": [1884, 746, 689, 294, 1186, 321, 1415, 281, 584, 11, 1954, 1338, 11, 3879, 11, 300, 311, 257, 957, 3998, 1878, 892, 13], "temperature": 0.0, "avg_logprob": -0.1451927995028561, "compression_ratio": 1.46448087431694, "no_speech_prob": 2.482475792930927e-06}, {"id": 799, "seek": 529420, "start": 5312.2, "end": 5318.08, "text": " So if that was our loss function, we're going to call the generator G. It's just something", "tokens": [407, 498, 300, 390, 527, 4470, 2445, 11, 321, 434, 516, 281, 818, 264, 19265, 460, 13, 467, 311, 445, 746], "temperature": 0.0, "avg_logprob": -0.1451927995028561, "compression_ratio": 1.46448087431694, "no_speech_prob": 2.482475792930927e-06}, {"id": 800, "seek": 531808, "start": 5318.08, "end": 5326.76, "text": " exactly like our perceptual losses style transfer model. But the loss function is now going", "tokens": [2293, 411, 527, 43276, 901, 15352, 3758, 5003, 2316, 13, 583, 264, 4470, 2445, 307, 586, 516], "temperature": 0.0, "avg_logprob": -0.11176114858582963, "compression_ratio": 1.6862745098039216, "no_speech_prob": 2.0261393274267903e-06}, {"id": 801, "seek": 531808, "start": 5326.76, "end": 5332.04, "text": " to be take the output of that and stick it through D, the discriminator, and try to trick", "tokens": [281, 312, 747, 264, 5598, 295, 300, 293, 2897, 309, 807, 413, 11, 264, 20828, 1639, 11, 293, 853, 281, 4282], "temperature": 0.0, "avg_logprob": -0.11176114858582963, "compression_ratio": 1.6862745098039216, "no_speech_prob": 2.0261393274267903e-06}, {"id": 802, "seek": 531808, "start": 5332.04, "end": 5339.36, "text": " it. So the generator's doing well if the discriminator's getting it wrong.", "tokens": [309, 13, 407, 264, 19265, 311, 884, 731, 498, 264, 20828, 1639, 311, 1242, 309, 2085, 13], "temperature": 0.0, "avg_logprob": -0.11176114858582963, "compression_ratio": 1.6862745098039216, "no_speech_prob": 2.0261393274267903e-06}, {"id": 803, "seek": 531808, "start": 5339.36, "end": 5346.0, "text": " So one way to do this would be to take our discriminator and train it as best as we can", "tokens": [407, 472, 636, 281, 360, 341, 576, 312, 281, 747, 527, 20828, 1639, 293, 3847, 309, 382, 1151, 382, 321, 393], "temperature": 0.0, "avg_logprob": -0.11176114858582963, "compression_ratio": 1.6862745098039216, "no_speech_prob": 2.0261393274267903e-06}, {"id": 804, "seek": 534600, "start": 5346.0, "end": 5351.72, "text": " to recognize the difference between our crappy Simpsons and real Simpsons, and then get a", "tokens": [281, 5521, 264, 2649, 1296, 527, 36531, 3998, 1878, 892, 293, 957, 3998, 1878, 892, 11, 293, 550, 483, 257], "temperature": 0.0, "avg_logprob": -0.09844798010748786, "compression_ratio": 1.897119341563786, "no_speech_prob": 1.4823561969024013e-06}, {"id": 805, "seek": 534600, "start": 5351.72, "end": 5357.6, "text": " generator and train it to trick that discriminator. But now at the end of that, it's probably", "tokens": [19265, 293, 3847, 309, 281, 4282, 300, 20828, 1639, 13, 583, 586, 412, 264, 917, 295, 300, 11, 309, 311, 1391], "temperature": 0.0, "avg_logprob": -0.09844798010748786, "compression_ratio": 1.897119341563786, "no_speech_prob": 1.4823561969024013e-06}, {"id": 806, "seek": 534600, "start": 5357.6, "end": 5361.32, "text": " still not very good because you realize that actually the discriminator didn't have to", "tokens": [920, 406, 588, 665, 570, 291, 4325, 300, 767, 264, 20828, 1639, 994, 380, 362, 281], "temperature": 0.0, "avg_logprob": -0.09844798010748786, "compression_ratio": 1.897119341563786, "no_speech_prob": 1.4823561969024013e-06}, {"id": 807, "seek": 534600, "start": 5361.32, "end": 5367.24, "text": " be very good before because my Simpsons generators were so bad. So I could now go back and retrain", "tokens": [312, 588, 665, 949, 570, 452, 3998, 1878, 892, 38662, 645, 370, 1578, 13, 407, 286, 727, 586, 352, 646, 293, 1533, 7146], "temperature": 0.0, "avg_logprob": -0.09844798010748786, "compression_ratio": 1.897119341563786, "no_speech_prob": 1.4823561969024013e-06}, {"id": 808, "seek": 534600, "start": 5367.24, "end": 5373.4, "text": " the discriminator based on my better generated images, and then I could go back and retrain", "tokens": [264, 20828, 1639, 2361, 322, 452, 1101, 10833, 5267, 11, 293, 550, 286, 727, 352, 646, 293, 1533, 7146], "temperature": 0.0, "avg_logprob": -0.09844798010748786, "compression_ratio": 1.897119341563786, "no_speech_prob": 1.4823561969024013e-06}, {"id": 809, "seek": 537340, "start": 5373.4, "end": 5377.5599999999995, "text": " the generator, and back and forth I go.", "tokens": [264, 19265, 11, 293, 646, 293, 5220, 286, 352, 13], "temperature": 0.0, "avg_logprob": -0.12603290457474559, "compression_ratio": 1.7272727272727273, "no_speech_prob": 1.0953080163744744e-05}, {"id": 810, "seek": 537340, "start": 5377.5599999999995, "end": 5383.44, "text": " And that is the general approach of a GAN, is to keep going back between two things,", "tokens": [400, 300, 307, 264, 2674, 3109, 295, 257, 460, 1770, 11, 307, 281, 1066, 516, 646, 1296, 732, 721, 11], "temperature": 0.0, "avg_logprob": -0.12603290457474559, "compression_ratio": 1.7272727272727273, "no_speech_prob": 1.0953080163744744e-05}, {"id": 811, "seek": 537340, "start": 5383.44, "end": 5390.4, "text": " which is training a discriminator and training a generator using a discriminator as a loss", "tokens": [597, 307, 3097, 257, 20828, 1639, 293, 3097, 257, 19265, 1228, 257, 20828, 1639, 382, 257, 4470], "temperature": 0.0, "avg_logprob": -0.12603290457474559, "compression_ratio": 1.7272727272727273, "no_speech_prob": 1.0953080163744744e-05}, {"id": 812, "seek": 537340, "start": 5390.4, "end": 5399.219999999999, "text": " function. So we've got one thing which is discriminator on some image, and another thing", "tokens": [2445, 13, 407, 321, 600, 658, 472, 551, 597, 307, 20828, 1639, 322, 512, 3256, 11, 293, 1071, 551], "temperature": 0.0, "avg_logprob": -0.12603290457474559, "compression_ratio": 1.7272727272727273, "no_speech_prob": 1.0953080163744744e-05}, {"id": 813, "seek": 539922, "start": 5399.22, "end": 5417.320000000001, "text": " which is a discriminator on a generator on some noise.", "tokens": [597, 307, 257, 20828, 1639, 322, 257, 19265, 322, 512, 5658, 13], "temperature": 0.0, "avg_logprob": -0.2764928936958313, "compression_ratio": 1.0, "no_speech_prob": 9.223413144354708e-06}, {"id": 814, "seek": 541732, "start": 5417.32, "end": 5430.32, "text": " So in practice, these things are going to spit out probabilities. So that's the general", "tokens": [407, 294, 3124, 11, 613, 721, 366, 516, 281, 22127, 484, 33783, 13, 407, 300, 311, 264, 2674], "temperature": 0.0, "avg_logprob": -0.21854774987519676, "compression_ratio": 1.6303030303030304, "no_speech_prob": 1.16593937491416e-05}, {"id": 815, "seek": 541732, "start": 5430.32, "end": 5436.58, "text": " idea. In practice, they found it very difficult to do this, like train the discriminator as", "tokens": [1558, 13, 682, 3124, 11, 436, 1352, 309, 588, 2252, 281, 360, 341, 11, 411, 3847, 264, 20828, 1639, 382], "temperature": 0.0, "avg_logprob": -0.21854774987519676, "compression_ratio": 1.6303030303030304, "no_speech_prob": 1.16593937491416e-05}, {"id": 816, "seek": 541732, "start": 5436.58, "end": 5445.5199999999995, "text": " best as we can, stop, train the generator as best as we can, so instead what the original", "tokens": [1151, 382, 321, 393, 11, 1590, 11, 3847, 264, 19265, 382, 1151, 382, 321, 393, 11, 370, 2602, 437, 264, 3380], "temperature": 0.0, "avg_logprob": -0.21854774987519676, "compression_ratio": 1.6303030303030304, "no_speech_prob": 1.16593937491416e-05}, {"id": 817, "seek": 544552, "start": 5445.52, "end": 5456.280000000001, "text": " GAN paper is called Generative Adversarial Nets. And what they did was to, and here you", "tokens": [460, 1770, 3035, 307, 1219, 15409, 1166, 1999, 840, 44745, 426, 1385, 13, 400, 437, 436, 630, 390, 281, 11, 293, 510, 291], "temperature": 0.0, "avg_logprob": -0.24142121577608414, "compression_ratio": 1.5112359550561798, "no_speech_prob": 8.267827070085332e-06}, {"id": 818, "seek": 544552, "start": 5456.280000000001, "end": 5463.400000000001, "text": " can see they've actually specified this loss function, so here it is in notation, is to", "tokens": [393, 536, 436, 600, 767, 22206, 341, 4470, 2445, 11, 370, 510, 309, 307, 294, 24657, 11, 307, 281], "temperature": 0.0, "avg_logprob": -0.24142121577608414, "compression_ratio": 1.5112359550561798, "no_speech_prob": 8.267827070085332e-06}, {"id": 819, "seek": 544552, "start": 5463.400000000001, "end": 5471.080000000001, "text": " call it minimizing the generator whilst maximizing the discriminator. This is what min-max is", "tokens": [818, 309, 46608, 264, 19265, 18534, 5138, 3319, 264, 20828, 1639, 13, 639, 307, 437, 923, 12, 41167, 307], "temperature": 0.0, "avg_logprob": -0.24142121577608414, "compression_ratio": 1.5112359550561798, "no_speech_prob": 8.267827070085332e-06}, {"id": 820, "seek": 547108, "start": 5471.08, "end": 5477.68, "text": " referring to. What they do in practice is they do it a batch at a time. So they have", "tokens": [13761, 281, 13, 708, 436, 360, 294, 3124, 307, 436, 360, 309, 257, 15245, 412, 257, 565, 13, 407, 436, 362], "temperature": 0.0, "avg_logprob": -0.12653530005252722, "compression_ratio": 2.0, "no_speech_prob": 4.356862518761773e-06}, {"id": 821, "seek": 547108, "start": 5477.68, "end": 5481.16, "text": " a loop, and we're going to go through a loop and do a single batch, put it through the", "tokens": [257, 6367, 11, 293, 321, 434, 516, 281, 352, 807, 257, 6367, 293, 360, 257, 2167, 15245, 11, 829, 309, 807, 264], "temperature": 0.0, "avg_logprob": -0.12653530005252722, "compression_ratio": 2.0, "no_speech_prob": 4.356862518761773e-06}, {"id": 822, "seek": 547108, "start": 5481.16, "end": 5486.48, "text": " discriminator, that same batch, stick it through the generator. So we're going to do it a batch", "tokens": [20828, 1639, 11, 300, 912, 15245, 11, 2897, 309, 807, 264, 19265, 13, 407, 321, 434, 516, 281, 360, 309, 257, 15245], "temperature": 0.0, "avg_logprob": -0.12653530005252722, "compression_ratio": 2.0, "no_speech_prob": 4.356862518761773e-06}, {"id": 823, "seek": 547108, "start": 5486.48, "end": 5488.04, "text": " at a time.", "tokens": [412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.12653530005252722, "compression_ratio": 2.0, "no_speech_prob": 4.356862518761773e-06}, {"id": 824, "seek": 547108, "start": 5488.04, "end": 5495.08, "text": " So let's look at that. So here's the original GAN from that paper, and we're going to do", "tokens": [407, 718, 311, 574, 412, 300, 13, 407, 510, 311, 264, 3380, 460, 1770, 490, 300, 3035, 11, 293, 321, 434, 516, 281, 360], "temperature": 0.0, "avg_logprob": -0.12653530005252722, "compression_ratio": 2.0, "no_speech_prob": 4.356862518761773e-06}, {"id": 825, "seek": 547108, "start": 5495.08, "end": 5499.92, "text": " it on MNIST. And what we're going to do is we're going to see if we can start from scratch", "tokens": [309, 322, 376, 45, 19756, 13, 400, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 536, 498, 321, 393, 722, 490, 8459], "temperature": 0.0, "avg_logprob": -0.12653530005252722, "compression_ratio": 2.0, "no_speech_prob": 4.356862518761773e-06}, {"id": 826, "seek": 549992, "start": 5499.92, "end": 5509.16, "text": " to create something which can create images which the discriminator cannot tell whether", "tokens": [281, 1884, 746, 597, 393, 1884, 5267, 597, 264, 20828, 1639, 2644, 980, 1968], "temperature": 0.0, "avg_logprob": -0.1579590220200388, "compression_ratio": 1.6149732620320856, "no_speech_prob": 9.818272701522801e-06}, {"id": 827, "seek": 549992, "start": 5509.16, "end": 5514.68, "text": " they're real or fake. It's a discriminator that has learned to be good at discriminating", "tokens": [436, 434, 957, 420, 7592, 13, 467, 311, 257, 20828, 1639, 300, 575, 3264, 281, 312, 665, 412, 20828, 990], "temperature": 0.0, "avg_logprob": -0.1579590220200388, "compression_ratio": 1.6149732620320856, "no_speech_prob": 9.818272701522801e-06}, {"id": 828, "seek": 549992, "start": 5514.68, "end": 5518.84, "text": " real from fake pictures of MNIST images.", "tokens": [957, 490, 7592, 5242, 295, 376, 45, 19756, 5267, 13], "temperature": 0.0, "avg_logprob": -0.1579590220200388, "compression_ratio": 1.6149732620320856, "no_speech_prob": 9.818272701522801e-06}, {"id": 829, "seek": 549992, "start": 5518.84, "end": 5524.16, "text": " So load in MNIST, and the first thing they do in the paper is to just use a standard", "tokens": [407, 3677, 294, 376, 45, 19756, 11, 293, 264, 700, 551, 436, 360, 294, 264, 3035, 307, 281, 445, 764, 257, 3832], "temperature": 0.0, "avg_logprob": -0.1579590220200388, "compression_ratio": 1.6149732620320856, "no_speech_prob": 9.818272701522801e-06}, {"id": 830, "seek": 552416, "start": 5524.16, "end": 5538.599999999999, "text": " multilayer perceptron. So here's our generator, it's just a standard multilayer perceptron,", "tokens": [2120, 388, 11167, 43276, 2044, 13, 407, 510, 311, 527, 19265, 11, 309, 311, 445, 257, 3832, 2120, 388, 11167, 43276, 2044, 11], "temperature": 0.0, "avg_logprob": -0.13248639636569554, "compression_ratio": 1.7419354838709677, "no_speech_prob": 1.1300715414108709e-05}, {"id": 831, "seek": 552416, "start": 5538.599999999999, "end": 5544.5199999999995, "text": " and here's our discriminator, which is also a standard multilayer perceptron. The generator", "tokens": [293, 510, 311, 527, 20828, 1639, 11, 597, 307, 611, 257, 3832, 2120, 388, 11167, 43276, 2044, 13, 440, 19265], "temperature": 0.0, "avg_logprob": -0.13248639636569554, "compression_ratio": 1.7419354838709677, "no_speech_prob": 1.1300715414108709e-05}, {"id": 832, "seek": 552416, "start": 5544.5199999999995, "end": 5549.76, "text": " has a sigmoid activation, so in other words we're going to spit out an image where all", "tokens": [575, 257, 4556, 3280, 327, 24433, 11, 370, 294, 661, 2283, 321, 434, 516, 281, 22127, 484, 364, 3256, 689, 439], "temperature": 0.0, "avg_logprob": -0.13248639636569554, "compression_ratio": 1.7419354838709677, "no_speech_prob": 1.1300715414108709e-05}, {"id": 833, "seek": 554976, "start": 5549.76, "end": 5554.360000000001, "text": " of the pixels are between 0 and 1, so if you want to print it out, we'll just multiply", "tokens": [295, 264, 18668, 366, 1296, 1958, 293, 502, 11, 370, 498, 291, 528, 281, 4482, 309, 484, 11, 321, 603, 445, 12972], "temperature": 0.0, "avg_logprob": -0.2022595553054023, "compression_ratio": 1.6863636363636363, "no_speech_prob": 7.646501217095647e-06}, {"id": 834, "seek": 554976, "start": 5554.360000000001, "end": 5556.280000000001, "text": " it by 255.", "tokens": [309, 538, 3552, 20, 13], "temperature": 0.0, "avg_logprob": -0.2022595553054023, "compression_ratio": 1.6863636363636363, "no_speech_prob": 7.646501217095647e-06}, {"id": 835, "seek": 554976, "start": 5556.280000000001, "end": 5562.6, "text": " So there's our generator, there's our discriminator. So there's then the combination of the two.", "tokens": [407, 456, 311, 527, 19265, 11, 456, 311, 527, 20828, 1639, 13, 407, 456, 311, 550, 264, 6562, 295, 264, 732, 13], "temperature": 0.0, "avg_logprob": -0.2022595553054023, "compression_ratio": 1.6863636363636363, "no_speech_prob": 7.646501217095647e-06}, {"id": 836, "seek": 554976, "start": 5562.6, "end": 5566.360000000001, "text": " So take the generator and stick it into the discriminator, so we can just use sequential", "tokens": [407, 747, 264, 19265, 293, 2897, 309, 666, 264, 20828, 1639, 11, 370, 321, 393, 445, 764, 42881], "temperature": 0.0, "avg_logprob": -0.2022595553054023, "compression_ratio": 1.6863636363636363, "no_speech_prob": 7.646501217095647e-06}, {"id": 837, "seek": 554976, "start": 5566.360000000001, "end": 5572.320000000001, "text": " for that. And this is actually therefore the loss function that I want on my generator.", "tokens": [337, 300, 13, 400, 341, 307, 767, 4412, 264, 4470, 2445, 300, 286, 528, 322, 452, 19265, 13], "temperature": 0.0, "avg_logprob": -0.2022595553054023, "compression_ratio": 1.6863636363636363, "no_speech_prob": 7.646501217095647e-06}, {"id": 838, "seek": 557232, "start": 5572.32, "end": 5579.799999999999, "text": " Just generate something and see if you can fool the discriminator. So there's all my", "tokens": [1449, 8460, 746, 293, 536, 498, 291, 393, 7979, 264, 20828, 1639, 13, 407, 456, 311, 439, 452], "temperature": 0.0, "avg_logprob": -0.151952758667961, "compression_ratio": 1.7065217391304348, "no_speech_prob": 1.0953056516882498e-05}, {"id": 839, "seek": 557232, "start": 5579.799999999999, "end": 5581.5599999999995, "text": " architectures set up.", "tokens": [6331, 1303, 992, 493, 13], "temperature": 0.0, "avg_logprob": -0.151952758667961, "compression_ratio": 1.7065217391304348, "no_speech_prob": 1.0953056516882498e-05}, {"id": 840, "seek": 557232, "start": 5581.5599999999995, "end": 5585.44, "text": " So the next thing I need to do is set up this thing called train, which is going to do this", "tokens": [407, 264, 958, 551, 286, 643, 281, 360, 307, 992, 493, 341, 551, 1219, 3847, 11, 597, 307, 516, 281, 360, 341], "temperature": 0.0, "avg_logprob": -0.151952758667961, "compression_ratio": 1.7065217391304348, "no_speech_prob": 1.0953056516882498e-05}, {"id": 841, "seek": 557232, "start": 5585.44, "end": 5591.92, "text": " adversarial training. Let's go back and have a look at train. So what train is going to", "tokens": [17641, 44745, 3097, 13, 961, 311, 352, 646, 293, 362, 257, 574, 412, 3847, 13, 407, 437, 3847, 307, 516, 281], "temperature": 0.0, "avg_logprob": -0.151952758667961, "compression_ratio": 1.7065217391304348, "no_speech_prob": 1.0953056516882498e-05}, {"id": 842, "seek": 557232, "start": 5591.92, "end": 5598.44, "text": " do is go through a bunch of epochs. And notice here I wrap it in this TQDM, this is the thing", "tokens": [360, 307, 352, 807, 257, 3840, 295, 30992, 28346, 13, 400, 3449, 510, 286, 7019, 309, 294, 341, 314, 48, 35, 44, 11, 341, 307, 264, 551], "temperature": 0.0, "avg_logprob": -0.151952758667961, "compression_ratio": 1.7065217391304348, "no_speech_prob": 1.0953056516882498e-05}, {"id": 843, "seek": 557232, "start": 5598.44, "end": 5601.599999999999, "text": " that creates a nice little poke progress bar. It doesn't do anything else, it just creates", "tokens": [300, 7829, 257, 1481, 707, 19712, 4205, 2159, 13, 467, 1177, 380, 360, 1340, 1646, 11, 309, 445, 7829], "temperature": 0.0, "avg_logprob": -0.151952758667961, "compression_ratio": 1.7065217391304348, "no_speech_prob": 1.0953056516882498e-05}, {"id": 844, "seek": 560160, "start": 5601.6, "end": 5605.160000000001, "text": " a little progress bar. We learned about that last week.", "tokens": [257, 707, 4205, 2159, 13, 492, 3264, 466, 300, 1036, 1243, 13], "temperature": 0.0, "avg_logprob": -0.14828365150539355, "compression_ratio": 1.772972972972973, "no_speech_prob": 4.860433818976162e-06}, {"id": 845, "seek": 560160, "start": 5605.160000000001, "end": 5611.56, "text": " So the first thing I need to do is to generate some data to feed the discriminator. So I've", "tokens": [407, 264, 700, 551, 286, 643, 281, 360, 307, 281, 8460, 512, 1412, 281, 3154, 264, 20828, 1639, 13, 407, 286, 600], "temperature": 0.0, "avg_logprob": -0.14828365150539355, "compression_ratio": 1.772972972972973, "no_speech_prob": 4.860433818976162e-06}, {"id": 846, "seek": 560160, "start": 5611.56, "end": 5616.400000000001, "text": " created a little function for that, and here's my little function. So it's going to create", "tokens": [2942, 257, 707, 2445, 337, 300, 11, 293, 510, 311, 452, 707, 2445, 13, 407, 309, 311, 516, 281, 1884], "temperature": 0.0, "avg_logprob": -0.14828365150539355, "compression_ratio": 1.772972972972973, "no_speech_prob": 4.860433818976162e-06}, {"id": 847, "seek": 560160, "start": 5616.400000000001, "end": 5622.4400000000005, "text": " a little bit of data that's real and a little bit of data that's fake. So my real data is", "tokens": [257, 707, 857, 295, 1412, 300, 311, 957, 293, 257, 707, 857, 295, 1412, 300, 311, 7592, 13, 407, 452, 957, 1412, 307], "temperature": 0.0, "avg_logprob": -0.14828365150539355, "compression_ratio": 1.772972972972973, "no_speech_prob": 4.860433818976162e-06}, {"id": 848, "seek": 562244, "start": 5622.44, "end": 5632.839999999999, "text": " going to go into my actual training set and grab some randomly selected MNIST digits.", "tokens": [516, 281, 352, 666, 452, 3539, 3097, 992, 293, 4444, 512, 16979, 8209, 376, 45, 19756, 27011, 13], "temperature": 0.0, "avg_logprob": -0.20305905197605942, "compression_ratio": 1.494186046511628, "no_speech_prob": 5.955127107881708e-06}, {"id": 849, "seek": 562244, "start": 5632.839999999999, "end": 5639.28, "text": " And then let's create some fake. So noise is a function that I've just created up here,", "tokens": [400, 550, 718, 311, 1884, 512, 7592, 13, 407, 5658, 307, 257, 2445, 300, 286, 600, 445, 2942, 493, 510, 11], "temperature": 0.0, "avg_logprob": -0.20305905197605942, "compression_ratio": 1.494186046511628, "no_speech_prob": 5.955127107881708e-06}, {"id": 850, "seek": 562244, "start": 5639.28, "end": 5647.679999999999, "text": " which creates some 100 random numbers. So let's create some noise called g.predict.", "tokens": [597, 7829, 512, 2319, 4974, 3547, 13, 407, 718, 311, 1884, 512, 5658, 1219, 290, 13, 79, 24945, 13], "temperature": 0.0, "avg_logprob": -0.20305905197605942, "compression_ratio": 1.494186046511628, "no_speech_prob": 5.955127107881708e-06}, {"id": 851, "seek": 564768, "start": 5647.68, "end": 5653.0, "text": " And so then I'll concatenate the two together. So now I've got some real data and some fake", "tokens": [400, 370, 550, 286, 603, 1588, 7186, 473, 264, 732, 1214, 13, 407, 586, 286, 600, 658, 512, 957, 1412, 293, 512, 7592], "temperature": 0.0, "avg_logprob": -0.15749700701966576, "compression_ratio": 1.7587939698492463, "no_speech_prob": 6.0488896451715846e-06}, {"id": 852, "seek": 564768, "start": 5653.0, "end": 5658.68, "text": " data. So this is going to try and predict whether or not something is fake. So 1 means", "tokens": [1412, 13, 407, 341, 307, 516, 281, 853, 293, 6069, 1968, 420, 406, 746, 307, 7592, 13, 407, 502, 1355], "temperature": 0.0, "avg_logprob": -0.15749700701966576, "compression_ratio": 1.7587939698492463, "no_speech_prob": 6.0488896451715846e-06}, {"id": 853, "seek": 564768, "start": 5658.68, "end": 5668.280000000001, "text": " fake, 0 means real. So I'm going to return my data and my labels, which is a bunch of", "tokens": [7592, 11, 1958, 1355, 957, 13, 407, 286, 478, 516, 281, 2736, 452, 1412, 293, 452, 16949, 11, 597, 307, 257, 3840, 295], "temperature": 0.0, "avg_logprob": -0.15749700701966576, "compression_ratio": 1.7587939698492463, "no_speech_prob": 6.0488896451715846e-06}, {"id": 854, "seek": 564768, "start": 5668.280000000001, "end": 5672.88, "text": " zeros to say they're all real and a bunch of ones to say they're all fake. So there's", "tokens": [35193, 281, 584, 436, 434, 439, 957, 293, 257, 3840, 295, 2306, 281, 584, 436, 434, 439, 7592, 13, 407, 456, 311], "temperature": 0.0, "avg_logprob": -0.15749700701966576, "compression_ratio": 1.7587939698492463, "no_speech_prob": 6.0488896451715846e-06}, {"id": 855, "seek": 567288, "start": 5672.88, "end": 5681.2, "text": " my discriminator's data. So go ahead and create a set of data for the discriminator and then", "tokens": [452, 20828, 1639, 311, 1412, 13, 407, 352, 2286, 293, 1884, 257, 992, 295, 1412, 337, 264, 20828, 1639, 293, 550], "temperature": 0.0, "avg_logprob": -0.12938438415527342, "compression_ratio": 1.853658536585366, "no_speech_prob": 1.0289449164702091e-05}, {"id": 856, "seek": 567288, "start": 5681.2, "end": 5685.6, "text": " do one batch of training.", "tokens": [360, 472, 15245, 295, 3097, 13], "temperature": 0.0, "avg_logprob": -0.12938438415527342, "compression_ratio": 1.853658536585366, "no_speech_prob": 1.0289449164702091e-05}, {"id": 857, "seek": 567288, "start": 5685.6, "end": 5690.28, "text": " Now I'm going to do the same thing for the generator, but when I train the generator,", "tokens": [823, 286, 478, 516, 281, 360, 264, 912, 551, 337, 264, 19265, 11, 457, 562, 286, 3847, 264, 19265, 11], "temperature": 0.0, "avg_logprob": -0.12938438415527342, "compression_ratio": 1.853658536585366, "no_speech_prob": 1.0289449164702091e-05}, {"id": 858, "seek": 567288, "start": 5690.28, "end": 5696.16, "text": " I don't want to change the discriminator's weights. So make trainable simply goes through", "tokens": [286, 500, 380, 528, 281, 1319, 264, 20828, 1639, 311, 17443, 13, 407, 652, 3847, 712, 2935, 1709, 807], "temperature": 0.0, "avg_logprob": -0.12938438415527342, "compression_ratio": 1.853658536585366, "no_speech_prob": 1.0289449164702091e-05}, {"id": 859, "seek": 567288, "start": 5696.16, "end": 5701.72, "text": " each layer and says it's not trainable. So make my discriminator non-trainable and do", "tokens": [1184, 4583, 293, 1619, 309, 311, 406, 3847, 712, 13, 407, 652, 452, 20828, 1639, 2107, 12, 83, 7146, 712, 293, 360], "temperature": 0.0, "avg_logprob": -0.12938438415527342, "compression_ratio": 1.853658536585366, "no_speech_prob": 1.0289449164702091e-05}, {"id": 860, "seek": 570172, "start": 5701.72, "end": 5710.8, "text": " one batch of training where I'm taking noise as my inputs and my goal is to get the discriminator", "tokens": [472, 15245, 295, 3097, 689, 286, 478, 1940, 5658, 382, 452, 15743, 293, 452, 3387, 307, 281, 483, 264, 20828, 1639], "temperature": 0.0, "avg_logprob": -0.1658294049999382, "compression_ratio": 1.578125, "no_speech_prob": 6.048896011634497e-06}, {"id": 861, "seek": 570172, "start": 5710.8, "end": 5717.280000000001, "text": " to think that they are actually real. So that's why I'm passing in a bunch of zeros, because", "tokens": [281, 519, 300, 436, 366, 767, 957, 13, 407, 300, 311, 983, 286, 478, 8437, 294, 257, 3840, 295, 35193, 11, 570], "temperature": 0.0, "avg_logprob": -0.1658294049999382, "compression_ratio": 1.578125, "no_speech_prob": 6.048896011634497e-06}, {"id": 862, "seek": 570172, "start": 5717.280000000001, "end": 5720.68, "text": " remember 0 means real.", "tokens": [1604, 1958, 1355, 957, 13], "temperature": 0.0, "avg_logprob": -0.1658294049999382, "compression_ratio": 1.578125, "no_speech_prob": 6.048896011634497e-06}, {"id": 863, "seek": 570172, "start": 5720.68, "end": 5725.04, "text": " And that's it. And then make discriminator trainable again. So keep looping through this.", "tokens": [400, 300, 311, 309, 13, 400, 550, 652, 20828, 1639, 3847, 712, 797, 13, 407, 1066, 6367, 278, 807, 341, 13], "temperature": 0.0, "avg_logprob": -0.1658294049999382, "compression_ratio": 1.578125, "no_speech_prob": 6.048896011634497e-06}, {"id": 864, "seek": 572504, "start": 5725.04, "end": 5732.12, "text": " Train the discriminator on a batch of half real, half fake, and then train the generator", "tokens": [28029, 264, 20828, 1639, 322, 257, 15245, 295, 1922, 957, 11, 1922, 7592, 11, 293, 550, 3847, 264, 19265], "temperature": 0.0, "avg_logprob": -0.18560149643447374, "compression_ratio": 1.642156862745098, "no_speech_prob": 3.187554966643802e-06}, {"id": 865, "seek": 572504, "start": 5732.12, "end": 5739.38, "text": " to try and trick the discriminator using all fake. Repeat.", "tokens": [281, 853, 293, 4282, 264, 20828, 1639, 1228, 439, 7592, 13, 28523, 13], "temperature": 0.0, "avg_logprob": -0.18560149643447374, "compression_ratio": 1.642156862745098, "no_speech_prob": 3.187554966643802e-06}, {"id": 866, "seek": 572504, "start": 5739.38, "end": 5745.24, "text": " So that's the training loop. That's the basic GAN. Because we use TQDM, we get a nice little", "tokens": [407, 300, 311, 264, 3097, 6367, 13, 663, 311, 264, 3875, 460, 1770, 13, 1436, 321, 764, 314, 48, 35, 44, 11, 321, 483, 257, 1481, 707], "temperature": 0.0, "avg_logprob": -0.18560149643447374, "compression_ratio": 1.642156862745098, "no_speech_prob": 3.187554966643802e-06}, {"id": 867, "seek": 572504, "start": 5745.24, "end": 5754.68, "text": " progress bar. We can plot out the loss at each step. So there's our loss for the discriminator", "tokens": [4205, 2159, 13, 492, 393, 7542, 484, 264, 4470, 412, 1184, 1823, 13, 407, 456, 311, 527, 4470, 337, 264, 20828, 1639], "temperature": 0.0, "avg_logprob": -0.18560149643447374, "compression_ratio": 1.642156862745098, "no_speech_prob": 3.187554966643802e-06}, {"id": 868, "seek": 575468, "start": 5754.68, "end": 5759.08, "text": " and there's our loss for the generator. So the question is, what do these loss curves", "tokens": [293, 456, 311, 527, 4470, 337, 264, 19265, 13, 407, 264, 1168, 307, 11, 437, 360, 613, 4470, 19490], "temperature": 0.0, "avg_logprob": -0.12754759872168825, "compression_ratio": 1.7224334600760456, "no_speech_prob": 8.530270861228928e-06}, {"id": 869, "seek": 575468, "start": 5759.08, "end": 5766.8, "text": " mean? Are they good or bad? How do we know? And the answer is, for this kind of GAN, they", "tokens": [914, 30, 2014, 436, 665, 420, 1578, 30, 1012, 360, 321, 458, 30, 400, 264, 1867, 307, 11, 337, 341, 733, 295, 460, 1770, 11, 436], "temperature": 0.0, "avg_logprob": -0.12754759872168825, "compression_ratio": 1.7224334600760456, "no_speech_prob": 8.530270861228928e-06}, {"id": 870, "seek": 575468, "start": 5766.8, "end": 5772.6, "text": " mean nothing at all. The generator could get fantastic, but it could be because the discriminator", "tokens": [914, 1825, 412, 439, 13, 440, 19265, 727, 483, 5456, 11, 457, 309, 727, 312, 570, 264, 20828, 1639], "temperature": 0.0, "avg_logprob": -0.12754759872168825, "compression_ratio": 1.7224334600760456, "no_speech_prob": 8.530270861228928e-06}, {"id": 871, "seek": 575468, "start": 5772.6, "end": 5778.34, "text": " is terrible. And they don't really know whether each one is good or not, so even the order", "tokens": [307, 6237, 13, 400, 436, 500, 380, 534, 458, 1968, 1184, 472, 307, 665, 420, 406, 11, 370, 754, 264, 1668], "temperature": 0.0, "avg_logprob": -0.12754759872168825, "compression_ratio": 1.7224334600760456, "no_speech_prob": 8.530270861228928e-06}, {"id": 872, "seek": 575468, "start": 5778.34, "end": 5783.360000000001, "text": " of magnitude of both of them is meaningless. So these curves mean nothing. The direction", "tokens": [295, 15668, 295, 1293, 295, 552, 307, 33232, 13, 407, 613, 19490, 914, 1825, 13, 440, 3513], "temperature": 0.0, "avg_logprob": -0.12754759872168825, "compression_ratio": 1.7224334600760456, "no_speech_prob": 8.530270861228928e-06}, {"id": 873, "seek": 578336, "start": 5783.36, "end": 5790.0, "text": " of the curves mean nothing. And this is one of the real difficulties with training GANs.", "tokens": [295, 264, 19490, 914, 1825, 13, 400, 341, 307, 472, 295, 264, 957, 14399, 365, 3097, 460, 1770, 82, 13], "temperature": 0.0, "avg_logprob": -0.1542743315179664, "compression_ratio": 1.5497835497835497, "no_speech_prob": 4.936976438330021e-06}, {"id": 874, "seek": 578336, "start": 5790.0, "end": 5796.799999999999, "text": " And here's what happens when I plot 12 randomly selected random noise vectors stuck through", "tokens": [400, 510, 311, 437, 2314, 562, 286, 7542, 2272, 16979, 8209, 4974, 5658, 18875, 5541, 807], "temperature": 0.0, "avg_logprob": -0.1542743315179664, "compression_ratio": 1.5497835497835497, "no_speech_prob": 4.936976438330021e-06}, {"id": 875, "seek": 578336, "start": 5796.799999999999, "end": 5801.4, "text": " there and we have not got things that look terribly like MS digits and they also don't", "tokens": [456, 293, 321, 362, 406, 658, 721, 300, 574, 22903, 411, 7395, 27011, 293, 436, 611, 500, 380], "temperature": 0.0, "avg_logprob": -0.1542743315179664, "compression_ratio": 1.5497835497835497, "no_speech_prob": 4.936976438330021e-06}, {"id": 876, "seek": 578336, "start": 5801.4, "end": 5812.94, "text": " look terribly much like they have a lot of variety. This is called mode class. Very common", "tokens": [574, 22903, 709, 411, 436, 362, 257, 688, 295, 5673, 13, 639, 307, 1219, 4391, 1508, 13, 4372, 2689], "temperature": 0.0, "avg_logprob": -0.1542743315179664, "compression_ratio": 1.5497835497835497, "no_speech_prob": 4.936976438330021e-06}, {"id": 877, "seek": 581294, "start": 5812.94, "end": 5819.08, "text": " problem when training GANs. And what it means is that the generator and the discriminator", "tokens": [1154, 562, 3097, 460, 1770, 82, 13, 400, 437, 309, 1355, 307, 300, 264, 19265, 293, 264, 20828, 1639], "temperature": 0.0, "avg_logprob": -0.19474889119466146, "compression_ratio": 1.4827586206896552, "no_speech_prob": 4.936950972478371e-06}, {"id": 878, "seek": 581294, "start": 5819.08, "end": 5826.48, "text": " have kind of reached a stalemate where neither of them basically knows how to go from here.", "tokens": [362, 733, 295, 6488, 257, 49875, 443, 473, 689, 9662, 295, 552, 1936, 3255, 577, 281, 352, 490, 510, 13], "temperature": 0.0, "avg_logprob": -0.19474889119466146, "compression_ratio": 1.4827586206896552, "no_speech_prob": 4.936950972478371e-06}, {"id": 879, "seek": 581294, "start": 5826.48, "end": 5834.04, "text": " And in terms of optimization, we've basically found a local minimum. So that was not very", "tokens": [400, 294, 2115, 295, 19618, 11, 321, 600, 1936, 1352, 257, 2654, 7285, 13, 407, 300, 390, 406, 588], "temperature": 0.0, "avg_logprob": -0.19474889119466146, "compression_ratio": 1.4827586206896552, "no_speech_prob": 4.936950972478371e-06}, {"id": 880, "seek": 581294, "start": 5834.04, "end": 5836.16, "text": " successful. Can we do better?", "tokens": [4406, 13, 1664, 321, 360, 1101, 30], "temperature": 0.0, "avg_logprob": -0.19474889119466146, "compression_ratio": 1.4827586206896552, "no_speech_prob": 4.936950972478371e-06}, {"id": 881, "seek": 583616, "start": 5836.16, "end": 5848.0, "text": " So the next major paper that came along was this one, Unsupervised Representation Learning", "tokens": [407, 264, 958, 2563, 3035, 300, 1361, 2051, 390, 341, 472, 11, 25017, 12879, 24420, 19945, 399, 15205], "temperature": 0.0, "avg_logprob": -0.1834087091333726, "compression_ratio": 1.4378378378378378, "no_speech_prob": 7.1831759669294115e-06}, {"id": 882, "seek": 583616, "start": 5848.0, "end": 5853.96, "text": " with Deep Convolutional Gerative Adversarial Networks. So this created something that they", "tokens": [365, 14895, 2656, 85, 3386, 304, 9409, 1166, 1999, 840, 44745, 12640, 82, 13, 407, 341, 2942, 746, 300, 436], "temperature": 0.0, "avg_logprob": -0.1834087091333726, "compression_ratio": 1.4378378378378378, "no_speech_prob": 7.1831759669294115e-06}, {"id": 883, "seek": 583616, "start": 5853.96, "end": 5862.2, "text": " called DC GANs. And the main page that you want to look at here is page 3 where they", "tokens": [1219, 9114, 460, 1770, 82, 13, 400, 264, 2135, 3028, 300, 291, 528, 281, 574, 412, 510, 307, 3028, 805, 689, 436], "temperature": 0.0, "avg_logprob": -0.1834087091333726, "compression_ratio": 1.4378378378378378, "no_speech_prob": 7.1831759669294115e-06}, {"id": 884, "seek": 586220, "start": 5862.2, "end": 5868.12, "text": " say core to our approach is doing these 3 things. And basically what they do is they", "tokens": [584, 4965, 281, 527, 3109, 307, 884, 613, 805, 721, 13, 400, 1936, 437, 436, 360, 307, 436], "temperature": 0.0, "avg_logprob": -0.20408536676774947, "compression_ratio": 1.7745901639344261, "no_speech_prob": 7.071859272400616e-06}, {"id": 885, "seek": 586220, "start": 5868.12, "end": 5874.12, "text": " just do exactly the same thing as GANs, but they do 3 things. One is to use the kinds", "tokens": [445, 360, 2293, 264, 912, 551, 382, 460, 1770, 82, 11, 457, 436, 360, 805, 721, 13, 1485, 307, 281, 764, 264, 3685], "temperature": 0.0, "avg_logprob": -0.20408536676774947, "compression_ratio": 1.7745901639344261, "no_speech_prob": 7.071859272400616e-06}, {"id": 886, "seek": 586220, "start": 5874.12, "end": 5879.36, "text": " of, all of them is to learn the tricks that we've been learning for generative models.", "tokens": [295, 11, 439, 295, 552, 307, 281, 1466, 264, 11733, 300, 321, 600, 668, 2539, 337, 1337, 1166, 5245, 13], "temperature": 0.0, "avg_logprob": -0.20408536676774947, "compression_ratio": 1.7745901639344261, "no_speech_prob": 7.071859272400616e-06}, {"id": 887, "seek": 586220, "start": 5879.36, "end": 5886.5599999999995, "text": " Use an all-convolutional net, get rid of max pooling and use strata convolutions instead,", "tokens": [8278, 364, 439, 12, 1671, 85, 3386, 304, 2533, 11, 483, 3973, 295, 11469, 7005, 278, 293, 764, 1056, 3274, 3754, 15892, 2602, 11], "temperature": 0.0, "avg_logprob": -0.20408536676774947, "compression_ratio": 1.7745901639344261, "no_speech_prob": 7.071859272400616e-06}, {"id": 888, "seek": 586220, "start": 5886.5599999999995, "end": 5890.36, "text": " get rid of fully connected layers and use lots of convolutional features instead, and", "tokens": [483, 3973, 295, 4498, 4582, 7914, 293, 764, 3195, 295, 3754, 2308, 1966, 4122, 2602, 11, 293], "temperature": 0.0, "avg_logprob": -0.20408536676774947, "compression_ratio": 1.7745901639344261, "no_speech_prob": 7.071859272400616e-06}, {"id": 889, "seek": 589036, "start": 5890.36, "end": 5897.16, "text": " add in batch norm. And then use a CNN rather than MLP.", "tokens": [909, 294, 15245, 2026, 13, 400, 550, 764, 257, 24859, 2831, 813, 21601, 47, 13], "temperature": 0.0, "avg_logprob": -0.16075455624124277, "compression_ratio": 1.5471698113207548, "no_speech_prob": 4.936976438330021e-06}, {"id": 890, "seek": 589036, "start": 5897.16, "end": 5904.44, "text": " So here is that. This will all look very familiar, it looks just like last lesson stuff. So the", "tokens": [407, 510, 307, 300, 13, 639, 486, 439, 574, 588, 4963, 11, 309, 1542, 445, 411, 1036, 6898, 1507, 13, 407, 264], "temperature": 0.0, "avg_logprob": -0.16075455624124277, "compression_ratio": 1.5471698113207548, "no_speech_prob": 4.936976438330021e-06}, {"id": 891, "seek": 589036, "start": 5904.44, "end": 5913.88, "text": " generator is going to take in a random grid of inputs, it's going to do a batch norm,", "tokens": [19265, 307, 516, 281, 747, 294, 257, 4974, 10748, 295, 15743, 11, 309, 311, 516, 281, 360, 257, 15245, 2026, 11], "temperature": 0.0, "avg_logprob": -0.16075455624124277, "compression_ratio": 1.5471698113207548, "no_speech_prob": 4.936976438330021e-06}, {"id": 892, "seek": 589036, "start": 5913.88, "end": 5919.04, "text": " upsample. You'll notice that I'm doing even newer than this paper, I'm doing the upsampling", "tokens": [15497, 335, 781, 13, 509, 603, 3449, 300, 286, 478, 884, 754, 17628, 813, 341, 3035, 11, 286, 478, 884, 264, 15497, 335, 11970], "temperature": 0.0, "avg_logprob": -0.16075455624124277, "compression_ratio": 1.5471698113207548, "no_speech_prob": 4.936976438330021e-06}, {"id": 893, "seek": 591904, "start": 5919.04, "end": 5926.68, "text": " approach because we know that's better. Upsample, 1x1 conv, batch norm, upsample, 1x1 conv,", "tokens": [3109, 570, 321, 458, 300, 311, 1101, 13, 624, 1878, 335, 781, 11, 502, 87, 16, 3754, 11, 15245, 2026, 11, 15497, 335, 781, 11, 502, 87, 16, 3754, 11], "temperature": 0.0, "avg_logprob": -0.18956522319627844, "compression_ratio": 1.6237113402061856, "no_speech_prob": 1.0289437341270968e-05}, {"id": 894, "seek": 591904, "start": 5926.68, "end": 5931.32, "text": " batch norm, and then a final conv layer.", "tokens": [15245, 2026, 11, 293, 550, 257, 2572, 3754, 4583, 13], "temperature": 0.0, "avg_logprob": -0.18956522319627844, "compression_ratio": 1.6237113402061856, "no_speech_prob": 1.0289437341270968e-05}, {"id": 895, "seek": 591904, "start": 5931.32, "end": 5937.6, "text": " Discriminator basically does the opposite, which is some 2x2 subsamplings, so downsampling", "tokens": [19839, 16796, 1639, 1936, 775, 264, 6182, 11, 597, 307, 512, 568, 87, 17, 2090, 335, 26921, 11, 370, 760, 19988, 11970], "temperature": 0.0, "avg_logprob": -0.18956522319627844, "compression_ratio": 1.6237113402061856, "no_speech_prob": 1.0289437341270968e-05}, {"id": 896, "seek": 591904, "start": 5937.6, "end": 5943.72, "text": " in the discriminator. Another trick that they mention, I think it's mentioned in the paper,", "tokens": [294, 264, 20828, 1639, 13, 3996, 4282, 300, 436, 2152, 11, 286, 519, 309, 311, 2835, 294, 264, 3035, 11], "temperature": 0.0, "avg_logprob": -0.18956522319627844, "compression_ratio": 1.6237113402061856, "no_speech_prob": 1.0289437341270968e-05}, {"id": 897, "seek": 594372, "start": 5943.72, "end": 5949.280000000001, "text": " is to, before you do the back and forth batch for the discriminator and a batch for the", "tokens": [307, 281, 11, 949, 291, 360, 264, 646, 293, 5220, 15245, 337, 264, 20828, 1639, 293, 257, 15245, 337, 264], "temperature": 0.0, "avg_logprob": -0.1803569793701172, "compression_ratio": 1.789237668161435, "no_speech_prob": 1.3007011148147285e-05}, {"id": 898, "seek": 594372, "start": 5949.280000000001, "end": 5956.2, "text": " generator, is to train the discriminator for a fraction of an epoch, like do a few batches", "tokens": [19265, 11, 307, 281, 3847, 264, 20828, 1639, 337, 257, 14135, 295, 364, 30992, 339, 11, 411, 360, 257, 1326, 15245, 279], "temperature": 0.0, "avg_logprob": -0.1803569793701172, "compression_ratio": 1.789237668161435, "no_speech_prob": 1.3007011148147285e-05}, {"id": 899, "seek": 594372, "start": 5956.2, "end": 5959.68, "text": " through the discriminator so at least it knows how to recognize the difference between a", "tokens": [807, 264, 20828, 1639, 370, 412, 1935, 309, 3255, 577, 281, 5521, 264, 2649, 1296, 257], "temperature": 0.0, "avg_logprob": -0.1803569793701172, "compression_ratio": 1.789237668161435, "no_speech_prob": 1.3007011148147285e-05}, {"id": 900, "seek": 594372, "start": 5959.68, "end": 5963.84, "text": " random image and a real image a little bit.", "tokens": [4974, 3256, 293, 257, 957, 3256, 257, 707, 857, 13], "temperature": 0.0, "avg_logprob": -0.1803569793701172, "compression_ratio": 1.789237668161435, "no_speech_prob": 1.3007011148147285e-05}, {"id": 901, "seek": 594372, "start": 5963.84, "end": 5969.2, "text": " So you can see here I actually just start by calling discriminator.fit with just a very", "tokens": [407, 291, 393, 536, 510, 286, 767, 445, 722, 538, 5141, 20828, 1639, 13, 6845, 365, 445, 257, 588], "temperature": 0.0, "avg_logprob": -0.1803569793701172, "compression_ratio": 1.789237668161435, "no_speech_prob": 1.3007011148147285e-05}, {"id": 902, "seek": 596920, "start": 5969.2, "end": 5976.36, "text": " small amount of data. So this is kind of like bootstrapping the discriminator. And then", "tokens": [1359, 2372, 295, 1412, 13, 407, 341, 307, 733, 295, 411, 11450, 19639, 3759, 264, 20828, 1639, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.14685136621648615, "compression_ratio": 1.4696132596685083, "no_speech_prob": 5.682402843376622e-06}, {"id": 903, "seek": 596920, "start": 5976.36, "end": 5984.4, "text": " I just go ahead and call the same train as we had before with my better architectures.", "tokens": [286, 445, 352, 2286, 293, 818, 264, 912, 3847, 382, 321, 632, 949, 365, 452, 1101, 6331, 1303, 13], "temperature": 0.0, "avg_logprob": -0.14685136621648615, "compression_ratio": 1.4696132596685083, "no_speech_prob": 5.682402843376622e-06}, {"id": 904, "seek": 596920, "start": 5984.4, "end": 5991.32, "text": " And again, these curves are totally meaningless, but we have something which if you squint,", "tokens": [400, 797, 11, 613, 19490, 366, 3879, 33232, 11, 457, 321, 362, 746, 597, 498, 291, 2339, 686, 11], "temperature": 0.0, "avg_logprob": -0.14685136621648615, "compression_ratio": 1.4696132596685083, "no_speech_prob": 5.682402843376622e-06}, {"id": 905, "seek": 599132, "start": 5991.32, "end": 6001.88, "text": " you could almost convince yourself that that's a 5. So until a week or two before this course", "tokens": [291, 727, 1920, 13447, 1803, 300, 300, 311, 257, 1025, 13, 407, 1826, 257, 1243, 420, 732, 949, 341, 1164], "temperature": 0.0, "avg_logprob": -0.1806018646449259, "compression_ratio": 1.4404145077720207, "no_speech_prob": 7.296337116713403e-06}, {"id": 906, "seek": 599132, "start": 6001.88, "end": 6008.799999999999, "text": " started, this was kind of about as good as we had. People were much better at the artisanal", "tokens": [1409, 11, 341, 390, 733, 295, 466, 382, 665, 382, 321, 632, 13, 3432, 645, 709, 1101, 412, 264, 1523, 14804, 304], "temperature": 0.0, "avg_logprob": -0.1806018646449259, "compression_ratio": 1.4404145077720207, "no_speech_prob": 7.296337116713403e-06}, {"id": 907, "seek": 599132, "start": 6008.799999999999, "end": 6015.88, "text": " details of this than I was, and indeed there's a whole page called GAN Hacks, which had lots", "tokens": [4365, 295, 341, 813, 286, 390, 11, 293, 6451, 456, 311, 257, 1379, 3028, 1219, 460, 1770, 389, 7424, 11, 597, 632, 3195], "temperature": 0.0, "avg_logprob": -0.1806018646449259, "compression_ratio": 1.4404145077720207, "no_speech_prob": 7.296337116713403e-06}, {"id": 908, "seek": 601588, "start": 6015.88, "end": 6023.56, "text": " of tips. But then, a couple of weeks before this class started, as I mentioned in the", "tokens": [295, 6082, 13, 583, 550, 11, 257, 1916, 295, 3259, 949, 341, 1508, 1409, 11, 382, 286, 2835, 294, 264], "temperature": 0.0, "avg_logprob": -0.14607109342302596, "compression_ratio": 1.6144578313253013, "no_speech_prob": 1.0289429155818652e-05}, {"id": 909, "seek": 601588, "start": 6023.56, "end": 6030.6, "text": " first class, along came the Wasserstein GAN. And the Wasserstein GAN got rid of all of", "tokens": [700, 1508, 11, 2051, 1361, 264, 17351, 9089, 460, 1770, 13, 400, 264, 17351, 9089, 460, 1770, 658, 3973, 295, 439, 295], "temperature": 0.0, "avg_logprob": -0.14607109342302596, "compression_ratio": 1.6144578313253013, "no_speech_prob": 1.0289429155818652e-05}, {"id": 910, "seek": 601588, "start": 6030.6, "end": 6045.16, "text": " these problems. And here is the Wasserstein GAN paper. And this paper is quite an extraordinary", "tokens": [613, 2740, 13, 400, 510, 307, 264, 17351, 9089, 460, 1770, 3035, 13, 400, 341, 3035, 307, 1596, 364, 10581], "temperature": 0.0, "avg_logprob": -0.14607109342302596, "compression_ratio": 1.6144578313253013, "no_speech_prob": 1.0289429155818652e-05}, {"id": 911, "seek": 604516, "start": 6045.16, "end": 6051.84, "text": " paper. It's particularly extraordinary because, I think I mentioned this in the first class", "tokens": [3035, 13, 467, 311, 4098, 10581, 570, 11, 286, 519, 286, 2835, 341, 294, 264, 700, 1508], "temperature": 0.0, "avg_logprob": -0.18583782513936362, "compression_ratio": 1.669683257918552, "no_speech_prob": 6.144125109130982e-06}, {"id": 912, "seek": 604516, "start": 6051.84, "end": 6059.82, "text": " of this part, most papers tend to either be math theory that goes nowhere, or nice experiments", "tokens": [295, 341, 644, 11, 881, 10577, 3928, 281, 2139, 312, 5221, 5261, 300, 1709, 11159, 11, 420, 1481, 12050], "temperature": 0.0, "avg_logprob": -0.18583782513936362, "compression_ratio": 1.669683257918552, "no_speech_prob": 6.144125109130982e-06}, {"id": 913, "seek": 604516, "start": 6059.82, "end": 6066.24, "text": " in engineering where the theory bits are kind of hacked on at the end and kind of meaningless.", "tokens": [294, 7043, 689, 264, 5261, 9239, 366, 733, 295, 36218, 322, 412, 264, 917, 293, 733, 295, 33232, 13], "temperature": 0.0, "avg_logprob": -0.18583782513936362, "compression_ratio": 1.669683257918552, "no_speech_prob": 6.144125109130982e-06}, {"id": 914, "seek": 604516, "start": 6066.24, "end": 6074.2, "text": " This paper is entirely driven by theory, and then the theory they go on to show this is", "tokens": [639, 3035, 307, 7696, 9555, 538, 5261, 11, 293, 550, 264, 5261, 436, 352, 322, 281, 855, 341, 307], "temperature": 0.0, "avg_logprob": -0.18583782513936362, "compression_ratio": 1.669683257918552, "no_speech_prob": 6.144125109130982e-06}, {"id": 915, "seek": 607420, "start": 6074.2, "end": 6078.24, "text": " what the theory means, this is what we do, and suddenly all the problems go away. The", "tokens": [437, 264, 5261, 1355, 11, 341, 307, 437, 321, 360, 11, 293, 5800, 439, 264, 2740, 352, 1314, 13, 440], "temperature": 0.0, "avg_logprob": -0.1325432576170755, "compression_ratio": 1.8675213675213675, "no_speech_prob": 1.1659448318823706e-05}, {"id": 916, "seek": 607420, "start": 6078.24, "end": 6082.28, "text": " loss curves are going to actually mean something, and we're going to be able to do what I said", "tokens": [4470, 19490, 366, 516, 281, 767, 914, 746, 11, 293, 321, 434, 516, 281, 312, 1075, 281, 360, 437, 286, 848], "temperature": 0.0, "avg_logprob": -0.1325432576170755, "compression_ratio": 1.8675213675213675, "no_speech_prob": 1.1659448318823706e-05}, {"id": 917, "seek": 607420, "start": 6082.28, "end": 6089.5599999999995, "text": " we wanted to do right at the start of this GAN section, which is to train the discriminator", "tokens": [321, 1415, 281, 360, 558, 412, 264, 722, 295, 341, 460, 1770, 3541, 11, 597, 307, 281, 3847, 264, 20828, 1639], "temperature": 0.0, "avg_logprob": -0.1325432576170755, "compression_ratio": 1.8675213675213675, "no_speech_prob": 1.1659448318823706e-05}, {"id": 918, "seek": 607420, "start": 6089.5599999999995, "end": 6093.88, "text": " a whole bunch of steps and then do a generator, and then discriminator a whole bunch of steps", "tokens": [257, 1379, 3840, 295, 4439, 293, 550, 360, 257, 19265, 11, 293, 550, 20828, 1639, 257, 1379, 3840, 295, 4439], "temperature": 0.0, "avg_logprob": -0.1325432576170755, "compression_ratio": 1.8675213675213675, "no_speech_prob": 1.1659448318823706e-05}, {"id": 919, "seek": 607420, "start": 6093.88, "end": 6098.8, "text": " and do the generator. And all that is going to suddenly start working.", "tokens": [293, 360, 264, 19265, 13, 400, 439, 300, 307, 516, 281, 5800, 722, 1364, 13], "temperature": 0.0, "avg_logprob": -0.1325432576170755, "compression_ratio": 1.8675213675213675, "no_speech_prob": 1.1659448318823706e-05}, {"id": 920, "seek": 609880, "start": 6098.8, "end": 6107.28, "text": " How do we get it to work? So in fact, despite the fact that this paper is both long and", "tokens": [1012, 360, 321, 483, 309, 281, 589, 30, 407, 294, 1186, 11, 7228, 264, 1186, 300, 341, 3035, 307, 1293, 938, 293], "temperature": 0.0, "avg_logprob": -0.125651710911801, "compression_ratio": 1.6465116279069767, "no_speech_prob": 1.3845904504705686e-05}, {"id": 921, "seek": 609880, "start": 6107.28, "end": 6113.320000000001, "text": " full of equations and theorems and proofs, and there's a whole bunch of appendices at", "tokens": [1577, 295, 11787, 293, 10299, 2592, 293, 8177, 82, 11, 293, 456, 311, 257, 1379, 3840, 295, 34116, 1473, 412], "temperature": 0.0, "avg_logprob": -0.125651710911801, "compression_ratio": 1.6465116279069767, "no_speech_prob": 1.3845904504705686e-05}, {"id": 922, "seek": 609880, "start": 6113.320000000001, "end": 6118.2, "text": " the back with more theorems and proofs, there's actually only two things we need to do. One", "tokens": [264, 646, 365, 544, 10299, 2592, 293, 8177, 82, 11, 456, 311, 767, 787, 732, 721, 321, 643, 281, 360, 13, 1485], "temperature": 0.0, "avg_logprob": -0.125651710911801, "compression_ratio": 1.6465116279069767, "no_speech_prob": 1.3845904504705686e-05}, {"id": 923, "seek": 609880, "start": 6118.2, "end": 6125.24, "text": " is remove the log from the loss function. So rather than using cross-entropy loss, we're", "tokens": [307, 4159, 264, 3565, 490, 264, 4470, 2445, 13, 407, 2831, 813, 1228, 3278, 12, 317, 27514, 4470, 11, 321, 434], "temperature": 0.0, "avg_logprob": -0.125651710911801, "compression_ratio": 1.6465116279069767, "no_speech_prob": 1.3845904504705686e-05}, {"id": 924, "seek": 612524, "start": 6125.24, "end": 6129.679999999999, "text": " just going to use mean squared error. That's one change. And the second change is we're", "tokens": [445, 516, 281, 764, 914, 8889, 6713, 13, 663, 311, 472, 1319, 13, 400, 264, 1150, 1319, 307, 321, 434], "temperature": 0.0, "avg_logprob": -0.18722203092755013, "compression_ratio": 1.848623853211009, "no_speech_prob": 8.664616871101316e-06}, {"id": 925, "seek": 612524, "start": 6129.679999999999, "end": 6136.84, "text": " going to constrain the weights so that they lie between negative.01 and positive.01.", "tokens": [516, 281, 1817, 7146, 264, 17443, 370, 300, 436, 4544, 1296, 3671, 2411, 10607, 293, 3353, 2411, 10607, 13], "temperature": 0.0, "avg_logprob": -0.18722203092755013, "compression_ratio": 1.848623853211009, "no_speech_prob": 8.664616871101316e-06}, {"id": 926, "seek": 612524, "start": 6136.84, "end": 6140.84, "text": " We're going to constrain the weights to make them small.", "tokens": [492, 434, 516, 281, 1817, 7146, 264, 17443, 281, 652, 552, 1359, 13], "temperature": 0.0, "avg_logprob": -0.18722203092755013, "compression_ratio": 1.848623853211009, "no_speech_prob": 8.664616871101316e-06}, {"id": 927, "seek": 612524, "start": 6140.84, "end": 6147.679999999999, "text": " Now in the process of saying that's all we're going to do is to not give credit to this", "tokens": [823, 294, 264, 1399, 295, 1566, 300, 311, 439, 321, 434, 516, 281, 360, 307, 281, 406, 976, 5397, 281, 341], "temperature": 0.0, "avg_logprob": -0.18722203092755013, "compression_ratio": 1.848623853211009, "no_speech_prob": 8.664616871101316e-06}, {"id": 928, "seek": 612524, "start": 6147.679999999999, "end": 6153.0, "text": " paper. This paper is that they figured out that that's what we need to do. And on the", "tokens": [3035, 13, 639, 3035, 307, 300, 436, 8932, 484, 300, 300, 311, 437, 321, 643, 281, 360, 13, 400, 322, 264], "temperature": 0.0, "avg_logprob": -0.18722203092755013, "compression_ratio": 1.848623853211009, "no_speech_prob": 8.664616871101316e-06}, {"id": 929, "seek": 615300, "start": 6153.0, "end": 6157.4, "text": " forums, some of you have been reading through this paper and I've already given you some", "tokens": [26998, 11, 512, 295, 291, 362, 668, 3760, 807, 341, 3035, 293, 286, 600, 1217, 2212, 291, 512], "temperature": 0.0, "avg_logprob": -0.18696558586904935, "compression_ratio": 1.6869918699186992, "no_speech_prob": 1.670134770392906e-05}, {"id": 930, "seek": 615300, "start": 6157.4, "end": 6164.8, "text": " tips as to some really great walkthroughs. I put it on our wiki. It explains all the", "tokens": [6082, 382, 281, 512, 534, 869, 1792, 11529, 82, 13, 286, 829, 309, 322, 527, 261, 9850, 13, 467, 13948, 439, 264], "temperature": 0.0, "avg_logprob": -0.18696558586904935, "compression_ratio": 1.6869918699186992, "no_speech_prob": 1.670134770392906e-05}, {"id": 931, "seek": 615300, "start": 6164.8, "end": 6170.48, "text": " math from scratch. But basically what the math says is this.", "tokens": [5221, 490, 8459, 13, 583, 1936, 437, 264, 5221, 1619, 307, 341, 13], "temperature": 0.0, "avg_logprob": -0.18696558586904935, "compression_ratio": 1.6869918699186992, "no_speech_prob": 1.670134770392906e-05}, {"id": 932, "seek": 615300, "start": 6170.48, "end": 6177.56, "text": " Again, the loss function for again is not really the loss function you put into Keras.", "tokens": [3764, 11, 264, 4470, 2445, 337, 797, 307, 406, 534, 264, 4470, 2445, 291, 829, 666, 591, 6985, 13], "temperature": 0.0, "avg_logprob": -0.18696558586904935, "compression_ratio": 1.6869918699186992, "no_speech_prob": 1.670134770392906e-05}, {"id": 933, "seek": 615300, "start": 6177.56, "end": 6182.28, "text": " We thought we were just putting in a cross-entropy loss function. But in fact, again, what we", "tokens": [492, 1194, 321, 645, 445, 3372, 294, 257, 3278, 12, 317, 27514, 4470, 2445, 13, 583, 294, 1186, 11, 797, 11, 437, 321], "temperature": 0.0, "avg_logprob": -0.18696558586904935, "compression_ratio": 1.6869918699186992, "no_speech_prob": 1.670134770392906e-05}, {"id": 934, "seek": 618228, "start": 6182.28, "end": 6186.639999999999, "text": " really care about is the difference between two distributions, the difference between", "tokens": [534, 1127, 466, 307, 264, 2649, 1296, 732, 37870, 11, 264, 2649, 1296], "temperature": 0.0, "avg_logprob": -0.12152067474696947, "compression_ratio": 2.0588235294117645, "no_speech_prob": 7.071858362905914e-06}, {"id": 935, "seek": 618228, "start": 6186.639999999999, "end": 6192.4, "text": " the discriminator and the generator. And the difference between two loss functions has", "tokens": [264, 20828, 1639, 293, 264, 19265, 13, 400, 264, 2649, 1296, 732, 4470, 6828, 575], "temperature": 0.0, "avg_logprob": -0.12152067474696947, "compression_ratio": 2.0588235294117645, "no_speech_prob": 7.071858362905914e-06}, {"id": 936, "seek": 618228, "start": 6192.4, "end": 6197.84, "text": " a very different shape for the loss function on its own.", "tokens": [257, 588, 819, 3909, 337, 264, 4470, 2445, 322, 1080, 1065, 13], "temperature": 0.0, "avg_logprob": -0.12152067474696947, "compression_ratio": 2.0588235294117645, "no_speech_prob": 7.071858362905914e-06}, {"id": 937, "seek": 618228, "start": 6197.84, "end": 6201.8, "text": " So it turns out that the difference between the two loss functions, the two cross-entropy", "tokens": [407, 309, 4523, 484, 300, 264, 2649, 1296, 264, 732, 4470, 6828, 11, 264, 732, 3278, 12, 317, 27514], "temperature": 0.0, "avg_logprob": -0.12152067474696947, "compression_ratio": 2.0588235294117645, "no_speech_prob": 7.071858362905914e-06}, {"id": 938, "seek": 618228, "start": 6201.8, "end": 6211.36, "text": " loss functions, is something called the Jensen-Shannon distance. And this paper shows that that loss", "tokens": [4470, 6828, 11, 307, 746, 1219, 264, 508, 32934, 12, 7774, 16138, 4560, 13, 400, 341, 3035, 3110, 300, 300, 4470], "temperature": 0.0, "avg_logprob": -0.12152067474696947, "compression_ratio": 2.0588235294117645, "no_speech_prob": 7.071858362905914e-06}, {"id": 939, "seek": 621136, "start": 6211.36, "end": 6222.599999999999, "text": " function is hideous. It is not differentiable and it does not have a nice smooth shape at", "tokens": [2445, 307, 6479, 563, 13, 467, 307, 406, 819, 9364, 293, 309, 775, 406, 362, 257, 1481, 5508, 3909, 412], "temperature": 0.0, "avg_logprob": -0.17393663055018374, "compression_ratio": 1.6349206349206349, "no_speech_prob": 6.540419690281851e-06}, {"id": 940, "seek": 621136, "start": 6222.599999999999, "end": 6224.36, "text": " all.", "tokens": [439, 13], "temperature": 0.0, "avg_logprob": -0.17393663055018374, "compression_ratio": 1.6349206349206349, "no_speech_prob": 6.540419690281851e-06}, {"id": 941, "seek": 621136, "start": 6224.36, "end": 6229.679999999999, "text": " So it kind of explains why it is that we kept getting this mode collapse and failing to", "tokens": [407, 309, 733, 295, 13948, 983, 309, 307, 300, 321, 4305, 1242, 341, 4391, 15584, 293, 18223, 281], "temperature": 0.0, "avg_logprob": -0.17393663055018374, "compression_ratio": 1.6349206349206349, "no_speech_prob": 6.540419690281851e-06}, {"id": 942, "seek": 621136, "start": 6229.679999999999, "end": 6235.48, "text": " find nice minimums. It's basically that mathematically this loss function does not behave the way", "tokens": [915, 1481, 7285, 82, 13, 467, 311, 1936, 300, 44003, 341, 4470, 2445, 775, 406, 15158, 264, 636], "temperature": 0.0, "avg_logprob": -0.17393663055018374, "compression_ratio": 1.6349206349206349, "no_speech_prob": 6.540419690281851e-06}, {"id": 943, "seek": 621136, "start": 6235.48, "end": 6237.679999999999, "text": " a good loss function should.", "tokens": [257, 665, 4470, 2445, 820, 13], "temperature": 0.0, "avg_logprob": -0.17393663055018374, "compression_ratio": 1.6349206349206349, "no_speech_prob": 6.540419690281851e-06}, {"id": 944, "seek": 623768, "start": 6237.68, "end": 6244.320000000001, "text": " And previously we've not come across anything like this because we've been training a single", "tokens": [400, 8046, 321, 600, 406, 808, 2108, 1340, 411, 341, 570, 321, 600, 668, 3097, 257, 2167], "temperature": 0.0, "avg_logprob": -0.18194704318265303, "compression_ratio": 1.6485507246376812, "no_speech_prob": 6.540404683619272e-06}, {"id": 945, "seek": 623768, "start": 6244.320000000001, "end": 6250.4800000000005, "text": " function at a time. We really understand those loss functions, mean squared error, cross-entropy.", "tokens": [2445, 412, 257, 565, 13, 492, 534, 1223, 729, 4470, 6828, 11, 914, 8889, 6713, 11, 3278, 12, 317, 27514, 13], "temperature": 0.0, "avg_logprob": -0.18194704318265303, "compression_ratio": 1.6485507246376812, "no_speech_prob": 6.540404683619272e-06}, {"id": 946, "seek": 623768, "start": 6250.4800000000005, "end": 6256.360000000001, "text": " Even though we haven't always derived the math in detail, plenty of people have. We", "tokens": [2754, 1673, 321, 2378, 380, 1009, 18949, 264, 5221, 294, 2607, 11, 7140, 295, 561, 362, 13, 492], "temperature": 0.0, "avg_logprob": -0.18194704318265303, "compression_ratio": 1.6485507246376812, "no_speech_prob": 6.540404683619272e-06}, {"id": 947, "seek": 623768, "start": 6256.360000000001, "end": 6260.400000000001, "text": " know that they're nice and smooth and that they have pretty nice shapes and they do what", "tokens": [458, 300, 436, 434, 1481, 293, 5508, 293, 300, 436, 362, 1238, 1481, 10854, 293, 436, 360, 437], "temperature": 0.0, "avg_logprob": -0.18194704318265303, "compression_ratio": 1.6485507246376812, "no_speech_prob": 6.540404683619272e-06}, {"id": 948, "seek": 623768, "start": 6260.400000000001, "end": 6266.92, "text": " we want them to do. In this case, by training two things adversarially to each other, we're", "tokens": [321, 528, 552, 281, 360, 13, 682, 341, 1389, 11, 538, 3097, 732, 721, 17641, 289, 2270, 281, 1184, 661, 11, 321, 434], "temperature": 0.0, "avg_logprob": -0.18194704318265303, "compression_ratio": 1.6485507246376812, "no_speech_prob": 6.540404683619272e-06}, {"id": 949, "seek": 626692, "start": 6266.92, "end": 6273.4800000000005, "text": " actually doing something quite different. This paper just absolutely fantastically shows", "tokens": [767, 884, 746, 1596, 819, 13, 639, 3035, 445, 3122, 4115, 22808, 3110], "temperature": 0.0, "avg_logprob": -0.23404752506929286, "compression_ratio": 1.3008130081300813, "no_speech_prob": 2.5071380150620826e-05}, {"id": 950, "seek": 626692, "start": 6273.4800000000005, "end": 6293.68, "text": " with both examples and with theory why that's just never going to work.", "tokens": [365, 1293, 5110, 293, 365, 5261, 983, 300, 311, 445, 1128, 516, 281, 589, 13], "temperature": 0.0, "avg_logprob": -0.23404752506929286, "compression_ratio": 1.3008130081300813, "no_speech_prob": 2.5071380150620826e-05}, {"id": 951, "seek": 629368, "start": 6293.68, "end": 6301.240000000001, "text": " Then the cosine distance. So the cosine distance is the difference between two things, whereas", "tokens": [1396, 264, 23565, 4560, 13, 407, 264, 23565, 4560, 307, 264, 2649, 1296, 732, 721, 11, 9735], "temperature": 0.0, "avg_logprob": -0.15462024924681358, "compression_ratio": 1.8325991189427313, "no_speech_prob": 1.568905463500414e-05}, {"id": 952, "seek": 629368, "start": 6301.240000000001, "end": 6305.52, "text": " these distances that we're talking about here are the distances between two distributions,", "tokens": [613, 22182, 300, 321, 434, 1417, 466, 510, 366, 264, 22182, 1296, 732, 37870, 11], "temperature": 0.0, "avg_logprob": -0.15462024924681358, "compression_ratio": 1.8325991189427313, "no_speech_prob": 1.568905463500414e-05}, {"id": 953, "seek": 629368, "start": 6305.52, "end": 6309.04, "text": " which is a much more tricky problem to deal with.", "tokens": [597, 307, 257, 709, 544, 12414, 1154, 281, 2028, 365, 13], "temperature": 0.0, "avg_logprob": -0.15462024924681358, "compression_ratio": 1.8325991189427313, "no_speech_prob": 1.568905463500414e-05}, {"id": 954, "seek": 629368, "start": 6309.04, "end": 6313.8, "text": " The cosine distance, actually if you look at the notebook during the week, you'll see", "tokens": [440, 23565, 4560, 11, 767, 498, 291, 574, 412, 264, 21060, 1830, 264, 1243, 11, 291, 603, 536], "temperature": 0.0, "avg_logprob": -0.15462024924681358, "compression_ratio": 1.8325991189427313, "no_speech_prob": 1.568905463500414e-05}, {"id": 955, "seek": 629368, "start": 6313.8, "end": 6321.4800000000005, "text": " it's basically the same as the Euclidean distance, but you normalize the data first. So it has", "tokens": [309, 311, 1936, 264, 912, 382, 264, 462, 1311, 31264, 282, 4560, 11, 457, 291, 2710, 1125, 264, 1412, 700, 13, 407, 309, 575], "temperature": 0.0, "avg_logprob": -0.15462024924681358, "compression_ratio": 1.8325991189427313, "no_speech_prob": 1.568905463500414e-05}, {"id": 956, "seek": 632148, "start": 6321.48, "end": 6329.5199999999995, "text": " all the same nice properties that the Euclidean distance did.", "tokens": [439, 264, 912, 1481, 7221, 300, 264, 462, 1311, 31264, 282, 4560, 630, 13], "temperature": 0.0, "avg_logprob": -0.13915869654441365, "compression_ratio": 1.638095238095238, "no_speech_prob": 7.646488484169822e-06}, {"id": 957, "seek": 632148, "start": 6329.5199999999995, "end": 6336.48, "text": " So one thing that's fun is that the authors of this paper released their code in PyTorch.", "tokens": [407, 472, 551, 300, 311, 1019, 307, 300, 264, 16552, 295, 341, 3035, 4736, 641, 3089, 294, 9953, 51, 284, 339, 13], "temperature": 0.0, "avg_logprob": -0.13915869654441365, "compression_ratio": 1.638095238095238, "no_speech_prob": 7.646488484169822e-06}, {"id": 958, "seek": 632148, "start": 6336.48, "end": 6344.48, "text": " And luckily PyTorch, the first kind of pre-release came out in mid-January. You won't be surprised", "tokens": [400, 22880, 9953, 51, 284, 339, 11, 264, 700, 733, 295, 659, 12, 265, 1122, 1361, 484, 294, 2062, 12, 46356, 6164, 13, 509, 1582, 380, 312, 6100], "temperature": 0.0, "avg_logprob": -0.13915869654441365, "compression_ratio": 1.638095238095238, "no_speech_prob": 7.646488484169822e-06}, {"id": 959, "seek": 632148, "start": 6344.48, "end": 6350.04, "text": " to hear that one of the authors of the paper is the main author of PyTorch. So he was writing", "tokens": [281, 1568, 300, 472, 295, 264, 16552, 295, 264, 3035, 307, 264, 2135, 3793, 295, 9953, 51, 284, 339, 13, 407, 415, 390, 3579], "temperature": 0.0, "avg_logprob": -0.13915869654441365, "compression_ratio": 1.638095238095238, "no_speech_prob": 7.646488484169822e-06}, {"id": 960, "seek": 635004, "start": 6350.04, "end": 6356.64, "text": " this before he even released the code. There's lots of reasons we want to learn PyTorch anyway,", "tokens": [341, 949, 415, 754, 4736, 264, 3089, 13, 821, 311, 3195, 295, 4112, 321, 528, 281, 1466, 9953, 51, 284, 339, 4033, 11], "temperature": 0.0, "avg_logprob": -0.1164969061022607, "compression_ratio": 1.651063829787234, "no_speech_prob": 2.0784991647815332e-05}, {"id": 961, "seek": 635004, "start": 6356.64, "end": 6358.84, "text": " so here's a good reason.", "tokens": [370, 510, 311, 257, 665, 1778, 13], "temperature": 0.0, "avg_logprob": -0.1164969061022607, "compression_ratio": 1.651063829787234, "no_speech_prob": 2.0784991647815332e-05}, {"id": 962, "seek": 635004, "start": 6358.84, "end": 6365.16, "text": " So let's look at the Wasserstein GAN in PyTorch. Most of the code, in fact other than this", "tokens": [407, 718, 311, 574, 412, 264, 17351, 9089, 460, 1770, 294, 9953, 51, 284, 339, 13, 4534, 295, 264, 3089, 11, 294, 1186, 661, 813, 341], "temperature": 0.0, "avg_logprob": -0.1164969061022607, "compression_ratio": 1.651063829787234, "no_speech_prob": 2.0784991647815332e-05}, {"id": 963, "seek": 635004, "start": 6365.16, "end": 6371.72, "text": " pretty much all the code I'm showing you in this part of the course, is very loosely based", "tokens": [1238, 709, 439, 264, 3089, 286, 478, 4099, 291, 294, 341, 644, 295, 264, 1164, 11, 307, 588, 37966, 2361], "temperature": 0.0, "avg_logprob": -0.1164969061022607, "compression_ratio": 1.651063829787234, "no_speech_prob": 2.0784991647815332e-05}, {"id": 964, "seek": 635004, "start": 6371.72, "end": 6375.56, "text": " on lots of bits of other code, which I had to massively rewrite because all of it was", "tokens": [322, 3195, 295, 9239, 295, 661, 3089, 11, 597, 286, 632, 281, 29379, 28132, 570, 439, 295, 309, 390], "temperature": 0.0, "avg_logprob": -0.1164969061022607, "compression_ratio": 1.651063829787234, "no_speech_prob": 2.0784991647815332e-05}, {"id": 965, "seek": 637556, "start": 6375.56, "end": 6381.64, "text": " wrong and hideous. This code actually I only did some minor refactoring to simplify things,", "tokens": [2085, 293, 6479, 563, 13, 639, 3089, 767, 286, 787, 630, 512, 6696, 1895, 578, 3662, 281, 20460, 721, 11], "temperature": 0.0, "avg_logprob": -0.1514377704886503, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.1381393910123734e-06}, {"id": 966, "seek": 637556, "start": 6381.64, "end": 6387.76, "text": " so this is actually very close to their code. So it's a very nice paper with very nice code.", "tokens": [370, 341, 307, 767, 588, 1998, 281, 641, 3089, 13, 407, 309, 311, 257, 588, 1481, 3035, 365, 588, 1481, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1514377704886503, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.1381393910123734e-06}, {"id": 967, "seek": 637556, "start": 6387.76, "end": 6390.4800000000005, "text": " So that's a great thing.", "tokens": [407, 300, 311, 257, 869, 551, 13], "temperature": 0.0, "avg_logprob": -0.1514377704886503, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.1381393910123734e-06}, {"id": 968, "seek": 637556, "start": 6390.4800000000005, "end": 6402.52, "text": " So before we look at the Wasserstein GAN in PyTorch, let's look briefly at PyTorch. Basically", "tokens": [407, 949, 321, 574, 412, 264, 17351, 9089, 460, 1770, 294, 9953, 51, 284, 339, 11, 718, 311, 574, 10515, 412, 9953, 51, 284, 339, 13, 8537], "temperature": 0.0, "avg_logprob": -0.1514377704886503, "compression_ratio": 1.5459183673469388, "no_speech_prob": 3.1381393910123734e-06}, {"id": 969, "seek": 640252, "start": 6402.52, "end": 6409.120000000001, "text": " what you're going to see is that PyTorch looks a lot like NumPy, which is nice. We don't", "tokens": [437, 291, 434, 516, 281, 536, 307, 300, 9953, 51, 284, 339, 1542, 257, 688, 411, 22592, 47, 88, 11, 597, 307, 1481, 13, 492, 500, 380], "temperature": 0.0, "avg_logprob": -0.13089871668553615, "compression_ratio": 1.5502183406113537, "no_speech_prob": 8.139646524796262e-06}, {"id": 970, "seek": 640252, "start": 6409.120000000001, "end": 6416.040000000001, "text": " have to create a computational graph using variables and placeholders and later on run", "tokens": [362, 281, 1884, 257, 28270, 4295, 1228, 9102, 293, 1081, 12916, 293, 1780, 322, 1190], "temperature": 0.0, "avg_logprob": -0.13089871668553615, "compression_ratio": 1.5502183406113537, "no_speech_prob": 8.139646524796262e-06}, {"id": 971, "seek": 640252, "start": 6416.040000000001, "end": 6424.200000000001, "text": " it in a session. I'm sure you've seen by now with Keras, with TensorFlow, you try to print", "tokens": [309, 294, 257, 5481, 13, 286, 478, 988, 291, 600, 1612, 538, 586, 365, 591, 6985, 11, 365, 37624, 11, 291, 853, 281, 4482], "temperature": 0.0, "avg_logprob": -0.13089871668553615, "compression_ratio": 1.5502183406113537, "no_speech_prob": 8.139646524796262e-06}, {"id": 972, "seek": 640252, "start": 6424.200000000001, "end": 6428.280000000001, "text": " something out with some intermediate output and it just prints out like tensor and tells", "tokens": [746, 484, 365, 512, 19376, 5598, 293, 309, 445, 22305, 484, 411, 40863, 293, 5112], "temperature": 0.0, "avg_logprob": -0.13089871668553615, "compression_ratio": 1.5502183406113537, "no_speech_prob": 8.139646524796262e-06}, {"id": 973, "seek": 642828, "start": 6428.28, "end": 6433.5199999999995, "text": " you how many dimensions it has. That's because all that thing is is a symbolic part of a", "tokens": [291, 577, 867, 12819, 309, 575, 13, 663, 311, 570, 439, 300, 551, 307, 307, 257, 25755, 644, 295, 257], "temperature": 0.0, "avg_logprob": -0.12963214287391076, "compression_ratio": 1.5432098765432098, "no_speech_prob": 5.014718226448167e-06}, {"id": 974, "seek": 642828, "start": 6433.5199999999995, "end": 6436.0, "text": " computational graph.", "tokens": [28270, 4295, 13], "temperature": 0.0, "avg_logprob": -0.12963214287391076, "compression_ratio": 1.5432098765432098, "no_speech_prob": 5.014718226448167e-06}, {"id": 975, "seek": 642828, "start": 6436.0, "end": 6442.0, "text": " PyTorch doesn't work that way. PyTorch is what's called a define-by-run framework. It's", "tokens": [9953, 51, 284, 339, 1177, 380, 589, 300, 636, 13, 9953, 51, 284, 339, 307, 437, 311, 1219, 257, 6964, 12, 2322, 12, 12997, 8388, 13, 467, 311], "temperature": 0.0, "avg_logprob": -0.12963214287391076, "compression_ratio": 1.5432098765432098, "no_speech_prob": 5.014718226448167e-06}, {"id": 976, "seek": 642828, "start": 6442.0, "end": 6451.28, "text": " basically designed to be so fast to take your code and compile it that you don't have to", "tokens": [1936, 4761, 281, 312, 370, 2370, 281, 747, 428, 3089, 293, 31413, 309, 300, 291, 500, 380, 362, 281], "temperature": 0.0, "avg_logprob": -0.12963214287391076, "compression_ratio": 1.5432098765432098, "no_speech_prob": 5.014718226448167e-06}, {"id": 977, "seek": 642828, "start": 6451.28, "end": 6457.44, "text": " create that graph in advance. Every time you run a piece of code, it puts it on the GPU,", "tokens": [1884, 300, 4295, 294, 7295, 13, 2048, 565, 291, 1190, 257, 2522, 295, 3089, 11, 309, 8137, 309, 322, 264, 18407, 11], "temperature": 0.0, "avg_logprob": -0.12963214287391076, "compression_ratio": 1.5432098765432098, "no_speech_prob": 5.014718226448167e-06}, {"id": 978, "seek": 645744, "start": 6457.44, "end": 6463.08, "text": " runs it, sends it back all in one go. So it makes things look very simple.", "tokens": [6676, 309, 11, 14790, 309, 646, 439, 294, 472, 352, 13, 407, 309, 1669, 721, 574, 588, 2199, 13], "temperature": 0.0, "avg_logprob": -0.14192487152529434, "compression_ratio": 1.473053892215569, "no_speech_prob": 2.7693888569046976e-06}, {"id": 979, "seek": 645744, "start": 6463.08, "end": 6468.0, "text": " So this is a slightly cut-down version of the PyTorch tutorial that PyTorch provides", "tokens": [407, 341, 307, 257, 4748, 1723, 12, 5093, 3037, 295, 264, 9953, 51, 284, 339, 7073, 300, 9953, 51, 284, 339, 6417], "temperature": 0.0, "avg_logprob": -0.14192487152529434, "compression_ratio": 1.473053892215569, "no_speech_prob": 2.7693888569046976e-06}, {"id": 980, "seek": 645744, "start": 6468.0, "end": 6478.0, "text": " on their website. So rather than creating np.array, you create torch.tensor. But other", "tokens": [322, 641, 3144, 13, 407, 2831, 813, 4084, 33808, 13, 2284, 320, 11, 291, 1884, 27822, 13, 83, 23153, 13, 583, 661], "temperature": 0.0, "avg_logprob": -0.14192487152529434, "compression_ratio": 1.473053892215569, "no_speech_prob": 2.7693888569046976e-06}, {"id": 981, "seek": 647800, "start": 6478.0, "end": 6491.72, "text": " than that, it's identical. So here's a random torch.tensor. So the API is a little bit different.", "tokens": [813, 300, 11, 309, 311, 14800, 13, 407, 510, 311, 257, 4974, 27822, 13, 83, 23153, 13, 407, 264, 9362, 307, 257, 707, 857, 819, 13], "temperature": 0.0, "avg_logprob": -0.17054246266682943, "compression_ratio": 1.4021739130434783, "no_speech_prob": 3.844924776785774e-06}, {"id": 982, "seek": 647800, "start": 6491.72, "end": 6498.56, "text": " Rather than dot shape, it's dot size. But you can see it looks very similar.", "tokens": [16571, 813, 5893, 3909, 11, 309, 311, 5893, 2744, 13, 583, 291, 393, 536, 309, 1542, 588, 2531, 13], "temperature": 0.0, "avg_logprob": -0.17054246266682943, "compression_ratio": 1.4021739130434783, "no_speech_prob": 3.844924776785774e-06}, {"id": 983, "seek": 647800, "start": 6498.56, "end": 6505.16, "text": " And so unlike in TensorFlow or Theano, we can just say x plus y and there it is. We", "tokens": [400, 370, 8343, 294, 37624, 420, 440, 3730, 11, 321, 393, 445, 584, 2031, 1804, 288, 293, 456, 309, 307, 13, 492], "temperature": 0.0, "avg_logprob": -0.17054246266682943, "compression_ratio": 1.4021739130434783, "no_speech_prob": 3.844924776785774e-06}, {"id": 984, "seek": 650516, "start": 6505.16, "end": 6512.92, "text": " don't have to say z equals x plus y, f equals function, x and y as inputs, z as output,", "tokens": [500, 380, 362, 281, 584, 710, 6915, 2031, 1804, 288, 11, 283, 6915, 2445, 11, 2031, 293, 288, 382, 15743, 11, 710, 382, 5598, 11], "temperature": 0.0, "avg_logprob": -0.26309261719385785, "compression_ratio": 1.5601851851851851, "no_speech_prob": 2.902301275753416e-06}, {"id": 985, "seek": 650516, "start": 6512.92, "end": 6518.44, "text": " and function dot of vowel. No, we just go x plus y and there it is. So you can see why", "tokens": [293, 2445, 5893, 295, 29410, 13, 883, 11, 321, 445, 352, 2031, 1804, 288, 293, 456, 309, 307, 13, 407, 291, 393, 536, 983], "temperature": 0.0, "avg_logprob": -0.26309261719385785, "compression_ratio": 1.5601851851851851, "no_speech_prob": 2.902301275753416e-06}, {"id": 986, "seek": 650516, "start": 6518.44, "end": 6525.2, "text": " it's called define-by-run. We just provide the code and it just runs it.", "tokens": [309, 311, 1219, 6964, 12, 2322, 12, 12997, 13, 492, 445, 2893, 264, 3089, 293, 309, 445, 6676, 309, 13], "temperature": 0.0, "avg_logprob": -0.26309261719385785, "compression_ratio": 1.5601851851851851, "no_speech_prob": 2.902301275753416e-06}, {"id": 987, "seek": 650516, "start": 6525.2, "end": 6532.8, "text": " Generally speaking, most operations in torch, as well as having this prefix version, this", "tokens": [21082, 4124, 11, 881, 7705, 294, 27822, 11, 382, 731, 382, 1419, 341, 46969, 3037, 11, 341], "temperature": 0.0, "avg_logprob": -0.26309261719385785, "compression_ratio": 1.5601851851851851, "no_speech_prob": 2.902301275753416e-06}, {"id": 988, "seek": 653280, "start": 6532.8, "end": 6539.4400000000005, "text": " is exactly the same thing. You can often add, in fact, nearly always add an out equals and", "tokens": [307, 2293, 264, 912, 551, 13, 509, 393, 2049, 909, 11, 294, 1186, 11, 6217, 1009, 909, 364, 484, 6915, 293], "temperature": 0.0, "avg_logprob": -0.13006984336035593, "compression_ratio": 1.6, "no_speech_prob": 5.771899395767832e-06}, {"id": 989, "seek": 653280, "start": 6539.4400000000005, "end": 6543.68, "text": " that puts the result in this pre-allocated memory. We've already talked about why it's", "tokens": [300, 8137, 264, 1874, 294, 341, 659, 12, 336, 905, 770, 4675, 13, 492, 600, 1217, 2825, 466, 983, 309, 311], "temperature": 0.0, "avg_logprob": -0.13006984336035593, "compression_ratio": 1.6, "no_speech_prob": 5.771899395767832e-06}, {"id": 990, "seek": 653280, "start": 6543.68, "end": 6549.4400000000005, "text": " really important to pre-allocate memory. It's particularly important on GPUs. So if you", "tokens": [534, 1021, 281, 659, 12, 336, 42869, 4675, 13, 467, 311, 4098, 1021, 322, 18407, 82, 13, 407, 498, 291], "temperature": 0.0, "avg_logprob": -0.13006984336035593, "compression_ratio": 1.6, "no_speech_prob": 5.771899395767832e-06}, {"id": 991, "seek": 653280, "start": 6549.4400000000005, "end": 6554.16, "text": " write your own algorithms in PyTorch, you'll need to be very careful of this.", "tokens": [2464, 428, 1065, 14642, 294, 9953, 51, 284, 339, 11, 291, 603, 643, 281, 312, 588, 5026, 295, 341, 13], "temperature": 0.0, "avg_logprob": -0.13006984336035593, "compression_ratio": 1.6, "no_speech_prob": 5.771899395767832e-06}, {"id": 992, "seek": 653280, "start": 6554.16, "end": 6558.52, "text": " Perhaps the best trick is that you can stick an underscore on the end of most things and", "tokens": [10517, 264, 1151, 4282, 307, 300, 291, 393, 2897, 364, 37556, 322, 264, 917, 295, 881, 721, 293], "temperature": 0.0, "avg_logprob": -0.13006984336035593, "compression_ratio": 1.6, "no_speech_prob": 5.771899395767832e-06}, {"id": 993, "seek": 655852, "start": 6558.52, "end": 6564.4800000000005, "text": " it causes it to do in place. This is basically y plus equals x. That's what this underscore", "tokens": [309, 7700, 309, 281, 360, 294, 1081, 13, 639, 307, 1936, 288, 1804, 6915, 2031, 13, 663, 311, 437, 341, 37556], "temperature": 0.0, "avg_logprob": -0.1471195478697081, "compression_ratio": 1.4751381215469612, "no_speech_prob": 4.7108933358686045e-06}, {"id": 994, "seek": 655852, "start": 6564.4800000000005, "end": 6572.4400000000005, "text": " at the end means. So there's some good little tricks. You can do slicing just like NumPy.", "tokens": [412, 264, 917, 1355, 13, 407, 456, 311, 512, 665, 707, 11733, 13, 509, 393, 360, 46586, 445, 411, 22592, 47, 88, 13], "temperature": 0.0, "avg_logprob": -0.1471195478697081, "compression_ratio": 1.4751381215469612, "no_speech_prob": 4.7108933358686045e-06}, {"id": 995, "seek": 655852, "start": 6572.4400000000005, "end": 6580.92, "text": " You can turn NumPy stuff into torch tensors and vice versa by simply going dot NumPy.", "tokens": [509, 393, 1261, 22592, 47, 88, 1507, 666, 27822, 10688, 830, 293, 11964, 25650, 538, 2935, 516, 5893, 22592, 47, 88, 13], "temperature": 0.0, "avg_logprob": -0.1471195478697081, "compression_ratio": 1.4751381215469612, "no_speech_prob": 4.7108933358686045e-06}, {"id": 996, "seek": 658092, "start": 6580.92, "end": 6589.4800000000005, "text": " One thing to be very aware of is that A and B are now referring to the same thing. So", "tokens": [1485, 551, 281, 312, 588, 3650, 295, 307, 300, 316, 293, 363, 366, 586, 13761, 281, 264, 912, 551, 13, 407], "temperature": 0.0, "avg_logprob": -0.1657884246424625, "compression_ratio": 1.4689265536723164, "no_speech_prob": 7.411263595713535e-06}, {"id": 997, "seek": 658092, "start": 6589.4800000000005, "end": 6599.52, "text": " if I now add underscore, so in place, A plus equals 1, it also changes B. Vice versa, you", "tokens": [498, 286, 586, 909, 37556, 11, 370, 294, 1081, 11, 316, 1804, 6915, 502, 11, 309, 611, 2962, 363, 13, 13276, 25650, 11, 291], "temperature": 0.0, "avg_logprob": -0.1657884246424625, "compression_ratio": 1.4689265536723164, "no_speech_prob": 7.411263595713535e-06}, {"id": 998, "seek": 658092, "start": 6599.52, "end": 6605.6, "text": " can turn NumPy into torch by calling torch from NumPy. And again, same thing, if you", "tokens": [393, 1261, 22592, 47, 88, 666, 27822, 538, 5141, 27822, 490, 22592, 47, 88, 13, 400, 797, 11, 912, 551, 11, 498, 291], "temperature": 0.0, "avg_logprob": -0.1657884246424625, "compression_ratio": 1.4689265536723164, "no_speech_prob": 7.411263595713535e-06}, {"id": 999, "seek": 660560, "start": 6605.6, "end": 6611.56, "text": " change the NumPy, it changes the torch.", "tokens": [1319, 264, 22592, 47, 88, 11, 309, 2962, 264, 27822, 13], "temperature": 0.0, "avg_logprob": -0.12990587811137355, "compression_ratio": 1.5699481865284974, "no_speech_prob": 2.225277285106131e-06}, {"id": 1000, "seek": 660560, "start": 6611.56, "end": 6615.68, "text": " All of that so far has been running on the CPU. To turn anything into something that", "tokens": [1057, 295, 300, 370, 1400, 575, 668, 2614, 322, 264, 13199, 13, 1407, 1261, 1340, 666, 746, 300], "temperature": 0.0, "avg_logprob": -0.12990587811137355, "compression_ratio": 1.5699481865284974, "no_speech_prob": 2.225277285106131e-06}, {"id": 1001, "seek": 660560, "start": 6615.68, "end": 6621.160000000001, "text": " runs on the GPU, you chuck.cooter at the end of it. So this x plus y just ran on the", "tokens": [6676, 322, 264, 18407, 11, 291, 20870, 2411, 1291, 21585, 412, 264, 917, 295, 309, 13, 407, 341, 2031, 1804, 288, 445, 5872, 322, 264], "temperature": 0.0, "avg_logprob": -0.12990587811137355, "compression_ratio": 1.5699481865284974, "no_speech_prob": 2.225277285106131e-06}, {"id": 1002, "seek": 660560, "start": 6621.160000000001, "end": 6625.320000000001, "text": " GPU.", "tokens": [18407, 13], "temperature": 0.0, "avg_logprob": -0.12990587811137355, "compression_ratio": 1.5699481865284974, "no_speech_prob": 2.225277285106131e-06}, {"id": 1003, "seek": 660560, "start": 6625.320000000001, "end": 6632.240000000001, "text": " So where things get cool is that something like this knows not just how to do that piece", "tokens": [407, 689, 721, 483, 1627, 307, 300, 746, 411, 341, 3255, 406, 445, 577, 281, 360, 300, 2522], "temperature": 0.0, "avg_logprob": -0.12990587811137355, "compression_ratio": 1.5699481865284974, "no_speech_prob": 2.225277285106131e-06}, {"id": 1004, "seek": 663224, "start": 6632.24, "end": 6637.96, "text": " of arithmetic, but it also knows how to take the gradient of that. To make anything into", "tokens": [295, 42973, 11, 457, 309, 611, 3255, 577, 281, 747, 264, 16235, 295, 300, 13, 1407, 652, 1340, 666], "temperature": 0.0, "avg_logprob": -0.17282475707351522, "compression_ratio": 1.5954545454545455, "no_speech_prob": 2.2959138732403517e-06}, {"id": 1005, "seek": 663224, "start": 6637.96, "end": 6644.92, "text": " something which calculates gradients, you just take your torch tensor, wrap it in variable,", "tokens": [746, 597, 4322, 1024, 2771, 2448, 11, 291, 445, 747, 428, 27822, 40863, 11, 7019, 309, 294, 7006, 11], "temperature": 0.0, "avg_logprob": -0.17282475707351522, "compression_ratio": 1.5954545454545455, "no_speech_prob": 2.2959138732403517e-06}, {"id": 1006, "seek": 663224, "start": 6644.92, "end": 6649.48, "text": " and add this parameter to it. And now from now on, anything I do to x, it's going to", "tokens": [293, 909, 341, 13075, 281, 309, 13, 400, 586, 490, 586, 322, 11, 1340, 286, 360, 281, 2031, 11, 309, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.17282475707351522, "compression_ratio": 1.5954545454545455, "no_speech_prob": 2.2959138732403517e-06}, {"id": 1007, "seek": 663224, "start": 6649.48, "end": 6656.719999999999, "text": " remember what I did so that it can take the gradient of it. So for example, x plus 2,", "tokens": [1604, 437, 286, 630, 370, 300, 309, 393, 747, 264, 16235, 295, 309, 13, 407, 337, 1365, 11, 2031, 1804, 568, 11], "temperature": 0.0, "avg_logprob": -0.17282475707351522, "compression_ratio": 1.5954545454545455, "no_speech_prob": 2.2959138732403517e-06}, {"id": 1008, "seek": 665672, "start": 6656.72, "end": 6662.4400000000005, "text": " I get back 3, just like a normal tensor. So a variable and a tensor have the same API,", "tokens": [286, 483, 646, 805, 11, 445, 411, 257, 2710, 40863, 13, 407, 257, 7006, 293, 257, 40863, 362, 264, 912, 9362, 11], "temperature": 0.0, "avg_logprob": -0.2013306390671503, "compression_ratio": 1.52020202020202, "no_speech_prob": 8.939671715779696e-06}, {"id": 1009, "seek": 665672, "start": 6662.4400000000005, "end": 6671.8, "text": " except that I can keep doing things to it, squared times 3,.mean. Later on I can go", "tokens": [3993, 300, 286, 393, 1066, 884, 721, 281, 309, 11, 8889, 1413, 805, 11, 2411, 1398, 282, 13, 11965, 322, 286, 393, 352], "temperature": 0.0, "avg_logprob": -0.2013306390671503, "compression_ratio": 1.52020202020202, "no_speech_prob": 8.939671715779696e-06}, {"id": 1010, "seek": 665672, "start": 6671.8, "end": 6676.12, "text": ".backward and.grad and I can get the gradient.", "tokens": [2411, 3207, 1007, 293, 2411, 7165, 293, 286, 393, 483, 264, 16235, 13], "temperature": 0.0, "avg_logprob": -0.2013306390671503, "compression_ratio": 1.52020202020202, "no_speech_prob": 8.939671715779696e-06}, {"id": 1011, "seek": 665672, "start": 6676.12, "end": 6682.4400000000005, "text": " So that's the critical difference between a tensor and a variable. They have exactly", "tokens": [407, 300, 311, 264, 4924, 2649, 1296, 257, 40863, 293, 257, 7006, 13, 814, 362, 2293], "temperature": 0.0, "avg_logprob": -0.2013306390671503, "compression_ratio": 1.52020202020202, "no_speech_prob": 8.939671715779696e-06}, {"id": 1012, "seek": 668244, "start": 6682.44, "end": 6689.719999999999, "text": " the same API except variable also has.backward and that gets you the gradient. So when I", "tokens": [264, 912, 9362, 3993, 7006, 611, 575, 2411, 3207, 1007, 293, 300, 2170, 291, 264, 16235, 13, 407, 562, 286], "temperature": 0.0, "avg_logprob": -0.18189283779689244, "compression_ratio": 1.5885416666666667, "no_speech_prob": 2.6841955786949256e-06}, {"id": 1013, "seek": 668244, "start": 6689.719999999999, "end": 6697.28, "text": " say.gradient, the reason that this is dout dx is because I typed out.backward. So this", "tokens": [584, 2411, 7165, 1196, 11, 264, 1778, 300, 341, 307, 274, 346, 30017, 307, 570, 286, 33941, 484, 2411, 3207, 1007, 13, 407, 341], "temperature": 0.0, "avg_logprob": -0.18189283779689244, "compression_ratio": 1.5885416666666667, "no_speech_prob": 2.6841955786949256e-06}, {"id": 1014, "seek": 668244, "start": 6697.28, "end": 6704.9, "text": " is the thing, the derivative is respect to.", "tokens": [307, 264, 551, 11, 264, 13760, 307, 3104, 281, 13], "temperature": 0.0, "avg_logprob": -0.18189283779689244, "compression_ratio": 1.5885416666666667, "no_speech_prob": 2.6841955786949256e-06}, {"id": 1015, "seek": 668244, "start": 6704.9, "end": 6710.24, "text": " So this is kind of crazy. You can do things like while loops and get the gradients of", "tokens": [407, 341, 307, 733, 295, 3219, 13, 509, 393, 360, 721, 411, 1339, 16121, 293, 483, 264, 2771, 2448, 295], "temperature": 0.0, "avg_logprob": -0.18189283779689244, "compression_ratio": 1.5885416666666667, "no_speech_prob": 2.6841955786949256e-06}, {"id": 1016, "seek": 671024, "start": 6710.24, "end": 6716.599999999999, "text": " them. So this kind of thing is pretty tricky to do with TensorFlow or Theano or these kind", "tokens": [552, 13, 407, 341, 733, 295, 551, 307, 1238, 12414, 281, 360, 365, 37624, 420, 440, 3730, 420, 613, 733], "temperature": 0.0, "avg_logprob": -0.16609132612073743, "compression_ratio": 1.4974358974358974, "no_speech_prob": 4.495165740081575e-06}, {"id": 1017, "seek": 671024, "start": 6716.599999999999, "end": 6723.28, "text": " of computation graph approaches. So it gives you a whole lot of flexibility to define things", "tokens": [295, 24903, 4295, 11587, 13, 407, 309, 2709, 291, 257, 1379, 688, 295, 12635, 281, 6964, 721], "temperature": 0.0, "avg_logprob": -0.16609132612073743, "compression_ratio": 1.4974358974358974, "no_speech_prob": 4.495165740081575e-06}, {"id": 1018, "seek": 671024, "start": 6723.28, "end": 6729.719999999999, "text": " in much more natural ways. So you can really write PyTorch just like you're writing regular", "tokens": [294, 709, 544, 3303, 2098, 13, 407, 291, 393, 534, 2464, 9953, 51, 284, 339, 445, 411, 291, 434, 3579, 3890], "temperature": 0.0, "avg_logprob": -0.16609132612073743, "compression_ratio": 1.4974358974358974, "no_speech_prob": 4.495165740081575e-06}, {"id": 1019, "seek": 671024, "start": 6729.719999999999, "end": 6735.2, "text": " old NumPy stuff.", "tokens": [1331, 22592, 47, 88, 1507, 13], "temperature": 0.0, "avg_logprob": -0.16609132612073743, "compression_ratio": 1.4974358974358974, "no_speech_prob": 4.495165740081575e-06}, {"id": 1020, "seek": 673520, "start": 6735.2, "end": 6740.2, "text": " It has plenty of libraries, so if you want to create a neural network, here's how you", "tokens": [467, 575, 7140, 295, 15148, 11, 370, 498, 291, 528, 281, 1884, 257, 18161, 3209, 11, 510, 311, 577, 291], "temperature": 0.0, "avg_logprob": -0.14948607965842964, "compression_ratio": 1.5462555066079295, "no_speech_prob": 8.801056537777185e-06}, {"id": 1021, "seek": 673520, "start": 6740.2, "end": 6747.12, "text": " do a CNN. I warned you early on that if you don't know about OO in Python, you need to", "tokens": [360, 257, 24859, 13, 286, 21284, 291, 2440, 322, 300, 498, 291, 500, 380, 458, 466, 422, 46, 294, 15329, 11, 291, 643, 281], "temperature": 0.0, "avg_logprob": -0.14948607965842964, "compression_ratio": 1.5462555066079295, "no_speech_prob": 8.801056537777185e-06}, {"id": 1022, "seek": 673520, "start": 6747.12, "end": 6753.639999999999, "text": " learn it, so here's why. Because in PyTorch, everything's kind of done using OO. I really", "tokens": [1466, 309, 11, 370, 510, 311, 983, 13, 1436, 294, 9953, 51, 284, 339, 11, 1203, 311, 733, 295, 1096, 1228, 422, 46, 13, 286, 534], "temperature": 0.0, "avg_logprob": -0.14948607965842964, "compression_ratio": 1.5462555066079295, "no_speech_prob": 8.801056537777185e-06}, {"id": 1023, "seek": 673520, "start": 6753.639999999999, "end": 6763.8, "text": " like this, because in TensorFlow, they kind of invent their own weird way of programming", "tokens": [411, 341, 11, 570, 294, 37624, 11, 436, 733, 295, 7962, 641, 1065, 3657, 636, 295, 9410], "temperature": 0.0, "avg_logprob": -0.14948607965842964, "compression_ratio": 1.5462555066079295, "no_speech_prob": 8.801056537777185e-06}, {"id": 1024, "seek": 676380, "start": 6763.8, "end": 6769.04, "text": " rather than use Python OO. Where else PyTorch just goes, oh, we already have these features", "tokens": [2831, 813, 764, 15329, 422, 46, 13, 2305, 1646, 9953, 51, 284, 339, 445, 1709, 11, 1954, 11, 321, 1217, 362, 613, 4122], "temperature": 0.0, "avg_logprob": -0.1462096142512496, "compression_ratio": 1.586046511627907, "no_speech_prob": 9.516216778138187e-06}, {"id": 1025, "seek": 676380, "start": 6769.04, "end": 6775.0, "text": " in the language, let's just use them. So it's way easier in my opinion.", "tokens": [294, 264, 2856, 11, 718, 311, 445, 764, 552, 13, 407, 309, 311, 636, 3571, 294, 452, 4800, 13], "temperature": 0.0, "avg_logprob": -0.1462096142512496, "compression_ratio": 1.586046511627907, "no_speech_prob": 9.516216778138187e-06}, {"id": 1026, "seek": 676380, "start": 6775.0, "end": 6781.4400000000005, "text": " So to create a neural net, you create a new class, you derive from module, and then in", "tokens": [407, 281, 1884, 257, 18161, 2533, 11, 291, 1884, 257, 777, 1508, 11, 291, 28446, 490, 10088, 11, 293, 550, 294], "temperature": 0.0, "avg_logprob": -0.1462096142512496, "compression_ratio": 1.586046511627907, "no_speech_prob": 9.516216778138187e-06}, {"id": 1027, "seek": 676380, "start": 6781.4400000000005, "end": 6792.0, "text": " the constructor, you create all of the things that have weights. So Conv1 is now something", "tokens": [264, 47479, 11, 291, 1884, 439, 295, 264, 721, 300, 362, 17443, 13, 407, 2656, 85, 16, 307, 586, 746], "temperature": 0.0, "avg_logprob": -0.1462096142512496, "compression_ratio": 1.586046511627907, "no_speech_prob": 9.516216778138187e-06}, {"id": 1028, "seek": 679200, "start": 6792.0, "end": 6797.04, "text": " that has some weights, 2D conv, conv2 is something with some weights, polyconnected1 is something", "tokens": [300, 575, 512, 17443, 11, 568, 35, 3754, 11, 3754, 17, 307, 746, 365, 512, 17443, 11, 6754, 9826, 292, 16, 307, 746], "temperature": 0.0, "avg_logprob": -0.15424147106352307, "compression_ratio": 1.7130434782608697, "no_speech_prob": 5.5075829550332855e-06}, {"id": 1029, "seek": 679200, "start": 6797.04, "end": 6804.6, "text": " with some weights. So there's all of your layers, and then you get to say exactly what", "tokens": [365, 512, 17443, 13, 407, 456, 311, 439, 295, 428, 7914, 11, 293, 550, 291, 483, 281, 584, 2293, 437], "temperature": 0.0, "avg_logprob": -0.15424147106352307, "compression_ratio": 1.7130434782608697, "no_speech_prob": 5.5075829550332855e-06}, {"id": 1030, "seek": 679200, "start": 6804.6, "end": 6807.72, "text": " happens in your forward pass.", "tokens": [2314, 294, 428, 2128, 1320, 13], "temperature": 0.0, "avg_logprob": -0.15424147106352307, "compression_ratio": 1.7130434782608697, "no_speech_prob": 5.5075829550332855e-06}, {"id": 1031, "seek": 679200, "start": 6807.72, "end": 6812.64, "text": " Now because MaxPool2D doesn't have any weights and ReLU doesn't have any weights, there's", "tokens": [823, 570, 7402, 47, 1092, 17, 35, 1177, 380, 362, 604, 17443, 293, 1300, 43, 52, 1177, 380, 362, 604, 17443, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.15424147106352307, "compression_ratio": 1.7130434782608697, "no_speech_prob": 5.5075829550332855e-06}, {"id": 1032, "seek": 679200, "start": 6812.64, "end": 6819.08, "text": " no need to define them in the initializer. You can just call them as functions. But these", "tokens": [572, 643, 281, 6964, 552, 294, 264, 5883, 6545, 13, 509, 393, 445, 818, 552, 382, 6828, 13, 583, 613], "temperature": 0.0, "avg_logprob": -0.15424147106352307, "compression_ratio": 1.7130434782608697, "no_speech_prob": 5.5075829550332855e-06}, {"id": 1033, "seek": 681908, "start": 6819.08, "end": 6826.04, "text": " things have weights, so they need to be stateful and persistent.", "tokens": [721, 362, 17443, 11, 370, 436, 643, 281, 312, 1785, 906, 293, 24315, 13], "temperature": 0.0, "avg_logprob": -0.11739098340615459, "compression_ratio": 1.5373831775700935, "no_speech_prob": 8.53028177516535e-06}, {"id": 1034, "seek": 681908, "start": 6826.04, "end": 6833.16, "text": " So in my forward pass, you literally just define what are the things that happen..view", "tokens": [407, 294, 452, 2128, 1320, 11, 291, 3736, 445, 6964, 437, 366, 264, 721, 300, 1051, 13, 2411, 1759], "temperature": 0.0, "avg_logprob": -0.11739098340615459, "compression_ratio": 1.5373831775700935, "no_speech_prob": 8.53028177516535e-06}, {"id": 1035, "seek": 681908, "start": 6833.16, "end": 6841.08, "text": " is the same as reshape. The whole API has different names for everything, which is mildly", "tokens": [307, 264, 912, 382, 725, 42406, 13, 440, 1379, 9362, 575, 819, 5288, 337, 1203, 11, 597, 307, 15154, 356], "temperature": 0.0, "avg_logprob": -0.11739098340615459, "compression_ratio": 1.5373831775700935, "no_speech_prob": 8.53028177516535e-06}, {"id": 1036, "seek": 681908, "start": 6841.08, "end": 6846.32, "text": " annoying for the first week, but you kind of get used to it. So.reshape is called.view.", "tokens": [11304, 337, 264, 700, 1243, 11, 457, 291, 733, 295, 483, 1143, 281, 309, 13, 407, 2411, 495, 42406, 307, 1219, 2411, 1759, 13], "temperature": 0.0, "avg_logprob": -0.11739098340615459, "compression_ratio": 1.5373831775700935, "no_speech_prob": 8.53028177516535e-06}, {"id": 1037, "seek": 684632, "start": 6846.32, "end": 6851.04, "text": " During the week, if you try to use PyTorch and you're like, how do you say blah in PyTorch", "tokens": [6842, 264, 1243, 11, 498, 291, 853, 281, 764, 9953, 51, 284, 339, 293, 291, 434, 411, 11, 577, 360, 291, 584, 12288, 294, 9953, 51, 284, 339], "temperature": 0.0, "avg_logprob": -0.1380833203975971, "compression_ratio": 1.5829596412556053, "no_speech_prob": 1.3211831173975952e-05}, {"id": 1038, "seek": 684632, "start": 6851.04, "end": 6856.719999999999, "text": " and you can't find it, feel free to post on the forum. Having said that, PyTorch has its", "tokens": [293, 291, 393, 380, 915, 309, 11, 841, 1737, 281, 2183, 322, 264, 17542, 13, 10222, 848, 300, 11, 9953, 51, 284, 339, 575, 1080], "temperature": 0.0, "avg_logprob": -0.1380833203975971, "compression_ratio": 1.5829596412556053, "no_speech_prob": 1.3211831173975952e-05}, {"id": 1039, "seek": 684632, "start": 6856.719999999999, "end": 6864.96, "text": " own discourse-based forums. And as you can see, it is just as busy and friendly as our", "tokens": [1065, 23938, 12, 6032, 26998, 13, 400, 382, 291, 393, 536, 11, 309, 307, 445, 382, 5856, 293, 9208, 382, 527], "temperature": 0.0, "avg_logprob": -0.1380833203975971, "compression_ratio": 1.5829596412556053, "no_speech_prob": 1.3211831173975952e-05}, {"id": 1040, "seek": 684632, "start": 6864.96, "end": 6872.28, "text": " forums. People are posting on these all the time. So I find it a really great, helpful", "tokens": [26998, 13, 3432, 366, 15978, 322, 613, 439, 264, 565, 13, 407, 286, 915, 309, 257, 534, 869, 11, 4961], "temperature": 0.0, "avg_logprob": -0.1380833203975971, "compression_ratio": 1.5829596412556053, "no_speech_prob": 1.3211831173975952e-05}, {"id": 1041, "seek": 687228, "start": 6872.28, "end": 6885.639999999999, "text": " community. So feel free to ask over there or over here.", "tokens": [1768, 13, 407, 841, 1737, 281, 1029, 670, 456, 420, 670, 510, 13], "temperature": 0.0, "avg_logprob": -0.1875002861022949, "compression_ratio": 1.309090909090909, "no_speech_prob": 6.401903374353424e-05}, {"id": 1042, "seek": 687228, "start": 6885.639999999999, "end": 6894.759999999999, "text": " You can then put all of that computation onto the GPU by calling.cuda. You can then take", "tokens": [509, 393, 550, 829, 439, 295, 300, 24903, 3911, 264, 18407, 538, 5141, 2411, 66, 11152, 13, 509, 393, 550, 747], "temperature": 0.0, "avg_logprob": -0.1875002861022949, "compression_ratio": 1.309090909090909, "no_speech_prob": 6.401903374353424e-05}, {"id": 1043, "seek": 689476, "start": 6894.76, "end": 6904.16, "text": " some input, put that on the GPU with.cuda. You can then calculate your derivatives, calculate", "tokens": [512, 4846, 11, 829, 300, 322, 264, 18407, 365, 2411, 66, 11152, 13, 509, 393, 550, 8873, 428, 33733, 11, 8873], "temperature": 0.0, "avg_logprob": -0.1432516659007353, "compression_ratio": 1.5736040609137056, "no_speech_prob": 1.1843031643365975e-05}, {"id": 1044, "seek": 689476, "start": 6904.16, "end": 6916.280000000001, "text": " your loss, and then later on you can optimize it. This is just one step of the optimizer,", "tokens": [428, 4470, 11, 293, 550, 1780, 322, 291, 393, 19719, 309, 13, 639, 307, 445, 472, 1823, 295, 264, 5028, 6545, 11], "temperature": 0.0, "avg_logprob": -0.1432516659007353, "compression_ratio": 1.5736040609137056, "no_speech_prob": 1.1843031643365975e-05}, {"id": 1045, "seek": 689476, "start": 6916.280000000001, "end": 6918.4400000000005, "text": " so we have to put that in the loop.", "tokens": [370, 321, 362, 281, 829, 300, 294, 264, 6367, 13], "temperature": 0.0, "avg_logprob": -0.1432516659007353, "compression_ratio": 1.5736040609137056, "no_speech_prob": 1.1843031643365975e-05}, {"id": 1046, "seek": 689476, "start": 6918.4400000000005, "end": 6923.76, "text": " So there's the basic pieces. At the end here, there's a complete process, but I think more", "tokens": [407, 456, 311, 264, 3875, 3755, 13, 1711, 264, 917, 510, 11, 456, 311, 257, 3566, 1399, 11, 457, 286, 519, 544], "temperature": 0.0, "avg_logprob": -0.1432516659007353, "compression_ratio": 1.5736040609137056, "no_speech_prob": 1.1843031643365975e-05}, {"id": 1047, "seek": 692376, "start": 6923.76, "end": 6930.400000000001, "text": " fun will be to see the process in the Wasserstein GAN. So here it is. I've kind of got this", "tokens": [1019, 486, 312, 281, 536, 264, 1399, 294, 264, 17351, 9089, 460, 1770, 13, 407, 510, 309, 307, 13, 286, 600, 733, 295, 658, 341], "temperature": 0.0, "avg_logprob": -0.21740863634192426, "compression_ratio": 1.565, "no_speech_prob": 2.9772645575576462e-05}, {"id": 1048, "seek": 692376, "start": 6930.400000000001, "end": 6937.320000000001, "text": " TorchUtils thing which you'll find in GitHub, which has the basic stuff you'll want for", "tokens": [7160, 339, 52, 83, 4174, 551, 597, 291, 603, 915, 294, 23331, 11, 597, 575, 264, 3875, 1507, 291, 603, 528, 337], "temperature": 0.0, "avg_logprob": -0.21740863634192426, "compression_ratio": 1.565, "no_speech_prob": 2.9772645575576462e-05}, {"id": 1049, "seek": 692376, "start": 6937.320000000001, "end": 6940.8, "text": " Torch all there, so you can just import that.", "tokens": [7160, 339, 439, 456, 11, 370, 291, 393, 445, 974, 300, 13], "temperature": 0.0, "avg_logprob": -0.21740863634192426, "compression_ratio": 1.565, "no_speech_prob": 2.9772645575576462e-05}, {"id": 1050, "seek": 692376, "start": 6940.8, "end": 6948.400000000001, "text": " So let's get the Wasserstein GAN working. So we set up the batch size, the size of each", "tokens": [407, 718, 311, 483, 264, 17351, 9089, 460, 1770, 1364, 13, 407, 321, 992, 493, 264, 15245, 2744, 11, 264, 2744, 295, 1184], "temperature": 0.0, "avg_logprob": -0.21740863634192426, "compression_ratio": 1.565, "no_speech_prob": 2.9772645575576462e-05}, {"id": 1051, "seek": 694840, "start": 6948.4, "end": 6955.2, "text": " image, the size of our noise vector. And look how cool it is, I really like this. This is", "tokens": [3256, 11, 264, 2744, 295, 527, 5658, 8062, 13, 400, 574, 577, 1627, 309, 307, 11, 286, 534, 411, 341, 13, 639, 307], "temperature": 0.0, "avg_logprob": -0.1880026611627317, "compression_ratio": 1.5473251028806585, "no_speech_prob": 3.1875563308858545e-06}, {"id": 1052, "seek": 694840, "start": 6955.2, "end": 6963.5199999999995, "text": " how you import datasets. It has a datasets module already in the TorchVision library.", "tokens": [577, 291, 974, 42856, 13, 467, 575, 257, 42856, 10088, 1217, 294, 264, 7160, 339, 53, 1991, 6405, 13], "temperature": 0.0, "avg_logprob": -0.1880026611627317, "compression_ratio": 1.5473251028806585, "no_speech_prob": 3.1875563308858545e-06}, {"id": 1053, "seek": 694840, "start": 6963.5199999999995, "end": 6968.799999999999, "text": " Here's the CyPhar 10 dataset. It will automatically download it to this path for you if you say", "tokens": [1692, 311, 264, 10295, 47, 5854, 1266, 28872, 13, 467, 486, 6772, 5484, 309, 281, 341, 3100, 337, 291, 498, 291, 584], "temperature": 0.0, "avg_logprob": -0.1880026611627317, "compression_ratio": 1.5473251028806585, "no_speech_prob": 3.1875563308858545e-06}, {"id": 1054, "seek": 694840, "start": 6968.799999999999, "end": 6970.719999999999, "text": " download=\"true\".", "tokens": [5484, 13114, 6903, 622, 1883], "temperature": 0.0, "avg_logprob": -0.1880026611627317, "compression_ratio": 1.5473251028806585, "no_speech_prob": 3.1875563308858545e-06}, {"id": 1055, "seek": 694840, "start": 6970.719999999999, "end": 6978.16, "text": " And rather than having to figure out how to do the preprocessing, you can create a list", "tokens": [400, 2831, 813, 1419, 281, 2573, 484, 577, 281, 360, 264, 2666, 340, 780, 278, 11, 291, 393, 1884, 257, 1329], "temperature": 0.0, "avg_logprob": -0.1880026611627317, "compression_ratio": 1.5473251028806585, "no_speech_prob": 3.1875563308858545e-06}, {"id": 1056, "seek": 697816, "start": 6978.16, "end": 6985.0, "text": " of transforms. So I think this is a really lovely API. The reason that this is so new", "tokens": [295, 35592, 13, 407, 286, 519, 341, 307, 257, 534, 7496, 9362, 13, 440, 1778, 300, 341, 307, 370, 777], "temperature": 0.0, "avg_logprob": -0.1606466905126032, "compression_ratio": 1.633587786259542, "no_speech_prob": 1.4738906429556664e-05}, {"id": 1057, "seek": 697816, "start": 6985.0, "end": 6989.92, "text": " yet has such a nice API is because this comes from a lower library called Torch that's been", "tokens": [1939, 575, 1270, 257, 1481, 9362, 307, 570, 341, 1487, 490, 257, 3126, 6405, 1219, 7160, 339, 300, 311, 668], "temperature": 0.0, "avg_logprob": -0.1606466905126032, "compression_ratio": 1.633587786259542, "no_speech_prob": 1.4738906429556664e-05}, {"id": 1058, "seek": 697816, "start": 6989.92, "end": 6994.96, "text": " around for many years, and so these guys are basically started off by copying what they", "tokens": [926, 337, 867, 924, 11, 293, 370, 613, 1074, 366, 1936, 1409, 766, 538, 27976, 437, 436], "temperature": 0.0, "avg_logprob": -0.1606466905126032, "compression_ratio": 1.633587786259542, "no_speech_prob": 1.4738906429556664e-05}, {"id": 1059, "seek": 697816, "start": 6994.96, "end": 7001.84, "text": " already had and what already works well. So I think this is very elegant.", "tokens": [1217, 632, 293, 437, 1217, 1985, 731, 13, 407, 286, 519, 341, 307, 588, 21117, 13], "temperature": 0.0, "avg_logprob": -0.1606466905126032, "compression_ratio": 1.633587786259542, "no_speech_prob": 1.4738906429556664e-05}, {"id": 1060, "seek": 697816, "start": 7001.84, "end": 7006.48, "text": " So I've got two different things you can look at here. They're both from the paper. Mine", "tokens": [407, 286, 600, 658, 732, 819, 721, 291, 393, 574, 412, 510, 13, 814, 434, 1293, 490, 264, 3035, 13, 11620], "temperature": 0.0, "avg_logprob": -0.1606466905126032, "compression_ratio": 1.633587786259542, "no_speech_prob": 1.4738906429556664e-05}, {"id": 1061, "seek": 700648, "start": 7006.48, "end": 7010.48, "text": " is CyPhar 10, which are these tiny little images. Another is something we haven't seen", "tokens": [307, 10295, 47, 5854, 1266, 11, 597, 366, 613, 5870, 707, 5267, 13, 3996, 307, 746, 321, 2378, 380, 1612], "temperature": 0.0, "avg_logprob": -0.12217080593109131, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.2805399819626473e-05}, {"id": 1062, "seek": 700648, "start": 7010.48, "end": 7022.08, "text": " before, which is called Lsun, which is a really nice dataset. It's a huge dataset with millions", "tokens": [949, 11, 597, 307, 1219, 441, 11314, 11, 597, 307, 257, 534, 1481, 28872, 13, 467, 311, 257, 2603, 28872, 365, 6803], "temperature": 0.0, "avg_logprob": -0.12217080593109131, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.2805399819626473e-05}, {"id": 1063, "seek": 700648, "start": 7022.08, "end": 7032.919999999999, "text": " of images, 3 million bedroom images for example. So we can use either one. This is pretty cool.", "tokens": [295, 5267, 11, 805, 2459, 11211, 5267, 337, 1365, 13, 407, 321, 393, 764, 2139, 472, 13, 639, 307, 1238, 1627, 13], "temperature": 0.0, "avg_logprob": -0.12217080593109131, "compression_ratio": 1.4787234042553192, "no_speech_prob": 1.2805399819626473e-05}, {"id": 1064, "seek": 703292, "start": 7032.92, "end": 7037.4800000000005, "text": " We can then create a data loader, say how many workers to use. We already know what", "tokens": [492, 393, 550, 1884, 257, 1412, 3677, 260, 11, 584, 577, 867, 5600, 281, 764, 13, 492, 1217, 458, 437], "temperature": 0.0, "avg_logprob": -0.15965615967173635, "compression_ratio": 1.6455026455026456, "no_speech_prob": 1.0451464731886517e-05}, {"id": 1065, "seek": 703292, "start": 7037.4800000000005, "end": 7044.24, "text": " workers are. This is all built into the framework. So now that you know how many workers your", "tokens": [5600, 366, 13, 639, 307, 439, 3094, 666, 264, 8388, 13, 407, 586, 300, 291, 458, 577, 867, 5600, 428], "temperature": 0.0, "avg_logprob": -0.15965615967173635, "compression_ratio": 1.6455026455026456, "no_speech_prob": 1.0451464731886517e-05}, {"id": 1066, "seek": 703292, "start": 7044.24, "end": 7049.4400000000005, "text": " CPU likes to use, you can just go ahead and put that number in here. Use your CPU to load", "tokens": [13199, 5902, 281, 764, 11, 291, 393, 445, 352, 2286, 293, 829, 300, 1230, 294, 510, 13, 8278, 428, 13199, 281, 3677], "temperature": 0.0, "avg_logprob": -0.15965615967173635, "compression_ratio": 1.6455026455026456, "no_speech_prob": 1.0451464731886517e-05}, {"id": 1067, "seek": 703292, "start": 7049.4400000000005, "end": 7054.56, "text": " in this data in parallel in the background.", "tokens": [294, 341, 1412, 294, 8952, 294, 264, 3678, 13], "temperature": 0.0, "avg_logprob": -0.15965615967173635, "compression_ratio": 1.6455026455026456, "no_speech_prob": 1.0451464731886517e-05}, {"id": 1068, "seek": 705456, "start": 7054.56, "end": 7063.200000000001, "text": " So we're going to start with CyPhar 10, so we've got 47,000 of those images. Put the", "tokens": [407, 321, 434, 516, 281, 722, 365, 10295, 47, 5854, 1266, 11, 370, 321, 600, 658, 16953, 11, 1360, 295, 729, 5267, 13, 4935, 264], "temperature": 0.0, "avg_logprob": -0.24993533819494113, "compression_ratio": 1.4136125654450262, "no_speech_prob": 2.1112215108587407e-05}, {"id": 1069, "seek": 705456, "start": 7063.200000000001, "end": 7068.6, "text": " definitions of the discriminator and the generator architectures into a separate Python file,", "tokens": [21988, 295, 264, 20828, 1639, 293, 264, 19265, 6331, 1303, 666, 257, 4994, 15329, 3991, 11], "temperature": 0.0, "avg_logprob": -0.24993533819494113, "compression_ratio": 1.4136125654450262, "no_speech_prob": 2.1112215108587407e-05}, {"id": 1070, "seek": 705456, "start": 7068.6, "end": 7075.400000000001, "text": " bcgan.py. We're going to skip over very quickly because it's really straightforward. Here's", "tokens": [272, 66, 1275, 13, 8200, 13, 492, 434, 516, 281, 10023, 670, 588, 2661, 570, 309, 311, 534, 15325, 13, 1692, 311], "temperature": 0.0, "avg_logprob": -0.24993533819494113, "compression_ratio": 1.4136125654450262, "no_speech_prob": 2.1112215108587407e-05}, {"id": 1071, "seek": 707540, "start": 7075.4, "end": 7085.5199999999995, "text": " a conv block that consists of a conv2d, batchnorm2d, and a leaky relu. So in my initializer, I", "tokens": [257, 3754, 3461, 300, 14689, 295, 257, 3754, 17, 67, 11, 15245, 13403, 17, 67, 11, 293, 257, 476, 15681, 1039, 84, 13, 407, 294, 452, 5883, 6545, 11, 286], "temperature": 0.0, "avg_logprob": -0.16566945329497132, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.4970987649576273e-05}, {"id": 1072, "seek": 707540, "start": 7085.5199999999995, "end": 7094.2, "text": " can go ahead and say we'll start with a conv block, optionally have a few extra conv blocks.", "tokens": [393, 352, 2286, 293, 584, 321, 603, 722, 365, 257, 3754, 3461, 11, 3614, 379, 362, 257, 1326, 2857, 3754, 8474, 13], "temperature": 0.0, "avg_logprob": -0.16566945329497132, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.4970987649576273e-05}, {"id": 1073, "seek": 707540, "start": 7094.2, "end": 7101.12, "text": " This is really nice. Here's a while loop that says keep adding more downsampling blocks", "tokens": [639, 307, 534, 1481, 13, 1692, 311, 257, 1339, 6367, 300, 1619, 1066, 5127, 544, 760, 19988, 11970, 8474], "temperature": 0.0, "avg_logprob": -0.16566945329497132, "compression_ratio": 1.4864864864864864, "no_speech_prob": 1.4970987649576273e-05}, {"id": 1074, "seek": 710112, "start": 7101.12, "end": 7111.72, "text": " until you've got as many as you need. So that's really nice kind of use of a while loop to", "tokens": [1826, 291, 600, 658, 382, 867, 382, 291, 643, 13, 407, 300, 311, 534, 1481, 733, 295, 764, 295, 257, 1339, 6367, 281], "temperature": 0.0, "avg_logprob": -0.1711887763096736, "compression_ratio": 1.3857142857142857, "no_speech_prob": 4.785073087987257e-06}, {"id": 1075, "seek": 710112, "start": 7111.72, "end": 7119.76, "text": " simplify our architecture. And then a final conv block at the end to actually create the", "tokens": [20460, 527, 9482, 13, 400, 550, 257, 2572, 3754, 3461, 412, 264, 917, 281, 767, 1884, 264], "temperature": 0.0, "avg_logprob": -0.1711887763096736, "compression_ratio": 1.3857142857142857, "no_speech_prob": 4.785073087987257e-06}, {"id": 1076, "seek": 710112, "start": 7119.76, "end": 7122.36, "text": " thing we want.", "tokens": [551, 321, 528, 13], "temperature": 0.0, "avg_logprob": -0.1711887763096736, "compression_ratio": 1.3857142857142857, "no_speech_prob": 4.785073087987257e-06}, {"id": 1077, "seek": 712236, "start": 7122.36, "end": 7131.799999999999, "text": " And then this is pretty nifty. If you pass in ngpu greater than 1, then it will call", "tokens": [400, 550, 341, 307, 1238, 297, 37177, 13, 759, 291, 1320, 294, 6415, 34859, 5044, 813, 502, 11, 550, 309, 486, 818], "temperature": 0.0, "avg_logprob": -0.18207687055560903, "compression_ratio": 1.4846625766871167, "no_speech_prob": 4.356846602604492e-06}, {"id": 1078, "seek": 712236, "start": 7131.799999999999, "end": 7139.96, "text": " parallel.data.parallel passing in those GPU IDs and it will do automatic multi-GPU training.", "tokens": [8952, 13, 67, 3274, 13, 2181, 336, 338, 8437, 294, 729, 18407, 48212, 293, 309, 486, 360, 12509, 4825, 12, 38, 8115, 3097, 13], "temperature": 0.0, "avg_logprob": -0.18207687055560903, "compression_ratio": 1.4846625766871167, "no_speech_prob": 4.356846602604492e-06}, {"id": 1079, "seek": 712236, "start": 7139.96, "end": 7146.32, "text": " So this is by far the easiest multi-GPU training I've ever seen.", "tokens": [407, 341, 307, 538, 1400, 264, 12889, 4825, 12, 38, 8115, 3097, 286, 600, 1562, 1612, 13], "temperature": 0.0, "avg_logprob": -0.18207687055560903, "compression_ratio": 1.4846625766871167, "no_speech_prob": 4.356846602604492e-06}, {"id": 1080, "seek": 714632, "start": 7146.32, "end": 7163.96, "text": " So that's it, that's the forward pass. We'll learn more about this over the next couple", "tokens": [407, 300, 311, 309, 11, 300, 311, 264, 2128, 1320, 13, 492, 603, 1466, 544, 466, 341, 670, 264, 958, 1916], "temperature": 0.0, "avg_logprob": -0.11195897082893216, "compression_ratio": 1.3358778625954197, "no_speech_prob": 9.368603969051037e-06}, {"id": 1081, "seek": 714632, "start": 7163.96, "end": 7170.639999999999, "text": " of weeks. In fact, given we're a little short of time, let's discuss that next week and", "tokens": [295, 3259, 13, 682, 1186, 11, 2212, 321, 434, 257, 707, 2099, 295, 565, 11, 718, 311, 2248, 300, 958, 1243, 293], "temperature": 0.0, "avg_logprob": -0.11195897082893216, "compression_ratio": 1.3358778625954197, "no_speech_prob": 9.368603969051037e-06}, {"id": 1082, "seek": 717064, "start": 7170.64, "end": 7177.56, "text": " let me know if you don't think we cover it. Here's the generator, looks very, very similar.", "tokens": [718, 385, 458, 498, 291, 500, 380, 519, 321, 2060, 309, 13, 1692, 311, 264, 19265, 11, 1542, 588, 11, 588, 2531, 13], "temperature": 0.0, "avg_logprob": -0.1802922669831697, "compression_ratio": 1.6173285198555956, "no_speech_prob": 7.766878297843505e-06}, {"id": 1083, "seek": 717064, "start": 7177.56, "end": 7185.12, "text": " Again there's a while loop to make sure we've gone through the right number of decon blocks.", "tokens": [3764, 456, 311, 257, 1339, 6367, 281, 652, 988, 321, 600, 2780, 807, 264, 558, 1230, 295, 979, 266, 8474, 13], "temperature": 0.0, "avg_logprob": -0.1802922669831697, "compression_ratio": 1.6173285198555956, "no_speech_prob": 7.766878297843505e-06}, {"id": 1084, "seek": 717064, "start": 7185.12, "end": 7189.160000000001, "text": " So this is actually interesting. This would probably be better off with an upsampling", "tokens": [407, 341, 307, 767, 1880, 13, 639, 576, 1391, 312, 1101, 766, 365, 364, 15497, 335, 11970], "temperature": 0.0, "avg_logprob": -0.1802922669831697, "compression_ratio": 1.6173285198555956, "no_speech_prob": 7.766878297843505e-06}, {"id": 1085, "seek": 717064, "start": 7189.160000000001, "end": 7193.92, "text": " block followed by a one-by-one convolution. So maybe at home you could try this and see", "tokens": [3461, 6263, 538, 257, 472, 12, 2322, 12, 546, 45216, 13, 407, 1310, 412, 1280, 291, 727, 853, 341, 293, 536], "temperature": 0.0, "avg_logprob": -0.1802922669831697, "compression_ratio": 1.6173285198555956, "no_speech_prob": 7.766878297843505e-06}, {"id": 1086, "seek": 717064, "start": 7193.92, "end": 7200.280000000001, "text": " if you get better results because this has probably got the checkerboard pattern problem.", "tokens": [498, 291, 483, 1101, 3542, 570, 341, 575, 1391, 658, 264, 1520, 260, 3787, 5102, 1154, 13], "temperature": 0.0, "avg_logprob": -0.1802922669831697, "compression_ratio": 1.6173285198555956, "no_speech_prob": 7.766878297843505e-06}, {"id": 1087, "seek": 720028, "start": 7200.28, "end": 7210.04, "text": " So there's our generator and our discriminator. It's only 75 lines of code, nice and easy.", "tokens": [407, 456, 311, 527, 19265, 293, 527, 20828, 1639, 13, 467, 311, 787, 9562, 3876, 295, 3089, 11, 1481, 293, 1858, 13], "temperature": 0.0, "avg_logprob": -0.18011781792891654, "compression_ratio": 1.5919282511210762, "no_speech_prob": 7.031059794826433e-05}, {"id": 1088, "seek": 720028, "start": 7210.04, "end": 7214.4, "text": " Everything's a little bit different in PyTorch. If we want to say what initializer to use,", "tokens": [5471, 311, 257, 707, 857, 819, 294, 9953, 51, 284, 339, 13, 759, 321, 528, 281, 584, 437, 5883, 6545, 281, 764, 11], "temperature": 0.0, "avg_logprob": -0.18011781792891654, "compression_ratio": 1.5919282511210762, "no_speech_prob": 7.031059794826433e-05}, {"id": 1089, "seek": 720028, "start": 7214.4, "end": 7221.8, "text": " again we're going to use a little bit more decoupled, maybe at first it's a little more", "tokens": [797, 321, 434, 516, 281, 764, 257, 707, 857, 544, 979, 263, 15551, 11, 1310, 412, 700, 309, 311, 257, 707, 544], "temperature": 0.0, "avg_logprob": -0.18011781792891654, "compression_ratio": 1.5919282511210762, "no_speech_prob": 7.031059794826433e-05}, {"id": 1090, "seek": 720028, "start": 7221.8, "end": 7226.32, "text": " complex but there's less things you have to learn. In this case we can call something", "tokens": [3997, 457, 456, 311, 1570, 721, 291, 362, 281, 1466, 13, 682, 341, 1389, 321, 393, 818, 746], "temperature": 0.0, "avg_logprob": -0.18011781792891654, "compression_ratio": 1.5919282511210762, "no_speech_prob": 7.031059794826433e-05}, {"id": 1091, "seek": 722632, "start": 7226.32, "end": 7234.0, "text": " called apply, which takes some function and passes it to everything in our architecture.", "tokens": [1219, 3079, 11, 597, 2516, 512, 2445, 293, 11335, 309, 281, 1203, 294, 527, 9482, 13], "temperature": 0.0, "avg_logprob": -0.24479042400013318, "compression_ratio": 1.7536231884057971, "no_speech_prob": 8.139641977322754e-06}, {"id": 1092, "seek": 722632, "start": 7234.0, "end": 7240.5199999999995, "text": " So this function is something that says, oh is this a conv2d or conv transpose 2d, if so", "tokens": [407, 341, 2445, 307, 746, 300, 1619, 11, 1954, 307, 341, 257, 3754, 17, 67, 420, 3754, 25167, 568, 67, 11, 498, 370], "temperature": 0.0, "avg_logprob": -0.24479042400013318, "compression_ratio": 1.7536231884057971, "no_speech_prob": 8.139641977322754e-06}, {"id": 1093, "seek": 722632, "start": 7240.5199999999995, "end": 7246.16, "text": " use this initialization function. Or if it's a batch norm, use this initialization function.", "tokens": [764, 341, 5883, 2144, 2445, 13, 1610, 498, 309, 311, 257, 15245, 2026, 11, 764, 341, 5883, 2144, 2445, 13], "temperature": 0.0, "avg_logprob": -0.24479042400013318, "compression_ratio": 1.7536231884057971, "no_speech_prob": 8.139641977322754e-06}, {"id": 1094, "seek": 722632, "start": 7246.16, "end": 7253.04, "text": " So again, everything's a little bit different, there isn't a separate initializer parameter.", "tokens": [407, 797, 11, 1203, 311, 257, 707, 857, 819, 11, 456, 1943, 380, 257, 4994, 5883, 6545, 13075, 13], "temperature": 0.0, "avg_logprob": -0.24479042400013318, "compression_ratio": 1.7536231884057971, "no_speech_prob": 8.139641977322754e-06}, {"id": 1095, "seek": 725304, "start": 7253.04, "end": 7263.36, "text": " This is in my opinion much more flexible, I really like it.", "tokens": [639, 307, 294, 452, 4800, 709, 544, 11358, 11, 286, 534, 411, 309, 13], "temperature": 0.0, "avg_logprob": -0.13069913473473974, "compression_ratio": 1.6649484536082475, "no_speech_prob": 2.3552427592221648e-05}, {"id": 1096, "seek": 725304, "start": 7263.36, "end": 7270.68, "text": " As before, we need something that creates some noise. Let's go ahead and create some", "tokens": [1018, 949, 11, 321, 643, 746, 300, 7829, 512, 5658, 13, 961, 311, 352, 2286, 293, 1884, 512], "temperature": 0.0, "avg_logprob": -0.13069913473473974, "compression_ratio": 1.6649484536082475, "no_speech_prob": 2.3552427592221648e-05}, {"id": 1097, "seek": 725304, "start": 7270.68, "end": 7274.68, "text": " fixed noise. We're going to have an optimizer for the discriminator, we've got an optimizer", "tokens": [6806, 5658, 13, 492, 434, 516, 281, 362, 364, 5028, 6545, 337, 264, 20828, 1639, 11, 321, 600, 658, 364, 5028, 6545], "temperature": 0.0, "avg_logprob": -0.13069913473473974, "compression_ratio": 1.6649484536082475, "no_speech_prob": 2.3552427592221648e-05}, {"id": 1098, "seek": 725304, "start": 7274.68, "end": 7280.12, "text": " for the generator. Here is something that does one step of the discriminator. So we're", "tokens": [337, 264, 19265, 13, 1692, 307, 746, 300, 775, 472, 1823, 295, 264, 20828, 1639, 13, 407, 321, 434], "temperature": 0.0, "avg_logprob": -0.13069913473473974, "compression_ratio": 1.6649484536082475, "no_speech_prob": 2.3552427592221648e-05}, {"id": 1099, "seek": 728012, "start": 7280.12, "end": 7284.2, "text": " going to call the forward pass, and then we call the backward pass, and then we return", "tokens": [516, 281, 818, 264, 2128, 1320, 11, 293, 550, 321, 818, 264, 23897, 1320, 11, 293, 550, 321, 2736], "temperature": 0.0, "avg_logprob": -0.17767717380716344, "compression_ratio": 1.7122641509433962, "no_speech_prob": 1.0129911970579997e-05}, {"id": 1100, "seek": 728012, "start": 7284.2, "end": 7286.44, "text": " the error.", "tokens": [264, 6713, 13], "temperature": 0.0, "avg_logprob": -0.17767717380716344, "compression_ratio": 1.7122641509433962, "no_speech_prob": 1.0129911970579997e-05}, {"id": 1101, "seek": 728012, "start": 7286.44, "end": 7292.08, "text": " Just like before, we've got something called makeTrainable. So this is how we make something", "tokens": [1449, 411, 949, 11, 321, 600, 658, 746, 1219, 652, 51, 7146, 712, 13, 407, 341, 307, 577, 321, 652, 746], "temperature": 0.0, "avg_logprob": -0.17767717380716344, "compression_ratio": 1.7122641509433962, "no_speech_prob": 1.0129911970579997e-05}, {"id": 1102, "seek": 728012, "start": 7292.08, "end": 7298.32, "text": " trainable or not trainable in PyTorch. And just like before, we have a train loop. The", "tokens": [3847, 712, 420, 406, 3847, 712, 294, 9953, 51, 284, 339, 13, 400, 445, 411, 949, 11, 321, 362, 257, 3847, 6367, 13, 440], "temperature": 0.0, "avg_logprob": -0.17767717380716344, "compression_ratio": 1.7122641509433962, "no_speech_prob": 1.0129911970579997e-05}, {"id": 1103, "seek": 728012, "start": 7298.32, "end": 7304.96, "text": " train loop has got a little bit more going on, partly because of the Wasserstein GAN,", "tokens": [3847, 6367, 575, 658, 257, 707, 857, 544, 516, 322, 11, 17031, 570, 295, 264, 17351, 9089, 460, 1770, 11], "temperature": 0.0, "avg_logprob": -0.17767717380716344, "compression_ratio": 1.7122641509433962, "no_speech_prob": 1.0129911970579997e-05}, {"id": 1104, "seek": 730496, "start": 7304.96, "end": 7317.68, "text": " partly because of PyTorch, but the basic idea is the same. For each epoch, for each batch,", "tokens": [17031, 570, 295, 9953, 51, 284, 339, 11, 457, 264, 3875, 1558, 307, 264, 912, 13, 1171, 1184, 30992, 339, 11, 337, 1184, 15245, 11], "temperature": 0.0, "avg_logprob": -0.10889804057585888, "compression_ratio": 1.5513513513513513, "no_speech_prob": 8.664600500196684e-06}, {"id": 1105, "seek": 730496, "start": 7317.68, "end": 7326.0, "text": " make the discriminator trainable. And then this is the number of iterations to train", "tokens": [652, 264, 20828, 1639, 3847, 712, 13, 400, 550, 341, 307, 264, 1230, 295, 36540, 281, 3847], "temperature": 0.0, "avg_logprob": -0.10889804057585888, "compression_ratio": 1.5513513513513513, "no_speech_prob": 8.664600500196684e-06}, {"id": 1106, "seek": 730496, "start": 7326.0, "end": 7327.88, "text": " the discriminator for.", "tokens": [264, 20828, 1639, 337, 13], "temperature": 0.0, "avg_logprob": -0.10889804057585888, "compression_ratio": 1.5513513513513513, "no_speech_prob": 8.664600500196684e-06}, {"id": 1107, "seek": 730496, "start": 7327.88, "end": 7332.0, "text": " So remember I told you one of the nice things about the Wasserstein GAN is that we don't", "tokens": [407, 1604, 286, 1907, 291, 472, 295, 264, 1481, 721, 466, 264, 17351, 9089, 460, 1770, 307, 300, 321, 500, 380], "temperature": 0.0, "avg_logprob": -0.10889804057585888, "compression_ratio": 1.5513513513513513, "no_speech_prob": 8.664600500196684e-06}, {"id": 1108, "seek": 733200, "start": 7332.0, "end": 7335.6, "text": " have to do one batch discriminator, one batch generator, one batch discriminator, one batch", "tokens": [362, 281, 360, 472, 15245, 20828, 1639, 11, 472, 15245, 19265, 11, 472, 15245, 20828, 1639, 11, 472, 15245], "temperature": 0.0, "avg_logprob": -0.1662835486141252, "compression_ratio": 1.89010989010989, "no_speech_prob": 1.012990833260119e-05}, {"id": 1109, "seek": 733200, "start": 7335.6, "end": 7341.24, "text": " generator, but we can actually train the discriminator properly for a bunch of batches. And in the", "tokens": [19265, 11, 457, 321, 393, 767, 3847, 264, 20828, 1639, 6108, 337, 257, 3840, 295, 15245, 279, 13, 400, 294, 264], "temperature": 0.0, "avg_logprob": -0.1662835486141252, "compression_ratio": 1.89010989010989, "no_speech_prob": 1.012990833260119e-05}, {"id": 1110, "seek": 733200, "start": 7341.24, "end": 7353.88, "text": " paper, they suggest using 5 iterations or 5 batches of discriminator training each time", "tokens": [3035, 11, 436, 3402, 1228, 1025, 36540, 420, 1025, 15245, 279, 295, 20828, 1639, 3097, 1184, 565], "temperature": 0.0, "avg_logprob": -0.1662835486141252, "compression_ratio": 1.89010989010989, "no_speech_prob": 1.012990833260119e-05}, {"id": 1111, "seek": 733200, "start": 7353.88, "end": 7358.48, "text": " through the loop, unless you're still in the first 25 iterations.", "tokens": [807, 264, 6367, 11, 5969, 291, 434, 920, 294, 264, 700, 3552, 36540, 13], "temperature": 0.0, "avg_logprob": -0.1662835486141252, "compression_ratio": 1.89010989010989, "no_speech_prob": 1.012990833260119e-05}, {"id": 1112, "seek": 735848, "start": 7358.48, "end": 7365.799999999999, "text": " They say if you're in the first 25 iterations, do 100 batches. And then they also say from", "tokens": [814, 584, 498, 291, 434, 294, 264, 700, 3552, 36540, 11, 360, 2319, 15245, 279, 13, 400, 550, 436, 611, 584, 490], "temperature": 0.0, "avg_logprob": -0.12389133788727141, "compression_ratio": 1.6325581395348838, "no_speech_prob": 1.2805377082258929e-05}, {"id": 1113, "seek": 735848, "start": 7365.799999999999, "end": 7372.94, "text": " time to time, do 100 batches. So it's kind of nice by having the flexibility here to", "tokens": [565, 281, 565, 11, 360, 2319, 15245, 279, 13, 407, 309, 311, 733, 295, 1481, 538, 1419, 264, 12635, 510, 281], "temperature": 0.0, "avg_logprob": -0.12389133788727141, "compression_ratio": 1.6325581395348838, "no_speech_prob": 1.2805377082258929e-05}, {"id": 1114, "seek": 735848, "start": 7372.94, "end": 7378.12, "text": " really change things, we can do exactly what the paper wants us to do. So basically at", "tokens": [534, 1319, 721, 11, 321, 393, 360, 2293, 437, 264, 3035, 2738, 505, 281, 360, 13, 407, 1936, 412], "temperature": 0.0, "avg_logprob": -0.12389133788727141, "compression_ratio": 1.6325581395348838, "no_speech_prob": 1.2805377082258929e-05}, {"id": 1115, "seek": 735848, "start": 7378.12, "end": 7384.4, "text": " first we're going to train the discriminator carefully, and we'll also from time to time", "tokens": [700, 321, 434, 516, 281, 3847, 264, 20828, 1639, 7500, 11, 293, 321, 603, 611, 490, 565, 281, 565], "temperature": 0.0, "avg_logprob": -0.12389133788727141, "compression_ratio": 1.6325581395348838, "no_speech_prob": 1.2805377082258929e-05}, {"id": 1116, "seek": 738440, "start": 7384.4, "end": 7389.92, "text": " train the discriminator very carefully. Otherwise we'll just do 5 batches.", "tokens": [3847, 264, 20828, 1639, 588, 7500, 13, 10328, 321, 603, 445, 360, 1025, 15245, 279, 13], "temperature": 0.0, "avg_logprob": -0.12284068119378737, "compression_ratio": 1.702970297029703, "no_speech_prob": 7.527963589382125e-06}, {"id": 1117, "seek": 738440, "start": 7389.92, "end": 7396.719999999999, "text": " So this is where we go ahead and train the discriminator. And you'll see here we clamp", "tokens": [407, 341, 307, 689, 321, 352, 2286, 293, 3847, 264, 20828, 1639, 13, 400, 291, 603, 536, 510, 321, 17690], "temperature": 0.0, "avg_logprob": -0.12284068119378737, "compression_ratio": 1.702970297029703, "no_speech_prob": 7.527963589382125e-06}, {"id": 1118, "seek": 738440, "start": 7396.719999999999, "end": 7406.08, "text": " the weights in the discriminator to fall in this range. And if you're interested in reading", "tokens": [264, 17443, 294, 264, 20828, 1639, 281, 2100, 294, 341, 3613, 13, 400, 498, 291, 434, 3102, 294, 3760], "temperature": 0.0, "avg_logprob": -0.12284068119378737, "compression_ratio": 1.702970297029703, "no_speech_prob": 7.527963589382125e-06}, {"id": 1119, "seek": 738440, "start": 7406.08, "end": 7413.32, "text": " the paper, the paper explains that basically the reason for this is that their assumptions", "tokens": [264, 3035, 11, 264, 3035, 13948, 300, 1936, 264, 1778, 337, 341, 307, 300, 641, 17695], "temperature": 0.0, "avg_logprob": -0.12284068119378737, "compression_ratio": 1.702970297029703, "no_speech_prob": 7.527963589382125e-06}, {"id": 1120, "seek": 741332, "start": 7413.32, "end": 7420.08, "text": " are only true in this kind of small area. So that's why we have to make sure that the", "tokens": [366, 787, 2074, 294, 341, 733, 295, 1359, 1859, 13, 407, 300, 311, 983, 321, 362, 281, 652, 988, 300, 264], "temperature": 0.0, "avg_logprob": -0.1209970201764788, "compression_ratio": 1.8060606060606061, "no_speech_prob": 1.3631252841150854e-05}, {"id": 1121, "seek": 741332, "start": 7420.08, "end": 7423.92, "text": " weights stay in this small area.", "tokens": [17443, 1754, 294, 341, 1359, 1859, 13], "temperature": 0.0, "avg_logprob": -0.1209970201764788, "compression_ratio": 1.8060606060606061, "no_speech_prob": 1.3631252841150854e-05}, {"id": 1122, "seek": 741332, "start": 7423.92, "end": 7430.48, "text": " So then we go ahead and do a single step with the discriminator. Then we create some noise", "tokens": [407, 550, 321, 352, 2286, 293, 360, 257, 2167, 1823, 365, 264, 20828, 1639, 13, 1396, 321, 1884, 512, 5658], "temperature": 0.0, "avg_logprob": -0.1209970201764788, "compression_ratio": 1.8060606060606061, "no_speech_prob": 1.3631252841150854e-05}, {"id": 1123, "seek": 741332, "start": 7430.48, "end": 7441.599999999999, "text": " and do a single step with the generator. We get our fake data for the discriminator that", "tokens": [293, 360, 257, 2167, 1823, 365, 264, 19265, 13, 492, 483, 527, 7592, 1412, 337, 264, 20828, 1639, 300], "temperature": 0.0, "avg_logprob": -0.1209970201764788, "compression_ratio": 1.8060606060606061, "no_speech_prob": 1.3631252841150854e-05}, {"id": 1124, "seek": 744160, "start": 7441.6, "end": 7446.4400000000005, "text": " we can subtract the fake from the real to get our error for the discriminator. So there's", "tokens": [321, 393, 16390, 264, 7592, 490, 264, 957, 281, 483, 527, 6713, 337, 264, 20828, 1639, 13, 407, 456, 311], "temperature": 0.0, "avg_logprob": -0.13243908352322048, "compression_ratio": 1.8223350253807107, "no_speech_prob": 9.666017831477802e-06}, {"id": 1125, "seek": 744160, "start": 7446.4400000000005, "end": 7457.96, "text": " one step with the discriminator. We do that either 5 or 100 times. Make our discriminator", "tokens": [472, 1823, 365, 264, 20828, 1639, 13, 492, 360, 300, 2139, 1025, 420, 2319, 1413, 13, 4387, 527, 20828, 1639], "temperature": 0.0, "avg_logprob": -0.13243908352322048, "compression_ratio": 1.8223350253807107, "no_speech_prob": 9.666017831477802e-06}, {"id": 1126, "seek": 744160, "start": 7457.96, "end": 7464.52, "text": " not trainable and then do one step of the generator. You can see here we call the generator", "tokens": [406, 3847, 712, 293, 550, 360, 472, 1823, 295, 264, 19265, 13, 509, 393, 536, 510, 321, 818, 264, 19265], "temperature": 0.0, "avg_logprob": -0.13243908352322048, "compression_ratio": 1.8223350253807107, "no_speech_prob": 9.666017831477802e-06}, {"id": 1127, "seek": 744160, "start": 7464.52, "end": 7470.72, "text": " with some noise and then pass it into the discriminator to see if we tricked it or not.", "tokens": [365, 512, 5658, 293, 550, 1320, 309, 666, 264, 20828, 1639, 281, 536, 498, 321, 39345, 309, 420, 406, 13], "temperature": 0.0, "avg_logprob": -0.13243908352322048, "compression_ratio": 1.8223350253807107, "no_speech_prob": 9.666017831477802e-06}, {"id": 1128, "seek": 747072, "start": 7470.72, "end": 7475.76, "text": " So during the week you can look at these two different versions and you're going to see", "tokens": [407, 1830, 264, 1243, 291, 393, 574, 412, 613, 732, 819, 9606, 293, 291, 434, 516, 281, 536], "temperature": 0.0, "avg_logprob": -0.1504841204042788, "compression_ratio": 1.6582914572864322, "no_speech_prob": 9.223390406987164e-06}, {"id": 1129, "seek": 747072, "start": 7475.76, "end": 7481.76, "text": " basically the PyTorch and the Keras version are basically the same thing. The only difference", "tokens": [1936, 264, 9953, 51, 284, 339, 293, 264, 591, 6985, 3037, 366, 1936, 264, 912, 551, 13, 440, 787, 2649], "temperature": 0.0, "avg_logprob": -0.1504841204042788, "compression_ratio": 1.6582914572864322, "no_speech_prob": 9.223390406987164e-06}, {"id": 1130, "seek": 747072, "start": 7481.76, "end": 7488.96, "text": " is in the two things. One is the presence of this clamping and the second is that the", "tokens": [307, 294, 264, 732, 721, 13, 1485, 307, 264, 6814, 295, 341, 17690, 278, 293, 264, 1150, 307, 300, 264], "temperature": 0.0, "avg_logprob": -0.1504841204042788, "compression_ratio": 1.6582914572864322, "no_speech_prob": 9.223390406987164e-06}, {"id": 1131, "seek": 747072, "start": 7488.96, "end": 7495.68, "text": " loss function is mean squared error rather than cross-entropy.", "tokens": [4470, 2445, 307, 914, 8889, 6713, 2831, 813, 3278, 12, 317, 27514, 13], "temperature": 0.0, "avg_logprob": -0.1504841204042788, "compression_ratio": 1.6582914572864322, "no_speech_prob": 9.223390406987164e-06}, {"id": 1132, "seek": 749568, "start": 7495.68, "end": 7509.58, "text": " So let's see what happens. Here are some examples from CyPhar 10. They're certainly a lot better", "tokens": [407, 718, 311, 536, 437, 2314, 13, 1692, 366, 512, 5110, 490, 10295, 47, 5854, 1266, 13, 814, 434, 3297, 257, 688, 1101], "temperature": 0.0, "avg_logprob": -0.2131017538217398, "compression_ratio": 1.2907801418439717, "no_speech_prob": 3.5559785374061903e-06}, {"id": 1133, "seek": 749568, "start": 7509.58, "end": 7520.8, "text": " than our crappy vsegan MNIST examples, but they're not great. Why are they not great?", "tokens": [813, 527, 36531, 371, 405, 1275, 376, 45, 19756, 5110, 11, 457, 436, 434, 406, 869, 13, 1545, 366, 436, 406, 869, 30], "temperature": 0.0, "avg_logprob": -0.2131017538217398, "compression_ratio": 1.2907801418439717, "no_speech_prob": 3.5559785374061903e-06}, {"id": 1134, "seek": 752080, "start": 7520.8, "end": 7527.92, "text": " So probably the reason they're not great is because CyPhar 10 has quite a few different", "tokens": [407, 1391, 264, 1778, 436, 434, 406, 869, 307, 570, 10295, 47, 5854, 1266, 575, 1596, 257, 1326, 819], "temperature": 0.0, "avg_logprob": -0.1508370978491647, "compression_ratio": 1.7003891050583657, "no_speech_prob": 1.9333540421939688e-06}, {"id": 1135, "seek": 752080, "start": 7527.92, "end": 7532.400000000001, "text": " kinds of categories of different kinds of things. So it doesn't really know what it's", "tokens": [3685, 295, 10479, 295, 819, 3685, 295, 721, 13, 407, 309, 1177, 380, 534, 458, 437, 309, 311], "temperature": 0.0, "avg_logprob": -0.1508370978491647, "compression_ratio": 1.7003891050583657, "no_speech_prob": 1.9333540421939688e-06}, {"id": 1136, "seek": 752080, "start": 7532.400000000001, "end": 7536.4800000000005, "text": " meant to be drawing a picture of. Sometimes I guess it kind of figures it out, like this", "tokens": [4140, 281, 312, 6316, 257, 3036, 295, 13, 4803, 286, 2041, 309, 733, 295, 9624, 309, 484, 11, 411, 341], "temperature": 0.0, "avg_logprob": -0.1508370978491647, "compression_ratio": 1.7003891050583657, "no_speech_prob": 1.9333540421939688e-06}, {"id": 1137, "seek": 752080, "start": 7536.4800000000005, "end": 7542.72, "text": " must be a plane I think. But a lot of the time it's kind of, it hedges and kind of draws", "tokens": [1633, 312, 257, 5720, 286, 519, 13, 583, 257, 688, 295, 264, 565, 309, 311, 733, 295, 11, 309, 33653, 2880, 293, 733, 295, 20045], "temperature": 0.0, "avg_logprob": -0.1508370978491647, "compression_ratio": 1.7003891050583657, "no_speech_prob": 1.9333540421939688e-06}, {"id": 1138, "seek": 752080, "start": 7542.72, "end": 7545.88, "text": " a picture of something that looks like it might be a reasonable picture, but it's not", "tokens": [257, 3036, 295, 746, 300, 1542, 411, 309, 1062, 312, 257, 10585, 3036, 11, 457, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.1508370978491647, "compression_ratio": 1.7003891050583657, "no_speech_prob": 1.9333540421939688e-06}, {"id": 1139, "seek": 754588, "start": 7545.88, "end": 7554.28, "text": " a picture of anything in particular. On the other hand, the Lsun dataset has 3 million", "tokens": [257, 3036, 295, 1340, 294, 1729, 13, 1282, 264, 661, 1011, 11, 264, 441, 11314, 28872, 575, 805, 2459], "temperature": 0.0, "avg_logprob": -0.2671564063247369, "compression_ratio": 1.2971014492753623, "no_speech_prob": 1.679726210568333e-06}, {"id": 1140, "seek": 754588, "start": 7554.28, "end": 7562.04, "text": " bedrooms. So we would hope that when we train the Vassarstein GAN on Lsun bedrooms, we might", "tokens": [39955, 13, 407, 321, 576, 1454, 300, 562, 321, 3847, 264, 691, 640, 289, 9089, 460, 1770, 322, 441, 11314, 39955, 11, 321, 1062], "temperature": 0.0, "avg_logprob": -0.2671564063247369, "compression_ratio": 1.2971014492753623, "no_speech_prob": 1.679726210568333e-06}, {"id": 1141, "seek": 756204, "start": 7562.04, "end": 7576.64, "text": " get better results. Here's the real CyPhar 10, by the way. So here are our fake bedrooms.", "tokens": [483, 1101, 3542, 13, 1692, 311, 264, 957, 10295, 47, 5854, 1266, 11, 538, 264, 636, 13, 407, 510, 366, 527, 7592, 39955, 13], "temperature": 0.0, "avg_logprob": -0.1974199579117146, "compression_ratio": 1.326241134751773, "no_speech_prob": 3.785308990700287e-06}, {"id": 1142, "seek": 756204, "start": 7576.64, "end": 7586.54, "text": " And they are pretty freaking awesome. So literally these started out as random noise and everyone", "tokens": [400, 436, 366, 1238, 14612, 3476, 13, 407, 3736, 613, 1409, 484, 382, 4974, 5658, 293, 1518], "temperature": 0.0, "avg_logprob": -0.1974199579117146, "compression_ratio": 1.326241134751773, "no_speech_prob": 3.785308990700287e-06}, {"id": 1143, "seek": 758654, "start": 7586.54, "end": 7598.88, "text": " has been turned in. And here are the real bedrooms.", "tokens": [575, 668, 3574, 294, 13, 400, 510, 366, 264, 957, 39955, 13], "temperature": 0.0, "avg_logprob": -0.2462801367549573, "compression_ratio": 1.5302013422818792, "no_speech_prob": 1.0289435522281565e-05}, {"id": 1144, "seek": 758654, "start": 7598.88, "end": 7606.64, "text": " You can kind of see here that, imagine if you took this and stuck it on the end of any", "tokens": [509, 393, 733, 295, 536, 510, 300, 11, 3811, 498, 291, 1890, 341, 293, 5541, 309, 322, 264, 917, 295, 604], "temperature": 0.0, "avg_logprob": -0.2462801367549573, "compression_ratio": 1.5302013422818792, "no_speech_prob": 1.0289435522281565e-05}, {"id": 1145, "seek": 758654, "start": 7606.64, "end": 7616.28, "text": " kind of generator. You could really use this to make your generator much more believable.", "tokens": [733, 295, 19265, 13, 509, 727, 534, 764, 341, 281, 652, 428, 19265, 709, 544, 1351, 17915, 13], "temperature": 0.0, "avg_logprob": -0.2462801367549573, "compression_ratio": 1.5302013422818792, "no_speech_prob": 1.0289435522281565e-05}, {"id": 1146, "seek": 761628, "start": 7616.28, "end": 7621.719999999999, "text": " Like anytime you kind of look at it and you say, Oh, that doesn't look like the real X,", "tokens": [1743, 13038, 291, 733, 295, 574, 412, 309, 293, 291, 584, 11, 876, 11, 300, 1177, 380, 574, 411, 264, 957, 1783, 11], "temperature": 0.0, "avg_logprob": -0.2095047697728994, "compression_ratio": 1.3833333333333333, "no_speech_prob": 9.36866217671195e-06}, {"id": 1147, "seek": 761628, "start": 7621.719999999999, "end": 7632.74, "text": " maybe you could try using a W again to try to make it look more like a real X.", "tokens": [1310, 291, 727, 853, 1228, 257, 343, 797, 281, 853, 281, 652, 309, 574, 544, 411, 257, 957, 1783, 13], "temperature": 0.0, "avg_logprob": -0.2095047697728994, "compression_ratio": 1.3833333333333333, "no_speech_prob": 9.36866217671195e-06}, {"id": 1148, "seek": 763274, "start": 7632.74, "end": 7647.719999999999, "text": " So this paper is so new and so important. The loss function for these actually makes", "tokens": [407, 341, 3035, 307, 370, 777, 293, 370, 1021, 13, 440, 4470, 2445, 337, 613, 767, 1669], "temperature": 0.0, "avg_logprob": -0.16175694465637208, "compression_ratio": 1.5813953488372092, "no_speech_prob": 5.862775196874281e-06}, {"id": 1149, "seek": 763274, "start": 7647.719999999999, "end": 7653.32, "text": " sense. Like the discriminator and the generator loss functions actually decrease as they get", "tokens": [2020, 13, 1743, 264, 20828, 1639, 293, 264, 19265, 4470, 6828, 767, 11514, 382, 436, 483], "temperature": 0.0, "avg_logprob": -0.16175694465637208, "compression_ratio": 1.5813953488372092, "no_speech_prob": 5.862775196874281e-06}, {"id": 1150, "seek": 763274, "start": 7653.32, "end": 7660.5599999999995, "text": " better. So you can actually tell if your thing is training properly. You can't exactly compare", "tokens": [1101, 13, 407, 291, 393, 767, 980, 498, 428, 551, 307, 3097, 6108, 13, 509, 393, 380, 2293, 6794], "temperature": 0.0, "avg_logprob": -0.16175694465637208, "compression_ratio": 1.5813953488372092, "no_speech_prob": 5.862775196874281e-06}, {"id": 1151, "seek": 766056, "start": 7660.56, "end": 7666.200000000001, "text": " two different architectures to each other still, but you can certainly see that the", "tokens": [732, 819, 6331, 1303, 281, 1184, 661, 920, 11, 457, 291, 393, 3297, 536, 300, 264], "temperature": 0.0, "avg_logprob": -0.14579810266909393, "compression_ratio": 1.4793814432989691, "no_speech_prob": 5.3381222642201465e-06}, {"id": 1152, "seek": 766056, "start": 7666.200000000001, "end": 7668.160000000001, "text": " training curves are working.", "tokens": [3097, 19490, 366, 1364, 13], "temperature": 0.0, "avg_logprob": -0.14579810266909393, "compression_ratio": 1.4793814432989691, "no_speech_prob": 5.3381222642201465e-06}, {"id": 1153, "seek": 766056, "start": 7668.160000000001, "end": 7676.72, "text": " So now that we have, in my opinion, a GAN that actually really works reliably for the", "tokens": [407, 586, 300, 321, 362, 11, 294, 452, 4800, 11, 257, 460, 1770, 300, 767, 534, 1985, 49927, 337, 264], "temperature": 0.0, "avg_logprob": -0.14579810266909393, "compression_ratio": 1.4793814432989691, "no_speech_prob": 5.3381222642201465e-06}, {"id": 1154, "seek": 766056, "start": 7676.72, "end": 7685.4800000000005, "text": " first time ever, I feel like this changes the equation for what generators can and can't", "tokens": [700, 565, 1562, 11, 286, 841, 411, 341, 2962, 264, 5367, 337, 437, 38662, 393, 293, 393, 380], "temperature": 0.0, "avg_logprob": -0.14579810266909393, "compression_ratio": 1.4793814432989691, "no_speech_prob": 5.3381222642201465e-06}, {"id": 1155, "seek": 768548, "start": 7685.48, "end": 7695.2, "text": " do. This has not been applied to anything yet. So you can take any old paper that produces", "tokens": [360, 13, 639, 575, 406, 668, 6456, 281, 1340, 1939, 13, 407, 291, 393, 747, 604, 1331, 3035, 300, 14725], "temperature": 0.0, "avg_logprob": -0.18251337933896192, "compression_ratio": 1.4943820224719102, "no_speech_prob": 7.071851541695651e-06}, {"id": 1156, "seek": 768548, "start": 7695.2, "end": 7704.719999999999, "text": " 3D outputs or segmentations or depth outputs or colorization or whatever and add this and", "tokens": [805, 35, 23930, 420, 9469, 763, 420, 7161, 23930, 420, 2017, 2144, 420, 2035, 293, 909, 341, 293], "temperature": 0.0, "avg_logprob": -0.18251337933896192, "compression_ratio": 1.4943820224719102, "no_speech_prob": 7.071851541695651e-06}, {"id": 1157, "seek": 768548, "start": 7704.719999999999, "end": 7710.2, "text": " it would be great to see what happens. None of that's been done before. It's not been", "tokens": [309, 576, 312, 869, 281, 536, 437, 2314, 13, 14492, 295, 300, 311, 668, 1096, 949, 13, 467, 311, 406, 668], "temperature": 0.0, "avg_logprob": -0.18251337933896192, "compression_ratio": 1.4943820224719102, "no_speech_prob": 7.071851541695651e-06}, {"id": 1158, "seek": 771020, "start": 7710.2, "end": 7719.88, "text": " done before because we haven't had a good way to train GANs before.", "tokens": [1096, 949, 570, 321, 2378, 380, 632, 257, 665, 636, 281, 3847, 460, 1770, 82, 949, 13], "temperature": 0.0, "avg_logprob": -0.1615694219415838, "compression_ratio": 1.4177215189873418, "no_speech_prob": 8.267822522611823e-06}, {"id": 1159, "seek": 771020, "start": 7719.88, "end": 7728.28, "text": " This is kind of something where anybody who's interested in a project, this would be a great", "tokens": [639, 307, 733, 295, 746, 689, 4472, 567, 311, 3102, 294, 257, 1716, 11, 341, 576, 312, 257, 869], "temperature": 0.0, "avg_logprob": -0.1615694219415838, "compression_ratio": 1.4177215189873418, "no_speech_prob": 8.267822522611823e-06}, {"id": 1160, "seek": 771020, "start": 7728.28, "end": 7733.96, "text": " project and something that maybe you can do reasonably quickly.", "tokens": [1716, 293, 746, 300, 1310, 291, 393, 360, 23551, 2661, 13], "temperature": 0.0, "avg_logprob": -0.1615694219415838, "compression_ratio": 1.4177215189873418, "no_speech_prob": 8.267822522611823e-06}, {"id": 1161, "seek": 773396, "start": 7733.96, "end": 7740.64, "text": " Another thing you could do as a project is to convert this into Keras. So you can take", "tokens": [3996, 551, 291, 727, 360, 382, 257, 1716, 307, 281, 7620, 341, 666, 591, 6985, 13, 407, 291, 393, 747], "temperature": 0.0, "avg_logprob": -0.19035841470741363, "compression_ratio": 1.5424528301886793, "no_speech_prob": 1.384587085340172e-05}, {"id": 1162, "seek": 773396, "start": 7740.64, "end": 7747.36, "text": " the Keras DCGAN notebook that we've already got and change the loss function at the weight", "tokens": [264, 591, 6985, 9114, 27699, 21060, 300, 321, 600, 1217, 658, 293, 1319, 264, 4470, 2445, 412, 264, 3364], "temperature": 0.0, "avg_logprob": -0.19035841470741363, "compression_ratio": 1.5424528301886793, "no_speech_prob": 1.384587085340172e-05}, {"id": 1163, "seek": 773396, "start": 7747.36, "end": 7754.84, "text": " clipping, try training on this Lsun bedroom dataset and you should get the same results.", "tokens": [49320, 11, 853, 3097, 322, 341, 441, 11314, 11211, 28872, 293, 291, 820, 483, 264, 912, 3542, 13], "temperature": 0.0, "avg_logprob": -0.19035841470741363, "compression_ratio": 1.5424528301886793, "no_speech_prob": 1.384587085340172e-05}, {"id": 1164, "seek": 773396, "start": 7754.84, "end": 7759.88, "text": " And then you can add this on top of any of your Keras stuff.", "tokens": [400, 550, 291, 393, 909, 341, 322, 1192, 295, 604, 295, 428, 591, 6985, 1507, 13], "temperature": 0.0, "avg_logprob": -0.19035841470741363, "compression_ratio": 1.5424528301886793, "no_speech_prob": 1.384587085340172e-05}, {"id": 1165, "seek": 775988, "start": 7759.88, "end": 7767.24, "text": " There's so much you could do this week. I don't feel like I want to give you an assignment", "tokens": [821, 311, 370, 709, 291, 727, 360, 341, 1243, 13, 286, 500, 380, 841, 411, 286, 528, 281, 976, 291, 364, 15187], "temperature": 0.0, "avg_logprob": -0.18295828850714715, "compression_ratio": 1.6055045871559632, "no_speech_prob": 8.939649887906853e-06}, {"id": 1166, "seek": 775988, "start": 7767.24, "end": 7773.22, "text": " per se because there's a thousand assignments you could do. As per usual, you should go", "tokens": [680, 369, 570, 456, 311, 257, 4714, 22546, 291, 727, 360, 13, 1018, 680, 7713, 11, 291, 820, 352], "temperature": 0.0, "avg_logprob": -0.18295828850714715, "compression_ratio": 1.6055045871559632, "no_speech_prob": 8.939649887906853e-06}, {"id": 1167, "seek": 775988, "start": 7773.22, "end": 7781.88, "text": " back and look at the papers. The original GAN paper is a fairly easy read. There's a", "tokens": [646, 293, 574, 412, 264, 10577, 13, 440, 3380, 460, 1770, 3035, 307, 257, 6457, 1858, 1401, 13, 821, 311, 257], "temperature": 0.0, "avg_logprob": -0.18295828850714715, "compression_ratio": 1.6055045871559632, "no_speech_prob": 8.939649887906853e-06}, {"id": 1168, "seek": 775988, "start": 7781.88, "end": 7789.84, "text": " section called Theoretical Results, which is kind of like the pointless math bit. Here", "tokens": [3541, 1219, 440, 26262, 804, 5015, 33361, 11, 597, 307, 733, 295, 411, 264, 32824, 5221, 857, 13, 1692], "temperature": 0.0, "avg_logprob": -0.18295828850714715, "compression_ratio": 1.6055045871559632, "no_speech_prob": 8.939649887906853e-06}, {"id": 1169, "seek": 778984, "start": 7789.84, "end": 7794.400000000001, "text": " are some theoretical stuff. It's actually interesting to read this now because you go", "tokens": [366, 512, 20864, 1507, 13, 467, 311, 767, 1880, 281, 1401, 341, 586, 570, 291, 352], "temperature": 0.0, "avg_logprob": -0.20219386916562734, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.2219025848025922e-05}, {"id": 1170, "seek": 778984, "start": 7794.400000000001, "end": 7800.08, "text": " back and you look at this stuff where they prove various nice things about their GAN.", "tokens": [646, 293, 291, 574, 412, 341, 1507, 689, 436, 7081, 3683, 1481, 721, 466, 641, 460, 1770, 13], "temperature": 0.0, "avg_logprob": -0.20219386916562734, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.2219025848025922e-05}, {"id": 1171, "seek": 778984, "start": 7800.08, "end": 7806.12, "text": " They're talking about how the generative model perfectly replicates the data generating process.", "tokens": [814, 434, 1417, 466, 577, 264, 1337, 1166, 2316, 6239, 3248, 299, 1024, 264, 1412, 17746, 1399, 13], "temperature": 0.0, "avg_logprob": -0.20219386916562734, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.2219025848025922e-05}, {"id": 1172, "seek": 778984, "start": 7806.12, "end": 7813.0, "text": " It's interesting to go back and look and say, okay, so they've proved these things, but", "tokens": [467, 311, 1880, 281, 352, 646, 293, 574, 293, 584, 11, 1392, 11, 370, 436, 600, 14617, 613, 721, 11, 457], "temperature": 0.0, "avg_logprob": -0.20219386916562734, "compression_ratio": 1.640552995391705, "no_speech_prob": 1.2219025848025922e-05}, {"id": 1173, "seek": 781300, "start": 7813.0, "end": 7820.0, "text": " it turned out to be totally pointless. It still didn't work. It didn't really work.", "tokens": [309, 3574, 484, 281, 312, 3879, 32824, 13, 467, 920, 994, 380, 589, 13, 467, 994, 380, 534, 589, 13], "temperature": 0.0, "avg_logprob": -0.20046437724252766, "compression_ratio": 1.6859903381642511, "no_speech_prob": 4.157348485023249e-06}, {"id": 1174, "seek": 781300, "start": 7820.0, "end": 7825.4, "text": " It's kind of interesting to look back and say, this isn't a good paper, it is a good", "tokens": [467, 311, 733, 295, 1880, 281, 574, 646, 293, 584, 11, 341, 1943, 380, 257, 665, 3035, 11, 309, 307, 257, 665], "temperature": 0.0, "avg_logprob": -0.20046437724252766, "compression_ratio": 1.6859903381642511, "no_speech_prob": 4.157348485023249e-06}, {"id": 1175, "seek": 781300, "start": 7825.4, "end": 7830.84, "text": " paper, but it is interesting to see when is the theoretical stuff useful and when not.", "tokens": [3035, 11, 457, 309, 307, 1880, 281, 536, 562, 307, 264, 20864, 1507, 4420, 293, 562, 406, 13], "temperature": 0.0, "avg_logprob": -0.20046437724252766, "compression_ratio": 1.6859903381642511, "no_speech_prob": 4.157348485023249e-06}, {"id": 1176, "seek": 781300, "start": 7830.84, "end": 7838.56, "text": " Then you look at the Wasserstein GAN theoretical sections and it spends a lot of time talking", "tokens": [1396, 291, 574, 412, 264, 17351, 9089, 460, 1770, 20864, 10863, 293, 309, 25620, 257, 688, 295, 565, 1417], "temperature": 0.0, "avg_logprob": -0.20046437724252766, "compression_ratio": 1.6859903381642511, "no_speech_prob": 4.157348485023249e-06}, {"id": 1177, "seek": 783856, "start": 7838.56, "end": 7843.76, "text": " about why their theory actually matters. So they have this really cool example, for example,", "tokens": [466, 983, 641, 5261, 767, 7001, 13, 407, 436, 362, 341, 534, 1627, 1365, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.20799169086274646, "compression_ratio": 1.704225352112676, "no_speech_prob": 7.296343937923666e-06}, {"id": 1178, "seek": 783856, "start": 7843.76, "end": 7849.200000000001, "text": " where they say, that's creating something really simple. What if you want to learn just", "tokens": [689, 436, 584, 11, 300, 311, 4084, 746, 534, 2199, 13, 708, 498, 291, 528, 281, 1466, 445], "temperature": 0.0, "avg_logprob": -0.20799169086274646, "compression_ratio": 1.704225352112676, "no_speech_prob": 7.296343937923666e-06}, {"id": 1179, "seek": 783856, "start": 7849.200000000001, "end": 7856.6, "text": " parallel lines? And they show why it is that the old way of doing GANs can't learn parallel", "tokens": [8952, 3876, 30, 400, 436, 855, 983, 309, 307, 300, 264, 1331, 636, 295, 884, 460, 1770, 82, 393, 380, 1466, 8952], "temperature": 0.0, "avg_logprob": -0.20799169086274646, "compression_ratio": 1.704225352112676, "no_speech_prob": 7.296343937923666e-06}, {"id": 1180, "seek": 783856, "start": 7856.6, "end": 7864.04, "text": " lines. And then they show how their different objective function can learn parallel lines.", "tokens": [3876, 13, 400, 550, 436, 855, 577, 641, 819, 10024, 2445, 393, 1466, 8952, 3876, 13], "temperature": 0.0, "avg_logprob": -0.20799169086274646, "compression_ratio": 1.704225352112676, "no_speech_prob": 7.296343937923666e-06}, {"id": 1181, "seek": 786404, "start": 7864.04, "end": 7871.44, "text": " So I think anybody who's interested in getting into the theory a little bit, it's very interesting", "tokens": [407, 286, 519, 4472, 567, 311, 3102, 294, 1242, 666, 264, 5261, 257, 707, 857, 11, 309, 311, 588, 1880], "temperature": 0.0, "avg_logprob": -0.14628668529231373, "compression_ratio": 1.6930232558139535, "no_speech_prob": 5.014710040995851e-06}, {"id": 1182, "seek": 786404, "start": 7871.44, "end": 7880.44, "text": " to look at why the proof of convergence showed something that didn't show something that", "tokens": [281, 574, 412, 983, 264, 8177, 295, 32181, 4712, 746, 300, 994, 380, 855, 746, 300], "temperature": 0.0, "avg_logprob": -0.14628668529231373, "compression_ratio": 1.6930232558139535, "no_speech_prob": 5.014710040995851e-06}, {"id": 1183, "seek": 786404, "start": 7880.44, "end": 7885.44, "text": " really turned out to matter. Where else in this paper, the theory turned out to be super", "tokens": [534, 3574, 484, 281, 1871, 13, 2305, 1646, 294, 341, 3035, 11, 264, 5261, 3574, 484, 281, 312, 1687], "temperature": 0.0, "avg_logprob": -0.14628668529231373, "compression_ratio": 1.6930232558139535, "no_speech_prob": 5.014710040995851e-06}, {"id": 1184, "seek": 786404, "start": 7885.44, "end": 7891.04, "text": " important and basically created something that allowed GANs to work for the first time.", "tokens": [1021, 293, 1936, 2942, 746, 300, 4350, 460, 1770, 82, 281, 589, 337, 264, 700, 565, 13], "temperature": 0.0, "avg_logprob": -0.14628668529231373, "compression_ratio": 1.6930232558139535, "no_speech_prob": 5.014710040995851e-06}, {"id": 1185, "seek": 789104, "start": 7891.04, "end": 7896.72, "text": " So there's lots of stuff you can get out of these papers if you're interested.", "tokens": [407, 456, 311, 3195, 295, 1507, 291, 393, 483, 484, 295, 613, 10577, 498, 291, 434, 3102, 13], "temperature": 0.0, "avg_logprob": -0.1903186064500075, "compression_ratio": 1.5380116959064327, "no_speech_prob": 6.302686961134896e-05}, {"id": 1186, "seek": 789104, "start": 7896.72, "end": 7902.28, "text": " In terms of the notation, we might look at some of the notation a little bit more next", "tokens": [682, 2115, 295, 264, 24657, 11, 321, 1062, 574, 412, 512, 295, 264, 24657, 257, 707, 857, 544, 958], "temperature": 0.0, "avg_logprob": -0.1903186064500075, "compression_ratio": 1.5380116959064327, "no_speech_prob": 6.302686961134896e-05}, {"id": 1187, "seek": 789104, "start": 7902.28, "end": 7921.0, "text": " week. But if we look for example at the algorithm sections, I think in general the most important", "tokens": [1243, 13, 583, 498, 321, 574, 337, 1365, 412, 264, 9284, 10863, 11, 286, 519, 294, 2674, 264, 881, 1021], "temperature": 0.0, "avg_logprob": -0.1903186064500075, "compression_ratio": 1.5380116959064327, "no_speech_prob": 6.302686961134896e-05}, {"id": 1188, "seek": 792100, "start": 7921.0, "end": 7926.28, "text": " part, the bit I find the most useful not being a math guy, is the bit where they actually", "tokens": [644, 11, 264, 857, 286, 915, 264, 881, 4420, 406, 885, 257, 5221, 2146, 11, 307, 264, 857, 689, 436, 767], "temperature": 0.0, "avg_logprob": -0.2804792986975776, "compression_ratio": 1.4745762711864407, "no_speech_prob": 8.13959923107177e-06}, {"id": 1189, "seek": 792100, "start": 7926.28, "end": 7934.52, "text": " write the pseudocode. Even that it's useful to learn some kind of nomenclature.", "tokens": [2464, 264, 25505, 532, 905, 1429, 13, 2754, 300, 309, 311, 4420, 281, 1466, 512, 733, 295, 297, 4726, 3474, 1503, 13], "temperature": 0.0, "avg_logprob": -0.2804792986975776, "compression_ratio": 1.4745762711864407, "no_speech_prob": 8.13959923107177e-06}, {"id": 1190, "seek": 792100, "start": 7934.52, "end": 7943.96, "text": " So for each iteration, what does this mean? Sample, noise samples from noise prior. There's", "tokens": [407, 337, 1184, 24784, 11, 437, 775, 341, 914, 30, 4832, 781, 11, 5658, 10938, 490, 5658, 4059, 13, 821, 311], "temperature": 0.0, "avg_logprob": -0.2804792986975776, "compression_ratio": 1.4745762711864407, "no_speech_prob": 8.13959923107177e-06}, {"id": 1191, "seek": 794396, "start": 7943.96, "end": 7953.0, "text": " a lot of probability nomenclature which you can very quickly translate. A prior simply", "tokens": [257, 688, 295, 8482, 297, 4726, 3474, 1503, 597, 291, 393, 588, 2661, 13799, 13, 316, 4059, 2935], "temperature": 0.0, "avg_logprob": -0.13027667999267578, "compression_ratio": 1.4782608695652173, "no_speech_prob": 1.4738840036443435e-05}, {"id": 1192, "seek": 794396, "start": 7953.0, "end": 7964.72, "text": " means np.random.something. So in this case, we're probably like np.random.normal. So this", "tokens": [1355, 33808, 13, 3699, 298, 13, 31681, 13, 407, 294, 341, 1389, 11, 321, 434, 1391, 411, 33808, 13, 3699, 298, 13, 23157, 13, 407, 341], "temperature": 0.0, "avg_logprob": -0.13027667999267578, "compression_ratio": 1.4782608695652173, "no_speech_prob": 1.4738840036443435e-05}, {"id": 1193, "seek": 794396, "start": 7964.72, "end": 7969.56, "text": " just means some random number generator that you get to pick.", "tokens": [445, 1355, 512, 4974, 1230, 19265, 300, 291, 483, 281, 1888, 13], "temperature": 0.0, "avg_logprob": -0.13027667999267578, "compression_ratio": 1.4782608695652173, "no_speech_prob": 1.4738840036443435e-05}, {"id": 1194, "seek": 796956, "start": 7969.56, "end": 7975.240000000001, "text": " This one here, sample from a data-generating distribution, that means randomly pick some", "tokens": [639, 472, 510, 11, 6889, 490, 257, 1412, 12, 21848, 990, 7316, 11, 300, 1355, 16979, 1888, 512], "temperature": 0.0, "avg_logprob": -0.1411579760109506, "compression_ratio": 1.6495327102803738, "no_speech_prob": 1.4063979506317992e-05}, {"id": 1195, "seek": 796956, "start": 7975.240000000001, "end": 7982.0, "text": " stuff from your array. So these are the two steps. Generate some random numbers and then", "tokens": [1507, 490, 428, 10225, 13, 407, 613, 366, 264, 732, 4439, 13, 15409, 473, 512, 4974, 3547, 293, 550], "temperature": 0.0, "avg_logprob": -0.1411579760109506, "compression_ratio": 1.6495327102803738, "no_speech_prob": 1.4063979506317992e-05}, {"id": 1196, "seek": 796956, "start": 7982.0, "end": 7989.120000000001, "text": " randomly select some things from your array. And then the bit where it talks about the", "tokens": [16979, 3048, 512, 721, 490, 428, 10225, 13, 400, 550, 264, 857, 689, 309, 6686, 466, 264], "temperature": 0.0, "avg_logprob": -0.1411579760109506, "compression_ratio": 1.6495327102803738, "no_speech_prob": 1.4063979506317992e-05}, {"id": 1197, "seek": 796956, "start": 7989.120000000001, "end": 7995.64, "text": " gradient you can largely ignore, except the bit in the middle is your loss function. You", "tokens": [16235, 291, 393, 11611, 11200, 11, 3993, 264, 857, 294, 264, 2808, 307, 428, 4470, 2445, 13, 509], "temperature": 0.0, "avg_logprob": -0.1411579760109506, "compression_ratio": 1.6495327102803738, "no_speech_prob": 1.4063979506317992e-05}, {"id": 1198, "seek": 799564, "start": 7995.64, "end": 8005.360000000001, "text": " can see here, these things here is your noise. So noise, generator on noise, discriminator", "tokens": [393, 536, 510, 11, 613, 721, 510, 307, 428, 5658, 13, 407, 5658, 11, 19265, 322, 5658, 11, 20828, 1639], "temperature": 0.0, "avg_logprob": -0.18442650941702035, "compression_ratio": 1.838862559241706, "no_speech_prob": 1.2411408533807844e-05}, {"id": 1199, "seek": 799564, "start": 8005.360000000001, "end": 8010.12, "text": " on generator on noise. So there's the bit where we're trying to fool the discriminator.", "tokens": [322, 19265, 322, 5658, 13, 407, 456, 311, 264, 857, 689, 321, 434, 1382, 281, 7979, 264, 20828, 1639, 13], "temperature": 0.0, "avg_logprob": -0.18442650941702035, "compression_ratio": 1.838862559241706, "no_speech_prob": 1.2411408533807844e-05}, {"id": 1200, "seek": 799564, "start": 8010.12, "end": 8014.96, "text": " And we're trying to make that trick it, so that's why we do 1-. And then here's getting", "tokens": [400, 321, 434, 1382, 281, 652, 300, 4282, 309, 11, 370, 300, 311, 983, 321, 360, 502, 12, 13, 400, 550, 510, 311, 1242], "temperature": 0.0, "avg_logprob": -0.18442650941702035, "compression_ratio": 1.838862559241706, "no_speech_prob": 1.2411408533807844e-05}, {"id": 1201, "seek": 799564, "start": 8014.96, "end": 8021.4400000000005, "text": " the discriminator to be accurate, because these x's is the real data. So that's the", "tokens": [264, 20828, 1639, 281, 312, 8559, 11, 570, 613, 2031, 311, 307, 264, 957, 1412, 13, 407, 300, 311, 264], "temperature": 0.0, "avg_logprob": -0.18442650941702035, "compression_ratio": 1.838862559241706, "no_speech_prob": 1.2411408533807844e-05}, {"id": 1202, "seek": 799564, "start": 8021.4400000000005, "end": 8025.240000000001, "text": " math version of what we just learned.", "tokens": [5221, 3037, 295, 437, 321, 445, 3264, 13], "temperature": 0.0, "avg_logprob": -0.18442650941702035, "compression_ratio": 1.838862559241706, "no_speech_prob": 1.2411408533807844e-05}, {"id": 1203, "seek": 802524, "start": 8025.24, "end": 8032.599999999999, "text": " The Wasserstein GAN also has an algorithm section, so it's kind of interesting to compare", "tokens": [440, 17351, 9089, 460, 1770, 611, 575, 364, 9284, 3541, 11, 370, 309, 311, 733, 295, 1880, 281, 6794], "temperature": 0.0, "avg_logprob": -0.18552069596841303, "compression_ratio": 1.5780346820809248, "no_speech_prob": 8.220048039220273e-05}, {"id": 1204, "seek": 802524, "start": 8032.599999999999, "end": 8041.599999999999, "text": " the two. Here we go, here's the Wasserstein GAN, here's the algorithm. And basically this", "tokens": [264, 732, 13, 1692, 321, 352, 11, 510, 311, 264, 17351, 9089, 460, 1770, 11, 510, 311, 264, 9284, 13, 400, 1936, 341], "temperature": 0.0, "avg_logprob": -0.18552069596841303, "compression_ratio": 1.5780346820809248, "no_speech_prob": 8.220048039220273e-05}, {"id": 1205, "seek": 802524, "start": 8041.599999999999, "end": 8048.26, "text": " says exactly the same thing as the last one said, but I actually find this one a bit clearer.", "tokens": [1619, 2293, 264, 912, 551, 382, 264, 1036, 472, 848, 11, 457, 286, 767, 915, 341, 472, 257, 857, 26131, 13], "temperature": 0.0, "avg_logprob": -0.18552069596841303, "compression_ratio": 1.5780346820809248, "no_speech_prob": 8.220048039220273e-05}, {"id": 1206, "seek": 804826, "start": 8048.26, "end": 8056.08, "text": " Sample from the real data, sample from your priors. Hopefully that's enough to get going.", "tokens": [4832, 781, 490, 264, 957, 1412, 11, 6889, 490, 428, 1790, 830, 13, 10429, 300, 311, 1547, 281, 483, 516, 13], "temperature": 0.0, "avg_logprob": -0.20316839218139648, "compression_ratio": 1.3923076923076922, "no_speech_prob": 2.111189314746298e-05}, {"id": 1207, "seek": 805608, "start": 8056.08, "end": 8083.08, "text": " I look forward to talking on the forums and see how everybody gets along. Thanks everybody.", "tokens": [50364, 286, 574, 2128, 281, 1417, 322, 264, 26998, 293, 536, 577, 2201, 2170, 2051, 13, 2561, 2201, 13, 51714], "temperature": 0.0, "avg_logprob": -0.3336352620806013, "compression_ratio": 1.1375, "no_speech_prob": 3.070641469093971e-05}], "language": "en"}