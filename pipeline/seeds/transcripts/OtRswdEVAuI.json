{"text": " Okay, now I can see this. Okay. So I'm Rachel, and I'm going to talk about my story of co-founding Fast.ai. I'm going to start back in high school because I've never liked exclusiveness. I went to a very poor public high school in Texas. It was very racially diverse. It was 30% white, 30% Latino, 40% black, and a lot of the wealthier, whiter school districts around us had a very exclusive and sometimes racist attitude. And I also saw that they had access to a lot more resources than we did. And I really hated that inequality and disparity and kind of educational access. Skipping ahead to 2013, since this is a lightning talk. I was working as a data scientist, and deep learning was starting to win a lot of Kaggle competitions, so I was very interested in it. This was before any of the open source deep learning frameworks had been released. I watched Jeffrey Hinton's videos on Coursera, and then I went to hear a pretty famous researcher was speaking at a meetup. I was very excited. And his talk was pretty much purely theoretical. And during the Q&A, I asked a question about how he had initialized his weights, and he said, oh, that's part of a dirty bag of tricks that nobody publishes. And at the time, I was really disappointed. Just feeling like the field was so exclusive and kind of inaccessible because everyone doing it had studied with the same four PhD thesis advisors, and then they weren't sharing the practical info. Also at this time, I was working for a tech company that was very popular, but I was very unhappy there. And people were kind of constantly saying to me, like, oh, you're so lucky to work there. You're lucky to have this job. And I was unhappy and kind of felt like do I need to settle? Like maybe this is as good as it gets. And I gave up on going to meetups and deep learning for a while. Skipping ahead now to 2015, I had my daughter, and it took me about eight weeks to recover from giving birth, so I was mostly lying down during that time. And Andre Karpathy had released his CNN course at Stanford online for free. And so I read the slides. I read them aloud to my newborn. And when I was feeling better, I coded all the assignments, and I thought it was fantastic. That was the most accessible introduction to CNNs I had seen. And at this point, Cafe and Fiano and Keras had been released. I think this was kind of right before TensorFlow was released. And so these are really positive steps. Andre's course and having these open source frameworks available. But Jeremy and I still felt like a lot was missing. Most of the research was happening at Google and OpenAI. And they just have so much money and so much data and so many GPUs that I think they're not even aware of kind of the situation that most of the world trying to do this is in with very limited resources and often with much more practical problems, whereas their research focus tends to be more theoretical. With starting Fast.AI, so our goal was we want eventually for anyone anywhere with limited resources to be able to use deep learning on the problems they care about. And that felt like such a kind of grandiose and maybe somewhat vague goal that I found it embarrassing to tell people what we were doing at first because it's just so ambitious. And we did it now. We were going to do it. And we still don't know how we're going to do it. We tried a few things that didn't pan out but we realized pretty early that a cycle of iterating between research and teaching would be helpful for us. And just as we've told you with deep learning to always start with kind of the simplest model possible on a small sample data set. That's what you all are for us. We were like, let's start by seeing if we can teach coders who will put in 70 hours of time to use deep learning. And when we proposed this last USF, we weren't sure if that was even possible or how we would do it. But we knew we would try our best. And I think it was also important for us to kind of make this commitment and put ourselves on the hook of, okay, now we have to deliver. Yeah, so that's how we started. I've been very excited about helping to bond. I hope you are too. If not, let me know. And we're less than a year into Fast.AI's journey and I'm excited about where we'll go in the future. Thanks. Thank you. Applause Can you share some of the things which did work? Alright, and some of this is also time. So like I will come back to these. So there's a language called J, which is a descendant of APL for really vectorizing math operations. And it has a really neat notation. And so we felt like there's some potential there to be able to program more concisely. Yeah, and it's like a total mind trip to learn. Because something that would be like 20 lines of code in another program is like nine symbols. But like the way those symbols are put together. So that was something. But I think we're going to return to that, that we were kind of studying some last year to set aside. And I think we're going to go back to this too. We're kind of working on some super resolution, which we have returned to with the course that we kind of put aside. Any other questions? What is your focus after Fast 2? Well, so my personal focus in May and June will be entering a numerical linear algebra class at USF, which is getting computers to do matrix operations very quickly and with acceptable accuracy. I'm actually not even sure what \u2013 we want to come back to \u2013 and one of our goals is to make it easier for people to deploy apps. And so we're hoping to make several test apps and deploy them to see kind of what the pain points in that process are. So I think that's something we'll probably return to this summer. Any other questions? What are your thoughts on Fast 2? My last question. How do you measure your progress rate? So how do you know if you can improve on what you do? That's a good question. I guess it's somewhat subjective. And I mean, I find a lot of satisfaction when I'm able to help people and kind of getting positive feedback around that. Something Jeremy and I were talking about earlier is that I think I've also had to recognize things that I'm going to do less of to have more time for the high priority stuff. And so I'm right now putting a lot of time into preparing for the course I'm going to teach in May. That's really important to me. But I had to kind of choose, like, okay, I need to go to less conferences and go to fewer meetups and kind of decide these are the things I'm going to put less time into. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.8, "text": " Okay, now I can see this. Okay. So I'm Rachel, and I'm going to talk about my story", "tokens": [1033, 11, 586, 286, 393, 536, 341, 13, 1033, 13, 407, 286, 478, 14246, 11, 293, 286, 478, 516, 281, 751, 466, 452, 1657], "temperature": 0.0, "avg_logprob": -0.19983043848911178, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.07577928155660629}, {"id": 1, "seek": 0, "start": 4.8, "end": 11.4, "text": " of co-founding Fast.ai. I'm going to start back in high school because I've never liked exclusiveness.", "tokens": [295, 598, 12, 17493, 278, 15968, 13, 1301, 13, 286, 478, 516, 281, 722, 646, 294, 1090, 1395, 570, 286, 600, 1128, 4501, 15085, 8477, 13], "temperature": 0.0, "avg_logprob": -0.19983043848911178, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.07577928155660629}, {"id": 2, "seek": 0, "start": 11.4, "end": 17.2, "text": " I went to a very poor public high school in Texas. It was very racially diverse.", "tokens": [286, 1437, 281, 257, 588, 4716, 1908, 1090, 1395, 294, 7885, 13, 467, 390, 588, 4129, 2270, 9521, 13], "temperature": 0.0, "avg_logprob": -0.19983043848911178, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.07577928155660629}, {"id": 3, "seek": 0, "start": 17.2, "end": 25.5, "text": " It was 30% white, 30% Latino, 40% black, and a lot of the wealthier, whiter school districts around us", "tokens": [467, 390, 2217, 4, 2418, 11, 2217, 4, 25422, 11, 3356, 4, 2211, 11, 293, 257, 688, 295, 264, 7203, 811, 11, 315, 1681, 1395, 16815, 926, 505], "temperature": 0.0, "avg_logprob": -0.19983043848911178, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.07577928155660629}, {"id": 4, "seek": 2550, "start": 25.5, "end": 32.3, "text": " had a very exclusive and sometimes racist attitude. And I also saw that they had access to a lot more", "tokens": [632, 257, 588, 13005, 293, 2171, 16419, 10157, 13, 400, 286, 611, 1866, 300, 436, 632, 2105, 281, 257, 688, 544], "temperature": 0.0, "avg_logprob": -0.14983590443929037, "compression_ratio": 1.6097560975609757, "no_speech_prob": 2.930927075794898e-05}, {"id": 5, "seek": 2550, "start": 32.3, "end": 40.2, "text": " resources than we did. And I really hated that inequality and disparity and kind of educational access.", "tokens": [3593, 813, 321, 630, 13, 400, 286, 534, 17398, 300, 16970, 293, 47415, 293, 733, 295, 10189, 2105, 13], "temperature": 0.0, "avg_logprob": -0.14983590443929037, "compression_ratio": 1.6097560975609757, "no_speech_prob": 2.930927075794898e-05}, {"id": 6, "seek": 2550, "start": 40.2, "end": 47.6, "text": " Skipping ahead to 2013, since this is a lightning talk. I was working as a data scientist,", "tokens": [7324, 6297, 2286, 281, 9012, 11, 1670, 341, 307, 257, 16589, 751, 13, 286, 390, 1364, 382, 257, 1412, 12662, 11], "temperature": 0.0, "avg_logprob": -0.14983590443929037, "compression_ratio": 1.6097560975609757, "no_speech_prob": 2.930927075794898e-05}, {"id": 7, "seek": 2550, "start": 47.6, "end": 52.400000000000006, "text": " and deep learning was starting to win a lot of Kaggle competitions, so I was very interested in it.", "tokens": [293, 2452, 2539, 390, 2891, 281, 1942, 257, 688, 295, 48751, 22631, 26185, 11, 370, 286, 390, 588, 3102, 294, 309, 13], "temperature": 0.0, "avg_logprob": -0.14983590443929037, "compression_ratio": 1.6097560975609757, "no_speech_prob": 2.930927075794898e-05}, {"id": 8, "seek": 5240, "start": 52.4, "end": 56.9, "text": " This was before any of the open source deep learning frameworks had been released.", "tokens": [639, 390, 949, 604, 295, 264, 1269, 4009, 2452, 2539, 29834, 632, 668, 4736, 13], "temperature": 0.0, "avg_logprob": -0.12007611316183339, "compression_ratio": 1.5845070422535212, "no_speech_prob": 3.9438808016711846e-05}, {"id": 9, "seek": 5240, "start": 56.9, "end": 63.6, "text": " I watched Jeffrey Hinton's videos on Coursera, and then I went to hear a pretty famous researcher", "tokens": [286, 6337, 28721, 389, 12442, 311, 2145, 322, 383, 5067, 1663, 11, 293, 550, 286, 1437, 281, 1568, 257, 1238, 4618, 21751], "temperature": 0.0, "avg_logprob": -0.12007611316183339, "compression_ratio": 1.5845070422535212, "no_speech_prob": 3.9438808016711846e-05}, {"id": 10, "seek": 5240, "start": 63.6, "end": 69.9, "text": " was speaking at a meetup. I was very excited. And his talk was pretty much purely theoretical.", "tokens": [390, 4124, 412, 257, 1677, 1010, 13, 286, 390, 588, 2919, 13, 400, 702, 751, 390, 1238, 709, 17491, 20864, 13], "temperature": 0.0, "avg_logprob": -0.12007611316183339, "compression_ratio": 1.5845070422535212, "no_speech_prob": 3.9438808016711846e-05}, {"id": 11, "seek": 5240, "start": 69.9, "end": 75.6, "text": " And during the Q&A, I asked a question about how he had initialized his weights, and he said,", "tokens": [400, 1830, 264, 1249, 5, 32, 11, 286, 2351, 257, 1168, 466, 577, 415, 632, 5883, 1602, 702, 17443, 11, 293, 415, 848, 11], "temperature": 0.0, "avg_logprob": -0.12007611316183339, "compression_ratio": 1.5845070422535212, "no_speech_prob": 3.9438808016711846e-05}, {"id": 12, "seek": 5240, "start": 75.6, "end": 80.0, "text": " oh, that's part of a dirty bag of tricks that nobody publishes. And at the time,", "tokens": [1954, 11, 300, 311, 644, 295, 257, 9360, 3411, 295, 11733, 300, 5079, 11374, 279, 13, 400, 412, 264, 565, 11], "temperature": 0.0, "avg_logprob": -0.12007611316183339, "compression_ratio": 1.5845070422535212, "no_speech_prob": 3.9438808016711846e-05}, {"id": 13, "seek": 8000, "start": 80.0, "end": 85.2, "text": " I was really disappointed. Just feeling like the field was so exclusive and kind of inaccessible", "tokens": [286, 390, 534, 13856, 13, 1449, 2633, 411, 264, 2519, 390, 370, 13005, 293, 733, 295, 33230, 780, 964], "temperature": 0.0, "avg_logprob": -0.14429734767168417, "compression_ratio": 1.56198347107438, "no_speech_prob": 3.943798583350144e-05}, {"id": 14, "seek": 8000, "start": 85.2, "end": 90.0, "text": " because everyone doing it had studied with the same four PhD thesis advisors,", "tokens": [570, 1518, 884, 309, 632, 9454, 365, 264, 912, 1451, 14476, 22288, 29136, 11], "temperature": 0.0, "avg_logprob": -0.14429734767168417, "compression_ratio": 1.56198347107438, "no_speech_prob": 3.943798583350144e-05}, {"id": 15, "seek": 8000, "start": 90.0, "end": 97.1, "text": " and then they weren't sharing the practical info. Also at this time, I was working for a tech company", "tokens": [293, 550, 436, 4999, 380, 5414, 264, 8496, 13614, 13, 2743, 412, 341, 565, 11, 286, 390, 1364, 337, 257, 7553, 2237], "temperature": 0.0, "avg_logprob": -0.14429734767168417, "compression_ratio": 1.56198347107438, "no_speech_prob": 3.943798583350144e-05}, {"id": 16, "seek": 8000, "start": 97.1, "end": 103.3, "text": " that was very popular, but I was very unhappy there. And people were kind of constantly saying to me,", "tokens": [300, 390, 588, 3743, 11, 457, 286, 390, 588, 22172, 456, 13, 400, 561, 645, 733, 295, 6460, 1566, 281, 385, 11], "temperature": 0.0, "avg_logprob": -0.14429734767168417, "compression_ratio": 1.56198347107438, "no_speech_prob": 3.943798583350144e-05}, {"id": 17, "seek": 10330, "start": 103.3, "end": 110.2, "text": " like, oh, you're so lucky to work there. You're lucky to have this job. And I was unhappy", "tokens": [411, 11, 1954, 11, 291, 434, 370, 6356, 281, 589, 456, 13, 509, 434, 6356, 281, 362, 341, 1691, 13, 400, 286, 390, 22172], "temperature": 0.0, "avg_logprob": -0.16257826763650646, "compression_ratio": 1.5724907063197027, "no_speech_prob": 2.8408123398548923e-05}, {"id": 18, "seek": 10330, "start": 110.2, "end": 114.1, "text": " and kind of felt like do I need to settle? Like maybe this is as good as it gets.", "tokens": [293, 733, 295, 2762, 411, 360, 286, 643, 281, 11852, 30, 1743, 1310, 341, 307, 382, 665, 382, 309, 2170, 13], "temperature": 0.0, "avg_logprob": -0.16257826763650646, "compression_ratio": 1.5724907063197027, "no_speech_prob": 2.8408123398548923e-05}, {"id": 19, "seek": 10330, "start": 114.1, "end": 118.2, "text": " And I gave up on going to meetups and deep learning for a while.", "tokens": [400, 286, 2729, 493, 322, 516, 281, 1677, 7528, 293, 2452, 2539, 337, 257, 1339, 13], "temperature": 0.0, "avg_logprob": -0.16257826763650646, "compression_ratio": 1.5724907063197027, "no_speech_prob": 2.8408123398548923e-05}, {"id": 20, "seek": 10330, "start": 118.2, "end": 124.8, "text": " Skipping ahead now to 2015, I had my daughter, and it took me about eight weeks to recover", "tokens": [7324, 6297, 2286, 586, 281, 7546, 11, 286, 632, 452, 4653, 11, 293, 309, 1890, 385, 466, 3180, 3259, 281, 8114], "temperature": 0.0, "avg_logprob": -0.16257826763650646, "compression_ratio": 1.5724907063197027, "no_speech_prob": 2.8408123398548923e-05}, {"id": 21, "seek": 10330, "start": 124.8, "end": 129.9, "text": " from giving birth, so I was mostly lying down during that time. And Andre Karpathy had released", "tokens": [490, 2902, 3965, 11, 370, 286, 390, 5240, 8493, 760, 1830, 300, 565, 13, 400, 20667, 591, 6529, 9527, 632, 4736], "temperature": 0.0, "avg_logprob": -0.16257826763650646, "compression_ratio": 1.5724907063197027, "no_speech_prob": 2.8408123398548923e-05}, {"id": 22, "seek": 12990, "start": 129.9, "end": 136.70000000000002, "text": " his CNN course at Stanford online for free. And so I read the slides. I read them aloud to my newborn.", "tokens": [702, 24859, 1164, 412, 20374, 2950, 337, 1737, 13, 400, 370, 286, 1401, 264, 9788, 13, 286, 1401, 552, 43888, 281, 452, 32928, 13], "temperature": 0.0, "avg_logprob": -0.17573663923475477, "compression_ratio": 1.6367041198501873, "no_speech_prob": 2.6272444301866926e-05}, {"id": 23, "seek": 12990, "start": 136.70000000000002, "end": 141.20000000000002, "text": " And when I was feeling better, I coded all the assignments, and I thought it was fantastic.", "tokens": [400, 562, 286, 390, 2633, 1101, 11, 286, 34874, 439, 264, 22546, 11, 293, 286, 1194, 309, 390, 5456, 13], "temperature": 0.0, "avg_logprob": -0.17573663923475477, "compression_ratio": 1.6367041198501873, "no_speech_prob": 2.6272444301866926e-05}, {"id": 24, "seek": 12990, "start": 141.20000000000002, "end": 146.1, "text": " That was the most accessible introduction to CNNs I had seen. And at this point,", "tokens": [663, 390, 264, 881, 9515, 9339, 281, 24859, 82, 286, 632, 1612, 13, 400, 412, 341, 935, 11], "temperature": 0.0, "avg_logprob": -0.17573663923475477, "compression_ratio": 1.6367041198501873, "no_speech_prob": 2.6272444301866926e-05}, {"id": 25, "seek": 12990, "start": 146.1, "end": 151.5, "text": " Cafe and Fiano and Keras had been released. I think this was kind of right before", "tokens": [35864, 293, 479, 6254, 293, 591, 6985, 632, 668, 4736, 13, 286, 519, 341, 390, 733, 295, 558, 949], "temperature": 0.0, "avg_logprob": -0.17573663923475477, "compression_ratio": 1.6367041198501873, "no_speech_prob": 2.6272444301866926e-05}, {"id": 26, "seek": 12990, "start": 151.5, "end": 157.9, "text": " TensorFlow was released. And so these are really positive steps. Andre's course", "tokens": [37624, 390, 4736, 13, 400, 370, 613, 366, 534, 3353, 4439, 13, 20667, 311, 1164], "temperature": 0.0, "avg_logprob": -0.17573663923475477, "compression_ratio": 1.6367041198501873, "no_speech_prob": 2.6272444301866926e-05}, {"id": 27, "seek": 15790, "start": 157.9, "end": 163.20000000000002, "text": " and having these open source frameworks available. But Jeremy and I still felt like a lot was missing.", "tokens": [293, 1419, 613, 1269, 4009, 29834, 2435, 13, 583, 17809, 293, 286, 920, 2762, 411, 257, 688, 390, 5361, 13], "temperature": 0.0, "avg_logprob": -0.12479211699287847, "compression_ratio": 1.6583629893238434, "no_speech_prob": 6.708237924613059e-05}, {"id": 28, "seek": 15790, "start": 163.20000000000002, "end": 169.1, "text": " Most of the research was happening at Google and OpenAI. And they just have so much money", "tokens": [4534, 295, 264, 2132, 390, 2737, 412, 3329, 293, 7238, 48698, 13, 400, 436, 445, 362, 370, 709, 1460], "temperature": 0.0, "avg_logprob": -0.12479211699287847, "compression_ratio": 1.6583629893238434, "no_speech_prob": 6.708237924613059e-05}, {"id": 29, "seek": 15790, "start": 169.1, "end": 174.20000000000002, "text": " and so much data and so many GPUs that I think they're not even aware of kind of the situation", "tokens": [293, 370, 709, 1412, 293, 370, 867, 18407, 82, 300, 286, 519, 436, 434, 406, 754, 3650, 295, 733, 295, 264, 2590], "temperature": 0.0, "avg_logprob": -0.12479211699287847, "compression_ratio": 1.6583629893238434, "no_speech_prob": 6.708237924613059e-05}, {"id": 30, "seek": 15790, "start": 174.20000000000002, "end": 179.20000000000002, "text": " that most of the world trying to do this is in with very limited resources and often with much more", "tokens": [300, 881, 295, 264, 1002, 1382, 281, 360, 341, 307, 294, 365, 588, 5567, 3593, 293, 2049, 365, 709, 544], "temperature": 0.0, "avg_logprob": -0.12479211699287847, "compression_ratio": 1.6583629893238434, "no_speech_prob": 6.708237924613059e-05}, {"id": 31, "seek": 15790, "start": 179.20000000000002, "end": 184.20000000000002, "text": " practical problems, whereas their research focus tends to be more theoretical.", "tokens": [8496, 2740, 11, 9735, 641, 2132, 1879, 12258, 281, 312, 544, 20864, 13], "temperature": 0.0, "avg_logprob": -0.12479211699287847, "compression_ratio": 1.6583629893238434, "no_speech_prob": 6.708237924613059e-05}, {"id": 32, "seek": 18420, "start": 184.2, "end": 193.6, "text": " With starting Fast.AI, so our goal was we want eventually for anyone anywhere with limited resources", "tokens": [2022, 2891, 15968, 13, 48698, 11, 370, 527, 3387, 390, 321, 528, 4728, 337, 2878, 4992, 365, 5567, 3593], "temperature": 0.0, "avg_logprob": -0.14641494336335556, "compression_ratio": 1.5950413223140496, "no_speech_prob": 5.143590897205286e-05}, {"id": 33, "seek": 18420, "start": 193.6, "end": 199.29999999999998, "text": " to be able to use deep learning on the problems they care about. And that felt like such a kind of grandiose", "tokens": [281, 312, 1075, 281, 764, 2452, 2539, 322, 264, 2740, 436, 1127, 466, 13, 400, 300, 2762, 411, 1270, 257, 733, 295, 45155, 541], "temperature": 0.0, "avg_logprob": -0.14641494336335556, "compression_ratio": 1.5950413223140496, "no_speech_prob": 5.143590897205286e-05}, {"id": 34, "seek": 18420, "start": 199.29999999999998, "end": 205.29999999999998, "text": " and maybe somewhat vague goal that I found it embarrassing to tell people what we were doing at first", "tokens": [293, 1310, 8344, 24247, 3387, 300, 286, 1352, 309, 17299, 281, 980, 561, 437, 321, 645, 884, 412, 700], "temperature": 0.0, "avg_logprob": -0.14641494336335556, "compression_ratio": 1.5950413223140496, "no_speech_prob": 5.143590897205286e-05}, {"id": 35, "seek": 18420, "start": 205.29999999999998, "end": 209.29999999999998, "text": " because it's just so ambitious. And we did it now. We were going to do it.", "tokens": [570, 309, 311, 445, 370, 20239, 13, 400, 321, 630, 309, 586, 13, 492, 645, 516, 281, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.14641494336335556, "compression_ratio": 1.5950413223140496, "no_speech_prob": 5.143590897205286e-05}, {"id": 36, "seek": 20930, "start": 209.3, "end": 215.10000000000002, "text": " And we still don't know how we're going to do it. We tried a few things that didn't pan out", "tokens": [400, 321, 920, 500, 380, 458, 577, 321, 434, 516, 281, 360, 309, 13, 492, 3031, 257, 1326, 721, 300, 994, 380, 2462, 484], "temperature": 0.0, "avg_logprob": -0.10640055557777142, "compression_ratio": 1.6056338028169015, "no_speech_prob": 3.218637721147388e-05}, {"id": 37, "seek": 20930, "start": 215.10000000000002, "end": 220.8, "text": " but we realized pretty early that a cycle of iterating between research and teaching", "tokens": [457, 321, 5334, 1238, 2440, 300, 257, 6586, 295, 17138, 990, 1296, 2132, 293, 4571], "temperature": 0.0, "avg_logprob": -0.10640055557777142, "compression_ratio": 1.6056338028169015, "no_speech_prob": 3.218637721147388e-05}, {"id": 38, "seek": 20930, "start": 220.8, "end": 226.60000000000002, "text": " would be helpful for us. And just as we've told you with deep learning to always start with", "tokens": [576, 312, 4961, 337, 505, 13, 400, 445, 382, 321, 600, 1907, 291, 365, 2452, 2539, 281, 1009, 722, 365], "temperature": 0.0, "avg_logprob": -0.10640055557777142, "compression_ratio": 1.6056338028169015, "no_speech_prob": 3.218637721147388e-05}, {"id": 39, "seek": 20930, "start": 226.60000000000002, "end": 233.8, "text": " kind of the simplest model possible on a small sample data set. That's what you all are for us.", "tokens": [733, 295, 264, 22811, 2316, 1944, 322, 257, 1359, 6889, 1412, 992, 13, 663, 311, 437, 291, 439, 366, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.10640055557777142, "compression_ratio": 1.6056338028169015, "no_speech_prob": 3.218637721147388e-05}, {"id": 40, "seek": 20930, "start": 233.8, "end": 239.10000000000002, "text": " We were like, let's start by seeing if we can teach coders who will put in 70 hours of time", "tokens": [492, 645, 411, 11, 718, 311, 722, 538, 2577, 498, 321, 393, 2924, 17656, 433, 567, 486, 829, 294, 5285, 2496, 295, 565], "temperature": 0.0, "avg_logprob": -0.10640055557777142, "compression_ratio": 1.6056338028169015, "no_speech_prob": 3.218637721147388e-05}, {"id": 41, "seek": 23910, "start": 239.1, "end": 245.6, "text": " to use deep learning. And when we proposed this last USF, we weren't sure if that was even possible", "tokens": [281, 764, 2452, 2539, 13, 400, 562, 321, 10348, 341, 1036, 2546, 37, 11, 321, 4999, 380, 988, 498, 300, 390, 754, 1944], "temperature": 0.0, "avg_logprob": -0.13612718657245787, "compression_ratio": 1.6076388888888888, "no_speech_prob": 6.30189897492528e-05}, {"id": 42, "seek": 23910, "start": 245.6, "end": 250.7, "text": " or how we would do it. But we knew we would try our best. And I think it was also important for us", "tokens": [420, 577, 321, 576, 360, 309, 13, 583, 321, 2586, 321, 576, 853, 527, 1151, 13, 400, 286, 519, 309, 390, 611, 1021, 337, 505], "temperature": 0.0, "avg_logprob": -0.13612718657245787, "compression_ratio": 1.6076388888888888, "no_speech_prob": 6.30189897492528e-05}, {"id": 43, "seek": 23910, "start": 250.7, "end": 254.6, "text": " to kind of make this commitment and put ourselves on the hook of, okay, now we have to deliver.", "tokens": [281, 733, 295, 652, 341, 8371, 293, 829, 4175, 322, 264, 6328, 295, 11, 1392, 11, 586, 321, 362, 281, 4239, 13], "temperature": 0.0, "avg_logprob": -0.13612718657245787, "compression_ratio": 1.6076388888888888, "no_speech_prob": 6.30189897492528e-05}, {"id": 44, "seek": 23910, "start": 254.6, "end": 260.2, "text": " Yeah, so that's how we started. I've been very excited about helping to bond.", "tokens": [865, 11, 370, 300, 311, 577, 321, 1409, 13, 286, 600, 668, 588, 2919, 466, 4315, 281, 6086, 13], "temperature": 0.0, "avg_logprob": -0.13612718657245787, "compression_ratio": 1.6076388888888888, "no_speech_prob": 6.30189897492528e-05}, {"id": 45, "seek": 23910, "start": 260.2, "end": 266.8, "text": " I hope you are too. If not, let me know. And we're less than a year into Fast.AI's journey", "tokens": [286, 1454, 291, 366, 886, 13, 759, 406, 11, 718, 385, 458, 13, 400, 321, 434, 1570, 813, 257, 1064, 666, 15968, 13, 48698, 311, 4671], "temperature": 0.0, "avg_logprob": -0.13612718657245787, "compression_ratio": 1.6076388888888888, "no_speech_prob": 6.30189897492528e-05}, {"id": 46, "seek": 26680, "start": 266.8, "end": 270.5, "text": " and I'm excited about where we'll go in the future. Thanks.", "tokens": [293, 286, 478, 2919, 466, 689, 321, 603, 352, 294, 264, 2027, 13, 2561, 13], "temperature": 0.0, "avg_logprob": -0.29758315862611284, "compression_ratio": 1.4407582938388626, "no_speech_prob": 6.603817746508867e-05}, {"id": 47, "seek": 26680, "start": 270.5, "end": 271.5, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.29758315862611284, "compression_ratio": 1.4407582938388626, "no_speech_prob": 6.603817746508867e-05}, {"id": 48, "seek": 26680, "start": 271.5, "end": 273.5, "text": " Applause", "tokens": [19281], "temperature": 0.0, "avg_logprob": -0.29758315862611284, "compression_ratio": 1.4407582938388626, "no_speech_prob": 6.603817746508867e-05}, {"id": 49, "seek": 26680, "start": 273.5, "end": 277.5, "text": " Can you share some of the things which did work?", "tokens": [1664, 291, 2073, 512, 295, 264, 721, 597, 630, 589, 30], "temperature": 0.0, "avg_logprob": -0.29758315862611284, "compression_ratio": 1.4407582938388626, "no_speech_prob": 6.603817746508867e-05}, {"id": 50, "seek": 26680, "start": 277.5, "end": 283.2, "text": " Alright, and some of this is also time. So like I will come back to these.", "tokens": [2798, 11, 293, 512, 295, 341, 307, 611, 565, 13, 407, 411, 286, 486, 808, 646, 281, 613, 13], "temperature": 0.0, "avg_logprob": -0.29758315862611284, "compression_ratio": 1.4407582938388626, "no_speech_prob": 6.603817746508867e-05}, {"id": 51, "seek": 26680, "start": 283.2, "end": 292.2, "text": " So there's a language called J, which is a descendant of APL for really vectorizing math operations.", "tokens": [407, 456, 311, 257, 2856, 1219, 508, 11, 597, 307, 257, 16333, 394, 295, 5372, 43, 337, 534, 8062, 3319, 5221, 7705, 13], "temperature": 0.0, "avg_logprob": -0.29758315862611284, "compression_ratio": 1.4407582938388626, "no_speech_prob": 6.603817746508867e-05}, {"id": 52, "seek": 29220, "start": 292.2, "end": 297.3, "text": " And it has a really neat notation. And so we felt like there's some potential there to be able to", "tokens": [400, 309, 575, 257, 534, 10654, 24657, 13, 400, 370, 321, 2762, 411, 456, 311, 512, 3995, 456, 281, 312, 1075, 281], "temperature": 0.0, "avg_logprob": -0.23339242755242115, "compression_ratio": 1.7028112449799198, "no_speech_prob": 0.00022333716333378106}, {"id": 53, "seek": 29220, "start": 297.3, "end": 306.09999999999997, "text": " program more concisely. Yeah, and it's like a total mind trip to learn.", "tokens": [1461, 544, 1588, 271, 736, 13, 865, 11, 293, 309, 311, 411, 257, 3217, 1575, 4931, 281, 1466, 13], "temperature": 0.0, "avg_logprob": -0.23339242755242115, "compression_ratio": 1.7028112449799198, "no_speech_prob": 0.00022333716333378106}, {"id": 54, "seek": 29220, "start": 306.09999999999997, "end": 312.59999999999997, "text": " Because something that would be like 20 lines of code in another program is like nine symbols.", "tokens": [1436, 746, 300, 576, 312, 411, 945, 3876, 295, 3089, 294, 1071, 1461, 307, 411, 4949, 16944, 13], "temperature": 0.0, "avg_logprob": -0.23339242755242115, "compression_ratio": 1.7028112449799198, "no_speech_prob": 0.00022333716333378106}, {"id": 55, "seek": 29220, "start": 312.59999999999997, "end": 316.8, "text": " But like the way those symbols are put together. So that was something.", "tokens": [583, 411, 264, 636, 729, 16944, 366, 829, 1214, 13, 407, 300, 390, 746, 13], "temperature": 0.0, "avg_logprob": -0.23339242755242115, "compression_ratio": 1.7028112449799198, "no_speech_prob": 0.00022333716333378106}, {"id": 56, "seek": 29220, "start": 316.8, "end": 320.8, "text": " But I think we're going to return to that, that we were kind of studying some last year", "tokens": [583, 286, 519, 321, 434, 516, 281, 2736, 281, 300, 11, 300, 321, 645, 733, 295, 7601, 512, 1036, 1064], "temperature": 0.0, "avg_logprob": -0.23339242755242115, "compression_ratio": 1.7028112449799198, "no_speech_prob": 0.00022333716333378106}, {"id": 57, "seek": 32080, "start": 320.8, "end": 327.5, "text": " to set aside. And I think we're going to go back to this too. We're kind of working on some", "tokens": [281, 992, 7359, 13, 400, 286, 519, 321, 434, 516, 281, 352, 646, 281, 341, 886, 13, 492, 434, 733, 295, 1364, 322, 512], "temperature": 0.0, "avg_logprob": -0.2925648255781694, "compression_ratio": 1.5, "no_speech_prob": 0.00012335409701336175}, {"id": 58, "seek": 32080, "start": 327.5, "end": 335.2, "text": " super resolution, which we have returned to with the course that we kind of put aside.", "tokens": [1687, 8669, 11, 597, 321, 362, 8752, 281, 365, 264, 1164, 300, 321, 733, 295, 829, 7359, 13], "temperature": 0.0, "avg_logprob": -0.2925648255781694, "compression_ratio": 1.5, "no_speech_prob": 0.00012335409701336175}, {"id": 59, "seek": 32080, "start": 335.2, "end": 337.2, "text": " Any other questions?", "tokens": [2639, 661, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2925648255781694, "compression_ratio": 1.5, "no_speech_prob": 0.00012335409701336175}, {"id": 60, "seek": 32080, "start": 337.2, "end": 340.6, "text": " What is your focus after Fast 2?", "tokens": [708, 307, 428, 1879, 934, 15968, 568, 30], "temperature": 0.0, "avg_logprob": -0.2925648255781694, "compression_ratio": 1.5, "no_speech_prob": 0.00012335409701336175}, {"id": 61, "seek": 32080, "start": 340.6, "end": 348.2, "text": " Well, so my personal focus in May and June will be entering a numerical linear algebra class at USF,", "tokens": [1042, 11, 370, 452, 2973, 1879, 294, 1891, 293, 6928, 486, 312, 11104, 257, 29054, 8213, 21989, 1508, 412, 2546, 37, 11], "temperature": 0.0, "avg_logprob": -0.2925648255781694, "compression_ratio": 1.5, "no_speech_prob": 0.00012335409701336175}, {"id": 62, "seek": 34820, "start": 348.2, "end": 357.5, "text": " which is getting computers to do matrix operations very quickly and with acceptable accuracy.", "tokens": [597, 307, 1242, 10807, 281, 360, 8141, 7705, 588, 2661, 293, 365, 15513, 14170, 13], "temperature": 0.0, "avg_logprob": -0.16895292093465616, "compression_ratio": 1.564516129032258, "no_speech_prob": 6.604066584259272e-05}, {"id": 63, "seek": 34820, "start": 357.5, "end": 363.7, "text": " I'm actually not even sure what \u2013 we want to come back to \u2013 and one of our goals is to make it", "tokens": [286, 478, 767, 406, 754, 988, 437, 1662, 321, 528, 281, 808, 646, 281, 1662, 293, 472, 295, 527, 5493, 307, 281, 652, 309], "temperature": 0.0, "avg_logprob": -0.16895292093465616, "compression_ratio": 1.564516129032258, "no_speech_prob": 6.604066584259272e-05}, {"id": 64, "seek": 34820, "start": 363.7, "end": 370.8, "text": " easier for people to deploy apps. And so we're hoping to make several test apps and deploy them", "tokens": [3571, 337, 561, 281, 7274, 7733, 13, 400, 370, 321, 434, 7159, 281, 652, 2940, 1500, 7733, 293, 7274, 552], "temperature": 0.0, "avg_logprob": -0.16895292093465616, "compression_ratio": 1.564516129032258, "no_speech_prob": 6.604066584259272e-05}, {"id": 65, "seek": 34820, "start": 370.8, "end": 374.59999999999997, "text": " to see kind of what the pain points in that process are. So I think that's something we'll probably", "tokens": [281, 536, 733, 295, 437, 264, 1822, 2793, 294, 300, 1399, 366, 13, 407, 286, 519, 300, 311, 746, 321, 603, 1391], "temperature": 0.0, "avg_logprob": -0.16895292093465616, "compression_ratio": 1.564516129032258, "no_speech_prob": 6.604066584259272e-05}, {"id": 66, "seek": 37460, "start": 374.6, "end": 378.6, "text": " return to this summer.", "tokens": [2736, 281, 341, 4266, 13], "temperature": 0.0, "avg_logprob": -0.3963804244995117, "compression_ratio": 1.4947916666666667, "no_speech_prob": 7.483254739781842e-05}, {"id": 67, "seek": 37460, "start": 378.6, "end": 382.6, "text": " Any other questions?", "tokens": [2639, 661, 1651, 30], "temperature": 0.0, "avg_logprob": -0.3963804244995117, "compression_ratio": 1.4947916666666667, "no_speech_prob": 7.483254739781842e-05}, {"id": 68, "seek": 37460, "start": 382.6, "end": 386.6, "text": " What are your thoughts on Fast 2?", "tokens": [708, 366, 428, 4598, 322, 15968, 568, 30], "temperature": 0.0, "avg_logprob": -0.3963804244995117, "compression_ratio": 1.4947916666666667, "no_speech_prob": 7.483254739781842e-05}, {"id": 69, "seek": 37460, "start": 386.6, "end": 395.6, "text": " My last question. How do you measure your progress rate? So how do you know if you can improve on what you do?", "tokens": [1222, 1036, 1168, 13, 1012, 360, 291, 3481, 428, 4205, 3314, 30, 407, 577, 360, 291, 458, 498, 291, 393, 3470, 322, 437, 291, 360, 30], "temperature": 0.0, "avg_logprob": -0.3963804244995117, "compression_ratio": 1.4947916666666667, "no_speech_prob": 7.483254739781842e-05}, {"id": 70, "seek": 37460, "start": 395.6, "end": 403.8, "text": " That's a good question. I guess it's somewhat subjective. And I mean, I find a lot of satisfaction", "tokens": [663, 311, 257, 665, 1168, 13, 286, 2041, 309, 311, 8344, 25972, 13, 400, 286, 914, 11, 286, 915, 257, 688, 295, 18715], "temperature": 0.0, "avg_logprob": -0.3963804244995117, "compression_ratio": 1.4947916666666667, "no_speech_prob": 7.483254739781842e-05}, {"id": 71, "seek": 40380, "start": 403.8, "end": 408.6, "text": " when I'm able to help people and kind of getting positive feedback around that.", "tokens": [562, 286, 478, 1075, 281, 854, 561, 293, 733, 295, 1242, 3353, 5824, 926, 300, 13], "temperature": 0.0, "avg_logprob": -0.15362400327410017, "compression_ratio": 1.7738853503184713, "no_speech_prob": 8.7477128545288e-05}, {"id": 72, "seek": 40380, "start": 408.6, "end": 413.8, "text": " Something Jeremy and I were talking about earlier is that I think I've also had to recognize things", "tokens": [6595, 17809, 293, 286, 645, 1417, 466, 3071, 307, 300, 286, 519, 286, 600, 611, 632, 281, 5521, 721], "temperature": 0.0, "avg_logprob": -0.15362400327410017, "compression_ratio": 1.7738853503184713, "no_speech_prob": 8.7477128545288e-05}, {"id": 73, "seek": 40380, "start": 413.8, "end": 417.6, "text": " that I'm going to do less of to have more time for the high priority stuff.", "tokens": [300, 286, 478, 516, 281, 360, 1570, 295, 281, 362, 544, 565, 337, 264, 1090, 9365, 1507, 13], "temperature": 0.0, "avg_logprob": -0.15362400327410017, "compression_ratio": 1.7738853503184713, "no_speech_prob": 8.7477128545288e-05}, {"id": 74, "seek": 40380, "start": 417.6, "end": 423.2, "text": " And so I'm right now putting a lot of time into preparing for the course I'm going to teach in May.", "tokens": [400, 370, 286, 478, 558, 586, 3372, 257, 688, 295, 565, 666, 10075, 337, 264, 1164, 286, 478, 516, 281, 2924, 294, 1891, 13], "temperature": 0.0, "avg_logprob": -0.15362400327410017, "compression_ratio": 1.7738853503184713, "no_speech_prob": 8.7477128545288e-05}, {"id": 75, "seek": 40380, "start": 423.2, "end": 428.40000000000003, "text": " That's really important to me. But I had to kind of choose, like, okay, I need to go to less conferences", "tokens": [663, 311, 534, 1021, 281, 385, 13, 583, 286, 632, 281, 733, 295, 2826, 11, 411, 11, 1392, 11, 286, 643, 281, 352, 281, 1570, 22032], "temperature": 0.0, "avg_logprob": -0.15362400327410017, "compression_ratio": 1.7738853503184713, "no_speech_prob": 8.7477128545288e-05}, {"id": 76, "seek": 40380, "start": 428.40000000000003, "end": 432.8, "text": " and go to fewer meetups and kind of decide these are the things I'm going to put less time into.", "tokens": [293, 352, 281, 13366, 1677, 7528, 293, 733, 295, 4536, 613, 366, 264, 721, 286, 478, 516, 281, 829, 1570, 565, 666, 13], "temperature": 0.0, "avg_logprob": -0.15362400327410017, "compression_ratio": 1.7738853503184713, "no_speech_prob": 8.7477128545288e-05}, {"id": 77, "seek": 43280, "start": 432.8, "end": 436.8, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50564], "temperature": 0.0, "avg_logprob": -0.31314388910929364, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.00034433440305292606}], "language": "en"}