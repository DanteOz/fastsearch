{"text": " Beginning of our end of last class I introduced just kind of the start of the start of lesson four on compressed sensing of CT scans and I just wanted we talked about a few really useful concepts at the beginning and I wanted to review those and so one of those was broadcasting and numpy and that's how numpy deals with arrays of different shapes and kind of the rules for whether or not you can do arithmetic on them. Can anyone remind us what the kind of two rules for for broadcasting are in numpy? Connor? It's like you line up the dimensions of your matrices and they have like the same for like a particular dimension if they have the same the same number you can broadcast them or if one of them is one. Yes exactly and then for lining them up do you start at the kind of beginning or end? What? Jeremy throw it back. Yes exactly yeah thank you. Yeah those are those are the rules for broadcasting. Start with the trailing dimensions which is the far right hand side and then two dimensions are compatible if they're either equal or one of them is one. And so then I wrote a few problems as review so suppose we have actually is the font large enough on this? Is that better? Let me okay so we've got V which is three so three just a tuple M is three by three and A is two by three by three and so kind of before we actually run these which of the following operations will work and which won't? So take a moment to think about these and then you can do like a thumbs up thumbs down maybe. Does anyone want more time? Okay so for the first one A plus B thumbs up if you think that'll work thumbs down if you think that it won't work. Thanks for everyone that's participating. Yeah I see I see mostly thumbs up and that's that's correct that works so and yeah V may be a little bit confusing since it's kind of just got this single dimension showing up but yeah that works the the threes line up and then you've got the two and three before and so what's happening with that is that actually might be helpful to put A here so you can see one has been added kind of to this whole first column along both the both matrices if you think of this as being like an array of two matrices and then we've got two was added along this whole second column and three was added here. Let's go on to the next one how about A plus M and I should leave the dimensions up so you can see thumbs up if you think A plus M will work thumbs down if not excellent so yeah saw all thumbs up and that works because the three by three lines up with the three by three at the end of two by three by three so we can do that and their matrix M is kind of being added to you know this first matrix in A and to the second matrix in A and how about A dot transpose or A transpose plus M thumbs up or thumbs down great yeah I see a lot of thumbs down and this is nice we get the air operands could not be broadcast together with shapes 3 3 2 and 3 3 now you understand what that air means if you get it any questions about broadcasting Kelsey so that and actually it's helpful for me to to show it and so that's reversing though let me also put let me change this to a so you can have kind of like the visualization so here we're taking 5 10 15 so basically we end up taking kind of the the first column of this matrix and the first column of this one and putting those together to get this new first matrix and then kind of second column here 10 20 30 and negative 2 negative 4 negative 6 and putting those together and then 15 30 45 negative 3 negative 6 negative 9 and putting those together let me do this again I think it'll be clearer since we've got three showing up as a dimension twice let me do something with them completely different dimensions oh so you're I think you're reversing the order of the dimensions yeah okay but now I've got a 2 3 4 so I think this will be kind of a nice example so when we reverse the completely reverse the order of dimensions it becomes 4 3 2 and then this is what a transpose looks like yeah and I definitely also recommend kind of looking at small test cases of these because I think often it's helpful to to kind of visualize how they're changing yeah good question any other questions about broadcasting okay so next up we talked about how sci-fi stores sparse matrices and that there were a few different matrix storage formats and let's see can anyone describe how how coordinate wise storage works Matthew exactly yeah so you're keeping track of the index for the row the index for the column and the value that you want there great and what's a what's an advantage of this this approach actually advantage or disadvantage so we have to allocate less memory or storage so less memory than a dense matrix yes yes and this advantage because we cannot access the element by index that fast right so it's harder to get an entire row or an entire column exactly yes yes if you wanted to find everything in a particular row you would have to go through your array of row indices and pick out those kind of corresponding values all right and so then um kind of this was an example we saw last time of and they've used this nice color coding to show like 75 is in row 6 column 4 over here they have value 75 row 6 column 4 and that's how it's being stored next step is that oh and then this is also kind of illustrating for things like matrix multiplication you can just you know look up what you have in your value array you're not having to go through all the spaces where you have zeros all right so compressed sparse row data structure can anyone describe what's going on with that picture Sam so to save space the row indices are not repeated it just says which of the end observations is the first that has that row exactly yes so this uses even less space than the coordinate sparse storage because it just keeps track of a row pointer which is Sam said it's just kind of telling you the first place that or the first value that that's on that row so for row one the third value is the first to show up there which is 22 and so we see that's the first value on row one and for let's see what else they color-coded and row three the ninth value is the first there and so you can see the ninth values 42 and that's the first thing on row three so what's a what are some benefits and or pros and cons of this approach Valentine I think when they are trying to look for non-zero elements of that matrix you don't have to go through all the non-zero elements you can just keep row by row until you get to the road which you need so if you're looking up a particular row yes it's very quick to do that yeah fast lookup by Rose and then can you think of a disadvantage by but by columns it will be just the same complexity of big or of and in the worst case yeah so column lookup is painful or yeah more painful because you're kind of having to go backwards to calculate thank you wait throw the microphone it's for the bit it's for the it's for the video so the row pointer great question is telling you so there the index is telling you kind of where that row starts so row zero the first one is in value zero so the how index is being used is different for value and row pointer and actually it's probably easier to look at so the first the first three values are in row zero so you really just need to store a zero and then this three lets you know okay now we've moved on to row one and the kind of starting with index zero the third value 22 so if you go over here the third value is 22 that's the first thing in row one and then we've got a three values here and then value six is the first thing in row two so down here we store six for the row pointer so it's that saying row two starts with value six which is 31 so the for the row pointer yeah the index is telling you the row number and it's telling you that though in terms of what the index for the value is Tim's got his hand up about this is like the values are stored in memory in like in 21 entries and the real point is telling the address of where the row starts yeah that's a great way of putting it like you can kind of think about like you've turned you've turned this matrix into an array of values 11 12 14 22 23 25 31 and you what yeah you want to keep track of where you're switching from one row to another and so you're just kind of keeping track of okay we switch or you know we started a row here at 11 then another row started at 22 another row started at 31 another row started at 42 and so we just need a pointer to those spots where a new row is starting actually okay let me go to you will like this table better Terrence so this table okay you're welcome any other questions about compressed storage or sparse arrays and so we didn't go into detail on the compressed column storage but it's the exact same idea is compressed row only you're keeping track of column pointers and it's fast to look up a particular column and but in that case it's slow to look up a row Kelsey that's a good question I would have to look that up let me write that down something also to remember is that converting between these types is linear time so I think generally they kind of recommend converting if you're going to yeah be looking up a lot of rows or looking up a lot of columns but I'll tell you the exact times next time any other questions I have this question so like once we know that we have sparse matrix and we try to decide which format to use so like can we just look up for every format like this format is better for matrix multiplication this form is better for like trying to get the inverse this form is better for like to get in the transpose matrix omega this form is better for multiplying matrix by columns or stuff like that yes you can just trade off yes so yeah different operations and I don't know if it um I think some of the things you listed will probably be equally good in both but yeah it's it's very dependent on what algorithm you're using and so particularly like looking at your code as well of if kind of if you're accessing things by row or by column in a loop that should be a factor and I've copied a little bit of yeah so here like the sci-pi documentation says that for multiplication or inversion it recommends either CSC or CSR so I think that those are probably equally good but yeah if you're doing something else where you are you know looping through your rows or looping through your columns you'd want to think about that you're welcome good question and then it also says COO I think is a good format for constructing your matrices since you don't want to have to be calculating the row or column pointers yourself typically and it's it's efficient to convert then so kind of use COO to make your pass your matrix into to sci-pi okay yeah so we'll be using be using both broadcasting and sparse storage today and going back to this problem of CT scans and so I showed last time in this article that I think is very nicely written and that's it starts with can math really save your life of course it can and then talking about kind of how CT scans work I want to try introducing this in a different way today so if you are actually kind of a working on CT scan data what would happen is you would be receiving some data that might like look like this on the left-hand side and you're trying to reconstruct this full picture and the idea and so this is in real life this is usually 3d we're just going to be looking at a 2d picture and here the dimensions of this this is L width for both of them but then this is just a seventh as tall what you started with and the idea is you know it seems seems clear if you did a ton of x-rays of someone you know from every angle and got all this data that you'd be able to reconstruct the original but you want to limit how much radiation people are experiencing and so the idea is that we're kind of getting you know like much much smaller amount of data and want to reconstruct this picture that includes a larger amount of data so it's kind of like the opposite of data compression and that you're kind of starting with the smaller amount of data and need to uncompress it to get the full picture and then it's also you're having to find kind of the meaning of yeah kind of what these measurements so these would be the measurements from different x-rays shot at different angles and different locations and then getting back to okay what would that mean for the the picture there questions about kind of the setup and and so this problem since we're using we're gonna use data that we generate for the problem like we're gonna be building this picture it's different from a kind of real CT scan and that we first will have to make our data then get what the measurements would be and then we're seeing if we can reconstruct the original just from these measurements yeah and so I'm gonna show some some pictures but I kind of what it'll look like is that an x-ray shot at a particular angle and a particular location you're just gonna get a single number from that so you know here we have a line intersecting with our picture and that would result in just one number so kind of one pixel in this left-hand side of our measurements and then this is a kind of brief review so from the background removal lesson that was background removal using robust PCA was written as this optimization problem and do you remember what's special about the L1 norm? Shout it out. Yeah it shrinks things to zero resulting in a sparse solution right so it induces sparsity because yeah it's kind of pushing pushing many of the coefficients to zero and so you'll notice this this picture that we'll be trying to construct is sparse so we'll be using the L1 norm today. Okay so the first part of this is just generating the data and I think this uses some interesting numpy methods that some of them I hadn't even seen before so I think it's an interesting process again if you were really working with CT scans you're not building your own fake data set and so here we're choosing 128 for the dimension so this is 128 by 128 and I'm gonna kind of walk through what this code is doing oops so this is the whole the whole method for generating synthetic data this will return kind of one square like this but we'll walk through that more slowly and to walk through it I'm gonna go through kind of a smaller example of just creating an 8 by 8 picture that has five points and we'll see what the points mean in a moment. But that'll give you kind of the the density of the data set of those white circles. So there's a numpy a numpy method called oGrid that returns returns something as a column and as a row and so here we're getting the numbers 0 to 7 as a column and as a row back and then this is that this is actually going to be very handy in a moment we're gonna use broadcasting with this so we want to end up getting something that's 7 by 7 or sorry 8 by 8 so we're kind of getting this row and column and we can do some operations and together with broadcasting that's gonna go from you know having something that is 8 by 1 and 1 by 8 to something that's 8 by 8 that's kind of a handy handy trick and so this is basically kind of like the equation for a circle we're saying X minus a center point squared plus Y minus a center point squared and we get and then kind of combining that with broadcasting so the X part of the equation is still just going to be you know this 8 by 1 column the Y part is this 1 by 8 row and when we add those together we get an 8 by 8 grid and this kind of has a density of being zero at the center and then getting larger as you go further away since we're using the circular equation. Are there questions about this? Jeremy? Oh yes that's a great idea. And here since zero is the first entry of both you can kind of see the original X in the first column and the original Y here. Okay so now we're constructing something called mask outer and basically that's because we're just going to be kind of interested in this center and the kind of the center of our picture and I think this is kind of fitting with the idea of you know if you thought about doing a CT scan of someone's you know someone's torso that you're kind of getting this like circular cross-section is what we're getting here so we're just adding an inequality so kind of taking you know our XY grid and then seeing when it's less than this radius squared that gives us this outer mask which is kind of a you know a ball of trues surrounded with false at the border. And this is also important I should say I guess because the the X-ray will be coming at different angles like this kind of ensures that it's going through the same amount of you know person being X-rayed kind of from each angle the X-rays traveling a similar distance. So we take that mask oh no so that's our outer mask and then we're constructing something called mask where we just randomly generate some points in a 2d grid and so that was a parameter earlier kind of how many points we wanted to generate in this case it's five so we've still got something eight by eight and it's all zeros with five ones. And we can plot what that looks like so here we're just plotting kind of each each point is a pixel zero or one and we have five five white boxes. We'll use a Gaussian filter then to kind of blur that so that's kind of going around these places but making it a bit more kind of continuous. And this is I mean some of this is you know this is specific to kind of like we're trying to get these like globby looking shapes in our in our data. Here we combine seeing when so now we've kind of gotten this Gaussian filter version we're just going to take the parts of that that are greater than the mean for it and then also when when those points lie inside that inner circle and so that's what this is. And then actually I should um maybe pull up ND image well I'll come back to that in a moment. We're kind of using this additional library here is where we get this binary erosion feature from and this is just picking out the middle so kind of this was our whole thing we want to separate that into what was the middle and what was the exterior. And so this is how we make yeah kind of make those globs that you saw and this is a more pixelated version since it's just eight by eight whereas our original was much larger but this actually let me scroll back up so it kind of this circular or not circular globby shape here that's how we would get kind of the globby shapes here. Jeremy? Oh yes yeah the carrot sign is XOR which is exclusive or actually first let me just see where ND image okay so that is a SciPy library I'll go back to that. Yeah so Jeremy pointed out the the binary erosion gives us the inside really what we want is what's left over and so we're taking an exclusive or with kind of between this picture the result that's everything exclusive or with this interior just leaves us with the exterior. And then I just wanted to pull up because I think this is an interesting library we're just using a little bit of functionality from it but SciPy has an ND image for multi-dimensional image processing kind of as a library so if you're interested in it I think that would be something to check out with yeah with different types of filters. Are there questions kind of so far what we're doing to create these globs? I think this is more like putting a Gaussian centered at each point and kind of looking at what shape that creates. Yeah so we have like the five pixels that we've made white and we kind of like are putting Gaussians centered at each of those and looking at the distribution that creates. Let me pull up the documentation though. Oh there it goes. Yeah I guess it is like Jeremy saying that he thinks it's like a convolution. Yeah I think that's accurate. Oh like what this looks like in in 1D would or in I guess kind of in 1D would be like taking the points you have and if you put like a Gaussian around each of those and then you're kind of looking at a looking at the method that covers all of these you kind of hear about this in kernel methods sometimes kind of like looking at where your data is and then kind of using Gaussians to construct a distribution kind of based around that data. Yeah good question. Any other questions? Matthew? On the Gaussian? Yeah. So what that's doing, yes I think Jeremy pointing out it's a convolution is helpful. It's kind of like blurring the points around wherever we had these white pixels so we were kind of starting with this picture and so you could think of that as kind of doing this averaging method to kind of even out the squares around this and so that's why we kind of have it very white in the corner but you know if we take a point here and get the average of the stuff around it you know that's gonna be gray whereas a point here an average of everything around it's still gonna be black and that's a way that kind of like smooths it out. Hi you're welcome. Okay and we can always come back to this later too. So this is yeah so that's kind of just to getting that that kind of picture with the globs that in the end it's gonna be what we're trying to recreate. The next step is to generate the projections and so this will be the kind of the single value that we get from shooting an X-ray at a particular angle through our picture. So again I'm gonna walk through this and this is something where you don't have to understand every line of the code. The more I want you to kind of get the idea of like what the steps are. I should also just while it's on the screen want to highlight and here we're using sparse.coo matrix in this line for our operator. Yeah so here we're kind of feeding in what the dimensions we want it to be and we have L as well as L divided by 7 and again the idea is that we're using less radiation than kind of you know taking it at every single angle in every single location. And so this creates we'll kind of come back to what this what this matrix looks like but we've got a sparse matrix in coordinate format and then there is a dense method which converts sparse matrices to dense and is very useful and that'll be helpful when we're wanting to plot what we're doing. We need to have it dense for for creating these images. But the idea is that the so the first the first dimension is going to tell you the angle and we only have L L over 7 angles and then we have L positions so that's kind of every single pixel height and then each image is L by L. So we're going to be getting something that's L over 7 by L by L by L. So just to kind of get a feel for this matrix the this is an angle indexed with three and we're kind of have it starting from zero or just kind of position zero and then you'll notice the positions moving and basically getting lower each time. So then this is position one which is really from this distance almost looks identical but the line is slightly lower than the previous picture. I can go on two and it becomes more obvious if you say go to position 40. So now we can see that okay we've definitely been lowering this angle kind of keeping same angle in this case the angle with index three and going to a different position so now we're low at kind of down to 40 and then we can look at other other angles at vertical location 40. So now I'm changing the first coordinate to be a 5 and this is a different angle. Actually let me kind of show like if you did 4 comma 40 that's giving you something in between angles 3 and angle 5. And so what we have is a kind of a matrix that's keeping track of all these different angles and locations. Here we can see this is a completely different angle the one indexed with number 15 and at location 40 still this is angle index with 17 at location 40. So we're kind of getting all these different angles at every possible location. Where here the location basically corresponds to the height within the picture. Questions questions about this? This is a little bit tricky because projection T is it's a matrix in four dimensions which can be hard to think about. So here we're kind of just looking at these two-dimensional pictures from it by indexing the first and second dimensions and then we're seeing everything that's in the third and fourth dimension. Matthew? So the projection and we'll kind of get to that in a moment the projection is going to talk about how we're projecting into one dimension which is weird to think about but it's going to be kind of taking this you know this just line at a certain place together with our whole image and just getting a single number from that. Yes, so oh and so that's that's representing what the CT scan gets because the CT scan you know you've got this well the cross-section you know two-dimensional cross-section of a person and you're sending an x-ray at a particular angle and even though those could be represented as you know like a 2d picture of the x-ray and a 2d picture of the cross-section of the person you just get a single number from that which is like the reading that the you know the CT scan or MRI machine is picking up. So kind of getting that down to a single number. Yeah so typically so projections are kind of take something you know that goes from a higher dimension to a lower dimension and I think this is somewhat unusual because I feel like people often don't talk about projections into 1d. Any other questions? Okay so yeah now I'm just kind of showing kind of you can transpose you know x-ray kind of going through these points we're just going to get a single single number from that. Oh here I've also showed just how much intersection there is. The idea here is that the x-ray kind of going through different materials of different densities that's going to affect the reading at the end so it's got a sense of kind of what what yeah kind of like the density of what it's passed through based on kind of what the measurement is. And so here I wanted to illustrate that and so we get this from so here proj stores the projection this is at the very beginning when I showed that little L by 7 L over 7 by L matrix. This is that the readings and so here where there was a lot of intersection like this this x-ray was having to pass through a lot of the a lot of the glob globules and we get a kind of larger number 6.4 and then here you know we have a line kind of going off off through this side part it's not really passing through much and we'll get a lower number. Yeah just 2.1 so this is kind of how we're capturing information of how much the line has passed through. And then we're also adding we add some noise to that so kind of assuming that this would would involve some noise in our measurements and then this is this is what we're referring to is kind of the projection this this matrix but that's just all the measurements so it's a bunch of 1D projections coming from these lines at different angles. Tim? That's a good question so star in in a Python is used to unpack unpack list so there's something called star args and star star and actually let me pull this up because this is a really useful Python concept but it's useful when you want to be able to pass yeah like a list or dictionary of argument so the dictionary use two stars. No that's in Python too as well yeah. Let me see. Yeah and this this can be useful if you kind of like have a bunch of parameters and don't know how many you'll have. I actually find this really weird and annoying because like some things in like parts of Python, parts of NumPy they expect a shape as a tuple and sometimes they expect the dimensions as arguments so in this case the thing that virtual is using is arguments so you have to put the star there. Okay so that's true about this issue with shape but I do want to say star args shows up other places that can be useful. Yeah actually let me show an application I really like of star. Okay yeah I'm gonna be careful about that. And are you all familiar with zip? Zip yes. Wait that's not. Oh I didn't know that put list at the front like okay so what zip does is you can pass it to list or tuples and it'll of the same length and it will go through and kind of pair them together so here we're picking off you know one and four two and five three and six but something that's kind of fun is that I'll call this C. You can undo zip then by using zip again together with star. So in this case we wanted to pass to zip three things one four two five three six and we can do that by unpacking this list into kind of the the three tuples using star so that's the way that lets you get your your original two back. Okay other questions about this figure and that was yeah great question about star args. Matthew? So you have the value that you're getting back you're reading their highlight in the matrix? Say that again the map the values that you're reading. Yes yes yeah. And then what are the X and Y axes? For this matrix the great question the X axes are the different angles and then the Y axes corresponds to the different kind of vertical position so when we showed how like you know there's a line here and then lower yeah that's what the the Y axis is corresponding to here. You're welcome. Alright so now that so here the hard part was creating this data set and it's actually going to be pretty quick to get back to our answer. We're going to use use regression to try to recover the data. We'll start out with the L2 penalization this is called a ridge regression and so here we're just using scikit-learns linear model ridge, fitting it to our projection operator projection and this is this is what we get which is not not very good. So this was using least squares error. Now if we use L1 error which is called a lasso regression this is what we get which is really close to our original picture. So this is a case where we had you know very kind of like perfectly sparse data set and so L2 regression did really poorly and L1 regression did a lot better. There are questions about this. Tim? Oh okay Tim and then Terrence can go next. Okay okay let me think about that one. Let's hear Terrence's question. Is the intensity of each pixel here sort of the sum of polynomials derived from the coefficients we got in that long sprague? In other words we interpolate between polynomials. We add polynomials together where each polynomial comes from an angle and a height. Where are you getting polynomials from? I use polynomial but it could be a line. We're basically adding what we see. Each pixel is the summation of what is visible from a bunch of different angles. Yes. Yeah that's a good way of putting it. Yeah so yeah each pixel is going to be a sum of what was seen from a bunch of different angles. Basically what Tim's question was that he just answered. Okay Jeremy's voting for a break. Yeah well let me say one more thing but then yeah then we'll take a break and come back to this. Yeah actually yeah let's take a break and we will discuss this in more detail. So let's be back in seven minutes so that would be 12.05. Did I start back up? Yeah so let's talk about what's going on with this regression. So just kind of to restate the problem. So when you have a CT scan and you get the kind of like the picture that looks like the insides. Actually there's one up here. You know it looks like a picture of organs or tumors. That's not actually what the CT scan is producing directly but rather you know it's taking these measurements and then you know this field of compressed sensing is around how do you get from those measurements back to or not back to but you know create a reconstruction of what the kind of the person's organs look like. So here so Tim asked a great question about what's what's going on with this regression. So we have we have something called the projection operator and that's basically kind of like if you think of linear regression being AX equals B and you're trying to find X. In that case so the projection operator is A. The original picture which is this is like our X and then B is the measurements we got. And then we go back up here this and it's it's hard to think about the projection operator because it's a four dimensional matrix or four dimensional tensor. And so that's what we're trying to kind of get at up here. So let's go up to it. With all these plots of proj T. So this is just basically kind of like a part of A. So A is this four dimensional matrix and we can look at slices of it but A represents the lines coming from different angles at different locations. So it's like all all the angles and locations that the CT scans taking and it like what those look like in 2D. So let me also. Actually I think I can show that down here. So this is the projection operator dot shape. Oh and that is also it's been distorted. So this kind of was the four dimensional thing we reshaped it so it was easier to look at. So we're having 128 over seven which is 18 something that was 18 by 128 by 128 by 128 and we've reshaped it here just to make it two dimensional. But the idea was four dimensional that we kind of had angles by vertical location of where the X ray was shooting. And by X coordinate by Y coordinate of the cross section. So that's our matrix A. And then X which we're trying to solve is this 128 by 128 image. And so we're kind of thinking about like OK we put all these X rays from different angles are kind of effectively being multiplied by this image and then we get out you know the smaller matrix of measurements. So backwards OK we've got the smaller matrix of measurements. We've got all the X ray angles. How can we get the picture of what what those X rays were passing through. Are there more questions about this. And I should say that. Here. So with the CT scan it kind of makes more sense to think about OK what is what is this X ray passing through. What we're doing though with the fact that it's multiplying is just kind of taking advantage of the fact that we have a lot of zeros and ones and basically every place where either the person's organ is zero you know we've got a black spot or where the X ray is not passing those are all zero. And so those will zero out. And so the only thing that gets picked up is where both of them are non zero. And those are the intersections. So you can kind of see this is a different one where they're intersecting. So if we were kind of multiplying the picture of the organs times the picture of the X ray that's just going to pick up the intersections because everything else zeros out and gives us kind of a measurement of how many and how many locations were both of those non zero. I have a question. So I'm using down here. Proj dot ravel does anyone know what ravel does. Is that a hand Sam. Just makes it a one dimensional. Exactly. Yes. Yeah, and I actually feel like unravel would make more sense but it's yeah kind of flattening it into a one dimensional ray and that's handy here because we're basically converting what would be a four dimensional matrix times a two dimensional matrix equals a two dimensional matrix is kind of how I think the problem makes sense of thinking with like the CT scans but we've converted that into a just typical matrix by a vector equals a vector. And so that's why we're having to unravel these readings just to be a you know one dimensional array. A lot of people look very puzzled so I'd love to get more questions Sam. Yes. Yeah. So the four dimensions and we go back up. The four dimensions are coming from our projection operator. And so those are the angle that it's at and we have a total of L over seven angles which in this case is 18 angles. Is 18 in this case. Yes, we've got 18 distinct angles L positions and that return. So this is an L by L matrix. And that's just kind of each vertical possible height is the position. And then the image for each is L by L. And so what we're displaying here is we're kind of indexing on those first two we're picking an angle on a position and then showing the image. And so this is our way of trying to look at little pieces of this four dimensional array is we're just kind of you know indexing on the first two and then viewing a 2D picture. So I guess I'm confused. So really we're multiplying the last two dimensions by. We're multiplying the line in the last two dimensions by X. And that's giving us a single value that's like how much it's intersecting. Yes. Exactly. So that again have three dimensions with the. Yes. Yeah. Yes, that makes sense. Yeah. Yeah. So another Yeah, that's a great way of thinking about it. Another like what's happening here with the dimensions is we're actually kind of reshaping this four dimensional thing. Go down to where I have it. So the projection operator. Kind of was just write it 128 by. Oh no, this one's 18 18 by 128 by 128 by 128. But 18 times 128 is 2304 and 128 by 128 is 16,384. And so what's that? What this is doing is you can kind of think of, you know, we've turned our picture with the cellular globs or organs or however we want to think about those. That was two dimensional. We've kind of unraveled that into like a single vector. And then we're going to multiply that two thousand and three hundred two thousand three hundred four times. Basically, like that's getting multiplied with this X ray for we have two thousand three hundred four different X rays. You could think of it since we wanted to take an X ray reading from 18 different angles at 128 positions for each angle. So that might be helpful to kind of think of. You have twenty three hundred kind of separate. Yeah. Separate readings. So how does that relate to the previous picture? The one that's kind of wide and short? The this one. Yeah. So this one is actually let me write it out. This is 18 by 128. We have unraveled this into just one thing that's two thousand three hundred and four long. So kind of for each of those two thousand three hundred and four multiplications we're doing, we're getting back one pixel here. Or one spot in this matrix. So this this is the result of doing two thousand three hundred and four. Multiplications. Yes. Yeah. So this is what the CT scanner is actually measuring. But then it knows the angles and locations that it's shot the X ray to get each of these points. Yes. Yes. Good questions. Are there questions about this? Matthew. And then which part of that are we? So this is B in the regression. You can think of this as like the column on the right hand side and then A is. I'm going to hold some of these up. A is the collection of all these matrices. But it's into a two matrix. Projection is still to. Yes. Yeah. Yeah. Yeah. So it's like I think it. The time we do the regression and just to be. Yes. Yeah. Yeah. Yeah. I guess actually. Yeah. So here we've just reshaped it as 40 to get the kind of meaning for the different points. And in its 2D form, this picture would be like a single row. So we've kind of taken this whole picture and made this. This is one row. This picture is another row and so on because we've just kind of like unraveled that picture. And so each row is a single angle and single location. But then all the X, Y coordinates for that angle. Well, there are 18 angles, but there are 128 locations. Yeah. So there are 2000 rows. All right. So, yeah. So these I should say these pictures here, these are all part of the matrix. A the picture at the bottom. That's the vector B. To it. So this is this is the vector B when it's unraveled. So you think of that as like a row of each row that is the image or no, it's more like each each each single location in this, like each pixel here is a reading from one of those like entire pictures above. So kind of taking the angle to a particular location that just gives you a single value. So that would just be one entry here. You're welcome. Oh, Matthew. Let me think about that. What would be the kind of the background you're trying to remove? Yeah, I mean, the tough thing is you don't actually have like you don't have the picture of the line going through the through the globs. It's you just have like a single number for each of those. Yeah. Yeah. So that's kind of a yeah, like the point you're trying to get to is the picture of the globs. Yeah. Any other questions? All right. We'll probably review this at the beginning of next class. Definitely continue to think about it. Email me if you think of kind of other other questions because it is. All right. So let's start on close these. Oh, wait. Another question. Yes. Yeah. So this kind of human 18 angles is enough to get a really great reconstruction. Yeah. Whereas kind of like a naive guess might be like, oh, maybe I need 128 angles in order to, you know, be capturing data of the same dimensionality of what I'm trying to recreate. Yeah. And there's a there's an entire field that kind of focuses on this called compressed sensing or compressive sensing. This is a topic David you've been skiing. It was a lot about. All right. So the next next lesson continuing with the theme of linear regression will be looking we'll be using polynomial features. But so different linear regression problem. We're going to use a data set from patients with diabetes. This is kind of a classic data set from a famous paper and it's included in scikit learn, which is nice. I think I mentioned in an earlier lesson, but let me pull this up again. That scikit learn has a number of data sets that that come with it, both kind of where the data is already kind of present with scikit learn or where they give you data kind of loading utilities that you can pull extra data in. So I think that's a nice, nice feature. So we'll be using this data diabetes data set. So we just call low diabetes to get the data and then we know what the feature names are just from looking at the documentation. And so this data is going to have age, sex, BMI, blood pressure, and then various blood serum levels. We're going to use a train test split, which is kind of scikit learn gives you one there and in here, you're probably familiar actually ask you, can someone explain why splitting into a training and test set is important in machine learning? Kelsey. Exactly. You don't want to overfit to your particular particular data set. You're trying to come up with a model that will be general enough to handle new data. And so you want to hold out some of your data as a test set and not not look at it until the end. So we're going to hold out 20% of our data for the test set and that'll allow us to evaluate how well our model does on new data. So the problem of linear regression is AX equals B and typically A has more rows than columns. So this would be when you have more data samples than variables. And yeah, we're trying to find an X that minimizes the L2 air, which is the sum of the squares of AX minus B. And so this is kind of assuming that our data that there's this linear relationship between the things we're measuring and what we're trying to predict. And so in this case, that would be a linear relationship between age, sex, BMI, different blood serum levels and the kind of long term health outcome of the patient. So we can use and we're using linear model from scikit learn has has linear regression for us. So we kind of create create a regression, fit it to our training set with the Y training data and then make a prediction on the test set. And then here written just a little helper method regression metrics that returns the mean squared air as well as the mean absolute air, kind of between the actual data and between the prediction. And so we run that and we get seventy five for the mean squared air and sixty for mean absolute air. Your questions kind of on the setup or on this is kind of a kind of a basic linear regression so far. All right. So now we want to we want to try to improve this. One way we can do that is by adding more features. And so we're going to try adding polynomial features. And the idea here is that instead of just having it, you know, our outcome depend linearly on these variables. We can also look at things like age squared or age time sex, age times BMI. And so those are the interactions between the different terms. And this is kind of letting us look for a more complex relationships. And so we're just kind of going up to the squared version. So that gets how each term interacts with each other term as well as their squared versions. And so now and actually I should have. I put the dimensions before we start this. So we were starting with three hundred and fifty three rows. So that's probably three hundred fifty three different patients and 10 variables. If we add these polynomial features, now we've got sixty five different variables that we're looking at. And so do a linear regression again. And we've just added. We kind of created these training features and now using those to fit our regression. And that improves our error. So we before I think had seventy five and sixty. Now we've got fifty five and forty two. Unfortunately, time is squared in the number of features. And so this is this is going to slow us down a lot. And we can look. Let's go back up here. Here's the time. So before it was five hundred and thirty five microseconds. And I think we've seen this before, but using percent time it in a Jupyter notebook runs. So here this is doing seven runs, a thousand loops each kind of runs at multiple times and then gives you this average of how long it takes. So it's a really useful way to compare compare the times of things. So that was five hundred and thirty five microseconds. So now we're up to six hundred and thirty five microseconds. So it's not that much worse in this case, but it's something that's going to on larger data sets be an issue. Or was there also a plus minus. Oh, yes, I'm sorry. So, yeah, the one above was to do the linear regression. This is just to pull. OK, so this is just to create the features. Sorry to create these polynomial features. Sorry about that. And so that's you're having to take all the data points and multiply them together. You know, all possible pairs and doing that calculation just to even create this set of polynomial data is taking even longer than it took just for us to do the linear regression. So we're still going to have to do a linear regression on this this new data set. So this is this is kind of a time concern. So it's something that has improved improved our air, but it's going to slow us down. So we're going to look at a way to speed up the future generation. First, I should stop. Are there any questions on how the polynomial features allow us to kind of create a better model than the plain linear linear regression? But then they take longer to calculate. OK, so we're going to use Numba today, which is a Python library that compiles directly to C. Jake Vander Plaas has some nice tutorials on them. And I like in this tutorial, he says that a lot of people ask him, isn't Python pretty slow? And he's kind of got an answer of why he likes and Jacob Vander Plaas, I should say, has a PhD in astrophysics and works at the University of Washington, has like a center for data science. And he he's a contributor to a lot of Python scientific packages and does a lot of speaking. And also, I think helps run like University of Washington's kind of like their data science institute. They have like data data science for social good, summer programs and things. But he goes through kind of reasons why he likes having a Python implementation as opposed to just doing the whole thing in Fortran or C. And it's you know, Python code is easier to read, understand and contribute to. Pure Python packages are easier to install than Python wrapped C or Fortran code. It's easy to use its scale. So I think these are kind of some good good arguments for why you would want to maybe compile some of your Python code to C as opposed to just switching to C or Fortran completely. And numbers one way one way to do that. So from here from Numba, we're importing a number number of methods and decorators and types that I'll talk about as we use them. So we're going to step back from the problem of this linear regression or polynomial feature generation and just talk about what number is and how to use it and kind of go through a sample problem. So Numba is going to allow us to kind of avoid memory allocations and copies and give us better locality. So we're going to start with kind of this toy example. So this is something just in plain Python and NumPy where we have some number of observations that we're looping through. We've got two different arrays X and Y and we kind of want to take each each value and X and Y. Do some computations on them and then store them in a raise Z. So this is just a process in Python. Notice since we're using NumPy we can give ZZ a type. This is our I'll ask you do do X and Y have types here. And actually this is confusing because I named these variables X and Y do X and Y inside inside this inner loop have types. So anyone want to make a guess. So so now I'm suggesting float 32. So for our arrays X and Y that we're passing in we have float 32 and ditto for ZZ where we're going to put our result we have float 32. But here inside the loop we have these kind of just temporary variables X and Y we're using and those don't have specific types. So even though they're actually all we're always going to be putting float 32s in them. Python doesn't know that. And that's kind of one of the things that so Python is not a typed language but in language type languages like C or C plus plus you have to say you know what what type of variable it is when you declare it. And that you know lets and lets it know how much memory to set aside. And so it's kind of better for optimization. Although some people prefer that you know Python is flexible and you can give it different types and not have to declare it. So here we're timing this time to just kind of take in our two arrays go through each of them do all these operations and create an output. And that's taking 49 milliseconds. So this was a kind of the worst version. What would be a way before we even get to number a way to improve this. To speed it up. Oh wait Jeremy throw the microphone. Yes. Yes. Yeah. So this this for loop seems like a bad idea because it's like we're individually going through each each pair of elements in the arrays. We're doing the exact same thing. But NumPy lets us vectorize that. So we can here take out the for loop all together and kind of just do the operations on the entire matrices thanks to NumPy. And so if we compare this was 49 milliseconds. This is 35 microseconds. So notice that's a over a thousand times better. The units have changed from milliseconds to microseconds. So that's a big speed up. So that's really great that NumPy lets us vectorize. Does anyone remember the other kind of technical term or buzzword that we often say along with vectorize. It's actually an acronym. Yeah SIMD. So single instruction multiple data. So that's what NumPy is letting us do here because we are doing the same same instruction on all these different entries in X and Y. So now number has something called a just in time compiler decorator and in Python decorators are kind of these methods that are applied to functions to kind of alter how your function works that show up with an at sign above the above the method. So this is pretty simple. So we imported JIT from number above again JIT stands for just in time compiler and we just add add JIT on top here. Apply it to. So we've got our for loop back. So this is kind of where this is the code from the top original Python process. And what this does is so we're no longer vectorizing but we do have better better locality here. And now when we run it we're down to six microseconds. So the version with NumPy was almost 36 microseconds. So this is six times quicker. And then the one in plain Python with the for loop was really slow. That was like 50 50 milliseconds. Does anyone want to say what does it mean to have better better locality. Kind of learned about this with Brad. It means that the memory is stored on the device. Yes. Yeah. So it's what it's it's you're kind of you're accessing data that's close to each other in memory. Yeah. So it's often I mean you can talk about time locality or space locality but it's kind of using things that you access. Kind of like when you access or when you access something use it multiple times before you write it back to slow memory. So kind of like while you have it in fast memory like do all the operations you need with it as opposed to writing something you know or carrying something from slow memory to fast using it taking it back to slow. Bringing it to fast again using it again trying to consolidate all those uses and then yeah and using things next to each other. Great. Thank you. And so here it can seem kind of counterintuitive that we've put the for loop back in. But the idea is that we're kind of you know we're picking up X and Y which we need and then we do a bunch of operations with X and Y. And this is you know this is kind of a toy toy example but you could have a more complicated algorithm where you are you know using them multiple times. What would happen what would happen if we were doing this in NumPy without the for loop. So kind of this example up here has potentially has poor locality. Why is that? Sam. Yes. Yeah. So the issue with the NumPy array is if you want to do something on all of X maybe all of X doesn't fit in cache and so you're pulling in part of it you know doing the operation on that part then you have to pull in the next part of X do the operation on that part pull in another part of X do the operation on that part and then you go into the next line and you're like oh I need the first part of X again. And this is you know if X is a really long array. Thank you. Questions about this. These are kind of getting at the concepts we saw back in week one with the Halide video. Okay so let's go on to make this even a little bit better. Numba also has a vectorized decorator. So here we're using Numba instead of NumPy. So at this one we use the just in time compiler decorator and kept the for loop. So we're taking out the for loop. Just have the vectorized decorator. And it's actually like I mean it's almost equivalent to the using the just in time compiler which was 6.4 microseconds this is 5.8. But it's kind of good to know these two different options. Tim. So this is. This is still compiling to see so it's still optimizing what happens. So it's not doing like with NumPy where it's doing this like you know having to use all of X so it's you know might pull the first part of X into cache and then pull in the second part and then pull in the third part and then the next line it has to use X again so it starts again with the first part of X. Numba has optimized that away so it's not going to. Yeah do that sort of thing and the reason Numba is able to do this is because it's compiling to see. So Python like when it's running dynamically it doesn't know that I'm going to use X again in the next line and so this is kind of wasteful that I'm pulling each section into cache and then putting them back when I'm going to have to do that again. So it's kind of like one line from now whereas C is able to optimize things like that and so that's kind of what numbers getting you is this. Kind of big picture optimization. NumPy does you see yes that's true but that's kind of on an operation scale. Yes yeah yeah whereas here even though NumPy is using C on an operation scale you still kind of it doesn't have this knowledge between lines of like hey I'm using X in this line but I'm about to use X again in this very next line. Yeah. I'm just looking at time. I don't think it's a super quick question as well is could we wrap this in another decorator for just in time like could we also just in time to vectorize or that not work. I'm actually not sure about that. I think they recommend just using one but I'll I can look at that. What. Using. Thanks good questions. Okay yeah and actually I guess in the interest of time should probably stop here. So next time we'll be applying this to going back to our problem of wanting these polynomial features but wanting to be able to create them more quickly. I also wanted to remind you that Thursday homework to is due and so is the draft of your writing assignment. Tim. So, I mean the better shape your draft is in I think the better feedback you'll get which will make your final better, but it should be reasonably complete. Thanks.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.86, "text": " Beginning of our end of last class I introduced just kind of the start of", "tokens": [45705, 295, 527, 917, 295, 1036, 1508, 286, 7268, 445, 733, 295, 264, 722, 295], "temperature": 0.0, "avg_logprob": -0.23028102391202684, "compression_ratio": 1.664835164835165, "no_speech_prob": 0.003375647123903036}, {"id": 1, "seek": 0, "start": 12.06, "end": 18.6, "text": " the start of lesson four on compressed sensing of CT scans and I just wanted we", "tokens": [264, 722, 295, 6898, 1451, 322, 30353, 30654, 295, 19529, 35116, 293, 286, 445, 1415, 321], "temperature": 0.0, "avg_logprob": -0.23028102391202684, "compression_ratio": 1.664835164835165, "no_speech_prob": 0.003375647123903036}, {"id": 2, "seek": 0, "start": 18.6, "end": 22.740000000000002, "text": " talked about a few really useful concepts at the beginning and I wanted", "tokens": [2825, 466, 257, 1326, 534, 4420, 10392, 412, 264, 2863, 293, 286, 1415], "temperature": 0.0, "avg_logprob": -0.23028102391202684, "compression_ratio": 1.664835164835165, "no_speech_prob": 0.003375647123903036}, {"id": 3, "seek": 0, "start": 22.740000000000002, "end": 27.580000000000002, "text": " to review those and so one of those was broadcasting and numpy and that's how", "tokens": [281, 3131, 729, 293, 370, 472, 295, 729, 390, 30024, 293, 1031, 8200, 293, 300, 311, 577], "temperature": 0.0, "avg_logprob": -0.23028102391202684, "compression_ratio": 1.664835164835165, "no_speech_prob": 0.003375647123903036}, {"id": 4, "seek": 2758, "start": 27.58, "end": 32.56, "text": " numpy deals with arrays of different shapes and kind of the rules for whether", "tokens": [1031, 8200, 11215, 365, 41011, 295, 819, 10854, 293, 733, 295, 264, 4474, 337, 1968], "temperature": 0.0, "avg_logprob": -0.1684030532836914, "compression_ratio": 1.4452554744525548, "no_speech_prob": 2.354041498620063e-05}, {"id": 5, "seek": 2758, "start": 32.56, "end": 38.379999999999995, "text": " or not you can do arithmetic on them. Can anyone remind us what the kind of two", "tokens": [420, 406, 291, 393, 360, 42973, 322, 552, 13, 1664, 2878, 4160, 505, 437, 264, 733, 295, 732], "temperature": 0.0, "avg_logprob": -0.1684030532836914, "compression_ratio": 1.4452554744525548, "no_speech_prob": 2.354041498620063e-05}, {"id": 6, "seek": 2758, "start": 38.379999999999995, "end": 44.239999999999995, "text": " rules for for broadcasting are in numpy?", "tokens": [4474, 337, 337, 30024, 366, 294, 1031, 8200, 30], "temperature": 0.0, "avg_logprob": -0.1684030532836914, "compression_ratio": 1.4452554744525548, "no_speech_prob": 2.354041498620063e-05}, {"id": 7, "seek": 4424, "start": 44.24, "end": 55.760000000000005, "text": " Connor? It's like you line up the dimensions of your matrices and they have like the same", "tokens": [33133, 30, 467, 311, 411, 291, 1622, 493, 264, 12819, 295, 428, 32284, 293, 436, 362, 411, 264, 912], "temperature": 0.0, "avg_logprob": -0.31424721427585767, "compression_ratio": 1.680232558139535, "no_speech_prob": 0.00021640727936755866}, {"id": 8, "seek": 4424, "start": 55.760000000000005, "end": 63.3, "text": " for like a particular dimension if they have the same the same number you can broadcast them or if one of them is one.", "tokens": [337, 411, 257, 1729, 10139, 498, 436, 362, 264, 912, 264, 912, 1230, 291, 393, 9975, 552, 420, 498, 472, 295, 552, 307, 472, 13], "temperature": 0.0, "avg_logprob": -0.31424721427585767, "compression_ratio": 1.680232558139535, "no_speech_prob": 0.00021640727936755866}, {"id": 9, "seek": 4424, "start": 63.3, "end": 69.78, "text": " Yes exactly and then for lining them up do you start at the kind of beginning or", "tokens": [1079, 2293, 293, 550, 337, 19628, 552, 493, 360, 291, 722, 412, 264, 733, 295, 2863, 420], "temperature": 0.0, "avg_logprob": -0.31424721427585767, "compression_ratio": 1.680232558139535, "no_speech_prob": 0.00021640727936755866}, {"id": 10, "seek": 6978, "start": 69.78, "end": 82.78, "text": " end? What? Jeremy throw it back. Yes exactly yeah thank you. Yeah those are", "tokens": [917, 30, 708, 30, 17809, 3507, 309, 646, 13, 1079, 2293, 1338, 1309, 291, 13, 865, 729, 366], "temperature": 0.0, "avg_logprob": -0.19162962311192563, "compression_ratio": 1.56, "no_speech_prob": 8.938497558119707e-06}, {"id": 11, "seek": 6978, "start": 82.78, "end": 88.78, "text": " those are the rules for broadcasting. Start with the trailing dimensions which", "tokens": [729, 366, 264, 4474, 337, 30024, 13, 6481, 365, 264, 944, 4883, 12819, 597], "temperature": 0.0, "avg_logprob": -0.19162962311192563, "compression_ratio": 1.56, "no_speech_prob": 8.938497558119707e-06}, {"id": 12, "seek": 6978, "start": 88.78, "end": 93.06, "text": " is the far right hand side and then two dimensions are compatible if they're", "tokens": [307, 264, 1400, 558, 1011, 1252, 293, 550, 732, 12819, 366, 18218, 498, 436, 434], "temperature": 0.0, "avg_logprob": -0.19162962311192563, "compression_ratio": 1.56, "no_speech_prob": 8.938497558119707e-06}, {"id": 13, "seek": 6978, "start": 93.06, "end": 99.34, "text": " either equal or one of them is one. And so then I wrote a few problems as review", "tokens": [2139, 2681, 420, 472, 295, 552, 307, 472, 13, 400, 370, 550, 286, 4114, 257, 1326, 2740, 382, 3131], "temperature": 0.0, "avg_logprob": -0.19162962311192563, "compression_ratio": 1.56, "no_speech_prob": 8.938497558119707e-06}, {"id": 14, "seek": 9934, "start": 99.34, "end": 109.7, "text": " so suppose we have actually is the font large enough on this? Is that better?", "tokens": [370, 7297, 321, 362, 767, 307, 264, 10703, 2416, 1547, 322, 341, 30, 1119, 300, 1101, 30], "temperature": 0.0, "avg_logprob": -0.2163038031999455, "compression_ratio": 1.3217391304347825, "no_speech_prob": 1.1476802683318965e-05}, {"id": 15, "seek": 9934, "start": 109.7, "end": 122.02000000000001, "text": " Let me okay so we've got V which is three so three just a tuple M is three", "tokens": [961, 385, 1392, 370, 321, 600, 658, 691, 597, 307, 1045, 370, 1045, 445, 257, 2604, 781, 376, 307, 1045], "temperature": 0.0, "avg_logprob": -0.2163038031999455, "compression_ratio": 1.3217391304347825, "no_speech_prob": 1.1476802683318965e-05}, {"id": 16, "seek": 12202, "start": 122.02, "end": 129.14, "text": " by three and A is two by three by three and so kind of before we actually run", "tokens": [538, 1045, 293, 316, 307, 732, 538, 1045, 538, 1045, 293, 370, 733, 295, 949, 321, 767, 1190], "temperature": 0.0, "avg_logprob": -0.14015719850184555, "compression_ratio": 1.5256410256410255, "no_speech_prob": 2.521341912142816e-06}, {"id": 17, "seek": 12202, "start": 129.14, "end": 135.14, "text": " these which of the following operations will work and which won't? So take a", "tokens": [613, 597, 295, 264, 3480, 7705, 486, 589, 293, 597, 1582, 380, 30, 407, 747, 257], "temperature": 0.0, "avg_logprob": -0.14015719850184555, "compression_ratio": 1.5256410256410255, "no_speech_prob": 2.521341912142816e-06}, {"id": 18, "seek": 13514, "start": 135.14, "end": 154.98, "text": " moment to think about these and then you can do like a thumbs up thumbs down maybe.", "tokens": [50364, 1623, 281, 519, 466, 613, 293, 550, 291, 393, 360, 411, 257, 8838, 493, 8838, 760, 1310, 13, 51356], "temperature": 0.0, "avg_logprob": -0.2629258292061942, "compression_ratio": 1.1527777777777777, "no_speech_prob": 1.693882222753018e-05}, {"id": 19, "seek": 16514, "start": 165.14, "end": 173.89999999999998, "text": " Does anyone want more time? Okay so for the first one A plus B thumbs up if you", "tokens": [4402, 2878, 528, 544, 565, 30, 1033, 370, 337, 264, 700, 472, 316, 1804, 363, 8838, 493, 498, 291], "temperature": 0.0, "avg_logprob": -0.18696764707565308, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.0027144888881593943}, {"id": 20, "seek": 16514, "start": 173.89999999999998, "end": 182.17999999999998, "text": " think that'll work thumbs down if you think that it won't work. Thanks for", "tokens": [519, 300, 603, 589, 8838, 760, 498, 291, 519, 300, 309, 1582, 380, 589, 13, 2561, 337], "temperature": 0.0, "avg_logprob": -0.18696764707565308, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.0027144888881593943}, {"id": 21, "seek": 16514, "start": 182.17999999999998, "end": 187.45999999999998, "text": " everyone that's participating. Yeah I see I see mostly thumbs up and that's", "tokens": [1518, 300, 311, 13950, 13, 865, 286, 536, 286, 536, 5240, 8838, 493, 293, 300, 311], "temperature": 0.0, "avg_logprob": -0.18696764707565308, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.0027144888881593943}, {"id": 22, "seek": 16514, "start": 187.45999999999998, "end": 193.66, "text": " that's correct that works so and yeah V may be a little bit confusing since it's", "tokens": [300, 311, 3006, 300, 1985, 370, 293, 1338, 691, 815, 312, 257, 707, 857, 13181, 1670, 309, 311], "temperature": 0.0, "avg_logprob": -0.18696764707565308, "compression_ratio": 1.586734693877551, "no_speech_prob": 0.0027144888881593943}, {"id": 23, "seek": 19366, "start": 193.66, "end": 201.54, "text": " kind of just got this single dimension showing up but yeah that works the the", "tokens": [733, 295, 445, 658, 341, 2167, 10139, 4099, 493, 457, 1338, 300, 1985, 264, 264], "temperature": 0.0, "avg_logprob": -0.13346114328929357, "compression_ratio": 1.5374149659863945, "no_speech_prob": 2.482350964783109e-06}, {"id": 24, "seek": 19366, "start": 201.54, "end": 206.34, "text": " threes line up and then you've got the two and three before and so what's", "tokens": [258, 4856, 1622, 493, 293, 550, 291, 600, 658, 264, 732, 293, 1045, 949, 293, 370, 437, 311], "temperature": 0.0, "avg_logprob": -0.13346114328929357, "compression_ratio": 1.5374149659863945, "no_speech_prob": 2.482350964783109e-06}, {"id": 25, "seek": 19366, "start": 206.34, "end": 215.5, "text": " happening with that is that actually might be helpful to put A here so you", "tokens": [2737, 365, 300, 307, 300, 767, 1062, 312, 4961, 281, 829, 316, 510, 370, 291], "temperature": 0.0, "avg_logprob": -0.13346114328929357, "compression_ratio": 1.5374149659863945, "no_speech_prob": 2.482350964783109e-06}, {"id": 26, "seek": 21550, "start": 215.5, "end": 225.3, "text": " can see one has been added kind of to this whole first column along both the", "tokens": [393, 536, 472, 575, 668, 3869, 733, 295, 281, 341, 1379, 700, 7738, 2051, 1293, 264], "temperature": 0.0, "avg_logprob": -0.09425675563323192, "compression_ratio": 1.6577540106951871, "no_speech_prob": 7.071214440657059e-06}, {"id": 27, "seek": 21550, "start": 225.3, "end": 229.86, "text": " both matrices if you think of this as being like an array of two matrices and", "tokens": [1293, 32284, 498, 291, 519, 295, 341, 382, 885, 411, 364, 10225, 295, 732, 32284, 293], "temperature": 0.0, "avg_logprob": -0.09425675563323192, "compression_ratio": 1.6577540106951871, "no_speech_prob": 7.071214440657059e-06}, {"id": 28, "seek": 21550, "start": 229.86, "end": 235.98, "text": " then we've got two was added along this whole second column and three was added", "tokens": [550, 321, 600, 658, 732, 390, 3869, 2051, 341, 1379, 1150, 7738, 293, 1045, 390, 3869], "temperature": 0.0, "avg_logprob": -0.09425675563323192, "compression_ratio": 1.6577540106951871, "no_speech_prob": 7.071214440657059e-06}, {"id": 29, "seek": 21550, "start": 235.98, "end": 244.3, "text": " here. Let's go on to the next one how about A plus M and I should leave the", "tokens": [510, 13, 961, 311, 352, 322, 281, 264, 958, 472, 577, 466, 316, 1804, 376, 293, 286, 820, 1856, 264], "temperature": 0.0, "avg_logprob": -0.09425675563323192, "compression_ratio": 1.6577540106951871, "no_speech_prob": 7.071214440657059e-06}, {"id": 30, "seek": 24430, "start": 244.3, "end": 249.62, "text": " dimensions up so you can see thumbs up if you think A plus M will work thumbs", "tokens": [12819, 493, 370, 291, 393, 536, 8838, 493, 498, 291, 519, 316, 1804, 376, 486, 589, 8838], "temperature": 0.0, "avg_logprob": -0.11248463850754958, "compression_ratio": 1.7701149425287357, "no_speech_prob": 3.5007612950721523e-06}, {"id": 31, "seek": 24430, "start": 249.62, "end": 257.18, "text": " down if not excellent so yeah saw all thumbs up and that works because the", "tokens": [760, 498, 406, 7103, 370, 1338, 1866, 439, 8838, 493, 293, 300, 1985, 570, 264], "temperature": 0.0, "avg_logprob": -0.11248463850754958, "compression_ratio": 1.7701149425287357, "no_speech_prob": 3.5007612950721523e-06}, {"id": 32, "seek": 24430, "start": 257.18, "end": 260.74, "text": " three by three lines up with the three by three at the end of two by three by", "tokens": [1045, 538, 1045, 3876, 493, 365, 264, 1045, 538, 1045, 412, 264, 917, 295, 732, 538, 1045, 538], "temperature": 0.0, "avg_logprob": -0.11248463850754958, "compression_ratio": 1.7701149425287357, "no_speech_prob": 3.5007612950721523e-06}, {"id": 33, "seek": 24430, "start": 260.74, "end": 270.46000000000004, "text": " three so we can do that and their matrix M is kind of being added to you know", "tokens": [1045, 370, 321, 393, 360, 300, 293, 641, 8141, 376, 307, 733, 295, 885, 3869, 281, 291, 458], "temperature": 0.0, "avg_logprob": -0.11248463850754958, "compression_ratio": 1.7701149425287357, "no_speech_prob": 3.5007612950721523e-06}, {"id": 34, "seek": 27046, "start": 270.46, "end": 275.32, "text": " this first matrix in A and to the second matrix in A and how about A dot", "tokens": [341, 700, 8141, 294, 316, 293, 281, 264, 1150, 8141, 294, 316, 293, 577, 466, 316, 5893], "temperature": 0.0, "avg_logprob": -0.16329261584159654, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.2252436338021653e-06}, {"id": 35, "seek": 27046, "start": 275.32, "end": 284.21999999999997, "text": " transpose or A transpose plus M thumbs up or thumbs down great yeah I see a lot", "tokens": [25167, 420, 316, 25167, 1804, 376, 8838, 493, 420, 8838, 760, 869, 1338, 286, 536, 257, 688], "temperature": 0.0, "avg_logprob": -0.16329261584159654, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.2252436338021653e-06}, {"id": 36, "seek": 27046, "start": 284.21999999999997, "end": 290.58, "text": " of thumbs down and this is nice we get the air operands could not be broadcast", "tokens": [295, 8838, 760, 293, 341, 307, 1481, 321, 483, 264, 1988, 2208, 2967, 727, 406, 312, 9975], "temperature": 0.0, "avg_logprob": -0.16329261584159654, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.2252436338021653e-06}, {"id": 37, "seek": 27046, "start": 290.58, "end": 295.65999999999997, "text": " together with shapes 3 3 2 and 3 3 now you understand what that air means if", "tokens": [1214, 365, 10854, 805, 805, 568, 293, 805, 805, 586, 291, 1223, 437, 300, 1988, 1355, 498], "temperature": 0.0, "avg_logprob": -0.16329261584159654, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.2252436338021653e-06}, {"id": 38, "seek": 29566, "start": 295.66, "end": 301.18, "text": " you get it any questions about broadcasting", "tokens": [291, 483, 309, 604, 1651, 466, 30024], "temperature": 0.0, "avg_logprob": -0.2904183796473912, "compression_ratio": 1.29, "no_speech_prob": 8.800379873719066e-06}, {"id": 39, "seek": 29566, "start": 304.02000000000004, "end": 307.02000000000004, "text": " Kelsey", "tokens": [44714], "temperature": 0.0, "avg_logprob": -0.2904183796473912, "compression_ratio": 1.29, "no_speech_prob": 8.800379873719066e-06}, {"id": 40, "seek": 29566, "start": 315.98, "end": 322.86, "text": " so that and actually it's helpful for me to to show it and so that's reversing", "tokens": [370, 300, 293, 767, 309, 311, 4961, 337, 385, 281, 281, 855, 309, 293, 370, 300, 311, 14582, 278], "temperature": 0.0, "avg_logprob": -0.2904183796473912, "compression_ratio": 1.29, "no_speech_prob": 8.800379873719066e-06}, {"id": 41, "seek": 32286, "start": 322.86, "end": 327.42, "text": " though let me also put", "tokens": [1673, 718, 385, 611, 829], "temperature": 0.0, "avg_logprob": -0.2284623384475708, "compression_ratio": 1.4365079365079365, "no_speech_prob": 1.7500629837741144e-05}, {"id": 42, "seek": 32286, "start": 333.98, "end": 340.26, "text": " let me change this to a so you can have kind of like the visualization so here", "tokens": [718, 385, 1319, 341, 281, 257, 370, 291, 393, 362, 733, 295, 411, 264, 25801, 370, 510], "temperature": 0.0, "avg_logprob": -0.2284623384475708, "compression_ratio": 1.4365079365079365, "no_speech_prob": 1.7500629837741144e-05}, {"id": 43, "seek": 32286, "start": 340.26, "end": 348.06, "text": " we're taking 5 10 15 so basically we end up taking kind of the the first column", "tokens": [321, 434, 1940, 1025, 1266, 2119, 370, 1936, 321, 917, 493, 1940, 733, 295, 264, 264, 700, 7738], "temperature": 0.0, "avg_logprob": -0.2284623384475708, "compression_ratio": 1.4365079365079365, "no_speech_prob": 1.7500629837741144e-05}, {"id": 44, "seek": 34806, "start": 348.06, "end": 352.98, "text": " of this matrix and the first column of this one and putting those together to", "tokens": [295, 341, 8141, 293, 264, 700, 7738, 295, 341, 472, 293, 3372, 729, 1214, 281], "temperature": 0.0, "avg_logprob": -0.0819156625297632, "compression_ratio": 2.0104712041884816, "no_speech_prob": 2.930768096121028e-05}, {"id": 45, "seek": 34806, "start": 352.98, "end": 359.22, "text": " get this new first matrix and then kind of second column here 10 20 30 and", "tokens": [483, 341, 777, 700, 8141, 293, 550, 733, 295, 1150, 7738, 510, 1266, 945, 2217, 293], "temperature": 0.0, "avg_logprob": -0.0819156625297632, "compression_ratio": 2.0104712041884816, "no_speech_prob": 2.930768096121028e-05}, {"id": 46, "seek": 34806, "start": 359.22, "end": 364.62, "text": " negative 2 negative 4 negative 6 and putting those together and then 15 30", "tokens": [3671, 568, 3671, 1017, 3671, 1386, 293, 3372, 729, 1214, 293, 550, 2119, 2217], "temperature": 0.0, "avg_logprob": -0.0819156625297632, "compression_ratio": 2.0104712041884816, "no_speech_prob": 2.930768096121028e-05}, {"id": 47, "seek": 34806, "start": 364.62, "end": 370.54, "text": " 45 negative 3 negative 6 negative 9 and putting those together let me do this", "tokens": [6905, 3671, 805, 3671, 1386, 3671, 1722, 293, 3372, 729, 1214, 718, 385, 360, 341], "temperature": 0.0, "avg_logprob": -0.0819156625297632, "compression_ratio": 2.0104712041884816, "no_speech_prob": 2.930768096121028e-05}, {"id": 48, "seek": 34806, "start": 370.54, "end": 376.06, "text": " again I think it'll be clearer since we've got three showing up as a dimension", "tokens": [797, 286, 519, 309, 603, 312, 26131, 1670, 321, 600, 658, 1045, 4099, 493, 382, 257, 10139], "temperature": 0.0, "avg_logprob": -0.0819156625297632, "compression_ratio": 2.0104712041884816, "no_speech_prob": 2.930768096121028e-05}, {"id": 49, "seek": 37606, "start": 376.06, "end": 387.62, "text": " twice let me do something with them completely different dimensions oh so", "tokens": [6091, 718, 385, 360, 746, 365, 552, 2584, 819, 12819, 1954, 370], "temperature": 0.0, "avg_logprob": -0.11684698071973078, "compression_ratio": 1.4966887417218544, "no_speech_prob": 1.2218053598189726e-05}, {"id": 50, "seek": 37606, "start": 387.62, "end": 395.18, "text": " you're I think you're reversing the order of the dimensions yeah okay but now", "tokens": [291, 434, 286, 519, 291, 434, 14582, 278, 264, 1668, 295, 264, 12819, 1338, 1392, 457, 586], "temperature": 0.0, "avg_logprob": -0.11684698071973078, "compression_ratio": 1.4966887417218544, "no_speech_prob": 1.2218053598189726e-05}, {"id": 51, "seek": 37606, "start": 395.18, "end": 403.06, "text": " I've got a 2 3 4 so I think this will be kind of a nice example so when we", "tokens": [286, 600, 658, 257, 568, 805, 1017, 370, 286, 519, 341, 486, 312, 733, 295, 257, 1481, 1365, 370, 562, 321], "temperature": 0.0, "avg_logprob": -0.11684698071973078, "compression_ratio": 1.4966887417218544, "no_speech_prob": 1.2218053598189726e-05}, {"id": 52, "seek": 40306, "start": 403.06, "end": 409.3, "text": " reverse the completely reverse the order of dimensions it becomes 4 3 2 and then", "tokens": [9943, 264, 2584, 9943, 264, 1668, 295, 12819, 309, 3643, 1017, 805, 568, 293, 550], "temperature": 0.0, "avg_logprob": -0.12554414132062128, "compression_ratio": 1.5427135678391959, "no_speech_prob": 5.3378576012619305e-06}, {"id": 53, "seek": 40306, "start": 409.3, "end": 416.46, "text": " this is what a transpose looks like yeah and I definitely also recommend kind of", "tokens": [341, 307, 437, 257, 25167, 1542, 411, 1338, 293, 286, 2138, 611, 2748, 733, 295], "temperature": 0.0, "avg_logprob": -0.12554414132062128, "compression_ratio": 1.5427135678391959, "no_speech_prob": 5.3378576012619305e-06}, {"id": 54, "seek": 40306, "start": 416.46, "end": 419.26, "text": " looking at small test cases of these because I think often it's helpful to", "tokens": [1237, 412, 1359, 1500, 3331, 295, 613, 570, 286, 519, 2049, 309, 311, 4961, 281], "temperature": 0.0, "avg_logprob": -0.12554414132062128, "compression_ratio": 1.5427135678391959, "no_speech_prob": 5.3378576012619305e-06}, {"id": 55, "seek": 40306, "start": 419.26, "end": 424.22, "text": " to kind of visualize how they're changing yeah good question any other", "tokens": [281, 733, 295, 23273, 577, 436, 434, 4473, 1338, 665, 1168, 604, 661], "temperature": 0.0, "avg_logprob": -0.12554414132062128, "compression_ratio": 1.5427135678391959, "no_speech_prob": 5.3378576012619305e-06}, {"id": 56, "seek": 42422, "start": 424.22, "end": 434.86, "text": " questions about broadcasting okay so next up we talked about how sci-fi stores", "tokens": [1651, 466, 30024, 1392, 370, 958, 493, 321, 2825, 466, 577, 2180, 12, 13325, 9512], "temperature": 0.0, "avg_logprob": -0.23498712267194474, "compression_ratio": 1.3771929824561404, "no_speech_prob": 2.857171921277768e-06}, {"id": 57, "seek": 42422, "start": 434.86, "end": 443.62, "text": " sparse matrices and that there were a few different matrix storage formats and", "tokens": [637, 11668, 32284, 293, 300, 456, 645, 257, 1326, 819, 8141, 6725, 25879, 293], "temperature": 0.0, "avg_logprob": -0.23498712267194474, "compression_ratio": 1.3771929824561404, "no_speech_prob": 2.857171921277768e-06}, {"id": 58, "seek": 44362, "start": 443.62, "end": 454.46, "text": " let's see can anyone describe how how coordinate wise storage works", "tokens": [718, 311, 536, 393, 2878, 6786, 577, 577, 15670, 10829, 6725, 1985], "temperature": 0.0, "avg_logprob": -0.2729979816235994, "compression_ratio": 1.3963963963963963, "no_speech_prob": 1.4062654372537509e-05}, {"id": 59, "seek": 44362, "start": 459.42, "end": 462.42, "text": " Matthew", "tokens": [12434], "temperature": 0.0, "avg_logprob": -0.2729979816235994, "compression_ratio": 1.3963963963963963, "no_speech_prob": 1.4062654372537509e-05}, {"id": 60, "seek": 44362, "start": 467.74, "end": 472.22, "text": " exactly yeah so you're keeping track of the index for the row the index for the", "tokens": [2293, 1338, 370, 291, 434, 5145, 2837, 295, 264, 8186, 337, 264, 5386, 264, 8186, 337, 264], "temperature": 0.0, "avg_logprob": -0.2729979816235994, "compression_ratio": 1.3963963963963963, "no_speech_prob": 1.4062654372537509e-05}, {"id": 61, "seek": 47222, "start": 472.22, "end": 477.74, "text": " column and the value that you want there great and what's a what's an advantage", "tokens": [7738, 293, 264, 2158, 300, 291, 528, 456, 869, 293, 437, 311, 257, 437, 311, 364, 5002], "temperature": 0.0, "avg_logprob": -0.16465528955999412, "compression_ratio": 1.683453237410072, "no_speech_prob": 2.0141720597166568e-05}, {"id": 62, "seek": 47222, "start": 477.74, "end": 491.42, "text": " of this this approach actually advantage or disadvantage so we have to allocate", "tokens": [295, 341, 341, 3109, 767, 5002, 420, 24292, 370, 321, 362, 281, 35713], "temperature": 0.0, "avg_logprob": -0.16465528955999412, "compression_ratio": 1.683453237410072, "no_speech_prob": 2.0141720597166568e-05}, {"id": 63, "seek": 47222, "start": 491.42, "end": 499.5, "text": " less memory or storage so less memory than a dense matrix yes yes and this", "tokens": [1570, 4675, 420, 6725, 370, 1570, 4675, 813, 257, 18011, 8141, 2086, 2086, 293, 341], "temperature": 0.0, "avg_logprob": -0.16465528955999412, "compression_ratio": 1.683453237410072, "no_speech_prob": 2.0141720597166568e-05}, {"id": 64, "seek": 49950, "start": 499.5, "end": 505.3, "text": " advantage because we cannot access the element by index that fast right so it's", "tokens": [5002, 570, 321, 2644, 2105, 264, 4478, 538, 8186, 300, 2370, 558, 370, 309, 311], "temperature": 0.0, "avg_logprob": -0.1319326673235212, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.710508488235064e-05}, {"id": 65, "seek": 49950, "start": 505.3, "end": 512.62, "text": " harder to get an entire row or an entire column exactly yes yes if you wanted to", "tokens": [6081, 281, 483, 364, 2302, 5386, 420, 364, 2302, 7738, 2293, 2086, 2086, 498, 291, 1415, 281], "temperature": 0.0, "avg_logprob": -0.1319326673235212, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.710508488235064e-05}, {"id": 66, "seek": 49950, "start": 512.62, "end": 516.94, "text": " find everything in a particular row you would have to go through your array of", "tokens": [915, 1203, 294, 257, 1729, 5386, 291, 576, 362, 281, 352, 807, 428, 10225, 295], "temperature": 0.0, "avg_logprob": -0.1319326673235212, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.710508488235064e-05}, {"id": 67, "seek": 49950, "start": 516.94, "end": 523.94, "text": " row indices and pick out those kind of corresponding values all right and so", "tokens": [5386, 43840, 293, 1888, 484, 729, 733, 295, 11760, 4190, 439, 558, 293, 370], "temperature": 0.0, "avg_logprob": -0.1319326673235212, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.710508488235064e-05}, {"id": 68, "seek": 49950, "start": 523.94, "end": 528.38, "text": " then um kind of this was an example we saw last time of and they've used this", "tokens": [550, 1105, 733, 295, 341, 390, 364, 1365, 321, 1866, 1036, 565, 295, 293, 436, 600, 1143, 341], "temperature": 0.0, "avg_logprob": -0.1319326673235212, "compression_ratio": 1.6837606837606838, "no_speech_prob": 2.710508488235064e-05}, {"id": 69, "seek": 52838, "start": 528.38, "end": 534.58, "text": " nice color coding to show like 75 is in row 6 column 4 over here they have value", "tokens": [1481, 2017, 17720, 281, 855, 411, 9562, 307, 294, 5386, 1386, 7738, 1017, 670, 510, 436, 362, 2158], "temperature": 0.0, "avg_logprob": -0.1389828211144556, "compression_ratio": 1.6476683937823835, "no_speech_prob": 6.240641141630476e-06}, {"id": 70, "seek": 52838, "start": 534.58, "end": 545.14, "text": " 75 row 6 column 4 and that's how it's being stored next step is that oh and", "tokens": [9562, 5386, 1386, 7738, 1017, 293, 300, 311, 577, 309, 311, 885, 12187, 958, 1823, 307, 300, 1954, 293], "temperature": 0.0, "avg_logprob": -0.1389828211144556, "compression_ratio": 1.6476683937823835, "no_speech_prob": 6.240641141630476e-06}, {"id": 71, "seek": 52838, "start": 545.14, "end": 548.82, "text": " then this is also kind of illustrating for things like matrix multiplication you", "tokens": [550, 341, 307, 611, 733, 295, 8490, 8754, 337, 721, 411, 8141, 27290, 291], "temperature": 0.0, "avg_logprob": -0.1389828211144556, "compression_ratio": 1.6476683937823835, "no_speech_prob": 6.240641141630476e-06}, {"id": 72, "seek": 52838, "start": 548.82, "end": 553.54, "text": " can just you know look up what you have in your value array you're not having to", "tokens": [393, 445, 291, 458, 574, 493, 437, 291, 362, 294, 428, 2158, 10225, 291, 434, 406, 1419, 281], "temperature": 0.0, "avg_logprob": -0.1389828211144556, "compression_ratio": 1.6476683937823835, "no_speech_prob": 6.240641141630476e-06}, {"id": 73, "seek": 55354, "start": 553.54, "end": 561.62, "text": " go through all the spaces where you have zeros all right so compressed sparse row", "tokens": [352, 807, 439, 264, 7673, 689, 291, 362, 35193, 439, 558, 370, 30353, 637, 11668, 5386], "temperature": 0.0, "avg_logprob": -0.16008615493774414, "compression_ratio": 1.3392857142857142, "no_speech_prob": 1.4970079064369202e-05}, {"id": 74, "seek": 56162, "start": 561.62, "end": 586.3, "text": " data structure can anyone describe what's going on with that picture Sam", "tokens": [1412, 3877, 393, 2878, 6786, 437, 311, 516, 322, 365, 300, 3036, 4832], "temperature": 0.0, "avg_logprob": -0.3019373557146858, "compression_ratio": 1.0140845070422535, "no_speech_prob": 3.882526289089583e-05}, {"id": 75, "seek": 58630, "start": 586.3, "end": 600.18, "text": " so to save space the row indices are not repeated it just says which of the end", "tokens": [370, 281, 3155, 1901, 264, 5386, 43840, 366, 406, 10477, 309, 445, 1619, 597, 295, 264, 917], "temperature": 0.0, "avg_logprob": -0.22390071132726835, "compression_ratio": 1.6233766233766234, "no_speech_prob": 1.300610074395081e-05}, {"id": 76, "seek": 58630, "start": 600.18, "end": 608.78, "text": " observations is the first that has that row exactly yes so this uses even less space than the", "tokens": [18163, 307, 264, 700, 300, 575, 300, 5386, 2293, 2086, 370, 341, 4960, 754, 1570, 1901, 813, 264], "temperature": 0.0, "avg_logprob": -0.22390071132726835, "compression_ratio": 1.6233766233766234, "no_speech_prob": 1.300610074395081e-05}, {"id": 77, "seek": 58630, "start": 608.78, "end": 613.18, "text": " coordinate sparse storage because it just keeps track of a row pointer which", "tokens": [15670, 637, 11668, 6725, 570, 309, 445, 5965, 2837, 295, 257, 5386, 23918, 597], "temperature": 0.0, "avg_logprob": -0.22390071132726835, "compression_ratio": 1.6233766233766234, "no_speech_prob": 1.300610074395081e-05}, {"id": 78, "seek": 61318, "start": 613.18, "end": 617.7399999999999, "text": " is Sam said it's just kind of telling you the first place that or the first", "tokens": [307, 4832, 848, 309, 311, 445, 733, 295, 3585, 291, 264, 700, 1081, 300, 420, 264, 700], "temperature": 0.0, "avg_logprob": -0.1327574820745559, "compression_ratio": 1.8362573099415205, "no_speech_prob": 6.85412805978558e-06}, {"id": 79, "seek": 61318, "start": 617.7399999999999, "end": 624.0999999999999, "text": " value that that's on that row so for row one the third value is the first to show", "tokens": [2158, 300, 300, 311, 322, 300, 5386, 370, 337, 5386, 472, 264, 2636, 2158, 307, 264, 700, 281, 855], "temperature": 0.0, "avg_logprob": -0.1327574820745559, "compression_ratio": 1.8362573099415205, "no_speech_prob": 6.85412805978558e-06}, {"id": 80, "seek": 61318, "start": 624.0999999999999, "end": 630.38, "text": " up there which is 22 and so we see that's the first value on row one and for", "tokens": [493, 456, 597, 307, 5853, 293, 370, 321, 536, 300, 311, 264, 700, 2158, 322, 5386, 472, 293, 337], "temperature": 0.0, "avg_logprob": -0.1327574820745559, "compression_ratio": 1.8362573099415205, "no_speech_prob": 6.85412805978558e-06}, {"id": 81, "seek": 61318, "start": 630.38, "end": 640.0999999999999, "text": " let's see what else they color-coded and row three the ninth value is the first", "tokens": [718, 311, 536, 437, 1646, 436, 2017, 12, 66, 12340, 293, 5386, 1045, 264, 28207, 2158, 307, 264, 700], "temperature": 0.0, "avg_logprob": -0.1327574820745559, "compression_ratio": 1.8362573099415205, "no_speech_prob": 6.85412805978558e-06}, {"id": 82, "seek": 64010, "start": 640.1, "end": 643.82, "text": " there and so you can see the ninth values 42 and that's the first thing on", "tokens": [456, 293, 370, 291, 393, 536, 264, 28207, 4190, 14034, 293, 300, 311, 264, 700, 551, 322], "temperature": 0.0, "avg_logprob": -0.21025908270547555, "compression_ratio": 1.4272727272727272, "no_speech_prob": 2.7106058041681536e-05}, {"id": 83, "seek": 64010, "start": 643.82, "end": 653.26, "text": " row three so what's a what are some benefits and or pros and cons of this", "tokens": [5386, 1045, 370, 437, 311, 257, 437, 366, 512, 5311, 293, 420, 6267, 293, 1014, 295, 341], "temperature": 0.0, "avg_logprob": -0.21025908270547555, "compression_ratio": 1.4272727272727272, "no_speech_prob": 2.7106058041681536e-05}, {"id": 84, "seek": 64010, "start": 653.26, "end": 655.66, "text": " approach", "tokens": [3109], "temperature": 0.0, "avg_logprob": -0.21025908270547555, "compression_ratio": 1.4272727272727272, "no_speech_prob": 2.7106058041681536e-05}, {"id": 85, "seek": 65566, "start": 655.66, "end": 671.9399999999999, "text": " Valentine I think when they are trying to look for non-zero elements of that", "tokens": [7188, 317, 533, 286, 519, 562, 436, 366, 1382, 281, 574, 337, 2107, 12, 32226, 4959, 295, 300], "temperature": 0.0, "avg_logprob": -0.22353113265264601, "compression_ratio": 1.5294117647058822, "no_speech_prob": 6.39873105683364e-05}, {"id": 86, "seek": 65566, "start": 671.9399999999999, "end": 676.9, "text": " matrix you don't have to go through all the non-zero elements you can just keep", "tokens": [8141, 291, 500, 380, 362, 281, 352, 807, 439, 264, 2107, 12, 32226, 4959, 291, 393, 445, 1066], "temperature": 0.0, "avg_logprob": -0.22353113265264601, "compression_ratio": 1.5294117647058822, "no_speech_prob": 6.39873105683364e-05}, {"id": 87, "seek": 65566, "start": 676.9, "end": 681.54, "text": " row by row until you get to the road which you need so if you're looking up a", "tokens": [5386, 538, 5386, 1826, 291, 483, 281, 264, 3060, 597, 291, 643, 370, 498, 291, 434, 1237, 493, 257], "temperature": 0.0, "avg_logprob": -0.22353113265264601, "compression_ratio": 1.5294117647058822, "no_speech_prob": 6.39873105683364e-05}, {"id": 88, "seek": 68154, "start": 681.54, "end": 686.54, "text": " particular row yes it's very quick to do that yeah fast lookup by Rose and then", "tokens": [1729, 5386, 2086, 309, 311, 588, 1702, 281, 360, 300, 1338, 2370, 574, 1010, 538, 12765, 293, 550], "temperature": 0.0, "avg_logprob": -0.20687296483423803, "compression_ratio": 1.5792079207920793, "no_speech_prob": 8.138971679727547e-06}, {"id": 89, "seek": 68154, "start": 686.54, "end": 693.42, "text": " can you think of a disadvantage by but by columns it will be just the same", "tokens": [393, 291, 519, 295, 257, 24292, 538, 457, 538, 13766, 309, 486, 312, 445, 264, 912], "temperature": 0.0, "avg_logprob": -0.20687296483423803, "compression_ratio": 1.5792079207920793, "no_speech_prob": 8.138971679727547e-06}, {"id": 90, "seek": 68154, "start": 693.42, "end": 699.74, "text": " complexity of big or of and in the worst case yeah so column lookup is painful or", "tokens": [14024, 295, 955, 420, 295, 293, 294, 264, 5855, 1389, 1338, 370, 7738, 574, 1010, 307, 11697, 420], "temperature": 0.0, "avg_logprob": -0.20687296483423803, "compression_ratio": 1.5792079207920793, "no_speech_prob": 8.138971679727547e-06}, {"id": 91, "seek": 68154, "start": 699.74, "end": 704.4599999999999, "text": " yeah more painful because you're kind of having to go backwards to calculate thank", "tokens": [1338, 544, 11697, 570, 291, 434, 733, 295, 1419, 281, 352, 12204, 281, 8873, 1309], "temperature": 0.0, "avg_logprob": -0.20687296483423803, "compression_ratio": 1.5792079207920793, "no_speech_prob": 8.138971679727547e-06}, {"id": 92, "seek": 70446, "start": 704.46, "end": 716.86, "text": " you wait throw the microphone it's for the bit it's for the it's for the video", "tokens": [291, 1699, 3507, 264, 10952, 309, 311, 337, 264, 857, 309, 311, 337, 264, 309, 311, 337, 264, 960], "temperature": 0.0, "avg_logprob": -0.1295679493954307, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.6439875253126957e-05}, {"id": 93, "seek": 70446, "start": 716.86, "end": 723.86, "text": " so the row pointer great question is telling you so there the index is", "tokens": [370, 264, 5386, 23918, 869, 1168, 307, 3585, 291, 370, 456, 264, 8186, 307], "temperature": 0.0, "avg_logprob": -0.1295679493954307, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.6439875253126957e-05}, {"id": 94, "seek": 70446, "start": 723.86, "end": 731.6600000000001, "text": " telling you kind of where that row starts so row zero the first one is in", "tokens": [3585, 291, 733, 295, 689, 300, 5386, 3719, 370, 5386, 4018, 264, 700, 472, 307, 294], "temperature": 0.0, "avg_logprob": -0.1295679493954307, "compression_ratio": 1.7286821705426356, "no_speech_prob": 1.6439875253126957e-05}, {"id": 95, "seek": 73166, "start": 731.66, "end": 737.02, "text": " value zero so the how index is being used is different for value and row", "tokens": [2158, 4018, 370, 264, 577, 8186, 307, 885, 1143, 307, 819, 337, 2158, 293, 5386], "temperature": 0.0, "avg_logprob": -0.10822165012359619, "compression_ratio": 1.8018433179723503, "no_speech_prob": 7.5273087531968486e-06}, {"id": 96, "seek": 73166, "start": 737.02, "end": 743.02, "text": " pointer and actually it's probably easier to look at so the first the first three", "tokens": [23918, 293, 767, 309, 311, 1391, 3571, 281, 574, 412, 370, 264, 700, 264, 700, 1045], "temperature": 0.0, "avg_logprob": -0.10822165012359619, "compression_ratio": 1.8018433179723503, "no_speech_prob": 7.5273087531968486e-06}, {"id": 97, "seek": 73166, "start": 743.02, "end": 747.6999999999999, "text": " values are in row zero so you really just need to store a zero and then this", "tokens": [4190, 366, 294, 5386, 4018, 370, 291, 534, 445, 643, 281, 3531, 257, 4018, 293, 550, 341], "temperature": 0.0, "avg_logprob": -0.10822165012359619, "compression_ratio": 1.8018433179723503, "no_speech_prob": 7.5273087531968486e-06}, {"id": 98, "seek": 73166, "start": 747.6999999999999, "end": 755.78, "text": " three lets you know okay now we've moved on to row one and the kind of starting", "tokens": [1045, 6653, 291, 458, 1392, 586, 321, 600, 4259, 322, 281, 5386, 472, 293, 264, 733, 295, 2891], "temperature": 0.0, "avg_logprob": -0.10822165012359619, "compression_ratio": 1.8018433179723503, "no_speech_prob": 7.5273087531968486e-06}, {"id": 99, "seek": 73166, "start": 755.78, "end": 761.02, "text": " with index zero the third value 22 so if you go over here the third value is 22", "tokens": [365, 8186, 4018, 264, 2636, 2158, 5853, 370, 498, 291, 352, 670, 510, 264, 2636, 2158, 307, 5853], "temperature": 0.0, "avg_logprob": -0.10822165012359619, "compression_ratio": 1.8018433179723503, "no_speech_prob": 7.5273087531968486e-06}, {"id": 100, "seek": 76102, "start": 761.02, "end": 768.22, "text": " that's the first thing in row one and then we've got a three values here and", "tokens": [300, 311, 264, 700, 551, 294, 5386, 472, 293, 550, 321, 600, 658, 257, 1045, 4190, 510, 293], "temperature": 0.0, "avg_logprob": -0.1041061282157898, "compression_ratio": 1.9254658385093169, "no_speech_prob": 2.42989572143415e-05}, {"id": 101, "seek": 76102, "start": 768.22, "end": 772.34, "text": " then value six is the first thing in row two so down here we store six for the", "tokens": [550, 2158, 2309, 307, 264, 700, 551, 294, 5386, 732, 370, 760, 510, 321, 3531, 2309, 337, 264], "temperature": 0.0, "avg_logprob": -0.1041061282157898, "compression_ratio": 1.9254658385093169, "no_speech_prob": 2.42989572143415e-05}, {"id": 102, "seek": 76102, "start": 772.34, "end": 784.22, "text": " row pointer so it's that saying row two starts with value six which is 31 so the", "tokens": [5386, 23918, 370, 309, 311, 300, 1566, 5386, 732, 3719, 365, 2158, 2309, 597, 307, 10353, 370, 264], "temperature": 0.0, "avg_logprob": -0.1041061282157898, "compression_ratio": 1.9254658385093169, "no_speech_prob": 2.42989572143415e-05}, {"id": 103, "seek": 76102, "start": 784.22, "end": 790.54, "text": " for the row pointer yeah the index is telling you the row number and it's", "tokens": [337, 264, 5386, 23918, 1338, 264, 8186, 307, 3585, 291, 264, 5386, 1230, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.1041061282157898, "compression_ratio": 1.9254658385093169, "no_speech_prob": 2.42989572143415e-05}, {"id": 104, "seek": 79054, "start": 790.54, "end": 797.42, "text": " telling you that though in terms of what the index for the value is Tim's got his", "tokens": [3585, 291, 300, 1673, 294, 2115, 295, 437, 264, 8186, 337, 264, 2158, 307, 7172, 311, 658, 702], "temperature": 0.0, "avg_logprob": -0.22437412922198957, "compression_ratio": 1.1265822784810127, "no_speech_prob": 2.144370046153199e-05}, {"id": 105, "seek": 79054, "start": 797.42, "end": 799.78, "text": " hand up", "tokens": [1011, 493], "temperature": 0.0, "avg_logprob": -0.22437412922198957, "compression_ratio": 1.1265822784810127, "no_speech_prob": 2.144370046153199e-05}, {"id": 106, "seek": 79978, "start": 799.78, "end": 808.14, "text": " about this is like the values are stored in memory in like in 21 entries and the", "tokens": [466, 341, 307, 411, 264, 4190, 366, 12187, 294, 4675, 294, 411, 294, 5080, 23041, 293, 264], "temperature": 0.0, "avg_logprob": -0.208031419205339, "compression_ratio": 1.6187845303867403, "no_speech_prob": 2.6270741727785207e-05}, {"id": 107, "seek": 79978, "start": 808.14, "end": 813.74, "text": " real point is telling the address of where the row starts", "tokens": [957, 935, 307, 3585, 264, 2985, 295, 689, 264, 5386, 3719], "temperature": 0.0, "avg_logprob": -0.208031419205339, "compression_ratio": 1.6187845303867403, "no_speech_prob": 2.6270741727785207e-05}, {"id": 108, "seek": 79978, "start": 816.9399999999999, "end": 821.06, "text": " yeah that's a great way of putting it like you can kind of think about like", "tokens": [1338, 300, 311, 257, 869, 636, 295, 3372, 309, 411, 291, 393, 733, 295, 519, 466, 411], "temperature": 0.0, "avg_logprob": -0.208031419205339, "compression_ratio": 1.6187845303867403, "no_speech_prob": 2.6270741727785207e-05}, {"id": 109, "seek": 79978, "start": 821.06, "end": 826.4599999999999, "text": " you've turned you've turned this matrix into an array of values 11 12 14 22 23", "tokens": [291, 600, 3574, 291, 600, 3574, 341, 8141, 666, 364, 10225, 295, 4190, 2975, 2272, 3499, 5853, 6673], "temperature": 0.0, "avg_logprob": -0.208031419205339, "compression_ratio": 1.6187845303867403, "no_speech_prob": 2.6270741727785207e-05}, {"id": 110, "seek": 82646, "start": 826.46, "end": 832.3000000000001, "text": " 25 31 and you what yeah you want to keep track of where you're switching from one", "tokens": [3552, 10353, 293, 291, 437, 1338, 291, 528, 281, 1066, 2837, 295, 689, 291, 434, 16493, 490, 472], "temperature": 0.0, "avg_logprob": -0.11505824121935614, "compression_ratio": 1.9608938547486034, "no_speech_prob": 3.3210573747055605e-05}, {"id": 111, "seek": 82646, "start": 832.3000000000001, "end": 837.62, "text": " row to another and so you're just kind of keeping track of okay we switch or", "tokens": [5386, 281, 1071, 293, 370, 291, 434, 445, 733, 295, 5145, 2837, 295, 1392, 321, 3679, 420], "temperature": 0.0, "avg_logprob": -0.11505824121935614, "compression_ratio": 1.9608938547486034, "no_speech_prob": 3.3210573747055605e-05}, {"id": 112, "seek": 82646, "start": 837.62, "end": 842.6600000000001, "text": " you know we started a row here at 11 then another row started at 22 another", "tokens": [291, 458, 321, 1409, 257, 5386, 510, 412, 2975, 550, 1071, 5386, 1409, 412, 5853, 1071], "temperature": 0.0, "avg_logprob": -0.11505824121935614, "compression_ratio": 1.9608938547486034, "no_speech_prob": 3.3210573747055605e-05}, {"id": 113, "seek": 82646, "start": 842.6600000000001, "end": 848.74, "text": " row started at 31 another row started at 42 and so we just need a pointer to those", "tokens": [5386, 1409, 412, 10353, 1071, 5386, 1409, 412, 14034, 293, 370, 321, 445, 643, 257, 23918, 281, 729], "temperature": 0.0, "avg_logprob": -0.11505824121935614, "compression_ratio": 1.9608938547486034, "no_speech_prob": 3.3210573747055605e-05}, {"id": 114, "seek": 84874, "start": 848.74, "end": 869.22, "text": " spots where a new row is starting actually okay let me go to you will like", "tokens": [10681, 689, 257, 777, 5386, 307, 2891, 767, 1392, 718, 385, 352, 281, 291, 486, 411], "temperature": 0.0, "avg_logprob": -0.14997317790985107, "compression_ratio": 1.1384615384615384, "no_speech_prob": 0.00015353319759014994}, {"id": 115, "seek": 86922, "start": 869.22, "end": 888.3000000000001, "text": " this table better Terrence so this table okay you're welcome any other questions", "tokens": [341, 3199, 1101, 6564, 10760, 370, 341, 3199, 1392, 291, 434, 2928, 604, 661, 1651], "temperature": 0.0, "avg_logprob": -0.15407311916351318, "compression_ratio": 1.3508771929824561, "no_speech_prob": 3.373265644768253e-05}, {"id": 116, "seek": 86922, "start": 888.3000000000001, "end": 895.38, "text": " about compressed storage or sparse arrays and so we didn't go into detail", "tokens": [466, 30353, 6725, 420, 637, 11668, 41011, 293, 370, 321, 994, 380, 352, 666, 2607], "temperature": 0.0, "avg_logprob": -0.15407311916351318, "compression_ratio": 1.3508771929824561, "no_speech_prob": 3.373265644768253e-05}, {"id": 117, "seek": 89538, "start": 895.38, "end": 902.1, "text": " on the compressed column storage but it's the exact same idea is compressed", "tokens": [322, 264, 30353, 7738, 6725, 457, 309, 311, 264, 1900, 912, 1558, 307, 30353], "temperature": 0.0, "avg_logprob": -0.1544849191393171, "compression_ratio": 1.6, "no_speech_prob": 1.1842277672258206e-05}, {"id": 118, "seek": 89538, "start": 902.1, "end": 909.14, "text": " row only you're keeping track of column pointers and it's fast to look up a", "tokens": [5386, 787, 291, 434, 5145, 2837, 295, 7738, 44548, 293, 309, 311, 2370, 281, 574, 493, 257], "temperature": 0.0, "avg_logprob": -0.1544849191393171, "compression_ratio": 1.6, "no_speech_prob": 1.1842277672258206e-05}, {"id": 119, "seek": 89538, "start": 909.14, "end": 914.26, "text": " particular column and but in that case it's slow to look up a row", "tokens": [1729, 7738, 293, 457, 294, 300, 1389, 309, 311, 2964, 281, 574, 493, 257, 5386], "temperature": 0.0, "avg_logprob": -0.1544849191393171, "compression_ratio": 1.6, "no_speech_prob": 1.1842277672258206e-05}, {"id": 120, "seek": 91426, "start": 914.26, "end": 929.34, "text": " Kelsey that's a good question I would have to look that up let me write that", "tokens": [44714, 300, 311, 257, 665, 1168, 286, 576, 362, 281, 574, 300, 493, 718, 385, 2464, 300], "temperature": 0.0, "avg_logprob": -0.1663975583182441, "compression_ratio": 1.353448275862069, "no_speech_prob": 1.1544348126335535e-06}, {"id": 121, "seek": 91426, "start": 929.34, "end": 939.5, "text": " down something also to remember is that converting between these types is linear", "tokens": [760, 746, 611, 281, 1604, 307, 300, 29942, 1296, 613, 3467, 307, 8213], "temperature": 0.0, "avg_logprob": -0.1663975583182441, "compression_ratio": 1.353448275862069, "no_speech_prob": 1.1544348126335535e-06}, {"id": 122, "seek": 93950, "start": 939.5, "end": 946.26, "text": " time so I think generally they kind of recommend converting if you're going to", "tokens": [565, 370, 286, 519, 5101, 436, 733, 295, 2748, 29942, 498, 291, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.24026148135845476, "compression_ratio": 1.5147058823529411, "no_speech_prob": 2.260203245896264e-06}, {"id": 123, "seek": 93950, "start": 946.26, "end": 950.54, "text": " yeah be looking up a lot of rows or looking up a lot of columns but I'll", "tokens": [1338, 312, 1237, 493, 257, 688, 295, 13241, 420, 1237, 493, 257, 688, 295, 13766, 457, 286, 603], "temperature": 0.0, "avg_logprob": -0.24026148135845476, "compression_ratio": 1.5147058823529411, "no_speech_prob": 2.260203245896264e-06}, {"id": 124, "seek": 93950, "start": 950.54, "end": 954.42, "text": " tell you the exact times next time", "tokens": [980, 291, 264, 1900, 1413, 958, 565], "temperature": 0.0, "avg_logprob": -0.24026148135845476, "compression_ratio": 1.5147058823529411, "no_speech_prob": 2.260203245896264e-06}, {"id": 125, "seek": 95442, "start": 954.42, "end": 973.9, "text": " any other questions I have this question so like once we know that we have sparse", "tokens": [604, 661, 1651, 286, 362, 341, 1168, 370, 411, 1564, 321, 458, 300, 321, 362, 637, 11668], "temperature": 0.0, "avg_logprob": -0.17882886747034585, "compression_ratio": 1.4375, "no_speech_prob": 0.00023363718355540186}, {"id": 126, "seek": 95442, "start": 973.9, "end": 981.3, "text": " matrix and we try to decide which format to use so like can we just look up for", "tokens": [8141, 293, 321, 853, 281, 4536, 597, 7877, 281, 764, 370, 411, 393, 321, 445, 574, 493, 337], "temperature": 0.0, "avg_logprob": -0.17882886747034585, "compression_ratio": 1.4375, "no_speech_prob": 0.00023363718355540186}, {"id": 127, "seek": 98130, "start": 981.3, "end": 986.5799999999999, "text": " every format like this format is better for matrix multiplication this form is", "tokens": [633, 7877, 411, 341, 7877, 307, 1101, 337, 8141, 27290, 341, 1254, 307], "temperature": 0.0, "avg_logprob": -0.18711382548014324, "compression_ratio": 1.9535864978902953, "no_speech_prob": 4.538745997706428e-05}, {"id": 128, "seek": 98130, "start": 986.5799999999999, "end": 991.66, "text": " better for like trying to get the inverse this form is better for like to", "tokens": [1101, 337, 411, 1382, 281, 483, 264, 17340, 341, 1254, 307, 1101, 337, 411, 281], "temperature": 0.0, "avg_logprob": -0.18711382548014324, "compression_ratio": 1.9535864978902953, "no_speech_prob": 4.538745997706428e-05}, {"id": 129, "seek": 98130, "start": 991.66, "end": 996.3, "text": " get in the transpose matrix omega this form is better for multiplying matrix by", "tokens": [483, 294, 264, 25167, 8141, 10498, 341, 1254, 307, 1101, 337, 30955, 8141, 538], "temperature": 0.0, "avg_logprob": -0.18711382548014324, "compression_ratio": 1.9535864978902953, "no_speech_prob": 4.538745997706428e-05}, {"id": 130, "seek": 98130, "start": 996.3, "end": 1001.66, "text": " columns or stuff like that yes you can just trade off yes so yeah different", "tokens": [13766, 420, 1507, 411, 300, 2086, 291, 393, 445, 4923, 766, 2086, 370, 1338, 819], "temperature": 0.0, "avg_logprob": -0.18711382548014324, "compression_ratio": 1.9535864978902953, "no_speech_prob": 4.538745997706428e-05}, {"id": 131, "seek": 98130, "start": 1001.66, "end": 1005.4599999999999, "text": " operations and I don't know if it um I think some of the things you listed will", "tokens": [7705, 293, 286, 500, 380, 458, 498, 309, 1105, 286, 519, 512, 295, 264, 721, 291, 10052, 486], "temperature": 0.0, "avg_logprob": -0.18711382548014324, "compression_ratio": 1.9535864978902953, "no_speech_prob": 4.538745997706428e-05}, {"id": 132, "seek": 98130, "start": 1005.4599999999999, "end": 1009.8599999999999, "text": " probably be equally good in both but yeah it's it's very dependent on what", "tokens": [1391, 312, 12309, 665, 294, 1293, 457, 1338, 309, 311, 309, 311, 588, 12334, 322, 437], "temperature": 0.0, "avg_logprob": -0.18711382548014324, "compression_ratio": 1.9535864978902953, "no_speech_prob": 4.538745997706428e-05}, {"id": 133, "seek": 100986, "start": 1009.86, "end": 1013.58, "text": " algorithm you're using and so particularly like looking at your code", "tokens": [9284, 291, 434, 1228, 293, 370, 4098, 411, 1237, 412, 428, 3089], "temperature": 0.0, "avg_logprob": -0.10362071133731457, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.6441250409116037e-05}, {"id": 134, "seek": 100986, "start": 1013.58, "end": 1019.3000000000001, "text": " as well of if kind of if you're accessing things by row or by column in a", "tokens": [382, 731, 295, 498, 733, 295, 498, 291, 434, 26440, 721, 538, 5386, 420, 538, 7738, 294, 257], "temperature": 0.0, "avg_logprob": -0.10362071133731457, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.6441250409116037e-05}, {"id": 135, "seek": 100986, "start": 1019.3000000000001, "end": 1027.38, "text": " loop that should be a factor and I've copied a little bit of yeah so here like", "tokens": [6367, 300, 820, 312, 257, 5952, 293, 286, 600, 25365, 257, 707, 857, 295, 1338, 370, 510, 411], "temperature": 0.0, "avg_logprob": -0.10362071133731457, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.6441250409116037e-05}, {"id": 136, "seek": 100986, "start": 1027.38, "end": 1031.1, "text": " the sci-pi documentation says that for multiplication or inversion it", "tokens": [264, 2180, 12, 22630, 14333, 1619, 300, 337, 27290, 420, 43576, 309], "temperature": 0.0, "avg_logprob": -0.10362071133731457, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.6441250409116037e-05}, {"id": 137, "seek": 100986, "start": 1031.1, "end": 1037.14, "text": " recommends either CSC or CSR so I think that those are probably equally good but", "tokens": [34556, 2139, 9460, 34, 420, 9460, 49, 370, 286, 519, 300, 729, 366, 1391, 12309, 665, 457], "temperature": 0.0, "avg_logprob": -0.10362071133731457, "compression_ratio": 1.5897435897435896, "no_speech_prob": 1.6441250409116037e-05}, {"id": 138, "seek": 103714, "start": 1037.14, "end": 1040.5800000000002, "text": " yeah if you're doing something else where you are you know looping through", "tokens": [1338, 498, 291, 434, 884, 746, 1646, 689, 291, 366, 291, 458, 6367, 278, 807], "temperature": 0.0, "avg_logprob": -0.13089611313559793, "compression_ratio": 1.7419354838709677, "no_speech_prob": 2.3686900476604933e-06}, {"id": 139, "seek": 103714, "start": 1040.5800000000002, "end": 1044.94, "text": " your rows or looping through your columns you'd want to think about that", "tokens": [428, 13241, 420, 6367, 278, 807, 428, 13766, 291, 1116, 528, 281, 519, 466, 300], "temperature": 0.0, "avg_logprob": -0.13089611313559793, "compression_ratio": 1.7419354838709677, "no_speech_prob": 2.3686900476604933e-06}, {"id": 140, "seek": 103714, "start": 1044.94, "end": 1053.0200000000002, "text": " you're welcome good question and then it also says COO I think is a good format", "tokens": [291, 434, 2928, 665, 1168, 293, 550, 309, 611, 1619, 3002, 46, 286, 519, 307, 257, 665, 7877], "temperature": 0.0, "avg_logprob": -0.13089611313559793, "compression_ratio": 1.7419354838709677, "no_speech_prob": 2.3686900476604933e-06}, {"id": 141, "seek": 103714, "start": 1053.0200000000002, "end": 1056.3400000000001, "text": " for constructing your matrices since you don't want to have to be calculating", "tokens": [337, 39969, 428, 32284, 1670, 291, 500, 380, 528, 281, 362, 281, 312, 28258], "temperature": 0.0, "avg_logprob": -0.13089611313559793, "compression_ratio": 1.7419354838709677, "no_speech_prob": 2.3686900476604933e-06}, {"id": 142, "seek": 103714, "start": 1056.3400000000001, "end": 1061.6200000000001, "text": " the row or column pointers yourself typically and it's it's efficient to", "tokens": [264, 5386, 420, 7738, 44548, 1803, 5850, 293, 309, 311, 309, 311, 7148, 281], "temperature": 0.0, "avg_logprob": -0.13089611313559793, "compression_ratio": 1.7419354838709677, "no_speech_prob": 2.3686900476604933e-06}, {"id": 143, "seek": 106162, "start": 1061.62, "end": 1069.58, "text": " convert then so kind of use COO to make your pass your matrix into to sci-pi", "tokens": [7620, 550, 370, 733, 295, 764, 3002, 46, 281, 652, 428, 1320, 428, 8141, 666, 281, 2180, 12, 22630], "temperature": 0.0, "avg_logprob": -0.19133453045861196, "compression_ratio": 1.425, "no_speech_prob": 2.6840355076274136e-06}, {"id": 144, "seek": 106162, "start": 1077.86, "end": 1084.4599999999998, "text": " okay yeah so we'll be using be using both broadcasting and sparse storage", "tokens": [1392, 1338, 370, 321, 603, 312, 1228, 312, 1228, 1293, 30024, 293, 637, 11668, 6725], "temperature": 0.0, "avg_logprob": -0.19133453045861196, "compression_ratio": 1.425, "no_speech_prob": 2.6840355076274136e-06}, {"id": 145, "seek": 106162, "start": 1084.4599999999998, "end": 1091.1399999999999, "text": " today and going back to this problem of CT scans and so I showed last time in", "tokens": [965, 293, 516, 646, 281, 341, 1154, 295, 19529, 35116, 293, 370, 286, 4712, 1036, 565, 294], "temperature": 0.0, "avg_logprob": -0.19133453045861196, "compression_ratio": 1.425, "no_speech_prob": 2.6840355076274136e-06}, {"id": 146, "seek": 109114, "start": 1091.14, "end": 1098.0200000000002, "text": " this article that I think is very nicely written and that's it starts with can", "tokens": [341, 7222, 300, 286, 519, 307, 588, 9594, 3720, 293, 300, 311, 309, 3719, 365, 393], "temperature": 0.0, "avg_logprob": -0.13043059800800524, "compression_ratio": 1.614213197969543, "no_speech_prob": 7.182543868111679e-06}, {"id": 147, "seek": 109114, "start": 1098.0200000000002, "end": 1103.3000000000002, "text": " math really save your life of course it can and then talking about kind of how", "tokens": [5221, 534, 3155, 428, 993, 295, 1164, 309, 393, 293, 550, 1417, 466, 733, 295, 577], "temperature": 0.0, "avg_logprob": -0.13043059800800524, "compression_ratio": 1.614213197969543, "no_speech_prob": 7.182543868111679e-06}, {"id": 148, "seek": 109114, "start": 1103.3000000000002, "end": 1114.22, "text": " CT scans work I want to try introducing this in a different way today so if you", "tokens": [19529, 35116, 589, 286, 528, 281, 853, 15424, 341, 294, 257, 819, 636, 965, 370, 498, 291], "temperature": 0.0, "avg_logprob": -0.13043059800800524, "compression_ratio": 1.614213197969543, "no_speech_prob": 7.182543868111679e-06}, {"id": 149, "seek": 109114, "start": 1114.22, "end": 1119.7800000000002, "text": " are actually kind of a working on CT scan data what would happen is you would be", "tokens": [366, 767, 733, 295, 257, 1364, 322, 19529, 11049, 1412, 437, 576, 1051, 307, 291, 576, 312], "temperature": 0.0, "avg_logprob": -0.13043059800800524, "compression_ratio": 1.614213197969543, "no_speech_prob": 7.182543868111679e-06}, {"id": 150, "seek": 111978, "start": 1119.78, "end": 1123.5, "text": " receiving some data that might like look like this on the left-hand side and", "tokens": [10040, 512, 1412, 300, 1062, 411, 574, 411, 341, 322, 264, 1411, 12, 5543, 1252, 293], "temperature": 0.0, "avg_logprob": -0.11514394494551647, "compression_ratio": 1.6956521739130435, "no_speech_prob": 6.048386239854153e-06}, {"id": 151, "seek": 111978, "start": 1123.5, "end": 1129.58, "text": " you're trying to reconstruct this full picture and the idea and so this is in", "tokens": [291, 434, 1382, 281, 31499, 341, 1577, 3036, 293, 264, 1558, 293, 370, 341, 307, 294], "temperature": 0.0, "avg_logprob": -0.11514394494551647, "compression_ratio": 1.6956521739130435, "no_speech_prob": 6.048386239854153e-06}, {"id": 152, "seek": 111978, "start": 1129.58, "end": 1135.34, "text": " real life this is usually 3d we're just going to be looking at a 2d picture and", "tokens": [957, 993, 341, 307, 2673, 805, 67, 321, 434, 445, 516, 281, 312, 1237, 412, 257, 568, 67, 3036, 293], "temperature": 0.0, "avg_logprob": -0.11514394494551647, "compression_ratio": 1.6956521739130435, "no_speech_prob": 6.048386239854153e-06}, {"id": 153, "seek": 111978, "start": 1135.34, "end": 1142.82, "text": " here the dimensions of this this is L width for both of them but then this is", "tokens": [510, 264, 12819, 295, 341, 341, 307, 441, 11402, 337, 1293, 295, 552, 457, 550, 341, 307], "temperature": 0.0, "avg_logprob": -0.11514394494551647, "compression_ratio": 1.6956521739130435, "no_speech_prob": 6.048386239854153e-06}, {"id": 154, "seek": 114282, "start": 1142.82, "end": 1150.3799999999999, "text": " just a seventh as tall what you started with and the idea is you know it seems", "tokens": [445, 257, 17875, 382, 6764, 437, 291, 1409, 365, 293, 264, 1558, 307, 291, 458, 309, 2544], "temperature": 0.0, "avg_logprob": -0.08135859455381121, "compression_ratio": 1.8509803921568628, "no_speech_prob": 1.696280378382653e-05}, {"id": 155, "seek": 114282, "start": 1150.3799999999999, "end": 1155.1, "text": " seems clear if you did a ton of x-rays of someone you know from every angle and", "tokens": [2544, 1850, 498, 291, 630, 257, 2952, 295, 2031, 12, 36212, 295, 1580, 291, 458, 490, 633, 5802, 293], "temperature": 0.0, "avg_logprob": -0.08135859455381121, "compression_ratio": 1.8509803921568628, "no_speech_prob": 1.696280378382653e-05}, {"id": 156, "seek": 114282, "start": 1155.1, "end": 1158.5, "text": " got all this data that you'd be able to reconstruct the original but you want to", "tokens": [658, 439, 341, 1412, 300, 291, 1116, 312, 1075, 281, 31499, 264, 3380, 457, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.08135859455381121, "compression_ratio": 1.8509803921568628, "no_speech_prob": 1.696280378382653e-05}, {"id": 157, "seek": 114282, "start": 1158.5, "end": 1162.02, "text": " limit how much radiation people are experiencing and so the idea is that", "tokens": [4948, 577, 709, 12420, 561, 366, 11139, 293, 370, 264, 1558, 307, 300], "temperature": 0.0, "avg_logprob": -0.08135859455381121, "compression_ratio": 1.8509803921568628, "no_speech_prob": 1.696280378382653e-05}, {"id": 158, "seek": 114282, "start": 1162.02, "end": 1167.7, "text": " we're kind of getting you know like much much smaller amount of data and want to", "tokens": [321, 434, 733, 295, 1242, 291, 458, 411, 709, 709, 4356, 2372, 295, 1412, 293, 528, 281], "temperature": 0.0, "avg_logprob": -0.08135859455381121, "compression_ratio": 1.8509803921568628, "no_speech_prob": 1.696280378382653e-05}, {"id": 159, "seek": 114282, "start": 1167.7, "end": 1172.46, "text": " reconstruct this picture that includes a larger amount of data so it's kind of", "tokens": [31499, 341, 3036, 300, 5974, 257, 4833, 2372, 295, 1412, 370, 309, 311, 733, 295], "temperature": 0.0, "avg_logprob": -0.08135859455381121, "compression_ratio": 1.8509803921568628, "no_speech_prob": 1.696280378382653e-05}, {"id": 160, "seek": 117246, "start": 1172.46, "end": 1175.7, "text": " like the opposite of data compression and that you're kind of starting with", "tokens": [411, 264, 6182, 295, 1412, 19355, 293, 300, 291, 434, 733, 295, 2891, 365], "temperature": 0.0, "avg_logprob": -0.10711531803525727, "compression_ratio": 1.8523809523809525, "no_speech_prob": 2.9020563943049638e-06}, {"id": 161, "seek": 117246, "start": 1175.7, "end": 1182.58, "text": " the smaller amount of data and need to uncompress it to get the full picture", "tokens": [264, 4356, 2372, 295, 1412, 293, 643, 281, 8585, 11637, 309, 281, 483, 264, 1577, 3036], "temperature": 0.0, "avg_logprob": -0.10711531803525727, "compression_ratio": 1.8523809523809525, "no_speech_prob": 2.9020563943049638e-06}, {"id": 162, "seek": 117246, "start": 1182.58, "end": 1189.5, "text": " and then it's also you're having to find kind of the meaning of yeah kind of what", "tokens": [293, 550, 309, 311, 611, 291, 434, 1419, 281, 915, 733, 295, 264, 3620, 295, 1338, 733, 295, 437], "temperature": 0.0, "avg_logprob": -0.10711531803525727, "compression_ratio": 1.8523809523809525, "no_speech_prob": 2.9020563943049638e-06}, {"id": 163, "seek": 117246, "start": 1189.5, "end": 1193.3, "text": " these measurements so these would be the measurements from different x-rays shot", "tokens": [613, 15383, 370, 613, 576, 312, 264, 15383, 490, 819, 2031, 12, 36212, 3347], "temperature": 0.0, "avg_logprob": -0.10711531803525727, "compression_ratio": 1.8523809523809525, "no_speech_prob": 2.9020563943049638e-06}, {"id": 164, "seek": 117246, "start": 1193.3, "end": 1198.06, "text": " at different angles and different locations and then getting back to okay", "tokens": [412, 819, 14708, 293, 819, 9253, 293, 550, 1242, 646, 281, 1392], "temperature": 0.0, "avg_logprob": -0.10711531803525727, "compression_ratio": 1.8523809523809525, "no_speech_prob": 2.9020563943049638e-06}, {"id": 165, "seek": 119806, "start": 1198.06, "end": 1206.1, "text": " what would that mean for the the picture there questions about kind of the setup", "tokens": [437, 576, 300, 914, 337, 264, 264, 3036, 456, 1651, 466, 733, 295, 264, 8657], "temperature": 0.0, "avg_logprob": -0.132860173119439, "compression_ratio": 1.7914691943127963, "no_speech_prob": 5.421915375336539e-06}, {"id": 166, "seek": 119806, "start": 1208.8999999999999, "end": 1213.6599999999999, "text": " and and so this problem since we're using we're gonna use data that we", "tokens": [293, 293, 370, 341, 1154, 1670, 321, 434, 1228, 321, 434, 799, 764, 1412, 300, 321], "temperature": 0.0, "avg_logprob": -0.132860173119439, "compression_ratio": 1.7914691943127963, "no_speech_prob": 5.421915375336539e-06}, {"id": 167, "seek": 119806, "start": 1213.6599999999999, "end": 1217.34, "text": " generate for the problem like we're gonna be building this picture it's", "tokens": [8460, 337, 264, 1154, 411, 321, 434, 799, 312, 2390, 341, 3036, 309, 311], "temperature": 0.0, "avg_logprob": -0.132860173119439, "compression_ratio": 1.7914691943127963, "no_speech_prob": 5.421915375336539e-06}, {"id": 168, "seek": 119806, "start": 1217.34, "end": 1222.06, "text": " different from a kind of real CT scan and that we first will have to make our", "tokens": [819, 490, 257, 733, 295, 957, 19529, 11049, 293, 300, 321, 700, 486, 362, 281, 652, 527], "temperature": 0.0, "avg_logprob": -0.132860173119439, "compression_ratio": 1.7914691943127963, "no_speech_prob": 5.421915375336539e-06}, {"id": 169, "seek": 119806, "start": 1222.06, "end": 1226.02, "text": " data then get what the measurements would be and then we're seeing if we can", "tokens": [1412, 550, 483, 437, 264, 15383, 576, 312, 293, 550, 321, 434, 2577, 498, 321, 393], "temperature": 0.0, "avg_logprob": -0.132860173119439, "compression_ratio": 1.7914691943127963, "no_speech_prob": 5.421915375336539e-06}, {"id": 170, "seek": 122602, "start": 1226.02, "end": 1238.3799999999999, "text": " reconstruct the original just from these measurements yeah and so I'm gonna show", "tokens": [31499, 264, 3380, 445, 490, 613, 15383, 1338, 293, 370, 286, 478, 799, 855], "temperature": 0.0, "avg_logprob": -0.1249961079777898, "compression_ratio": 1.5939086294416243, "no_speech_prob": 5.9548488025029656e-06}, {"id": 171, "seek": 122602, "start": 1238.3799999999999, "end": 1244.5, "text": " some some pictures but I kind of what it'll look like is that an x-ray shot at", "tokens": [512, 512, 5242, 457, 286, 733, 295, 437, 309, 603, 574, 411, 307, 300, 364, 2031, 12, 3458, 3347, 412], "temperature": 0.0, "avg_logprob": -0.1249961079777898, "compression_ratio": 1.5939086294416243, "no_speech_prob": 5.9548488025029656e-06}, {"id": 172, "seek": 122602, "start": 1244.5, "end": 1248.66, "text": " a particular angle and a particular location you're just gonna get a single", "tokens": [257, 1729, 5802, 293, 257, 1729, 4914, 291, 434, 445, 799, 483, 257, 2167], "temperature": 0.0, "avg_logprob": -0.1249961079777898, "compression_ratio": 1.5939086294416243, "no_speech_prob": 5.9548488025029656e-06}, {"id": 173, "seek": 122602, "start": 1248.66, "end": 1252.1399999999999, "text": " number from that so you know here we have a line intersecting with our picture", "tokens": [1230, 490, 300, 370, 291, 458, 510, 321, 362, 257, 1622, 27815, 278, 365, 527, 3036], "temperature": 0.0, "avg_logprob": -0.1249961079777898, "compression_ratio": 1.5939086294416243, "no_speech_prob": 5.9548488025029656e-06}, {"id": 174, "seek": 125214, "start": 1252.14, "end": 1257.74, "text": " and that would result in just one number so kind of one pixel in this left-hand", "tokens": [293, 300, 576, 1874, 294, 445, 472, 1230, 370, 733, 295, 472, 19261, 294, 341, 1411, 12, 5543], "temperature": 0.0, "avg_logprob": -0.08273420333862305, "compression_ratio": 1.6134020618556701, "no_speech_prob": 3.041435320483288e-06}, {"id": 175, "seek": 125214, "start": 1257.74, "end": 1266.8200000000002, "text": " side of our measurements and then this is a kind of brief review so from the", "tokens": [1252, 295, 527, 15383, 293, 550, 341, 307, 257, 733, 295, 5353, 3131, 370, 490, 264], "temperature": 0.0, "avg_logprob": -0.08273420333862305, "compression_ratio": 1.6134020618556701, "no_speech_prob": 3.041435320483288e-06}, {"id": 176, "seek": 125214, "start": 1266.8200000000002, "end": 1273.7, "text": " background removal lesson that was background removal using robust PCA was", "tokens": [3678, 17933, 6898, 300, 390, 3678, 17933, 1228, 13956, 6465, 32, 390], "temperature": 0.0, "avg_logprob": -0.08273420333862305, "compression_ratio": 1.6134020618556701, "no_speech_prob": 3.041435320483288e-06}, {"id": 177, "seek": 125214, "start": 1273.7, "end": 1280.38, "text": " written as this optimization problem and do you remember what's special about the", "tokens": [3720, 382, 341, 19618, 1154, 293, 360, 291, 1604, 437, 311, 2121, 466, 264], "temperature": 0.0, "avg_logprob": -0.08273420333862305, "compression_ratio": 1.6134020618556701, "no_speech_prob": 3.041435320483288e-06}, {"id": 178, "seek": 128038, "start": 1280.38, "end": 1292.0200000000002, "text": " L1 norm? Shout it out. Yeah it shrinks things to zero resulting in a sparse", "tokens": [441, 16, 2026, 30, 32749, 309, 484, 13, 865, 309, 9884, 16431, 721, 281, 4018, 16505, 294, 257, 637, 11668], "temperature": 0.0, "avg_logprob": -0.22027120590209961, "compression_ratio": 1.5906735751295338, "no_speech_prob": 1.922218143590726e-05}, {"id": 179, "seek": 128038, "start": 1292.0200000000002, "end": 1296.0600000000002, "text": " solution right so it induces sparsity because yeah it's kind of pushing", "tokens": [3827, 558, 370, 309, 13716, 887, 637, 685, 507, 570, 1338, 309, 311, 733, 295, 7380], "temperature": 0.0, "avg_logprob": -0.22027120590209961, "compression_ratio": 1.5906735751295338, "no_speech_prob": 1.922218143590726e-05}, {"id": 180, "seek": 128038, "start": 1296.0600000000002, "end": 1302.0600000000002, "text": " pushing many of the coefficients to zero and so you'll notice this this picture", "tokens": [7380, 867, 295, 264, 31994, 281, 4018, 293, 370, 291, 603, 3449, 341, 341, 3036], "temperature": 0.0, "avg_logprob": -0.22027120590209961, "compression_ratio": 1.5906735751295338, "no_speech_prob": 1.922218143590726e-05}, {"id": 181, "seek": 130206, "start": 1302.06, "end": 1316.34, "text": " that we'll be trying to construct is sparse so we'll be using the L1 norm today.", "tokens": [300, 321, 603, 312, 1382, 281, 7690, 307, 637, 11668, 370, 321, 603, 312, 1228, 264, 441, 16, 2026, 965, 13], "temperature": 0.0, "avg_logprob": -0.23765720755366956, "compression_ratio": 1.4736842105263157, "no_speech_prob": 4.157206603849772e-06}, {"id": 182, "seek": 130206, "start": 1316.34, "end": 1321.06, "text": " Okay so the first part of this is just generating the data and I think", "tokens": [1033, 370, 264, 700, 644, 295, 341, 307, 445, 17746, 264, 1412, 293, 286, 519], "temperature": 0.0, "avg_logprob": -0.23765720755366956, "compression_ratio": 1.4736842105263157, "no_speech_prob": 4.157206603849772e-06}, {"id": 183, "seek": 130206, "start": 1321.06, "end": 1328.54, "text": " this uses some interesting numpy methods that some of them I hadn't even", "tokens": [341, 4960, 512, 1880, 1031, 8200, 7150, 300, 512, 295, 552, 286, 8782, 380, 754], "temperature": 0.0, "avg_logprob": -0.23765720755366956, "compression_ratio": 1.4736842105263157, "no_speech_prob": 4.157206603849772e-06}, {"id": 184, "seek": 132854, "start": 1328.54, "end": 1334.34, "text": " seen before so I think it's an interesting process again if you were", "tokens": [1612, 949, 370, 286, 519, 309, 311, 364, 1880, 1399, 797, 498, 291, 645], "temperature": 0.0, "avg_logprob": -0.09827708553623508, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.3006390872760676e-05}, {"id": 185, "seek": 132854, "start": 1334.34, "end": 1343.8999999999999, "text": " really working with CT scans you're not building your own fake data set and so", "tokens": [534, 1364, 365, 19529, 35116, 291, 434, 406, 2390, 428, 1065, 7592, 1412, 992, 293, 370], "temperature": 0.0, "avg_logprob": -0.09827708553623508, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.3006390872760676e-05}, {"id": 186, "seek": 132854, "start": 1343.8999999999999, "end": 1348.82, "text": " here we're choosing 128 for the dimension so this is 128 by 128 and I'm", "tokens": [510, 321, 434, 10875, 29810, 337, 264, 10139, 370, 341, 307, 29810, 538, 29810, 293, 286, 478], "temperature": 0.0, "avg_logprob": -0.09827708553623508, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.3006390872760676e-05}, {"id": 187, "seek": 132854, "start": 1348.82, "end": 1356.26, "text": " gonna kind of walk through what this code is doing oops so this is the whole the", "tokens": [799, 733, 295, 1792, 807, 437, 341, 3089, 307, 884, 34166, 370, 341, 307, 264, 1379, 264], "temperature": 0.0, "avg_logprob": -0.09827708553623508, "compression_ratio": 1.5463917525773196, "no_speech_prob": 1.3006390872760676e-05}, {"id": 188, "seek": 135626, "start": 1356.26, "end": 1362.26, "text": " whole method for generating synthetic data this will return kind of one", "tokens": [1379, 3170, 337, 17746, 23420, 1412, 341, 486, 2736, 733, 295, 472], "temperature": 0.0, "avg_logprob": -0.21593974696265328, "compression_ratio": 1.5894736842105264, "no_speech_prob": 5.954944299446652e-06}, {"id": 189, "seek": 135626, "start": 1362.26, "end": 1372.34, "text": " square like this but we'll walk through that more slowly and to walk through it", "tokens": [3732, 411, 341, 457, 321, 603, 1792, 807, 300, 544, 5692, 293, 281, 1792, 807, 309], "temperature": 0.0, "avg_logprob": -0.21593974696265328, "compression_ratio": 1.5894736842105264, "no_speech_prob": 5.954944299446652e-06}, {"id": 190, "seek": 135626, "start": 1372.34, "end": 1376.3799999999999, "text": " I'm gonna go through kind of a smaller example of just creating an 8 by 8", "tokens": [286, 478, 799, 352, 807, 733, 295, 257, 4356, 1365, 295, 445, 4084, 364, 1649, 538, 1649], "temperature": 0.0, "avg_logprob": -0.21593974696265328, "compression_ratio": 1.5894736842105264, "no_speech_prob": 5.954944299446652e-06}, {"id": 191, "seek": 135626, "start": 1376.3799999999999, "end": 1385.54, "text": " picture that has five points and we'll see what the points mean in a moment.", "tokens": [3036, 300, 575, 1732, 2793, 293, 321, 603, 536, 437, 264, 2793, 914, 294, 257, 1623, 13], "temperature": 0.0, "avg_logprob": -0.21593974696265328, "compression_ratio": 1.5894736842105264, "no_speech_prob": 5.954944299446652e-06}, {"id": 192, "seek": 138554, "start": 1385.54, "end": 1391.74, "text": " But that'll give you kind of the the density of the data set of those white", "tokens": [583, 300, 603, 976, 291, 733, 295, 264, 264, 10305, 295, 264, 1412, 992, 295, 729, 2418], "temperature": 0.0, "avg_logprob": -0.1719059467315674, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.7693010906659765e-06}, {"id": 193, "seek": 138554, "start": 1391.74, "end": 1401.3799999999999, "text": " circles. So there's a numpy a numpy method called oGrid that returns", "tokens": [13040, 13, 407, 456, 311, 257, 1031, 8200, 257, 1031, 8200, 3170, 1219, 277, 38, 8558, 300, 11247], "temperature": 0.0, "avg_logprob": -0.1719059467315674, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.7693010906659765e-06}, {"id": 194, "seek": 138554, "start": 1401.3799999999999, "end": 1407.78, "text": " returns something as a column and as a row and so here we're getting the", "tokens": [11247, 746, 382, 257, 7738, 293, 382, 257, 5386, 293, 370, 510, 321, 434, 1242, 264], "temperature": 0.0, "avg_logprob": -0.1719059467315674, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.7693010906659765e-06}, {"id": 195, "seek": 138554, "start": 1407.78, "end": 1414.62, "text": " numbers 0 to 7 as a column and as a row back and then this is that this is", "tokens": [3547, 1958, 281, 1614, 382, 257, 7738, 293, 382, 257, 5386, 646, 293, 550, 341, 307, 300, 341, 307], "temperature": 0.0, "avg_logprob": -0.1719059467315674, "compression_ratio": 1.7076023391812865, "no_speech_prob": 2.7693010906659765e-06}, {"id": 196, "seek": 141462, "start": 1414.62, "end": 1417.54, "text": " actually going to be very handy in a moment we're gonna use broadcasting with", "tokens": [767, 516, 281, 312, 588, 13239, 294, 257, 1623, 321, 434, 799, 764, 30024, 365], "temperature": 0.0, "avg_logprob": -0.11534307440932916, "compression_ratio": 1.8737864077669903, "no_speech_prob": 2.684112587303389e-06}, {"id": 197, "seek": 141462, "start": 1417.54, "end": 1422.9799999999998, "text": " this so we want to end up getting something that's 7 by 7 or sorry 8 by 8", "tokens": [341, 370, 321, 528, 281, 917, 493, 1242, 746, 300, 311, 1614, 538, 1614, 420, 2597, 1649, 538, 1649], "temperature": 0.0, "avg_logprob": -0.11534307440932916, "compression_ratio": 1.8737864077669903, "no_speech_prob": 2.684112587303389e-06}, {"id": 198, "seek": 141462, "start": 1422.9799999999998, "end": 1427.8999999999999, "text": " so we're kind of getting this row and column and we can do some operations and", "tokens": [370, 321, 434, 733, 295, 1242, 341, 5386, 293, 7738, 293, 321, 393, 360, 512, 7705, 293], "temperature": 0.0, "avg_logprob": -0.11534307440932916, "compression_ratio": 1.8737864077669903, "no_speech_prob": 2.684112587303389e-06}, {"id": 199, "seek": 141462, "start": 1427.8999999999999, "end": 1431.4199999999998, "text": " together with broadcasting that's gonna go from you know having something that", "tokens": [1214, 365, 30024, 300, 311, 799, 352, 490, 291, 458, 1419, 746, 300], "temperature": 0.0, "avg_logprob": -0.11534307440932916, "compression_ratio": 1.8737864077669903, "no_speech_prob": 2.684112587303389e-06}, {"id": 200, "seek": 141462, "start": 1431.4199999999998, "end": 1439.26, "text": " is 8 by 1 and 1 by 8 to something that's 8 by 8 that's kind of a handy handy", "tokens": [307, 1649, 538, 502, 293, 502, 538, 1649, 281, 746, 300, 311, 1649, 538, 1649, 300, 311, 733, 295, 257, 13239, 13239], "temperature": 0.0, "avg_logprob": -0.11534307440932916, "compression_ratio": 1.8737864077669903, "no_speech_prob": 2.684112587303389e-06}, {"id": 201, "seek": 143926, "start": 1439.26, "end": 1444.98, "text": " trick and so this is basically kind of like the equation for a circle we're", "tokens": [4282, 293, 370, 341, 307, 1936, 733, 295, 411, 264, 5367, 337, 257, 6329, 321, 434], "temperature": 0.0, "avg_logprob": -0.09201080282938849, "compression_ratio": 1.7625570776255708, "no_speech_prob": 1.1188957387275877e-06}, {"id": 202, "seek": 143926, "start": 1444.98, "end": 1451.02, "text": " saying X minus a center point squared plus Y minus a center point squared and", "tokens": [1566, 1783, 3175, 257, 3056, 935, 8889, 1804, 398, 3175, 257, 3056, 935, 8889, 293], "temperature": 0.0, "avg_logprob": -0.09201080282938849, "compression_ratio": 1.7625570776255708, "no_speech_prob": 1.1188957387275877e-06}, {"id": 203, "seek": 143926, "start": 1451.02, "end": 1457.18, "text": " we get and then kind of combining that with broadcasting so the X part of the", "tokens": [321, 483, 293, 550, 733, 295, 21928, 300, 365, 30024, 370, 264, 1783, 644, 295, 264], "temperature": 0.0, "avg_logprob": -0.09201080282938849, "compression_ratio": 1.7625570776255708, "no_speech_prob": 1.1188957387275877e-06}, {"id": 204, "seek": 143926, "start": 1457.18, "end": 1461.82, "text": " equation is still just going to be you know this 8 by 1 column the Y part is", "tokens": [5367, 307, 920, 445, 516, 281, 312, 291, 458, 341, 1649, 538, 502, 7738, 264, 398, 644, 307], "temperature": 0.0, "avg_logprob": -0.09201080282938849, "compression_ratio": 1.7625570776255708, "no_speech_prob": 1.1188957387275877e-06}, {"id": 205, "seek": 143926, "start": 1461.82, "end": 1469.02, "text": " this 1 by 8 row and when we add those together we get an 8 by 8 grid and this", "tokens": [341, 502, 538, 1649, 5386, 293, 562, 321, 909, 729, 1214, 321, 483, 364, 1649, 538, 1649, 10748, 293, 341], "temperature": 0.0, "avg_logprob": -0.09201080282938849, "compression_ratio": 1.7625570776255708, "no_speech_prob": 1.1188957387275877e-06}, {"id": 206, "seek": 146902, "start": 1469.02, "end": 1474.3, "text": " kind of has a density of being zero at the center and then getting larger as", "tokens": [733, 295, 575, 257, 10305, 295, 885, 4018, 412, 264, 3056, 293, 550, 1242, 4833, 382], "temperature": 0.0, "avg_logprob": -0.38560118765201207, "compression_ratio": 1.404109589041096, "no_speech_prob": 6.338797447824618e-06}, {"id": 207, "seek": 146902, "start": 1474.3, "end": 1481.22, "text": " you go further away since we're using the circular equation. Are there questions about this?", "tokens": [291, 352, 3052, 1314, 1670, 321, 434, 1228, 264, 16476, 5367, 13, 2014, 456, 1651, 466, 341, 30], "temperature": 0.0, "avg_logprob": -0.38560118765201207, "compression_ratio": 1.404109589041096, "no_speech_prob": 6.338797447824618e-06}, {"id": 208, "seek": 146902, "start": 1481.22, "end": 1486.22, "text": " Jeremy?", "tokens": [17809, 30], "temperature": 0.0, "avg_logprob": -0.38560118765201207, "compression_ratio": 1.404109589041096, "no_speech_prob": 6.338797447824618e-06}, {"id": 209, "seek": 148622, "start": 1486.22, "end": 1503.5, "text": " Oh yes that's a great idea.", "tokens": [876, 2086, 300, 311, 257, 869, 1558, 13], "temperature": 0.0, "avg_logprob": -0.27431729782459346, "compression_ratio": 1.375, "no_speech_prob": 1.6186189895961434e-05}, {"id": 210, "seek": 148622, "start": 1503.5, "end": 1507.98, "text": " And here since zero is the first entry of both you can kind of see the original", "tokens": [400, 510, 1670, 4018, 307, 264, 700, 8729, 295, 1293, 291, 393, 733, 295, 536, 264, 3380], "temperature": 0.0, "avg_logprob": -0.27431729782459346, "compression_ratio": 1.375, "no_speech_prob": 1.6186189895961434e-05}, {"id": 211, "seek": 150798, "start": 1507.98, "end": 1530.54, "text": " X in the first column and the original Y here.", "tokens": [1783, 294, 264, 700, 7738, 293, 264, 3380, 398, 510, 13], "temperature": 0.0, "avg_logprob": -0.20662249288251322, "compression_ratio": 1.2115384615384615, "no_speech_prob": 3.7633722968166694e-05}, {"id": 212, "seek": 150798, "start": 1530.54, "end": 1535.42, "text": " Okay so now we're constructing something called mask outer and basically that's", "tokens": [1033, 370, 586, 321, 434, 39969, 746, 1219, 6094, 10847, 293, 1936, 300, 311], "temperature": 0.0, "avg_logprob": -0.20662249288251322, "compression_ratio": 1.2115384615384615, "no_speech_prob": 3.7633722968166694e-05}, {"id": 213, "seek": 153542, "start": 1535.42, "end": 1539.5, "text": " because we're just going to be kind of interested in this center and the kind", "tokens": [570, 321, 434, 445, 516, 281, 312, 733, 295, 3102, 294, 341, 3056, 293, 264, 733], "temperature": 0.0, "avg_logprob": -0.10434406682064659, "compression_ratio": 1.8364485981308412, "no_speech_prob": 4.8602796596242115e-06}, {"id": 214, "seek": 153542, "start": 1539.5, "end": 1544.54, "text": " of the center of our picture and I think this is kind of fitting with the idea of", "tokens": [295, 264, 3056, 295, 527, 3036, 293, 286, 519, 341, 307, 733, 295, 15669, 365, 264, 1558, 295], "temperature": 0.0, "avg_logprob": -0.10434406682064659, "compression_ratio": 1.8364485981308412, "no_speech_prob": 4.8602796596242115e-06}, {"id": 215, "seek": 153542, "start": 1544.54, "end": 1549.66, "text": " you know if you thought about doing a CT scan of someone's you know someone's", "tokens": [291, 458, 498, 291, 1194, 466, 884, 257, 19529, 11049, 295, 1580, 311, 291, 458, 1580, 311], "temperature": 0.0, "avg_logprob": -0.10434406682064659, "compression_ratio": 1.8364485981308412, "no_speech_prob": 4.8602796596242115e-06}, {"id": 216, "seek": 153542, "start": 1549.66, "end": 1553.9, "text": " torso that you're kind of getting this like circular cross-section is what", "tokens": [34917, 300, 291, 434, 733, 295, 1242, 341, 411, 16476, 3278, 12, 11963, 307, 437], "temperature": 0.0, "avg_logprob": -0.10434406682064659, "compression_ratio": 1.8364485981308412, "no_speech_prob": 4.8602796596242115e-06}, {"id": 217, "seek": 153542, "start": 1553.9, "end": 1560.22, "text": " we're getting here so we're just adding an inequality so kind of taking you know", "tokens": [321, 434, 1242, 510, 370, 321, 434, 445, 5127, 364, 16970, 370, 733, 295, 1940, 291, 458], "temperature": 0.0, "avg_logprob": -0.10434406682064659, "compression_ratio": 1.8364485981308412, "no_speech_prob": 4.8602796596242115e-06}, {"id": 218, "seek": 156022, "start": 1560.22, "end": 1567.38, "text": " our XY grid and then seeing when it's less than this radius squared that gives", "tokens": [527, 48826, 10748, 293, 550, 2577, 562, 309, 311, 1570, 813, 341, 15845, 8889, 300, 2709], "temperature": 0.0, "avg_logprob": -0.130495974222819, "compression_ratio": 1.505, "no_speech_prob": 2.642499339344795e-06}, {"id": 219, "seek": 156022, "start": 1567.38, "end": 1574.14, "text": " us this outer mask which is kind of a you know a ball of trues surrounded with", "tokens": [505, 341, 10847, 6094, 597, 307, 733, 295, 257, 291, 458, 257, 2594, 295, 504, 1247, 13221, 365], "temperature": 0.0, "avg_logprob": -0.130495974222819, "compression_ratio": 1.505, "no_speech_prob": 2.642499339344795e-06}, {"id": 220, "seek": 156022, "start": 1574.14, "end": 1582.06, "text": " false at the border. And this is also important I should say I guess because", "tokens": [7908, 412, 264, 7838, 13, 400, 341, 307, 611, 1021, 286, 820, 584, 286, 2041, 570], "temperature": 0.0, "avg_logprob": -0.130495974222819, "compression_ratio": 1.505, "no_speech_prob": 2.642499339344795e-06}, {"id": 221, "seek": 156022, "start": 1582.06, "end": 1585.66, "text": " the the X-ray will be coming at different angles like this kind of", "tokens": [264, 264, 1783, 12, 3458, 486, 312, 1348, 412, 819, 14708, 411, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.130495974222819, "compression_ratio": 1.505, "no_speech_prob": 2.642499339344795e-06}, {"id": 222, "seek": 158566, "start": 1585.66, "end": 1592.94, "text": " ensures that it's going through the same amount of you know person being X-rayed", "tokens": [28111, 300, 309, 311, 516, 807, 264, 912, 2372, 295, 291, 458, 954, 885, 1783, 12, 3458, 292], "temperature": 0.0, "avg_logprob": -0.11270211605315512, "compression_ratio": 1.641350210970464, "no_speech_prob": 6.854200819361722e-06}, {"id": 223, "seek": 158566, "start": 1592.94, "end": 1599.94, "text": " kind of from each angle the X-rays traveling a similar distance. So we take", "tokens": [733, 295, 490, 1184, 5802, 264, 1783, 12, 36212, 9712, 257, 2531, 4560, 13, 407, 321, 747], "temperature": 0.0, "avg_logprob": -0.11270211605315512, "compression_ratio": 1.641350210970464, "no_speech_prob": 6.854200819361722e-06}, {"id": 224, "seek": 158566, "start": 1599.94, "end": 1605.8200000000002, "text": " that mask oh no so that's our outer mask and then we're constructing something", "tokens": [300, 6094, 1954, 572, 370, 300, 311, 527, 10847, 6094, 293, 550, 321, 434, 39969, 746], "temperature": 0.0, "avg_logprob": -0.11270211605315512, "compression_ratio": 1.641350210970464, "no_speech_prob": 6.854200819361722e-06}, {"id": 225, "seek": 158566, "start": 1605.8200000000002, "end": 1611.14, "text": " called mask where we just randomly generate some points in a 2d grid and so", "tokens": [1219, 6094, 689, 321, 445, 16979, 8460, 512, 2793, 294, 257, 568, 67, 10748, 293, 370], "temperature": 0.0, "avg_logprob": -0.11270211605315512, "compression_ratio": 1.641350210970464, "no_speech_prob": 6.854200819361722e-06}, {"id": 226, "seek": 158566, "start": 1611.14, "end": 1615.18, "text": " that was a parameter earlier kind of how many points we wanted to generate in", "tokens": [300, 390, 257, 13075, 3071, 733, 295, 577, 867, 2793, 321, 1415, 281, 8460, 294], "temperature": 0.0, "avg_logprob": -0.11270211605315512, "compression_ratio": 1.641350210970464, "no_speech_prob": 6.854200819361722e-06}, {"id": 227, "seek": 161518, "start": 1615.18, "end": 1619.5, "text": " this case it's five so we've still got something eight by eight and it's all", "tokens": [341, 1389, 309, 311, 1732, 370, 321, 600, 920, 658, 746, 3180, 538, 3180, 293, 309, 311, 439], "temperature": 0.0, "avg_logprob": -0.1414377962956663, "compression_ratio": 1.5570469798657718, "no_speech_prob": 8.013108526938595e-06}, {"id": 228, "seek": 161518, "start": 1619.5, "end": 1629.78, "text": " zeros with five ones. And we can plot what that looks like so here we're just", "tokens": [35193, 365, 1732, 2306, 13, 400, 321, 393, 7542, 437, 300, 1542, 411, 370, 510, 321, 434, 445], "temperature": 0.0, "avg_logprob": -0.1414377962956663, "compression_ratio": 1.5570469798657718, "no_speech_prob": 8.013108526938595e-06}, {"id": 229, "seek": 161518, "start": 1629.78, "end": 1639.94, "text": " plotting kind of each each point is a pixel zero or one and we have five five", "tokens": [41178, 733, 295, 1184, 1184, 935, 307, 257, 19261, 4018, 420, 472, 293, 321, 362, 1732, 1732], "temperature": 0.0, "avg_logprob": -0.1414377962956663, "compression_ratio": 1.5570469798657718, "no_speech_prob": 8.013108526938595e-06}, {"id": 230, "seek": 163994, "start": 1639.94, "end": 1649.3, "text": " white boxes. We'll use a Gaussian filter then to kind of blur that so that's kind", "tokens": [2418, 9002, 13, 492, 603, 764, 257, 39148, 6608, 550, 281, 733, 295, 14257, 300, 370, 300, 311, 733], "temperature": 0.0, "avg_logprob": -0.12651719585541757, "compression_ratio": 1.5354838709677419, "no_speech_prob": 2.156773689421243e-06}, {"id": 231, "seek": 163994, "start": 1649.3, "end": 1661.38, "text": " of going around these places but making it a bit more kind of continuous. And", "tokens": [295, 516, 926, 613, 3190, 457, 1455, 309, 257, 857, 544, 733, 295, 10957, 13, 400], "temperature": 0.0, "avg_logprob": -0.12651719585541757, "compression_ratio": 1.5354838709677419, "no_speech_prob": 2.156773689421243e-06}, {"id": 232, "seek": 163994, "start": 1661.38, "end": 1665.26, "text": " this is I mean some of this is you know this is specific to kind of like we're", "tokens": [341, 307, 286, 914, 512, 295, 341, 307, 291, 458, 341, 307, 2685, 281, 733, 295, 411, 321, 434], "temperature": 0.0, "avg_logprob": -0.12651719585541757, "compression_ratio": 1.5354838709677419, "no_speech_prob": 2.156773689421243e-06}, {"id": 233, "seek": 166526, "start": 1665.26, "end": 1673.18, "text": " trying to get these like globby looking shapes in our in our data. Here we", "tokens": [1382, 281, 483, 613, 411, 16125, 2322, 1237, 10854, 294, 527, 294, 527, 1412, 13, 1692, 321], "temperature": 0.0, "avg_logprob": -0.11648954104070794, "compression_ratio": 1.5968586387434556, "no_speech_prob": 3.1380388918478275e-06}, {"id": 234, "seek": 166526, "start": 1673.18, "end": 1679.86, "text": " combine seeing when so now we've kind of gotten this Gaussian filter version", "tokens": [10432, 2577, 562, 370, 586, 321, 600, 733, 295, 5768, 341, 39148, 6608, 3037], "temperature": 0.0, "avg_logprob": -0.11648954104070794, "compression_ratio": 1.5968586387434556, "no_speech_prob": 3.1380388918478275e-06}, {"id": 235, "seek": 166526, "start": 1679.86, "end": 1684.58, "text": " we're just going to take the parts of that that are greater than the mean for", "tokens": [321, 434, 445, 516, 281, 747, 264, 3166, 295, 300, 300, 366, 5044, 813, 264, 914, 337], "temperature": 0.0, "avg_logprob": -0.11648954104070794, "compression_ratio": 1.5968586387434556, "no_speech_prob": 3.1380388918478275e-06}, {"id": 236, "seek": 166526, "start": 1684.58, "end": 1690.9, "text": " it and then also when when those points lie inside that inner circle and so", "tokens": [309, 293, 550, 611, 562, 562, 729, 2793, 4544, 1854, 300, 7284, 6329, 293, 370], "temperature": 0.0, "avg_logprob": -0.11648954104070794, "compression_ratio": 1.5968586387434556, "no_speech_prob": 3.1380388918478275e-06}, {"id": 237, "seek": 169090, "start": 1690.9, "end": 1707.18, "text": " that's what this is. And then actually I should um maybe pull up ND image well", "tokens": [300, 311, 437, 341, 307, 13, 400, 550, 767, 286, 820, 1105, 1310, 2235, 493, 40709, 3256, 731], "temperature": 0.0, "avg_logprob": -0.14229989980722402, "compression_ratio": 1.526829268292683, "no_speech_prob": 4.565651579468977e-06}, {"id": 238, "seek": 169090, "start": 1707.18, "end": 1711.0600000000002, "text": " I'll come back to that in a moment. We're kind of using this additional library", "tokens": [286, 603, 808, 646, 281, 300, 294, 257, 1623, 13, 492, 434, 733, 295, 1228, 341, 4497, 6405], "temperature": 0.0, "avg_logprob": -0.14229989980722402, "compression_ratio": 1.526829268292683, "no_speech_prob": 4.565651579468977e-06}, {"id": 239, "seek": 169090, "start": 1711.0600000000002, "end": 1715.8600000000001, "text": " here is where we get this binary erosion feature from and this is just picking", "tokens": [510, 307, 689, 321, 483, 341, 17434, 32173, 4111, 490, 293, 341, 307, 445, 8867], "temperature": 0.0, "avg_logprob": -0.14229989980722402, "compression_ratio": 1.526829268292683, "no_speech_prob": 4.565651579468977e-06}, {"id": 240, "seek": 169090, "start": 1715.8600000000001, "end": 1719.5400000000002, "text": " out the middle so kind of this was our whole thing we want to separate that", "tokens": [484, 264, 2808, 370, 733, 295, 341, 390, 527, 1379, 551, 321, 528, 281, 4994, 300], "temperature": 0.0, "avg_logprob": -0.14229989980722402, "compression_ratio": 1.526829268292683, "no_speech_prob": 4.565651579468977e-06}, {"id": 241, "seek": 171954, "start": 1719.54, "end": 1727.46, "text": " into what was the middle and what was the exterior. And so this is how we make", "tokens": [666, 437, 390, 264, 2808, 293, 437, 390, 264, 20677, 13, 400, 370, 341, 307, 577, 321, 652], "temperature": 0.0, "avg_logprob": -0.15321787198384604, "compression_ratio": 1.761467889908257, "no_speech_prob": 6.64319668430835e-06}, {"id": 242, "seek": 171954, "start": 1727.46, "end": 1731.54, "text": " yeah kind of make those globs that you saw and this is a more pixelated", "tokens": [1338, 733, 295, 652, 729, 3114, 929, 300, 291, 1866, 293, 341, 307, 257, 544, 19261, 770], "temperature": 0.0, "avg_logprob": -0.15321787198384604, "compression_ratio": 1.761467889908257, "no_speech_prob": 6.64319668430835e-06}, {"id": 243, "seek": 171954, "start": 1731.54, "end": 1735.94, "text": " version since it's just eight by eight whereas our original was much larger but", "tokens": [3037, 1670, 309, 311, 445, 3180, 538, 3180, 9735, 527, 3380, 390, 709, 4833, 457], "temperature": 0.0, "avg_logprob": -0.15321787198384604, "compression_ratio": 1.761467889908257, "no_speech_prob": 6.64319668430835e-06}, {"id": 244, "seek": 171954, "start": 1735.94, "end": 1740.62, "text": " this actually let me scroll back up so it kind of this circular or not", "tokens": [341, 767, 718, 385, 11369, 646, 493, 370, 309, 733, 295, 341, 16476, 420, 406], "temperature": 0.0, "avg_logprob": -0.15321787198384604, "compression_ratio": 1.761467889908257, "no_speech_prob": 6.64319668430835e-06}, {"id": 245, "seek": 171954, "start": 1740.62, "end": 1748.82, "text": " circular globby shape here that's how we would get kind of the globby shapes here.", "tokens": [16476, 16125, 2322, 3909, 510, 300, 311, 577, 321, 576, 483, 733, 295, 264, 16125, 2322, 10854, 510, 13], "temperature": 0.0, "avg_logprob": -0.15321787198384604, "compression_ratio": 1.761467889908257, "no_speech_prob": 6.64319668430835e-06}, {"id": 246, "seek": 174882, "start": 1748.82, "end": 1764.4199999999998, "text": " Jeremy? Oh yes yeah the carrot sign is XOR which is exclusive or actually first", "tokens": [17809, 30, 876, 2086, 1338, 264, 22767, 1465, 307, 1783, 2483, 597, 307, 13005, 420, 767, 700], "temperature": 0.0, "avg_logprob": -0.20949816703796387, "compression_ratio": 1.2248062015503876, "no_speech_prob": 5.507140485860873e-06}, {"id": 247, "seek": 174882, "start": 1764.4199999999998, "end": 1775.06, "text": " let me just see where ND image okay so that is a SciPy library I'll go back to", "tokens": [718, 385, 445, 536, 689, 40709, 3256, 1392, 370, 300, 307, 257, 16942, 47, 88, 6405, 286, 603, 352, 646, 281], "temperature": 0.0, "avg_logprob": -0.20949816703796387, "compression_ratio": 1.2248062015503876, "no_speech_prob": 5.507140485860873e-06}, {"id": 248, "seek": 177506, "start": 1775.06, "end": 1783.94, "text": " that. Yeah so Jeremy pointed out the the binary erosion gives us the inside", "tokens": [300, 13, 865, 370, 17809, 10932, 484, 264, 264, 17434, 32173, 2709, 505, 264, 1854], "temperature": 0.0, "avg_logprob": -0.1481368671764027, "compression_ratio": 1.5290322580645161, "no_speech_prob": 6.681298714283912e-07}, {"id": 249, "seek": 177506, "start": 1783.94, "end": 1790.58, "text": " really what we want is what's left over and so we're taking an exclusive or with", "tokens": [534, 437, 321, 528, 307, 437, 311, 1411, 670, 293, 370, 321, 434, 1940, 364, 13005, 420, 365], "temperature": 0.0, "avg_logprob": -0.1481368671764027, "compression_ratio": 1.5290322580645161, "no_speech_prob": 6.681298714283912e-07}, {"id": 250, "seek": 177506, "start": 1790.58, "end": 1798.3, "text": " kind of between this picture the result that's everything exclusive or with this", "tokens": [733, 295, 1296, 341, 3036, 264, 1874, 300, 311, 1203, 13005, 420, 365, 341], "temperature": 0.0, "avg_logprob": -0.1481368671764027, "compression_ratio": 1.5290322580645161, "no_speech_prob": 6.681298714283912e-07}, {"id": 251, "seek": 179830, "start": 1798.3, "end": 1805.3, "text": " interior just leaves us with the exterior.", "tokens": [10636, 445, 5510, 505, 365, 264, 20677, 13], "temperature": 0.0, "avg_logprob": -0.5646620591481527, "compression_ratio": 0.9130434782608695, "no_speech_prob": 5.388799399952404e-05}, {"id": 252, "seek": 180530, "start": 1805.3, "end": 1830.82, "text": " And then I just wanted to pull up because I think this is an interesting", "tokens": [400, 550, 286, 445, 1415, 281, 2235, 493, 570, 286, 519, 341, 307, 364, 1880], "temperature": 0.0, "avg_logprob": -0.12224925191778886, "compression_ratio": 1.2627118644067796, "no_speech_prob": 6.704310362692922e-05}, {"id": 253, "seek": 180530, "start": 1830.82, "end": 1835.18, "text": " library we're just using a little bit of functionality from it but SciPy has", "tokens": [6405, 321, 434, 445, 1228, 257, 707, 857, 295, 14980, 490, 309, 457, 16942, 47, 88, 575], "temperature": 0.0, "avg_logprob": -0.12224925191778886, "compression_ratio": 1.2627118644067796, "no_speech_prob": 6.704310362692922e-05}, {"id": 254, "seek": 183518, "start": 1835.18, "end": 1840.26, "text": " an ND image for multi-dimensional image processing kind of as a library so if", "tokens": [364, 40709, 3256, 337, 4825, 12, 18759, 3256, 9007, 733, 295, 382, 257, 6405, 370, 498], "temperature": 0.0, "avg_logprob": -0.15076276659965515, "compression_ratio": 1.4666666666666666, "no_speech_prob": 2.2821519451099448e-05}, {"id": 255, "seek": 183518, "start": 1840.26, "end": 1846.46, "text": " you're interested in it I think that would be something to check out with", "tokens": [291, 434, 3102, 294, 309, 286, 519, 300, 576, 312, 746, 281, 1520, 484, 365], "temperature": 0.0, "avg_logprob": -0.15076276659965515, "compression_ratio": 1.4666666666666666, "no_speech_prob": 2.2821519451099448e-05}, {"id": 256, "seek": 183518, "start": 1846.46, "end": 1853.3, "text": " yeah with different types of filters. Are there questions kind of so far what", "tokens": [1338, 365, 819, 3467, 295, 15995, 13, 2014, 456, 1651, 733, 295, 370, 1400, 437], "temperature": 0.0, "avg_logprob": -0.15076276659965515, "compression_ratio": 1.4666666666666666, "no_speech_prob": 2.2821519451099448e-05}, {"id": 257, "seek": 185330, "start": 1853.3, "end": 1867.5, "text": " we're doing to create these globs?", "tokens": [50364, 321, 434, 884, 281, 1884, 613, 3114, 929, 30, 51074], "temperature": 0.0, "avg_logprob": -0.4308609167734782, "compression_ratio": 0.8095238095238095, "no_speech_prob": 0.0001558087533339858}, {"id": 258, "seek": 188330, "start": 1883.3, "end": 1901.34, "text": " I think this is more like putting a Gaussian centered at each point and kind", "tokens": [286, 519, 341, 307, 544, 411, 3372, 257, 39148, 18988, 412, 1184, 935, 293, 733], "temperature": 0.0, "avg_logprob": -0.22176600791312553, "compression_ratio": 1.3217391304347825, "no_speech_prob": 0.08499664813280106}, {"id": 259, "seek": 188330, "start": 1901.34, "end": 1909.1399999999999, "text": " of looking at what shape that creates. Yeah so we have like the five pixels", "tokens": [295, 1237, 412, 437, 3909, 300, 7829, 13, 865, 370, 321, 362, 411, 264, 1732, 18668], "temperature": 0.0, "avg_logprob": -0.22176600791312553, "compression_ratio": 1.3217391304347825, "no_speech_prob": 0.08499664813280106}, {"id": 260, "seek": 190914, "start": 1909.14, "end": 1914.26, "text": " that we've made white and we kind of like are putting Gaussians centered at", "tokens": [300, 321, 600, 1027, 2418, 293, 321, 733, 295, 411, 366, 3372, 10384, 2023, 2567, 18988, 412], "temperature": 0.0, "avg_logprob": -0.2128832773728804, "compression_ratio": 1.3858267716535433, "no_speech_prob": 2.3182248696684837e-05}, {"id": 261, "seek": 190914, "start": 1914.26, "end": 1919.5400000000002, "text": " each of those and looking at the distribution that creates. Let me pull up", "tokens": [1184, 295, 729, 293, 1237, 412, 264, 7316, 300, 7829, 13, 961, 385, 2235, 493], "temperature": 0.0, "avg_logprob": -0.2128832773728804, "compression_ratio": 1.3858267716535433, "no_speech_prob": 2.3182248696684837e-05}, {"id": 262, "seek": 190914, "start": 1919.5400000000002, "end": 1923.5, "text": " the documentation though.", "tokens": [264, 14333, 1673, 13], "temperature": 0.0, "avg_logprob": -0.2128832773728804, "compression_ratio": 1.3858267716535433, "no_speech_prob": 2.3182248696684837e-05}, {"id": 263, "seek": 192350, "start": 1923.5, "end": 1940.86, "text": " Oh there it goes. Yeah I guess it is like Jeremy saying that he thinks it's like a", "tokens": [876, 456, 309, 1709, 13, 865, 286, 2041, 309, 307, 411, 17809, 1566, 300, 415, 7309, 309, 311, 411, 257], "temperature": 0.0, "avg_logprob": -0.40603790964399067, "compression_ratio": 1.1046511627906976, "no_speech_prob": 2.225062871730188e-06}, {"id": 264, "seek": 192350, "start": 1940.86, "end": 1943.66, "text": " convolution.", "tokens": [45216, 13], "temperature": 0.0, "avg_logprob": -0.40603790964399067, "compression_ratio": 1.1046511627906976, "no_speech_prob": 2.225062871730188e-06}, {"id": 265, "seek": 194366, "start": 1943.66, "end": 1972.3000000000002, "text": " Yeah I think that's accurate. Oh like what this looks like in", "tokens": [50364, 865, 286, 519, 300, 311, 8559, 13, 876, 411, 437, 341, 1542, 411, 294, 51796], "temperature": 0.0, "avg_logprob": -0.3393755520091337, "compression_ratio": 1.0166666666666666, "no_speech_prob": 3.321032636449672e-05}, {"id": 266, "seek": 197366, "start": 1974.6200000000001, "end": 1988.8200000000002, "text": " in 1D would or in I guess kind of in 1D would be like taking the points you", "tokens": [294, 502, 35, 576, 420, 294, 286, 2041, 733, 295, 294, 502, 35, 576, 312, 411, 1940, 264, 2793, 291], "temperature": 0.0, "avg_logprob": -0.2306836900256929, "compression_ratio": 1.3454545454545455, "no_speech_prob": 0.013220037333667278}, {"id": 267, "seek": 197366, "start": 1988.8200000000002, "end": 1999.42, "text": " have and if you put like a Gaussian around each of those and then you're", "tokens": [362, 293, 498, 291, 829, 411, 257, 39148, 926, 1184, 295, 729, 293, 550, 291, 434], "temperature": 0.0, "avg_logprob": -0.2306836900256929, "compression_ratio": 1.3454545454545455, "no_speech_prob": 0.013220037333667278}, {"id": 268, "seek": 199942, "start": 1999.42, "end": 2011.26, "text": " kind of looking at a looking at the method that covers all of these you kind", "tokens": [733, 295, 1237, 412, 257, 1237, 412, 264, 3170, 300, 10538, 439, 295, 613, 291, 733], "temperature": 0.0, "avg_logprob": -0.11400532272626769, "compression_ratio": 1.6814814814814816, "no_speech_prob": 1.0451114576426335e-05}, {"id": 269, "seek": 199942, "start": 2011.26, "end": 2014.22, "text": " of hear about this in kernel methods sometimes kind of like looking at where", "tokens": [295, 1568, 466, 341, 294, 28256, 7150, 2171, 733, 295, 411, 1237, 412, 689], "temperature": 0.0, "avg_logprob": -0.11400532272626769, "compression_ratio": 1.6814814814814816, "no_speech_prob": 1.0451114576426335e-05}, {"id": 270, "seek": 199942, "start": 2014.22, "end": 2020.7, "text": " your data is and then kind of using Gaussians to construct a distribution", "tokens": [428, 1412, 307, 293, 550, 733, 295, 1228, 10384, 2023, 2567, 281, 7690, 257, 7316], "temperature": 0.0, "avg_logprob": -0.11400532272626769, "compression_ratio": 1.6814814814814816, "no_speech_prob": 1.0451114576426335e-05}, {"id": 271, "seek": 202070, "start": 2020.7, "end": 2037.9, "text": " kind of based around that data. Yeah good question. Any other questions?", "tokens": [733, 295, 2361, 926, 300, 1412, 13, 865, 665, 1168, 13, 2639, 661, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2892208601299085, "compression_ratio": 1.0285714285714285, "no_speech_prob": 3.6471974453888834e-05}, {"id": 272, "seek": 203790, "start": 2037.9, "end": 2062.2000000000003, "text": " Matthew? On the Gaussian? Yeah. So what that's doing, yes I think Jeremy", "tokens": [12434, 30, 1282, 264, 39148, 30, 865, 13, 407, 437, 300, 311, 884, 11, 2086, 286, 519, 17809], "temperature": 0.0, "avg_logprob": -0.2640729299405726, "compression_ratio": 1.176, "no_speech_prob": 1.77748515852727e-05}, {"id": 273, "seek": 203790, "start": 2062.2000000000003, "end": 2065.82, "text": " pointing out it's a convolution is helpful. It's kind of like blurring the", "tokens": [12166, 484, 309, 311, 257, 45216, 307, 4961, 13, 467, 311, 733, 295, 411, 14257, 2937, 264], "temperature": 0.0, "avg_logprob": -0.2640729299405726, "compression_ratio": 1.176, "no_speech_prob": 1.77748515852727e-05}, {"id": 274, "seek": 206582, "start": 2065.82, "end": 2070.34, "text": " points around wherever we had these white pixels so we were kind of starting", "tokens": [2793, 926, 8660, 321, 632, 613, 2418, 18668, 370, 321, 645, 733, 295, 2891], "temperature": 0.0, "avg_logprob": -0.08116712823378301, "compression_ratio": 1.9915611814345993, "no_speech_prob": 4.907350376015529e-05}, {"id": 275, "seek": 206582, "start": 2070.34, "end": 2073.98, "text": " with this picture and so you could think of that as kind of doing this averaging", "tokens": [365, 341, 3036, 293, 370, 291, 727, 519, 295, 300, 382, 733, 295, 884, 341, 47308], "temperature": 0.0, "avg_logprob": -0.08116712823378301, "compression_ratio": 1.9915611814345993, "no_speech_prob": 4.907350376015529e-05}, {"id": 276, "seek": 206582, "start": 2073.98, "end": 2078.1800000000003, "text": " method to kind of even out the squares around this and so that's why we kind of", "tokens": [3170, 281, 733, 295, 754, 484, 264, 19368, 926, 341, 293, 370, 300, 311, 983, 321, 733, 295], "temperature": 0.0, "avg_logprob": -0.08116712823378301, "compression_ratio": 1.9915611814345993, "no_speech_prob": 4.907350376015529e-05}, {"id": 277, "seek": 206582, "start": 2078.1800000000003, "end": 2082.02, "text": " have it very white in the corner but you know if we take a point here and get the", "tokens": [362, 309, 588, 2418, 294, 264, 4538, 457, 291, 458, 498, 321, 747, 257, 935, 510, 293, 483, 264], "temperature": 0.0, "avg_logprob": -0.08116712823378301, "compression_ratio": 1.9915611814345993, "no_speech_prob": 4.907350376015529e-05}, {"id": 278, "seek": 206582, "start": 2082.02, "end": 2086.98, "text": " average of the stuff around it you know that's gonna be gray whereas a point", "tokens": [4274, 295, 264, 1507, 926, 309, 291, 458, 300, 311, 799, 312, 10855, 9735, 257, 935], "temperature": 0.0, "avg_logprob": -0.08116712823378301, "compression_ratio": 1.9915611814345993, "no_speech_prob": 4.907350376015529e-05}, {"id": 279, "seek": 206582, "start": 2086.98, "end": 2091.1400000000003, "text": " here an average of everything around it's still gonna be black and that's a", "tokens": [510, 364, 4274, 295, 1203, 926, 309, 311, 920, 799, 312, 2211, 293, 300, 311, 257], "temperature": 0.0, "avg_logprob": -0.08116712823378301, "compression_ratio": 1.9915611814345993, "no_speech_prob": 4.907350376015529e-05}, {"id": 280, "seek": 209114, "start": 2091.14, "end": 2097.3399999999997, "text": " way that kind of like smooths it out. Hi you're welcome.", "tokens": [636, 300, 733, 295, 411, 5508, 82, 309, 484, 13, 2421, 291, 434, 2928, 13], "temperature": 0.0, "avg_logprob": -0.19374772707621257, "compression_ratio": 1.4726027397260273, "no_speech_prob": 0.00010069628478959203}, {"id": 281, "seek": 209114, "start": 2102.5, "end": 2111.94, "text": " Okay and we can always come back to this later too. So this is yeah so that's kind", "tokens": [1033, 293, 321, 393, 1009, 808, 646, 281, 341, 1780, 886, 13, 407, 341, 307, 1338, 370, 300, 311, 733], "temperature": 0.0, "avg_logprob": -0.19374772707621257, "compression_ratio": 1.4726027397260273, "no_speech_prob": 0.00010069628478959203}, {"id": 282, "seek": 209114, "start": 2111.94, "end": 2118.02, "text": " of just to getting that that kind of picture with the globs that in the end", "tokens": [295, 445, 281, 1242, 300, 300, 733, 295, 3036, 365, 264, 3114, 929, 300, 294, 264, 917], "temperature": 0.0, "avg_logprob": -0.19374772707621257, "compression_ratio": 1.4726027397260273, "no_speech_prob": 0.00010069628478959203}, {"id": 283, "seek": 211802, "start": 2118.02, "end": 2122.38, "text": " it's gonna be what we're trying to recreate. The next step is to generate", "tokens": [309, 311, 799, 312, 437, 321, 434, 1382, 281, 25833, 13, 440, 958, 1823, 307, 281, 8460], "temperature": 0.0, "avg_logprob": -0.12906906127929688, "compression_ratio": 1.517766497461929, "no_speech_prob": 5.306678940542042e-05}, {"id": 284, "seek": 211802, "start": 2122.38, "end": 2127.74, "text": " the projections and so this will be the kind of the single value that we get", "tokens": [264, 32371, 293, 370, 341, 486, 312, 264, 733, 295, 264, 2167, 2158, 300, 321, 483], "temperature": 0.0, "avg_logprob": -0.12906906127929688, "compression_ratio": 1.517766497461929, "no_speech_prob": 5.306678940542042e-05}, {"id": 285, "seek": 211802, "start": 2127.74, "end": 2136.7, "text": " from shooting an X-ray at a particular angle through our picture. So again", "tokens": [490, 5942, 364, 1783, 12, 3458, 412, 257, 1729, 5802, 807, 527, 3036, 13, 407, 797], "temperature": 0.0, "avg_logprob": -0.12906906127929688, "compression_ratio": 1.517766497461929, "no_speech_prob": 5.306678940542042e-05}, {"id": 286, "seek": 211802, "start": 2136.7, "end": 2140.14, "text": " I'm gonna walk through this and this is something where you don't have to", "tokens": [286, 478, 799, 1792, 807, 341, 293, 341, 307, 746, 689, 291, 500, 380, 362, 281], "temperature": 0.0, "avg_logprob": -0.12906906127929688, "compression_ratio": 1.517766497461929, "no_speech_prob": 5.306678940542042e-05}, {"id": 287, "seek": 214014, "start": 2140.14, "end": 2151.42, "text": " understand every line of the code. The more I want you to kind of get the idea", "tokens": [1223, 633, 1622, 295, 264, 3089, 13, 440, 544, 286, 528, 291, 281, 733, 295, 483, 264, 1558], "temperature": 0.0, "avg_logprob": -0.1773133739348381, "compression_ratio": 1.4805194805194806, "no_speech_prob": 1.0451049092807807e-05}, {"id": 288, "seek": 214014, "start": 2151.42, "end": 2155.3799999999997, "text": " of like what the steps are. I should also just while it's on the screen want to", "tokens": [295, 411, 437, 264, 4439, 366, 13, 286, 820, 611, 445, 1339, 309, 311, 322, 264, 2568, 528, 281], "temperature": 0.0, "avg_logprob": -0.1773133739348381, "compression_ratio": 1.4805194805194806, "no_speech_prob": 1.0451049092807807e-05}, {"id": 289, "seek": 214014, "start": 2155.3799999999997, "end": 2161.58, "text": " highlight and here we're using sparse.coo matrix in this line for our", "tokens": [5078, 293, 510, 321, 434, 1228, 637, 11668, 13, 1291, 78, 8141, 294, 341, 1622, 337, 527], "temperature": 0.0, "avg_logprob": -0.1773133739348381, "compression_ratio": 1.4805194805194806, "no_speech_prob": 1.0451049092807807e-05}, {"id": 290, "seek": 216158, "start": 2161.58, "end": 2171.66, "text": " operator. Yeah so here we're kind of feeding in what the dimensions we want", "tokens": [12973, 13, 865, 370, 510, 321, 434, 733, 295, 12919, 294, 437, 264, 12819, 321, 528], "temperature": 0.0, "avg_logprob": -0.14398821917447177, "compression_ratio": 1.5731707317073171, "no_speech_prob": 6.048778686817968e-06}, {"id": 291, "seek": 216158, "start": 2171.66, "end": 2176.62, "text": " it to be and we have L as well as L divided by 7 and again the idea is that", "tokens": [309, 281, 312, 293, 321, 362, 441, 382, 731, 382, 441, 6666, 538, 1614, 293, 797, 264, 1558, 307, 300], "temperature": 0.0, "avg_logprob": -0.14398821917447177, "compression_ratio": 1.5731707317073171, "no_speech_prob": 6.048778686817968e-06}, {"id": 292, "seek": 216158, "start": 2176.62, "end": 2184.7799999999997, "text": " we're using less radiation than kind of you know taking it at every single angle", "tokens": [321, 434, 1228, 1570, 12420, 813, 733, 295, 291, 458, 1940, 309, 412, 633, 2167, 5802], "temperature": 0.0, "avg_logprob": -0.14398821917447177, "compression_ratio": 1.5731707317073171, "no_speech_prob": 6.048778686817968e-06}, {"id": 293, "seek": 218478, "start": 2184.78, "end": 2195.98, "text": " in every single location. And so this creates we'll kind of come back to what", "tokens": [294, 633, 2167, 4914, 13, 400, 370, 341, 7829, 321, 603, 733, 295, 808, 646, 281, 437], "temperature": 0.0, "avg_logprob": -0.15817437853131974, "compression_ratio": 1.6214689265536724, "no_speech_prob": 1.4737978744960856e-05}, {"id": 294, "seek": 218478, "start": 2195.98, "end": 2201.7400000000002, "text": " this what this matrix looks like but we've got a sparse matrix in", "tokens": [341, 437, 341, 8141, 1542, 411, 457, 321, 600, 658, 257, 637, 11668, 8141, 294], "temperature": 0.0, "avg_logprob": -0.15817437853131974, "compression_ratio": 1.6214689265536724, "no_speech_prob": 1.4737978744960856e-05}, {"id": 295, "seek": 218478, "start": 2201.7400000000002, "end": 2206.6200000000003, "text": " coordinate format and then there is a dense method which converts", "tokens": [15670, 7877, 293, 550, 456, 307, 257, 18011, 3170, 597, 38874], "temperature": 0.0, "avg_logprob": -0.15817437853131974, "compression_ratio": 1.6214689265536724, "no_speech_prob": 1.4737978744960856e-05}, {"id": 296, "seek": 218478, "start": 2206.6200000000003, "end": 2211.7400000000002, "text": " sparse matrices to dense and is very useful and that'll be helpful when we're", "tokens": [637, 11668, 32284, 281, 18011, 293, 307, 588, 4420, 293, 300, 603, 312, 4961, 562, 321, 434], "temperature": 0.0, "avg_logprob": -0.15817437853131974, "compression_ratio": 1.6214689265536724, "no_speech_prob": 1.4737978744960856e-05}, {"id": 297, "seek": 221174, "start": 2211.74, "end": 2216.8999999999996, "text": " wanting to plot what we're doing. We need to have it dense for for creating these", "tokens": [7935, 281, 7542, 437, 321, 434, 884, 13, 492, 643, 281, 362, 309, 18011, 337, 337, 4084, 613], "temperature": 0.0, "avg_logprob": -0.11130231543432308, "compression_ratio": 1.681081081081081, "no_speech_prob": 1.260630688193487e-05}, {"id": 298, "seek": 221174, "start": 2216.8999999999996, "end": 2225.06, "text": " images. But the idea is that the so the first the first dimension is going to", "tokens": [5267, 13, 583, 264, 1558, 307, 300, 264, 370, 264, 700, 264, 700, 10139, 307, 516, 281], "temperature": 0.0, "avg_logprob": -0.11130231543432308, "compression_ratio": 1.681081081081081, "no_speech_prob": 1.260630688193487e-05}, {"id": 299, "seek": 221174, "start": 2225.06, "end": 2230.3399999999997, "text": " tell you the angle and we only have L L over 7 angles and then we have L", "tokens": [980, 291, 264, 5802, 293, 321, 787, 362, 441, 441, 670, 1614, 14708, 293, 550, 321, 362, 441], "temperature": 0.0, "avg_logprob": -0.11130231543432308, "compression_ratio": 1.681081081081081, "no_speech_prob": 1.260630688193487e-05}, {"id": 300, "seek": 221174, "start": 2230.3399999999997, "end": 2238.7, "text": " positions so that's kind of every single pixel height and then each image is L", "tokens": [8432, 370, 300, 311, 733, 295, 633, 2167, 19261, 6681, 293, 550, 1184, 3256, 307, 441], "temperature": 0.0, "avg_logprob": -0.11130231543432308, "compression_ratio": 1.681081081081081, "no_speech_prob": 1.260630688193487e-05}, {"id": 301, "seek": 223870, "start": 2238.7, "end": 2243.2599999999998, "text": " by L. So we're going to be getting something that's L over 7 by L by L by", "tokens": [538, 441, 13, 407, 321, 434, 516, 281, 312, 1242, 746, 300, 311, 441, 670, 1614, 538, 441, 538, 441, 538], "temperature": 0.0, "avg_logprob": -0.11677890870629287, "compression_ratio": 1.643979057591623, "no_speech_prob": 1.9525101379258558e-05}, {"id": 302, "seek": 223870, "start": 2243.2599999999998, "end": 2255.54, "text": " L. So just to kind of get a feel for this matrix the this is an angle indexed with", "tokens": [441, 13, 407, 445, 281, 733, 295, 483, 257, 841, 337, 341, 8141, 264, 341, 307, 364, 5802, 8186, 292, 365], "temperature": 0.0, "avg_logprob": -0.11677890870629287, "compression_ratio": 1.643979057591623, "no_speech_prob": 1.9525101379258558e-05}, {"id": 303, "seek": 223870, "start": 2255.54, "end": 2263.16, "text": " three and we're kind of have it starting from zero or just kind of position zero", "tokens": [1045, 293, 321, 434, 733, 295, 362, 309, 2891, 490, 4018, 420, 445, 733, 295, 2535, 4018], "temperature": 0.0, "avg_logprob": -0.11677890870629287, "compression_ratio": 1.643979057591623, "no_speech_prob": 1.9525101379258558e-05}, {"id": 304, "seek": 223870, "start": 2263.16, "end": 2266.22, "text": " and then you'll notice the positions moving and basically getting lower each", "tokens": [293, 550, 291, 603, 3449, 264, 8432, 2684, 293, 1936, 1242, 3126, 1184], "temperature": 0.0, "avg_logprob": -0.11677890870629287, "compression_ratio": 1.643979057591623, "no_speech_prob": 1.9525101379258558e-05}, {"id": 305, "seek": 226622, "start": 2266.22, "end": 2270.8599999999997, "text": " time. So then this is position one which is really from this distance almost", "tokens": [565, 13, 407, 550, 341, 307, 2535, 472, 597, 307, 534, 490, 341, 4560, 1920], "temperature": 0.0, "avg_logprob": -0.17460894852541806, "compression_ratio": 1.6347826086956523, "no_speech_prob": 9.817866157391109e-06}, {"id": 306, "seek": 226622, "start": 2270.8599999999997, "end": 2276.3399999999997, "text": " looks identical but the line is slightly lower than the previous picture.", "tokens": [1542, 14800, 457, 264, 1622, 307, 4748, 3126, 813, 264, 3894, 3036, 13], "temperature": 0.0, "avg_logprob": -0.17460894852541806, "compression_ratio": 1.6347826086956523, "no_speech_prob": 9.817866157391109e-06}, {"id": 307, "seek": 226622, "start": 2276.9399999999996, "end": 2285.62, "text": " I can go on two and it becomes more obvious if you say go to position 40. So", "tokens": [286, 393, 352, 322, 732, 293, 309, 3643, 544, 6322, 498, 291, 584, 352, 281, 2535, 3356, 13, 407], "temperature": 0.0, "avg_logprob": -0.17460894852541806, "compression_ratio": 1.6347826086956523, "no_speech_prob": 9.817866157391109e-06}, {"id": 308, "seek": 226622, "start": 2285.62, "end": 2290.3399999999997, "text": " now we can see that okay we've definitely been lowering this angle kind", "tokens": [586, 321, 393, 536, 300, 1392, 321, 600, 2138, 668, 28124, 341, 5802, 733], "temperature": 0.0, "avg_logprob": -0.17460894852541806, "compression_ratio": 1.6347826086956523, "no_speech_prob": 9.817866157391109e-06}, {"id": 309, "seek": 226622, "start": 2290.3399999999997, "end": 2295.1, "text": " of keeping same angle in this case the angle with index three and going to a", "tokens": [295, 5145, 912, 5802, 294, 341, 1389, 264, 5802, 365, 8186, 1045, 293, 516, 281, 257], "temperature": 0.0, "avg_logprob": -0.17460894852541806, "compression_ratio": 1.6347826086956523, "no_speech_prob": 9.817866157391109e-06}, {"id": 310, "seek": 229510, "start": 2295.1, "end": 2300.14, "text": " different position so now we're low at kind of down to 40 and then we can look", "tokens": [819, 2535, 370, 586, 321, 434, 2295, 412, 733, 295, 760, 281, 3356, 293, 550, 321, 393, 574], "temperature": 0.0, "avg_logprob": -0.1635458246866862, "compression_ratio": 1.53125, "no_speech_prob": 8.530047125532292e-06}, {"id": 311, "seek": 229510, "start": 2300.14, "end": 2304.94, "text": " at other other angles at vertical location 40. So now I'm changing the", "tokens": [412, 661, 661, 14708, 412, 9429, 4914, 3356, 13, 407, 586, 286, 478, 4473, 264], "temperature": 0.0, "avg_logprob": -0.1635458246866862, "compression_ratio": 1.53125, "no_speech_prob": 8.530047125532292e-06}, {"id": 312, "seek": 229510, "start": 2304.94, "end": 2309.74, "text": " first coordinate to be a 5 and this is a different angle. Actually let me", "tokens": [700, 15670, 281, 312, 257, 1025, 293, 341, 307, 257, 819, 5802, 13, 5135, 718, 385], "temperature": 0.0, "avg_logprob": -0.1635458246866862, "compression_ratio": 1.53125, "no_speech_prob": 8.530047125532292e-06}, {"id": 313, "seek": 229510, "start": 2309.74, "end": 2317.46, "text": " kind of show like if you did 4 comma 40 that's giving you something in", "tokens": [733, 295, 855, 411, 498, 291, 630, 1017, 22117, 3356, 300, 311, 2902, 291, 746, 294], "temperature": 0.0, "avg_logprob": -0.1635458246866862, "compression_ratio": 1.53125, "no_speech_prob": 8.530047125532292e-06}, {"id": 314, "seek": 231746, "start": 2317.46, "end": 2327.98, "text": " between angles 3 and angle 5. And so what we have is a kind of a matrix that's", "tokens": [1296, 14708, 805, 293, 5802, 1025, 13, 400, 370, 437, 321, 362, 307, 257, 733, 295, 257, 8141, 300, 311], "temperature": 0.0, "avg_logprob": -0.14962345257140042, "compression_ratio": 1.4709677419354839, "no_speech_prob": 1.267904622181959e-06}, {"id": 315, "seek": 231746, "start": 2327.98, "end": 2339.42, "text": " keeping track of all these different angles and locations. Here we can see", "tokens": [5145, 2837, 295, 439, 613, 819, 14708, 293, 9253, 13, 1692, 321, 393, 536], "temperature": 0.0, "avg_logprob": -0.14962345257140042, "compression_ratio": 1.4709677419354839, "no_speech_prob": 1.267904622181959e-06}, {"id": 316, "seek": 231746, "start": 2339.46, "end": 2345.3, "text": " this is a completely different angle the one indexed with number 15 and at", "tokens": [341, 307, 257, 2584, 819, 5802, 264, 472, 8186, 292, 365, 1230, 2119, 293, 412], "temperature": 0.0, "avg_logprob": -0.14962345257140042, "compression_ratio": 1.4709677419354839, "no_speech_prob": 1.267904622181959e-06}, {"id": 317, "seek": 234530, "start": 2345.3, "end": 2352.78, "text": " location 40 still this is angle index with 17 at location 40. So we're kind of", "tokens": [4914, 3356, 920, 341, 307, 5802, 8186, 365, 3282, 412, 4914, 3356, 13, 407, 321, 434, 733, 295], "temperature": 0.0, "avg_logprob": -0.16094837188720704, "compression_ratio": 1.4903225806451612, "no_speech_prob": 5.507436071638949e-06}, {"id": 318, "seek": 234530, "start": 2352.78, "end": 2358.7400000000002, "text": " getting all these different angles at every possible location. Where here the", "tokens": [1242, 439, 613, 819, 14708, 412, 633, 1944, 4914, 13, 2305, 510, 264], "temperature": 0.0, "avg_logprob": -0.16094837188720704, "compression_ratio": 1.4903225806451612, "no_speech_prob": 5.507436071638949e-06}, {"id": 319, "seek": 234530, "start": 2358.7400000000002, "end": 2365.86, "text": " location basically corresponds to the height within the picture. Questions", "tokens": [4914, 1936, 23249, 281, 264, 6681, 1951, 264, 3036, 13, 27738], "temperature": 0.0, "avg_logprob": -0.16094837188720704, "compression_ratio": 1.4903225806451612, "no_speech_prob": 5.507436071638949e-06}, {"id": 320, "seek": 236586, "start": 2365.86, "end": 2377.06, "text": " questions about this? This is a little bit tricky because projection T is it's", "tokens": [1651, 466, 341, 30, 639, 307, 257, 707, 857, 12414, 570, 22743, 314, 307, 309, 311], "temperature": 0.0, "avg_logprob": -0.15084295634981953, "compression_ratio": 1.6076555023923444, "no_speech_prob": 3.3404376154066995e-06}, {"id": 321, "seek": 236586, "start": 2377.06, "end": 2380.38, "text": " a matrix in four dimensions which can be hard to think about. So here we're kind", "tokens": [257, 8141, 294, 1451, 12819, 597, 393, 312, 1152, 281, 519, 466, 13, 407, 510, 321, 434, 733], "temperature": 0.0, "avg_logprob": -0.15084295634981953, "compression_ratio": 1.6076555023923444, "no_speech_prob": 3.3404376154066995e-06}, {"id": 322, "seek": 236586, "start": 2380.38, "end": 2386.1, "text": " of just looking at these two-dimensional pictures from it by indexing the first", "tokens": [295, 445, 1237, 412, 613, 732, 12, 18759, 5242, 490, 309, 538, 8186, 278, 264, 700], "temperature": 0.0, "avg_logprob": -0.15084295634981953, "compression_ratio": 1.6076555023923444, "no_speech_prob": 3.3404376154066995e-06}, {"id": 323, "seek": 236586, "start": 2386.1, "end": 2389.2200000000003, "text": " and second dimensions and then we're seeing everything that's in the third", "tokens": [293, 1150, 12819, 293, 550, 321, 434, 2577, 1203, 300, 311, 294, 264, 2636], "temperature": 0.0, "avg_logprob": -0.15084295634981953, "compression_ratio": 1.6076555023923444, "no_speech_prob": 3.3404376154066995e-06}, {"id": 324, "seek": 238922, "start": 2389.22, "end": 2404.02, "text": " and fourth dimension. Matthew?", "tokens": [293, 6409, 10139, 13, 12434, 30], "temperature": 0.0, "avg_logprob": -0.3062615230165679, "compression_ratio": 1.2272727272727273, "no_speech_prob": 6.747652150806971e-06}, {"id": 325, "seek": 238922, "start": 2409.14, "end": 2413.3799999999997, "text": " So the projection and we'll kind of get to that in a moment the projection is", "tokens": [407, 264, 22743, 293, 321, 603, 733, 295, 483, 281, 300, 294, 257, 1623, 264, 22743, 307], "temperature": 0.0, "avg_logprob": -0.3062615230165679, "compression_ratio": 1.2272727272727273, "no_speech_prob": 6.747652150806971e-06}, {"id": 326, "seek": 241338, "start": 2413.38, "end": 2419.98, "text": " going to talk about how we're projecting into one dimension which is weird to", "tokens": [516, 281, 751, 466, 577, 321, 434, 43001, 666, 472, 10139, 597, 307, 3657, 281], "temperature": 0.0, "avg_logprob": -0.1493322245279948, "compression_ratio": 1.5765306122448979, "no_speech_prob": 4.936514869768871e-06}, {"id": 327, "seek": 241338, "start": 2419.98, "end": 2426.26, "text": " think about but it's going to be kind of taking this you know this just line at a", "tokens": [519, 466, 457, 309, 311, 516, 281, 312, 733, 295, 1940, 341, 291, 458, 341, 445, 1622, 412, 257], "temperature": 0.0, "avg_logprob": -0.1493322245279948, "compression_ratio": 1.5765306122448979, "no_speech_prob": 4.936514869768871e-06}, {"id": 328, "seek": 241338, "start": 2426.26, "end": 2430.26, "text": " certain place together with our whole image and just getting a single number", "tokens": [1629, 1081, 1214, 365, 527, 1379, 3256, 293, 445, 1242, 257, 2167, 1230], "temperature": 0.0, "avg_logprob": -0.1493322245279948, "compression_ratio": 1.5765306122448979, "no_speech_prob": 4.936514869768871e-06}, {"id": 329, "seek": 241338, "start": 2430.26, "end": 2440.1, "text": " from that. Yes, so oh and so that's that's representing what the CT scan", "tokens": [490, 300, 13, 1079, 11, 370, 1954, 293, 370, 300, 311, 300, 311, 13460, 437, 264, 19529, 11049], "temperature": 0.0, "avg_logprob": -0.1493322245279948, "compression_ratio": 1.5765306122448979, "no_speech_prob": 4.936514869768871e-06}, {"id": 330, "seek": 244010, "start": 2440.1, "end": 2447.06, "text": " gets because the CT scan you know you've got this well the cross-section you", "tokens": [2170, 570, 264, 19529, 11049, 291, 458, 291, 600, 658, 341, 731, 264, 3278, 12, 11963, 291], "temperature": 0.0, "avg_logprob": -0.10076414170812388, "compression_ratio": 1.8488372093023255, "no_speech_prob": 2.506650889699813e-05}, {"id": 331, "seek": 244010, "start": 2447.06, "end": 2451.02, "text": " know two-dimensional cross-section of a person and you're sending an x-ray at a", "tokens": [458, 732, 12, 18759, 3278, 12, 11963, 295, 257, 954, 293, 291, 434, 7750, 364, 2031, 12, 3458, 412, 257], "temperature": 0.0, "avg_logprob": -0.10076414170812388, "compression_ratio": 1.8488372093023255, "no_speech_prob": 2.506650889699813e-05}, {"id": 332, "seek": 244010, "start": 2451.02, "end": 2454.38, "text": " particular angle and even though those could be represented as you know like a", "tokens": [1729, 5802, 293, 754, 1673, 729, 727, 312, 10379, 382, 291, 458, 411, 257], "temperature": 0.0, "avg_logprob": -0.10076414170812388, "compression_ratio": 1.8488372093023255, "no_speech_prob": 2.506650889699813e-05}, {"id": 333, "seek": 244010, "start": 2454.38, "end": 2458.94, "text": " 2d picture of the x-ray and a 2d picture of the cross-section of the person you", "tokens": [568, 67, 3036, 295, 264, 2031, 12, 3458, 293, 257, 568, 67, 3036, 295, 264, 3278, 12, 11963, 295, 264, 954, 291], "temperature": 0.0, "avg_logprob": -0.10076414170812388, "compression_ratio": 1.8488372093023255, "no_speech_prob": 2.506650889699813e-05}, {"id": 334, "seek": 244010, "start": 2458.94, "end": 2463.38, "text": " just get a single number from that which is like the reading that the you know the", "tokens": [445, 483, 257, 2167, 1230, 490, 300, 597, 307, 411, 264, 3760, 300, 264, 291, 458, 264], "temperature": 0.0, "avg_logprob": -0.10076414170812388, "compression_ratio": 1.8488372093023255, "no_speech_prob": 2.506650889699813e-05}, {"id": 335, "seek": 244010, "start": 2463.38, "end": 2468.18, "text": " CT scan or MRI machine is picking up. So kind of getting that down to a single", "tokens": [19529, 11049, 420, 32812, 3479, 307, 8867, 493, 13, 407, 733, 295, 1242, 300, 760, 281, 257, 2167], "temperature": 0.0, "avg_logprob": -0.10076414170812388, "compression_ratio": 1.8488372093023255, "no_speech_prob": 2.506650889699813e-05}, {"id": 336, "seek": 246818, "start": 2468.18, "end": 2474.7, "text": " number. Yeah so typically so projections are kind of take something you know that", "tokens": [1230, 13, 865, 370, 5850, 370, 32371, 366, 733, 295, 747, 746, 291, 458, 300], "temperature": 0.0, "avg_logprob": -0.1731979023326527, "compression_ratio": 1.4727272727272727, "no_speech_prob": 6.853128979855683e-06}, {"id": 337, "seek": 246818, "start": 2474.7, "end": 2480.46, "text": " goes from a higher dimension to a lower dimension and I think this is somewhat", "tokens": [1709, 490, 257, 2946, 10139, 281, 257, 3126, 10139, 293, 286, 519, 341, 307, 8344], "temperature": 0.0, "avg_logprob": -0.1731979023326527, "compression_ratio": 1.4727272727272727, "no_speech_prob": 6.853128979855683e-06}, {"id": 338, "seek": 246818, "start": 2480.46, "end": 2487.7, "text": " unusual because I feel like people often don't talk about projections into 1d. Any", "tokens": [10901, 570, 286, 841, 411, 561, 2049, 500, 380, 751, 466, 32371, 666, 502, 67, 13, 2639], "temperature": 0.0, "avg_logprob": -0.1731979023326527, "compression_ratio": 1.4727272727272727, "no_speech_prob": 6.853128979855683e-06}, {"id": 339, "seek": 248770, "start": 2487.7, "end": 2504.5, "text": " other questions? Okay so yeah now I'm just kind of showing kind of you can", "tokens": [661, 1651, 30, 1033, 370, 1338, 586, 286, 478, 445, 733, 295, 4099, 733, 295, 291, 393], "temperature": 0.0, "avg_logprob": -0.1795028567314148, "compression_ratio": 1.3508771929824561, "no_speech_prob": 3.611792180890916e-06}, {"id": 340, "seek": 248770, "start": 2508.9399999999996, "end": 2513.8199999999997, "text": " transpose you know x-ray kind of going through these points we're just going to", "tokens": [25167, 291, 458, 2031, 12, 3458, 733, 295, 516, 807, 613, 2793, 321, 434, 445, 516, 281], "temperature": 0.0, "avg_logprob": -0.1795028567314148, "compression_ratio": 1.3508771929824561, "no_speech_prob": 3.611792180890916e-06}, {"id": 341, "seek": 251382, "start": 2513.82, "end": 2521.1800000000003, "text": " get a single single number from that. Oh here I've also showed just how much", "tokens": [483, 257, 2167, 2167, 1230, 490, 300, 13, 876, 510, 286, 600, 611, 4712, 445, 577, 709], "temperature": 0.0, "avg_logprob": -0.14463283660564016, "compression_ratio": 1.8066037735849056, "no_speech_prob": 1.6026816638259334e-06}, {"id": 342, "seek": 251382, "start": 2521.1800000000003, "end": 2528.34, "text": " intersection there is. The idea here is that the x-ray kind of going", "tokens": [15236, 456, 307, 13, 440, 1558, 510, 307, 300, 264, 2031, 12, 3458, 733, 295, 516], "temperature": 0.0, "avg_logprob": -0.14463283660564016, "compression_ratio": 1.8066037735849056, "no_speech_prob": 1.6026816638259334e-06}, {"id": 343, "seek": 251382, "start": 2528.34, "end": 2531.94, "text": " through different materials of different densities that's going to affect the", "tokens": [807, 819, 5319, 295, 819, 24505, 1088, 300, 311, 516, 281, 3345, 264], "temperature": 0.0, "avg_logprob": -0.14463283660564016, "compression_ratio": 1.8066037735849056, "no_speech_prob": 1.6026816638259334e-06}, {"id": 344, "seek": 251382, "start": 2531.94, "end": 2539.82, "text": " reading at the end so it's got a sense of kind of what what yeah kind of like", "tokens": [3760, 412, 264, 917, 370, 309, 311, 658, 257, 2020, 295, 733, 295, 437, 437, 1338, 733, 295, 411], "temperature": 0.0, "avg_logprob": -0.14463283660564016, "compression_ratio": 1.8066037735849056, "no_speech_prob": 1.6026816638259334e-06}, {"id": 345, "seek": 251382, "start": 2539.82, "end": 2543.78, "text": " the density of what it's passed through based on kind of what the measurement is.", "tokens": [264, 10305, 295, 437, 309, 311, 4678, 807, 2361, 322, 733, 295, 437, 264, 13160, 307, 13], "temperature": 0.0, "avg_logprob": -0.14463283660564016, "compression_ratio": 1.8066037735849056, "no_speech_prob": 1.6026816638259334e-06}, {"id": 346, "seek": 254378, "start": 2543.78, "end": 2552.34, "text": " And so here I wanted to illustrate that and so we get this from so here proj", "tokens": [400, 370, 510, 286, 1415, 281, 23221, 300, 293, 370, 321, 483, 341, 490, 370, 510, 447, 73], "temperature": 0.0, "avg_logprob": -0.12987942695617677, "compression_ratio": 1.6473684210526316, "no_speech_prob": 5.862377292942256e-06}, {"id": 347, "seek": 254378, "start": 2552.34, "end": 2558.42, "text": " stores the projection this is at the very beginning when I showed that little", "tokens": [9512, 264, 22743, 341, 307, 412, 264, 588, 2863, 562, 286, 4712, 300, 707], "temperature": 0.0, "avg_logprob": -0.12987942695617677, "compression_ratio": 1.6473684210526316, "no_speech_prob": 5.862377292942256e-06}, {"id": 348, "seek": 254378, "start": 2558.42, "end": 2566.98, "text": " L by 7 L over 7 by L matrix. This is that the readings and so here where there was", "tokens": [441, 538, 1614, 441, 670, 1614, 538, 441, 8141, 13, 639, 307, 300, 264, 27319, 293, 370, 510, 689, 456, 390], "temperature": 0.0, "avg_logprob": -0.12987942695617677, "compression_ratio": 1.6473684210526316, "no_speech_prob": 5.862377292942256e-06}, {"id": 349, "seek": 254378, "start": 2566.98, "end": 2572.5, "text": " a lot of intersection like this this x-ray was having to pass through a lot", "tokens": [257, 688, 295, 15236, 411, 341, 341, 2031, 12, 3458, 390, 1419, 281, 1320, 807, 257, 688], "temperature": 0.0, "avg_logprob": -0.12987942695617677, "compression_ratio": 1.6473684210526316, "no_speech_prob": 5.862377292942256e-06}, {"id": 350, "seek": 257250, "start": 2572.5, "end": 2582.7, "text": " of the a lot of the glob globules and we get a kind of larger number 6.4 and then", "tokens": [295, 264, 257, 688, 295, 264, 16125, 16125, 3473, 293, 321, 483, 257, 733, 295, 4833, 1230, 1386, 13, 19, 293, 550], "temperature": 0.0, "avg_logprob": -0.13706252069184274, "compression_ratio": 1.542483660130719, "no_speech_prob": 1.1658842595352326e-05}, {"id": 351, "seek": 257250, "start": 2582.7, "end": 2586.9, "text": " here you know we have a line kind of going off off through this side part", "tokens": [510, 291, 458, 321, 362, 257, 1622, 733, 295, 516, 766, 766, 807, 341, 1252, 644], "temperature": 0.0, "avg_logprob": -0.13706252069184274, "compression_ratio": 1.542483660130719, "no_speech_prob": 1.1658842595352326e-05}, {"id": 352, "seek": 257250, "start": 2586.9, "end": 2596.5, "text": " it's not really passing through much and we'll get a lower number. Yeah just 2.1", "tokens": [309, 311, 406, 534, 8437, 807, 709, 293, 321, 603, 483, 257, 3126, 1230, 13, 865, 445, 568, 13, 16], "temperature": 0.0, "avg_logprob": -0.13706252069184274, "compression_ratio": 1.542483660130719, "no_speech_prob": 1.1658842595352326e-05}, {"id": 353, "seek": 259650, "start": 2596.5, "end": 2603.02, "text": " so this is kind of how we're capturing information of how much the line has", "tokens": [370, 341, 307, 733, 295, 577, 321, 434, 23384, 1589, 295, 577, 709, 264, 1622, 575], "temperature": 0.0, "avg_logprob": -0.1416647736455353, "compression_ratio": 1.744186046511628, "no_speech_prob": 2.5611932414904004e-06}, {"id": 354, "seek": 259650, "start": 2603.02, "end": 2611.14, "text": " passed through. And then we're also adding we add some noise to that so kind", "tokens": [4678, 807, 13, 400, 550, 321, 434, 611, 5127, 321, 909, 512, 5658, 281, 300, 370, 733], "temperature": 0.0, "avg_logprob": -0.1416647736455353, "compression_ratio": 1.744186046511628, "no_speech_prob": 2.5611932414904004e-06}, {"id": 355, "seek": 259650, "start": 2611.14, "end": 2615.66, "text": " of assuming that this would would involve some noise in our measurements", "tokens": [295, 11926, 300, 341, 576, 576, 9494, 512, 5658, 294, 527, 15383], "temperature": 0.0, "avg_logprob": -0.1416647736455353, "compression_ratio": 1.744186046511628, "no_speech_prob": 2.5611932414904004e-06}, {"id": 356, "seek": 259650, "start": 2615.66, "end": 2621.82, "text": " and then this is this is what we're referring to is kind of the projection", "tokens": [293, 550, 341, 307, 341, 307, 437, 321, 434, 13761, 281, 307, 733, 295, 264, 22743], "temperature": 0.0, "avg_logprob": -0.1416647736455353, "compression_ratio": 1.744186046511628, "no_speech_prob": 2.5611932414904004e-06}, {"id": 357, "seek": 262182, "start": 2621.82, "end": 2627.5, "text": " this this matrix but that's just all the measurements so it's a bunch of 1D", "tokens": [341, 341, 8141, 457, 300, 311, 445, 439, 264, 15383, 370, 309, 311, 257, 3840, 295, 502, 35], "temperature": 0.0, "avg_logprob": -0.2020450245250355, "compression_ratio": 1.3935483870967742, "no_speech_prob": 1.6186291759368032e-05}, {"id": 358, "seek": 262182, "start": 2627.5, "end": 2633.46, "text": " projections coming from these lines at different angles. Tim?", "tokens": [32371, 1348, 490, 613, 3876, 412, 819, 14708, 13, 7172, 30], "temperature": 0.0, "avg_logprob": -0.2020450245250355, "compression_ratio": 1.3935483870967742, "no_speech_prob": 1.6186291759368032e-05}, {"id": 359, "seek": 262182, "start": 2640.34, "end": 2650.6600000000003, "text": " That's a good question so star in in a Python is used to unpack unpack list so", "tokens": [663, 311, 257, 665, 1168, 370, 3543, 294, 294, 257, 15329, 307, 1143, 281, 26699, 26699, 1329, 370], "temperature": 0.0, "avg_logprob": -0.2020450245250355, "compression_ratio": 1.3935483870967742, "no_speech_prob": 1.6186291759368032e-05}, {"id": 360, "seek": 265066, "start": 2650.66, "end": 2655.7, "text": " there's something called star args and star star and actually let me pull this", "tokens": [456, 311, 746, 1219, 3543, 3882, 82, 293, 3543, 3543, 293, 767, 718, 385, 2235, 341], "temperature": 0.0, "avg_logprob": -0.25304974595161334, "compression_ratio": 1.6166666666666667, "no_speech_prob": 1.4061478395888116e-05}, {"id": 361, "seek": 265066, "start": 2655.7, "end": 2660.2999999999997, "text": " up because this is a really useful Python concept but it's useful when you", "tokens": [493, 570, 341, 307, 257, 534, 4420, 15329, 3410, 457, 309, 311, 4420, 562, 291], "temperature": 0.0, "avg_logprob": -0.25304974595161334, "compression_ratio": 1.6166666666666667, "no_speech_prob": 1.4061478395888116e-05}, {"id": 362, "seek": 265066, "start": 2660.2999999999997, "end": 2664.5, "text": " want to be able to pass yeah like a list or dictionary of argument so the", "tokens": [528, 281, 312, 1075, 281, 1320, 1338, 411, 257, 1329, 420, 25890, 295, 6770, 370, 264], "temperature": 0.0, "avg_logprob": -0.25304974595161334, "compression_ratio": 1.6166666666666667, "no_speech_prob": 1.4061478395888116e-05}, {"id": 363, "seek": 265066, "start": 2664.5, "end": 2667.94, "text": " dictionary use two stars.", "tokens": [25890, 764, 732, 6105, 13], "temperature": 0.0, "avg_logprob": -0.25304974595161334, "compression_ratio": 1.6166666666666667, "no_speech_prob": 1.4061478395888116e-05}, {"id": 364, "seek": 266794, "start": 2667.94, "end": 2677.7400000000002, "text": " No that's in Python too as well yeah.", "tokens": [883, 300, 311, 294, 15329, 886, 382, 731, 1338, 13], "temperature": 0.0, "avg_logprob": -0.365485774146186, "compression_ratio": 1.1919191919191918, "no_speech_prob": 2.077756289509125e-05}, {"id": 365, "seek": 266794, "start": 2683.78, "end": 2690.7000000000003, "text": " Let me see. Yeah and this this can be useful if you kind of like have a bunch of", "tokens": [961, 385, 536, 13, 865, 293, 341, 341, 393, 312, 4420, 498, 291, 733, 295, 411, 362, 257, 3840, 295], "temperature": 0.0, "avg_logprob": -0.365485774146186, "compression_ratio": 1.1919191919191918, "no_speech_prob": 2.077756289509125e-05}, {"id": 366, "seek": 269070, "start": 2690.7, "end": 2698.54, "text": " parameters and don't know how many you'll have. I actually find this really", "tokens": [9834, 293, 500, 380, 458, 577, 867, 291, 603, 362, 13, 286, 767, 915, 341, 534], "temperature": 0.0, "avg_logprob": -0.33491075774769724, "compression_ratio": 1.6585365853658536, "no_speech_prob": 8.47809569677338e-05}, {"id": 367, "seek": 269070, "start": 2698.54, "end": 2703.66, "text": " weird and annoying because like some things in like parts of Python, parts of", "tokens": [3657, 293, 11304, 570, 411, 512, 721, 294, 411, 3166, 295, 15329, 11, 3166, 295], "temperature": 0.0, "avg_logprob": -0.33491075774769724, "compression_ratio": 1.6585365853658536, "no_speech_prob": 8.47809569677338e-05}, {"id": 368, "seek": 269070, "start": 2703.66, "end": 2708.98, "text": " NumPy they expect a shape as a tuple and sometimes they expect the dimensions as", "tokens": [22592, 47, 88, 436, 2066, 257, 3909, 382, 257, 2604, 781, 293, 2171, 436, 2066, 264, 12819, 382], "temperature": 0.0, "avg_logprob": -0.33491075774769724, "compression_ratio": 1.6585365853658536, "no_speech_prob": 8.47809569677338e-05}, {"id": 369, "seek": 269070, "start": 2708.98, "end": 2714.98, "text": " arguments so in this case the thing that virtual is using is arguments so you have to put the star there.", "tokens": [12869, 370, 294, 341, 1389, 264, 551, 300, 6374, 307, 1228, 307, 12869, 370, 291, 362, 281, 829, 264, 3543, 456, 13], "temperature": 0.0, "avg_logprob": -0.33491075774769724, "compression_ratio": 1.6585365853658536, "no_speech_prob": 8.47809569677338e-05}, {"id": 370, "seek": 271498, "start": 2714.98, "end": 2726.02, "text": " Okay so that's true about this issue with shape but I do want to say star args", "tokens": [1033, 370, 300, 311, 2074, 466, 341, 2734, 365, 3909, 457, 286, 360, 528, 281, 584, 3543, 3882, 82], "temperature": 0.0, "avg_logprob": -0.1966686016175805, "compression_ratio": 1.3416666666666666, "no_speech_prob": 7.135894702514634e-05}, {"id": 371, "seek": 271498, "start": 2726.02, "end": 2736.34, "text": " shows up other places that can be useful. Yeah actually let me show an application", "tokens": [3110, 493, 661, 3190, 300, 393, 312, 4420, 13, 865, 767, 718, 385, 855, 364, 3861], "temperature": 0.0, "avg_logprob": -0.1966686016175805, "compression_ratio": 1.3416666666666666, "no_speech_prob": 7.135894702514634e-05}, {"id": 372, "seek": 273634, "start": 2736.34, "end": 2747.6600000000003, "text": " I really like of star. Okay yeah I'm gonna be careful about that.", "tokens": [50364, 286, 534, 411, 295, 3543, 13, 1033, 1338, 286, 478, 799, 312, 5026, 466, 300, 13, 50930], "temperature": 0.0, "avg_logprob": -0.26567697525024414, "compression_ratio": 0.9420289855072463, "no_speech_prob": 2.884009518311359e-05}, {"id": 373, "seek": 276634, "start": 2766.78, "end": 2781.02, "text": " And are you all familiar with zip? Zip yes. Wait that's not.", "tokens": [400, 366, 291, 439, 4963, 365, 20730, 30, 1176, 647, 2086, 13, 3802, 300, 311, 406, 13], "temperature": 0.0, "avg_logprob": -0.7319944472539992, "compression_ratio": 0.8823529411764706, "no_speech_prob": 0.026751955971121788}, {"id": 374, "seek": 278102, "start": 2781.02, "end": 2798.1, "text": " Oh I didn't know that put list at the front like okay so what zip does is you can pass it to list", "tokens": [876, 286, 994, 380, 458, 300, 829, 1329, 412, 264, 1868, 411, 1392, 370, 437, 20730, 775, 307, 291, 393, 1320, 309, 281, 1329], "temperature": 0.0, "avg_logprob": -0.13904429884517894, "compression_ratio": 1.5766871165644172, "no_speech_prob": 4.264375820639543e-05}, {"id": 375, "seek": 278102, "start": 2798.1, "end": 2802.54, "text": " or tuples and it'll of the same length and it will go through and kind of pair", "tokens": [420, 2604, 2622, 293, 309, 603, 295, 264, 912, 4641, 293, 309, 486, 352, 807, 293, 733, 295, 6119], "temperature": 0.0, "avg_logprob": -0.13904429884517894, "compression_ratio": 1.5766871165644172, "no_speech_prob": 4.264375820639543e-05}, {"id": 376, "seek": 278102, "start": 2802.54, "end": 2807.78, "text": " them together so here we're picking off you know one and four two and five three", "tokens": [552, 1214, 370, 510, 321, 434, 8867, 766, 291, 458, 472, 293, 1451, 732, 293, 1732, 1045], "temperature": 0.0, "avg_logprob": -0.13904429884517894, "compression_ratio": 1.5766871165644172, "no_speech_prob": 4.264375820639543e-05}, {"id": 377, "seek": 280778, "start": 2807.78, "end": 2822.0600000000004, "text": " and six but something that's kind of fun is that I'll call this C. You can undo", "tokens": [293, 2309, 457, 746, 300, 311, 733, 295, 1019, 307, 300, 286, 603, 818, 341, 383, 13, 509, 393, 23779], "temperature": 0.0, "avg_logprob": -0.15124051769574484, "compression_ratio": 1.025974025974026, "no_speech_prob": 1.8924398318631575e-05}, {"id": 378, "seek": 282206, "start": 2822.06, "end": 2838.5, "text": " zip then by using zip again together with star. So in this case we wanted to", "tokens": [20730, 550, 538, 1228, 20730, 797, 1214, 365, 3543, 13, 407, 294, 341, 1389, 321, 1415, 281], "temperature": 0.0, "avg_logprob": -0.09246254762013753, "compression_ratio": 1.564625850340136, "no_speech_prob": 9.972442967409734e-06}, {"id": 379, "seek": 282206, "start": 2838.5, "end": 2845.14, "text": " pass to zip three things one four two five three six and we can do that by", "tokens": [1320, 281, 20730, 1045, 721, 472, 1451, 732, 1732, 1045, 2309, 293, 321, 393, 360, 300, 538], "temperature": 0.0, "avg_logprob": -0.09246254762013753, "compression_ratio": 1.564625850340136, "no_speech_prob": 9.972442967409734e-06}, {"id": 380, "seek": 282206, "start": 2845.14, "end": 2850.46, "text": " unpacking this list into kind of the the three tuples using star so that's the", "tokens": [26699, 278, 341, 1329, 666, 733, 295, 264, 264, 1045, 2604, 2622, 1228, 3543, 370, 300, 311, 264], "temperature": 0.0, "avg_logprob": -0.09246254762013753, "compression_ratio": 1.564625850340136, "no_speech_prob": 9.972442967409734e-06}, {"id": 381, "seek": 285046, "start": 2850.46, "end": 2862.82, "text": " way that lets you get your your original two back. Okay other questions about this", "tokens": [636, 300, 6653, 291, 483, 428, 428, 3380, 732, 646, 13, 1033, 661, 1651, 466, 341], "temperature": 0.0, "avg_logprob": -0.27443838119506836, "compression_ratio": 1.3214285714285714, "no_speech_prob": 3.822574217338115e-05}, {"id": 382, "seek": 285046, "start": 2862.82, "end": 2869.82, "text": " figure and that was yeah great question about star args. Matthew?", "tokens": [2573, 293, 300, 390, 1338, 869, 1168, 466, 3543, 3882, 82, 13, 12434, 30], "temperature": 0.0, "avg_logprob": -0.27443838119506836, "compression_ratio": 1.3214285714285714, "no_speech_prob": 3.822574217338115e-05}, {"id": 383, "seek": 286982, "start": 2869.82, "end": 2877.82, "text": " So you have the value that you're getting back you're reading their highlight in the matrix?", "tokens": [407, 291, 362, 264, 2158, 300, 291, 434, 1242, 646, 291, 434, 3760, 641, 5078, 294, 264, 8141, 30], "temperature": 0.0, "avg_logprob": -0.3933301252477309, "compression_ratio": 1.6993865030674846, "no_speech_prob": 8.479889220325276e-05}, {"id": 384, "seek": 286982, "start": 2877.82, "end": 2888.82, "text": " Say that again the map the values that you're reading. Yes yes yeah. And then what are the X and Y axes?", "tokens": [6463, 300, 797, 264, 4471, 264, 4190, 300, 291, 434, 3760, 13, 1079, 2086, 1338, 13, 400, 550, 437, 366, 264, 1783, 293, 398, 35387, 30], "temperature": 0.0, "avg_logprob": -0.3933301252477309, "compression_ratio": 1.6993865030674846, "no_speech_prob": 8.479889220325276e-05}, {"id": 385, "seek": 286982, "start": 2888.82, "end": 2895.3, "text": " For this matrix the great question the X axes are the different angles and then", "tokens": [1171, 341, 8141, 264, 869, 1168, 264, 1783, 35387, 366, 264, 819, 14708, 293, 550], "temperature": 0.0, "avg_logprob": -0.3933301252477309, "compression_ratio": 1.6993865030674846, "no_speech_prob": 8.479889220325276e-05}, {"id": 386, "seek": 289530, "start": 2895.3, "end": 2900.9, "text": " the Y axes corresponds to the different kind of vertical position so when we", "tokens": [264, 398, 35387, 23249, 281, 264, 819, 733, 295, 9429, 2535, 370, 562, 321], "temperature": 0.0, "avg_logprob": -0.18166382212034413, "compression_ratio": 1.591160220994475, "no_speech_prob": 1.0951815056614578e-05}, {"id": 387, "seek": 289530, "start": 2900.9, "end": 2904.5, "text": " showed how like you know there's a line here and then lower yeah that's what the", "tokens": [4712, 577, 411, 291, 458, 456, 311, 257, 1622, 510, 293, 550, 3126, 1338, 300, 311, 437, 264], "temperature": 0.0, "avg_logprob": -0.18166382212034413, "compression_ratio": 1.591160220994475, "no_speech_prob": 1.0951815056614578e-05}, {"id": 388, "seek": 289530, "start": 2904.5, "end": 2910.02, "text": " the Y axis is corresponding to here. You're welcome.", "tokens": [264, 398, 10298, 307, 11760, 281, 510, 13, 509, 434, 2928, 13], "temperature": 0.0, "avg_logprob": -0.18166382212034413, "compression_ratio": 1.591160220994475, "no_speech_prob": 1.0951815056614578e-05}, {"id": 389, "seek": 289530, "start": 2919.94, "end": 2924.86, "text": " Alright so now that so here the hard part was creating this data set and it's", "tokens": [2798, 370, 586, 300, 370, 510, 264, 1152, 644, 390, 4084, 341, 1412, 992, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.18166382212034413, "compression_ratio": 1.591160220994475, "no_speech_prob": 1.0951815056614578e-05}, {"id": 390, "seek": 292486, "start": 2924.86, "end": 2933.3, "text": " actually going to be pretty quick to get back to our answer. We're going to use", "tokens": [767, 516, 281, 312, 1238, 1702, 281, 483, 646, 281, 527, 1867, 13, 492, 434, 516, 281, 764], "temperature": 0.0, "avg_logprob": -0.1305847250182053, "compression_ratio": 1.5066666666666666, "no_speech_prob": 2.111167304974515e-05}, {"id": 391, "seek": 292486, "start": 2933.3, "end": 2941.1, "text": " use regression to try to recover the data. We'll start out with the L2", "tokens": [764, 24590, 281, 853, 281, 8114, 264, 1412, 13, 492, 603, 722, 484, 365, 264, 441, 17], "temperature": 0.0, "avg_logprob": -0.1305847250182053, "compression_ratio": 1.5066666666666666, "no_speech_prob": 2.111167304974515e-05}, {"id": 392, "seek": 292486, "start": 2941.1, "end": 2949.54, "text": " penalization this is called a ridge regression and so here we're just using", "tokens": [13661, 2144, 341, 307, 1219, 257, 34651, 24590, 293, 370, 510, 321, 434, 445, 1228], "temperature": 0.0, "avg_logprob": -0.1305847250182053, "compression_ratio": 1.5066666666666666, "no_speech_prob": 2.111167304974515e-05}, {"id": 393, "seek": 294954, "start": 2949.54, "end": 2960.9, "text": " scikit-learns linear model ridge, fitting it to our projection operator", "tokens": [2180, 22681, 12, 306, 1083, 82, 8213, 2316, 34651, 11, 15669, 309, 281, 527, 22743, 12973], "temperature": 0.0, "avg_logprob": -0.19959232455394307, "compression_ratio": 1.509933774834437, "no_speech_prob": 9.080103154701646e-06}, {"id": 394, "seek": 294954, "start": 2960.9, "end": 2971.5, "text": " projection and this is this is what we get which is not not very good. So this", "tokens": [22743, 293, 341, 307, 341, 307, 437, 321, 483, 597, 307, 406, 406, 588, 665, 13, 407, 341], "temperature": 0.0, "avg_logprob": -0.19959232455394307, "compression_ratio": 1.509933774834437, "no_speech_prob": 9.080103154701646e-06}, {"id": 395, "seek": 294954, "start": 2971.5, "end": 2978.94, "text": " was using least squares error. Now if we use L1 error which is called a lasso", "tokens": [390, 1228, 1935, 19368, 6713, 13, 823, 498, 321, 764, 441, 16, 6713, 597, 307, 1219, 257, 2439, 539], "temperature": 0.0, "avg_logprob": -0.19959232455394307, "compression_ratio": 1.509933774834437, "no_speech_prob": 9.080103154701646e-06}, {"id": 396, "seek": 297894, "start": 2978.94, "end": 2988.94, "text": " regression this is what we get which is really close to our original picture. So", "tokens": [24590, 341, 307, 437, 321, 483, 597, 307, 534, 1998, 281, 527, 3380, 3036, 13, 407], "temperature": 0.0, "avg_logprob": -0.1624983007257635, "compression_ratio": 1.567251461988304, "no_speech_prob": 3.966902113461401e-06}, {"id": 397, "seek": 297894, "start": 2988.94, "end": 2995.34, "text": " this is a case where we had you know very kind of like perfectly sparse data", "tokens": [341, 307, 257, 1389, 689, 321, 632, 291, 458, 588, 733, 295, 411, 6239, 637, 11668, 1412], "temperature": 0.0, "avg_logprob": -0.1624983007257635, "compression_ratio": 1.567251461988304, "no_speech_prob": 3.966902113461401e-06}, {"id": 398, "seek": 297894, "start": 2995.34, "end": 3000.94, "text": " set and so L2 regression did really poorly and L1 regression did a lot", "tokens": [992, 293, 370, 441, 17, 24590, 630, 534, 22271, 293, 441, 16, 24590, 630, 257, 688], "temperature": 0.0, "avg_logprob": -0.1624983007257635, "compression_ratio": 1.567251461988304, "no_speech_prob": 3.966902113461401e-06}, {"id": 399, "seek": 300094, "start": 3000.94, "end": 3014.3, "text": " better. There are questions about this. Tim? Oh okay Tim and then Terrence can go", "tokens": [1101, 13, 821, 366, 1651, 466, 341, 13, 7172, 30, 876, 1392, 7172, 293, 550, 6564, 10760, 393, 352], "temperature": 0.0, "avg_logprob": -0.3243240209726187, "compression_ratio": 1.0481927710843373, "no_speech_prob": 6.013335951138288e-05}, {"id": 400, "seek": 301430, "start": 3014.3, "end": 3041.5800000000004, "text": " next. Okay okay let me think about that one. Let's hear Terrence's question.", "tokens": [50364, 958, 13, 1033, 1392, 718, 385, 519, 466, 300, 472, 13, 961, 311, 1568, 6564, 10760, 311, 1168, 13, 51728], "temperature": 0.0, "avg_logprob": -0.24357011101462625, "compression_ratio": 1.0, "no_speech_prob": 0.0001233627845067531}, {"id": 401, "seek": 304430, "start": 3044.3, "end": 3059.5800000000004, "text": " Is the intensity of each pixel here sort of the sum of polynomials derived from the coefficients we got in that long sprague?", "tokens": [1119, 264, 13749, 295, 1184, 19261, 510, 1333, 295, 264, 2408, 295, 22560, 12356, 18949, 490, 264, 31994, 321, 658, 294, 300, 938, 637, 3731, 622, 30], "temperature": 0.0, "avg_logprob": -0.42159280938617255, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.7350457906723022}, {"id": 402, "seek": 304430, "start": 3059.5800000000004, "end": 3070.5800000000004, "text": " In other words we interpolate between polynomials. We add polynomials together where each polynomial comes from an angle and a height.", "tokens": [682, 661, 2283, 321, 44902, 473, 1296, 22560, 12356, 13, 492, 909, 22560, 12356, 1214, 689, 1184, 26110, 1487, 490, 364, 5802, 293, 257, 6681, 13], "temperature": 0.0, "avg_logprob": -0.42159280938617255, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.7350457906723022}, {"id": 403, "seek": 307058, "start": 3070.58, "end": 3075.58, "text": " Where are you getting polynomials from?", "tokens": [2305, 366, 291, 1242, 22560, 12356, 490, 30], "temperature": 0.0, "avg_logprob": -0.5786893765131632, "compression_ratio": 0.8666666666666667, "no_speech_prob": 0.00010553604806773365}, {"id": 404, "seek": 307558, "start": 3075.58, "end": 3092.58, "text": " I use polynomial but it could be a line. We're basically adding what we see. Each pixel is the summation of what is visible from a bunch of different angles.", "tokens": [286, 764, 26110, 457, 309, 727, 312, 257, 1622, 13, 492, 434, 1936, 5127, 437, 321, 536, 13, 6947, 19261, 307, 264, 28811, 295, 437, 307, 8974, 490, 257, 3840, 295, 819, 14708, 13], "temperature": 0.0, "avg_logprob": -0.29567053443507146, "compression_ratio": 1.2661290322580645, "no_speech_prob": 4.468752376851626e-05}, {"id": 405, "seek": 309258, "start": 3092.58, "end": 3106.58, "text": " Yes. Yeah that's a good way of putting it. Yeah so yeah each pixel is going to be a sum of what was seen from a bunch of different angles.", "tokens": [50364, 1079, 13, 865, 300, 311, 257, 665, 636, 295, 3372, 309, 13, 865, 370, 1338, 1184, 19261, 307, 516, 281, 312, 257, 2408, 295, 437, 390, 1612, 490, 257, 3840, 295, 819, 14708, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1685745909407332, "compression_ratio": 1.2777777777777777, "no_speech_prob": 0.0015969249652698636}, {"id": 406, "seek": 312258, "start": 3122.58, "end": 3127.58, "text": " Basically what Tim's question was that he just answered.", "tokens": [8537, 437, 7172, 311, 1168, 390, 300, 415, 445, 10103, 13], "temperature": 0.0, "avg_logprob": -0.290875244140625, "compression_ratio": 1.3357142857142856, "no_speech_prob": 0.12240110337734222}, {"id": 407, "seek": 312258, "start": 3127.58, "end": 3138.58, "text": " Okay Jeremy's voting for a break.", "tokens": [1033, 17809, 311, 10419, 337, 257, 1821, 13], "temperature": 0.0, "avg_logprob": -0.290875244140625, "compression_ratio": 1.3357142857142856, "no_speech_prob": 0.12240110337734222}, {"id": 408, "seek": 312258, "start": 3138.58, "end": 3144.58, "text": " Yeah well let me say one more thing but then yeah then we'll take a break and come back to this.", "tokens": [865, 731, 718, 385, 584, 472, 544, 551, 457, 550, 1338, 550, 321, 603, 747, 257, 1821, 293, 808, 646, 281, 341, 13], "temperature": 0.0, "avg_logprob": -0.290875244140625, "compression_ratio": 1.3357142857142856, "no_speech_prob": 0.12240110337734222}, {"id": 409, "seek": 314458, "start": 3144.58, "end": 3154.58, "text": " Yeah actually yeah let's take a break and we will discuss this in more detail. So let's be back in seven minutes so that would be 12.05.", "tokens": [865, 767, 1338, 718, 311, 747, 257, 1821, 293, 321, 486, 2248, 341, 294, 544, 2607, 13, 407, 718, 311, 312, 646, 294, 3407, 2077, 370, 300, 576, 312, 2272, 13, 13328, 13], "temperature": 0.0, "avg_logprob": -0.1611336404150659, "compression_ratio": 1.5675675675675675, "no_speech_prob": 4.683327642851509e-05}, {"id": 410, "seek": 314458, "start": 3154.58, "end": 3158.58, "text": " Did I start back up?", "tokens": [2589, 286, 722, 646, 493, 30], "temperature": 0.0, "avg_logprob": -0.1611336404150659, "compression_ratio": 1.5675675675675675, "no_speech_prob": 4.683327642851509e-05}, {"id": 411, "seek": 314458, "start": 3158.58, "end": 3173.58, "text": " Yeah so let's talk about what's going on with this regression. So just kind of to restate the problem. So when you have a CT scan and you get the kind of like the picture that looks like the", "tokens": [865, 370, 718, 311, 751, 466, 437, 311, 516, 322, 365, 341, 24590, 13, 407, 445, 733, 295, 281, 1472, 473, 264, 1154, 13, 407, 562, 291, 362, 257, 19529, 11049, 293, 291, 483, 264, 733, 295, 411, 264, 3036, 300, 1542, 411, 264], "temperature": 0.0, "avg_logprob": -0.1611336404150659, "compression_ratio": 1.5675675675675675, "no_speech_prob": 4.683327642851509e-05}, {"id": 412, "seek": 317358, "start": 3173.58, "end": 3184.58, "text": " insides. Actually there's one up here. You know it looks like a picture of organs or tumors. That's not actually what the CT scan is producing directly but rather you know it's taking these", "tokens": [1028, 1875, 13, 5135, 456, 311, 472, 493, 510, 13, 509, 458, 309, 1542, 411, 257, 3036, 295, 20659, 420, 38466, 13, 663, 311, 406, 767, 437, 264, 19529, 11049, 307, 10501, 3838, 457, 2831, 291, 458, 309, 311, 1940, 613], "temperature": 0.0, "avg_logprob": -0.12950961854722765, "compression_ratio": 1.75, "no_speech_prob": 1.777578472683672e-05}, {"id": 413, "seek": 317358, "start": 3184.58, "end": 3200.58, "text": " measurements and then you know this field of compressed sensing is around how do you get from those measurements back to or not back to but you know create a reconstruction of what the kind of the person's organs look like.", "tokens": [15383, 293, 550, 291, 458, 341, 2519, 295, 30353, 30654, 307, 926, 577, 360, 291, 483, 490, 729, 15383, 646, 281, 420, 406, 646, 281, 457, 291, 458, 1884, 257, 31565, 295, 437, 264, 733, 295, 264, 954, 311, 20659, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.12950961854722765, "compression_ratio": 1.75, "no_speech_prob": 1.777578472683672e-05}, {"id": 414, "seek": 320058, "start": 3200.58, "end": 3218.58, "text": " So here so Tim asked a great question about what's what's going on with this regression. So we have we have something called the projection operator and that's basically kind of like if you think of linear regression being AX equals B and you're trying to find X.", "tokens": [407, 510, 370, 7172, 2351, 257, 869, 1168, 466, 437, 311, 437, 311, 516, 322, 365, 341, 24590, 13, 407, 321, 362, 321, 362, 746, 1219, 264, 22743, 12973, 293, 300, 311, 1936, 733, 295, 411, 498, 291, 519, 295, 8213, 24590, 885, 316, 55, 6915, 363, 293, 291, 434, 1382, 281, 915, 1783, 13], "temperature": 0.0, "avg_logprob": -0.13926729105286678, "compression_ratio": 1.5290697674418605, "no_speech_prob": 9.025303006637841e-05}, {"id": 415, "seek": 321858, "start": 3218.58, "end": 3233.58, "text": " In that case so the projection operator is A. The original picture which is this is like our X and then B is the measurements we got.", "tokens": [682, 300, 1389, 370, 264, 22743, 12973, 307, 316, 13, 440, 3380, 3036, 597, 307, 341, 307, 411, 527, 1783, 293, 550, 363, 307, 264, 15383, 321, 658, 13], "temperature": 0.0, "avg_logprob": -0.1507963122743549, "compression_ratio": 1.2201834862385321, "no_speech_prob": 8.938848623074591e-06}, {"id": 416, "seek": 323358, "start": 3233.58, "end": 3248.58, "text": " And then we go back up here this and it's it's hard to think about the projection operator because it's a four dimensional matrix or four dimensional tensor. And so that's what we're trying to kind of get at up here.", "tokens": [400, 550, 321, 352, 646, 493, 510, 341, 293, 309, 311, 309, 311, 1152, 281, 519, 466, 264, 22743, 12973, 570, 309, 311, 257, 1451, 18795, 8141, 420, 1451, 18795, 40863, 13, 400, 370, 300, 311, 437, 321, 434, 1382, 281, 733, 295, 483, 412, 493, 510, 13], "temperature": 0.0, "avg_logprob": -0.2274595040541429, "compression_ratio": 1.5319148936170213, "no_speech_prob": 5.255069936538348e-06}, {"id": 417, "seek": 324858, "start": 3248.58, "end": 3272.58, "text": " So let's go up to it. With all these plots of proj T. So this is just basically kind of like a part of A. So A is this four dimensional matrix and we can look at slices of it but A represents the lines coming from different angles at different locations.", "tokens": [407, 718, 311, 352, 493, 281, 309, 13, 2022, 439, 613, 28609, 295, 447, 73, 314, 13, 407, 341, 307, 445, 1936, 733, 295, 411, 257, 644, 295, 316, 13, 407, 316, 307, 341, 1451, 18795, 8141, 293, 321, 393, 574, 412, 19793, 295, 309, 457, 316, 8855, 264, 3876, 1348, 490, 819, 14708, 412, 819, 9253, 13], "temperature": 0.0, "avg_logprob": -0.16611848338957755, "compression_ratio": 1.4767441860465116, "no_speech_prob": 2.8572587780217873e-06}, {"id": 418, "seek": 327258, "start": 3272.58, "end": 3282.58, "text": " So it's like all all the angles and locations that the CT scans taking and it like what those look like in 2D.", "tokens": [407, 309, 311, 411, 439, 439, 264, 14708, 293, 9253, 300, 264, 19529, 35116, 1940, 293, 309, 411, 437, 729, 574, 411, 294, 568, 35, 13], "temperature": 0.0, "avg_logprob": -0.1860963081826969, "compression_ratio": 1.3821138211382114, "no_speech_prob": 2.4823882540658815e-06}, {"id": 419, "seek": 327258, "start": 3282.58, "end": 3285.58, "text": " So let me also.", "tokens": [407, 718, 385, 611, 13], "temperature": 0.0, "avg_logprob": -0.1860963081826969, "compression_ratio": 1.3821138211382114, "no_speech_prob": 2.4823882540658815e-06}, {"id": 420, "seek": 327258, "start": 3285.58, "end": 3299.58, "text": " Actually I think I can show that down here.", "tokens": [5135, 286, 519, 286, 393, 855, 300, 760, 510, 13], "temperature": 0.0, "avg_logprob": -0.1860963081826969, "compression_ratio": 1.3821138211382114, "no_speech_prob": 2.4823882540658815e-06}, {"id": 421, "seek": 329958, "start": 3299.58, "end": 3303.58, "text": " So this is the projection operator dot shape.", "tokens": [407, 341, 307, 264, 22743, 12973, 5893, 3909, 13], "temperature": 0.0, "avg_logprob": -0.2694486049895591, "compression_ratio": 1.416, "no_speech_prob": 1.9220400645281188e-05}, {"id": 422, "seek": 329958, "start": 3303.58, "end": 3311.58, "text": " Oh and that is also it's been distorted. So this kind of was the four dimensional thing we reshaped it so it was easier to look at.", "tokens": [876, 293, 300, 307, 611, 309, 311, 668, 33431, 13, 407, 341, 733, 295, 390, 264, 1451, 18795, 551, 321, 725, 71, 18653, 309, 370, 309, 390, 3571, 281, 574, 412, 13], "temperature": 0.0, "avg_logprob": -0.2694486049895591, "compression_ratio": 1.416, "no_speech_prob": 1.9220400645281188e-05}, {"id": 423, "seek": 331158, "start": 3311.58, "end": 3334.58, "text": " So we're having 128 over seven which is 18 something that was 18 by 128 by 128 by 128 and we've reshaped it here just to make it two dimensional. But the idea was four dimensional that we kind of had angles by vertical location of where the X ray was shooting.", "tokens": [407, 321, 434, 1419, 29810, 670, 3407, 597, 307, 2443, 746, 300, 390, 2443, 538, 29810, 538, 29810, 538, 29810, 293, 321, 600, 725, 71, 18653, 309, 510, 445, 281, 652, 309, 732, 18795, 13, 583, 264, 1558, 390, 1451, 18795, 300, 321, 733, 295, 632, 14708, 538, 9429, 4914, 295, 689, 264, 1783, 18592, 390, 5942, 13], "temperature": 0.0, "avg_logprob": -0.2029949926560925, "compression_ratio": 1.5294117647058822, "no_speech_prob": 9.971739018510561e-06}, {"id": 424, "seek": 333458, "start": 3334.58, "end": 3344.58, "text": " And by X coordinate by Y coordinate of the cross section. So that's our matrix A.", "tokens": [400, 538, 1783, 15670, 538, 398, 15670, 295, 264, 3278, 3541, 13, 407, 300, 311, 527, 8141, 316, 13], "temperature": 0.0, "avg_logprob": -0.2492349044136379, "compression_ratio": 1.08, "no_speech_prob": 2.331997848159517e-06}, {"id": 425, "seek": 334458, "start": 3344.58, "end": 3364.58, "text": " And then X which we're trying to solve is this 128 by 128 image. And so we're kind of thinking about like OK we put all these X rays from different angles are kind of effectively being multiplied by this image and then we get out you know the smaller matrix of measurements.", "tokens": [400, 550, 1783, 597, 321, 434, 1382, 281, 5039, 307, 341, 29810, 538, 29810, 3256, 13, 400, 370, 321, 434, 733, 295, 1953, 466, 411, 2264, 321, 829, 439, 613, 1783, 24417, 490, 819, 14708, 366, 733, 295, 8659, 885, 17207, 538, 341, 3256, 293, 550, 321, 483, 484, 291, 458, 264, 4356, 8141, 295, 15383, 13], "temperature": 0.0, "avg_logprob": -0.06853066897783124, "compression_ratio": 1.481081081081081, "no_speech_prob": 3.446396931394702e-06}, {"id": 426, "seek": 336458, "start": 3364.58, "end": 3382.58, "text": " So backwards OK we've got the smaller matrix of measurements. We've got all the X ray angles. How can we get the picture of what what those X rays were passing through.", "tokens": [407, 12204, 2264, 321, 600, 658, 264, 4356, 8141, 295, 15383, 13, 492, 600, 658, 439, 264, 1783, 18592, 14708, 13, 1012, 393, 321, 483, 264, 3036, 295, 437, 437, 729, 1783, 24417, 645, 8437, 807, 13], "temperature": 0.0, "avg_logprob": -0.13671469106906797, "compression_ratio": 1.3333333333333333, "no_speech_prob": 4.860256922256667e-06}, {"id": 427, "seek": 338258, "start": 3382.58, "end": 3392.58, "text": " Are there more questions about this.", "tokens": [2014, 456, 544, 1651, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.15582526248434317, "compression_ratio": 0.9701492537313433, "no_speech_prob": 7.766582712065428e-06}, {"id": 428, "seek": 338258, "start": 3392.58, "end": 3397.58, "text": " And I should say that.", "tokens": [400, 286, 820, 584, 300, 13], "temperature": 0.0, "avg_logprob": -0.15582526248434317, "compression_ratio": 0.9701492537313433, "no_speech_prob": 7.766582712065428e-06}, {"id": 429, "seek": 338258, "start": 3397.58, "end": 3402.58, "text": " Here.", "tokens": [1692, 13], "temperature": 0.0, "avg_logprob": -0.15582526248434317, "compression_ratio": 0.9701492537313433, "no_speech_prob": 7.766582712065428e-06}, {"id": 430, "seek": 340258, "start": 3402.58, "end": 3417.58, "text": " So with the CT scan it kind of makes more sense to think about OK what is what is this X ray passing through. What we're doing though with the fact that it's multiplying is just kind of taking advantage of the fact that we have a lot of zeros and ones and basically", "tokens": [407, 365, 264, 19529, 11049, 309, 733, 295, 1669, 544, 2020, 281, 519, 466, 2264, 437, 307, 437, 307, 341, 1783, 18592, 8437, 807, 13, 708, 321, 434, 884, 1673, 365, 264, 1186, 300, 309, 311, 30955, 307, 445, 733, 295, 1940, 5002, 295, 264, 1186, 300, 321, 362, 257, 688, 295, 35193, 293, 2306, 293, 1936], "temperature": 0.0, "avg_logprob": -0.09310428431776703, "compression_ratio": 1.5497076023391814, "no_speech_prob": 4.565629296848783e-06}, {"id": 431, "seek": 341758, "start": 3417.58, "end": 3434.58, "text": " every place where either the person's organ is zero you know we've got a black spot or where the X ray is not passing those are all zero. And so those will zero out. And so the only thing that gets picked up is where both of them are non zero.", "tokens": [633, 1081, 689, 2139, 264, 954, 311, 1798, 307, 4018, 291, 458, 321, 600, 658, 257, 2211, 4008, 420, 689, 264, 1783, 18592, 307, 406, 8437, 729, 366, 439, 4018, 13, 400, 370, 729, 486, 4018, 484, 13, 400, 370, 264, 787, 551, 300, 2170, 6183, 493, 307, 689, 1293, 295, 552, 366, 2107, 4018, 13], "temperature": 0.0, "avg_logprob": -0.08925654093424479, "compression_ratio": 1.577922077922078, "no_speech_prob": 6.240541551960632e-06}, {"id": 432, "seek": 343458, "start": 3434.58, "end": 3457.58, "text": " And those are the intersections. So you can kind of see this is a different one where they're intersecting. So if we were kind of multiplying the picture of the organs times the picture of the X ray that's just going to pick up the intersections because everything else zeros out and gives us kind of a measurement of how many and how many locations were both of those non zero.", "tokens": [400, 729, 366, 264, 47664, 13, 407, 291, 393, 733, 295, 536, 341, 307, 257, 819, 472, 689, 436, 434, 27815, 278, 13, 407, 498, 321, 645, 733, 295, 30955, 264, 3036, 295, 264, 20659, 1413, 264, 3036, 295, 264, 1783, 18592, 300, 311, 445, 516, 281, 1888, 493, 264, 47664, 570, 1203, 1646, 35193, 484, 293, 2709, 505, 733, 295, 257, 13160, 295, 577, 867, 293, 577, 867, 9253, 645, 1293, 295, 729, 2107, 4018, 13], "temperature": 0.0, "avg_logprob": -0.11081055064260224, "compression_ratio": 1.7746478873239437, "no_speech_prob": 7.410797934426228e-06}, {"id": 433, "seek": 345758, "start": 3457.58, "end": 3478.58, "text": " I have a question. So I'm using down here.", "tokens": [286, 362, 257, 1168, 13, 407, 286, 478, 1228, 760, 510, 13], "temperature": 0.0, "avg_logprob": -0.2332385629415512, "compression_ratio": 0.84, "no_speech_prob": 3.7263457670633215e-06}, {"id": 434, "seek": 347858, "start": 3478.58, "end": 3486.58, "text": " Proj dot ravel does anyone know what ravel does.", "tokens": [1705, 73, 5893, 3342, 779, 775, 2878, 458, 437, 3342, 779, 775, 13], "temperature": 0.0, "avg_logprob": -0.3991446244089227, "compression_ratio": 1.1855670103092784, "no_speech_prob": 4.356603312771767e-06}, {"id": 435, "seek": 347858, "start": 3486.58, "end": 3490.58, "text": " Is that a hand Sam.", "tokens": [1119, 300, 257, 1011, 4832, 13], "temperature": 0.0, "avg_logprob": -0.3991446244089227, "compression_ratio": 1.1855670103092784, "no_speech_prob": 4.356603312771767e-06}, {"id": 436, "seek": 347858, "start": 3490.58, "end": 3497.58, "text": " Just makes it a one dimensional. Exactly. Yes.", "tokens": [1449, 1669, 309, 257, 472, 18795, 13, 7587, 13, 1079, 13], "temperature": 0.0, "avg_logprob": -0.3991446244089227, "compression_ratio": 1.1855670103092784, "no_speech_prob": 4.356603312771767e-06}, {"id": 437, "seek": 349758, "start": 3497.58, "end": 3509.58, "text": " Yeah, and I actually feel like unravel would make more sense but it's yeah kind of flattening it into a one dimensional ray and that's handy here because", "tokens": [865, 11, 293, 286, 767, 841, 411, 40507, 576, 652, 544, 2020, 457, 309, 311, 1338, 733, 295, 24183, 278, 309, 666, 257, 472, 18795, 18592, 293, 300, 311, 13239, 510, 570], "temperature": 0.0, "avg_logprob": -0.19878550370534262, "compression_ratio": 1.2857142857142858, "no_speech_prob": 1.6796534509921912e-06}, {"id": 438, "seek": 350958, "start": 3509.58, "end": 3530.58, "text": " we're basically converting what would be a four dimensional matrix times a two dimensional matrix equals a two dimensional matrix is kind of how I think the problem makes sense of thinking with like the CT scans but we've converted that into a just typical matrix by a vector equals a vector.", "tokens": [321, 434, 1936, 29942, 437, 576, 312, 257, 1451, 18795, 8141, 1413, 257, 732, 18795, 8141, 6915, 257, 732, 18795, 8141, 307, 733, 295, 577, 286, 519, 264, 1154, 1669, 2020, 295, 1953, 365, 411, 264, 19529, 35116, 457, 321, 600, 16424, 300, 666, 257, 445, 7476, 8141, 538, 257, 8062, 6915, 257, 8062, 13], "temperature": 0.0, "avg_logprob": -0.15149606284448655, "compression_ratio": 1.6878612716763006, "no_speech_prob": 2.156701839339803e-06}, {"id": 439, "seek": 353058, "start": 3530.58, "end": 3550.58, "text": " And so that's why we're having to unravel these readings just to be a you know one dimensional array.", "tokens": [400, 370, 300, 311, 983, 321, 434, 1419, 281, 40507, 613, 27319, 445, 281, 312, 257, 291, 458, 472, 18795, 10225, 13], "temperature": 0.0, "avg_logprob": -0.08233911257523757, "compression_ratio": 1.160919540229885, "no_speech_prob": 1.034814431477571e-06}, {"id": 440, "seek": 355058, "start": 3550.58, "end": 3560.58, "text": " A lot of people look very puzzled so I'd love to get more questions Sam.", "tokens": [316, 688, 295, 561, 574, 588, 18741, 1493, 370, 286, 1116, 959, 281, 483, 544, 1651, 4832, 13], "temperature": 0.0, "avg_logprob": -0.1481433667634663, "compression_ratio": 1.1574074074074074, "no_speech_prob": 1.209810761793051e-06}, {"id": 441, "seek": 355058, "start": 3560.58, "end": 3568.58, "text": " Yes. Yeah. So the four dimensions and we go back up.", "tokens": [1079, 13, 865, 13, 407, 264, 1451, 12819, 293, 321, 352, 646, 493, 13], "temperature": 0.0, "avg_logprob": -0.1481433667634663, "compression_ratio": 1.1574074074074074, "no_speech_prob": 1.209810761793051e-06}, {"id": 442, "seek": 356858, "start": 3568.58, "end": 3585.58, "text": " The four dimensions are coming from our projection operator. And so those are the angle that it's at and we have a total of L over seven angles which in this case is 18 angles.", "tokens": [440, 1451, 12819, 366, 1348, 490, 527, 22743, 12973, 13, 400, 370, 729, 366, 264, 5802, 300, 309, 311, 412, 293, 321, 362, 257, 3217, 295, 441, 670, 3407, 14708, 597, 294, 341, 1389, 307, 2443, 14708, 13], "temperature": 0.0, "avg_logprob": -0.10989217531113397, "compression_ratio": 1.353846153846154, "no_speech_prob": 8.13854785519652e-06}, {"id": 443, "seek": 358558, "start": 3585.58, "end": 3599.58, "text": " Is 18 in this case. Yes, we've got 18 distinct angles L positions and that return. So this is an L by L matrix. And that's just kind of each vertical possible height is the position.", "tokens": [1119, 2443, 294, 341, 1389, 13, 1079, 11, 321, 600, 658, 2443, 10644, 14708, 441, 8432, 293, 300, 2736, 13, 407, 341, 307, 364, 441, 538, 441, 8141, 13, 400, 300, 311, 445, 733, 295, 1184, 9429, 1944, 6681, 307, 264, 2535, 13], "temperature": 0.0, "avg_logprob": -0.14899601936340331, "compression_ratio": 1.4444444444444444, "no_speech_prob": 5.014334419684019e-06}, {"id": 444, "seek": 358558, "start": 3599.58, "end": 3605.58, "text": " And then the image for each is L by L.", "tokens": [400, 550, 264, 3256, 337, 1184, 307, 441, 538, 441, 13], "temperature": 0.0, "avg_logprob": -0.14899601936340331, "compression_ratio": 1.4444444444444444, "no_speech_prob": 5.014334419684019e-06}, {"id": 445, "seek": 360558, "start": 3605.58, "end": 3628.58, "text": " And so what we're displaying here is we're kind of indexing on those first two we're picking an angle on a position and then showing the image. And so this is our way of trying to look at little pieces of this four dimensional array is we're just kind of you know indexing on the first two and then viewing a 2D picture.", "tokens": [400, 370, 437, 321, 434, 36834, 510, 307, 321, 434, 733, 295, 8186, 278, 322, 729, 700, 732, 321, 434, 8867, 364, 5802, 322, 257, 2535, 293, 550, 4099, 264, 3256, 13, 400, 370, 341, 307, 527, 636, 295, 1382, 281, 574, 412, 707, 3755, 295, 341, 1451, 18795, 10225, 307, 321, 434, 445, 733, 295, 291, 458, 8186, 278, 322, 264, 700, 732, 293, 550, 17480, 257, 568, 35, 3036, 13], "temperature": 0.0, "avg_logprob": -0.08632267148871171, "compression_ratio": 1.6842105263157894, "no_speech_prob": 9.971983672585338e-06}, {"id": 446, "seek": 362858, "start": 3628.58, "end": 3636.58, "text": " So I guess I'm confused.", "tokens": [407, 286, 2041, 286, 478, 9019, 13], "temperature": 0.0, "avg_logprob": -0.17990165645793332, "compression_ratio": 1.5766423357664234, "no_speech_prob": 0.00023373766453005373}, {"id": 447, "seek": 362858, "start": 3636.58, "end": 3643.58, "text": " So really we're multiplying the last two dimensions by.", "tokens": [407, 534, 321, 434, 30955, 264, 1036, 732, 12819, 538, 13], "temperature": 0.0, "avg_logprob": -0.17990165645793332, "compression_ratio": 1.5766423357664234, "no_speech_prob": 0.00023373766453005373}, {"id": 448, "seek": 362858, "start": 3643.58, "end": 3648.58, "text": " We're multiplying the line in the last two dimensions by X.", "tokens": [492, 434, 30955, 264, 1622, 294, 264, 1036, 732, 12819, 538, 1783, 13], "temperature": 0.0, "avg_logprob": -0.17990165645793332, "compression_ratio": 1.5766423357664234, "no_speech_prob": 0.00023373766453005373}, {"id": 449, "seek": 362858, "start": 3648.58, "end": 3652.58, "text": " And that's giving us a single value that's like how much it's intersecting.", "tokens": [400, 300, 311, 2902, 505, 257, 2167, 2158, 300, 311, 411, 577, 709, 309, 311, 27815, 278, 13], "temperature": 0.0, "avg_logprob": -0.17990165645793332, "compression_ratio": 1.5766423357664234, "no_speech_prob": 0.00023373766453005373}, {"id": 450, "seek": 365258, "start": 3652.58, "end": 3664.58, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.21485457420349122, "compression_ratio": 0.6190476190476191, "no_speech_prob": 6.599208427360281e-05}, {"id": 451, "seek": 365258, "start": 3664.58, "end": 3679.58, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.21485457420349122, "compression_ratio": 0.6190476190476191, "no_speech_prob": 6.599208427360281e-05}, {"id": 452, "seek": 367958, "start": 3679.58, "end": 3692.58, "text": " So that again have three dimensions with the.", "tokens": [407, 300, 797, 362, 1045, 12819, 365, 264, 13], "temperature": 0.0, "avg_logprob": -0.3114480972290039, "compression_ratio": 0.9491525423728814, "no_speech_prob": 6.391039642039686e-05}, {"id": 453, "seek": 367958, "start": 3692.58, "end": 3704.58, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.3114480972290039, "compression_ratio": 0.9491525423728814, "no_speech_prob": 6.391039642039686e-05}, {"id": 454, "seek": 367958, "start": 3704.58, "end": 3707.58, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.3114480972290039, "compression_ratio": 0.9491525423728814, "no_speech_prob": 6.391039642039686e-05}, {"id": 455, "seek": 370758, "start": 3707.58, "end": 3709.58, "text": " Yes, that makes sense. Yeah.", "tokens": [1079, 11, 300, 1669, 2020, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.162580085127321, "compression_ratio": 1.5314285714285714, "no_speech_prob": 3.041411900994717e-06}, {"id": 456, "seek": 370758, "start": 3709.58, "end": 3712.58, "text": " Yeah. So another Yeah, that's a great way of thinking about it.", "tokens": [865, 13, 407, 1071, 865, 11, 300, 311, 257, 869, 636, 295, 1953, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.162580085127321, "compression_ratio": 1.5314285714285714, "no_speech_prob": 3.041411900994717e-06}, {"id": 457, "seek": 370758, "start": 3712.58, "end": 3721.58, "text": " Another like what's happening here with the dimensions is we're actually kind of reshaping this four dimensional thing.", "tokens": [3996, 411, 437, 311, 2737, 510, 365, 264, 12819, 307, 321, 434, 767, 733, 295, 725, 71, 569, 278, 341, 1451, 18795, 551, 13], "temperature": 0.0, "avg_logprob": -0.162580085127321, "compression_ratio": 1.5314285714285714, "no_speech_prob": 3.041411900994717e-06}, {"id": 458, "seek": 370758, "start": 3721.58, "end": 3728.58, "text": " Go down to where I have it.", "tokens": [1037, 760, 281, 689, 286, 362, 309, 13], "temperature": 0.0, "avg_logprob": -0.162580085127321, "compression_ratio": 1.5314285714285714, "no_speech_prob": 3.041411900994717e-06}, {"id": 459, "seek": 370758, "start": 3728.58, "end": 3733.58, "text": " So the projection operator.", "tokens": [407, 264, 22743, 12973, 13], "temperature": 0.0, "avg_logprob": -0.162580085127321, "compression_ratio": 1.5314285714285714, "no_speech_prob": 3.041411900994717e-06}, {"id": 460, "seek": 373358, "start": 3733.58, "end": 3738.58, "text": " Kind of was just write it 128 by.", "tokens": [9242, 295, 390, 445, 2464, 309, 29810, 538, 13], "temperature": 0.0, "avg_logprob": -0.2156828276965083, "compression_ratio": 1.25, "no_speech_prob": 5.255056294117821e-06}, {"id": 461, "seek": 373358, "start": 3738.58, "end": 3750.58, "text": " Oh no, this one's 18 18 by 128 by 128 by 128.", "tokens": [876, 572, 11, 341, 472, 311, 2443, 2443, 538, 29810, 538, 29810, 538, 29810, 13], "temperature": 0.0, "avg_logprob": -0.2156828276965083, "compression_ratio": 1.25, "no_speech_prob": 5.255056294117821e-06}, {"id": 462, "seek": 373358, "start": 3750.58, "end": 3761.58, "text": " But 18 times 128 is 2304 and 128 by 128 is 16,384.", "tokens": [583, 2443, 1413, 29810, 307, 35311, 19, 293, 29810, 538, 29810, 307, 3165, 11, 12625, 19, 13], "temperature": 0.0, "avg_logprob": -0.2156828276965083, "compression_ratio": 1.25, "no_speech_prob": 5.255056294117821e-06}, {"id": 463, "seek": 376158, "start": 3761.58, "end": 3766.58, "text": " And so what's that?", "tokens": [400, 370, 437, 311, 300, 30], "temperature": 0.0, "avg_logprob": -0.0993964399610247, "compression_ratio": 1.48, "no_speech_prob": 5.2550240070559084e-06}, {"id": 464, "seek": 376158, "start": 3766.58, "end": 3776.58, "text": " What this is doing is you can kind of think of, you know, we've turned our picture with the cellular globs or organs or however we want to think about those.", "tokens": [708, 341, 307, 884, 307, 291, 393, 733, 295, 519, 295, 11, 291, 458, 11, 321, 600, 3574, 527, 3036, 365, 264, 29267, 3114, 929, 420, 20659, 420, 4461, 321, 528, 281, 519, 466, 729, 13], "temperature": 0.0, "avg_logprob": -0.0993964399610247, "compression_ratio": 1.48, "no_speech_prob": 5.2550240070559084e-06}, {"id": 465, "seek": 376158, "start": 3776.58, "end": 3777.58, "text": " That was two dimensional.", "tokens": [663, 390, 732, 18795, 13], "temperature": 0.0, "avg_logprob": -0.0993964399610247, "compression_ratio": 1.48, "no_speech_prob": 5.2550240070559084e-06}, {"id": 466, "seek": 376158, "start": 3777.58, "end": 3781.58, "text": " We've kind of unraveled that into like a single vector.", "tokens": [492, 600, 733, 295, 40507, 292, 300, 666, 411, 257, 2167, 8062, 13], "temperature": 0.0, "avg_logprob": -0.0993964399610247, "compression_ratio": 1.48, "no_speech_prob": 5.2550240070559084e-06}, {"id": 467, "seek": 378158, "start": 3781.58, "end": 3797.58, "text": " And then we're going to multiply that two thousand and three hundred two thousand three hundred four times. Basically, like that's getting multiplied with this X ray for we have two thousand three hundred four different X rays.", "tokens": [400, 550, 321, 434, 516, 281, 12972, 300, 732, 4714, 293, 1045, 3262, 732, 4714, 1045, 3262, 1451, 1413, 13, 8537, 11, 411, 300, 311, 1242, 17207, 365, 341, 1783, 18592, 337, 321, 362, 732, 4714, 1045, 3262, 1451, 819, 1783, 24417, 13], "temperature": 0.0, "avg_logprob": -0.1375839645798142, "compression_ratio": 1.7313432835820894, "no_speech_prob": 8.578898587074946e-07}, {"id": 468, "seek": 378158, "start": 3797.58, "end": 3807.58, "text": " You could think of it since we wanted to take an X ray reading from 18 different angles at 128 positions for each angle.", "tokens": [509, 727, 519, 295, 309, 1670, 321, 1415, 281, 747, 364, 1783, 18592, 3760, 490, 2443, 819, 14708, 412, 29810, 8432, 337, 1184, 5802, 13], "temperature": 0.0, "avg_logprob": -0.1375839645798142, "compression_ratio": 1.7313432835820894, "no_speech_prob": 8.578898587074946e-07}, {"id": 469, "seek": 380758, "start": 3807.58, "end": 3813.58, "text": " So that might be helpful to kind of think of. You have twenty three hundred kind of separate.", "tokens": [407, 300, 1062, 312, 4961, 281, 733, 295, 519, 295, 13, 509, 362, 7699, 1045, 3262, 733, 295, 4994, 13], "temperature": 0.0, "avg_logprob": -0.2615734354654948, "compression_ratio": 1.5847953216374269, "no_speech_prob": 3.0892715585650876e-06}, {"id": 470, "seek": 380758, "start": 3813.58, "end": 3815.58, "text": " Yeah. Separate readings.", "tokens": [865, 13, 43480, 473, 27319, 13], "temperature": 0.0, "avg_logprob": -0.2615734354654948, "compression_ratio": 1.5847953216374269, "no_speech_prob": 3.0892715585650876e-06}, {"id": 471, "seek": 380758, "start": 3815.58, "end": 3822.58, "text": " So how does that relate to the previous picture? The one that's kind of wide and short?", "tokens": [407, 577, 775, 300, 10961, 281, 264, 3894, 3036, 30, 440, 472, 300, 311, 733, 295, 4874, 293, 2099, 30], "temperature": 0.0, "avg_logprob": -0.2615734354654948, "compression_ratio": 1.5847953216374269, "no_speech_prob": 3.0892715585650876e-06}, {"id": 472, "seek": 380758, "start": 3822.58, "end": 3826.58, "text": " The this one.", "tokens": [440, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.2615734354654948, "compression_ratio": 1.5847953216374269, "no_speech_prob": 3.0892715585650876e-06}, {"id": 473, "seek": 380758, "start": 3826.58, "end": 3833.58, "text": " Yeah. So this one is actually let me write it out.", "tokens": [865, 13, 407, 341, 472, 307, 767, 718, 385, 2464, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.2615734354654948, "compression_ratio": 1.5847953216374269, "no_speech_prob": 3.0892715585650876e-06}, {"id": 474, "seek": 383358, "start": 3833.58, "end": 3842.58, "text": " This is 18 by 128. We have unraveled this into just one thing that's two thousand three hundred and four long.", "tokens": [639, 307, 2443, 538, 29810, 13, 492, 362, 40507, 292, 341, 666, 445, 472, 551, 300, 311, 732, 4714, 1045, 3262, 293, 1451, 938, 13], "temperature": 0.0, "avg_logprob": -0.08818277498570884, "compression_ratio": 1.7989417989417988, "no_speech_prob": 1.1299884135951288e-05}, {"id": 475, "seek": 383358, "start": 3842.58, "end": 3850.58, "text": " So kind of for each of those two thousand three hundred and four multiplications we're doing, we're getting back one pixel here.", "tokens": [407, 733, 295, 337, 1184, 295, 729, 732, 4714, 1045, 3262, 293, 1451, 17596, 763, 321, 434, 884, 11, 321, 434, 1242, 646, 472, 19261, 510, 13], "temperature": 0.0, "avg_logprob": -0.08818277498570884, "compression_ratio": 1.7989417989417988, "no_speech_prob": 1.1299884135951288e-05}, {"id": 476, "seek": 383358, "start": 3850.58, "end": 3860.58, "text": " Or one spot in this matrix. So this this is the result of doing two thousand three hundred and four.", "tokens": [1610, 472, 4008, 294, 341, 8141, 13, 407, 341, 341, 307, 264, 1874, 295, 884, 732, 4714, 1045, 3262, 293, 1451, 13], "temperature": 0.0, "avg_logprob": -0.08818277498570884, "compression_ratio": 1.7989417989417988, "no_speech_prob": 1.1299884135951288e-05}, {"id": 477, "seek": 386058, "start": 3860.58, "end": 3865.58, "text": " Multiplications.", "tokens": [29238, 4770, 763, 13], "temperature": 0.0, "avg_logprob": -0.11236218043736049, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.00010888016549870372}, {"id": 478, "seek": 386058, "start": 3865.58, "end": 3869.58, "text": " Yes. Yeah. So this is what the CT scanner is actually measuring.", "tokens": [1079, 13, 865, 13, 407, 341, 307, 437, 264, 19529, 30211, 307, 767, 13389, 13], "temperature": 0.0, "avg_logprob": -0.11236218043736049, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.00010888016549870372}, {"id": 479, "seek": 386058, "start": 3869.58, "end": 3883.58, "text": " But then it knows the angles and locations that it's shot the X ray to get each of these points.", "tokens": [583, 550, 309, 3255, 264, 14708, 293, 9253, 300, 309, 311, 3347, 264, 1783, 18592, 281, 483, 1184, 295, 613, 2793, 13], "temperature": 0.0, "avg_logprob": -0.11236218043736049, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.00010888016549870372}, {"id": 480, "seek": 388358, "start": 3883.58, "end": 3896.58, "text": " Yes. Yes. Good questions.", "tokens": [1079, 13, 1079, 13, 2205, 1651, 13], "temperature": 0.0, "avg_logprob": -0.16327692114788553, "compression_ratio": 1.11864406779661, "no_speech_prob": 1.5934272596496157e-05}, {"id": 481, "seek": 388358, "start": 3896.58, "end": 3901.58, "text": " Are there questions about this?", "tokens": [2014, 456, 1651, 466, 341, 30], "temperature": 0.0, "avg_logprob": -0.16327692114788553, "compression_ratio": 1.11864406779661, "no_speech_prob": 1.5934272596496157e-05}, {"id": 482, "seek": 388358, "start": 3901.58, "end": 3905.58, "text": " Matthew.", "tokens": [12434, 13], "temperature": 0.0, "avg_logprob": -0.16327692114788553, "compression_ratio": 1.11864406779661, "no_speech_prob": 1.5934272596496157e-05}, {"id": 483, "seek": 390558, "start": 3905.58, "end": 3913.58, "text": " And then which part of that are we? So this is B in the regression.", "tokens": [400, 550, 597, 644, 295, 300, 366, 321, 30, 407, 341, 307, 363, 294, 264, 24590, 13], "temperature": 0.0, "avg_logprob": -0.20187141781761533, "compression_ratio": 1.3035714285714286, "no_speech_prob": 2.4822625164233614e-06}, {"id": 484, "seek": 390558, "start": 3913.58, "end": 3922.58, "text": " You can think of this as like the column on the right hand side and then A is.", "tokens": [509, 393, 519, 295, 341, 382, 411, 264, 7738, 322, 264, 558, 1011, 1252, 293, 550, 316, 307, 13], "temperature": 0.0, "avg_logprob": -0.20187141781761533, "compression_ratio": 1.3035714285714286, "no_speech_prob": 2.4822625164233614e-06}, {"id": 485, "seek": 392258, "start": 3922.58, "end": 3938.58, "text": " I'm going to hold some of these up. A is the collection of all these matrices.", "tokens": [286, 478, 516, 281, 1797, 512, 295, 613, 493, 13, 316, 307, 264, 5765, 295, 439, 613, 32284, 13], "temperature": 0.0, "avg_logprob": -0.3589413291529605, "compression_ratio": 1.4015748031496063, "no_speech_prob": 7.410442776745185e-06}, {"id": 486, "seek": 392258, "start": 3938.58, "end": 3943.58, "text": " But it's into a two matrix. Projection is still to. Yes. Yeah.", "tokens": [583, 309, 311, 666, 257, 732, 8141, 13, 9849, 313, 307, 920, 281, 13, 1079, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.3589413291529605, "compression_ratio": 1.4015748031496063, "no_speech_prob": 7.410442776745185e-06}, {"id": 487, "seek": 392258, "start": 3943.58, "end": 3950.58, "text": " Yeah. Yeah. So it's like I think it.", "tokens": [865, 13, 865, 13, 407, 309, 311, 411, 286, 519, 309, 13], "temperature": 0.0, "avg_logprob": -0.3589413291529605, "compression_ratio": 1.4015748031496063, "no_speech_prob": 7.410442776745185e-06}, {"id": 488, "seek": 395058, "start": 3950.58, "end": 3957.58, "text": " The time we do the regression and just to be. Yes. Yeah. Yeah.", "tokens": [440, 565, 321, 360, 264, 24590, 293, 445, 281, 312, 13, 1079, 13, 865, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.19328250525132665, "compression_ratio": 1.3893129770992367, "no_speech_prob": 7.888882464612834e-06}, {"id": 489, "seek": 395058, "start": 3957.58, "end": 3971.58, "text": " Yeah. I guess actually. Yeah. So here we've just reshaped it as 40 to get the kind of meaning for the different points.", "tokens": [865, 13, 286, 2041, 767, 13, 865, 13, 407, 510, 321, 600, 445, 725, 71, 18653, 309, 382, 3356, 281, 483, 264, 733, 295, 3620, 337, 264, 819, 2793, 13], "temperature": 0.0, "avg_logprob": -0.19328250525132665, "compression_ratio": 1.3893129770992367, "no_speech_prob": 7.888882464612834e-06}, {"id": 490, "seek": 397158, "start": 3971.58, "end": 3982.58, "text": " And in its 2D form, this picture would be like a single row. So we've kind of taken this whole picture and made this. This is one row.", "tokens": [400, 294, 1080, 568, 35, 1254, 11, 341, 3036, 576, 312, 411, 257, 2167, 5386, 13, 407, 321, 600, 733, 295, 2726, 341, 1379, 3036, 293, 1027, 341, 13, 639, 307, 472, 5386, 13], "temperature": 0.0, "avg_logprob": -0.08923453508421432, "compression_ratio": 1.665, "no_speech_prob": 1.3211246368882712e-05}, {"id": 491, "seek": 397158, "start": 3982.58, "end": 3988.58, "text": " This picture is another row and so on because we've just kind of like unraveled that picture.", "tokens": [639, 3036, 307, 1071, 5386, 293, 370, 322, 570, 321, 600, 445, 733, 295, 411, 40507, 292, 300, 3036, 13], "temperature": 0.0, "avg_logprob": -0.08923453508421432, "compression_ratio": 1.665, "no_speech_prob": 1.3211246368882712e-05}, {"id": 492, "seek": 397158, "start": 3988.58, "end": 3999.58, "text": " And so each row is a single angle and single location. But then all the X, Y coordinates for that angle.", "tokens": [400, 370, 1184, 5386, 307, 257, 2167, 5802, 293, 2167, 4914, 13, 583, 550, 439, 264, 1783, 11, 398, 21056, 337, 300, 5802, 13], "temperature": 0.0, "avg_logprob": -0.08923453508421432, "compression_ratio": 1.665, "no_speech_prob": 1.3211246368882712e-05}, {"id": 493, "seek": 399958, "start": 3999.58, "end": 4014.58, "text": " Well, there are 18 angles, but there are 128 locations. Yeah. So there are 2000 rows.", "tokens": [1042, 11, 456, 366, 2443, 14708, 11, 457, 456, 366, 29810, 9253, 13, 865, 13, 407, 456, 366, 8132, 13241, 13], "temperature": 0.0, "avg_logprob": -0.18339274911319509, "compression_ratio": 1.4296875, "no_speech_prob": 1.6441137631773017e-05}, {"id": 494, "seek": 399958, "start": 4014.58, "end": 4019.58, "text": " All right. So, yeah. So these I should say these pictures here, these are all part of the matrix.", "tokens": [1057, 558, 13, 407, 11, 1338, 13, 407, 613, 286, 820, 584, 613, 5242, 510, 11, 613, 366, 439, 644, 295, 264, 8141, 13], "temperature": 0.0, "avg_logprob": -0.18339274911319509, "compression_ratio": 1.4296875, "no_speech_prob": 1.6441137631773017e-05}, {"id": 495, "seek": 401958, "start": 4019.58, "end": 4031.58, "text": " A the picture at the bottom. That's the vector B.", "tokens": [316, 264, 3036, 412, 264, 2767, 13, 663, 311, 264, 8062, 363, 13], "temperature": 0.0, "avg_logprob": -0.20958095126681858, "compression_ratio": 1.2674418604651163, "no_speech_prob": 2.769276306935353e-06}, {"id": 496, "seek": 401958, "start": 4031.58, "end": 4041.58, "text": " To it. So this is this is the vector B when it's unraveled.", "tokens": [1407, 309, 13, 407, 341, 307, 341, 307, 264, 8062, 363, 562, 309, 311, 40507, 292, 13], "temperature": 0.0, "avg_logprob": -0.20958095126681858, "compression_ratio": 1.2674418604651163, "no_speech_prob": 2.769276306935353e-06}, {"id": 497, "seek": 404158, "start": 4041.58, "end": 4067.58, "text": " So you think of that as like a row of each row that is the image or no, it's more like each each each single location in this, like each pixel here is a reading from one of those like entire pictures above.", "tokens": [407, 291, 519, 295, 300, 382, 411, 257, 5386, 295, 1184, 5386, 300, 307, 264, 3256, 420, 572, 11, 309, 311, 544, 411, 1184, 1184, 1184, 2167, 4914, 294, 341, 11, 411, 1184, 19261, 510, 307, 257, 3760, 490, 472, 295, 729, 411, 2302, 5242, 3673, 13], "temperature": 0.0, "avg_logprob": -0.3222319659064798, "compression_ratio": 1.537313432835821, "no_speech_prob": 8.939136932895053e-06}, {"id": 498, "seek": 406758, "start": 4067.58, "end": 4075.58, "text": " So kind of taking the angle to a particular location that just gives you a single value. So that would just be one entry here.", "tokens": [407, 733, 295, 1940, 264, 5802, 281, 257, 1729, 4914, 300, 445, 2709, 291, 257, 2167, 2158, 13, 407, 300, 576, 445, 312, 472, 8729, 510, 13], "temperature": 0.0, "avg_logprob": -0.1445489960747796, "compression_ratio": 1.2792792792792793, "no_speech_prob": 1.3003756976104341e-05}, {"id": 499, "seek": 406758, "start": 4075.58, "end": 4081.58, "text": " You're welcome.", "tokens": [509, 434, 2928, 13], "temperature": 0.0, "avg_logprob": -0.1445489960747796, "compression_ratio": 1.2792792792792793, "no_speech_prob": 1.3003756976104341e-05}, {"id": 500, "seek": 408158, "start": 4081.58, "end": 4100.58, "text": " Oh, Matthew.", "tokens": [876, 11, 12434, 13], "temperature": 0.0, "avg_logprob": -0.3203083574771881, "compression_ratio": 0.6, "no_speech_prob": 1.1475355677248444e-05}, {"id": 501, "seek": 410058, "start": 4100.58, "end": 4111.58, "text": " Let me think about that.", "tokens": [961, 385, 519, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.27736008167266846, "compression_ratio": 0.8, "no_speech_prob": 2.7963935281150043e-05}, {"id": 502, "seek": 411158, "start": 4111.58, "end": 4133.58, "text": " What would be the kind of the background you're trying to remove?", "tokens": [708, 576, 312, 264, 733, 295, 264, 3678, 291, 434, 1382, 281, 4159, 30], "temperature": 0.0, "avg_logprob": -0.11002283626132542, "compression_ratio": 0.9701492537313433, "no_speech_prob": 3.0236482416512445e-05}, {"id": 503, "seek": 413358, "start": 4133.58, "end": 4142.58, "text": " Yeah, I mean, the tough thing is you don't actually have like you don't have the picture of the line going through the through the globs.", "tokens": [865, 11, 286, 914, 11, 264, 4930, 551, 307, 291, 500, 380, 767, 362, 411, 291, 500, 380, 362, 264, 3036, 295, 264, 1622, 516, 807, 264, 807, 264, 3114, 929, 13], "temperature": 0.0, "avg_logprob": -0.13129004116716056, "compression_ratio": 1.75, "no_speech_prob": 2.5464078134973533e-05}, {"id": 504, "seek": 413358, "start": 4142.58, "end": 4149.58, "text": " It's you just have like a single number for each of those.", "tokens": [467, 311, 291, 445, 362, 411, 257, 2167, 1230, 337, 1184, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.13129004116716056, "compression_ratio": 1.75, "no_speech_prob": 2.5464078134973533e-05}, {"id": 505, "seek": 413358, "start": 4149.58, "end": 4156.58, "text": " Yeah. Yeah. So that's kind of a yeah, like the point you're trying to get to is the picture of the globs.", "tokens": [865, 13, 865, 13, 407, 300, 311, 733, 295, 257, 1338, 11, 411, 264, 935, 291, 434, 1382, 281, 483, 281, 307, 264, 3036, 295, 264, 3114, 929, 13], "temperature": 0.0, "avg_logprob": -0.13129004116716056, "compression_ratio": 1.75, "no_speech_prob": 2.5464078134973533e-05}, {"id": 506, "seek": 413358, "start": 4156.58, "end": 4161.58, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.13129004116716056, "compression_ratio": 1.75, "no_speech_prob": 2.5464078134973533e-05}, {"id": 507, "seek": 416158, "start": 4161.58, "end": 4173.58, "text": " Any other questions?", "tokens": [2639, 661, 1651, 30], "temperature": 0.0, "avg_logprob": -0.3722521662712097, "compression_ratio": 0.7142857142857143, "no_speech_prob": 7.410439138766378e-06}, {"id": 508, "seek": 417358, "start": 4173.58, "end": 4195.58, "text": " All right. We'll probably review this at the beginning of next class. Definitely continue to think about it. Email me if you think of kind of other other questions because it is.", "tokens": [1057, 558, 13, 492, 603, 1391, 3131, 341, 412, 264, 2863, 295, 958, 1508, 13, 12151, 2354, 281, 519, 466, 309, 13, 49482, 385, 498, 291, 519, 295, 733, 295, 661, 661, 1651, 570, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.18060420199138363, "compression_ratio": 1.328358208955224, "no_speech_prob": 7.001926860539243e-07}, {"id": 509, "seek": 419558, "start": 4195.58, "end": 4206.58, "text": " All right. So let's start on close these.", "tokens": [1057, 558, 13, 407, 718, 311, 722, 322, 1998, 613, 13], "temperature": 0.0, "avg_logprob": -0.2559997042020162, "compression_ratio": 0.9452054794520548, "no_speech_prob": 6.604332156712189e-05}, {"id": 510, "seek": 419558, "start": 4206.58, "end": 4219.58, "text": " Oh, wait. Another question.", "tokens": [876, 11, 1699, 13, 3996, 1168, 13], "temperature": 0.0, "avg_logprob": -0.2559997042020162, "compression_ratio": 0.9452054794520548, "no_speech_prob": 6.604332156712189e-05}, {"id": 511, "seek": 421958, "start": 4219.58, "end": 4228.58, "text": " Yes. Yeah. So this kind of human 18 angles is enough to get a really great reconstruction.", "tokens": [1079, 13, 865, 13, 407, 341, 733, 295, 1952, 2443, 14708, 307, 1547, 281, 483, 257, 534, 869, 31565, 13], "temperature": 0.0, "avg_logprob": -0.14098447993181754, "compression_ratio": 1.4574468085106382, "no_speech_prob": 1.2678503935603658e-06}, {"id": 512, "seek": 421958, "start": 4228.58, "end": 4242.58, "text": " Yeah. Whereas kind of like a naive guess might be like, oh, maybe I need 128 angles in order to, you know, be capturing data of the same dimensionality of what I'm trying to recreate.", "tokens": [865, 13, 13813, 733, 295, 411, 257, 29052, 2041, 1062, 312, 411, 11, 1954, 11, 1310, 286, 643, 29810, 14708, 294, 1668, 281, 11, 291, 458, 11, 312, 23384, 1412, 295, 264, 912, 10139, 1860, 295, 437, 286, 478, 1382, 281, 25833, 13], "temperature": 0.0, "avg_logprob": -0.14098447993181754, "compression_ratio": 1.4574468085106382, "no_speech_prob": 1.2678503935603658e-06}, {"id": 513, "seek": 424258, "start": 4242.58, "end": 4251.58, "text": " Yeah. And there's a there's an entire field that kind of focuses on this called compressed sensing or compressive sensing.", "tokens": [865, 13, 400, 456, 311, 257, 456, 311, 364, 2302, 2519, 300, 733, 295, 16109, 322, 341, 1219, 30353, 30654, 420, 14778, 488, 30654, 13], "temperature": 0.0, "avg_logprob": -0.11219831992839945, "compression_ratio": 1.3406593406593406, "no_speech_prob": 2.190640771004837e-06}, {"id": 514, "seek": 425158, "start": 4251.58, "end": 4274.58, "text": " This is a topic David you've been skiing. It was a lot about.", "tokens": [639, 307, 257, 4829, 4389, 291, 600, 668, 32326, 13, 467, 390, 257, 688, 466, 13], "temperature": 0.0, "avg_logprob": -0.5539455413818359, "compression_ratio": 0.9384615384615385, "no_speech_prob": 2.8571562324941624e-06}, {"id": 515, "seek": 427458, "start": 4274.58, "end": 4286.58, "text": " All right. So the next next lesson continuing with the theme of linear regression will be looking we'll be using polynomial features.", "tokens": [1057, 558, 13, 407, 264, 958, 958, 6898, 9289, 365, 264, 6314, 295, 8213, 24590, 486, 312, 1237, 321, 603, 312, 1228, 26110, 4122, 13], "temperature": 0.0, "avg_logprob": -0.13959910822849647, "compression_ratio": 1.5031847133757963, "no_speech_prob": 3.2883403946470935e-06}, {"id": 516, "seek": 427458, "start": 4286.58, "end": 4292.58, "text": " But so different linear regression problem. We're going to use a data set from patients with diabetes.", "tokens": [583, 370, 819, 8213, 24590, 1154, 13, 492, 434, 516, 281, 764, 257, 1412, 992, 490, 4209, 365, 13881, 13], "temperature": 0.0, "avg_logprob": -0.13959910822849647, "compression_ratio": 1.5031847133757963, "no_speech_prob": 3.2883403946470935e-06}, {"id": 517, "seek": 429258, "start": 4292.58, "end": 4309.58, "text": " This is kind of a classic data set from a famous paper and it's included in scikit learn, which is nice. I think I mentioned in an earlier lesson, but let me pull this up again.", "tokens": [639, 307, 733, 295, 257, 7230, 1412, 992, 490, 257, 4618, 3035, 293, 309, 311, 5556, 294, 2180, 22681, 1466, 11, 597, 307, 1481, 13, 286, 519, 286, 2835, 294, 364, 3071, 6898, 11, 457, 718, 385, 2235, 341, 493, 797, 13], "temperature": 0.0, "avg_logprob": -0.12071451933487602, "compression_ratio": 1.3615384615384616, "no_speech_prob": 2.4059136194409803e-06}, {"id": 518, "seek": 430958, "start": 4309.58, "end": 4325.58, "text": " That scikit learn has a number of data sets that that come with it, both kind of where the data is already kind of present with scikit learn or where they give you data kind of loading utilities that you can pull extra data in.", "tokens": [663, 2180, 22681, 1466, 575, 257, 1230, 295, 1412, 6352, 300, 300, 808, 365, 309, 11, 1293, 733, 295, 689, 264, 1412, 307, 1217, 733, 295, 1974, 365, 2180, 22681, 1466, 420, 689, 436, 976, 291, 1412, 733, 295, 15114, 30482, 300, 291, 393, 2235, 2857, 1412, 294, 13], "temperature": 0.0, "avg_logprob": -0.08713923801075328, "compression_ratio": 1.638036809815951, "no_speech_prob": 9.816755664360244e-06}, {"id": 519, "seek": 430958, "start": 4325.58, "end": 4330.58, "text": " So I think that's a nice, nice feature.", "tokens": [407, 286, 519, 300, 311, 257, 1481, 11, 1481, 4111, 13], "temperature": 0.0, "avg_logprob": -0.08713923801075328, "compression_ratio": 1.638036809815951, "no_speech_prob": 9.816755664360244e-06}, {"id": 520, "seek": 433058, "start": 4330.58, "end": 4340.58, "text": " So we'll be using this data diabetes data set. So we just call low diabetes to get the data and then we know what the feature names are just from looking at the documentation.", "tokens": [407, 321, 603, 312, 1228, 341, 1412, 13881, 1412, 992, 13, 407, 321, 445, 818, 2295, 13881, 281, 483, 264, 1412, 293, 550, 321, 458, 437, 264, 4111, 5288, 366, 445, 490, 1237, 412, 264, 14333, 13], "temperature": 0.0, "avg_logprob": -0.08835088505464442, "compression_ratio": 1.5919540229885059, "no_speech_prob": 1.1299553989374544e-05}, {"id": 521, "seek": 433058, "start": 4340.58, "end": 4351.58, "text": " And so this data is going to have age, sex, BMI, blood pressure, and then various blood serum levels.", "tokens": [400, 370, 341, 1412, 307, 516, 281, 362, 3205, 11, 3260, 11, 363, 13808, 11, 3390, 3321, 11, 293, 550, 3683, 3390, 32755, 4358, 13], "temperature": 0.0, "avg_logprob": -0.08835088505464442, "compression_ratio": 1.5919540229885059, "no_speech_prob": 1.1299553989374544e-05}, {"id": 522, "seek": 435158, "start": 4351.58, "end": 4370.58, "text": " We're going to use a train test split, which is kind of scikit learn gives you one there and in here, you're probably familiar actually ask you, can someone explain why splitting into a training and test set is important in machine learning?", "tokens": [492, 434, 516, 281, 764, 257, 3847, 1500, 7472, 11, 597, 307, 733, 295, 2180, 22681, 1466, 2709, 291, 472, 456, 293, 294, 510, 11, 291, 434, 1391, 4963, 767, 1029, 291, 11, 393, 1580, 2903, 983, 30348, 666, 257, 3097, 293, 1500, 992, 307, 1021, 294, 3479, 2539, 30], "temperature": 0.0, "avg_logprob": -0.19970418788768626, "compression_ratio": 1.50625, "no_speech_prob": 3.76317766495049e-05}, {"id": 523, "seek": 437058, "start": 4370.58, "end": 4381.58, "text": " Kelsey.", "tokens": [44714, 13], "temperature": 0.0, "avg_logprob": -0.08982669285365513, "compression_ratio": 1.5375722543352601, "no_speech_prob": 1.2804044672520831e-05}, {"id": 524, "seek": 437058, "start": 4381.58, "end": 4388.58, "text": " Exactly. You don't want to overfit to your particular particular data set. You're trying to come up with a model that will be general enough to handle new data.", "tokens": [7587, 13, 509, 500, 380, 528, 281, 670, 6845, 281, 428, 1729, 1729, 1412, 992, 13, 509, 434, 1382, 281, 808, 493, 365, 257, 2316, 300, 486, 312, 2674, 1547, 281, 4813, 777, 1412, 13], "temperature": 0.0, "avg_logprob": -0.08982669285365513, "compression_ratio": 1.5375722543352601, "no_speech_prob": 1.2804044672520831e-05}, {"id": 525, "seek": 437058, "start": 4388.58, "end": 4396.58, "text": " And so you want to hold out some of your data as a test set and not not look at it until the end.", "tokens": [400, 370, 291, 528, 281, 1797, 484, 512, 295, 428, 1412, 382, 257, 1500, 992, 293, 406, 406, 574, 412, 309, 1826, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.08982669285365513, "compression_ratio": 1.5375722543352601, "no_speech_prob": 1.2804044672520831e-05}, {"id": 526, "seek": 439658, "start": 4396.58, "end": 4410.58, "text": " So we're going to hold out 20% of our data for the test set and that'll allow us to evaluate how well our model does on new data.", "tokens": [407, 321, 434, 516, 281, 1797, 484, 945, 4, 295, 527, 1412, 337, 264, 1500, 992, 293, 300, 603, 2089, 505, 281, 13059, 577, 731, 527, 2316, 775, 322, 777, 1412, 13], "temperature": 0.0, "avg_logprob": -0.12405224504141972, "compression_ratio": 1.382716049382716, "no_speech_prob": 5.954695097898366e-06}, {"id": 527, "seek": 439658, "start": 4410.58, "end": 4419.58, "text": " So the problem of linear regression is AX equals B and typically A has more rows than columns.", "tokens": [407, 264, 1154, 295, 8213, 24590, 307, 316, 55, 6915, 363, 293, 5850, 316, 575, 544, 13241, 813, 13766, 13], "temperature": 0.0, "avg_logprob": -0.12405224504141972, "compression_ratio": 1.382716049382716, "no_speech_prob": 5.954695097898366e-06}, {"id": 528, "seek": 441958, "start": 4419.58, "end": 4437.58, "text": " So this would be when you have more data samples than variables. And yeah, we're trying to find an X that minimizes the L2 air, which is the sum of the squares of AX minus B.", "tokens": [407, 341, 576, 312, 562, 291, 362, 544, 1412, 10938, 813, 9102, 13, 400, 1338, 11, 321, 434, 1382, 281, 915, 364, 1783, 300, 4464, 5660, 264, 441, 17, 1988, 11, 597, 307, 264, 2408, 295, 264, 19368, 295, 316, 55, 3175, 363, 13], "temperature": 0.0, "avg_logprob": -0.0858302613099416, "compression_ratio": 1.2985074626865671, "no_speech_prob": 1.8161601929023163e-06}, {"id": 529, "seek": 443758, "start": 4437.58, "end": 4465.58, "text": " And so this is kind of assuming that our data that there's this linear relationship between the things we're measuring and what we're trying to predict. And so in this case, that would be a linear relationship between age, sex, BMI, different blood serum levels and the kind of long term health outcome of the patient.", "tokens": [400, 370, 341, 307, 733, 295, 11926, 300, 527, 1412, 300, 456, 311, 341, 8213, 2480, 1296, 264, 721, 321, 434, 13389, 293, 437, 321, 434, 1382, 281, 6069, 13, 400, 370, 294, 341, 1389, 11, 300, 576, 312, 257, 8213, 2480, 1296, 3205, 11, 3260, 11, 363, 13808, 11, 819, 3390, 32755, 4358, 293, 264, 733, 295, 938, 1433, 1585, 9700, 295, 264, 4537, 13], "temperature": 0.0, "avg_logprob": -0.07438993453979492, "compression_ratio": 1.6476683937823835, "no_speech_prob": 1.9946403426729375e-06}, {"id": 530, "seek": 446558, "start": 4465.58, "end": 4474.58, "text": " So we can use and we're using linear model from scikit learn has has linear regression for us.", "tokens": [407, 321, 393, 764, 293, 321, 434, 1228, 8213, 2316, 490, 2180, 22681, 1466, 575, 575, 8213, 24590, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.13431964004248903, "compression_ratio": 1.5782312925170068, "no_speech_prob": 8.664112101541832e-06}, {"id": 531, "seek": 446558, "start": 4474.58, "end": 4487.58, "text": " So we kind of create create a regression, fit it to our training set with the Y training data and then make a prediction on the test set.", "tokens": [407, 321, 733, 295, 1884, 1884, 257, 24590, 11, 3318, 309, 281, 527, 3097, 992, 365, 264, 398, 3097, 1412, 293, 550, 652, 257, 17630, 322, 264, 1500, 992, 13], "temperature": 0.0, "avg_logprob": -0.13431964004248903, "compression_ratio": 1.5782312925170068, "no_speech_prob": 8.664112101541832e-06}, {"id": 532, "seek": 448758, "start": 4487.58, "end": 4501.58, "text": " And then here written just a little helper method regression metrics that returns the mean squared air as well as the mean absolute air, kind of between the actual data and between the prediction.", "tokens": [400, 550, 510, 3720, 445, 257, 707, 36133, 3170, 24590, 16367, 300, 11247, 264, 914, 8889, 1988, 382, 731, 382, 264, 914, 8236, 1988, 11, 733, 295, 1296, 264, 3539, 1412, 293, 1296, 264, 17630, 13], "temperature": 0.0, "avg_logprob": -0.1154678463935852, "compression_ratio": 1.4961832061068703, "no_speech_prob": 9.972060979634989e-06}, {"id": 533, "seek": 450158, "start": 4501.58, "end": 4527.58, "text": " And so we run that and we get seventy five for the mean squared air and sixty for mean absolute air. Your questions kind of on the setup or on this is kind of a kind of a basic linear regression so far.", "tokens": [400, 370, 321, 1190, 300, 293, 321, 483, 25662, 1732, 337, 264, 914, 8889, 1988, 293, 21390, 337, 914, 8236, 1988, 13, 2260, 1651, 733, 295, 322, 264, 8657, 420, 322, 341, 307, 733, 295, 257, 733, 295, 257, 3875, 8213, 24590, 370, 1400, 13], "temperature": 0.0, "avg_logprob": -0.1201857158115932, "compression_ratio": 1.518796992481203, "no_speech_prob": 9.721252354211174e-07}, {"id": 534, "seek": 452758, "start": 4527.58, "end": 4535.58, "text": " All right. So now we want to we want to try to improve this. One way we can do that is by adding more features.", "tokens": [1057, 558, 13, 407, 586, 321, 528, 281, 321, 528, 281, 853, 281, 3470, 341, 13, 1485, 636, 321, 393, 360, 300, 307, 538, 5127, 544, 4122, 13], "temperature": 0.0, "avg_logprob": -0.11568169032826144, "compression_ratio": 1.550561797752809, "no_speech_prob": 9.368061000714079e-06}, {"id": 535, "seek": 452758, "start": 4535.58, "end": 4548.58, "text": " And so we're going to try adding polynomial features. And the idea here is that instead of just having it, you know, our outcome depend linearly on these variables.", "tokens": [400, 370, 321, 434, 516, 281, 853, 5127, 26110, 4122, 13, 400, 264, 1558, 510, 307, 300, 2602, 295, 445, 1419, 309, 11, 291, 458, 11, 527, 9700, 5672, 43586, 322, 613, 9102, 13], "temperature": 0.0, "avg_logprob": -0.11568169032826144, "compression_ratio": 1.550561797752809, "no_speech_prob": 9.368061000714079e-06}, {"id": 536, "seek": 454858, "start": 4548.58, "end": 4558.58, "text": " We can also look at things like age squared or age time sex, age times BMI. And so those are the interactions between the different terms.", "tokens": [492, 393, 611, 574, 412, 721, 411, 3205, 8889, 420, 3205, 565, 3260, 11, 3205, 1413, 363, 13808, 13, 400, 370, 729, 366, 264, 13280, 1296, 264, 819, 2115, 13], "temperature": 0.0, "avg_logprob": -0.0987168624997139, "compression_ratio": 1.552325581395349, "no_speech_prob": 1.6536454268134548e-06}, {"id": 537, "seek": 454858, "start": 4558.58, "end": 4568.58, "text": " And this is kind of letting us look for a more complex relationships. And so we're just kind of going up to the squared version.", "tokens": [400, 341, 307, 733, 295, 8295, 505, 574, 337, 257, 544, 3997, 6159, 13, 400, 370, 321, 434, 445, 733, 295, 516, 493, 281, 264, 8889, 3037, 13], "temperature": 0.0, "avg_logprob": -0.0987168624997139, "compression_ratio": 1.552325581395349, "no_speech_prob": 1.6536454268134548e-06}, {"id": 538, "seek": 456858, "start": 4568.58, "end": 4581.58, "text": " So that gets how each term interacts with each other term as well as their squared versions. And so now and actually I should have.", "tokens": [407, 300, 2170, 577, 1184, 1433, 43582, 365, 1184, 661, 1433, 382, 731, 382, 641, 8889, 9606, 13, 400, 370, 586, 293, 767, 286, 820, 362, 13], "temperature": 0.0, "avg_logprob": -0.09965473129635766, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.228893552251975e-06}, {"id": 539, "seek": 456858, "start": 4581.58, "end": 4591.58, "text": " I put the dimensions before we start this.", "tokens": [286, 829, 264, 12819, 949, 321, 722, 341, 13], "temperature": 0.0, "avg_logprob": -0.09965473129635766, "compression_ratio": 1.380952380952381, "no_speech_prob": 1.228893552251975e-06}, {"id": 540, "seek": 459158, "start": 4591.58, "end": 4602.58, "text": " So we were starting with three hundred and fifty three rows. So that's probably three hundred fifty three different patients and 10 variables.", "tokens": [407, 321, 645, 2891, 365, 1045, 3262, 293, 13442, 1045, 13241, 13, 407, 300, 311, 1391, 1045, 3262, 13442, 1045, 819, 4209, 293, 1266, 9102, 13], "temperature": 0.0, "avg_logprob": -0.10653167400719984, "compression_ratio": 1.5732484076433122, "no_speech_prob": 2.443847506583552e-06}, {"id": 541, "seek": 459158, "start": 4602.58, "end": 4612.58, "text": " If we add these polynomial features, now we've got sixty five different variables that we're looking at.", "tokens": [759, 321, 909, 613, 26110, 4122, 11, 586, 321, 600, 658, 21390, 1732, 819, 9102, 300, 321, 434, 1237, 412, 13], "temperature": 0.0, "avg_logprob": -0.10653167400719984, "compression_ratio": 1.5732484076433122, "no_speech_prob": 2.443847506583552e-06}, {"id": 542, "seek": 461258, "start": 4612.58, "end": 4624.58, "text": " And so do a linear regression again. And we've just added. We kind of created these training features and now using those to fit our regression.", "tokens": [400, 370, 360, 257, 8213, 24590, 797, 13, 400, 321, 600, 445, 3869, 13, 492, 733, 295, 2942, 613, 3097, 4122, 293, 586, 1228, 729, 281, 3318, 527, 24590, 13], "temperature": 0.0, "avg_logprob": -0.11063251041230701, "compression_ratio": 1.5232558139534884, "no_speech_prob": 6.786597168684239e-07}, {"id": 543, "seek": 461258, "start": 4624.58, "end": 4634.58, "text": " And that improves our error. So we before I think had seventy five and sixty. Now we've got fifty five and forty two.", "tokens": [400, 300, 24771, 527, 6713, 13, 407, 321, 949, 286, 519, 632, 25662, 1732, 293, 21390, 13, 823, 321, 600, 658, 13442, 1732, 293, 15815, 732, 13], "temperature": 0.0, "avg_logprob": -0.11063251041230701, "compression_ratio": 1.5232558139534884, "no_speech_prob": 6.786597168684239e-07}, {"id": 544, "seek": 463458, "start": 4634.58, "end": 4643.58, "text": " Unfortunately, time is squared in the number of features. And so this is this is going to slow us down a lot.", "tokens": [8590, 11, 565, 307, 8889, 294, 264, 1230, 295, 4122, 13, 400, 370, 341, 307, 341, 307, 516, 281, 2964, 505, 760, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.07792831021685932, "compression_ratio": 1.2521008403361344, "no_speech_prob": 2.4060316263785353e-06}, {"id": 545, "seek": 463458, "start": 4643.58, "end": 4653.58, "text": " And we can look. Let's go back up here.", "tokens": [400, 321, 393, 574, 13, 961, 311, 352, 646, 493, 510, 13], "temperature": 0.0, "avg_logprob": -0.07792831021685932, "compression_ratio": 1.2521008403361344, "no_speech_prob": 2.4060316263785353e-06}, {"id": 546, "seek": 465358, "start": 4653.58, "end": 4667.58, "text": " Here's the time. So before it was five hundred and thirty five microseconds. And I think we've seen this before, but using percent time it in a Jupyter notebook runs.", "tokens": [1692, 311, 264, 565, 13, 407, 949, 309, 390, 1732, 3262, 293, 11790, 1732, 3123, 37841, 28750, 13, 400, 286, 519, 321, 600, 1612, 341, 949, 11, 457, 1228, 3043, 565, 309, 294, 257, 22125, 88, 391, 21060, 6676, 13], "temperature": 0.0, "avg_logprob": -0.09414142683932655, "compression_ratio": 1.535, "no_speech_prob": 5.989050464449974e-07}, {"id": 547, "seek": 465358, "start": 4667.58, "end": 4677.58, "text": " So here this is doing seven runs, a thousand loops each kind of runs at multiple times and then gives you this average of how long it takes.", "tokens": [407, 510, 341, 307, 884, 3407, 6676, 11, 257, 4714, 16121, 1184, 733, 295, 6676, 412, 3866, 1413, 293, 550, 2709, 291, 341, 4274, 295, 577, 938, 309, 2516, 13], "temperature": 0.0, "avg_logprob": -0.09414142683932655, "compression_ratio": 1.535, "no_speech_prob": 5.989050464449974e-07}, {"id": 548, "seek": 467758, "start": 4677.58, "end": 4685.58, "text": " So it's a really useful way to compare compare the times of things.", "tokens": [407, 309, 311, 257, 534, 4420, 636, 281, 6794, 6794, 264, 1413, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.07050963810511998, "compression_ratio": 1.744047619047619, "no_speech_prob": 4.289101980248233e-06}, {"id": 549, "seek": 467758, "start": 4685.58, "end": 4691.58, "text": " So that was five hundred and thirty five microseconds. So now we're up to six hundred and thirty five microseconds.", "tokens": [407, 300, 390, 1732, 3262, 293, 11790, 1732, 3123, 37841, 28750, 13, 407, 586, 321, 434, 493, 281, 2309, 3262, 293, 11790, 1732, 3123, 37841, 28750, 13], "temperature": 0.0, "avg_logprob": -0.07050963810511998, "compression_ratio": 1.744047619047619, "no_speech_prob": 4.289101980248233e-06}, {"id": 550, "seek": 467758, "start": 4691.58, "end": 4703.58, "text": " So it's not that much worse in this case, but it's something that's going to on larger data sets be an issue.", "tokens": [407, 309, 311, 406, 300, 709, 5324, 294, 341, 1389, 11, 457, 309, 311, 746, 300, 311, 516, 281, 322, 4833, 1412, 6352, 312, 364, 2734, 13], "temperature": 0.0, "avg_logprob": -0.07050963810511998, "compression_ratio": 1.744047619047619, "no_speech_prob": 4.289101980248233e-06}, {"id": 551, "seek": 470358, "start": 4703.58, "end": 4709.58, "text": " Or was there also a plus minus.", "tokens": [50364, 1610, 390, 456, 611, 257, 1804, 3175, 13, 50664], "temperature": 0.0, "avg_logprob": -0.32193428819829767, "compression_ratio": 0.7948717948717948, "no_speech_prob": 0.00010213998757535592}, {"id": 552, "seek": 473358, "start": 4734.58, "end": 4752.58, "text": " Oh, yes, I'm sorry. So, yeah, the one above was to do the linear regression. This is just to pull.", "tokens": [876, 11, 2086, 11, 286, 478, 2597, 13, 407, 11, 1338, 11, 264, 472, 3673, 390, 281, 360, 264, 8213, 24590, 13, 639, 307, 445, 281, 2235, 13], "temperature": 0.0, "avg_logprob": -0.15774518251419067, "compression_ratio": 1.0888888888888888, "no_speech_prob": 0.04883415251970291}, {"id": 553, "seek": 475258, "start": 4752.58, "end": 4763.58, "text": " OK, so this is just to create the features. Sorry to create these polynomial features. Sorry about that. And so that's you're having to take all the data points and multiply them together.", "tokens": [2264, 11, 370, 341, 307, 445, 281, 1884, 264, 4122, 13, 4919, 281, 1884, 613, 26110, 4122, 13, 4919, 466, 300, 13, 400, 370, 300, 311, 291, 434, 1419, 281, 747, 439, 264, 1412, 2793, 293, 12972, 552, 1214, 13], "temperature": 0.0, "avg_logprob": -0.07658598746782468, "compression_ratio": 1.688073394495413, "no_speech_prob": 3.2695879781385884e-05}, {"id": 554, "seek": 475258, "start": 4763.58, "end": 4775.58, "text": " You know, all possible pairs and doing that calculation just to even create this set of polynomial data is taking even longer than it took just for us to do the linear regression.", "tokens": [509, 458, 11, 439, 1944, 15494, 293, 884, 300, 17108, 445, 281, 754, 1884, 341, 992, 295, 26110, 1412, 307, 1940, 754, 2854, 813, 309, 1890, 445, 337, 505, 281, 360, 264, 8213, 24590, 13], "temperature": 0.0, "avg_logprob": -0.07658598746782468, "compression_ratio": 1.688073394495413, "no_speech_prob": 3.2695879781385884e-05}, {"id": 555, "seek": 477558, "start": 4775.58, "end": 4785.58, "text": " So we're still going to have to do a linear regression on this this new data set. So this is this is kind of a time concern.", "tokens": [407, 321, 434, 920, 516, 281, 362, 281, 360, 257, 8213, 24590, 322, 341, 341, 777, 1412, 992, 13, 407, 341, 307, 341, 307, 733, 295, 257, 565, 3136, 13], "temperature": 0.0, "avg_logprob": -0.08836576768330165, "compression_ratio": 1.532846715328467, "no_speech_prob": 2.15676436710055e-06}, {"id": 556, "seek": 477558, "start": 4785.58, "end": 4797.58, "text": " So it's something that has improved improved our air, but it's going to slow us down.", "tokens": [407, 309, 311, 746, 300, 575, 9689, 9689, 527, 1988, 11, 457, 309, 311, 516, 281, 2964, 505, 760, 13], "temperature": 0.0, "avg_logprob": -0.08836576768330165, "compression_ratio": 1.532846715328467, "no_speech_prob": 2.15676436710055e-06}, {"id": 557, "seek": 479758, "start": 4797.58, "end": 4810.58, "text": " So we're going to look at a way to speed up the future generation. First, I should stop. Are there any questions on how the polynomial features allow us to kind of create a better model than the plain linear linear regression?", "tokens": [407, 321, 434, 516, 281, 574, 412, 257, 636, 281, 3073, 493, 264, 2027, 5125, 13, 2386, 11, 286, 820, 1590, 13, 2014, 456, 604, 1651, 322, 577, 264, 26110, 4122, 2089, 505, 281, 733, 295, 1884, 257, 1101, 2316, 813, 264, 11121, 8213, 8213, 24590, 30], "temperature": 0.0, "avg_logprob": -0.10555809833964364, "compression_ratio": 1.453551912568306, "no_speech_prob": 2.3687271095695905e-06}, {"id": 558, "seek": 479758, "start": 4810.58, "end": 4819.58, "text": " But then they take longer to calculate.", "tokens": [583, 550, 436, 747, 2854, 281, 8873, 13], "temperature": 0.0, "avg_logprob": -0.10555809833964364, "compression_ratio": 1.453551912568306, "no_speech_prob": 2.3687271095695905e-06}, {"id": 559, "seek": 481958, "start": 4819.58, "end": 4827.58, "text": " OK, so we're going to use Numba today, which is a Python library that compiles directly to C.", "tokens": [2264, 11, 370, 321, 434, 516, 281, 764, 426, 49353, 965, 11, 597, 307, 257, 15329, 6405, 300, 715, 4680, 3838, 281, 383, 13], "temperature": 0.0, "avg_logprob": -0.12828173781886246, "compression_ratio": 1.369942196531792, "no_speech_prob": 3.288640300525003e-06}, {"id": 560, "seek": 481958, "start": 4827.58, "end": 4832.58, "text": " Jake Vander Plaas has some nice tutorials on them.", "tokens": [15822, 46588, 19942, 296, 575, 512, 1481, 17616, 322, 552, 13], "temperature": 0.0, "avg_logprob": -0.12828173781886246, "compression_ratio": 1.369942196531792, "no_speech_prob": 3.288640300525003e-06}, {"id": 561, "seek": 481958, "start": 4832.58, "end": 4841.58, "text": " And I like in this tutorial, he says that a lot of people ask him, isn't Python pretty slow?", "tokens": [400, 286, 411, 294, 341, 7073, 11, 415, 1619, 300, 257, 688, 295, 561, 1029, 796, 11, 1943, 380, 15329, 1238, 2964, 30], "temperature": 0.0, "avg_logprob": -0.12828173781886246, "compression_ratio": 1.369942196531792, "no_speech_prob": 3.288640300525003e-06}, {"id": 562, "seek": 484158, "start": 4841.58, "end": 4851.58, "text": " And he's kind of got an answer of why he likes and Jacob Vander Plaas, I should say, has a PhD in astrophysics and works at the University of Washington, has like a center for data science.", "tokens": [400, 415, 311, 733, 295, 658, 364, 1867, 295, 983, 415, 5902, 293, 14117, 46588, 19942, 296, 11, 286, 820, 584, 11, 575, 257, 14476, 294, 5357, 11741, 41732, 293, 1985, 412, 264, 3535, 295, 6149, 11, 575, 411, 257, 3056, 337, 1412, 3497, 13], "temperature": 0.0, "avg_logprob": -0.1023580079437584, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.4968587493058294e-05}, {"id": 563, "seek": 484158, "start": 4851.58, "end": 4859.58, "text": " And he he's a contributor to a lot of Python scientific packages and does a lot of speaking.", "tokens": [400, 415, 415, 311, 257, 42859, 281, 257, 688, 295, 15329, 8134, 17401, 293, 775, 257, 688, 295, 4124, 13], "temperature": 0.0, "avg_logprob": -0.1023580079437584, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.4968587493058294e-05}, {"id": 564, "seek": 484158, "start": 4859.58, "end": 4864.58, "text": " And also, I think helps run like University of Washington's kind of like their data science institute.", "tokens": [400, 611, 11, 286, 519, 3665, 1190, 411, 3535, 295, 6149, 311, 733, 295, 411, 641, 1412, 3497, 26860, 13], "temperature": 0.0, "avg_logprob": -0.1023580079437584, "compression_ratio": 1.696035242290749, "no_speech_prob": 1.4968587493058294e-05}, {"id": 565, "seek": 486458, "start": 4864.58, "end": 4871.58, "text": " They have like data data science for social good, summer programs and things.", "tokens": [814, 362, 411, 1412, 1412, 3497, 337, 2093, 665, 11, 4266, 4268, 293, 721, 13], "temperature": 0.0, "avg_logprob": -0.12623796657640107, "compression_ratio": 1.3694267515923566, "no_speech_prob": 2.5213923890987644e-06}, {"id": 566, "seek": 486458, "start": 4871.58, "end": 4880.58, "text": " But he goes through kind of reasons why he likes having a Python implementation as opposed to just doing the whole thing in Fortran or C.", "tokens": [583, 415, 1709, 807, 733, 295, 4112, 983, 415, 5902, 1419, 257, 15329, 11420, 382, 8851, 281, 445, 884, 264, 1379, 551, 294, 11002, 4257, 420, 383, 13], "temperature": 0.0, "avg_logprob": -0.12623796657640107, "compression_ratio": 1.3694267515923566, "no_speech_prob": 2.5213923890987644e-06}, {"id": 567, "seek": 488058, "start": 4880.58, "end": 4896.58, "text": " And it's you know, Python code is easier to read, understand and contribute to. Pure Python packages are easier to install than Python wrapped C or Fortran code.", "tokens": [400, 309, 311, 291, 458, 11, 15329, 3089, 307, 3571, 281, 1401, 11, 1223, 293, 10586, 281, 13, 29474, 15329, 17401, 366, 3571, 281, 3625, 813, 15329, 14226, 383, 420, 11002, 4257, 3089, 13], "temperature": 0.0, "avg_logprob": -0.13030802210172018, "compression_ratio": 1.3795620437956204, "no_speech_prob": 9.36777996685123e-06}, {"id": 568, "seek": 488058, "start": 4896.58, "end": 4899.58, "text": " It's easy to use its scale.", "tokens": [467, 311, 1858, 281, 764, 1080, 4373, 13], "temperature": 0.0, "avg_logprob": -0.13030802210172018, "compression_ratio": 1.3795620437956204, "no_speech_prob": 9.36777996685123e-06}, {"id": 569, "seek": 489958, "start": 4899.58, "end": 4911.58, "text": " So I think these are kind of some good good arguments for why you would want to maybe compile some of your Python code to C as opposed to just switching to C or Fortran completely.", "tokens": [407, 286, 519, 613, 366, 733, 295, 512, 665, 665, 12869, 337, 983, 291, 576, 528, 281, 1310, 31413, 512, 295, 428, 15329, 3089, 281, 383, 382, 8851, 281, 445, 16493, 281, 383, 420, 11002, 4257, 2584, 13], "temperature": 0.0, "avg_logprob": -0.10375908569053367, "compression_ratio": 1.4012738853503184, "no_speech_prob": 2.3685659016337013e-06}, {"id": 570, "seek": 489958, "start": 4911.58, "end": 4922.58, "text": " And numbers one way one way to do that.", "tokens": [400, 3547, 472, 636, 472, 636, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.10375908569053367, "compression_ratio": 1.4012738853503184, "no_speech_prob": 2.3685659016337013e-06}, {"id": 571, "seek": 492258, "start": 4922.58, "end": 4932.58, "text": " So from here from Numba, we're importing a number number of methods and decorators and types that I'll talk about as we use them.", "tokens": [407, 490, 510, 490, 426, 49353, 11, 321, 434, 43866, 257, 1230, 1230, 295, 7150, 293, 7919, 3391, 293, 3467, 300, 286, 603, 751, 466, 382, 321, 764, 552, 13], "temperature": 0.0, "avg_logprob": -0.08164997736612956, "compression_ratio": 1.6108374384236452, "no_speech_prob": 9.079632036446128e-06}, {"id": 572, "seek": 492258, "start": 4932.58, "end": 4951.58, "text": " So we're going to step back from the problem of this linear regression or polynomial feature generation and just talk about what number is and how to use it and kind of go through a sample problem.", "tokens": [407, 321, 434, 516, 281, 1823, 646, 490, 264, 1154, 295, 341, 8213, 24590, 420, 26110, 4111, 5125, 293, 445, 751, 466, 437, 1230, 307, 293, 577, 281, 764, 309, 293, 733, 295, 352, 807, 257, 6889, 1154, 13], "temperature": 0.0, "avg_logprob": -0.08164997736612956, "compression_ratio": 1.6108374384236452, "no_speech_prob": 9.079632036446128e-06}, {"id": 573, "seek": 495158, "start": 4951.58, "end": 4963.58, "text": " So Numba is going to allow us to kind of avoid memory allocations and copies and give us better locality.", "tokens": [407, 426, 49353, 307, 516, 281, 2089, 505, 281, 733, 295, 5042, 4675, 12660, 763, 293, 14341, 293, 976, 505, 1101, 1628, 1860, 13], "temperature": 0.0, "avg_logprob": -0.07328306117527922, "compression_ratio": 1.5666666666666667, "no_speech_prob": 2.994185479110456e-06}, {"id": 574, "seek": 495158, "start": 4963.58, "end": 4966.58, "text": " So we're going to start with kind of this toy example.", "tokens": [407, 321, 434, 516, 281, 722, 365, 733, 295, 341, 12058, 1365, 13], "temperature": 0.0, "avg_logprob": -0.07328306117527922, "compression_ratio": 1.5666666666666667, "no_speech_prob": 2.994185479110456e-06}, {"id": 575, "seek": 495158, "start": 4966.58, "end": 4977.58, "text": " So this is something just in plain Python and NumPy where we have some number of observations that we're looping through.", "tokens": [407, 341, 307, 746, 445, 294, 11121, 15329, 293, 22592, 47, 88, 689, 321, 362, 512, 1230, 295, 18163, 300, 321, 434, 6367, 278, 807, 13], "temperature": 0.0, "avg_logprob": -0.07328306117527922, "compression_ratio": 1.5666666666666667, "no_speech_prob": 2.994185479110456e-06}, {"id": 576, "seek": 497758, "start": 4977.58, "end": 4984.58, "text": " We've got two different arrays X and Y and we kind of want to take each each value and X and Y.", "tokens": [492, 600, 658, 732, 819, 41011, 1783, 293, 398, 293, 321, 733, 295, 528, 281, 747, 1184, 1184, 2158, 293, 1783, 293, 398, 13], "temperature": 0.0, "avg_logprob": -0.16523389021555582, "compression_ratio": 1.4228571428571428, "no_speech_prob": 5.1737238209170755e-06}, {"id": 577, "seek": 497758, "start": 4984.58, "end": 4993.58, "text": " Do some computations on them and then store them in a raise Z. So this is just a process in Python.", "tokens": [1144, 512, 2807, 763, 322, 552, 293, 550, 3531, 552, 294, 257, 5300, 1176, 13, 407, 341, 307, 445, 257, 1399, 294, 15329, 13], "temperature": 0.0, "avg_logprob": -0.16523389021555582, "compression_ratio": 1.4228571428571428, "no_speech_prob": 5.1737238209170755e-06}, {"id": 578, "seek": 497758, "start": 4993.58, "end": 5000.58, "text": " Notice since we're using NumPy we can give ZZ a type.", "tokens": [13428, 1670, 321, 434, 1228, 22592, 47, 88, 321, 393, 976, 1176, 57, 257, 2010, 13], "temperature": 0.0, "avg_logprob": -0.16523389021555582, "compression_ratio": 1.4228571428571428, "no_speech_prob": 5.1737238209170755e-06}, {"id": 579, "seek": 500058, "start": 5000.58, "end": 5016.58, "text": " This is our I'll ask you do do X and Y have types here.", "tokens": [639, 307, 527, 286, 603, 1029, 291, 360, 360, 1783, 293, 398, 362, 3467, 510, 13], "temperature": 0.0, "avg_logprob": -0.21601171493530275, "compression_ratio": 0.9322033898305084, "no_speech_prob": 1.1841926607303321e-05}, {"id": 580, "seek": 501658, "start": 5016.58, "end": 5040.58, "text": " And actually this is confusing because I named these variables X and Y do X and Y inside inside this inner loop have types.", "tokens": [400, 767, 341, 307, 13181, 570, 286, 4926, 613, 9102, 1783, 293, 398, 360, 1783, 293, 398, 1854, 1854, 341, 7284, 6367, 362, 3467, 13], "temperature": 0.0, "avg_logprob": -0.09781018618879647, "compression_ratio": 1.2551020408163265, "no_speech_prob": 2.0138821128057316e-05}, {"id": 581, "seek": 504058, "start": 5040.58, "end": 5049.58, "text": " So anyone want to make a guess. So so now I'm suggesting float 32.", "tokens": [407, 2878, 528, 281, 652, 257, 2041, 13, 407, 370, 586, 286, 478, 18094, 15706, 8858, 13], "temperature": 0.0, "avg_logprob": -0.14282271505772381, "compression_ratio": 1.6225490196078431, "no_speech_prob": 5.95395840718993e-06}, {"id": 582, "seek": 504058, "start": 5049.58, "end": 5059.58, "text": " So for our arrays X and Y that we're passing in we have float 32 and ditto for ZZ where we're going to put our result we have float 32.", "tokens": [407, 337, 527, 41011, 1783, 293, 398, 300, 321, 434, 8437, 294, 321, 362, 15706, 8858, 293, 274, 34924, 337, 1176, 57, 689, 321, 434, 516, 281, 829, 527, 1874, 321, 362, 15706, 8858, 13], "temperature": 0.0, "avg_logprob": -0.14282271505772381, "compression_ratio": 1.6225490196078431, "no_speech_prob": 5.95395840718993e-06}, {"id": 583, "seek": 504058, "start": 5059.58, "end": 5068.58, "text": " But here inside the loop we have these kind of just temporary variables X and Y we're using and those don't have specific types.", "tokens": [583, 510, 1854, 264, 6367, 321, 362, 613, 733, 295, 445, 13413, 9102, 1783, 293, 398, 321, 434, 1228, 293, 729, 500, 380, 362, 2685, 3467, 13], "temperature": 0.0, "avg_logprob": -0.14282271505772381, "compression_ratio": 1.6225490196078431, "no_speech_prob": 5.95395840718993e-06}, {"id": 584, "seek": 506858, "start": 5068.58, "end": 5073.58, "text": " So even though they're actually all we're always going to be putting float 32s in them.", "tokens": [407, 754, 1673, 436, 434, 767, 439, 321, 434, 1009, 516, 281, 312, 3372, 15706, 8858, 82, 294, 552, 13], "temperature": 0.0, "avg_logprob": -0.12777950824835363, "compression_ratio": 1.605, "no_speech_prob": 4.860264652961632e-06}, {"id": 585, "seek": 506858, "start": 5073.58, "end": 5091.58, "text": " Python doesn't know that. And that's kind of one of the things that so Python is not a typed language but in language type languages like C or C plus plus you have to say you know what what type of variable it is when you declare it.", "tokens": [15329, 1177, 380, 458, 300, 13, 400, 300, 311, 733, 295, 472, 295, 264, 721, 300, 370, 15329, 307, 406, 257, 33941, 2856, 457, 294, 2856, 2010, 8650, 411, 383, 420, 383, 1804, 1804, 291, 362, 281, 584, 291, 458, 437, 437, 2010, 295, 7006, 309, 307, 562, 291, 19710, 309, 13], "temperature": 0.0, "avg_logprob": -0.12777950824835363, "compression_ratio": 1.605, "no_speech_prob": 4.860264652961632e-06}, {"id": 586, "seek": 509158, "start": 5091.58, "end": 5100.58, "text": " And that you know lets and lets it know how much memory to set aside. And so it's kind of better for optimization.", "tokens": [400, 300, 291, 458, 6653, 293, 6653, 309, 458, 577, 709, 4675, 281, 992, 7359, 13, 400, 370, 309, 311, 733, 295, 1101, 337, 19618, 13], "temperature": 0.0, "avg_logprob": -0.08297703095844813, "compression_ratio": 1.49375, "no_speech_prob": 5.989101623526949e-07}, {"id": 587, "seek": 509158, "start": 5100.58, "end": 5114.58, "text": " Although some people prefer that you know Python is flexible and you can give it different types and not have to declare it.", "tokens": [5780, 512, 561, 4382, 300, 291, 458, 15329, 307, 11358, 293, 291, 393, 976, 309, 819, 3467, 293, 406, 362, 281, 19710, 309, 13], "temperature": 0.0, "avg_logprob": -0.08297703095844813, "compression_ratio": 1.49375, "no_speech_prob": 5.989101623526949e-07}, {"id": 588, "seek": 511458, "start": 5114.58, "end": 5124.58, "text": " So here we're timing this time to just kind of take in our two arrays go through each of them do all these operations and create an output.", "tokens": [407, 510, 321, 434, 10822, 341, 565, 281, 445, 733, 295, 747, 294, 527, 732, 41011, 352, 807, 1184, 295, 552, 360, 439, 613, 7705, 293, 1884, 364, 5598, 13], "temperature": 0.0, "avg_logprob": -0.08183487918641832, "compression_ratio": 1.4947916666666667, "no_speech_prob": 2.769241291389335e-06}, {"id": 589, "seek": 511458, "start": 5124.58, "end": 5132.58, "text": " And that's taking 49 milliseconds. So this was a kind of the worst version.", "tokens": [400, 300, 311, 1940, 16513, 34184, 13, 407, 341, 390, 257, 733, 295, 264, 5855, 3037, 13], "temperature": 0.0, "avg_logprob": -0.08183487918641832, "compression_ratio": 1.4947916666666667, "no_speech_prob": 2.769241291389335e-06}, {"id": 590, "seek": 511458, "start": 5132.58, "end": 5140.58, "text": " What would be a way before we even get to number a way to improve this.", "tokens": [708, 576, 312, 257, 636, 949, 321, 754, 483, 281, 1230, 257, 636, 281, 3470, 341, 13], "temperature": 0.0, "avg_logprob": -0.08183487918641832, "compression_ratio": 1.4947916666666667, "no_speech_prob": 2.769241291389335e-06}, {"id": 591, "seek": 514058, "start": 5140.58, "end": 5151.58, "text": " To speed it up.", "tokens": [1407, 3073, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.36101849873860675, "compression_ratio": 0.9122807017543859, "no_speech_prob": 1.496721597504802e-05}, {"id": 592, "seek": 514058, "start": 5151.58, "end": 5155.58, "text": " Oh wait Jeremy throw the microphone.", "tokens": [876, 1699, 17809, 3507, 264, 10952, 13], "temperature": 0.0, "avg_logprob": -0.36101849873860675, "compression_ratio": 0.9122807017543859, "no_speech_prob": 1.496721597504802e-05}, {"id": 593, "seek": 515558, "start": 5155.58, "end": 5174.58, "text": " Yes. Yes. Yeah. So this this for loop seems like a bad idea because it's like we're individually going through each each pair of elements in the arrays.", "tokens": [1079, 13, 1079, 13, 865, 13, 407, 341, 341, 337, 6367, 2544, 411, 257, 1578, 1558, 570, 309, 311, 411, 321, 434, 16652, 516, 807, 1184, 1184, 6119, 295, 4959, 294, 264, 41011, 13], "temperature": 0.0, "avg_logprob": -0.19533145838770374, "compression_ratio": 1.4012738853503184, "no_speech_prob": 3.28826172335539e-06}, {"id": 594, "seek": 515558, "start": 5174.58, "end": 5180.58, "text": " We're doing the exact same thing. But NumPy lets us vectorize that.", "tokens": [492, 434, 884, 264, 1900, 912, 551, 13, 583, 22592, 47, 88, 6653, 505, 8062, 1125, 300, 13], "temperature": 0.0, "avg_logprob": -0.19533145838770374, "compression_ratio": 1.4012738853503184, "no_speech_prob": 3.28826172335539e-06}, {"id": 595, "seek": 518058, "start": 5180.58, "end": 5189.58, "text": " So we can here take out the for loop all together and kind of just do the operations on the entire matrices thanks to NumPy.", "tokens": [407, 321, 393, 510, 747, 484, 264, 337, 6367, 439, 1214, 293, 733, 295, 445, 360, 264, 7705, 322, 264, 2302, 32284, 3231, 281, 22592, 47, 88, 13], "temperature": 0.0, "avg_logprob": -0.10995396931966146, "compression_ratio": 1.5380710659898478, "no_speech_prob": 1.165870617114706e-05}, {"id": 596, "seek": 518058, "start": 5189.58, "end": 5197.58, "text": " And so if we compare this was 49 milliseconds. This is 35 microseconds.", "tokens": [400, 370, 498, 321, 6794, 341, 390, 16513, 34184, 13, 639, 307, 6976, 3123, 37841, 28750, 13], "temperature": 0.0, "avg_logprob": -0.10995396931966146, "compression_ratio": 1.5380710659898478, "no_speech_prob": 1.165870617114706e-05}, {"id": 597, "seek": 518058, "start": 5197.58, "end": 5206.58, "text": " So notice that's a over a thousand times better. The units have changed from milliseconds to microseconds.", "tokens": [407, 3449, 300, 311, 257, 670, 257, 4714, 1413, 1101, 13, 440, 6815, 362, 3105, 490, 34184, 281, 3123, 37841, 28750, 13], "temperature": 0.0, "avg_logprob": -0.10995396931966146, "compression_ratio": 1.5380710659898478, "no_speech_prob": 1.165870617114706e-05}, {"id": 598, "seek": 520658, "start": 5206.58, "end": 5218.58, "text": " So that's a big speed up. So that's really great that NumPy lets us vectorize.", "tokens": [407, 300, 311, 257, 955, 3073, 493, 13, 407, 300, 311, 534, 869, 300, 22592, 47, 88, 6653, 505, 8062, 1125, 13], "temperature": 0.0, "avg_logprob": -0.0977664480403978, "compression_ratio": 1.3430656934306568, "no_speech_prob": 1.8447877891958342e-06}, {"id": 599, "seek": 520658, "start": 5218.58, "end": 5230.58, "text": " Does anyone remember the other kind of technical term or buzzword that we often say along with vectorize.", "tokens": [4402, 2878, 1604, 264, 661, 733, 295, 6191, 1433, 420, 13036, 7462, 300, 321, 2049, 584, 2051, 365, 8062, 1125, 13], "temperature": 0.0, "avg_logprob": -0.0977664480403978, "compression_ratio": 1.3430656934306568, "no_speech_prob": 1.8447877891958342e-06}, {"id": 600, "seek": 523058, "start": 5230.58, "end": 5236.58, "text": " It's actually an acronym.", "tokens": [467, 311, 767, 364, 39195, 13], "temperature": 0.0, "avg_logprob": -0.21149678230285646, "compression_ratio": 0.8064516129032258, "no_speech_prob": 1.0450749869050924e-05}, {"id": 601, "seek": 523658, "start": 5236.58, "end": 5260.58, "text": " Yeah SIMD. So single instruction multiple data. So that's what NumPy is letting us do here because we are doing the same same instruction on all these different entries in X and Y.", "tokens": [865, 24738, 35, 13, 407, 2167, 10951, 3866, 1412, 13, 407, 300, 311, 437, 22592, 47, 88, 307, 8295, 505, 360, 510, 570, 321, 366, 884, 264, 912, 912, 10951, 322, 439, 613, 819, 23041, 294, 1783, 293, 398, 13], "temperature": 0.0, "avg_logprob": -0.1607238704508001, "compression_ratio": 1.3333333333333333, "no_speech_prob": 6.338778348435881e-06}, {"id": 602, "seek": 526058, "start": 5260.58, "end": 5281.58, "text": " So now number has something called a just in time compiler decorator and in Python decorators are kind of these methods that are applied to functions to kind of alter how your function works that show up with an at sign above the above the method.", "tokens": [407, 586, 1230, 575, 746, 1219, 257, 445, 294, 565, 31958, 7919, 1639, 293, 294, 15329, 7919, 3391, 366, 733, 295, 613, 7150, 300, 366, 6456, 281, 6828, 281, 733, 295, 11337, 577, 428, 2445, 1985, 300, 855, 493, 365, 364, 412, 1465, 3673, 264, 3673, 264, 3170, 13], "temperature": 0.0, "avg_logprob": -0.11747270260217055, "compression_ratio": 1.6143790849673203, "no_speech_prob": 7.0715836955059785e-06}, {"id": 603, "seek": 528158, "start": 5281.58, "end": 5295.58, "text": " So this is pretty simple. So we imported JIT from number above again JIT stands for just in time compiler and we just add add JIT on top here.", "tokens": [407, 341, 307, 1238, 2199, 13, 407, 321, 25524, 508, 3927, 490, 1230, 3673, 797, 508, 3927, 7382, 337, 445, 294, 565, 31958, 293, 321, 445, 909, 909, 508, 3927, 322, 1192, 510, 13], "temperature": 0.0, "avg_logprob": -0.14357855660574778, "compression_ratio": 1.5, "no_speech_prob": 4.0926602196122985e-06}, {"id": 604, "seek": 528158, "start": 5295.58, "end": 5308.58, "text": " Apply it to. So we've got our for loop back. So this is kind of where this is the code from the top original Python process.", "tokens": [25264, 309, 281, 13, 407, 321, 600, 658, 527, 337, 6367, 646, 13, 407, 341, 307, 733, 295, 689, 341, 307, 264, 3089, 490, 264, 1192, 3380, 15329, 1399, 13], "temperature": 0.0, "avg_logprob": -0.14357855660574778, "compression_ratio": 1.5, "no_speech_prob": 4.0926602196122985e-06}, {"id": 605, "seek": 530858, "start": 5308.58, "end": 5319.58, "text": " And what this does is so we're no longer vectorizing but we do have better better locality here.", "tokens": [400, 437, 341, 775, 307, 370, 321, 434, 572, 2854, 8062, 3319, 457, 321, 360, 362, 1101, 1101, 1628, 1860, 510, 13], "temperature": 0.0, "avg_logprob": -0.08608820805182824, "compression_ratio": 1.1294117647058823, "no_speech_prob": 1.012936991173774e-05}, {"id": 606, "seek": 531958, "start": 5319.58, "end": 5348.58, "text": " And now when we run it we're down to six microseconds. So the version with NumPy was almost 36 microseconds. So this is six times quicker. And then the one in plain Python with the for loop was really slow. That was like 50 50 milliseconds.", "tokens": [400, 586, 562, 321, 1190, 309, 321, 434, 760, 281, 2309, 3123, 37841, 28750, 13, 407, 264, 3037, 365, 22592, 47, 88, 390, 1920, 8652, 3123, 37841, 28750, 13, 407, 341, 307, 2309, 1413, 16255, 13, 400, 550, 264, 472, 294, 11121, 15329, 365, 264, 337, 6367, 390, 534, 2964, 13, 663, 390, 411, 2625, 2625, 34184, 13], "temperature": 0.0, "avg_logprob": -0.09678540691252678, "compression_ratio": 1.4814814814814814, "no_speech_prob": 1.602730435479316e-06}, {"id": 607, "seek": 534858, "start": 5348.58, "end": 5360.58, "text": " Does anyone want to say what does it mean to have better better locality.", "tokens": [4402, 2878, 528, 281, 584, 437, 775, 309, 914, 281, 362, 1101, 1101, 1628, 1860, 13], "temperature": 0.0, "avg_logprob": -0.1750965118408203, "compression_ratio": 1.1808510638297873, "no_speech_prob": 4.330897718318738e-05}, {"id": 608, "seek": 534858, "start": 5360.58, "end": 5366.58, "text": " Kind of learned about this with Brad.", "tokens": [9242, 295, 3264, 466, 341, 365, 11895, 13], "temperature": 0.0, "avg_logprob": -0.1750965118408203, "compression_ratio": 1.1808510638297873, "no_speech_prob": 4.330897718318738e-05}, {"id": 609, "seek": 536658, "start": 5366.58, "end": 5386.58, "text": " It means that the memory is stored on the device. Yes. Yeah. So it's what it's it's you're kind of you're accessing data that's close to each other in memory.", "tokens": [467, 1355, 300, 264, 4675, 307, 12187, 322, 264, 4302, 13, 1079, 13, 865, 13, 407, 309, 311, 437, 309, 311, 309, 311, 291, 434, 733, 295, 291, 434, 26440, 1412, 300, 311, 1998, 281, 1184, 661, 294, 4675, 13], "temperature": 0.0, "avg_logprob": -0.28455571694807574, "compression_ratio": 1.3620689655172413, "no_speech_prob": 7.887638275860809e-06}, {"id": 610, "seek": 538658, "start": 5386.58, "end": 5397.58, "text": " Yeah. So it's often I mean you can talk about time locality or space locality but it's kind of using things that you access.", "tokens": [865, 13, 407, 309, 311, 2049, 286, 914, 291, 393, 751, 466, 565, 1628, 1860, 420, 1901, 1628, 1860, 457, 309, 311, 733, 295, 1228, 721, 300, 291, 2105, 13], "temperature": 0.0, "avg_logprob": -0.12401349336198232, "compression_ratio": 1.944915254237288, "no_speech_prob": 5.337783932191087e-06}, {"id": 611, "seek": 538658, "start": 5397.58, "end": 5415.58, "text": " Kind of like when you access or when you access something use it multiple times before you write it back to slow memory. So kind of like while you have it in fast memory like do all the operations you need with it as opposed to writing something you know or carrying something from slow memory to fast using it taking it back to slow.", "tokens": [9242, 295, 411, 562, 291, 2105, 420, 562, 291, 2105, 746, 764, 309, 3866, 1413, 949, 291, 2464, 309, 646, 281, 2964, 4675, 13, 407, 733, 295, 411, 1339, 291, 362, 309, 294, 2370, 4675, 411, 360, 439, 264, 7705, 291, 643, 365, 309, 382, 8851, 281, 3579, 746, 291, 458, 420, 9792, 746, 490, 2964, 4675, 281, 2370, 1228, 309, 1940, 309, 646, 281, 2964, 13], "temperature": 0.0, "avg_logprob": -0.12401349336198232, "compression_ratio": 1.944915254237288, "no_speech_prob": 5.337783932191087e-06}, {"id": 612, "seek": 541558, "start": 5415.58, "end": 5432.58, "text": " Bringing it to fast again using it again trying to consolidate all those uses and then yeah and using things next to each other. Great. Thank you.", "tokens": [45241, 309, 281, 2370, 797, 1228, 309, 797, 1382, 281, 49521, 439, 729, 4960, 293, 550, 1338, 293, 1228, 721, 958, 281, 1184, 661, 13, 3769, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.13658607707304113, "compression_ratio": 1.3394495412844036, "no_speech_prob": 7.410699708998436e-06}, {"id": 613, "seek": 543258, "start": 5432.58, "end": 5450.58, "text": " And so here it can seem kind of counterintuitive that we've put the for loop back in. But the idea is that we're kind of you know we're picking up X and Y which we need and then we do a bunch of operations with X and Y.", "tokens": [400, 370, 510, 309, 393, 1643, 733, 295, 5682, 686, 48314, 300, 321, 600, 829, 264, 337, 6367, 646, 294, 13, 583, 264, 1558, 307, 300, 321, 434, 733, 295, 291, 458, 321, 434, 8867, 493, 1783, 293, 398, 597, 321, 643, 293, 550, 321, 360, 257, 3840, 295, 7705, 365, 1783, 293, 398, 13], "temperature": 0.0, "avg_logprob": -0.10028111732612222, "compression_ratio": 1.5208333333333333, "no_speech_prob": 4.936367531627184e-06}, {"id": 614, "seek": 545058, "start": 5450.58, "end": 5470.58, "text": " And this is you know this is kind of a toy toy example but you could have a more complicated algorithm where you are you know using them multiple times. What would happen what would happen if we were doing this in NumPy without the for loop.", "tokens": [400, 341, 307, 291, 458, 341, 307, 733, 295, 257, 12058, 12058, 1365, 457, 291, 727, 362, 257, 544, 6179, 9284, 689, 291, 366, 291, 458, 1228, 552, 3866, 1413, 13, 708, 576, 1051, 437, 576, 1051, 498, 321, 645, 884, 341, 294, 22592, 47, 88, 1553, 264, 337, 6367, 13], "temperature": 0.0, "avg_logprob": -0.12180960395119407, "compression_ratio": 1.535031847133758, "no_speech_prob": 3.0115504046079877e-07}, {"id": 615, "seek": 547058, "start": 5470.58, "end": 5490.58, "text": " So kind of this example up here has potentially has poor locality. Why is that?", "tokens": [407, 733, 295, 341, 1365, 493, 510, 575, 7263, 575, 4716, 1628, 1860, 13, 1545, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.1660365624861284, "compression_ratio": 1.025974025974026, "no_speech_prob": 4.222681582177756e-06}, {"id": 616, "seek": 549058, "start": 5490.58, "end": 5518.58, "text": " Sam.", "tokens": [4832, 13], "temperature": 0.0, "avg_logprob": -0.26325831810633343, "compression_ratio": 0.3333333333333333, "no_speech_prob": 0.00020642792514991015}, {"id": 617, "seek": 551858, "start": 5518.58, "end": 5542.58, "text": " Yes. Yeah. So the issue with the NumPy array is if you want to do something on all of X maybe all of X doesn't fit in cache and so you're pulling in part of it you know doing the operation on that part then you have to pull in the next part of X do the operation on that part pull in another part of X do the operation on that part and then you go into the next line and you're like oh I need the first part of X again.", "tokens": [1079, 13, 865, 13, 407, 264, 2734, 365, 264, 22592, 47, 88, 10225, 307, 498, 291, 528, 281, 360, 746, 322, 439, 295, 1783, 1310, 439, 295, 1783, 1177, 380, 3318, 294, 19459, 293, 370, 291, 434, 8407, 294, 644, 295, 309, 291, 458, 884, 264, 6916, 322, 300, 644, 550, 291, 362, 281, 2235, 294, 264, 958, 644, 295, 1783, 360, 264, 6916, 322, 300, 644, 2235, 294, 1071, 644, 295, 1783, 360, 264, 6916, 322, 300, 644, 293, 550, 291, 352, 666, 264, 958, 1622, 293, 291, 434, 411, 1954, 286, 643, 264, 700, 644, 295, 1783, 797, 13], "temperature": 0.0, "avg_logprob": -0.12067070915585472, "compression_ratio": 1.9671361502347418, "no_speech_prob": 1.8920985894510522e-05}, {"id": 618, "seek": 554258, "start": 5542.58, "end": 5549.58, "text": " And this is you know if X is a really long array. Thank you.", "tokens": [400, 341, 307, 291, 458, 498, 1783, 307, 257, 534, 938, 10225, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.14498806993166605, "compression_ratio": 1.3255813953488371, "no_speech_prob": 4.0293525671586394e-06}, {"id": 619, "seek": 554258, "start": 5549.58, "end": 5554.58, "text": " Questions about this.", "tokens": [27738, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.14498806993166605, "compression_ratio": 1.3255813953488371, "no_speech_prob": 4.0293525671586394e-06}, {"id": 620, "seek": 554258, "start": 5554.58, "end": 5565.58, "text": " These are kind of getting at the concepts we saw back in week one with the Halide video.", "tokens": [1981, 366, 733, 295, 1242, 412, 264, 10392, 321, 1866, 646, 294, 1243, 472, 365, 264, 13896, 482, 960, 13], "temperature": 0.0, "avg_logprob": -0.14498806993166605, "compression_ratio": 1.3255813953488371, "no_speech_prob": 4.0293525671586394e-06}, {"id": 621, "seek": 556558, "start": 5565.58, "end": 5587.58, "text": " Okay so let's go on to make this even a little bit better. Numba also has a vectorized decorator. So here we're using Numba instead of NumPy. So at this one we use the just in time compiler decorator and kept the for loop.", "tokens": [1033, 370, 718, 311, 352, 322, 281, 652, 341, 754, 257, 707, 857, 1101, 13, 426, 49353, 611, 575, 257, 8062, 1602, 7919, 1639, 13, 407, 510, 321, 434, 1228, 426, 49353, 2602, 295, 22592, 47, 88, 13, 407, 412, 341, 472, 321, 764, 264, 445, 294, 565, 31958, 7919, 1639, 293, 4305, 264, 337, 6367, 13], "temperature": 0.0, "avg_logprob": -0.13562871589035283, "compression_ratio": 1.4415584415584415, "no_speech_prob": 9.367719940200914e-06}, {"id": 622, "seek": 558758, "start": 5587.58, "end": 5595.58, "text": " So we're taking out the for loop. Just have the vectorized decorator.", "tokens": [407, 321, 434, 1940, 484, 264, 337, 6367, 13, 1449, 362, 264, 8062, 1602, 7919, 1639, 13], "temperature": 0.0, "avg_logprob": -0.16324545631945972, "compression_ratio": 1.387434554973822, "no_speech_prob": 1.1478040505608078e-05}, {"id": 623, "seek": 558758, "start": 5595.58, "end": 5614.58, "text": " And it's actually like I mean it's almost equivalent to the using the just in time compiler which was 6.4 microseconds this is 5.8. But it's kind of good to know these two different options. Tim.", "tokens": [400, 309, 311, 767, 411, 286, 914, 309, 311, 1920, 10344, 281, 264, 1228, 264, 445, 294, 565, 31958, 597, 390, 1386, 13, 19, 3123, 37841, 28750, 341, 307, 1025, 13, 23, 13, 583, 309, 311, 733, 295, 665, 281, 458, 613, 732, 819, 3956, 13, 7172, 13], "temperature": 0.0, "avg_logprob": -0.16324545631945972, "compression_ratio": 1.387434554973822, "no_speech_prob": 1.1478040505608078e-05}, {"id": 624, "seek": 561458, "start": 5614.58, "end": 5622.58, "text": " So this is.", "tokens": [407, 341, 307, 13], "temperature": 0.0, "avg_logprob": -0.27228267669677736, "compression_ratio": 1.1095890410958904, "no_speech_prob": 4.9079240852734074e-05}, {"id": 625, "seek": 561458, "start": 5622.58, "end": 5627.58, "text": " This is still compiling to see so it's still optimizing what happens.", "tokens": [639, 307, 920, 715, 4883, 281, 536, 370, 309, 311, 920, 40425, 437, 2314, 13], "temperature": 0.0, "avg_logprob": -0.27228267669677736, "compression_ratio": 1.1095890410958904, "no_speech_prob": 4.9079240852734074e-05}, {"id": 626, "seek": 562758, "start": 5627.58, "end": 5645.58, "text": " So it's not doing like with NumPy where it's doing this like you know having to use all of X so it's you know might pull the first part of X into cache and then pull in the second part and then pull in the third part and then the next line it has to use X again so it starts again with the first part of X.", "tokens": [407, 309, 311, 406, 884, 411, 365, 22592, 47, 88, 689, 309, 311, 884, 341, 411, 291, 458, 1419, 281, 764, 439, 295, 1783, 370, 309, 311, 291, 458, 1062, 2235, 264, 700, 644, 295, 1783, 666, 19459, 293, 550, 2235, 294, 264, 1150, 644, 293, 550, 2235, 294, 264, 2636, 644, 293, 550, 264, 958, 1622, 309, 575, 281, 764, 1783, 797, 370, 309, 3719, 797, 365, 264, 700, 644, 295, 1783, 13], "temperature": 0.0, "avg_logprob": -0.08784590485275433, "compression_ratio": 1.9042553191489362, "no_speech_prob": 2.3185057216323912e-05}, {"id": 627, "seek": 562758, "start": 5645.58, "end": 5650.58, "text": " Numba has optimized that away so it's not going to.", "tokens": [426, 49353, 575, 26941, 300, 1314, 370, 309, 311, 406, 516, 281, 13], "temperature": 0.0, "avg_logprob": -0.08784590485275433, "compression_ratio": 1.9042553191489362, "no_speech_prob": 2.3185057216323912e-05}, {"id": 628, "seek": 565058, "start": 5650.58, "end": 5676.58, "text": " Yeah do that sort of thing and the reason Numba is able to do this is because it's compiling to see. So Python like when it's running dynamically it doesn't know that I'm going to use X again in the next line and so this is kind of wasteful that I'm pulling each section into cache and then putting them back when I'm going to have to do that again.", "tokens": [865, 360, 300, 1333, 295, 551, 293, 264, 1778, 426, 49353, 307, 1075, 281, 360, 341, 307, 570, 309, 311, 715, 4883, 281, 536, 13, 407, 15329, 411, 562, 309, 311, 2614, 43492, 309, 1177, 380, 458, 300, 286, 478, 516, 281, 764, 1783, 797, 294, 264, 958, 1622, 293, 370, 341, 307, 733, 295, 5964, 906, 300, 286, 478, 8407, 1184, 3541, 666, 19459, 293, 550, 3372, 552, 646, 562, 286, 478, 516, 281, 362, 281, 360, 300, 797, 13], "temperature": 0.0, "avg_logprob": -0.16087564580580768, "compression_ratio": 1.661904761904762, "no_speech_prob": 2.014432720898185e-05}, {"id": 629, "seek": 567658, "start": 5676.58, "end": 5687.58, "text": " So it's kind of like one line from now whereas C is able to optimize things like that and so that's kind of what numbers getting you is this.", "tokens": [407, 309, 311, 733, 295, 411, 472, 1622, 490, 586, 9735, 383, 307, 1075, 281, 19719, 721, 411, 300, 293, 370, 300, 311, 733, 295, 437, 3547, 1242, 291, 307, 341, 13], "temperature": 0.0, "avg_logprob": -0.24012541048454517, "compression_ratio": 1.565217391304348, "no_speech_prob": 3.480582745396532e-05}, {"id": 630, "seek": 567658, "start": 5687.58, "end": 5693.58, "text": " Kind of big picture optimization.", "tokens": [9242, 295, 955, 3036, 19618, 13], "temperature": 0.0, "avg_logprob": -0.24012541048454517, "compression_ratio": 1.565217391304348, "no_speech_prob": 3.480582745396532e-05}, {"id": 631, "seek": 567658, "start": 5693.58, "end": 5700.58, "text": " NumPy does you see yes that's true but that's kind of on an operation scale.", "tokens": [22592, 47, 88, 775, 291, 536, 2086, 300, 311, 2074, 457, 300, 311, 733, 295, 322, 364, 6916, 4373, 13], "temperature": 0.0, "avg_logprob": -0.24012541048454517, "compression_ratio": 1.565217391304348, "no_speech_prob": 3.480582745396532e-05}, {"id": 632, "seek": 570058, "start": 5700.58, "end": 5721.58, "text": " Yes yeah yeah whereas here even though NumPy is using C on an operation scale you still kind of it doesn't have this knowledge between lines of like hey I'm using X in this line but I'm about to use X again in this very next line.", "tokens": [1079, 1338, 1338, 9735, 510, 754, 1673, 22592, 47, 88, 307, 1228, 383, 322, 364, 6916, 4373, 291, 920, 733, 295, 309, 1177, 380, 362, 341, 3601, 1296, 3876, 295, 411, 4177, 286, 478, 1228, 1783, 294, 341, 1622, 457, 286, 478, 466, 281, 764, 1783, 797, 294, 341, 588, 958, 1622, 13], "temperature": 0.0, "avg_logprob": -0.1581419804057137, "compression_ratio": 1.4303030303030304, "no_speech_prob": 1.0288683370163199e-05}, {"id": 633, "seek": 570058, "start": 5721.58, "end": 5723.58, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.1581419804057137, "compression_ratio": 1.4303030303030304, "no_speech_prob": 1.0288683370163199e-05}, {"id": 634, "seek": 572358, "start": 5723.58, "end": 5734.58, "text": " I'm just looking at time. I don't think it's a super quick question as well is could we wrap this in another decorator for just in time like could we also just in time to vectorize or that not work.", "tokens": [286, 478, 445, 1237, 412, 565, 13, 286, 500, 380, 519, 309, 311, 257, 1687, 1702, 1168, 382, 731, 307, 727, 321, 7019, 341, 294, 1071, 7919, 1639, 337, 445, 294, 565, 411, 727, 321, 611, 445, 294, 565, 281, 8062, 1125, 420, 300, 406, 589, 13], "temperature": 0.0, "avg_logprob": -0.2660112734194155, "compression_ratio": 1.5968586387434556, "no_speech_prob": 8.528726539225318e-06}, {"id": 635, "seek": 572358, "start": 5734.58, "end": 5743.58, "text": " I'm actually not sure about that. I think they recommend just using one but I'll I can look at that.", "tokens": [286, 478, 767, 406, 988, 466, 300, 13, 286, 519, 436, 2748, 445, 1228, 472, 457, 286, 603, 286, 393, 574, 412, 300, 13], "temperature": 0.0, "avg_logprob": -0.2660112734194155, "compression_ratio": 1.5968586387434556, "no_speech_prob": 8.528726539225318e-06}, {"id": 636, "seek": 572358, "start": 5743.58, "end": 5748.58, "text": " What.", "tokens": [708, 13], "temperature": 0.0, "avg_logprob": -0.2660112734194155, "compression_ratio": 1.5968586387434556, "no_speech_prob": 8.528726539225318e-06}, {"id": 637, "seek": 574858, "start": 5748.58, "end": 5753.58, "text": " Using.", "tokens": [11142, 13], "temperature": 0.0, "avg_logprob": -0.36631035804748535, "compression_ratio": 0.7837837837837838, "no_speech_prob": 6.047278930054745e-06}, {"id": 638, "seek": 574858, "start": 5753.58, "end": 5769.58, "text": " Thanks good questions.", "tokens": [2561, 665, 1651, 13], "temperature": 0.0, "avg_logprob": -0.36631035804748535, "compression_ratio": 0.7837837837837838, "no_speech_prob": 6.047278930054745e-06}, {"id": 639, "seek": 576958, "start": 5769.58, "end": 5783.58, "text": " Okay yeah and actually I guess in the interest of time should probably stop here. So next time we'll be applying this to going back to our problem of wanting these polynomial features but wanting to be able to create them more quickly.", "tokens": [1033, 1338, 293, 767, 286, 2041, 294, 264, 1179, 295, 565, 820, 1391, 1590, 510, 13, 407, 958, 565, 321, 603, 312, 9275, 341, 281, 516, 646, 281, 527, 1154, 295, 7935, 613, 26110, 4122, 457, 7935, 281, 312, 1075, 281, 1884, 552, 544, 2661, 13], "temperature": 0.0, "avg_logprob": -0.09458112716674805, "compression_ratio": 1.5707762557077625, "no_speech_prob": 7.223857778626552e-07}, {"id": 640, "seek": 576958, "start": 5783.58, "end": 5792.58, "text": " I also wanted to remind you that Thursday homework to is due and so is the draft of your writing assignment.", "tokens": [286, 611, 1415, 281, 4160, 291, 300, 10383, 14578, 281, 307, 3462, 293, 370, 307, 264, 11206, 295, 428, 3579, 15187, 13], "temperature": 0.0, "avg_logprob": -0.09458112716674805, "compression_ratio": 1.5707762557077625, "no_speech_prob": 7.223857778626552e-07}, {"id": 641, "seek": 579258, "start": 5792.58, "end": 5800.58, "text": " Tim.", "tokens": [7172, 13], "temperature": 0.0, "avg_logprob": -0.1854989237901641, "compression_ratio": 1.319672131147541, "no_speech_prob": 2.8125655262556393e-06}, {"id": 642, "seek": 579258, "start": 5800.58, "end": 5813.58, "text": " So, I mean the better shape your draft is in I think the better feedback you'll get which will make your final better, but it should be reasonably complete.", "tokens": [407, 11, 286, 914, 264, 1101, 3909, 428, 11206, 307, 294, 286, 519, 264, 1101, 5824, 291, 603, 483, 597, 486, 652, 428, 2572, 1101, 11, 457, 309, 820, 312, 23551, 3566, 13], "temperature": 0.0, "avg_logprob": -0.1854989237901641, "compression_ratio": 1.319672131147541, "no_speech_prob": 2.8125655262556393e-06}, {"id": 643, "seek": 581358, "start": 5813.58, "end": 5823.58, "text": " Thanks.", "tokens": [50364, 2561, 13, 50864], "temperature": 0.0, "avg_logprob": -0.753359603881836, "compression_ratio": 0.4666666666666667, "no_speech_prob": 4.8214318667305633e-05}], "language": "en"}