{"text": " So hello and welcome to lesson 3 of practical deep learning for coders. We were looking at getting our model into production last week and so we're going to finish off that today and then we're going to start to look behind the scenes at what actually goes on when we train a neural network. We're going to look at kind of the math of what's going on and we're going to learn about SGD and some important stuff like that. The order is slightly different to the book. In the book there's a part in the book which says like hey you can either go to lesson 4 or lesson 3 now and then go back to the other one afterwards. So we're doing lesson 4 and then lesson 3, chapter 4 and then chapter 3 I should say. You can choose whichever way you're interested in. Chapter 4 is the more technical chapter about the foundations of how deep learning really works. Chapter 3 is all about ethics and so with the lessons we'll do that next week. So we're looking at 0.2 production notebook and we're going to look at the fast book version, the one with in fact everything I'm looking at today will be in the fast book version. And remember last week we had a look at our bears and we created this data loaders object by using the data block API which I hope everybody's had a chance to experiment with this week if you haven't now's a good time to do it. We kind of skipped over one of the lines a little bit which is this item transforms. So what this is doing here when we said resize the images we downloaded from the internet are lots of different sizes and lots of different aspect ratios some are tall and some are wide and a square and some are big some are small. When you say resize for an item transform it means each item to an item in this case is one image is going to be resized to 128 by 128 by squishing it or stretching it. And so we had a look at you can always say show batch to see a few examples and this is what they look like. Squishing and stretching isn't the only way that we can resize remember we have everything we have to make everything into a square before we kind of get it into our model by the time it gets to our model everything has to be the same size in each mini badge. But that's why they're making it a square is not the only way to do that but it's the easiest way and it's the by far the most common way. So another way to do this is we can create a another data block object and we can make a data block object that's an identical copy of an existing data block object where we can then change just some pieces and we can do that by calling the new method which is super handy. And so let's create another data block object and this time with different item transform where we resize using the squish method. We have a question what are the advantages of having square images versus rectangular ones? That's a great question. So really it's simplicity. If you know all of your images are rectangular of a particular aspect ratio to start with you may as well just keep them that way. But if you've got some which are tall and some which are wide making them all square is kind of the easiest. Otherwise you would have to kind of organize them such as all of the tall ones kind of ended up in a mini batch and all of the wide ones ended up in a mini batch and then you'd have to kind of then figure out what the best aspect ratio for each mini batch is. And we actually have some research that does that in fastai too but it's still a bit clunky. I should mention okay I just lied to you the default is not actually to squish or stretch the default I should have said sorry the default when we say resize is actually just to grab the center. So actually all we're doing is we're grabbing the center of each image. So if we want to squish or stretch you can add the resize method dot squish argument to resize and you can now see that this black bear is now looking much thinner but we have got the kind of leaves that are around on each side instance. Another question when you use the DLS dot new method what can and cannot be changed is it just the transforms? So it's not DLS dot new it's bears dot new right so we're not creating a new data loaders object we're creating a new data block object. I don't remember off the top of my head so check the documentation and I'm sure somebody can pop the answer into the into the forum. So you can see when we use dot squish that this grizzly bear has got pretty kind of wide and weird looking and this black bear has got pretty weird and thin looking and it's easiest kind of to see what's going on if we use resize method dot pad and what dot pad does as you can see is it just adds some black bars around each side. So you can see the grizzly bear was tall so then when we we stretched squishing and stretching opposites of each other so when we stretched it it ended up wide and the black bear was originally a wide rectangle so it ended up looking kind of thin. You don't have to use zeros, zeros means pad it with black you can also say like reflect to kind of have the the pixels will kind of look a bit better that way if you use reflect. All of these different methods have their own problems the the pad method is kind of the cleanest you end up with the correct size you end up with all of the pixels but you also end up with wasted pixels so you kind of end up with wasted computation. The squish method is the most efficient because you get all of the information you know and nothing's kind of wasted but on the downside your neural net's going to have to learn to kind of like recognize when something's been squished or stretched and in some cases it might it wouldn't even know so if there's two objects you're trying to recognize one of which tends to be thin and one of which tends to be thick and otherwise they're the same they could actually be impossible to distinguish. And then the default cropping approach actually removes some information so in this case you know this this grizzly bear here we actually lost a lot of its legs so if figuring it out what kind of bear it was required looking at its feet well we don't have its feet anymore so they all have downsides so there's something else that you can do a different approach which is instead of to say resize you can say random resized crop and actually this is the most common approach and what random resized crop does is each time it actually grabs a different part of the image and kind of zooms into it right so these this is all the same image and we're just grabbing a batch of four different versions of it and you can see some are kind of you know they're all squished in different ways and we've kind of selected different subsets and so forth now this kind of seems worse than any of the previous approaches because I'm losing information like this one here I've actually lost a whole lot of its of its back right but the cool thing about this is that remember we want to avoid overfitting and when you see a different part of the animal each time it's much less likely to overfit because you're not seeing the same image on each epoch that you go around that makes sense so so this random resized crop approach is actually super popular and so min scale 0.3 means we're going to pick at least 30% of the pixels of kind of the original size each time and then we'll kind of like zoom into that that square. So this idea of doing something so that each time the model sees the image it looks a bit different to last time it's called data augmentation and this is one type of data augmentation it's probably the most common but there are others and one of the best ways to do data augmentation is to use this org transforms function and what org transforms does is it actually returns a list of different augmentations and so there are augmentations which change contrast which change brightness which warp the perspective so you can see in this one here it looks like this bit's much closer to you and it's much away from you because it's going to be in perspective warped it rotates them see this one's actually been rotated this one's been made really dark right these are batch transforms not item transforms the difference is that item transforms happen one image at a time and so the thing that resizes them all to the same size that has to be an item transform pop it all into a mini batch put it on the GPU and then a batch transform happens to a whole mini batch at a time and by putting these as batch transforms that the augmentation happens super fast because it happens on the GPU and I don't know if there's any other libraries as we speak which allow you to write your own GPU accelerated transformations that run on the GPU in this way so this is a super handy thing in fast AI too. So you can check out the documentation for or transforms and when you do you'll find the documentation for all of the underlying transforms that it basically wraps right so you can see if I shift tab I don't remember if I've shown you this trick before if you go inside the parentheses of a function and hit shift tab a few times it'll pop open a list of all of the arguments and so you can basically see you can say like oh can I sometimes flip it left right can I sometimes flip it up down what's the maximum and I can rotate zoom change the lighting warp the perspective and so forth. How can we add different augmentations for train and validation sets? So the cool thing is that automatically fast AI will avoid doing data augmentation on the validation set so all of these or transforms will only be applied to the training set with the exception of random resize crop random resize crop has a different behavior for each the behavior for the training set is what we just saw which is to randomly pick a subset and kind of zoom into it and the behavior for the validation set is just to grab the center the largest center square that it can. You can write your own transformations that they're just Python they're just standard pytorch code the way if you and by default it will only be applied to the training set if you want to do something fancy like random resize crop where you actually have different things being applied to each you should come back to the next course to find out how to do that or read the documentation it's not rocket science but it's not something most people need to do. Okay so last time we we hear bit did bears.new with a random resize crop min scale of 0.5 we added some transforms and we went ahead and trained actually since last week I've rerun this notebook I've got it's on a different computer and I've got different images so it's not all exactly the same but I still got a good confusion matrix so of the black bears 37 were classified correctly two were grizzlies of one with a teddy. Now we talked about plot top losses and it's interesting you can see in this case there's some clearly kind of odd things going on this is not a bear at all this looks like it's a drawing of a bear which is decided is predicted as a teddy but this thing's meant to be a drawing of a black bear I can certainly see the confusion you can see how some parts of it have been cut off we'll talk about how to deal with that later. Now one of the interesting things is that we didn't really do much data cleaning at all before we built this model the only data cleaning we did was just to validate that each image can be opened there was that verify images call and the reason for that is it's actually much easier normally to clean your data after you create a model and I'll show you how we've got this thing called image classifier cleaner where you can pick a category right and training set or validation set and then what it will do is it will then list all of the images in that set and it will pick the ones which are the which is the least confident about which the most likely to be wrong where the where the loss is the worst to be more precise and so this this is a great way to look through your data and find problems so in this case the first one is not a teddy or a brown bear or a black bear it's a puppy dog right so this is a great cleaner because what I can do is I can now click delete here this one here looks a bit like an Ewok rather than a teddy I'm not sure what do you think Rachel is an Ewok I'm gonna call it an Ewok right and so you can kind of go through okay that's definitely not a teddy and so you can either say like oh that's wrong that's actually a grizzly bear or it's wrong it's a black bear or I should delete it or by default just keep it right and you can kind of keep going through until you think like okay they're all seem to be fine maybe that one's not and kind of once you get to the point where they all seem to be fine you can kind of say okay probably all the rest are fine too because they all have lower losses so they all fit the kind of the mold of a teddy and so then I can run this code here where I just go through cleaner.delete so that's all the things which I selected to delete for and unlink them so unlink is just another way of saying delete a file that's the Python name and then go through all the ones that we said change and we can actually move them to the correct directory. If you haven't seen this before you might be surprised that we've kind of created our own little GUI inside Jupyter Notebook. Yeah you can do this and we built this with less than a screen of code you can check out the source code in the fastai notebooks so this is a great time to remind you that if you go to the fastai repo and clone it and then go to nb's you'll find all of the code of fastai written as notebooks and they've got a lot of pros and examples and tests and so forth so the best place to learn about how this is implemented is to look at the notebooks rather than looking at the module. Okay by the way sometimes you'll see like weird little comments like this these weird little comments are part of a development environment for Jupyter Notebook we use called nbdev which we built so Silver and I built this thing to make it much easier for us to kind of create books and websites and libraries in Jupyter Notebooks so this particular one here hide means when this is turned into a book or into documentation don't show this cell and the reason for that is because you can see I've actually got it in the text right but I thought when you're actually running it it would be nice to have it sitting here waiting for you to run directly so that's why it's shown in the notebook but not in the in the book it's shown differently and you'll also see these things like s colon with a quote in the book that would end up saying Sylvain says and then what he says so there's kind of little bits and pieces in the in the notebooks that just look a little bit odd and that's because it's designed that way in order to show in order to create stuff in the book. Right so then last week we saw how you can export that to a pickle file that contains all the information for the model and then on the server where you're going to actually do your inference you can then load that saved file and you'll get back a learner that you can call predict on so predict perhaps the most interesting part of predict is the third thing that it returns which is a tensor in this case containing three numbers the three numbers there's three of them because we have three classes teddy bear grizzly bear and black bear right and so this doesn't make any sense until you know what the order of the classes is kind of in in in your data loaders and you can ask the data loaders what the order is by asking for its vocab so a vocab in fast AI is a really common concept it's basically any time that you've got like a mapping from numbers to strings or discrete levels, the mapping is always stored in the vocab so here this shows us that the the activation for black bear is 10 a neg 6 the activation for grizzly is 1 and the activation for teddy is 10 a neg 6 so very very confident that this particular one it was a grizzly not surprisingly this was something called grizzly.jpg so you need to kind of know this this mapping in order to display the correct thing but of course the data loaders object already knows that mapping and it's all the vocab and it's stored in with the loader so that's how it knows to say grizzly automatically so the first thing it gives you is the the human readable string that you'd want to display so this is kind of nice that with fast AI too you you save this object which has everything you need for inference it's got all the you know information about normalization about any kind of transformation steps about what the vocab is so it can display everything correctly right so now we want to deploy this as an app now if you've done some web programming before then all you need to know is that this line of code and this line of code so this is the line of code you would call once when your application starts up and then this is the line of code you would call every time you want to do an inference and there's also a batch version of it which you can lock up if you're interested this is just a one at a time so there's nothing special if you're already a web programmer or have access to a web programmer these are you know you just have to stick these two lines of code somewhere and the three things you get back are the the human readable string if you're doing categorization the index of that which in this case is one who's grizzly and the probability of each class one of the things we really wanted to do in this course though is not assume that everybody is a web developer most data scientists aren't but gee wouldn't it be great if all data scientists could at least like prototype an application to show off the thing they're working on and so we've tried to kind of curate an approach which none of its stuff we've built it's really just curated which shows how you can create a GUI and create a complete application in Jupyter Notebook so the key pieces of technology we use to do this are IPython widgets which is always called IPy widgets and voila IPy widgets which we import by default as widgets and that's also what they use in their own documentation as GUI widgets for example a file upload button so if I create this file upload button and then display it I see and we saw this in the last lesson as well or maybe it was less than one an actual clickable button so I can go ahead and click it and it says now okay you've selected one thing so how do I use that well these well these widgets have all kinds of methods and properties and the upload button has a data property which is an array containing all of the images you uploaded so you can pass that to PIO image dot create and so dot create is kind of the standard factory method we use in fast AI to create items and PIO image dot create is smart enough to be able to create an item from all kinds of different things and one of the things that can create it from is a binary blob which is what a file upload contains so then we can display it and there's our teddy right so you can see how you know cells of Jupyter Notebook can refer to other cells that were created that were kind of have GUI created data in them so let's hide that teddy away for a moment and the next thing to know about is that there's a kind of widget called output and an output widget is it's basically something that you can fill in later right so if I delete actually this part here so I've now got an output widget yeah actually let's do it this way around and you can't see the output widget even though I said please display it because nothing is output so then in the next cell I can say with that output placeholder display a thumbnail of the image and you'll see that the display will not appear here it appears back here right because that's how that's where the placeholder was so let's run that again to clear out that placeholder so we can create another kind of placeholder which is a label the labels kind of something where you can put text in it they can give it a value like I don't know please choose an image okay so we've now got a label containing please choose an image now let's create another button to do a classification now this is not a file upload button it's just a general button so this button doesn't do anything right and doesn't do anything until we attach an event handler to it an event handler is a callback we'll be learning all about callbacks in this course if you've ever done any GUI programming before or even web programming you'll be familiar with the idea that you write a function which is the thing you want to be called when the button is clicked on and then somehow you tell your framework that this is the on click event so here I go here's my button run I say the on click event the button run is to call this code and this code is going to do all the stuff we just saw and I create an image from the upload it's going to clear the output display the image call predict and then replace the label with a prediction so there it all is now so that hasn't done anything but I can now go back to this classify button which now has an event handler attached to it so watch this click oomph and look that's been filled in that's been filled in right in case you missed it let's run these again to clear everything out okay everything's gone this is please choose an image there's nothing here I click classify oh pop up right so it's kind of amazing how our notebook has suddenly turned into this interactive prototyping playground building applications and so once all this works we can dump it all together and so the easiest way to dump things together is to create a V box a V box is a vertical box and it's just a it's just something that you put widgets in and so in this case we're going to put the following widgets we're going to have a label that says select your bear then an upload button a run button an output placeholder and a label for predictions so let's run these again just to clear everything out so that we're not cheating and let's create our V box so as you can see it's just got all the all the pieces right now we've got whatever oh I accidentally ran the thing that displayed the bear let's get rid of that okay so there it is so now I can click upload I can choose my bear okay and then I can click classify right and notice I've this is exactly that this is this is like the same buttons as as these buttons they're like two places with we're viewing the same button which is kind of a wild idea so if I click classify it's going to change this label and this label because they're actually both references to the same label look there we are okay so this is our app right and so this is actually how I built that that image cleaner GUI is just using these exact things and I built that image cleaner GUI cell by cell in a notebook just like this and so you get this kind of interactive experimental framework for building a GUI so if you're a data scientist who's never done GUI stuff before this is a great time to get started because now you can you can make actual programs now of course an actual program running inside a notebook is kind of cool but what we really want is this program to run in a place anybody can run it that's where voila comes in so voila needs to be installed so you can just run these lines or install it it's listed in the pros and what voila does is it takes a notebook and just doesn't display anything except for the markdown the IPython widgets and the outputs right so all the code cells disappear and it doesn't give the person looking at that page the ability to run their own code they can only interact with the widgets right so what I did was I copied and pasted that code from the notebook into a separate notebook which only has those lines of code right so so these are just the same lines of code that we saw before and so this is a notebook it's just a normal notebook and then I installed voila and then when you do that if you navigate to this notebook but you replace notebooks up here with voila it actually displays not the notebook but just as I said the markdown and the widgets so here I've got my bear classifier and I can click upload let's do a grizzly bear this time and this is a slightly different version I actually made this so there's no classify button I thought it would be a bit more fancy to make it so when you click upload it just runs everything but as you can see there it all is right it's all working so this is the world's simplest prototype but it's it's a proof of concept right so you can add widgets with drop-downs and sliders and charts and you know everything that you can have in a you know an angular app or a react app or whatever and in fact there's even stuff which lets you use for example the whole Vue.js framework if you know that it's a very popular JavaScript framework the whole Vue.js framework you can actually use it in widgets and voila so now we want to get it so that this this app can be run by someone out there in the world so the voila documentation shows a few ways to do that but perhaps the easiest one is to use a system called binder and so binder is at mybinder.org and all you do is you paste in your github repository name here right and this is all in the book right so you paste in your github repo name you change where it says file you change that to URL you can see and then you put in the path which we were just experimenting with right so pop that here and then you say launch and what that does is it then gives you a URL so then this URL you can pass on to people and this is actually your interactive running application so binders free and so this isn't you know anybody can now use this to take their voila app and make it a publicly available web application so try it as it mentions here the first time you do this binder takes about five minutes to build your site because it actually uses something called docker to deploy the whole fast AI framework and python and blah blah blah but once you've done that that virtual machine will keep running for you know as long as people are using it it'll keep running for a while that virtual machine will keep running for a while as long as people are using it and you know it's it's reasonably fast so a few things to note here being a free service you won't be surprised to hear this is not using a GPU is using a CPU and so that might be surprising that we're deploying to something which runs on a CPU when you think about it though this makes much more sense to deploy to a CPU than a GPU the just a moment the thing that's happening here is that I am passing along let's go back to my app in my app I'm passing along a single image at a time so when I pass along that single image I don't have a huge amount of parallel work for a GPU to do this is actually something that a CPU is going to be doing more efficiently so we found that for folks coming through this course the vast majority of the time they wanted to deploy inference on a CPU not a GPU because they're normally just doing one item at a time it's way cheaper and easier to deploy to a CPU and the reason for that is that you can just use any hosting service you like because just remember this is just a this is just a program at this point right and you can use all the usuals horizontal scaling vertical scaling you know you can use Heroku you can use AWS you can use inexpensive instances super cheap and super easy having said that there are times you might need to deploy to a GPU for example maybe you're processing videos and so like a single video on on a CPU to process it it might take all day or you might be so successful that you have a thousand requests per second in which case you could like take 128 at a time batch them together and put the whole batch on the GPU and get the results back and pass them back around and you've got to be careful of that right because as if your requests aren't coming fast enough your user has to wait for a whole batch of people to be ready to to be processed but you know conceptually as long as your site is popular enough that could work. The other thing to talk about is you might want to deploy to a mobile phone and deploying to a mobile phone our recommendation is wherever possible do that by actually deploying to a server and then have a mobile phone talk to the server over a network and because if you do that again you can just use a normal PyTorch program on a normal server and normal network calls it makes life super easy when you try to run a PyTorch app on a phone you're suddenly now not an environment where not an environment where like PyTorch will run natively and so you have to like convert your program into some other form and there are other forms and the main form that you convert it to is something called O, N and X which is specifically designed for kind of super high speed high performance you know approach that can run on both servers or on mobile phones and it does not require the whole Python and PyTorch kind of runtime in place but it's much more complex and not using it's harder to debug and it's harder to set it up and it's harder to maintain it so if possible keep things simple and if you're lucky enough that you're so successful that you need to scale it up to GPUs or stuff like that then great you know hopefully you've got the finances at that point to justify you know spending money on a O, N, X expert or serving expert or whatever and there are various systems you can use to like O, N, X runtime and AWS SageMaker where you can kind of say here's my O, N, X bundle when it'll serve it for you or whatever PyTorch also has a mobile framework same idea. So all right so you've got I mean it's kind of funny we're talking about two different kinds of deployment here one is deploying like a hobby application you know that you're prototyping showing off to your friends to explaining to your colleagues how something might work you know a little interactive analysis and that's one thing but maybe you're actually prototyping something that you want to turn into a real product or an actual real part of your company's operations when you're deploying you know something in real life there's all kinds of things you got to be careful of. One example of something to be careful of is let's say you did exactly what we just did which actually this is your homework is to create your own application right I want you to create your own image search application you can use my exact set of widgets and whatever if you want to but better still go to the iPy widgets website and see what other widgets they have and try and come up with something cool try and come you know try and show off as best as you can and show us on the forum now let's say you decided that you want to create an app that would help the users of your app decide if they have healthy skin or unhealthy skin so if you did the exact thing we just did rather than searching for grizzly bear and teddy bear and so forth on Bing you would search for healthy skin and unhealthy skin right so here's what happens right if I and remember in our version we never actually looked at Bing we just used the Bing API the image search API but behind the scenes it's just using the website right so if I click healthy if I type healthy skin and say search I actually discover that the definition of healthy skin is young white women touching their face lovelingly so that's what your your healthy skin classifier would learn to detect right and so this is so this is a great example from Deb Raji and you should check out her paper actionable auditing for lots of cool insights about model bias but I mean here's here's like a fascinating example of how if you weren't looking at your data carefully you you end up with something that doesn't at all actually solve the problem you want to solve this is this is tricky right because the data that you train your algorithm on if you're building like a new product that didn't exist before by definition you don't have examples of the kind of data that's going to be used in real life right so you kind of try to find some from somewhere and if they and if you do that through like a Google search it's pretty likely you're not going to end up with a set of data that actually reflects the kind of mix you would see in real life so you know the main thing here is to say be careful right and and in particular for your test set you know that final set that you check on really try hard to gather data that that reflects the real world so like just you know for example for the healthy skin example you might go and actually talk to a dermatologist and try and find like 10 examples of healthy and unhealthy skin or something and that would be your kind of gold standard test. There's all kinds of issues you have to think about in deployment I can't cover all of them I can tell you that this O'Reilly book called building machine learning powered applications is is a great resource and this is one of the reasons we don't go into detail about a P2 a B testing and when should we refresh our data and how do we monitor things and so forth is because that book's already been written so we don't want to rewrite it. I do want to mention a particular area that I care a lot about though which is let's take this example let's say you're rolling out this bear detection system and it's going to be attached to video cameras around a campsite it's going to warn campers of incoming bears so if we used a model that was trained with that data that we just looked at you know those are all very nicely taken pictures of pretty perfect bears right there's really no relationship to the kinds of pictures you're actually going to have to be dealing with in your in your campsite bear detector which has it's going to have video and not images it's going to be nighttime it's going to be probably low resolution security cameras you need to make sure that the performance of the system is fast enough to tell you about it before the bear kills you you know there will be bears that are partially obscured by bushes or in lots of shadow or whatever none of which are the kinds of things you would see normally in like internet pictures. So what we call this we call this out of domain data out of domain data refers to a situation where the data that you are trying to do inference on is in some way different to the kind of data that you trained with and this is actually there's no perfect way to answer this question and when we look at ethics we'll talk about some really helpful ways to to minimize how much this happens for example it turns out that having a diverse team is a great way to kind of avoid being surprised by the kinds of data that people end up coming up with but really it's just something you've got to be super thoughtful about very similar to that is something called domain shift and domain shift is where maybe you start out with all of your data is in domain data but over time the kinds of data that you're seeing changes and so over time maybe raccoons start invading your campsite and you weren't training on raccoons before it was just a bear detector and so that's called domain shift and that's another thing that you have to be very careful of. Rachel was your question? No I was just going to add to that in saying that all data is biased so there's not kind of a you know a form of a de-biased data or perfectly representative in all cases data and that a lot of the proposals around addressing this have kind of been converging to this idea and that you see in papers like Timnit Gebru's data sheets for data sets of just writing down a lot of the details about your data set and how it was gathered and in which situations it's appropriate to use and how it was maintained and so there that's not that you've totally eliminated bias but that you're just very aware of the attributes of your data set so that you won't be blindsided by them later and there have been kind of several proposals in that school of thought which I which I really like around this idea of just kind of understanding how your data was gathered and what its limitations are. Thanks Rachel. So a key problem here is that you can't know the entire behavior of your neural network. With normal programming you typed in the if statements and the loops and whatever so in theory you know what the hell it does although it's still sometimes surprising. In this case you you didn't tell it anything you just gave it examples to learn from and hope that it learned something useful. There are hundreds of millions of parameters in a lot of these neural networks and so there's no way you can understand how they all combine with each other to create complex behavior. So really like there's a natural compromise here is that we're trying to get sophisticated behavior so like like recognizing pictures sophisticated enough behavior we can't describe it and so the natural downside is you can't expect the process that the thing is using to do that to be describable for you for you to be able to understand it. So our recommendation for kind of dealing with these issues is a very careful deployment strategy which I've summarized in this little graph this little chart here. The idea would be first of all whatever it is that you're going to use the model for start out by doing it manually so have a have a park ranger watching for bears have the model running next to them and each time the park ranger sees a bear they can check the model and see like did it seem to have picked it up. So the model is not doing anything there's just a person who's like running it and seeing would have made sensible choices and once you're confident that it makes sense that what it's doing seems reasonable in you know it's been as close to the real-life situation as possible then deploy it in a time and geography limited way so pick like one campsite not the entirety of California and do it for you know one day and have somebody watching it super carefully right. So now the basic bear detection is being done by the bear detector but there's still somebody watching it pretty closely and it's only happening in one campsite for one day and so then as you say like okay we haven't destroyed our company yet so let's do two campsites for a week and then let's do you know the entirety of Marin for a month and so forth. So this is actually what we did when I used to be at this company called optimal decisions optimal decisions was a company that I founded to do insurance pricing and if you if you change insurance prices by you know a percent or two in the wrong direction the wrong way you can basically destroy the whole company this has happened many times you know insurers are companies that set prices that's basically the product that they provide so when we deployed new prices for optimal decisions we always did it by like saying like okay we're going to do it for like five minutes or everybody whose name ends with a D you know so we'd kind of try to find some group which hopefully would be fairly you know it'll be different but not too many of them and we'd gradually scale it up and you've got to make sure that when you're doing this that you have a lot of really good reporting systems in place that you can recognize are your customers yelling at you are your computers burning up you know are your are your computers burning up are your costs by running out of control and so forth so it really requires great reporting systems. This fast AI have methods built in that provide for incremental learning ie improving the model slowly over time with a single data point each time. Yeah that's a great question so this is a little bit different which is this is really about dealing with domain shift and similar issues by continuing to train your model as you do inference and so the good news is you don't need anything special for that it's basically just a transfer learning problem so you can do this in many different ways probably the easiest is just to say like okay each night probably the easiest is just to say okay each night you know at midnight we're going to set off a task which grabs all of the previous day's transactions as mini batches and trains another epoch and so yeah that actually works fine you can basically think of this as a fine-tuning approach where your pre-trained model is yesterday's model and your fine-tuning data is today's data. So as you roll out your model one thing to be thinking about super carefully is that it might change the behavior of the system that it's a part of and this can create something called a feedback loop and feedback loops are one of the most challenging things for real-world model deployment particularly of machine learning models because they can take a very minor issue and explode it into a really big issue so for example think about a predictive policing algorithm it's an algorithm that was trained to recognize you know basically trained on data that says whereabouts are arrests being made and then as you train that algorithm based on where arrests are being made then you put in place a system that sends police officers to places that the model says are likely to have crime which in this case where were were there where were arrests so then more police go to that place find more crime because the more police that are there the more they'll see they arrest more people causing you know and then if you do this incremental learning like we're just talking about then it's going to say oh there's actually even more crime here and so tomorrow it sends even more police and so in that situation you end up like the predictive policing algorithm ends up kind of sending all of your police for one street block because at that point all of the arrests are happening there because that's the only place you have policemen right I should say police officers so there's actually a paper about this issue called to protect and serve and to protect and serve the authors write this really nice phrase predictive policing is aptly named it is predicting policing not predicting crime so if the initial model was perfect whatever the hell that even means but like it somehow sent police to exactly the best places to find crime based on the probability of crimes actually being in place I guess there's no problem right but as soon as there's any amount of bias right so for example in the US there's a lot more arrests of black people than of white people even for crimes where black people and white people are known to do them the same amount so in the presence of this bias or any kind of bias you're kind of like setting off this this domino chain of feedback loops where that bias will be exploded over time so you know one thing I like to think about is to think like well what would happen if this if this model was just really really really good so like who would be impacted you know what would this extreme result look like how would you know what was really happening this incredibly predictive algorithm that was like changing the behavior of yours if your police officers or whatever you know what would that look like what would actually happen and then like think about like okay what could go wrong then what kind of rollout plan what kind of monitoring systems what kind of oversight could provide the circuit breaker because that's what we really need here right is we need like nothing's going to be perfect you can't be sure that there's no feedback loops but what you can do is try to be sure that you see when the behavior of your system is behaving in a way that's not what you want did you have anything to add to that Rachel I would add to that is that you're at risk of potentially having a feedback loop anytime that your model is kind of controlling what your next round of data looks like and I think that's true for pretty much all products and that can be I think a hard jump from people people coming from kind of a science background where you may be thinking of data as I have just observed some sort of experiment whereas kind of whenever you're you know building something that interacts with the real world you are now also controlling what your future data looks like based on kind of behavior of your your algorithm for the current current round of data right so so given that you probably can't avoid feedback loops that you know the the thing you need to then really invest in is the human in the loop and so a lot of people like to focus on automating things which I find weird you know if you can decrease the amount of human involvement by like 90% you've got almost all of the economic upside of automating it completely but you still have the room to put human circuit breakers in place you need these appeals processes you need the monitoring you need you know humans involved to kind of go hey that's that's weird I don't think that's what we want okay yes Rachel and I just want more note about that those humans though do need to be integrated well with kind of product and engineering and so one issue that comes up is that in many companies I think that ends up kind of being underneath trust and safety handles a lot of sort of issues with how things can go wrong or how your platform can be abused and often trust and safety is pretty siloed away from product and edge which actually kind of has the control over you know these decisions that really end up influencing them and so having the the engineers probably consider them to be pretty pretty annoying a lot of the time how they get in the way and get in the way of them getting software out the door yeah but like the kind of the more integration you can have between those I think it's helpful for the kind of the people building the product to see what is going wrong and what can go wrong if the engineers are actually on top of that they're actually seeing these these things happening that it's not some kind of abstract problem anymore so you know at this point now that we've got to the end of chapter 2 you actually know a lot more than most people about about deep learning and actually about some pretty important foundations of machine learning more generally and of data products more generally so there was a great time to think about writing so sometimes we have a formatted text that doesn't quite format correctly in Tripita notebook by the way it only formats correctly in in the book book so that's what it means when you see this kind of pre-formatted text so the the idea here is to think about starting writing at this point before you go too much further Rachel. There was a question oh okay let's hit the question question is I am I assume there are fast AI type ways of keeping a nightly updated transfer learning setup well could there be one of the fast AI version 4 notebooks have an example of the nightly transfer learning training like the previous person asked I would be interested in knowing how to do that most effectively with fast AI. Sure so I guess my view is there's nothing faster specific about that at all so I actually suggest you read Emanuel's book that book I showed you to understand the kind of the ideas and if people are interested in this I can also point you at some academic research about this as well and there's not as much as that there should be but there is some there is some good work in this area. Okay so the reason we mentioned writing at this point in our journey is because you know things are going to start to get more and more heavy more and more complicated and a really good way to make sure that you're on top of it is to try to write down what you've learnt. So sorry I wasn't sharing the right part of the screen before but this is what I was describing in terms of the pre-formatted text which doesn't look correct. So Rachel actually has this great article that you should check out which is why you should blog and I will say it's sort of her saying because I have it in front of me and she doesn't, weird as it is. So Rachel says that the top advice she would give her younger self is to start blogging sooner. So Rachel has a math PhD and this kind of idea of like blogging was not exactly something I think they had a lot of in the PhD program but actually it's like it's a really great way of finding jobs in fact most of my students who have got the best jobs are students that have good blog posts. The thing I really love is that it helps you learn by writing down it's kind of synthesizes your ideas and yeah you know there's lots of reasons to blog. So there's actually something really cool I want to show you. Yeah. I was also just going to note I have a second post called advice for better blog post that's a little bit more advanced which I'll post a link to as well and that talks about some common pitfalls that I've seen in many in many blog posts and kind of the importance of putting putting the time in to do it well and some things to think about. So I'll share that post as well. Thanks Rachel. So one reason that sometimes people don't blog is because it's kind of annoying to figure out how to particularly because I think the thing that a lot of you will want to blog about is cool stuff that you're building in Jupyter Notebooks. So we've actually teamed up with a guy called Hamel Hussain and and with GitHub to create this free product as usual with fast AI no ads no anything called fast pages where you can actually blog with Jupyter Notebooks and so you can go to fast pages and see for yourself how to do it but the basic idea is that like you literally click one button it sets up a blog for you and then you dump your notebooks into a folder called underscore notebooks and they get turned into blog posts. It's basically like magic and Hamel's done this amazing job of this and so this means that you can create blog posts where you've got charts and tables and images you know where they're all actually the output of Jupyter Notebook along with all the markdown formatted text headings and so forth and hyperlinks and the whole thing. So this is a great way to start writing about what you're learning about here. So something that Rachel and I both feel strongly about when it comes to blogging is this which is don't try to think about the absolute most advanced thing you know and try to write a blog post that would impress Jeff Hinton right because most people are not Jeff Hinton so like a you probably won't do a good job because you're trying to like log for somebody who's more got more expertise than you and be you've got a small audience now right actually there's far more people that are not very familiar with deep learning than people who are they try to think you know and you really understand what it's like what it was like six months ago to be you because you were there six months ago so try and write something which the six months ago version of you would have been like super interesting full of little tidbits you would have loved you know that you would have that would have delighted you that six months ago version of you. Okay so once again don't move on until you've had a go at the questionnaire to make sure that you you know understand the key things we think that you need to understand and yeah have a think about these further research questions as well because they might help you to engage more closely with material. So let's have a break and we'll come back in five minutes time. So welcome back everybody this is a interesting moment in the course because we're kind of jumping from the part of the course which is you know very heavily around kind of the kind of the structure of like what are we trying to do with machine learning and what are the kind of the pieces and what do we need to know to make everything kind of work together. There was a bit of code but not masses there was basically no math and we kind of wanted to put that at the start for everybody who's not you know who's kind of wanting to an understanding of these issues without necessarily wanting to kind of dive deep into the code and the math themselves and now we're getting into the diving deep part. If you're not interested in that diving deep yourself you might want to skip to the next lesson about ethics where we you know is kind of that rounds out the kind of you know slightly less technical material. So what we're going to look at here is we're going to look at what we think of as kind of a toy problem but just a few years ago is considered a pretty challenging problem and the problem is recognizing handwritten digits and we're going to try and do it from scratch right and we're going to try and look at a number of different ways to do it. So we're going to have a look at a data set called MNIST and so if you've done any machine learning before you may well have come across MNIST. It contains handwritten digits and it was collated into a machine learning data set by a guy called John Lacoon and some colleagues and they use that to demonstrate I'm one of the you know probably the first computer system to provide really practically useful scalable recognition of handwritten digits. Lynette 5 with the system was actually used to automatically process like 10% of the checks in the US. So one of the things that really helps I think when building a new model is to kind of start with something simple and gradually scale it up. So we've created an even simpler version of MNIST which we call MNIST sample which only has threes and sevens. Okay so this is a good starting point to make sure that we can kind of do something easy. I picked threes and sevens MNIST sample because they're very different. I feel like if we can't do this we're going to have trouble recognizing every digit. So step one is to call untar data. Untar data is the fast AI function which takes a URL, checks whether you've already downloaded it. If you haven't it downloads it, checks whether you've already uncompressed it. If you haven't it uncompresses it and then it finally returns the path of where that ended up. So you can see here is he URLs dot MNIST sample. So you could just hit tab to get autocomplete. It's just some location right. It doesn't really matter where it is. And so then when we call that I've already downloaded it and already uncompressed it because I've already ran this once before so it happened straight away and so path shows me where it is. Now in this case path is dot and the reason path is dot is because I've used a special base path attribute to path to tell it kind of like where's my where's my starting point you know and and that's used to print. So when I go here ls which prints a list of files these are all relative to where I actually untarget this to. So it just makes it a lot easier not to have to see the whole set of parent path folders. Ls is actually so path is a let's see what kind of type it is. So it's a pathlib path object. Pathlib is part of the Python standard library. It's a really very very very nice library but it doesn't actually have ls where there are libraries that we find super helpful but they don't have exactly the things we want. We liberally add the things we want to them. So we add ls. So if you want to find out what ls is you know there's as we've mentioned there's a few ways you can do it. You can pop a question mark there and that will show you where it comes from. So there's actually a library called fastcore which is a lot of the foundational stuff in fast AI that is not dependent on PyTorch or pandas or any of these big heavy libraries. So this is part of fastcore and if you want to see exactly what it does you of course remember you can put in a second question mark to get the source code and as you can see there's not much source code to do it and you know maybe most importantly please don't forget about doc because really importantly that gives you this show in docs link which you can click on to get to the documentation to see examples, pictures if relevant, tutorials, tests and so forth. So what's so when you're looking at a new data set you kind of just I always start with just ls see what's in it and I can see here there's a train folder and there's a valid folder that's pretty normal. So let's look at ls on the train folder and it's got a folder called 7 and a folder called 3 and so this is looking quite a lot like our bare classifier data set we downloaded each set of images into a folder based on what its label was. This is doing it at another level though the first level of the folder hierarchy is it training or valid and the second level is what's the label and this is the most common way for image data sets to be distributed. So let's have a look let's just create something called threes that contains all of the contents of three directory training and let's just sort them so that this is consistent do the same for sevens and let's just look at the threes and you can see there's just they're just numbered. All right so let's grab one of those open it and take a look. Okay so there's the picture of a three and so what is that really? Not three, I am three. So PIO is the Python imaging library it's the most popular library by far for working with images on Python and it's a PNG not surprisingly. So Jupyter Notebook knows how to display many different types and you can actually tell if you create a new type you can tell it how to display your type and so PIO comes with something that will automatically display the image like so. What I want to do here though is to look at like how are we going to treat this as numbers right and so one easy way to treat things as numbers is to turn it into an array. The array is part of NumPy which is the most popular array programming library for Python and so if we pass our PIO image object to array it just converts the image into a bunch of numbers and the truth is it was a bunch of numbers the whole time it was actually stored as a bunch of numbers on disk it's just that there's this magic thing in Jupyter that knows how to display those numbers on the screen. So when we say array turning it back into a NumPy array we're kind of removing this ability for Jupyter Notebook to know how to display it like a picture. So once I do this we can then index into that array and create everything from the grab everything all the rows from 4 up to but not including 10 and all the columns from 4 up to and not including 10 and here are some numbers and they are 8-bit unsigned integers so they are between 0 and 255. So an image just like everything on a computer is just a bunch of numbers and therefore we can compute with it. We could do the same thing but instead of saying array we could say tensor. Now a tensor is basically the PyTorch version of a NumPy array and so you can see it looks it's exactly the same code as above but I've just replaced array with tensor and the output looks almost exactly the same except it replaces array with tensor and so you'll see this that basically a PyTorch tensor and a NumPy array behave nearly identically much if not most of the time but the key thing is that a PyTorch tensor can also be computed on a GPU not just a CPU. So in our work and in the book and in the notebooks and in our code we tend to use tensors PyTorch tensors much more often than NumPy arrays because they kind of have nearly all the benefits of NumPy arrays plus all the benefits of GPU computation and they've got a whole lot of extra functionality as well. A lot of people who have used Python for a long time always jump into NumPy because that's what they're used to. If that's you you might want to start considering jumping into tensor like wherever you used to write array start writing tensor and just see what happens because you might be surprised at how many things you can speed up or do more easily. So let's grab that that three image turn it into a tensor and so that's going to be three image tensor that's why I've got im3t. Okay and let's grab a bit of it okay and turn it into a pandas data frame and the only reason I'm turning it into a pandas data frame is that pandas has a very convenient thing called background gradient that turns a background into a gradient as you can see. So here is the top bit of three you can see that the zeros of the whites and the numbers near 255 are the blacks and there's some what's it bits in the middle which are which are gray. So here we have we can see what's going on when our images which are numbers actually get displayed on the screen it's just it's just doing this. And so I'm just showing a subset here the actual full number in mnist is a 28 by 28 pixel square so that's 768 pixels. So that's super tiny right where my mobile phone I don't know how many megapixels it is but it's millions of pixels so it's nice to start with something simple and small. Okay so here's our goal create a model but by model it has been some kind of computer program learnt from data that can recognize threes versus sevens. You could think of it as a three detector is it a three because if it's not a three it's a seven. So have it stop here pause the video and have a think how would you do it how would you like you don't need to know anything about neural networks or anything else how might you just with common sense build a tree detector. Okay so I hope you grabbed a piece of paper pen jotted some notes down. I'll tell you the first idea that came into my head was what if we grab every single three in the data set and take the average of the pixels. So what's the average of this pixel the average of this pixel the average of this pixel the average of this pixel right and so there'll be a 28 by 28 picture which is the average of all of the threes and that would be like the ideal three and then we'll do the same for sevens and then so when we then grab something from the validation set to classify we'll say like oh is this image closer to the ideal threes the ideal three the mean of the threes or the ideal seven. This is my idea and so I'm going to call this the pixel similarity approach. I'm describing this as a baseline a baseline is like a super simple model that should be pretty easy to program from scratch with very little magic you know maybe it's just a bunch of kind of simple averages simple arithmetic which you're super confident is going to be better than better than a random model right and one of the biggest mistakes I see in even experienced practitioners is that they fail to create a baseline and so then they build some fancy Bayesian model or or some fancy they create some fancy Bayesian model or some fancy neural network and they go wow Jeremy look at my amazingly great model and I'll say like how do you know it's amazingly great and I say oh look the accuracy is 80% and then I'll say okay let's see what happens if we create a model where we always predict the mean oh look that's 85% and people get pretty disheartened when they discover this right and so make sure you start with a reasonable baseline and then gradually build on top of it. So we need to get the average of the pixels so we're going to learn some nice Python programming tricks to do this so the first thing we need to do is we need a list of all of the sevens so remember we've got the sevens maybe it's just a list of file names right and so for each of those file names in the sevens let's image dot open that file just like we did before to get a PIO object and let's convert that into a tensor. So this thing here is called a list comprehension so if you haven't seen this before this is one of the most powerful and useful tools in Python. If you've done something with C sharp it's a little bit like link it's not as powerful as link but it's a similar idea if you've done some functional programming in in JavaScript it's a bit like some of the things you can do with that too but basically we're just going to go through this collection each item will become called O and then it will be passed to this function which opens it up and turns it into a tensor and then it will be collated all back into a list and so this will be all of the sevens as tensors. So Silva and I use list and dictionary comprehensions every day and so you should definitely spend some time checking it out if you haven't already. So now that we've got a list of all of the threes as tensors let's just grab one of them and display it. So remember this is a tensor not a PIO image object so Jupyter doesn't know how to display it so we have to use some command to display it and show image is a fast AI command that displays a tensor and so here is our three. So we need to get the average of all of those threes so to get the average the first thing we need to do is to turn change this so it's not a list but it's a tensor itself but currently three tensors one as a shape which is 28 by 28. So this is this is the rows by columns the size of this thing right but three tensors itself is just a list so I can't really easily do mathematical computations on that. So what we could do is we could stack all of these 28 by 28 images on top of each other to create a like a 3d cube of images and that's still called a tensor so a tensor can have as many of these axes or dimensions as you like and to stack them up you use funnily enough stack. So this is going to turn the list into a tensor and as you can see the shape of it is now 6131 by 28 by 28 so it's kind of like a cube of height 6131 by 28 by 28. The other thing we want to do is if we're going to take the mean we want to turn them into floating point values because we we don't want to kind of have integers rounding off. The other thing to know is that it's just as kind of a standard in computer vision that when you're working with floats that you expect them to be between zero and one so we just divide by 255 because they were between zero and 255 before. So this is a pretty standard way to kind of represent a bunch of images in PyTorch. So these three things here are called the axes first axis second axis third axis and overall we would say that this is a rank 3 tensor because it has three axes so the this one here was a rank 2 tensor it has two axes. So you can get the rank from a tensor by just taking the length of its shape 1 2 3 3. You can also get that from the word I've been using the word axis you can also use the word dimension I think numpy tends to call it axis PyTorch tends to call it dimension so the rank is also the number of dimensions and in. So you need to make sure that you remember this word rank is the number of axes or dimensions in a tensor and the shape is a list containing the size of each axis in a tensor. So we can now say stack threes dot mean now if we just say stack threes dot mean that returns a single number that's the average pixel across that whole cube that whole rank 3 tensor but if we say mean 0 that is take the mean over this axis that's the mean across the images right and so that's now 28 by 28 again because we kind of like reduced over this 6131 6131 axis we took the mean across that axis and so we can show that image and here is our ideal 3. So here's the ideal 7 using the same approach right so now let's just grab a 3 there's just any old 3 here it is and what I'm going to do is I'm going to say well is this 3 more similar to the perfect 3 or is it more similar to the perfect 7 and whichever one it's more similar to I'm going to assume that's that's the answer. So we can't just say look at each pixel and say what's the difference between this pixel you know 0 0 here and 0 0 here and then 0 1 here and then 0 1 here and take the average the reason we can't just take the average is that there's positives and negatives and they're going to average out to nothing right so I actually need them all to be positive numbers so there's two ways to make them all positive numbers I could take the absolute value which simply means remove the minus signs okay and then I could take the average of those that's called the mean absolute difference or L1 norm or I could take the square of each difference and then take the mean of that and then at the end I could take the square root kind of undoes the squaring and that's called the root mean squared error or L2. So let's have a look let's take a 3 and subtract from it the mean of the 3s and take the absolute value and take the mean and call that the distance using absolute value of the 3 to a 3 and that there is the number 0.1 right so this is the mean absolute difference or L1 norm so when you see a word like L1 norm if you haven't seen it before it may sound pretty fancy but all these math terms that we see you know you can turn them into a tiny bit of code right it's it's you know don't let the mathy bits fool you that they're often like in code it's just very obvious what they mean where else with math you just you just have to learn it or learn how to Google it so here the same version for squaring take the difference where it take the mean and then take the square root. So then we'll do the same thing for our 3 this time we'll compare it to the mean of the 7s right so the distance from a 3 to the mean of the 3s with in terms of absolute was 0.1 and the distance from a 3 to the mean of the 7s was 0.15 so it's closer to the mean of the 3s than it is to the mean of the 7s so we guess therefore that this is a 3 based on the mean absolute difference same thing with RMSE root mean squared error would be to compare this value with this value and again root means squared error it's closer to the mean 3 than to the mean 7 so this is like a machine learning model kind of it's a data driven model which attempts to recognize 3s versus 7s and so this is a good baseline I mean it's it's a reasonable baseline it's going to be better than random we don't actually have to write out minus abs mean we can just actually use L1 loss L1 loss does exactly that we don't have to write minus squared we can just write MSC loss that doesn't do the square root by default so we have to pop that in okay and as you can see they're exactly the same numbers it's very important before we kind of go too much further to make sure we're very comfortable working with arrays and tensors and you know they're so similar so we could start with a list of lists right which is kind of a matrix we can convert it into an array or into a tensor we can display it and they look almost the same you can index into a single row you can index into a single column and so it's important to know this is very important colon means every row because I put it in the first spot right so if I put it in the second spot it would mean every column and so therefore comma colon is exactly the same as removing it so it just turns out you can always remove colons that are at the end because they're kind of they're just implied right you never have to and I often kind of put them in anyway because just kind of makes it a bit more obvious how these things kind of match up or how they differ you can combine them together so give me the first row and everything from the first up to but not including the third column right so there's that five six you can add stuff to them you can check their type notice that this is different to the Python of cozy the Python type the type is a function just tells you it's a tensor if you want to know what kind of tensor you have to use type as a method so it's a long tensor you can multiply them by a float turns it into a float you know to have a fiddle around if you haven't done much stuff with numpy or pytorch before this is a good opportunity to just go crazy try things out try try things that you think might not work and see if you actually get an error message you know so we now want to find out how good is our model our model that involves just comparing something to to the domain so we should not compare you should not check how good our model is on the training set as we've discussed we should check it on a validation set and we already have a validation set it's everything inside the valid directory so let's go ahead and like combine all those steps before let's go through everything in the validation set three LS open them turn them into a tensor stack them all up turn them into floats divide by 255 okay let's do the same for sevens so we're just putting all the steps we did before into a couple of lines I always try to print out shapes like all the time because if a shape is not what you expected then you can you know get weird things going on so the idea is we want some function is three that will return true if we think something is a three so to do that we have to decide whether our digit that we're testing on is closer to the ideal three or the ideal seven so let's create a little function that returns takes the difference between two things takes the absolute value and then takes the mean so we're going to create this function amnest distance that takes the difference between two answers takes their absolute value and then takes the mean and it takes the mean and look at this we've got minus this time it takes the mean over the last over the second last and third last sorry the last and second last dimensions so this is going to take the mean across the kind of x and y axes and so here you can see it's returning a single number which is the distance of a three from the mean three so that's the same as the value that we got earlier point one one one four so we need to do this for every image in the validation set because we're trying to find the overall metric remember the metric is the thing we look at to say how good is our model so here's something crazy we can call amnest distance not just on r3 but are on the entire validation set against the main three so that's wild like there's no normal programming that we would do where we could somehow pass in either a matrix or a rank three tensor and somehow it works both times and what actually happened here is that instead of returning a single number it returned 1010 numbers and it did this because it used something called broadcasting and broadcasting is like the super special magic trick that lets you make python into a very very high performance language and in fact if you do this broadcasting on GPU tensors and pytorch it actually does this operation on the GPU even though you wrote it in python here's what happens look here this a minus b so we're doing a minus b on two things we've got first of all valid three tens or valid three tensor is a thousand or so images right and remember that main three is just our single ideal three so what is something of this shape minus something of this shape well broadcasting means that if this shape doesn't match this shape like if they did match it would just subtract every corresponding item but because they don't match it's a it actually acts as if there's a thousand and ten versions of this so it's actually going to subtract this from every single one of these right so broadcasting let's look at some examples so broadcasting requires us to first of all understand the idea of element-wise operations this is an element-wise operation here is a rank one tensor of size three and another rank one tensor of size three so we would say these sizes match they're the same and so when I add one two three to one one one I get back two three four it just takes the corresponding items and adds them together so that's called element-wise operations so when I have different shapes as we described before what it ends up doing is it basically copies this this number a thousand and ten times and it acts as if we had said valid three tens minus a thousand and ten copies of mean three as it says here it doesn't actually copy mean three a thousand and ten times it just pretends that it did right it just acts as if it did so basically kind of loops back around to the start again and again and it does the whole thing and see or encoder on the GPU so then we see absolute value right so let's go back up here after we do the minus we go absolute value so what happens when we call absolute value on something of size 10 10 by 28 by 28 just cause absolute value on each underlying thing and then finally we call mean minus one is the last element always in Python minus two is the second last so this is taking the mean over the last two axes and so then it's going to return just the first axis so we're going to end up with a thousand and ten means for a thousand and ten distances which is exactly what we want we want to know how far away is our each of our validation items away from the the ideal three so then we can create our is three function which is hey is the distance between the number in question and the perfect three less than the distance between the number in question and the perfect seven if it is it's a three right so our three that was that actual three we had is it a three yes okay and then we can turn that into a float and yes becomes one thanks to broadcasting we can do it for that entire set right so this is so cool we basically get rid of loops in in in in this kind of programming you should have very few very very few loops loops make things much harder to read and and hundreds of thousands of times slower on the GPU potentially tens of millions of times slower so we can just say is three on our whole valid three tens and then turn that into float and then take the mean so that's going to be the accuracy of the threes on average and here's the accuracy of the sevens it's just one minus that so the accuracy across threes is about 91 and a bit percent the accuracy on sevens is about 98 percent and the average of those two is about 95 percent so here we have a model that's 95 percent accurate at recognizing threes from sevens it might surprise you that we can do that using nothing but arithmetic right so that's what I mean by getting a good baseline now the thing is it's not obvious how we kind of improve this right I mean the thing is it doesn't match Arthur Samuel's description of machine learning right this is not something where there's a function which has some parameters which we're testing against some kind of measure of fitness and then using that to like improve the parameters iteratively we kind of we just did one step and that's that right so we want to try and do it in this way where we arrange for some automatic means of testing the effectiveness of he called it a weight assignment we'd call it a parameter assignment in terms of performance and a mechanism for alterating altering the weight assignment to maximize the performance that we want to do it that way right because we know from from chapter one from lesson one but if we do it that way we have this like magic box right called machine learning that can do you know particularly combined with neural nets should be able to solve any problem in theory if you can at least find the right set of weights so we need something that we can get better and better to learn so let's think about a function which has parameters so instead of finding an ideal image and seeing how far away something is from the ideal image so instead of like having something where we test how far away we are from an ideal image what we could instead do is come up with a set of weights for each pixel so we're trying to find out if something is the number three and so we know that like in the places that you would expect to find three pixels you could give those like high weights so you can say hey if there's a dot in those places we give it like a high score and if there's dots in other places we'll give it like a low score but we can actually come up with a function where the probability of something being an woman's case let's say an eight is equal to the pixels in the image multiplied by some set of weights and then we sum them up right so then anywhere where our the image we're looking at you know as pixels where there are high weights it's going to end up with a high probability so here x is the image that we're interested in and we're just going to represent it as a vector so let's just have all the rows stacked up end to end into a single long line so we're going to use an approach where we're going to start with a vector w so a vector is a rank one tensor okay we're going to start with a vector w that's going to contain random weights random parameters depending on whether you use the Arthur Samuel version of the terminology or not and so we'll then predict whether a number appears to be a three or a seven by using this tiny little function and then we will figure out how good the model is so we will calculate like how accurate it is or something like that yeah this is the loss and then the key step is we're then going to calculate the gradient now the gradient is something that measures for each weight if I made it a little bit bigger would the loss get better or worse if I made it a little bit smaller would the loss get better or worse and so if we do that for every weight we can decide for every weight whether we should make that weight a bit bigger or a bit smaller so that's called the gradient right so once we have the gradient we then step is the word we use a step we change all the weights up a little bit for the ones where the gradient we should said we should make them a bit higher and down a little bit for all the ones where the gradient said they should be a bit lower so now it should be a tiny bit better and then we go back to step two and calculate a new set of predictions using this formula calculate the gradient again set the weights keep doing that so this is basically the flow chart and then at some point when we're sick of waiting or when the loss gets good enough we'll stop so these seven steps one two three four five six seven these seven steps are the key to training all deep learning models this technique is called stochastic gradient descent well it's called gradient descent we'll see the stochastic bit very soon and for each of these seven steps there's lots of choices around exactly how to do it right we've just kind of hand waved a lot like what kind of random initialization and how do you calculate the gradient and exactly what step do you take based on the gradient and how do you decide when to stop blah blah blah blah so in this in this course we're going to be like learning about you know these steps you know that's kind of part one you know the other big part is like well what's the actual function neural network so how do we train the thing and what is the thing that we train so we initialize parameters with random values we need some function that's going to be the loss function that will return a number that's small if the performance of the model is good it's some way to figure out whether the weight should be increased a bit or decreased a bit and then we need to decide like when to stop which would have say let's just do a certain number of epochs so let's like go even simpler right we're not even going to do MNIST we're going to start with this function x squared okay and in faster.ai we've created a tiny little thing called plot function that plots a function all right so there's our function f and what we're going to do is we're going to try to find this is our loss function so we're going to try and find the bottom point right so we're going to try and figure out what is the x value which is at the bottom so our seven-step procedure requires us to start out by initializing so we need to pick some value right so the value we pick with this say oh let's just randomly pick minus one and a half great so now we need to know if I increase x a bit does my remember this is my loss does my loss get a bit better remember better is smaller or a bit worse so we can do that easily enough we can just try a slightly higher x and a slightly lower x and see what happens right and you can see it's just the slope right the slope at this point tells you that if I increase x by a bit then my loss will decrease because that is the slope at this point so if we change our our weight our parameter just a little bit in the direction of the slope right so here is the direction of the slope and so here's the new value at that point right and then do it again and then do it again eventually we'll get to the bottom of this curve right so this idea goes all the way back to Isaac Newton at the very least and this basic idea is called Newton's method so a key thing we need to be able to do is to calculate this slope and the bad news is do that we need calculus at least that's bad news for me because I've never been a fan of calculus we have to calculate the derivative here's the good news though maybe you spent ages in school learning how to calculate derivatives you don't have to anymore the computer does it for you and the computer does it fast it uses all of those methods that you learned at school and it had a whole lot more like clever tricks for speeding them up and it just does it all automatically so for example it knows I don't know if you remember this from high school that the derivative of x squared is 2x it's just something it knows it's part of its kind of bag of tricks right so so PyTorch knows that PyTorch has an engine built in that can take derivatives and find the gradient of functions so to do that we start with a tensor let's say and in this case we're going to modify this tensor with this special method called requiresGrad and what this does is it tells PyTorch that anytime I do a calculation with this xt it should remember what calculation it does so that I can take the derivative later. You see the underscore at the end an underscore at the end of a method in PyTorch means that this is called an in-place operation it actually modifies this so requiresGrad underscore modifies this tensor to tell PyTorch that we want to be calculating gradients on it so that means it's just going to have to keep track of all of the computations we do so that it can calculate the derivative later. Okay so we've got the number 3 and let's say we then call f on it remember f is just squaring it so 3 squared is 9 but the value is not just 9 it's 9 accompanied with a grad of grad function which is that it's it knows that a power operation has been taken so we can now call a special method backward and backward which refers to back propagation which we'll learn about which basically means take the derivative and so once it does that we can now look inside xt because we said requiresGrad and find out its gradient and remember the derivative of x squared is 2x in this case that was 3 2 times 3 is 6 right so we didn't have to figure out the derivative we just call backward and then get the grad attribute to get the derivative so that's how easy it is to do calculus in PyTorch so what you need to know about calculus is not how to take a derivative but what it means and what it means is it's a slope at some point. Now here's something interesting let's not just take 3 but let's take a rank 1 tensor also known as a vector 3 4 10 and let's add some to our f function so it's going to go x squared dot sum and now we can take f of this vector get back 125 and then we can say backward and grad and look 2x 2x 2x right so we can calculate this is this is vector calculus right we're getting the gradient for every element of a vector with the same two lines of code so that's kind of all you need to know about calculus right and if this is if this idea that a derivative for gradient is a slope is unfamiliar check out Khan Academy they have some great introductory calculus and don't forget you can skip all the bits where they teach you how to calculate the gradients yourself. So now that we know how to calculate the gradient that is the slope of the function that tells us if we change our input a little bit how will our output change correspondingly that's what a slope is right and so that tells us that every one of our parameters if we know their gradients then we know if we change that parameter up a bit or down a bit how will it change our loss so therefore we then know how to change our parameters so what we do is let's say all of our weights are called W we just subtract off them the gradients multiplied by some small number and that small number is often a number between about point 001 and point one and it's called the learning rate right and this here is the essence of gradient descent so if you pick a learning rate that's very small then you take the slope and you take a really small step in that direction and another small step another small step another small steps and it's going to take forever to get to the end if you pick a learning rate that's too big you jump way too far each time and again it's going to take forever and in fact in this case sorry this case we're assuming we're starting here and it's actually it's so big that it got worse and worse or here's one where we start here and it's like it's not so big it gets worse and worse but it just takes a long time to bounce in and out right so picking a good learning rate is really important both to making sure that it's even possible to solve the problem and that it's possible to solve it in a reasonable amount of time so we'll be learning about picking how to pick learning rates in this course. So let's try this let's try using gradient descent I said SGD that's not quite accurate it's just going to be gradient descent to solve an actual problem so the problem we're going to solve is let's imagine you were watching a roller coaster go over the top of a hump right so as it comes out of the previous hill it's going super fast and it's going up the hill and it's going slower and slower and slower until it gets to the top of the hump and then it goes down the other side it goes faster and faster and faster so if you like had a stopwatch or whatever or a sudden watch some kind of speedometer and you are measuring it just by hand at kind of equal time points you might end up with something that looks a bit like this right and so the way I did this was I just grabbed a range just grabs the numbers from not up to but not including 20 right so these are the time periods at which I'm taking my speed measurement and then I've just got some quadratic function here and multiply it by 3 and then square it and then add one whatever right and then I also actually sorry I take my time minus 9.5 square it times 0.75 add one and then I add a random number to that or add a random number to every observation so I end up with a quadratic function which is a bit bumpy so this is kind of like what it might look like in real life because my speedometer kind of testing is not perfect. Alright so we want to create a function that estimates at any time what is the speed of the roller coaster so we start by guessing what function it might be so we guess that it's a function a times time squared plus b times time plus c you might remember from school is quarter quadratic so let's create a function right and so let's create it using kind of the Arthur Samuels technique the machine learning technique this function is going to take two things it's going to take an input which in this case is a time and it's going to take some parameters and the parameters are a b and c so in in Python you can split out a list or a collection into its components like so and then here's that function. So we're not just trying to find any function in the world we're just trying to find some function which is a quadratic by finding an a in a b and a c so the the Arthur Samuel technique for doing this is to next up come up with a loss function come up with a measurement of how good we are so if we've got some predictions that come out of our function and the targets which are these you know actual values then we could just do the mean squared error okay so here's that mean squared error we saw before the difference squared and then take the mean so now we need to go through our seven-step process we want to come up with a set of three parameters a b and c which are as good as possible the step one is to initialize a b and c to random values so this is how you get random values three of them in PyTorch and remember we're going to be adjusting them so we have to tell PyTorch that we want the gradients I'm just going to save those away so I can check them later and then I calculate the predictions using that function f which was this and then let's create a little function which just plots how good at this point our predictions so here is a function that prints in red our predictions and in blue our targets so that looks pretty terrible so let's calculate the loss using that MSE function we wrote okay so now we want to improve this so calculate the gradients using the two steps we saw call backward and then get grad and this says that each of our parameters has a gradient that's negative let's pick a learning rate of 10 to the minus 5 so we multiply that by 10 to the minus 5 and step the weights and remember step the weights means minus equals learning rate times the gradient there's a wonderful trick here which I've called dot data the reason I've called dot data is dot data is a special attribute in PyTorch which if you use it then the gradient is not calculated and we certainly wouldn't want the gradient to be calculated of the actual step we're doing we only want the gradient to be calculated of our function f right so when we step the weights we have to use this special dot data attribute after we do that delete the gradients that we already had and let's see if loss improved so the loss before was 25,800 now it's 5,400 and the plot has gone from something that goes down to minus 300 oh to something that looks much better so let's do that a few times so I just grabbed those previous lines of code and pasted them all into a single cell okay so preds loss backward data grad is none and then from time to time print the loss out and repeat that ten times and look getting better and better and so we can actually look at it getting better and better so this is pretty cool right we have a technique this is the Arthur Samuel technique for finding a set of parameters that continuously improves by getting feedback from the result of measuring some loss function so that was kind of the key step right this this is the gradient descent method so you should make sure that you kind of go back and feel super comfortable with what's happened and you know if you're not feeling comfortable that that's fine right if it's been a while or if you've never done this kind of gradient descent before this might feel super unfamiliar so kind of try to find the first cell in this notebook where you don't fully understand what it's doing and then like stop and figure it out like look at everything that's going on do some experiments do some reading until you understand that cell where you were stuck before you move forwards so let's now apply this to MNIST so for MNIST we want to use this exact technique and there's basically nothing extra we have to do except one thing we need a loss function and the metric that we've been using is the error rate or the accuracy it's like how often are we correct right and and that's the thing that we're actually trying to make good our metric but we've got a very serious problem which is remember we need to calculate the gradient to figure out how we should change our parameters and the gradient is the slope or the steepness which you might remember from school is defined as rise over run it's y new minus y old divided by x new minus x old so the gradients actually defined when x new is is very very close to x old meaning their difference is very small but think about it accuracy if I change a parameter by a tiny tiny tiny amount the accuracy might not change at all because there might not be any three that we now predict as a seven or any seven that we now predict as a three because we change the parameter by such a small amount so it's it's it's possible in fact it's certain that the gradient is zero at many places and that means that our parameters aren't going to change at all because learning rate times gradient is still zero when the gradient zero for any learning rate so this is why the loss function and the metric are not always the same thing we can't use a metric as our loss if that metric has a gradient of zero so we need something different so we want to find something that kind of is pretty similar to the accuracy in that like as the accuracy gets better this ideal function we want gets better as well but it should not have a gradient of zero so let's think about that function suppose we had three images actually you know what this is actually probably a good time to stop because actually you know we've kind of we've got to the point here where we understand gradient descent we kind of know how to do it with a simple loss function and I actually think before we start looking at the MNIST loss function we shouldn't move on because we've got so much so much assignments to do for this week already so we've got build your web application and we've got go step through step through this notebook to make sure you fully understand it so I actually think we should probably stop right here before we make things too crazy so before I do Rachel are there any questions okay great all right well thanks everybody I'm sorry for that last minute change of tack there but I think this is going to make sense so I hope you have a lot of fun with your web applications try and think of something that's really fun really interesting it doesn't have to be like important it could just be some you know cute thing we've had students before a student that I think he said he had 16 different cousins and he created something that would classify a photo based on which of his cousins as for like his fiance meeting his family you know you can come up with anything you like but you know yeah show off your application and maybe have a look around at what I pay widgets can do and try and come up with something that you think is pretty cool all right thanks everybody I will see you next week.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.96, "text": " So hello and welcome to lesson 3 of practical deep learning for coders. We were looking", "tokens": [407, 7751, 293, 2928, 281, 6898, 805, 295, 8496, 2452, 2539, 337, 17656, 433, 13, 492, 645, 1237], "temperature": 0.0, "avg_logprob": -0.11904893602643694, "compression_ratio": 1.6926829268292682, "no_speech_prob": 0.0006985778454691172}, {"id": 1, "seek": 0, "start": 10.96, "end": 16.72, "text": " at getting our model into production last week and so we're going to finish off that", "tokens": [412, 1242, 527, 2316, 666, 4265, 1036, 1243, 293, 370, 321, 434, 516, 281, 2413, 766, 300], "temperature": 0.0, "avg_logprob": -0.11904893602643694, "compression_ratio": 1.6926829268292682, "no_speech_prob": 0.0006985778454691172}, {"id": 2, "seek": 0, "start": 16.72, "end": 20.92, "text": " today and then we're going to start to look behind the scenes at what actually goes on", "tokens": [965, 293, 550, 321, 434, 516, 281, 722, 281, 574, 2261, 264, 8026, 412, 437, 767, 1709, 322], "temperature": 0.0, "avg_logprob": -0.11904893602643694, "compression_ratio": 1.6926829268292682, "no_speech_prob": 0.0006985778454691172}, {"id": 3, "seek": 0, "start": 20.92, "end": 25.68, "text": " when we train a neural network. We're going to look at kind of the math of what's going", "tokens": [562, 321, 3847, 257, 18161, 3209, 13, 492, 434, 516, 281, 574, 412, 733, 295, 264, 5221, 295, 437, 311, 516], "temperature": 0.0, "avg_logprob": -0.11904893602643694, "compression_ratio": 1.6926829268292682, "no_speech_prob": 0.0006985778454691172}, {"id": 4, "seek": 2568, "start": 25.68, "end": 34.78, "text": " on and we're going to learn about SGD and some important stuff like that. The order", "tokens": [322, 293, 321, 434, 516, 281, 1466, 466, 34520, 35, 293, 512, 1021, 1507, 411, 300, 13, 440, 1668], "temperature": 0.0, "avg_logprob": -0.11449249512558683, "compression_ratio": 1.7540983606557377, "no_speech_prob": 8.26769246486947e-06}, {"id": 5, "seek": 2568, "start": 34.78, "end": 38.2, "text": " is slightly different to the book. In the book there's a part in the book which says", "tokens": [307, 4748, 819, 281, 264, 1446, 13, 682, 264, 1446, 456, 311, 257, 644, 294, 264, 1446, 597, 1619], "temperature": 0.0, "avg_logprob": -0.11449249512558683, "compression_ratio": 1.7540983606557377, "no_speech_prob": 8.26769246486947e-06}, {"id": 6, "seek": 2568, "start": 38.2, "end": 43.72, "text": " like hey you can either go to lesson 4 or lesson 3 now and then go back to the other", "tokens": [411, 4177, 291, 393, 2139, 352, 281, 6898, 1017, 420, 6898, 805, 586, 293, 550, 352, 646, 281, 264, 661], "temperature": 0.0, "avg_logprob": -0.11449249512558683, "compression_ratio": 1.7540983606557377, "no_speech_prob": 8.26769246486947e-06}, {"id": 7, "seek": 2568, "start": 43.72, "end": 48.64, "text": " one afterwards. So we're doing lesson 4 and then lesson 3, chapter 4 and then chapter", "tokens": [472, 10543, 13, 407, 321, 434, 884, 6898, 1017, 293, 550, 6898, 805, 11, 7187, 1017, 293, 550, 7187], "temperature": 0.0, "avg_logprob": -0.11449249512558683, "compression_ratio": 1.7540983606557377, "no_speech_prob": 8.26769246486947e-06}, {"id": 8, "seek": 2568, "start": 48.64, "end": 55.120000000000005, "text": " 3 I should say. You can choose whichever way you're interested in. Chapter 4 is the more", "tokens": [805, 286, 820, 584, 13, 509, 393, 2826, 24123, 636, 291, 434, 3102, 294, 13, 18874, 1017, 307, 264, 544], "temperature": 0.0, "avg_logprob": -0.11449249512558683, "compression_ratio": 1.7540983606557377, "no_speech_prob": 8.26769246486947e-06}, {"id": 9, "seek": 5512, "start": 55.12, "end": 60.64, "text": " technical chapter about the foundations of how deep learning really works. Chapter 3", "tokens": [6191, 7187, 466, 264, 22467, 295, 577, 2452, 2539, 534, 1985, 13, 18874, 805], "temperature": 0.0, "avg_logprob": -0.18656863936458726, "compression_ratio": 1.6445497630331753, "no_speech_prob": 5.014690032112412e-06}, {"id": 10, "seek": 5512, "start": 60.64, "end": 70.67999999999999, "text": " is all about ethics and so with the lessons we'll do that next week. So we're looking", "tokens": [307, 439, 466, 19769, 293, 370, 365, 264, 8820, 321, 603, 360, 300, 958, 1243, 13, 407, 321, 434, 1237], "temperature": 0.0, "avg_logprob": -0.18656863936458726, "compression_ratio": 1.6445497630331753, "no_speech_prob": 5.014690032112412e-06}, {"id": 11, "seek": 5512, "start": 70.67999999999999, "end": 77.72, "text": " at 0.2 production notebook and we're going to look at the fast book version, the one", "tokens": [412, 1958, 13, 17, 4265, 21060, 293, 321, 434, 516, 281, 574, 412, 264, 2370, 1446, 3037, 11, 264, 472], "temperature": 0.0, "avg_logprob": -0.18656863936458726, "compression_ratio": 1.6445497630331753, "no_speech_prob": 5.014690032112412e-06}, {"id": 12, "seek": 5512, "start": 77.72, "end": 84.14, "text": " with in fact everything I'm looking at today will be in the fast book version. And remember", "tokens": [365, 294, 1186, 1203, 286, 478, 1237, 412, 965, 486, 312, 294, 264, 2370, 1446, 3037, 13, 400, 1604], "temperature": 0.0, "avg_logprob": -0.18656863936458726, "compression_ratio": 1.6445497630331753, "no_speech_prob": 5.014690032112412e-06}, {"id": 13, "seek": 8414, "start": 84.14, "end": 94.76, "text": " last week we had a look at our bears and we created this data loaders object by using", "tokens": [1036, 1243, 321, 632, 257, 574, 412, 527, 17276, 293, 321, 2942, 341, 1412, 3677, 433, 2657, 538, 1228], "temperature": 0.0, "avg_logprob": -0.12170423310378502, "compression_ratio": 1.5446428571428572, "no_speech_prob": 4.3139050376339583e-07}, {"id": 14, "seek": 8414, "start": 94.76, "end": 98.8, "text": " the data block API which I hope everybody's had a chance to experiment with this week", "tokens": [264, 1412, 3461, 9362, 597, 286, 1454, 2201, 311, 632, 257, 2931, 281, 5120, 365, 341, 1243], "temperature": 0.0, "avg_logprob": -0.12170423310378502, "compression_ratio": 1.5446428571428572, "no_speech_prob": 4.3139050376339583e-07}, {"id": 15, "seek": 8414, "start": 98.8, "end": 105.52, "text": " if you haven't now's a good time to do it. We kind of skipped over one of the lines a", "tokens": [498, 291, 2378, 380, 586, 311, 257, 665, 565, 281, 360, 309, 13, 492, 733, 295, 30193, 670, 472, 295, 264, 3876, 257], "temperature": 0.0, "avg_logprob": -0.12170423310378502, "compression_ratio": 1.5446428571428572, "no_speech_prob": 4.3139050376339583e-07}, {"id": 16, "seek": 8414, "start": 105.52, "end": 114.08, "text": " little bit which is this item transforms. So what this is doing here when we said resize", "tokens": [707, 857, 597, 307, 341, 3174, 35592, 13, 407, 437, 341, 307, 884, 510, 562, 321, 848, 50069], "temperature": 0.0, "avg_logprob": -0.12170423310378502, "compression_ratio": 1.5446428571428572, "no_speech_prob": 4.3139050376339583e-07}, {"id": 17, "seek": 11408, "start": 114.08, "end": 117.52, "text": " the images we downloaded from the internet are lots of different sizes and lots of different", "tokens": [264, 5267, 321, 21748, 490, 264, 4705, 366, 3195, 295, 819, 11602, 293, 3195, 295, 819], "temperature": 0.0, "avg_logprob": -0.13581572541403114, "compression_ratio": 1.8204081632653062, "no_speech_prob": 4.425460701895645e-06}, {"id": 18, "seek": 11408, "start": 117.52, "end": 122.98, "text": " aspect ratios some are tall and some are wide and a square and some are big some are small.", "tokens": [4171, 32435, 512, 366, 6764, 293, 512, 366, 4874, 293, 257, 3732, 293, 512, 366, 955, 512, 366, 1359, 13], "temperature": 0.0, "avg_logprob": -0.13581572541403114, "compression_ratio": 1.8204081632653062, "no_speech_prob": 4.425460701895645e-06}, {"id": 19, "seek": 11408, "start": 122.98, "end": 127.6, "text": " When you say resize for an item transform it means each item to an item in this case", "tokens": [1133, 291, 584, 50069, 337, 364, 3174, 4088, 309, 1355, 1184, 3174, 281, 364, 3174, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.13581572541403114, "compression_ratio": 1.8204081632653062, "no_speech_prob": 4.425460701895645e-06}, {"id": 20, "seek": 11408, "start": 127.6, "end": 135.76, "text": " is one image is going to be resized to 128 by 128 by squishing it or stretching it. And", "tokens": [307, 472, 3256, 307, 516, 281, 312, 725, 1602, 281, 29810, 538, 29810, 538, 2339, 3807, 309, 420, 19632, 309, 13, 400], "temperature": 0.0, "avg_logprob": -0.13581572541403114, "compression_ratio": 1.8204081632653062, "no_speech_prob": 4.425460701895645e-06}, {"id": 21, "seek": 11408, "start": 135.76, "end": 141.8, "text": " so we had a look at you can always say show batch to see a few examples and this is what", "tokens": [370, 321, 632, 257, 574, 412, 291, 393, 1009, 584, 855, 15245, 281, 536, 257, 1326, 5110, 293, 341, 307, 437], "temperature": 0.0, "avg_logprob": -0.13581572541403114, "compression_ratio": 1.8204081632653062, "no_speech_prob": 4.425460701895645e-06}, {"id": 22, "seek": 14180, "start": 141.8, "end": 149.0, "text": " they look like. Squishing and stretching isn't the only way that we can resize remember we", "tokens": [436, 574, 411, 13, 8683, 3807, 293, 19632, 1943, 380, 264, 787, 636, 300, 321, 393, 50069, 1604, 321], "temperature": 0.0, "avg_logprob": -0.1528040799227628, "compression_ratio": 1.8432203389830508, "no_speech_prob": 2.4579907176303095e-07}, {"id": 23, "seek": 14180, "start": 149.0, "end": 154.04000000000002, "text": " have everything we have to make everything into a square before we kind of get it into", "tokens": [362, 1203, 321, 362, 281, 652, 1203, 666, 257, 3732, 949, 321, 733, 295, 483, 309, 666], "temperature": 0.0, "avg_logprob": -0.1528040799227628, "compression_ratio": 1.8432203389830508, "no_speech_prob": 2.4579907176303095e-07}, {"id": 24, "seek": 14180, "start": 154.04000000000002, "end": 157.68, "text": " our model by the time it gets to our model everything has to be the same size in each", "tokens": [527, 2316, 538, 264, 565, 309, 2170, 281, 527, 2316, 1203, 575, 281, 312, 264, 912, 2744, 294, 1184], "temperature": 0.0, "avg_logprob": -0.1528040799227628, "compression_ratio": 1.8432203389830508, "no_speech_prob": 2.4579907176303095e-07}, {"id": 25, "seek": 14180, "start": 157.68, "end": 161.68, "text": " mini badge. But that's why they're making it a square is not the only way to do that", "tokens": [8382, 25797, 13, 583, 300, 311, 983, 436, 434, 1455, 309, 257, 3732, 307, 406, 264, 787, 636, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.1528040799227628, "compression_ratio": 1.8432203389830508, "no_speech_prob": 2.4579907176303095e-07}, {"id": 26, "seek": 14180, "start": 161.68, "end": 171.76000000000002, "text": " but it's the easiest way and it's the by far the most common way. So another way to do", "tokens": [457, 309, 311, 264, 12889, 636, 293, 309, 311, 264, 538, 1400, 264, 881, 2689, 636, 13, 407, 1071, 636, 281, 360], "temperature": 0.0, "avg_logprob": -0.1528040799227628, "compression_ratio": 1.8432203389830508, "no_speech_prob": 2.4579907176303095e-07}, {"id": 27, "seek": 17176, "start": 171.76, "end": 182.07999999999998, "text": " this is we can create a another data block object and we can make a data block object", "tokens": [341, 307, 321, 393, 1884, 257, 1071, 1412, 3461, 2657, 293, 321, 393, 652, 257, 1412, 3461, 2657], "temperature": 0.0, "avg_logprob": -0.10852741289742385, "compression_ratio": 1.831578947368421, "no_speech_prob": 2.9023015031270916e-06}, {"id": 28, "seek": 17176, "start": 182.07999999999998, "end": 187.56, "text": " that's an identical copy of an existing data block object where we can then change just", "tokens": [300, 311, 364, 14800, 5055, 295, 364, 6741, 1412, 3461, 2657, 689, 321, 393, 550, 1319, 445], "temperature": 0.0, "avg_logprob": -0.10852741289742385, "compression_ratio": 1.831578947368421, "no_speech_prob": 2.9023015031270916e-06}, {"id": 29, "seek": 17176, "start": 187.56, "end": 192.76, "text": " some pieces and we can do that by calling the new method which is super handy. And so", "tokens": [512, 3755, 293, 321, 393, 360, 300, 538, 5141, 264, 777, 3170, 597, 307, 1687, 13239, 13, 400, 370], "temperature": 0.0, "avg_logprob": -0.10852741289742385, "compression_ratio": 1.831578947368421, "no_speech_prob": 2.9023015031270916e-06}, {"id": 30, "seek": 17176, "start": 192.76, "end": 198.39999999999998, "text": " let's create another data block object and this time with different item transform where", "tokens": [718, 311, 1884, 1071, 1412, 3461, 2657, 293, 341, 565, 365, 819, 3174, 4088, 689], "temperature": 0.0, "avg_logprob": -0.10852741289742385, "compression_ratio": 1.831578947368421, "no_speech_prob": 2.9023015031270916e-06}, {"id": 31, "seek": 19840, "start": 198.4, "end": 207.32, "text": " we resize using the squish method. We have a question what are the advantages of having", "tokens": [321, 50069, 1228, 264, 31379, 3170, 13, 492, 362, 257, 1168, 437, 366, 264, 14906, 295, 1419], "temperature": 0.0, "avg_logprob": -0.14613305727640788, "compression_ratio": 1.5491329479768785, "no_speech_prob": 2.964900431834394e-07}, {"id": 32, "seek": 19840, "start": 207.32, "end": 222.26, "text": " square images versus rectangular ones? That's a great question. So really it's simplicity.", "tokens": [3732, 5267, 5717, 31167, 2306, 30, 663, 311, 257, 869, 1168, 13, 407, 534, 309, 311, 25632, 13], "temperature": 0.0, "avg_logprob": -0.14613305727640788, "compression_ratio": 1.5491329479768785, "no_speech_prob": 2.964900431834394e-07}, {"id": 33, "seek": 19840, "start": 222.26, "end": 227.18, "text": " If you know all of your images are rectangular of a particular aspect ratio to start with", "tokens": [759, 291, 458, 439, 295, 428, 5267, 366, 31167, 295, 257, 1729, 4171, 8509, 281, 722, 365], "temperature": 0.0, "avg_logprob": -0.14613305727640788, "compression_ratio": 1.5491329479768785, "no_speech_prob": 2.964900431834394e-07}, {"id": 34, "seek": 22718, "start": 227.18, "end": 231.36, "text": " you may as well just keep them that way. But if you've got some which are tall and some", "tokens": [291, 815, 382, 731, 445, 1066, 552, 300, 636, 13, 583, 498, 291, 600, 658, 512, 597, 366, 6764, 293, 512], "temperature": 0.0, "avg_logprob": -0.09368482069535689, "compression_ratio": 1.905579399141631, "no_speech_prob": 1.1189371207365184e-06}, {"id": 35, "seek": 22718, "start": 231.36, "end": 237.76000000000002, "text": " which are wide making them all square is kind of the easiest. Otherwise you would have to", "tokens": [597, 366, 4874, 1455, 552, 439, 3732, 307, 733, 295, 264, 12889, 13, 10328, 291, 576, 362, 281], "temperature": 0.0, "avg_logprob": -0.09368482069535689, "compression_ratio": 1.905579399141631, "no_speech_prob": 1.1189371207365184e-06}, {"id": 36, "seek": 22718, "start": 237.76000000000002, "end": 242.08, "text": " kind of organize them such as all of the tall ones kind of ended up in a mini batch and", "tokens": [733, 295, 13859, 552, 1270, 382, 439, 295, 264, 6764, 2306, 733, 295, 4590, 493, 294, 257, 8382, 15245, 293], "temperature": 0.0, "avg_logprob": -0.09368482069535689, "compression_ratio": 1.905579399141631, "no_speech_prob": 1.1189371207365184e-06}, {"id": 37, "seek": 22718, "start": 242.08, "end": 245.84, "text": " all of the wide ones ended up in a mini batch and then you'd have to kind of then figure", "tokens": [439, 295, 264, 4874, 2306, 4590, 493, 294, 257, 8382, 15245, 293, 550, 291, 1116, 362, 281, 733, 295, 550, 2573], "temperature": 0.0, "avg_logprob": -0.09368482069535689, "compression_ratio": 1.905579399141631, "no_speech_prob": 1.1189371207365184e-06}, {"id": 38, "seek": 22718, "start": 245.84, "end": 251.14000000000001, "text": " out what the best aspect ratio for each mini batch is. And we actually have some research", "tokens": [484, 437, 264, 1151, 4171, 8509, 337, 1184, 8382, 15245, 307, 13, 400, 321, 767, 362, 512, 2132], "temperature": 0.0, "avg_logprob": -0.09368482069535689, "compression_ratio": 1.905579399141631, "no_speech_prob": 1.1189371207365184e-06}, {"id": 39, "seek": 25114, "start": 251.14, "end": 259.32, "text": " that does that in fastai too but it's still a bit clunky. I should mention okay I just", "tokens": [300, 775, 300, 294, 2370, 1301, 886, 457, 309, 311, 920, 257, 857, 596, 25837, 13, 286, 820, 2152, 1392, 286, 445], "temperature": 0.0, "avg_logprob": -0.14901855858889493, "compression_ratio": 1.7462686567164178, "no_speech_prob": 1.3925447319707018e-06}, {"id": 40, "seek": 25114, "start": 259.32, "end": 263.24, "text": " lied to you the default is not actually to squish or stretch the default I should have", "tokens": [20101, 281, 291, 264, 7576, 307, 406, 767, 281, 31379, 420, 5985, 264, 7576, 286, 820, 362], "temperature": 0.0, "avg_logprob": -0.14901855858889493, "compression_ratio": 1.7462686567164178, "no_speech_prob": 1.3925447319707018e-06}, {"id": 41, "seek": 25114, "start": 263.24, "end": 273.15999999999997, "text": " said sorry the default when we say resize is actually just to grab the center. So actually", "tokens": [848, 2597, 264, 7576, 562, 321, 584, 50069, 307, 767, 445, 281, 4444, 264, 3056, 13, 407, 767], "temperature": 0.0, "avg_logprob": -0.14901855858889493, "compression_ratio": 1.7462686567164178, "no_speech_prob": 1.3925447319707018e-06}, {"id": 42, "seek": 25114, "start": 273.15999999999997, "end": 276.26, "text": " all we're doing is we're grabbing the center of each image. So if we want to squish or", "tokens": [439, 321, 434, 884, 307, 321, 434, 23771, 264, 3056, 295, 1184, 3256, 13, 407, 498, 321, 528, 281, 31379, 420], "temperature": 0.0, "avg_logprob": -0.14901855858889493, "compression_ratio": 1.7462686567164178, "no_speech_prob": 1.3925447319707018e-06}, {"id": 43, "seek": 27626, "start": 276.26, "end": 281.48, "text": " stretch you can add the resize method dot squish argument to resize and you can now", "tokens": [5985, 291, 393, 909, 264, 50069, 3170, 5893, 31379, 6770, 281, 50069, 293, 291, 393, 586], "temperature": 0.0, "avg_logprob": -0.1410608021718151, "compression_ratio": 1.7261904761904763, "no_speech_prob": 8.71432007443218e-07}, {"id": 44, "seek": 27626, "start": 281.48, "end": 286.8, "text": " see that this black bear is now looking much thinner but we have got the kind of leaves", "tokens": [536, 300, 341, 2211, 6155, 307, 586, 1237, 709, 21905, 457, 321, 362, 658, 264, 733, 295, 5510], "temperature": 0.0, "avg_logprob": -0.1410608021718151, "compression_ratio": 1.7261904761904763, "no_speech_prob": 8.71432007443218e-07}, {"id": 45, "seek": 27626, "start": 286.8, "end": 296.08, "text": " that are around on each side instance. Another question when you use the DLS dot new method", "tokens": [300, 366, 926, 322, 1184, 1252, 5197, 13, 3996, 1168, 562, 291, 764, 264, 413, 19198, 5893, 777, 3170], "temperature": 0.0, "avg_logprob": -0.1410608021718151, "compression_ratio": 1.7261904761904763, "no_speech_prob": 8.71432007443218e-07}, {"id": 46, "seek": 27626, "start": 296.08, "end": 302.0, "text": " what can and cannot be changed is it just the transforms? So it's not DLS dot new it's", "tokens": [437, 393, 293, 2644, 312, 3105, 307, 309, 445, 264, 35592, 30, 407, 309, 311, 406, 413, 19198, 5893, 777, 309, 311], "temperature": 0.0, "avg_logprob": -0.1410608021718151, "compression_ratio": 1.7261904761904763, "no_speech_prob": 8.71432007443218e-07}, {"id": 47, "seek": 27626, "start": 302.0, "end": 305.26, "text": " bears dot new right so we're not creating a new data loaders object we're creating a", "tokens": [17276, 5893, 777, 558, 370, 321, 434, 406, 4084, 257, 777, 1412, 3677, 433, 2657, 321, 434, 4084, 257], "temperature": 0.0, "avg_logprob": -0.1410608021718151, "compression_ratio": 1.7261904761904763, "no_speech_prob": 8.71432007443218e-07}, {"id": 48, "seek": 30526, "start": 305.26, "end": 310.59999999999997, "text": " new data block object. I don't remember off the top of my head so check the documentation", "tokens": [777, 1412, 3461, 2657, 13, 286, 500, 380, 1604, 766, 264, 1192, 295, 452, 1378, 370, 1520, 264, 14333], "temperature": 0.0, "avg_logprob": -0.1030664334351989, "compression_ratio": 1.6682464454976302, "no_speech_prob": 2.2959097805141937e-06}, {"id": 49, "seek": 30526, "start": 310.59999999999997, "end": 319.71999999999997, "text": " and I'm sure somebody can pop the answer into the into the forum. So you can see when we", "tokens": [293, 286, 478, 988, 2618, 393, 1665, 264, 1867, 666, 264, 666, 264, 17542, 13, 407, 291, 393, 536, 562, 321], "temperature": 0.0, "avg_logprob": -0.1030664334351989, "compression_ratio": 1.6682464454976302, "no_speech_prob": 2.2959097805141937e-06}, {"id": 50, "seek": 30526, "start": 319.71999999999997, "end": 326.03999999999996, "text": " use dot squish that this grizzly bear has got pretty kind of wide and weird looking", "tokens": [764, 5893, 31379, 300, 341, 17865, 4313, 356, 6155, 575, 658, 1238, 733, 295, 4874, 293, 3657, 1237], "temperature": 0.0, "avg_logprob": -0.1030664334351989, "compression_ratio": 1.6682464454976302, "no_speech_prob": 2.2959097805141937e-06}, {"id": 51, "seek": 30526, "start": 326.03999999999996, "end": 330.56, "text": " and this black bear has got pretty weird and thin looking and it's easiest kind of to see", "tokens": [293, 341, 2211, 6155, 575, 658, 1238, 3657, 293, 5862, 1237, 293, 309, 311, 12889, 733, 295, 281, 536], "temperature": 0.0, "avg_logprob": -0.1030664334351989, "compression_ratio": 1.6682464454976302, "no_speech_prob": 2.2959097805141937e-06}, {"id": 52, "seek": 33056, "start": 330.56, "end": 336.48, "text": " what's going on if we use resize method dot pad and what dot pad does as you can see is", "tokens": [437, 311, 516, 322, 498, 321, 764, 50069, 3170, 5893, 6887, 293, 437, 5893, 6887, 775, 382, 291, 393, 536, 307], "temperature": 0.0, "avg_logprob": -0.10343620214569435, "compression_ratio": 1.7391304347826086, "no_speech_prob": 1.1189404176548123e-06}, {"id": 53, "seek": 33056, "start": 336.48, "end": 342.12, "text": " it just adds some black bars around each side. So you can see the grizzly bear was tall so", "tokens": [309, 445, 10860, 512, 2211, 10228, 926, 1184, 1252, 13, 407, 291, 393, 536, 264, 17865, 4313, 356, 6155, 390, 6764, 370], "temperature": 0.0, "avg_logprob": -0.10343620214569435, "compression_ratio": 1.7391304347826086, "no_speech_prob": 1.1189404176548123e-06}, {"id": 54, "seek": 33056, "start": 342.12, "end": 347.04, "text": " then when we we stretched squishing and stretching opposites of each other so when we stretched", "tokens": [550, 562, 321, 321, 23563, 2339, 3807, 293, 19632, 4665, 3324, 295, 1184, 661, 370, 562, 321, 23563], "temperature": 0.0, "avg_logprob": -0.10343620214569435, "compression_ratio": 1.7391304347826086, "no_speech_prob": 1.1189404176548123e-06}, {"id": 55, "seek": 33056, "start": 347.04, "end": 353.24, "text": " it it ended up wide and the black bear was originally a wide rectangle so it ended up", "tokens": [309, 309, 4590, 493, 4874, 293, 264, 2211, 6155, 390, 7993, 257, 4874, 21930, 370, 309, 4590, 493], "temperature": 0.0, "avg_logprob": -0.10343620214569435, "compression_ratio": 1.7391304347826086, "no_speech_prob": 1.1189404176548123e-06}, {"id": 56, "seek": 35324, "start": 353.24, "end": 360.6, "text": " looking kind of thin. You don't have to use zeros, zeros means pad it with black you can", "tokens": [1237, 733, 295, 5862, 13, 509, 500, 380, 362, 281, 764, 35193, 11, 35193, 1355, 6887, 309, 365, 2211, 291, 393], "temperature": 0.0, "avg_logprob": -0.119702535254933, "compression_ratio": 1.92, "no_speech_prob": 6.681506761196943e-07}, {"id": 57, "seek": 35324, "start": 360.6, "end": 366.08, "text": " also say like reflect to kind of have the the pixels will kind of look a bit better", "tokens": [611, 584, 411, 5031, 281, 733, 295, 362, 264, 264, 18668, 486, 733, 295, 574, 257, 857, 1101], "temperature": 0.0, "avg_logprob": -0.119702535254933, "compression_ratio": 1.92, "no_speech_prob": 6.681506761196943e-07}, {"id": 58, "seek": 35324, "start": 366.08, "end": 372.04, "text": " that way if you use reflect. All of these different methods have their own problems", "tokens": [300, 636, 498, 291, 764, 5031, 13, 1057, 295, 613, 819, 7150, 362, 641, 1065, 2740], "temperature": 0.0, "avg_logprob": -0.119702535254933, "compression_ratio": 1.92, "no_speech_prob": 6.681506761196943e-07}, {"id": 59, "seek": 35324, "start": 372.04, "end": 377.48, "text": " the the pad method is kind of the cleanest you end up with the correct size you end up", "tokens": [264, 264, 6887, 3170, 307, 733, 295, 264, 2541, 377, 291, 917, 493, 365, 264, 3006, 2744, 291, 917, 493], "temperature": 0.0, "avg_logprob": -0.119702535254933, "compression_ratio": 1.92, "no_speech_prob": 6.681506761196943e-07}, {"id": 60, "seek": 35324, "start": 377.48, "end": 381.88, "text": " with all of the pixels but you also end up with wasted pixels so you kind of end up with", "tokens": [365, 439, 295, 264, 18668, 457, 291, 611, 917, 493, 365, 19496, 18668, 370, 291, 733, 295, 917, 493, 365], "temperature": 0.0, "avg_logprob": -0.119702535254933, "compression_ratio": 1.92, "no_speech_prob": 6.681506761196943e-07}, {"id": 61, "seek": 38188, "start": 381.88, "end": 388.32, "text": " wasted computation. The squish method is the most efficient because you get all of the", "tokens": [19496, 24903, 13, 440, 31379, 3170, 307, 264, 881, 7148, 570, 291, 483, 439, 295, 264], "temperature": 0.0, "avg_logprob": -0.10106481290331074, "compression_ratio": 1.7991967871485943, "no_speech_prob": 5.453289304568898e-07}, {"id": 62, "seek": 38188, "start": 388.32, "end": 396.04, "text": " information you know and nothing's kind of wasted but on the downside your neural net's", "tokens": [1589, 291, 458, 293, 1825, 311, 733, 295, 19496, 457, 322, 264, 25060, 428, 18161, 2533, 311], "temperature": 0.0, "avg_logprob": -0.10106481290331074, "compression_ratio": 1.7991967871485943, "no_speech_prob": 5.453289304568898e-07}, {"id": 63, "seek": 38188, "start": 396.04, "end": 400.52, "text": " going to have to learn to kind of like recognize when something's been squished or stretched", "tokens": [516, 281, 362, 281, 1466, 281, 733, 295, 411, 5521, 562, 746, 311, 668, 2339, 4729, 420, 23563], "temperature": 0.0, "avg_logprob": -0.10106481290331074, "compression_ratio": 1.7991967871485943, "no_speech_prob": 5.453289304568898e-07}, {"id": 64, "seek": 38188, "start": 400.52, "end": 404.64, "text": " and in some cases it might it wouldn't even know so if there's two objects you're trying", "tokens": [293, 294, 512, 3331, 309, 1062, 309, 2759, 380, 754, 458, 370, 498, 456, 311, 732, 6565, 291, 434, 1382], "temperature": 0.0, "avg_logprob": -0.10106481290331074, "compression_ratio": 1.7991967871485943, "no_speech_prob": 5.453289304568898e-07}, {"id": 65, "seek": 38188, "start": 404.64, "end": 408.48, "text": " to recognize one of which tends to be thin and one of which tends to be thick and otherwise", "tokens": [281, 5521, 472, 295, 597, 12258, 281, 312, 5862, 293, 472, 295, 597, 12258, 281, 312, 5060, 293, 5911], "temperature": 0.0, "avg_logprob": -0.10106481290331074, "compression_ratio": 1.7991967871485943, "no_speech_prob": 5.453289304568898e-07}, {"id": 66, "seek": 40848, "start": 408.48, "end": 414.88, "text": " they're the same they could actually be impossible to distinguish. And then the default cropping", "tokens": [436, 434, 264, 912, 436, 727, 767, 312, 6243, 281, 20206, 13, 400, 550, 264, 7576, 4848, 3759], "temperature": 0.0, "avg_logprob": -0.10490877287728446, "compression_ratio": 1.6636363636363636, "no_speech_prob": 3.20582472568276e-07}, {"id": 67, "seek": 40848, "start": 414.88, "end": 424.24, "text": " approach actually removes some information so in this case you know this this grizzly", "tokens": [3109, 767, 30445, 512, 1589, 370, 294, 341, 1389, 291, 458, 341, 341, 17865, 4313, 356], "temperature": 0.0, "avg_logprob": -0.10490877287728446, "compression_ratio": 1.6636363636363636, "no_speech_prob": 3.20582472568276e-07}, {"id": 68, "seek": 40848, "start": 424.24, "end": 430.24, "text": " bear here we actually lost a lot of its legs so if figuring it out what kind of bear it", "tokens": [6155, 510, 321, 767, 2731, 257, 688, 295, 1080, 5668, 370, 498, 15213, 309, 484, 437, 733, 295, 6155, 309], "temperature": 0.0, "avg_logprob": -0.10490877287728446, "compression_ratio": 1.6636363636363636, "no_speech_prob": 3.20582472568276e-07}, {"id": 69, "seek": 40848, "start": 430.24, "end": 436.28000000000003, "text": " was required looking at its feet well we don't have its feet anymore so they all have downsides", "tokens": [390, 4739, 1237, 412, 1080, 3521, 731, 321, 500, 380, 362, 1080, 3521, 3602, 370, 436, 439, 362, 21554, 1875], "temperature": 0.0, "avg_logprob": -0.10490877287728446, "compression_ratio": 1.6636363636363636, "no_speech_prob": 3.20582472568276e-07}, {"id": 70, "seek": 43628, "start": 436.28, "end": 444.08, "text": " so there's something else that you can do a different approach which is instead of to", "tokens": [370, 456, 311, 746, 1646, 300, 291, 393, 360, 257, 819, 3109, 597, 307, 2602, 295, 281], "temperature": 0.0, "avg_logprob": -0.11972571582328982, "compression_ratio": 1.835978835978836, "no_speech_prob": 3.2563093554927036e-07}, {"id": 71, "seek": 43628, "start": 444.08, "end": 449.08, "text": " say resize you can say random resized crop and actually this is the most common approach", "tokens": [584, 50069, 291, 393, 584, 4974, 725, 1602, 9086, 293, 767, 341, 307, 264, 881, 2689, 3109], "temperature": 0.0, "avg_logprob": -0.11972571582328982, "compression_ratio": 1.835978835978836, "no_speech_prob": 3.2563093554927036e-07}, {"id": 72, "seek": 43628, "start": 449.08, "end": 458.0, "text": " and what random resized crop does is each time it actually grabs a different part of", "tokens": [293, 437, 4974, 725, 1602, 9086, 775, 307, 1184, 565, 309, 767, 30028, 257, 819, 644, 295], "temperature": 0.0, "avg_logprob": -0.11972571582328982, "compression_ratio": 1.835978835978836, "no_speech_prob": 3.2563093554927036e-07}, {"id": 73, "seek": 43628, "start": 458.0, "end": 463.67999999999995, "text": " the image and kind of zooms into it right so these this is all the same image and we're", "tokens": [264, 3256, 293, 733, 295, 5721, 4785, 666, 309, 558, 370, 613, 341, 307, 439, 264, 912, 3256, 293, 321, 434], "temperature": 0.0, "avg_logprob": -0.11972571582328982, "compression_ratio": 1.835978835978836, "no_speech_prob": 3.2563093554927036e-07}, {"id": 74, "seek": 46368, "start": 463.68, "end": 470.48, "text": " just grabbing a batch of four different versions of it and you can see some are kind of you", "tokens": [445, 23771, 257, 15245, 295, 1451, 819, 9606, 295, 309, 293, 291, 393, 536, 512, 366, 733, 295, 291], "temperature": 0.0, "avg_logprob": -0.08579613180721507, "compression_ratio": 1.71875, "no_speech_prob": 1.4367479934662697e-06}, {"id": 75, "seek": 46368, "start": 470.48, "end": 474.52, "text": " know they're all squished in different ways and we've kind of selected different subsets", "tokens": [458, 436, 434, 439, 2339, 4729, 294, 819, 2098, 293, 321, 600, 733, 295, 8209, 819, 2090, 1385], "temperature": 0.0, "avg_logprob": -0.08579613180721507, "compression_ratio": 1.71875, "no_speech_prob": 1.4367479934662697e-06}, {"id": 76, "seek": 46368, "start": 474.52, "end": 480.28000000000003, "text": " and so forth now this kind of seems worse than any of the previous approaches because", "tokens": [293, 370, 5220, 586, 341, 733, 295, 2544, 5324, 813, 604, 295, 264, 3894, 11587, 570], "temperature": 0.0, "avg_logprob": -0.08579613180721507, "compression_ratio": 1.71875, "no_speech_prob": 1.4367479934662697e-06}, {"id": 77, "seek": 46368, "start": 480.28000000000003, "end": 485.88, "text": " I'm losing information like this one here I've actually lost a whole lot of its of its", "tokens": [286, 478, 7027, 1589, 411, 341, 472, 510, 286, 600, 767, 2731, 257, 1379, 688, 295, 1080, 295, 1080], "temperature": 0.0, "avg_logprob": -0.08579613180721507, "compression_ratio": 1.71875, "no_speech_prob": 1.4367479934662697e-06}, {"id": 78, "seek": 46368, "start": 485.88, "end": 493.2, "text": " back right but the cool thing about this is that remember we want to avoid overfitting", "tokens": [646, 558, 457, 264, 1627, 551, 466, 341, 307, 300, 1604, 321, 528, 281, 5042, 670, 69, 2414], "temperature": 0.0, "avg_logprob": -0.08579613180721507, "compression_ratio": 1.71875, "no_speech_prob": 1.4367479934662697e-06}, {"id": 79, "seek": 49320, "start": 493.2, "end": 500.59999999999997, "text": " and when you see a different part of the animal each time it's much less likely to overfit", "tokens": [293, 562, 291, 536, 257, 819, 644, 295, 264, 5496, 1184, 565, 309, 311, 709, 1570, 3700, 281, 670, 6845], "temperature": 0.0, "avg_logprob": -0.11751659349961714, "compression_ratio": 1.5919282511210762, "no_speech_prob": 1.0030120165538392e-06}, {"id": 80, "seek": 49320, "start": 500.59999999999997, "end": 506.68, "text": " because you're not seeing the same image on each epoch that you go around that makes sense", "tokens": [570, 291, 434, 406, 2577, 264, 912, 3256, 322, 1184, 30992, 339, 300, 291, 352, 926, 300, 1669, 2020], "temperature": 0.0, "avg_logprob": -0.11751659349961714, "compression_ratio": 1.5919282511210762, "no_speech_prob": 1.0030120165538392e-06}, {"id": 81, "seek": 49320, "start": 506.68, "end": 515.28, "text": " so so this random resized crop approach is actually super popular and so min scale 0.3", "tokens": [370, 370, 341, 4974, 725, 1602, 9086, 3109, 307, 767, 1687, 3743, 293, 370, 923, 4373, 1958, 13, 18], "temperature": 0.0, "avg_logprob": -0.11751659349961714, "compression_ratio": 1.5919282511210762, "no_speech_prob": 1.0030120165538392e-06}, {"id": 82, "seek": 49320, "start": 515.28, "end": 521.02, "text": " means we're going to pick at least 30% of the pixels of kind of the original size each", "tokens": [1355, 321, 434, 516, 281, 1888, 412, 1935, 2217, 4, 295, 264, 18668, 295, 733, 295, 264, 3380, 2744, 1184], "temperature": 0.0, "avg_logprob": -0.11751659349961714, "compression_ratio": 1.5919282511210762, "no_speech_prob": 1.0030120165538392e-06}, {"id": 83, "seek": 52102, "start": 521.02, "end": 531.24, "text": " time and then we'll kind of like zoom into that that square.", "tokens": [565, 293, 550, 321, 603, 733, 295, 411, 8863, 666, 300, 300, 3732, 13], "temperature": 0.0, "avg_logprob": -0.06499185959498087, "compression_ratio": 1.6013071895424837, "no_speech_prob": 5.122889774611394e-07}, {"id": 84, "seek": 52102, "start": 531.24, "end": 538.64, "text": " So this idea of doing something so that each time the model sees the image it looks a bit", "tokens": [407, 341, 1558, 295, 884, 746, 370, 300, 1184, 565, 264, 2316, 8194, 264, 3256, 309, 1542, 257, 857], "temperature": 0.0, "avg_logprob": -0.06499185959498087, "compression_ratio": 1.6013071895424837, "no_speech_prob": 5.122889774611394e-07}, {"id": 85, "seek": 52102, "start": 538.64, "end": 544.0799999999999, "text": " different to last time it's called data augmentation and this is one type of data augmentation", "tokens": [819, 281, 1036, 565, 309, 311, 1219, 1412, 14501, 19631, 293, 341, 307, 472, 2010, 295, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.06499185959498087, "compression_ratio": 1.6013071895424837, "no_speech_prob": 5.122889774611394e-07}, {"id": 86, "seek": 54408, "start": 544.08, "end": 552.64, "text": " it's probably the most common but there are others and one of the best ways to do data", "tokens": [309, 311, 1391, 264, 881, 2689, 457, 456, 366, 2357, 293, 472, 295, 264, 1151, 2098, 281, 360, 1412], "temperature": 0.0, "avg_logprob": -0.08738074177189877, "compression_ratio": 1.8205128205128205, "no_speech_prob": 1.7603373407837353e-06}, {"id": 87, "seek": 54408, "start": 552.64, "end": 559.48, "text": " augmentation is to use this org transforms function and what org transforms does is it", "tokens": [14501, 19631, 307, 281, 764, 341, 14045, 35592, 2445, 293, 437, 14045, 35592, 775, 307, 309], "temperature": 0.0, "avg_logprob": -0.08738074177189877, "compression_ratio": 1.8205128205128205, "no_speech_prob": 1.7603373407837353e-06}, {"id": 88, "seek": 54408, "start": 559.48, "end": 568.72, "text": " actually returns a list of different augmentations and so there are augmentations which change", "tokens": [767, 11247, 257, 1329, 295, 819, 29919, 763, 293, 370, 456, 366, 29919, 763, 597, 1319], "temperature": 0.0, "avg_logprob": -0.08738074177189877, "compression_ratio": 1.8205128205128205, "no_speech_prob": 1.7603373407837353e-06}, {"id": 89, "seek": 54408, "start": 568.72, "end": 573.88, "text": " contrast which change brightness which warp the perspective so you can see in this one", "tokens": [8712, 597, 1319, 21367, 597, 36030, 264, 4585, 370, 291, 393, 536, 294, 341, 472], "temperature": 0.0, "avg_logprob": -0.08738074177189877, "compression_ratio": 1.8205128205128205, "no_speech_prob": 1.7603373407837353e-06}, {"id": 90, "seek": 57388, "start": 573.88, "end": 577.16, "text": " here it looks like this bit's much closer to you and it's much away from you because", "tokens": [510, 309, 1542, 411, 341, 857, 311, 709, 4966, 281, 291, 293, 309, 311, 709, 1314, 490, 291, 570], "temperature": 0.0, "avg_logprob": -0.11562652122683642, "compression_ratio": 1.9625468164794007, "no_speech_prob": 1.963800059456844e-06}, {"id": 91, "seek": 57388, "start": 577.16, "end": 580.68, "text": " it's going to be in perspective warped it rotates them see this one's actually been", "tokens": [309, 311, 516, 281, 312, 294, 4585, 1516, 3452, 309, 42133, 552, 536, 341, 472, 311, 767, 668], "temperature": 0.0, "avg_logprob": -0.11562652122683642, "compression_ratio": 1.9625468164794007, "no_speech_prob": 1.963800059456844e-06}, {"id": 92, "seek": 57388, "start": 580.68, "end": 588.12, "text": " rotated this one's been made really dark right these are batch transforms not item transforms", "tokens": [42146, 341, 472, 311, 668, 1027, 534, 2877, 558, 613, 366, 15245, 35592, 406, 3174, 35592], "temperature": 0.0, "avg_logprob": -0.11562652122683642, "compression_ratio": 1.9625468164794007, "no_speech_prob": 1.963800059456844e-06}, {"id": 93, "seek": 57388, "start": 588.12, "end": 592.48, "text": " the difference is that item transforms happen one image at a time and so the thing that", "tokens": [264, 2649, 307, 300, 3174, 35592, 1051, 472, 3256, 412, 257, 565, 293, 370, 264, 551, 300], "temperature": 0.0, "avg_logprob": -0.11562652122683642, "compression_ratio": 1.9625468164794007, "no_speech_prob": 1.963800059456844e-06}, {"id": 94, "seek": 57388, "start": 592.48, "end": 597.5, "text": " resizes them all to the same size that has to be an item transform pop it all into a", "tokens": [725, 5660, 552, 439, 281, 264, 912, 2744, 300, 575, 281, 312, 364, 3174, 4088, 1665, 309, 439, 666, 257], "temperature": 0.0, "avg_logprob": -0.11562652122683642, "compression_ratio": 1.9625468164794007, "no_speech_prob": 1.963800059456844e-06}, {"id": 95, "seek": 57388, "start": 597.5, "end": 602.84, "text": " mini batch put it on the GPU and then a batch transform happens to a whole mini batch at", "tokens": [8382, 15245, 829, 309, 322, 264, 18407, 293, 550, 257, 15245, 4088, 2314, 281, 257, 1379, 8382, 15245, 412], "temperature": 0.0, "avg_logprob": -0.11562652122683642, "compression_ratio": 1.9625468164794007, "no_speech_prob": 1.963800059456844e-06}, {"id": 96, "seek": 60284, "start": 602.84, "end": 608.4, "text": " a time and by putting these as batch transforms that the augmentation happens super fast because", "tokens": [257, 565, 293, 538, 3372, 613, 382, 15245, 35592, 300, 264, 14501, 19631, 2314, 1687, 2370, 570], "temperature": 0.0, "avg_logprob": -0.11886527663783024, "compression_ratio": 1.599009900990099, "no_speech_prob": 1.529410383227514e-06}, {"id": 97, "seek": 60284, "start": 608.4, "end": 614.2800000000001, "text": " it happens on the GPU and I don't know if there's any other libraries as we speak which", "tokens": [309, 2314, 322, 264, 18407, 293, 286, 500, 380, 458, 498, 456, 311, 604, 661, 15148, 382, 321, 1710, 597], "temperature": 0.0, "avg_logprob": -0.11886527663783024, "compression_ratio": 1.599009900990099, "no_speech_prob": 1.529410383227514e-06}, {"id": 98, "seek": 60284, "start": 614.2800000000001, "end": 619.6, "text": " allow you to write your own GPU accelerated transformations that run on the GPU in this", "tokens": [2089, 291, 281, 2464, 428, 1065, 18407, 29763, 34852, 300, 1190, 322, 264, 18407, 294, 341], "temperature": 0.0, "avg_logprob": -0.11886527663783024, "compression_ratio": 1.599009900990099, "no_speech_prob": 1.529410383227514e-06}, {"id": 99, "seek": 60284, "start": 619.6, "end": 629.5600000000001, "text": " way so this is a super handy thing in fast AI too.", "tokens": [636, 370, 341, 307, 257, 1687, 13239, 551, 294, 2370, 7318, 886, 13], "temperature": 0.0, "avg_logprob": -0.11886527663783024, "compression_ratio": 1.599009900990099, "no_speech_prob": 1.529410383227514e-06}, {"id": 100, "seek": 62956, "start": 629.56, "end": 635.4799999999999, "text": " So you can check out the documentation for or transforms and when you do you'll find", "tokens": [407, 291, 393, 1520, 484, 264, 14333, 337, 420, 35592, 293, 562, 291, 360, 291, 603, 915], "temperature": 0.0, "avg_logprob": -0.08774424062191861, "compression_ratio": 1.872340425531915, "no_speech_prob": 4.592128846070409e-07}, {"id": 101, "seek": 62956, "start": 635.4799999999999, "end": 641.8, "text": " the documentation for all of the underlying transforms that it basically wraps right so", "tokens": [264, 14333, 337, 439, 295, 264, 14217, 35592, 300, 309, 1936, 25831, 558, 370], "temperature": 0.0, "avg_logprob": -0.08774424062191861, "compression_ratio": 1.872340425531915, "no_speech_prob": 4.592128846070409e-07}, {"id": 102, "seek": 62956, "start": 641.8, "end": 645.88, "text": " you can see if I shift tab I don't remember if I've shown you this trick before if you", "tokens": [291, 393, 536, 498, 286, 5513, 4421, 286, 500, 380, 1604, 498, 286, 600, 4898, 291, 341, 4282, 949, 498, 291], "temperature": 0.0, "avg_logprob": -0.08774424062191861, "compression_ratio": 1.872340425531915, "no_speech_prob": 4.592128846070409e-07}, {"id": 103, "seek": 62956, "start": 645.88, "end": 651.3199999999999, "text": " go inside the parentheses of a function and hit shift tab a few times it'll pop open a", "tokens": [352, 1854, 264, 34153, 295, 257, 2445, 293, 2045, 5513, 4421, 257, 1326, 1413, 309, 603, 1665, 1269, 257], "temperature": 0.0, "avg_logprob": -0.08774424062191861, "compression_ratio": 1.872340425531915, "no_speech_prob": 4.592128846070409e-07}, {"id": 104, "seek": 62956, "start": 651.3199999999999, "end": 658.2399999999999, "text": " list of all of the arguments and so you can basically see you can say like oh can I sometimes", "tokens": [1329, 295, 439, 295, 264, 12869, 293, 370, 291, 393, 1936, 536, 291, 393, 584, 411, 1954, 393, 286, 2171], "temperature": 0.0, "avg_logprob": -0.08774424062191861, "compression_ratio": 1.872340425531915, "no_speech_prob": 4.592128846070409e-07}, {"id": 105, "seek": 65824, "start": 658.24, "end": 663.04, "text": " flip it left right can I sometimes flip it up down what's the maximum and I can rotate", "tokens": [7929, 309, 1411, 558, 393, 286, 2171, 7929, 309, 493, 760, 437, 311, 264, 6674, 293, 286, 393, 13121], "temperature": 0.0, "avg_logprob": -0.1597850935799735, "compression_ratio": 1.5612244897959184, "no_speech_prob": 2.8130048121965956e-06}, {"id": 106, "seek": 65824, "start": 663.04, "end": 671.16, "text": " zoom change the lighting warp the perspective and so forth.", "tokens": [8863, 1319, 264, 9577, 36030, 264, 4585, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.1597850935799735, "compression_ratio": 1.5612244897959184, "no_speech_prob": 2.8130048121965956e-06}, {"id": 107, "seek": 65824, "start": 671.16, "end": 677.44, "text": " How can we add different augmentations for train and validation sets?", "tokens": [1012, 393, 321, 909, 819, 29919, 763, 337, 3847, 293, 24071, 6352, 30], "temperature": 0.0, "avg_logprob": -0.1597850935799735, "compression_ratio": 1.5612244897959184, "no_speech_prob": 2.8130048121965956e-06}, {"id": 108, "seek": 65824, "start": 677.44, "end": 687.16, "text": " So the cool thing is that automatically fast AI will avoid doing data augmentation on the", "tokens": [407, 264, 1627, 551, 307, 300, 6772, 2370, 7318, 486, 5042, 884, 1412, 14501, 19631, 322, 264], "temperature": 0.0, "avg_logprob": -0.1597850935799735, "compression_ratio": 1.5612244897959184, "no_speech_prob": 2.8130048121965956e-06}, {"id": 109, "seek": 68716, "start": 687.16, "end": 698.24, "text": " validation set so all of these or transforms will only be applied to the training set with", "tokens": [24071, 992, 370, 439, 295, 613, 420, 35592, 486, 787, 312, 6456, 281, 264, 3097, 992, 365], "temperature": 0.0, "avg_logprob": -0.12732200133494842, "compression_ratio": 1.9395604395604396, "no_speech_prob": 4.664441064505809e-07}, {"id": 110, "seek": 68716, "start": 698.24, "end": 703.8399999999999, "text": " the exception of random resize crop random resize crop has a different behavior for each", "tokens": [264, 11183, 295, 4974, 50069, 9086, 4974, 50069, 9086, 575, 257, 819, 5223, 337, 1184], "temperature": 0.0, "avg_logprob": -0.12732200133494842, "compression_ratio": 1.9395604395604396, "no_speech_prob": 4.664441064505809e-07}, {"id": 111, "seek": 68716, "start": 703.8399999999999, "end": 708.0799999999999, "text": " the behavior for the training set is what we just saw which is to randomly pick a subset", "tokens": [264, 5223, 337, 264, 3097, 992, 307, 437, 321, 445, 1866, 597, 307, 281, 16979, 1888, 257, 25993], "temperature": 0.0, "avg_logprob": -0.12732200133494842, "compression_ratio": 1.9395604395604396, "no_speech_prob": 4.664441064505809e-07}, {"id": 112, "seek": 68716, "start": 708.0799999999999, "end": 713.9599999999999, "text": " and kind of zoom into it and the behavior for the validation set is just to grab the", "tokens": [293, 733, 295, 8863, 666, 309, 293, 264, 5223, 337, 264, 24071, 992, 307, 445, 281, 4444, 264], "temperature": 0.0, "avg_logprob": -0.12732200133494842, "compression_ratio": 1.9395604395604396, "no_speech_prob": 4.664441064505809e-07}, {"id": 113, "seek": 71396, "start": 713.96, "end": 721.0, "text": " center the largest center square that it can.", "tokens": [3056, 264, 6443, 3056, 3732, 300, 309, 393, 13], "temperature": 0.0, "avg_logprob": -0.11647038989596897, "compression_ratio": 1.6722689075630253, "no_speech_prob": 5.896408765693195e-07}, {"id": 114, "seek": 71396, "start": 721.0, "end": 725.1600000000001, "text": " You can write your own transformations that they're just Python they're just standard", "tokens": [509, 393, 2464, 428, 1065, 34852, 300, 436, 434, 445, 15329, 436, 434, 445, 3832], "temperature": 0.0, "avg_logprob": -0.11647038989596897, "compression_ratio": 1.6722689075630253, "no_speech_prob": 5.896408765693195e-07}, {"id": 115, "seek": 71396, "start": 725.1600000000001, "end": 731.8000000000001, "text": " pytorch code the way if you and by default it will only be applied to the training set", "tokens": [25878, 284, 339, 3089, 264, 636, 498, 291, 293, 538, 7576, 309, 486, 787, 312, 6456, 281, 264, 3097, 992], "temperature": 0.0, "avg_logprob": -0.11647038989596897, "compression_ratio": 1.6722689075630253, "no_speech_prob": 5.896408765693195e-07}, {"id": 116, "seek": 71396, "start": 731.8000000000001, "end": 735.0, "text": " if you want to do something fancy like random resize crop where you actually have different", "tokens": [498, 291, 528, 281, 360, 746, 10247, 411, 4974, 50069, 9086, 689, 291, 767, 362, 819], "temperature": 0.0, "avg_logprob": -0.11647038989596897, "compression_ratio": 1.6722689075630253, "no_speech_prob": 5.896408765693195e-07}, {"id": 117, "seek": 71396, "start": 735.0, "end": 738.84, "text": " things being applied to each you should come back to the next course to find out how to", "tokens": [721, 885, 6456, 281, 1184, 291, 820, 808, 646, 281, 264, 958, 1164, 281, 915, 484, 577, 281], "temperature": 0.0, "avg_logprob": -0.11647038989596897, "compression_ratio": 1.6722689075630253, "no_speech_prob": 5.896408765693195e-07}, {"id": 118, "seek": 73884, "start": 738.84, "end": 744.64, "text": " do that or read the documentation it's not rocket science but it's not something most", "tokens": [360, 300, 420, 1401, 264, 14333, 309, 311, 406, 13012, 3497, 457, 309, 311, 406, 746, 881], "temperature": 0.0, "avg_logprob": -0.141273683117282, "compression_ratio": 1.6299559471365639, "no_speech_prob": 5.093675554235233e-06}, {"id": 119, "seek": 73884, "start": 744.64, "end": 748.84, "text": " people need to do.", "tokens": [561, 643, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.141273683117282, "compression_ratio": 1.6299559471365639, "no_speech_prob": 5.093675554235233e-06}, {"id": 120, "seek": 73884, "start": 748.84, "end": 758.12, "text": " Okay so last time we we hear bit did bears.new with a random resize crop min scale of 0.5", "tokens": [1033, 370, 1036, 565, 321, 321, 1568, 857, 630, 17276, 13, 7686, 365, 257, 4974, 50069, 9086, 923, 4373, 295, 1958, 13, 20], "temperature": 0.0, "avg_logprob": -0.141273683117282, "compression_ratio": 1.6299559471365639, "no_speech_prob": 5.093675554235233e-06}, {"id": 121, "seek": 73884, "start": 758.12, "end": 763.1, "text": " we added some transforms and we went ahead and trained actually since last week I've", "tokens": [321, 3869, 512, 35592, 293, 321, 1437, 2286, 293, 8895, 767, 1670, 1036, 1243, 286, 600], "temperature": 0.0, "avg_logprob": -0.141273683117282, "compression_ratio": 1.6299559471365639, "no_speech_prob": 5.093675554235233e-06}, {"id": 122, "seek": 73884, "start": 763.1, "end": 766.84, "text": " rerun this notebook I've got it's on a different computer and I've got different images so", "tokens": [43819, 409, 341, 21060, 286, 600, 658, 309, 311, 322, 257, 819, 3820, 293, 286, 600, 658, 819, 5267, 370], "temperature": 0.0, "avg_logprob": -0.141273683117282, "compression_ratio": 1.6299559471365639, "no_speech_prob": 5.093675554235233e-06}, {"id": 123, "seek": 76684, "start": 766.84, "end": 774.96, "text": " it's not all exactly the same but I still got a good confusion matrix so of the black", "tokens": [309, 311, 406, 439, 2293, 264, 912, 457, 286, 920, 658, 257, 665, 15075, 8141, 370, 295, 264, 2211], "temperature": 0.0, "avg_logprob": -0.14451709247770764, "compression_ratio": 1.572093023255814, "no_speech_prob": 1.1544600511115277e-06}, {"id": 124, "seek": 76684, "start": 774.96, "end": 781.32, "text": " bears 37 were classified correctly two were grizzlies of one with a teddy.", "tokens": [17276, 13435, 645, 20627, 8944, 732, 645, 17865, 4313, 24119, 295, 472, 365, 257, 45116, 13], "temperature": 0.0, "avg_logprob": -0.14451709247770764, "compression_ratio": 1.572093023255814, "no_speech_prob": 1.1544600511115277e-06}, {"id": 125, "seek": 76684, "start": 781.32, "end": 787.9200000000001, "text": " Now we talked about plot top losses and it's interesting you can see in this case there's", "tokens": [823, 321, 2825, 466, 7542, 1192, 15352, 293, 309, 311, 1880, 291, 393, 536, 294, 341, 1389, 456, 311], "temperature": 0.0, "avg_logprob": -0.14451709247770764, "compression_ratio": 1.572093023255814, "no_speech_prob": 1.1544600511115277e-06}, {"id": 126, "seek": 76684, "start": 787.9200000000001, "end": 792.6, "text": " some clearly kind of odd things going on this is not a bear at all this looks like it's", "tokens": [512, 4448, 733, 295, 7401, 721, 516, 322, 341, 307, 406, 257, 6155, 412, 439, 341, 1542, 411, 309, 311], "temperature": 0.0, "avg_logprob": -0.14451709247770764, "compression_ratio": 1.572093023255814, "no_speech_prob": 1.1544600511115277e-06}, {"id": 127, "seek": 79260, "start": 792.6, "end": 799.36, "text": " a drawing of a bear which is decided is predicted as a teddy but this thing's meant to be a", "tokens": [257, 6316, 295, 257, 6155, 597, 307, 3047, 307, 19147, 382, 257, 45116, 457, 341, 551, 311, 4140, 281, 312, 257], "temperature": 0.0, "avg_logprob": -0.12994620823624112, "compression_ratio": 1.7020408163265306, "no_speech_prob": 6.893598651913635e-07}, {"id": 128, "seek": 79260, "start": 799.36, "end": 806.28, "text": " drawing of a black bear I can certainly see the confusion you can see how some parts of", "tokens": [6316, 295, 257, 2211, 6155, 286, 393, 3297, 536, 264, 15075, 291, 393, 536, 577, 512, 3166, 295], "temperature": 0.0, "avg_logprob": -0.12994620823624112, "compression_ratio": 1.7020408163265306, "no_speech_prob": 6.893598651913635e-07}, {"id": 129, "seek": 79260, "start": 806.28, "end": 810.8000000000001, "text": " it have been cut off we'll talk about how to deal with that later.", "tokens": [309, 362, 668, 1723, 766, 321, 603, 751, 466, 577, 281, 2028, 365, 300, 1780, 13], "temperature": 0.0, "avg_logprob": -0.12994620823624112, "compression_ratio": 1.7020408163265306, "no_speech_prob": 6.893598651913635e-07}, {"id": 130, "seek": 79260, "start": 810.8000000000001, "end": 816.08, "text": " Now one of the interesting things is that we didn't really do much data cleaning at", "tokens": [823, 472, 295, 264, 1880, 721, 307, 300, 321, 994, 380, 534, 360, 709, 1412, 8924, 412], "temperature": 0.0, "avg_logprob": -0.12994620823624112, "compression_ratio": 1.7020408163265306, "no_speech_prob": 6.893598651913635e-07}, {"id": 131, "seek": 79260, "start": 816.08, "end": 820.5600000000001, "text": " all before we built this model the only data cleaning we did was just to validate that", "tokens": [439, 949, 321, 3094, 341, 2316, 264, 787, 1412, 8924, 321, 630, 390, 445, 281, 29562, 300], "temperature": 0.0, "avg_logprob": -0.12994620823624112, "compression_ratio": 1.7020408163265306, "no_speech_prob": 6.893598651913635e-07}, {"id": 132, "seek": 82056, "start": 820.56, "end": 826.9599999999999, "text": " each image can be opened there was that verify images call and the reason for that is it's", "tokens": [1184, 3256, 393, 312, 5625, 456, 390, 300, 16888, 5267, 818, 293, 264, 1778, 337, 300, 307, 309, 311], "temperature": 0.0, "avg_logprob": -0.08312068446989983, "compression_ratio": 1.6107784431137724, "no_speech_prob": 2.482474201315199e-06}, {"id": 133, "seek": 82056, "start": 826.9599999999999, "end": 831.9599999999999, "text": " actually much easier normally to clean your data after you create a model and I'll show", "tokens": [767, 709, 3571, 5646, 281, 2541, 428, 1412, 934, 291, 1884, 257, 2316, 293, 286, 603, 855], "temperature": 0.0, "avg_logprob": -0.08312068446989983, "compression_ratio": 1.6107784431137724, "no_speech_prob": 2.482474201315199e-06}, {"id": 134, "seek": 82056, "start": 831.9599999999999, "end": 840.1999999999999, "text": " you how we've got this thing called image classifier cleaner where you can pick a category", "tokens": [291, 577, 321, 600, 658, 341, 551, 1219, 3256, 1508, 9902, 16532, 689, 291, 393, 1888, 257, 7719], "temperature": 0.0, "avg_logprob": -0.08312068446989983, "compression_ratio": 1.6107784431137724, "no_speech_prob": 2.482474201315199e-06}, {"id": 135, "seek": 84020, "start": 840.2, "end": 850.72, "text": " right and training set or validation set and then what it will do is it will then list", "tokens": [558, 293, 3097, 992, 420, 24071, 992, 293, 550, 437, 309, 486, 360, 307, 309, 486, 550, 1329], "temperature": 0.0, "avg_logprob": -0.0765888426038954, "compression_ratio": 1.7891156462585034, "no_speech_prob": 9.721522928884951e-07}, {"id": 136, "seek": 84020, "start": 850.72, "end": 860.08, "text": " all of the images in that set and it will pick the ones which are the which is the least", "tokens": [439, 295, 264, 5267, 294, 300, 992, 293, 309, 486, 1888, 264, 2306, 597, 366, 264, 597, 307, 264, 1935], "temperature": 0.0, "avg_logprob": -0.0765888426038954, "compression_ratio": 1.7891156462585034, "no_speech_prob": 9.721522928884951e-07}, {"id": 137, "seek": 84020, "start": 860.08, "end": 866.48, "text": " confident about which the most likely to be wrong where the where the loss is the worst", "tokens": [6679, 466, 597, 264, 881, 3700, 281, 312, 2085, 689, 264, 689, 264, 4470, 307, 264, 5855], "temperature": 0.0, "avg_logprob": -0.0765888426038954, "compression_ratio": 1.7891156462585034, "no_speech_prob": 9.721522928884951e-07}, {"id": 138, "seek": 86648, "start": 866.48, "end": 875.4, "text": " to be more precise and so this this is a great way to look through your data and find problems", "tokens": [281, 312, 544, 13600, 293, 370, 341, 341, 307, 257, 869, 636, 281, 574, 807, 428, 1412, 293, 915, 2740], "temperature": 0.0, "avg_logprob": -0.07266658983732524, "compression_ratio": 1.7009345794392523, "no_speech_prob": 1.1365619911885005e-06}, {"id": 139, "seek": 86648, "start": 875.4, "end": 881.64, "text": " so in this case the first one is not a teddy or a brown bear or a black bear it's a puppy", "tokens": [370, 294, 341, 1389, 264, 700, 472, 307, 406, 257, 45116, 420, 257, 6292, 6155, 420, 257, 2211, 6155, 309, 311, 257, 18196], "temperature": 0.0, "avg_logprob": -0.07266658983732524, "compression_ratio": 1.7009345794392523, "no_speech_prob": 1.1365619911885005e-06}, {"id": 140, "seek": 86648, "start": 881.64, "end": 888.4, "text": " dog right so this is a great cleaner because what I can do is I can now click delete here", "tokens": [3000, 558, 370, 341, 307, 257, 869, 16532, 570, 437, 286, 393, 360, 307, 286, 393, 586, 2052, 12097, 510], "temperature": 0.0, "avg_logprob": -0.07266658983732524, "compression_ratio": 1.7009345794392523, "no_speech_prob": 1.1365619911885005e-06}, {"id": 141, "seek": 86648, "start": 888.4, "end": 892.4, "text": " this one here looks a bit like an Ewok rather than a teddy I'm not sure what do you think", "tokens": [341, 472, 510, 1542, 257, 857, 411, 364, 28101, 453, 2831, 813, 257, 45116, 286, 478, 406, 988, 437, 360, 291, 519], "temperature": 0.0, "avg_logprob": -0.07266658983732524, "compression_ratio": 1.7009345794392523, "no_speech_prob": 1.1365619911885005e-06}, {"id": 142, "seek": 89240, "start": 892.4, "end": 898.72, "text": " Rachel is an Ewok I'm gonna call it an Ewok right and so you can kind of go through okay", "tokens": [14246, 307, 364, 28101, 453, 286, 478, 799, 818, 309, 364, 28101, 453, 558, 293, 370, 291, 393, 733, 295, 352, 807, 1392], "temperature": 0.0, "avg_logprob": -0.07014793004745092, "compression_ratio": 1.8429752066115703, "no_speech_prob": 9.368643986817915e-06}, {"id": 143, "seek": 89240, "start": 898.72, "end": 903.6, "text": " that's definitely not a teddy and so you can either say like oh that's wrong that's actually", "tokens": [300, 311, 2138, 406, 257, 45116, 293, 370, 291, 393, 2139, 584, 411, 1954, 300, 311, 2085, 300, 311, 767], "temperature": 0.0, "avg_logprob": -0.07014793004745092, "compression_ratio": 1.8429752066115703, "no_speech_prob": 9.368643986817915e-06}, {"id": 144, "seek": 89240, "start": 903.6, "end": 907.76, "text": " a grizzly bear or it's wrong it's a black bear or I should delete it or by default just", "tokens": [257, 17865, 4313, 356, 6155, 420, 309, 311, 2085, 309, 311, 257, 2211, 6155, 420, 286, 820, 12097, 309, 420, 538, 7576, 445], "temperature": 0.0, "avg_logprob": -0.07014793004745092, "compression_ratio": 1.8429752066115703, "no_speech_prob": 9.368643986817915e-06}, {"id": 145, "seek": 89240, "start": 907.76, "end": 911.6, "text": " keep it right and you can kind of keep going through until you think like okay they're", "tokens": [1066, 309, 558, 293, 291, 393, 733, 295, 1066, 516, 807, 1826, 291, 519, 411, 1392, 436, 434], "temperature": 0.0, "avg_logprob": -0.07014793004745092, "compression_ratio": 1.8429752066115703, "no_speech_prob": 9.368643986817915e-06}, {"id": 146, "seek": 89240, "start": 911.6, "end": 919.92, "text": " all seem to be fine maybe that one's not and kind of once you get to the point where they", "tokens": [439, 1643, 281, 312, 2489, 1310, 300, 472, 311, 406, 293, 733, 295, 1564, 291, 483, 281, 264, 935, 689, 436], "temperature": 0.0, "avg_logprob": -0.07014793004745092, "compression_ratio": 1.8429752066115703, "no_speech_prob": 9.368643986817915e-06}, {"id": 147, "seek": 91992, "start": 919.92, "end": 924.5999999999999, "text": " all seem to be fine you can kind of say okay probably all the rest are fine too because", "tokens": [439, 1643, 281, 312, 2489, 291, 393, 733, 295, 584, 1392, 1391, 439, 264, 1472, 366, 2489, 886, 570], "temperature": 0.0, "avg_logprob": -0.10359972017305391, "compression_ratio": 1.85, "no_speech_prob": 5.804997158520564e-07}, {"id": 148, "seek": 91992, "start": 924.5999999999999, "end": 929.64, "text": " they all have lower losses so they all fit the kind of the mold of a teddy and so then", "tokens": [436, 439, 362, 3126, 15352, 370, 436, 439, 3318, 264, 733, 295, 264, 11102, 295, 257, 45116, 293, 370, 550], "temperature": 0.0, "avg_logprob": -0.10359972017305391, "compression_ratio": 1.85, "no_speech_prob": 5.804997158520564e-07}, {"id": 149, "seek": 91992, "start": 929.64, "end": 936.16, "text": " I can run this code here where I just go through cleaner.delete so that's all the things which", "tokens": [286, 393, 1190, 341, 3089, 510, 689, 286, 445, 352, 807, 16532, 13, 18105, 3498, 370, 300, 311, 439, 264, 721, 597], "temperature": 0.0, "avg_logprob": -0.10359972017305391, "compression_ratio": 1.85, "no_speech_prob": 5.804997158520564e-07}, {"id": 150, "seek": 91992, "start": 936.16, "end": 944.7199999999999, "text": " I selected to delete for and unlink them so unlink is just another way of saying delete", "tokens": [286, 8209, 281, 12097, 337, 293, 517, 22473, 552, 370, 517, 22473, 307, 445, 1071, 636, 295, 1566, 12097], "temperature": 0.0, "avg_logprob": -0.10359972017305391, "compression_ratio": 1.85, "no_speech_prob": 5.804997158520564e-07}, {"id": 151, "seek": 91992, "start": 944.7199999999999, "end": 949.52, "text": " a file that's the Python name and then go through all the ones that we said change and", "tokens": [257, 3991, 300, 311, 264, 15329, 1315, 293, 550, 352, 807, 439, 264, 2306, 300, 321, 848, 1319, 293], "temperature": 0.0, "avg_logprob": -0.10359972017305391, "compression_ratio": 1.85, "no_speech_prob": 5.804997158520564e-07}, {"id": 152, "seek": 94952, "start": 949.52, "end": 956.3199999999999, "text": " we can actually move them to the correct directory.", "tokens": [321, 393, 767, 1286, 552, 281, 264, 3006, 21120, 13], "temperature": 0.0, "avg_logprob": -0.2013121287027995, "compression_ratio": 1.592760180995475, "no_speech_prob": 3.1561228297505295e-07}, {"id": 153, "seek": 94952, "start": 956.3199999999999, "end": 959.1999999999999, "text": " If you haven't seen this before you might be surprised that we've kind of created our", "tokens": [759, 291, 2378, 380, 1612, 341, 949, 291, 1062, 312, 6100, 300, 321, 600, 733, 295, 2942, 527], "temperature": 0.0, "avg_logprob": -0.2013121287027995, "compression_ratio": 1.592760180995475, "no_speech_prob": 3.1561228297505295e-07}, {"id": 154, "seek": 94952, "start": 959.1999999999999, "end": 964.96, "text": " own little GUI inside Jupyter Notebook.", "tokens": [1065, 707, 17917, 40, 1854, 22125, 88, 391, 11633, 2939, 13], "temperature": 0.0, "avg_logprob": -0.2013121287027995, "compression_ratio": 1.592760180995475, "no_speech_prob": 3.1561228297505295e-07}, {"id": 155, "seek": 94952, "start": 964.96, "end": 970.24, "text": " Yeah you can do this and we built this with less than a screen of code you can check out", "tokens": [865, 291, 393, 360, 341, 293, 321, 3094, 341, 365, 1570, 813, 257, 2568, 295, 3089, 291, 393, 1520, 484], "temperature": 0.0, "avg_logprob": -0.2013121287027995, "compression_ratio": 1.592760180995475, "no_speech_prob": 3.1561228297505295e-07}, {"id": 156, "seek": 94952, "start": 970.24, "end": 979.04, "text": " the source code in the fastai notebooks so this is a great time to remind you that if", "tokens": [264, 4009, 3089, 294, 264, 2370, 1301, 43782, 370, 341, 307, 257, 869, 565, 281, 4160, 291, 300, 498], "temperature": 0.0, "avg_logprob": -0.2013121287027995, "compression_ratio": 1.592760180995475, "no_speech_prob": 3.1561228297505295e-07}, {"id": 157, "seek": 97904, "start": 979.04, "end": 995.56, "text": " you go to the fastai repo and clone it and then go to nb's you'll find all of the code", "tokens": [291, 352, 281, 264, 2370, 1301, 49040, 293, 26506, 309, 293, 550, 352, 281, 297, 65, 311, 291, 603, 915, 439, 295, 264, 3089], "temperature": 0.0, "avg_logprob": -0.14567536723857022, "compression_ratio": 1.5263157894736843, "no_speech_prob": 1.1726397133315913e-06}, {"id": 158, "seek": 97904, "start": 995.56, "end": 1003.1999999999999, "text": " of fastai written as notebooks and they've got a lot of pros and examples and tests and", "tokens": [295, 2370, 1301, 3720, 382, 43782, 293, 436, 600, 658, 257, 688, 295, 6267, 293, 5110, 293, 6921, 293], "temperature": 0.0, "avg_logprob": -0.14567536723857022, "compression_ratio": 1.5263157894736843, "no_speech_prob": 1.1726397133315913e-06}, {"id": 159, "seek": 100320, "start": 1003.2, "end": 1009.0600000000001, "text": " so forth so the best place to learn about how this is implemented is to look at the", "tokens": [370, 5220, 370, 264, 1151, 1081, 281, 1466, 466, 577, 341, 307, 12270, 307, 281, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.14051426320836163, "compression_ratio": 1.6378378378378378, "no_speech_prob": 1.4823549463471863e-06}, {"id": 160, "seek": 100320, "start": 1009.0600000000001, "end": 1016.76, "text": " notebooks rather than looking at the module.", "tokens": [43782, 2831, 813, 1237, 412, 264, 10088, 13], "temperature": 0.0, "avg_logprob": -0.14051426320836163, "compression_ratio": 1.6378378378378378, "no_speech_prob": 1.4823549463471863e-06}, {"id": 161, "seek": 100320, "start": 1016.76, "end": 1023.88, "text": " Okay by the way sometimes you'll see like weird little comments like this these weird", "tokens": [1033, 538, 264, 636, 2171, 291, 603, 536, 411, 3657, 707, 3053, 411, 341, 613, 3657], "temperature": 0.0, "avg_logprob": -0.14051426320836163, "compression_ratio": 1.6378378378378378, "no_speech_prob": 1.4823549463471863e-06}, {"id": 162, "seek": 100320, "start": 1023.88, "end": 1027.52, "text": " little comments are part of a development environment for Jupyter Notebook we use called", "tokens": [707, 3053, 366, 644, 295, 257, 3250, 2823, 337, 22125, 88, 391, 11633, 2939, 321, 764, 1219], "temperature": 0.0, "avg_logprob": -0.14051426320836163, "compression_ratio": 1.6378378378378378, "no_speech_prob": 1.4823549463471863e-06}, {"id": 163, "seek": 102752, "start": 1027.52, "end": 1033.56, "text": " nbdev which we built so Silver and I built this thing to make it much easier for us to", "tokens": [297, 65, 40343, 597, 321, 3094, 370, 15861, 293, 286, 3094, 341, 551, 281, 652, 309, 709, 3571, 337, 505, 281], "temperature": 0.0, "avg_logprob": -0.1151614410932674, "compression_ratio": 1.5990990990990992, "no_speech_prob": 2.7264582058705855e-06}, {"id": 164, "seek": 102752, "start": 1033.56, "end": 1041.08, "text": " kind of create books and websites and libraries in Jupyter Notebooks so this particular one", "tokens": [733, 295, 1884, 3642, 293, 12891, 293, 15148, 294, 22125, 88, 391, 11633, 15170, 370, 341, 1729, 472], "temperature": 0.0, "avg_logprob": -0.1151614410932674, "compression_ratio": 1.5990990990990992, "no_speech_prob": 2.7264582058705855e-06}, {"id": 165, "seek": 102752, "start": 1041.08, "end": 1048.48, "text": " here hide means when this is turned into a book or into documentation don't show this", "tokens": [510, 6479, 1355, 562, 341, 307, 3574, 666, 257, 1446, 420, 666, 14333, 500, 380, 855, 341], "temperature": 0.0, "avg_logprob": -0.1151614410932674, "compression_ratio": 1.5990990990990992, "no_speech_prob": 2.7264582058705855e-06}, {"id": 166, "seek": 102752, "start": 1048.48, "end": 1053.12, "text": " cell and the reason for that is because you can see I've actually got it in the text right", "tokens": [2815, 293, 264, 1778, 337, 300, 307, 570, 291, 393, 536, 286, 600, 767, 658, 309, 294, 264, 2487, 558], "temperature": 0.0, "avg_logprob": -0.1151614410932674, "compression_ratio": 1.5990990990990992, "no_speech_prob": 2.7264582058705855e-06}, {"id": 167, "seek": 105312, "start": 1053.12, "end": 1057.6, "text": " but I thought when you're actually running it it would be nice to have it sitting here", "tokens": [457, 286, 1194, 562, 291, 434, 767, 2614, 309, 309, 576, 312, 1481, 281, 362, 309, 3798, 510], "temperature": 0.0, "avg_logprob": -0.09840614390823077, "compression_ratio": 1.8297872340425532, "no_speech_prob": 5.507513833435951e-06}, {"id": 168, "seek": 105312, "start": 1057.6, "end": 1062.7199999999998, "text": " waiting for you to run directly so that's why it's shown in the notebook but not in", "tokens": [3806, 337, 291, 281, 1190, 3838, 370, 300, 311, 983, 309, 311, 4898, 294, 264, 21060, 457, 406, 294], "temperature": 0.0, "avg_logprob": -0.09840614390823077, "compression_ratio": 1.8297872340425532, "no_speech_prob": 5.507513833435951e-06}, {"id": 169, "seek": 105312, "start": 1062.7199999999998, "end": 1068.7199999999998, "text": " the in the book it's shown differently and you'll also see these things like s colon", "tokens": [264, 294, 264, 1446, 309, 311, 4898, 7614, 293, 291, 603, 611, 536, 613, 721, 411, 262, 8255], "temperature": 0.0, "avg_logprob": -0.09840614390823077, "compression_ratio": 1.8297872340425532, "no_speech_prob": 5.507513833435951e-06}, {"id": 170, "seek": 105312, "start": 1068.7199999999998, "end": 1073.84, "text": " with a quote in the book that would end up saying Sylvain says and then what he says", "tokens": [365, 257, 6513, 294, 264, 1446, 300, 576, 917, 493, 1566, 3902, 14574, 491, 1619, 293, 550, 437, 415, 1619], "temperature": 0.0, "avg_logprob": -0.09840614390823077, "compression_ratio": 1.8297872340425532, "no_speech_prob": 5.507513833435951e-06}, {"id": 171, "seek": 105312, "start": 1073.84, "end": 1078.28, "text": " so there's kind of little bits and pieces in the in the notebooks that just look a little", "tokens": [370, 456, 311, 733, 295, 707, 9239, 293, 3755, 294, 264, 294, 264, 43782, 300, 445, 574, 257, 707], "temperature": 0.0, "avg_logprob": -0.09840614390823077, "compression_ratio": 1.8297872340425532, "no_speech_prob": 5.507513833435951e-06}, {"id": 172, "seek": 107828, "start": 1078.28, "end": 1084.36, "text": " bit odd and that's because it's designed that way in order to show in order to create stuff", "tokens": [857, 7401, 293, 300, 311, 570, 309, 311, 4761, 300, 636, 294, 1668, 281, 855, 294, 1668, 281, 1884, 1507], "temperature": 0.0, "avg_logprob": -0.11630926132202149, "compression_ratio": 1.7083333333333333, "no_speech_prob": 6.375536827363248e-07}, {"id": 173, "seek": 107828, "start": 1084.36, "end": 1086.84, "text": " in the book.", "tokens": [294, 264, 1446, 13], "temperature": 0.0, "avg_logprob": -0.11630926132202149, "compression_ratio": 1.7083333333333333, "no_speech_prob": 6.375536827363248e-07}, {"id": 174, "seek": 107828, "start": 1086.84, "end": 1092.66, "text": " Right so then last week we saw how you can export that to a pickle file that contains", "tokens": [1779, 370, 550, 1036, 1243, 321, 1866, 577, 291, 393, 10725, 300, 281, 257, 31433, 3991, 300, 8306], "temperature": 0.0, "avg_logprob": -0.11630926132202149, "compression_ratio": 1.7083333333333333, "no_speech_prob": 6.375536827363248e-07}, {"id": 175, "seek": 107828, "start": 1092.66, "end": 1097.76, "text": " all the information for the model and then on the server where you're going to actually", "tokens": [439, 264, 1589, 337, 264, 2316, 293, 550, 322, 264, 7154, 689, 291, 434, 516, 281, 767], "temperature": 0.0, "avg_logprob": -0.11630926132202149, "compression_ratio": 1.7083333333333333, "no_speech_prob": 6.375536827363248e-07}, {"id": 176, "seek": 107828, "start": 1097.76, "end": 1102.84, "text": " do your inference you can then load that saved file and you'll get back a learner that you", "tokens": [360, 428, 38253, 291, 393, 550, 3677, 300, 6624, 3991, 293, 291, 603, 483, 646, 257, 33347, 300, 291], "temperature": 0.0, "avg_logprob": -0.11630926132202149, "compression_ratio": 1.7083333333333333, "no_speech_prob": 6.375536827363248e-07}, {"id": 177, "seek": 110284, "start": 1102.84, "end": 1113.1599999999999, "text": " can call predict on so predict perhaps the most interesting part of predict is the third", "tokens": [393, 818, 6069, 322, 370, 6069, 4317, 264, 881, 1880, 644, 295, 6069, 307, 264, 2636], "temperature": 0.0, "avg_logprob": -0.09899081939306015, "compression_ratio": 1.745, "no_speech_prob": 1.3287744877743535e-06}, {"id": 178, "seek": 110284, "start": 1113.1599999999999, "end": 1120.24, "text": " thing that it returns which is a tensor in this case containing three numbers the three", "tokens": [551, 300, 309, 11247, 597, 307, 257, 40863, 294, 341, 1389, 19273, 1045, 3547, 264, 1045], "temperature": 0.0, "avg_logprob": -0.09899081939306015, "compression_ratio": 1.745, "no_speech_prob": 1.3287744877743535e-06}, {"id": 179, "seek": 110284, "start": 1120.24, "end": 1125.1999999999998, "text": " numbers there's three of them because we have three classes teddy bear grizzly bear and", "tokens": [3547, 456, 311, 1045, 295, 552, 570, 321, 362, 1045, 5359, 45116, 6155, 17865, 4313, 356, 6155, 293], "temperature": 0.0, "avg_logprob": -0.09899081939306015, "compression_ratio": 1.745, "no_speech_prob": 1.3287744877743535e-06}, {"id": 180, "seek": 110284, "start": 1125.1999999999998, "end": 1132.4399999999998, "text": " black bear right and so this doesn't make any sense until you know what the order of", "tokens": [2211, 6155, 558, 293, 370, 341, 1177, 380, 652, 604, 2020, 1826, 291, 458, 437, 264, 1668, 295], "temperature": 0.0, "avg_logprob": -0.09899081939306015, "compression_ratio": 1.745, "no_speech_prob": 1.3287744877743535e-06}, {"id": 181, "seek": 113244, "start": 1132.44, "end": 1140.52, "text": " the classes is kind of in in in your data loaders and you can ask the data loaders what", "tokens": [264, 5359, 307, 733, 295, 294, 294, 294, 428, 1412, 3677, 433, 293, 291, 393, 1029, 264, 1412, 3677, 433, 437], "temperature": 0.0, "avg_logprob": -0.10711966542636647, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.690361485401809e-07}, {"id": 182, "seek": 113244, "start": 1140.52, "end": 1146.68, "text": " the order is by asking for its vocab so a vocab in fast AI is a really common concept", "tokens": [264, 1668, 307, 538, 3365, 337, 1080, 2329, 455, 370, 257, 2329, 455, 294, 2370, 7318, 307, 257, 534, 2689, 3410], "temperature": 0.0, "avg_logprob": -0.10711966542636647, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.690361485401809e-07}, {"id": 183, "seek": 113244, "start": 1146.68, "end": 1153.68, "text": " it's basically any time that you've got like a mapping from numbers to strings or discrete", "tokens": [309, 311, 1936, 604, 565, 300, 291, 600, 658, 411, 257, 18350, 490, 3547, 281, 13985, 420, 27706], "temperature": 0.0, "avg_logprob": -0.10711966542636647, "compression_ratio": 1.5714285714285714, "no_speech_prob": 7.690361485401809e-07}, {"id": 184, "seek": 115368, "start": 1153.68, "end": 1163.52, "text": " levels, the mapping is always stored in the vocab so here this shows us that the the activation", "tokens": [4358, 11, 264, 18350, 307, 1009, 12187, 294, 264, 2329, 455, 370, 510, 341, 3110, 505, 300, 264, 264, 24433], "temperature": 0.0, "avg_logprob": -0.18581370089916474, "compression_ratio": 1.5546218487394958, "no_speech_prob": 9.276337777919252e-07}, {"id": 185, "seek": 115368, "start": 1163.52, "end": 1175.16, "text": " for black bear is 10 a neg 6 the activation for grizzly is 1 and the activation for teddy", "tokens": [337, 2211, 6155, 307, 1266, 257, 2485, 1386, 264, 24433, 337, 17865, 4313, 356, 307, 502, 293, 264, 24433, 337, 45116], "temperature": 0.0, "avg_logprob": -0.18581370089916474, "compression_ratio": 1.5546218487394958, "no_speech_prob": 9.276337777919252e-07}, {"id": 186, "seek": 117516, "start": 1175.16, "end": 1186.28, "text": " is 10 a neg 6 so very very confident that this particular one it was a grizzly not surprisingly", "tokens": [307, 1266, 257, 2485, 1386, 370, 588, 588, 6679, 300, 341, 1729, 472, 309, 390, 257, 17865, 4313, 356, 406, 17600], "temperature": 0.0, "avg_logprob": -0.09841634939005087, "compression_ratio": 1.6839622641509433, "no_speech_prob": 1.9750524415940163e-07}, {"id": 187, "seek": 117516, "start": 1186.28, "end": 1196.2, "text": " this was something called grizzly.jpg so you need to kind of know this this mapping in", "tokens": [341, 390, 746, 1219, 17865, 4313, 356, 13, 73, 49861, 370, 291, 643, 281, 733, 295, 458, 341, 341, 18350, 294], "temperature": 0.0, "avg_logprob": -0.09841634939005087, "compression_ratio": 1.6839622641509433, "no_speech_prob": 1.9750524415940163e-07}, {"id": 188, "seek": 117516, "start": 1196.2, "end": 1199.8400000000001, "text": " order to display the correct thing but of course the data loaders object already knows", "tokens": [1668, 281, 4674, 264, 3006, 551, 457, 295, 1164, 264, 1412, 3677, 433, 2657, 1217, 3255], "temperature": 0.0, "avg_logprob": -0.09841634939005087, "compression_ratio": 1.6839622641509433, "no_speech_prob": 1.9750524415940163e-07}, {"id": 189, "seek": 117516, "start": 1199.8400000000001, "end": 1204.96, "text": " that mapping and it's all the vocab and it's stored in with the loader so that's how it", "tokens": [300, 18350, 293, 309, 311, 439, 264, 2329, 455, 293, 309, 311, 12187, 294, 365, 264, 3677, 260, 370, 300, 311, 577, 309], "temperature": 0.0, "avg_logprob": -0.09841634939005087, "compression_ratio": 1.6839622641509433, "no_speech_prob": 1.9750524415940163e-07}, {"id": 190, "seek": 120496, "start": 1204.96, "end": 1208.96, "text": " knows to say grizzly automatically so the first thing it gives you is the the human", "tokens": [3255, 281, 584, 17865, 4313, 356, 6772, 370, 264, 700, 551, 309, 2709, 291, 307, 264, 264, 1952], "temperature": 0.0, "avg_logprob": -0.12625642923208383, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.179384968163504e-07}, {"id": 191, "seek": 120496, "start": 1208.96, "end": 1214.52, "text": " readable string that you'd want to display so this is kind of nice that with fast AI", "tokens": [49857, 6798, 300, 291, 1116, 528, 281, 4674, 370, 341, 307, 733, 295, 1481, 300, 365, 2370, 7318], "temperature": 0.0, "avg_logprob": -0.12625642923208383, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.179384968163504e-07}, {"id": 192, "seek": 120496, "start": 1214.52, "end": 1219.96, "text": " too you you save this object which has everything you need for inference it's got all the you", "tokens": [886, 291, 291, 3155, 341, 2657, 597, 575, 1203, 291, 643, 337, 38253, 309, 311, 658, 439, 264, 291], "temperature": 0.0, "avg_logprob": -0.12625642923208383, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.179384968163504e-07}, {"id": 193, "seek": 120496, "start": 1219.96, "end": 1225.68, "text": " know information about normalization about any kind of transformation steps about what", "tokens": [458, 1589, 466, 2710, 2144, 466, 604, 733, 295, 9887, 4439, 466, 437], "temperature": 0.0, "avg_logprob": -0.12625642923208383, "compression_ratio": 1.6778846153846154, "no_speech_prob": 6.179384968163504e-07}, {"id": 194, "seek": 122568, "start": 1225.68, "end": 1236.4, "text": " the vocab is so it can display everything correctly right so now we want to deploy this", "tokens": [264, 2329, 455, 307, 370, 309, 393, 4674, 1203, 8944, 558, 370, 586, 321, 528, 281, 7274, 341], "temperature": 0.0, "avg_logprob": -0.0511356509009073, "compression_ratio": 1.8842105263157896, "no_speech_prob": 8.315268473779724e-07}, {"id": 195, "seek": 122568, "start": 1236.4, "end": 1244.44, "text": " as an app now if you've done some web programming before then all you need to know is that this", "tokens": [382, 364, 724, 586, 498, 291, 600, 1096, 512, 3670, 9410, 949, 550, 439, 291, 643, 281, 458, 307, 300, 341], "temperature": 0.0, "avg_logprob": -0.0511356509009073, "compression_ratio": 1.8842105263157896, "no_speech_prob": 8.315268473779724e-07}, {"id": 196, "seek": 122568, "start": 1244.44, "end": 1249.6000000000001, "text": " line of code and this line of code so this is the line of code you would call once when", "tokens": [1622, 295, 3089, 293, 341, 1622, 295, 3089, 370, 341, 307, 264, 1622, 295, 3089, 291, 576, 818, 1564, 562], "temperature": 0.0, "avg_logprob": -0.0511356509009073, "compression_ratio": 1.8842105263157896, "no_speech_prob": 8.315268473779724e-07}, {"id": 197, "seek": 122568, "start": 1249.6000000000001, "end": 1254.42, "text": " your application starts up and then this is the line of code you would call every time", "tokens": [428, 3861, 3719, 493, 293, 550, 341, 307, 264, 1622, 295, 3089, 291, 576, 818, 633, 565], "temperature": 0.0, "avg_logprob": -0.0511356509009073, "compression_ratio": 1.8842105263157896, "no_speech_prob": 8.315268473779724e-07}, {"id": 198, "seek": 125442, "start": 1254.42, "end": 1258.24, "text": " you want to do an inference and there's also a batch version of it which you can lock up", "tokens": [291, 528, 281, 360, 364, 38253, 293, 456, 311, 611, 257, 15245, 3037, 295, 309, 597, 291, 393, 4017, 493], "temperature": 0.0, "avg_logprob": -0.13799765503522263, "compression_ratio": 1.7983539094650205, "no_speech_prob": 8.186343052329903e-07}, {"id": 199, "seek": 125442, "start": 1258.24, "end": 1265.68, "text": " if you're interested this is just a one at a time so there's nothing special if you're", "tokens": [498, 291, 434, 3102, 341, 307, 445, 257, 472, 412, 257, 565, 370, 456, 311, 1825, 2121, 498, 291, 434], "temperature": 0.0, "avg_logprob": -0.13799765503522263, "compression_ratio": 1.7983539094650205, "no_speech_prob": 8.186343052329903e-07}, {"id": 200, "seek": 125442, "start": 1265.68, "end": 1270.16, "text": " already a web programmer or have access to a web programmer these are you know you just", "tokens": [1217, 257, 3670, 32116, 420, 362, 2105, 281, 257, 3670, 32116, 613, 366, 291, 458, 291, 445], "temperature": 0.0, "avg_logprob": -0.13799765503522263, "compression_ratio": 1.7983539094650205, "no_speech_prob": 8.186343052329903e-07}, {"id": 201, "seek": 125442, "start": 1270.16, "end": 1275.0800000000002, "text": " have to stick these two lines of code somewhere and the three things you get back are the", "tokens": [362, 281, 2897, 613, 732, 3876, 295, 3089, 4079, 293, 264, 1045, 721, 291, 483, 646, 366, 264], "temperature": 0.0, "avg_logprob": -0.13799765503522263, "compression_ratio": 1.7983539094650205, "no_speech_prob": 8.186343052329903e-07}, {"id": 202, "seek": 125442, "start": 1275.0800000000002, "end": 1279.76, "text": " the human readable string if you're doing categorization the index of that which in", "tokens": [264, 1952, 49857, 6798, 498, 291, 434, 884, 19250, 2144, 264, 8186, 295, 300, 597, 294], "temperature": 0.0, "avg_logprob": -0.13799765503522263, "compression_ratio": 1.7983539094650205, "no_speech_prob": 8.186343052329903e-07}, {"id": 203, "seek": 127976, "start": 1279.76, "end": 1286.04, "text": " this case is one who's grizzly and the probability of each class one of the things we really", "tokens": [341, 1389, 307, 472, 567, 311, 17865, 4313, 356, 293, 264, 8482, 295, 1184, 1508, 472, 295, 264, 721, 321, 534], "temperature": 0.0, "avg_logprob": -0.09321434681232159, "compression_ratio": 1.745019920318725, "no_speech_prob": 1.5294111790353782e-06}, {"id": 204, "seek": 127976, "start": 1286.04, "end": 1292.44, "text": " wanted to do in this course though is not assume that everybody is a web developer most", "tokens": [1415, 281, 360, 294, 341, 1164, 1673, 307, 406, 6552, 300, 2201, 307, 257, 3670, 10754, 881], "temperature": 0.0, "avg_logprob": -0.09321434681232159, "compression_ratio": 1.745019920318725, "no_speech_prob": 1.5294111790353782e-06}, {"id": 205, "seek": 127976, "start": 1292.44, "end": 1297.16, "text": " data scientists aren't but gee wouldn't it be great if all data scientists could at least", "tokens": [1412, 7708, 3212, 380, 457, 24105, 2759, 380, 309, 312, 869, 498, 439, 1412, 7708, 727, 412, 1935], "temperature": 0.0, "avg_logprob": -0.09321434681232159, "compression_ratio": 1.745019920318725, "no_speech_prob": 1.5294111790353782e-06}, {"id": 206, "seek": 127976, "start": 1297.16, "end": 1304.12, "text": " like prototype an application to show off the thing they're working on and so we've", "tokens": [411, 19475, 364, 3861, 281, 855, 766, 264, 551, 436, 434, 1364, 322, 293, 370, 321, 600], "temperature": 0.0, "avg_logprob": -0.09321434681232159, "compression_ratio": 1.745019920318725, "no_speech_prob": 1.5294111790353782e-06}, {"id": 207, "seek": 127976, "start": 1304.12, "end": 1308.12, "text": " tried to kind of curate an approach which none of its stuff we've built it's really", "tokens": [3031, 281, 733, 295, 1262, 473, 364, 3109, 597, 6022, 295, 1080, 1507, 321, 600, 3094, 309, 311, 534], "temperature": 0.0, "avg_logprob": -0.09321434681232159, "compression_ratio": 1.745019920318725, "no_speech_prob": 1.5294111790353782e-06}, {"id": 208, "seek": 130812, "start": 1308.12, "end": 1315.7199999999998, "text": " just curated which shows how you can create a GUI and create a complete application in", "tokens": [445, 47851, 597, 3110, 577, 291, 393, 1884, 257, 17917, 40, 293, 1884, 257, 3566, 3861, 294], "temperature": 0.0, "avg_logprob": -0.1520132798414964, "compression_ratio": 1.5491329479768785, "no_speech_prob": 1.6536866951355478e-06}, {"id": 209, "seek": 130812, "start": 1315.7199999999998, "end": 1324.9199999999998, "text": " Jupyter Notebook so the key pieces of technology we use to do this are IPython widgets which", "tokens": [22125, 88, 391, 11633, 2939, 370, 264, 2141, 3755, 295, 2899, 321, 764, 281, 360, 341, 366, 8671, 88, 11943, 43355, 597], "temperature": 0.0, "avg_logprob": -0.1520132798414964, "compression_ratio": 1.5491329479768785, "no_speech_prob": 1.6536866951355478e-06}, {"id": 210, "seek": 130812, "start": 1324.9199999999998, "end": 1332.56, "text": " is always called IPy widgets and voila IPy widgets which we import by default as widgets", "tokens": [307, 1009, 1219, 8671, 88, 43355, 293, 45565, 8671, 88, 43355, 597, 321, 974, 538, 7576, 382, 43355], "temperature": 0.0, "avg_logprob": -0.1520132798414964, "compression_ratio": 1.5491329479768785, "no_speech_prob": 1.6536866951355478e-06}, {"id": 211, "seek": 133256, "start": 1332.56, "end": 1338.32, "text": " and that's also what they use in their own documentation as GUI widgets for example a", "tokens": [293, 300, 311, 611, 437, 436, 764, 294, 641, 1065, 14333, 382, 17917, 40, 43355, 337, 1365, 257], "temperature": 0.0, "avg_logprob": -0.08570474736830767, "compression_ratio": 1.6763285024154588, "no_speech_prob": 1.2289162896195194e-06}, {"id": 212, "seek": 133256, "start": 1338.32, "end": 1346.72, "text": " file upload button so if I create this file upload button and then display it I see and", "tokens": [3991, 6580, 2960, 370, 498, 286, 1884, 341, 3991, 6580, 2960, 293, 550, 4674, 309, 286, 536, 293], "temperature": 0.0, "avg_logprob": -0.08570474736830767, "compression_ratio": 1.6763285024154588, "no_speech_prob": 1.2289162896195194e-06}, {"id": 213, "seek": 133256, "start": 1346.72, "end": 1350.24, "text": " we saw this in the last lesson as well or maybe it was less than one an actual clickable", "tokens": [321, 1866, 341, 294, 264, 1036, 6898, 382, 731, 420, 1310, 309, 390, 1570, 813, 472, 364, 3539, 2052, 712], "temperature": 0.0, "avg_logprob": -0.08570474736830767, "compression_ratio": 1.6763285024154588, "no_speech_prob": 1.2289162896195194e-06}, {"id": 214, "seek": 133256, "start": 1350.24, "end": 1361.48, "text": " button so I can go ahead and click it and it says now okay you've selected one thing", "tokens": [2960, 370, 286, 393, 352, 2286, 293, 2052, 309, 293, 309, 1619, 586, 1392, 291, 600, 8209, 472, 551], "temperature": 0.0, "avg_logprob": -0.08570474736830767, "compression_ratio": 1.6763285024154588, "no_speech_prob": 1.2289162896195194e-06}, {"id": 215, "seek": 136148, "start": 1361.48, "end": 1372.32, "text": " so how do I use that well these well these widgets have all kinds of methods and properties", "tokens": [370, 577, 360, 286, 764, 300, 731, 613, 731, 613, 43355, 362, 439, 3685, 295, 7150, 293, 7221], "temperature": 0.0, "avg_logprob": -0.1046995222568512, "compression_ratio": 1.69375, "no_speech_prob": 5.896403081351309e-07}, {"id": 216, "seek": 136148, "start": 1372.32, "end": 1379.0, "text": " and the upload button has a data property which is an array containing all of the images", "tokens": [293, 264, 6580, 2960, 575, 257, 1412, 4707, 597, 307, 364, 10225, 19273, 439, 295, 264, 5267], "temperature": 0.0, "avg_logprob": -0.1046995222568512, "compression_ratio": 1.69375, "no_speech_prob": 5.896403081351309e-07}, {"id": 217, "seek": 136148, "start": 1379.0, "end": 1386.96, "text": " you uploaded so you can pass that to PIO image dot create and so dot create is kind of the", "tokens": [291, 17135, 370, 291, 393, 1320, 300, 281, 430, 15167, 3256, 5893, 1884, 293, 370, 5893, 1884, 307, 733, 295, 264], "temperature": 0.0, "avg_logprob": -0.1046995222568512, "compression_ratio": 1.69375, "no_speech_prob": 5.896403081351309e-07}, {"id": 218, "seek": 138696, "start": 1386.96, "end": 1396.3600000000001, "text": " standard factory method we use in fast AI to create items and PIO image dot create is", "tokens": [3832, 9265, 3170, 321, 764, 294, 2370, 7318, 281, 1884, 4754, 293, 430, 15167, 3256, 5893, 1884, 307], "temperature": 0.0, "avg_logprob": -0.10509116309029716, "compression_ratio": 1.650943396226415, "no_speech_prob": 5.368743813960464e-07}, {"id": 219, "seek": 138696, "start": 1396.3600000000001, "end": 1399.96, "text": " smart enough to be able to create an item from all kinds of different things and one", "tokens": [4069, 1547, 281, 312, 1075, 281, 1884, 364, 3174, 490, 439, 3685, 295, 819, 721, 293, 472], "temperature": 0.0, "avg_logprob": -0.10509116309029716, "compression_ratio": 1.650943396226415, "no_speech_prob": 5.368743813960464e-07}, {"id": 220, "seek": 138696, "start": 1399.96, "end": 1404.64, "text": " of the things that can create it from is a binary blob which is what a file upload contains", "tokens": [295, 264, 721, 300, 393, 1884, 309, 490, 307, 257, 17434, 46115, 597, 307, 437, 257, 3991, 6580, 8306], "temperature": 0.0, "avg_logprob": -0.10509116309029716, "compression_ratio": 1.650943396226415, "no_speech_prob": 5.368743813960464e-07}, {"id": 221, "seek": 138696, "start": 1404.64, "end": 1413.32, "text": " so then we can display it and there's our teddy right so you can see how you know cells", "tokens": [370, 550, 321, 393, 4674, 309, 293, 456, 311, 527, 45116, 558, 370, 291, 393, 536, 577, 291, 458, 5438], "temperature": 0.0, "avg_logprob": -0.10509116309029716, "compression_ratio": 1.650943396226415, "no_speech_prob": 5.368743813960464e-07}, {"id": 222, "seek": 141332, "start": 1413.32, "end": 1420.28, "text": " of Jupyter Notebook can refer to other cells that were created that were kind of have GUI", "tokens": [295, 22125, 88, 391, 11633, 2939, 393, 2864, 281, 661, 5438, 300, 645, 2942, 300, 645, 733, 295, 362, 17917, 40], "temperature": 0.0, "avg_logprob": -0.09866964817047119, "compression_ratio": 1.590643274853801, "no_speech_prob": 8.990948003884114e-07}, {"id": 223, "seek": 141332, "start": 1420.28, "end": 1427.24, "text": " created data in them so let's hide that teddy away for a moment and the next thing to know", "tokens": [2942, 1412, 294, 552, 370, 718, 311, 6479, 300, 45116, 1314, 337, 257, 1623, 293, 264, 958, 551, 281, 458], "temperature": 0.0, "avg_logprob": -0.09866964817047119, "compression_ratio": 1.590643274853801, "no_speech_prob": 8.990948003884114e-07}, {"id": 224, "seek": 141332, "start": 1427.24, "end": 1434.84, "text": " about is that there's a kind of widget called output and an output widget is it's basically", "tokens": [466, 307, 300, 456, 311, 257, 733, 295, 34047, 1219, 5598, 293, 364, 5598, 34047, 307, 309, 311, 1936], "temperature": 0.0, "avg_logprob": -0.09866964817047119, "compression_ratio": 1.590643274853801, "no_speech_prob": 8.990948003884114e-07}, {"id": 225, "seek": 143484, "start": 1434.84, "end": 1443.6399999999999, "text": " something that you can fill in later right so if I delete actually this part here so", "tokens": [746, 300, 291, 393, 2836, 294, 1780, 558, 370, 498, 286, 12097, 767, 341, 644, 510, 370], "temperature": 0.0, "avg_logprob": -0.1037358622397146, "compression_ratio": 1.6134969325153374, "no_speech_prob": 5.804993747915432e-07}, {"id": 226, "seek": 143484, "start": 1443.6399999999999, "end": 1454.1999999999998, "text": " I've now got an output widget yeah actually let's do it this way around and you can't", "tokens": [286, 600, 586, 658, 364, 5598, 34047, 1338, 767, 718, 311, 360, 309, 341, 636, 926, 293, 291, 393, 380], "temperature": 0.0, "avg_logprob": -0.1037358622397146, "compression_ratio": 1.6134969325153374, "no_speech_prob": 5.804993747915432e-07}, {"id": 227, "seek": 143484, "start": 1454.1999999999998, "end": 1458.28, "text": " see the output widget even though I said please display it because nothing is output so then", "tokens": [536, 264, 5598, 34047, 754, 1673, 286, 848, 1767, 4674, 309, 570, 1825, 307, 5598, 370, 550], "temperature": 0.0, "avg_logprob": -0.1037358622397146, "compression_ratio": 1.6134969325153374, "no_speech_prob": 5.804993747915432e-07}, {"id": 228, "seek": 145828, "start": 1458.28, "end": 1465.92, "text": " in the next cell I can say with that output placeholder display a thumbnail of the image", "tokens": [294, 264, 958, 2815, 286, 393, 584, 365, 300, 5598, 1081, 20480, 4674, 257, 26746, 295, 264, 3256], "temperature": 0.0, "avg_logprob": -0.1043814266429228, "compression_ratio": 1.825, "no_speech_prob": 8.990952551357623e-07}, {"id": 229, "seek": 145828, "start": 1465.92, "end": 1473.04, "text": " and you'll see that the display will not appear here it appears back here right because that's", "tokens": [293, 291, 603, 536, 300, 264, 4674, 486, 406, 4204, 510, 309, 7038, 646, 510, 558, 570, 300, 311], "temperature": 0.0, "avg_logprob": -0.1043814266429228, "compression_ratio": 1.825, "no_speech_prob": 8.990952551357623e-07}, {"id": 230, "seek": 145828, "start": 1473.04, "end": 1482.44, "text": " how that's where the placeholder was so let's run that again to clear out that placeholder", "tokens": [577, 300, 311, 689, 264, 1081, 20480, 390, 370, 718, 311, 1190, 300, 797, 281, 1850, 484, 300, 1081, 20480], "temperature": 0.0, "avg_logprob": -0.1043814266429228, "compression_ratio": 1.825, "no_speech_prob": 8.990952551357623e-07}, {"id": 231, "seek": 145828, "start": 1482.44, "end": 1487.96, "text": " so we can create another kind of placeholder which is a label the labels kind of something", "tokens": [370, 321, 393, 1884, 1071, 733, 295, 1081, 20480, 597, 307, 257, 7645, 264, 16949, 733, 295, 746], "temperature": 0.0, "avg_logprob": -0.1043814266429228, "compression_ratio": 1.825, "no_speech_prob": 8.990952551357623e-07}, {"id": 232, "seek": 148796, "start": 1487.96, "end": 1495.16, "text": " where you can put text in it they can give it a value like I don't know please choose", "tokens": [689, 291, 393, 829, 2487, 294, 309, 436, 393, 976, 309, 257, 2158, 411, 286, 500, 380, 458, 1767, 2826], "temperature": 0.0, "avg_logprob": -0.07173971849329332, "compression_ratio": 1.7810945273631842, "no_speech_prob": 1.2289173128010589e-06}, {"id": 233, "seek": 148796, "start": 1495.16, "end": 1501.6000000000001, "text": " an image okay so we've now got a label containing please choose an image now let's create another", "tokens": [364, 3256, 1392, 370, 321, 600, 586, 658, 257, 7645, 19273, 1767, 2826, 364, 3256, 586, 718, 311, 1884, 1071], "temperature": 0.0, "avg_logprob": -0.07173971849329332, "compression_ratio": 1.7810945273631842, "no_speech_prob": 1.2289173128010589e-06}, {"id": 234, "seek": 148796, "start": 1501.6000000000001, "end": 1507.24, "text": " button to do a classification now this is not a file upload button it's just a general", "tokens": [2960, 281, 360, 257, 21538, 586, 341, 307, 406, 257, 3991, 6580, 2960, 309, 311, 445, 257, 2674], "temperature": 0.0, "avg_logprob": -0.07173971849329332, "compression_ratio": 1.7810945273631842, "no_speech_prob": 1.2289173128010589e-06}, {"id": 235, "seek": 148796, "start": 1507.24, "end": 1514.56, "text": " button so this button doesn't do anything right and doesn't do anything until we attach", "tokens": [2960, 370, 341, 2960, 1177, 380, 360, 1340, 558, 293, 1177, 380, 360, 1340, 1826, 321, 5085], "temperature": 0.0, "avg_logprob": -0.07173971849329332, "compression_ratio": 1.7810945273631842, "no_speech_prob": 1.2289173128010589e-06}, {"id": 236, "seek": 151456, "start": 1514.56, "end": 1519.84, "text": " an event handler to it an event handler is a callback we'll be learning all about callbacks", "tokens": [364, 2280, 41967, 281, 309, 364, 2280, 41967, 307, 257, 818, 3207, 321, 603, 312, 2539, 439, 466, 818, 17758], "temperature": 0.0, "avg_logprob": -0.07176581418739175, "compression_ratio": 1.823045267489712, "no_speech_prob": 1.816217945815879e-06}, {"id": 237, "seek": 151456, "start": 1519.84, "end": 1525.84, "text": " in this course if you've ever done any GUI programming before or even web programming", "tokens": [294, 341, 1164, 498, 291, 600, 1562, 1096, 604, 17917, 40, 9410, 949, 420, 754, 3670, 9410], "temperature": 0.0, "avg_logprob": -0.07176581418739175, "compression_ratio": 1.823045267489712, "no_speech_prob": 1.816217945815879e-06}, {"id": 238, "seek": 151456, "start": 1525.84, "end": 1530.7, "text": " you'll be familiar with the idea that you write a function which is the thing you want", "tokens": [291, 603, 312, 4963, 365, 264, 1558, 300, 291, 2464, 257, 2445, 597, 307, 264, 551, 291, 528], "temperature": 0.0, "avg_logprob": -0.07176581418739175, "compression_ratio": 1.823045267489712, "no_speech_prob": 1.816217945815879e-06}, {"id": 239, "seek": 151456, "start": 1530.7, "end": 1536.52, "text": " to be called when the button is clicked on and then somehow you tell your framework that", "tokens": [281, 312, 1219, 562, 264, 2960, 307, 23370, 322, 293, 550, 6063, 291, 980, 428, 8388, 300], "temperature": 0.0, "avg_logprob": -0.07176581418739175, "compression_ratio": 1.823045267489712, "no_speech_prob": 1.816217945815879e-06}, {"id": 240, "seek": 151456, "start": 1536.52, "end": 1543.6799999999998, "text": " this is the on click event so here I go here's my button run I say the on click event the", "tokens": [341, 307, 264, 322, 2052, 2280, 370, 510, 286, 352, 510, 311, 452, 2960, 1190, 286, 584, 264, 322, 2052, 2280, 264], "temperature": 0.0, "avg_logprob": -0.07176581418739175, "compression_ratio": 1.823045267489712, "no_speech_prob": 1.816217945815879e-06}, {"id": 241, "seek": 154368, "start": 1543.68, "end": 1550.2, "text": " button run is to call this code and this code is going to do all the stuff we just saw and", "tokens": [2960, 1190, 307, 281, 818, 341, 3089, 293, 341, 3089, 307, 516, 281, 360, 439, 264, 1507, 321, 445, 1866, 293], "temperature": 0.0, "avg_logprob": -0.12491498834946577, "compression_ratio": 1.7254901960784315, "no_speech_prob": 1.5294085642381106e-06}, {"id": 242, "seek": 154368, "start": 1550.2, "end": 1556.3600000000001, "text": " I create an image from the upload it's going to clear the output display the image call", "tokens": [286, 1884, 364, 3256, 490, 264, 6580, 309, 311, 516, 281, 1850, 264, 5598, 4674, 264, 3256, 818], "temperature": 0.0, "avg_logprob": -0.12491498834946577, "compression_ratio": 1.7254901960784315, "no_speech_prob": 1.5294085642381106e-06}, {"id": 243, "seek": 154368, "start": 1556.3600000000001, "end": 1564.8, "text": " predict and then replace the label with a prediction so there it all is now so that", "tokens": [6069, 293, 550, 7406, 264, 7645, 365, 257, 17630, 370, 456, 309, 439, 307, 586, 370, 300], "temperature": 0.0, "avg_logprob": -0.12491498834946577, "compression_ratio": 1.7254901960784315, "no_speech_prob": 1.5294085642381106e-06}, {"id": 244, "seek": 154368, "start": 1564.8, "end": 1568.4, "text": " hasn't done anything but I can now go back to this classify button which now has an event", "tokens": [6132, 380, 1096, 1340, 457, 286, 393, 586, 352, 646, 281, 341, 33872, 2960, 597, 586, 575, 364, 2280], "temperature": 0.0, "avg_logprob": -0.12491498834946577, "compression_ratio": 1.7254901960784315, "no_speech_prob": 1.5294085642381106e-06}, {"id": 245, "seek": 156840, "start": 1568.4, "end": 1575.8400000000001, "text": " handler attached to it so watch this click oomph and look that's been filled in that's", "tokens": [41967, 8570, 281, 309, 370, 1159, 341, 2052, 277, 298, 950, 293, 574, 300, 311, 668, 6412, 294, 300, 311], "temperature": 0.0, "avg_logprob": -0.127158357251075, "compression_ratio": 1.664516129032258, "no_speech_prob": 1.9637986952147912e-06}, {"id": 246, "seek": 156840, "start": 1575.8400000000001, "end": 1580.3600000000001, "text": " been filled in right in case you missed it let's run these again to clear everything", "tokens": [668, 6412, 294, 558, 294, 1389, 291, 6721, 309, 718, 311, 1190, 613, 797, 281, 1850, 1203], "temperature": 0.0, "avg_logprob": -0.127158357251075, "compression_ratio": 1.664516129032258, "no_speech_prob": 1.9637986952147912e-06}, {"id": 247, "seek": 156840, "start": 1580.3600000000001, "end": 1590.52, "text": " out okay everything's gone this is please choose an image there's nothing here I click", "tokens": [484, 1392, 1203, 311, 2780, 341, 307, 1767, 2826, 364, 3256, 456, 311, 1825, 510, 286, 2052], "temperature": 0.0, "avg_logprob": -0.127158357251075, "compression_ratio": 1.664516129032258, "no_speech_prob": 1.9637986952147912e-06}, {"id": 248, "seek": 159052, "start": 1590.52, "end": 1601.4, "text": " classify oh pop up right so it's kind of amazing how our notebook has suddenly turned into", "tokens": [33872, 1954, 1665, 493, 558, 370, 309, 311, 733, 295, 2243, 577, 527, 21060, 575, 5800, 3574, 666], "temperature": 0.0, "avg_logprob": -0.12697134346797548, "compression_ratio": 1.563953488372093, "no_speech_prob": 1.248268404197006e-06}, {"id": 249, "seek": 159052, "start": 1601.4, "end": 1608.96, "text": " this interactive prototyping playground building applications and so once all this works we", "tokens": [341, 15141, 46219, 3381, 24646, 2390, 5821, 293, 370, 1564, 439, 341, 1985, 321], "temperature": 0.0, "avg_logprob": -0.12697134346797548, "compression_ratio": 1.563953488372093, "no_speech_prob": 1.248268404197006e-06}, {"id": 250, "seek": 159052, "start": 1608.96, "end": 1616.92, "text": " can dump it all together and so the easiest way to dump things together is to create a", "tokens": [393, 11430, 309, 439, 1214, 293, 370, 264, 12889, 636, 281, 11430, 721, 1214, 307, 281, 1884, 257], "temperature": 0.0, "avg_logprob": -0.12697134346797548, "compression_ratio": 1.563953488372093, "no_speech_prob": 1.248268404197006e-06}, {"id": 251, "seek": 161692, "start": 1616.92, "end": 1621.68, "text": " V box a V box is a vertical box and it's just a it's just something that you put widgets", "tokens": [691, 2424, 257, 691, 2424, 307, 257, 9429, 2424, 293, 309, 311, 445, 257, 309, 311, 445, 746, 300, 291, 829, 43355], "temperature": 0.0, "avg_logprob": -0.1400933539730379, "compression_ratio": 1.7611940298507462, "no_speech_prob": 6.577922135875269e-07}, {"id": 252, "seek": 161692, "start": 1621.68, "end": 1624.96, "text": " in and so in this case we're going to put the following widgets we're going to have", "tokens": [294, 293, 370, 294, 341, 1389, 321, 434, 516, 281, 829, 264, 3480, 43355, 321, 434, 516, 281, 362], "temperature": 0.0, "avg_logprob": -0.1400933539730379, "compression_ratio": 1.7611940298507462, "no_speech_prob": 6.577922135875269e-07}, {"id": 253, "seek": 161692, "start": 1624.96, "end": 1630.44, "text": " a label that says select your bear then an upload button a run button an output placeholder", "tokens": [257, 7645, 300, 1619, 3048, 428, 6155, 550, 364, 6580, 2960, 257, 1190, 2960, 364, 5598, 1081, 20480], "temperature": 0.0, "avg_logprob": -0.1400933539730379, "compression_ratio": 1.7611940298507462, "no_speech_prob": 6.577922135875269e-07}, {"id": 254, "seek": 161692, "start": 1630.44, "end": 1637.16, "text": " and a label for predictions so let's run these again just to clear everything out so that", "tokens": [293, 257, 7645, 337, 21264, 370, 718, 311, 1190, 613, 797, 445, 281, 1850, 1203, 484, 370, 300], "temperature": 0.0, "avg_logprob": -0.1400933539730379, "compression_ratio": 1.7611940298507462, "no_speech_prob": 6.577922135875269e-07}, {"id": 255, "seek": 163716, "start": 1637.16, "end": 1648.1200000000001, "text": " we're not cheating and let's create our V box so as you can see it's just got all the", "tokens": [321, 434, 406, 18309, 293, 718, 311, 1884, 527, 691, 2424, 370, 382, 291, 393, 536, 309, 311, 445, 658, 439, 264], "temperature": 0.0, "avg_logprob": -0.127360471089681, "compression_ratio": 1.375, "no_speech_prob": 7.002163329161704e-07}, {"id": 256, "seek": 163716, "start": 1648.1200000000001, "end": 1659.92, "text": " all the pieces right now we've got whatever oh I accidentally ran the thing that displayed", "tokens": [439, 264, 3755, 558, 586, 321, 600, 658, 2035, 1954, 286, 15715, 5872, 264, 551, 300, 16372], "temperature": 0.0, "avg_logprob": -0.127360471089681, "compression_ratio": 1.375, "no_speech_prob": 7.002163329161704e-07}, {"id": 257, "seek": 165992, "start": 1659.92, "end": 1671.64, "text": " the bear let's get rid of that okay so there it is so now I can click upload I can choose", "tokens": [264, 6155, 718, 311, 483, 3973, 295, 300, 1392, 370, 456, 309, 307, 370, 586, 286, 393, 2052, 6580, 286, 393, 2826], "temperature": 0.0, "avg_logprob": -0.0911851218252471, "compression_ratio": 1.6903225806451614, "no_speech_prob": 1.392544277223351e-06}, {"id": 258, "seek": 165992, "start": 1671.64, "end": 1680.24, "text": " my bear okay and then I can click classify right and notice I've this is exactly that", "tokens": [452, 6155, 1392, 293, 550, 286, 393, 2052, 33872, 558, 293, 3449, 286, 600, 341, 307, 2293, 300], "temperature": 0.0, "avg_logprob": -0.0911851218252471, "compression_ratio": 1.6903225806451614, "no_speech_prob": 1.392544277223351e-06}, {"id": 259, "seek": 165992, "start": 1680.24, "end": 1686.4, "text": " this is this is like the same buttons as as these buttons they're like two places with", "tokens": [341, 307, 341, 307, 411, 264, 912, 9905, 382, 382, 613, 9905, 436, 434, 411, 732, 3190, 365], "temperature": 0.0, "avg_logprob": -0.0911851218252471, "compression_ratio": 1.6903225806451614, "no_speech_prob": 1.392544277223351e-06}, {"id": 260, "seek": 168640, "start": 1686.4, "end": 1691.3200000000002, "text": " we're viewing the same button which is kind of a wild idea so if I click classify it's", "tokens": [321, 434, 17480, 264, 912, 2960, 597, 307, 733, 295, 257, 4868, 1558, 370, 498, 286, 2052, 33872, 309, 311], "temperature": 0.0, "avg_logprob": -0.06855329634651305, "compression_ratio": 1.623456790123457, "no_speech_prob": 1.3709545783058275e-06}, {"id": 261, "seek": 168640, "start": 1691.3200000000002, "end": 1697.0, "text": " going to change this label and this label because they're actually both references to", "tokens": [516, 281, 1319, 341, 7645, 293, 341, 7645, 570, 436, 434, 767, 1293, 15400, 281], "temperature": 0.0, "avg_logprob": -0.06855329634651305, "compression_ratio": 1.623456790123457, "no_speech_prob": 1.3709545783058275e-06}, {"id": 262, "seek": 168640, "start": 1697.0, "end": 1707.8200000000002, "text": " the same label look there we are okay so this is our app right and so this is actually how", "tokens": [264, 912, 7645, 574, 456, 321, 366, 1392, 370, 341, 307, 527, 724, 558, 293, 370, 341, 307, 767, 577], "temperature": 0.0, "avg_logprob": -0.06855329634651305, "compression_ratio": 1.623456790123457, "no_speech_prob": 1.3709545783058275e-06}, {"id": 263, "seek": 170782, "start": 1707.82, "end": 1717.0, "text": " I built that that image cleaner GUI is just using these exact things and I built that", "tokens": [286, 3094, 300, 300, 3256, 16532, 17917, 40, 307, 445, 1228, 613, 1900, 721, 293, 286, 3094, 300], "temperature": 0.0, "avg_logprob": -0.06391904467628115, "compression_ratio": 1.6956521739130435, "no_speech_prob": 6.615596959136383e-08}, {"id": 264, "seek": 170782, "start": 1717.0, "end": 1723.32, "text": " image cleaner GUI cell by cell in a notebook just like this and so you get this kind of", "tokens": [3256, 16532, 17917, 40, 2815, 538, 2815, 294, 257, 21060, 445, 411, 341, 293, 370, 291, 483, 341, 733, 295], "temperature": 0.0, "avg_logprob": -0.06391904467628115, "compression_ratio": 1.6956521739130435, "no_speech_prob": 6.615596959136383e-08}, {"id": 265, "seek": 170782, "start": 1723.32, "end": 1729.1599999999999, "text": " interactive experimental framework for building a GUI so if you're a data scientist who's", "tokens": [15141, 17069, 8388, 337, 2390, 257, 17917, 40, 370, 498, 291, 434, 257, 1412, 12662, 567, 311], "temperature": 0.0, "avg_logprob": -0.06391904467628115, "compression_ratio": 1.6956521739130435, "no_speech_prob": 6.615596959136383e-08}, {"id": 266, "seek": 170782, "start": 1729.1599999999999, "end": 1734.76, "text": " never done GUI stuff before this is a great time to get started because now you can you", "tokens": [1128, 1096, 17917, 40, 1507, 949, 341, 307, 257, 869, 565, 281, 483, 1409, 570, 586, 291, 393, 291], "temperature": 0.0, "avg_logprob": -0.06391904467628115, "compression_ratio": 1.6956521739130435, "no_speech_prob": 6.615596959136383e-08}, {"id": 267, "seek": 173476, "start": 1734.76, "end": 1742.04, "text": " can make actual programs now of course an actual program running inside a notebook is", "tokens": [393, 652, 3539, 4268, 586, 295, 1164, 364, 3539, 1461, 2614, 1854, 257, 21060, 307], "temperature": 0.0, "avg_logprob": -0.09167578181282418, "compression_ratio": 1.6352201257861636, "no_speech_prob": 1.1365619911885005e-06}, {"id": 268, "seek": 173476, "start": 1742.04, "end": 1747.52, "text": " kind of cool but what we really want is this program to run in a place anybody can run", "tokens": [733, 295, 1627, 457, 437, 321, 534, 528, 307, 341, 1461, 281, 1190, 294, 257, 1081, 4472, 393, 1190], "temperature": 0.0, "avg_logprob": -0.09167578181282418, "compression_ratio": 1.6352201257861636, "no_speech_prob": 1.1365619911885005e-06}, {"id": 269, "seek": 173476, "start": 1747.52, "end": 1756.5, "text": " it that's where voila comes in so voila needs to be installed so you can just run these", "tokens": [309, 300, 311, 689, 45565, 1487, 294, 370, 45565, 2203, 281, 312, 8899, 370, 291, 393, 445, 1190, 613], "temperature": 0.0, "avg_logprob": -0.09167578181282418, "compression_ratio": 1.6352201257861636, "no_speech_prob": 1.1365619911885005e-06}, {"id": 270, "seek": 175650, "start": 1756.5, "end": 1769.22, "text": " lines or install it it's listed in the pros and what voila does is it takes a notebook", "tokens": [3876, 420, 3625, 309, 309, 311, 10052, 294, 264, 6267, 293, 437, 45565, 775, 307, 309, 2516, 257, 21060], "temperature": 0.0, "avg_logprob": -0.1366070338657924, "compression_ratio": 1.5588235294117647, "no_speech_prob": 1.0348510386393173e-06}, {"id": 271, "seek": 175650, "start": 1769.22, "end": 1778.64, "text": " and just doesn't display anything except for the markdown the IPython widgets and the outputs", "tokens": [293, 445, 1177, 380, 4674, 1340, 3993, 337, 264, 1491, 5093, 264, 8671, 88, 11943, 43355, 293, 264, 23930], "temperature": 0.0, "avg_logprob": -0.1366070338657924, "compression_ratio": 1.5588235294117647, "no_speech_prob": 1.0348510386393173e-06}, {"id": 272, "seek": 175650, "start": 1778.64, "end": 1782.72, "text": " right so all the code cells disappear and it doesn't give the person looking at that", "tokens": [558, 370, 439, 264, 3089, 5438, 11596, 293, 309, 1177, 380, 976, 264, 954, 1237, 412, 300], "temperature": 0.0, "avg_logprob": -0.1366070338657924, "compression_ratio": 1.5588235294117647, "no_speech_prob": 1.0348510386393173e-06}, {"id": 273, "seek": 178272, "start": 1782.72, "end": 1789.16, "text": " page the ability to run their own code they can only interact with the widgets right so", "tokens": [3028, 264, 3485, 281, 1190, 641, 1065, 3089, 436, 393, 787, 4648, 365, 264, 43355, 558, 370], "temperature": 0.0, "avg_logprob": -0.09054050137919764, "compression_ratio": 1.6772151898734178, "no_speech_prob": 3.927856084828818e-07}, {"id": 274, "seek": 178272, "start": 1789.16, "end": 1796.64, "text": " what I did was I copied and pasted that code from the notebook into a separate notebook", "tokens": [437, 286, 630, 390, 286, 25365, 293, 1791, 292, 300, 3089, 490, 264, 21060, 666, 257, 4994, 21060], "temperature": 0.0, "avg_logprob": -0.09054050137919764, "compression_ratio": 1.6772151898734178, "no_speech_prob": 3.927856084828818e-07}, {"id": 275, "seek": 178272, "start": 1796.64, "end": 1809.0, "text": " which only has those lines of code right so so these are just the same lines of code that", "tokens": [597, 787, 575, 729, 3876, 295, 3089, 558, 370, 370, 613, 366, 445, 264, 912, 3876, 295, 3089, 300], "temperature": 0.0, "avg_logprob": -0.09054050137919764, "compression_ratio": 1.6772151898734178, "no_speech_prob": 3.927856084828818e-07}, {"id": 276, "seek": 180900, "start": 1809.0, "end": 1818.96, "text": " we saw before and so this is a notebook it's just a normal notebook and then I installed", "tokens": [321, 1866, 949, 293, 370, 341, 307, 257, 21060, 309, 311, 445, 257, 2710, 21060, 293, 550, 286, 8899], "temperature": 0.0, "avg_logprob": -0.08657018911270868, "compression_ratio": 1.5565217391304347, "no_speech_prob": 1.090727650421286e-07}, {"id": 277, "seek": 180900, "start": 1818.96, "end": 1831.0, "text": " voila and then when you do that if you navigate to this notebook but you replace notebooks", "tokens": [45565, 293, 550, 562, 291, 360, 300, 498, 291, 12350, 281, 341, 21060, 457, 291, 7406, 43782], "temperature": 0.0, "avg_logprob": -0.08657018911270868, "compression_ratio": 1.5565217391304347, "no_speech_prob": 1.090727650421286e-07}, {"id": 278, "seek": 183100, "start": 1831.0, "end": 1842.94, "text": " up here with voila it actually displays not the notebook but just as I said the markdown", "tokens": [493, 510, 365, 45565, 309, 767, 20119, 406, 264, 21060, 457, 445, 382, 286, 848, 264, 1491, 5093], "temperature": 0.0, "avg_logprob": -0.06669850209180046, "compression_ratio": 1.5689655172413792, "no_speech_prob": 5.539169478652184e-07}, {"id": 279, "seek": 183100, "start": 1842.94, "end": 1851.0, "text": " and the widgets so here I've got my bear classifier and I can click upload let's do a grizzly", "tokens": [293, 264, 43355, 370, 510, 286, 600, 658, 452, 6155, 1508, 9902, 293, 286, 393, 2052, 6580, 718, 311, 360, 257, 17865, 4313, 356], "temperature": 0.0, "avg_logprob": -0.06669850209180046, "compression_ratio": 1.5689655172413792, "no_speech_prob": 5.539169478652184e-07}, {"id": 280, "seek": 183100, "start": 1851.0, "end": 1859.28, "text": " bear this time and this is a slightly different version I actually made this so there's no", "tokens": [6155, 341, 565, 293, 341, 307, 257, 4748, 819, 3037, 286, 767, 1027, 341, 370, 456, 311, 572], "temperature": 0.0, "avg_logprob": -0.06669850209180046, "compression_ratio": 1.5689655172413792, "no_speech_prob": 5.539169478652184e-07}, {"id": 281, "seek": 185928, "start": 1859.28, "end": 1863.22, "text": " classify button I thought it would be a bit more fancy to make it so when you click upload", "tokens": [33872, 2960, 286, 1194, 309, 576, 312, 257, 857, 544, 10247, 281, 652, 309, 370, 562, 291, 2052, 6580], "temperature": 0.0, "avg_logprob": -0.10573471424191497, "compression_ratio": 1.681159420289855, "no_speech_prob": 8.186337936422206e-07}, {"id": 282, "seek": 185928, "start": 1863.22, "end": 1870.08, "text": " it just runs everything but as you can see there it all is right it's all working so", "tokens": [309, 445, 6676, 1203, 457, 382, 291, 393, 536, 456, 309, 439, 307, 558, 309, 311, 439, 1364, 370], "temperature": 0.0, "avg_logprob": -0.10573471424191497, "compression_ratio": 1.681159420289855, "no_speech_prob": 8.186337936422206e-07}, {"id": 283, "seek": 185928, "start": 1870.08, "end": 1876.16, "text": " this is the world's simplest prototype but it's it's a proof of concept right so you", "tokens": [341, 307, 264, 1002, 311, 22811, 19475, 457, 309, 311, 309, 311, 257, 8177, 295, 3410, 558, 370, 291], "temperature": 0.0, "avg_logprob": -0.10573471424191497, "compression_ratio": 1.681159420289855, "no_speech_prob": 8.186337936422206e-07}, {"id": 284, "seek": 185928, "start": 1876.16, "end": 1883.76, "text": " can add widgets with drop-downs and sliders and charts and you know everything that you", "tokens": [393, 909, 43355, 365, 3270, 12, 5093, 82, 293, 1061, 6936, 293, 17767, 293, 291, 458, 1203, 300, 291], "temperature": 0.0, "avg_logprob": -0.10573471424191497, "compression_ratio": 1.681159420289855, "no_speech_prob": 8.186337936422206e-07}, {"id": 285, "seek": 188376, "start": 1883.76, "end": 1889.92, "text": " can have in a you know an angular app or a react app or whatever and in fact there's", "tokens": [393, 362, 294, 257, 291, 458, 364, 24413, 724, 420, 257, 4515, 724, 420, 2035, 293, 294, 1186, 456, 311], "temperature": 0.0, "avg_logprob": -0.10848690163005482, "compression_ratio": 1.7114427860696517, "no_speech_prob": 1.0030113344328129e-06}, {"id": 286, "seek": 188376, "start": 1889.92, "end": 1896.2, "text": " even stuff which lets you use for example the whole Vue.js framework if you know that", "tokens": [754, 1507, 597, 6653, 291, 764, 337, 1365, 264, 1379, 691, 622, 13, 25530, 8388, 498, 291, 458, 300], "temperature": 0.0, "avg_logprob": -0.10848690163005482, "compression_ratio": 1.7114427860696517, "no_speech_prob": 1.0030113344328129e-06}, {"id": 287, "seek": 188376, "start": 1896.2, "end": 1900.68, "text": " it's a very popular JavaScript framework the whole Vue.js framework you can actually use", "tokens": [309, 311, 257, 588, 3743, 15778, 8388, 264, 1379, 691, 622, 13, 25530, 8388, 291, 393, 767, 764], "temperature": 0.0, "avg_logprob": -0.10848690163005482, "compression_ratio": 1.7114427860696517, "no_speech_prob": 1.0030113344328129e-06}, {"id": 288, "seek": 188376, "start": 1900.68, "end": 1911.66, "text": " it in widgets and voila so now we want to get it so that this this app can be run by", "tokens": [309, 294, 43355, 293, 45565, 370, 586, 321, 528, 281, 483, 309, 370, 300, 341, 341, 724, 393, 312, 1190, 538], "temperature": 0.0, "avg_logprob": -0.10848690163005482, "compression_ratio": 1.7114427860696517, "no_speech_prob": 1.0030113344328129e-06}, {"id": 289, "seek": 191166, "start": 1911.66, "end": 1916.6000000000001, "text": " someone out there in the world so the voila documentation shows a few ways to do that", "tokens": [1580, 484, 456, 294, 264, 1002, 370, 264, 45565, 14333, 3110, 257, 1326, 2098, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.09501223777657125, "compression_ratio": 1.6158536585365855, "no_speech_prob": 1.1365613090674742e-06}, {"id": 290, "seek": 191166, "start": 1916.6000000000001, "end": 1929.0400000000002, "text": " but perhaps the easiest one is to use a system called binder and so binder is at mybinder.org", "tokens": [457, 4317, 264, 12889, 472, 307, 281, 764, 257, 1185, 1219, 45630, 293, 370, 45630, 307, 412, 452, 65, 5669, 13, 4646], "temperature": 0.0, "avg_logprob": -0.09501223777657125, "compression_ratio": 1.6158536585365855, "no_speech_prob": 1.1365613090674742e-06}, {"id": 291, "seek": 191166, "start": 1929.0400000000002, "end": 1933.0, "text": " and all you do is you paste in your github repository name here right and this is all", "tokens": [293, 439, 291, 360, 307, 291, 9163, 294, 428, 290, 355, 836, 25841, 1315, 510, 558, 293, 341, 307, 439], "temperature": 0.0, "avg_logprob": -0.09501223777657125, "compression_ratio": 1.6158536585365855, "no_speech_prob": 1.1365613090674742e-06}, {"id": 292, "seek": 193300, "start": 1933.0, "end": 1944.48, "text": " in the book right so you paste in your github repo name you change where it says file you", "tokens": [294, 264, 1446, 558, 370, 291, 9163, 294, 428, 290, 355, 836, 49040, 1315, 291, 1319, 689, 309, 1619, 3991, 291], "temperature": 0.0, "avg_logprob": -0.09734091829897752, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.577914746230817e-07}, {"id": 293, "seek": 193300, "start": 1944.48, "end": 1953.32, "text": " change that to URL you can see and then you put in the path which we were just experimenting", "tokens": [1319, 300, 281, 12905, 291, 393, 536, 293, 550, 291, 829, 294, 264, 3100, 597, 321, 645, 445, 29070], "temperature": 0.0, "avg_logprob": -0.09734091829897752, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.577914746230817e-07}, {"id": 294, "seek": 193300, "start": 1953.32, "end": 1962.86, "text": " with right so pop that here and then you say launch and what that does is it then gives", "tokens": [365, 558, 370, 1665, 300, 510, 293, 550, 291, 584, 4025, 293, 437, 300, 775, 307, 309, 550, 2709], "temperature": 0.0, "avg_logprob": -0.09734091829897752, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.577914746230817e-07}, {"id": 295, "seek": 196286, "start": 1962.86, "end": 1973.6399999999999, "text": " you a URL so then this URL you can pass on to people and this is actually your interactive", "tokens": [291, 257, 12905, 370, 550, 341, 12905, 291, 393, 1320, 322, 281, 561, 293, 341, 307, 767, 428, 15141], "temperature": 0.0, "avg_logprob": -0.08737477045210582, "compression_ratio": 1.6181818181818182, "no_speech_prob": 1.9333513137098635e-06}, {"id": 296, "seek": 196286, "start": 1973.6399999999999, "end": 1979.9199999999998, "text": " running application so binders free and so this isn't you know anybody can now use this", "tokens": [2614, 3861, 370, 14786, 433, 1737, 293, 370, 341, 1943, 380, 291, 458, 4472, 393, 586, 764, 341], "temperature": 0.0, "avg_logprob": -0.08737477045210582, "compression_ratio": 1.6181818181818182, "no_speech_prob": 1.9333513137098635e-06}, {"id": 297, "seek": 196286, "start": 1979.9199999999998, "end": 1988.76, "text": " to take their voila app and make it a publicly available web application so try it as it", "tokens": [281, 747, 641, 45565, 724, 293, 652, 309, 257, 14843, 2435, 3670, 3861, 370, 853, 309, 382, 309], "temperature": 0.0, "avg_logprob": -0.08737477045210582, "compression_ratio": 1.6181818181818182, "no_speech_prob": 1.9333513137098635e-06}, {"id": 298, "seek": 198876, "start": 1988.76, "end": 1994.24, "text": " mentions here the first time you do this binder takes about five minutes to build your site", "tokens": [23844, 510, 264, 700, 565, 291, 360, 341, 45630, 2516, 466, 1732, 2077, 281, 1322, 428, 3621], "temperature": 0.0, "avg_logprob": -0.09335009256998698, "compression_ratio": 1.9781659388646289, "no_speech_prob": 2.026133643084904e-06}, {"id": 299, "seek": 198876, "start": 1994.24, "end": 1999.24, "text": " because it actually uses something called docker to deploy the whole fast AI framework", "tokens": [570, 309, 767, 4960, 746, 1219, 360, 9178, 281, 7274, 264, 1379, 2370, 7318, 8388], "temperature": 0.0, "avg_logprob": -0.09335009256998698, "compression_ratio": 1.9781659388646289, "no_speech_prob": 2.026133643084904e-06}, {"id": 300, "seek": 198876, "start": 1999.24, "end": 2005.28, "text": " and python and blah blah blah but once you've done that that virtual machine will keep running", "tokens": [293, 38797, 293, 12288, 12288, 12288, 457, 1564, 291, 600, 1096, 300, 300, 6374, 3479, 486, 1066, 2614], "temperature": 0.0, "avg_logprob": -0.09335009256998698, "compression_ratio": 1.9781659388646289, "no_speech_prob": 2.026133643084904e-06}, {"id": 301, "seek": 198876, "start": 2005.28, "end": 2013.08, "text": " for you know as long as people are using it it'll keep running for a while that virtual", "tokens": [337, 291, 458, 382, 938, 382, 561, 366, 1228, 309, 309, 603, 1066, 2614, 337, 257, 1339, 300, 6374], "temperature": 0.0, "avg_logprob": -0.09335009256998698, "compression_ratio": 1.9781659388646289, "no_speech_prob": 2.026133643084904e-06}, {"id": 302, "seek": 198876, "start": 2013.08, "end": 2018.0, "text": " machine will keep running for a while as long as people are using it and you know it's it's", "tokens": [3479, 486, 1066, 2614, 337, 257, 1339, 382, 938, 382, 561, 366, 1228, 309, 293, 291, 458, 309, 311, 309, 311], "temperature": 0.0, "avg_logprob": -0.09335009256998698, "compression_ratio": 1.9781659388646289, "no_speech_prob": 2.026133643084904e-06}, {"id": 303, "seek": 201800, "start": 2018.0, "end": 2025.04, "text": " reasonably fast so a few things to note here being a free service you won't be surprised", "tokens": [23551, 2370, 370, 257, 1326, 721, 281, 3637, 510, 885, 257, 1737, 2643, 291, 1582, 380, 312, 6100], "temperature": 0.0, "avg_logprob": -0.08422287683638316, "compression_ratio": 1.593939393939394, "no_speech_prob": 1.7880578297990724e-06}, {"id": 304, "seek": 201800, "start": 2025.04, "end": 2033.2, "text": " to hear this is not using a GPU is using a CPU and so that might be surprising that we're", "tokens": [281, 1568, 341, 307, 406, 1228, 257, 18407, 307, 1228, 257, 13199, 293, 370, 300, 1062, 312, 8830, 300, 321, 434], "temperature": 0.0, "avg_logprob": -0.08422287683638316, "compression_ratio": 1.593939393939394, "no_speech_prob": 1.7880578297990724e-06}, {"id": 305, "seek": 201800, "start": 2033.2, "end": 2042.72, "text": " deploying to something which runs on a CPU when you think about it though this makes", "tokens": [34198, 281, 746, 597, 6676, 322, 257, 13199, 562, 291, 519, 466, 309, 1673, 341, 1669], "temperature": 0.0, "avg_logprob": -0.08422287683638316, "compression_ratio": 1.593939393939394, "no_speech_prob": 1.7880578297990724e-06}, {"id": 306, "seek": 204272, "start": 2042.72, "end": 2055.42, "text": " much more sense to deploy to a CPU than a GPU the just a moment the thing that's happening", "tokens": [709, 544, 2020, 281, 7274, 281, 257, 13199, 813, 257, 18407, 264, 445, 257, 1623, 264, 551, 300, 311, 2737], "temperature": 0.0, "avg_logprob": -0.09317874908447266, "compression_ratio": 1.6441717791411044, "no_speech_prob": 1.172636984847486e-06}, {"id": 307, "seek": 204272, "start": 2055.42, "end": 2063.36, "text": " here is that I am passing along let's go back to my app in my app I'm passing along a single", "tokens": [510, 307, 300, 286, 669, 8437, 2051, 718, 311, 352, 646, 281, 452, 724, 294, 452, 724, 286, 478, 8437, 2051, 257, 2167], "temperature": 0.0, "avg_logprob": -0.09317874908447266, "compression_ratio": 1.6441717791411044, "no_speech_prob": 1.172636984847486e-06}, {"id": 308, "seek": 204272, "start": 2063.36, "end": 2068.6, "text": " image at a time so when I pass along that single image I don't have a huge amount of", "tokens": [3256, 412, 257, 565, 370, 562, 286, 1320, 2051, 300, 2167, 3256, 286, 500, 380, 362, 257, 2603, 2372, 295], "temperature": 0.0, "avg_logprob": -0.09317874908447266, "compression_ratio": 1.6441717791411044, "no_speech_prob": 1.172636984847486e-06}, {"id": 309, "seek": 206860, "start": 2068.6, "end": 2074.02, "text": " parallel work for a GPU to do this is actually something that a CPU is going to be doing", "tokens": [8952, 589, 337, 257, 18407, 281, 360, 341, 307, 767, 746, 300, 257, 13199, 307, 516, 281, 312, 884], "temperature": 0.0, "avg_logprob": -0.05859476686960243, "compression_ratio": 1.6682242990654206, "no_speech_prob": 9.570793508828501e-07}, {"id": 310, "seek": 206860, "start": 2074.02, "end": 2082.24, "text": " more efficiently so we found that for folks coming through this course the vast majority", "tokens": [544, 19621, 370, 321, 1352, 300, 337, 4024, 1348, 807, 341, 1164, 264, 8369, 6286], "temperature": 0.0, "avg_logprob": -0.05859476686960243, "compression_ratio": 1.6682242990654206, "no_speech_prob": 9.570793508828501e-07}, {"id": 311, "seek": 206860, "start": 2082.24, "end": 2088.16, "text": " of the time they wanted to deploy inference on a CPU not a GPU because they're normally", "tokens": [295, 264, 565, 436, 1415, 281, 7274, 38253, 322, 257, 13199, 406, 257, 18407, 570, 436, 434, 5646], "temperature": 0.0, "avg_logprob": -0.05859476686960243, "compression_ratio": 1.6682242990654206, "no_speech_prob": 9.570793508828501e-07}, {"id": 312, "seek": 206860, "start": 2088.16, "end": 2097.7999999999997, "text": " just doing one item at a time it's way cheaper and easier to deploy to a CPU and the reason", "tokens": [445, 884, 472, 3174, 412, 257, 565, 309, 311, 636, 12284, 293, 3571, 281, 7274, 281, 257, 13199, 293, 264, 1778], "temperature": 0.0, "avg_logprob": -0.05859476686960243, "compression_ratio": 1.6682242990654206, "no_speech_prob": 9.570793508828501e-07}, {"id": 313, "seek": 209780, "start": 2097.8, "end": 2102.88, "text": " for that is that you can just use any hosting service you like because just remember this", "tokens": [337, 300, 307, 300, 291, 393, 445, 764, 604, 16058, 2643, 291, 411, 570, 445, 1604, 341], "temperature": 0.0, "avg_logprob": -0.0813691150851366, "compression_ratio": 1.8159203980099503, "no_speech_prob": 3.3405185604351573e-06}, {"id": 314, "seek": 209780, "start": 2102.88, "end": 2110.4, "text": " is just a this is just a program at this point right and you can use all the usuals horizontal", "tokens": [307, 445, 257, 341, 307, 445, 257, 1461, 412, 341, 935, 558, 293, 291, 393, 764, 439, 264, 7713, 82, 12750], "temperature": 0.0, "avg_logprob": -0.0813691150851366, "compression_ratio": 1.8159203980099503, "no_speech_prob": 3.3405185604351573e-06}, {"id": 315, "seek": 209780, "start": 2110.4, "end": 2116.5600000000004, "text": " scaling vertical scaling you know you can use Heroku you can use AWS you can use inexpensive", "tokens": [21589, 9429, 21589, 291, 458, 291, 393, 764, 3204, 13275, 291, 393, 764, 17650, 291, 393, 764, 28382], "temperature": 0.0, "avg_logprob": -0.0813691150851366, "compression_ratio": 1.8159203980099503, "no_speech_prob": 3.3405185604351573e-06}, {"id": 316, "seek": 209780, "start": 2116.5600000000004, "end": 2123.84, "text": " instances super cheap and super easy having said that there are times you might need to", "tokens": [14519, 1687, 7084, 293, 1687, 1858, 1419, 848, 300, 456, 366, 1413, 291, 1062, 643, 281], "temperature": 0.0, "avg_logprob": -0.0813691150851366, "compression_ratio": 1.8159203980099503, "no_speech_prob": 3.3405185604351573e-06}, {"id": 317, "seek": 212384, "start": 2123.84, "end": 2132.76, "text": " deploy to a GPU for example maybe you're processing videos and so like a single video on on a", "tokens": [7274, 281, 257, 18407, 337, 1365, 1310, 291, 434, 9007, 2145, 293, 370, 411, 257, 2167, 960, 322, 322, 257], "temperature": 0.0, "avg_logprob": -0.0942653531119937, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.482350171500002e-06}, {"id": 318, "seek": 212384, "start": 2132.76, "end": 2140.52, "text": " CPU to process it it might take all day or you might be so successful that you have a", "tokens": [13199, 281, 1399, 309, 309, 1062, 747, 439, 786, 420, 291, 1062, 312, 370, 4406, 300, 291, 362, 257], "temperature": 0.0, "avg_logprob": -0.0942653531119937, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.482350171500002e-06}, {"id": 319, "seek": 212384, "start": 2140.52, "end": 2146.2400000000002, "text": " thousand requests per second in which case you could like take 128 at a time batch them", "tokens": [4714, 12475, 680, 1150, 294, 597, 1389, 291, 727, 411, 747, 29810, 412, 257, 565, 15245, 552], "temperature": 0.0, "avg_logprob": -0.0942653531119937, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.482350171500002e-06}, {"id": 320, "seek": 212384, "start": 2146.2400000000002, "end": 2150.52, "text": " together and put the whole batch on the GPU and get the results back and pass them back", "tokens": [1214, 293, 829, 264, 1379, 15245, 322, 264, 18407, 293, 483, 264, 3542, 646, 293, 1320, 552, 646], "temperature": 0.0, "avg_logprob": -0.0942653531119937, "compression_ratio": 1.628440366972477, "no_speech_prob": 1.482350171500002e-06}, {"id": 321, "seek": 215052, "start": 2150.52, "end": 2156.72, "text": " around and you've got to be careful of that right because as if your requests aren't coming", "tokens": [926, 293, 291, 600, 658, 281, 312, 5026, 295, 300, 558, 570, 382, 498, 428, 12475, 3212, 380, 1348], "temperature": 0.0, "avg_logprob": -0.12265709468296596, "compression_ratio": 1.6255707762557077, "no_speech_prob": 6.577917019967572e-07}, {"id": 322, "seek": 215052, "start": 2156.72, "end": 2162.92, "text": " fast enough your user has to wait for a whole batch of people to be ready to to be processed", "tokens": [2370, 1547, 428, 4195, 575, 281, 1699, 337, 257, 1379, 15245, 295, 561, 281, 312, 1919, 281, 281, 312, 18846], "temperature": 0.0, "avg_logprob": -0.12265709468296596, "compression_ratio": 1.6255707762557077, "no_speech_prob": 6.577917019967572e-07}, {"id": 323, "seek": 215052, "start": 2162.92, "end": 2173.44, "text": " but you know conceptually as long as your site is popular enough that could work. The", "tokens": [457, 291, 458, 3410, 671, 382, 938, 382, 428, 3621, 307, 3743, 1547, 300, 727, 589, 13, 440], "temperature": 0.0, "avg_logprob": -0.12265709468296596, "compression_ratio": 1.6255707762557077, "no_speech_prob": 6.577917019967572e-07}, {"id": 324, "seek": 215052, "start": 2173.44, "end": 2180.28, "text": " other thing to talk about is you might want to deploy to a mobile phone and deploying", "tokens": [661, 551, 281, 751, 466, 307, 291, 1062, 528, 281, 7274, 281, 257, 6013, 2593, 293, 34198], "temperature": 0.0, "avg_logprob": -0.12265709468296596, "compression_ratio": 1.6255707762557077, "no_speech_prob": 6.577917019967572e-07}, {"id": 325, "seek": 218028, "start": 2180.28, "end": 2185.84, "text": " to a mobile phone our recommendation is wherever possible do that by actually deploying to", "tokens": [281, 257, 6013, 2593, 527, 11879, 307, 8660, 1944, 360, 300, 538, 767, 34198, 281], "temperature": 0.0, "avg_logprob": -0.08928372942168138, "compression_ratio": 1.7635467980295567, "no_speech_prob": 5.682402843376622e-06}, {"id": 326, "seek": 218028, "start": 2185.84, "end": 2191.44, "text": " a server and then have a mobile phone talk to the server over a network and because if", "tokens": [257, 7154, 293, 550, 362, 257, 6013, 2593, 751, 281, 264, 7154, 670, 257, 3209, 293, 570, 498], "temperature": 0.0, "avg_logprob": -0.08928372942168138, "compression_ratio": 1.7635467980295567, "no_speech_prob": 5.682402843376622e-06}, {"id": 327, "seek": 218028, "start": 2191.44, "end": 2197.76, "text": " you do that again you can just use a normal PyTorch program on a normal server and normal", "tokens": [291, 360, 300, 797, 291, 393, 445, 764, 257, 2710, 9953, 51, 284, 339, 1461, 322, 257, 2710, 7154, 293, 2710], "temperature": 0.0, "avg_logprob": -0.08928372942168138, "compression_ratio": 1.7635467980295567, "no_speech_prob": 5.682402843376622e-06}, {"id": 328, "seek": 218028, "start": 2197.76, "end": 2205.32, "text": " network calls it makes life super easy when you try to run a PyTorch app on a phone you're", "tokens": [3209, 5498, 309, 1669, 993, 1687, 1858, 562, 291, 853, 281, 1190, 257, 9953, 51, 284, 339, 724, 322, 257, 2593, 291, 434], "temperature": 0.0, "avg_logprob": -0.08928372942168138, "compression_ratio": 1.7635467980295567, "no_speech_prob": 5.682402843376622e-06}, {"id": 329, "seek": 220532, "start": 2205.32, "end": 2210.32, "text": " suddenly now not an environment where not an environment where like PyTorch will run natively", "tokens": [5800, 586, 406, 364, 2823, 689, 406, 364, 2823, 689, 411, 9953, 51, 284, 339, 486, 1190, 8470, 356], "temperature": 0.0, "avg_logprob": -0.15367545151129003, "compression_ratio": 1.7380952380952381, "no_speech_prob": 3.2377297429775354e-06}, {"id": 330, "seek": 220532, "start": 2210.32, "end": 2216.6800000000003, "text": " and so you have to like convert your program into some other form and there are other forms", "tokens": [293, 370, 291, 362, 281, 411, 7620, 428, 1461, 666, 512, 661, 1254, 293, 456, 366, 661, 6422], "temperature": 0.0, "avg_logprob": -0.15367545151129003, "compression_ratio": 1.7380952380952381, "no_speech_prob": 3.2377297429775354e-06}, {"id": 331, "seek": 220532, "start": 2216.6800000000003, "end": 2221.6000000000004, "text": " and the main form that you convert it to is something called O, N and X which is specifically", "tokens": [293, 264, 2135, 1254, 300, 291, 7620, 309, 281, 307, 746, 1219, 422, 11, 426, 293, 1783, 597, 307, 4682], "temperature": 0.0, "avg_logprob": -0.15367545151129003, "compression_ratio": 1.7380952380952381, "no_speech_prob": 3.2377297429775354e-06}, {"id": 332, "seek": 220532, "start": 2221.6000000000004, "end": 2231.48, "text": " designed for kind of super high speed high performance you know approach that can run", "tokens": [4761, 337, 733, 295, 1687, 1090, 3073, 1090, 3389, 291, 458, 3109, 300, 393, 1190], "temperature": 0.0, "avg_logprob": -0.15367545151129003, "compression_ratio": 1.7380952380952381, "no_speech_prob": 3.2377297429775354e-06}, {"id": 333, "seek": 223148, "start": 2231.48, "end": 2239.04, "text": " on both servers or on mobile phones and it does not require the whole Python and PyTorch", "tokens": [322, 1293, 15909, 420, 322, 6013, 10216, 293, 309, 775, 406, 3651, 264, 1379, 15329, 293, 9953, 51, 284, 339], "temperature": 0.0, "avg_logprob": -0.11317709359255704, "compression_ratio": 1.6875, "no_speech_prob": 2.561259179856279e-06}, {"id": 334, "seek": 223148, "start": 2239.04, "end": 2249.76, "text": " kind of runtime in place but it's much more complex and not using it's harder to debug", "tokens": [733, 295, 34474, 294, 1081, 457, 309, 311, 709, 544, 3997, 293, 406, 1228, 309, 311, 6081, 281, 24083], "temperature": 0.0, "avg_logprob": -0.11317709359255704, "compression_ratio": 1.6875, "no_speech_prob": 2.561259179856279e-06}, {"id": 335, "seek": 223148, "start": 2249.76, "end": 2255.88, "text": " and it's harder to set it up and it's harder to maintain it so if possible keep things", "tokens": [293, 309, 311, 6081, 281, 992, 309, 493, 293, 309, 311, 6081, 281, 6909, 309, 370, 498, 1944, 1066, 721], "temperature": 0.0, "avg_logprob": -0.11317709359255704, "compression_ratio": 1.6875, "no_speech_prob": 2.561259179856279e-06}, {"id": 336, "seek": 223148, "start": 2255.88, "end": 2261.44, "text": " simple and if you're lucky enough that you're so successful that you need to scale it up", "tokens": [2199, 293, 498, 291, 434, 6356, 1547, 300, 291, 434, 370, 4406, 300, 291, 643, 281, 4373, 309, 493], "temperature": 0.0, "avg_logprob": -0.11317709359255704, "compression_ratio": 1.6875, "no_speech_prob": 2.561259179856279e-06}, {"id": 337, "seek": 226144, "start": 2261.44, "end": 2268.36, "text": " to GPUs or stuff like that then great you know hopefully you've got the finances at", "tokens": [281, 18407, 82, 420, 1507, 411, 300, 550, 869, 291, 458, 4696, 291, 600, 658, 264, 25123, 412], "temperature": 0.0, "avg_logprob": -0.15805915061463702, "compression_ratio": 1.631336405529954, "no_speech_prob": 2.812994353007525e-06}, {"id": 338, "seek": 226144, "start": 2268.36, "end": 2276.96, "text": " that point to justify you know spending money on a O, N, X expert or serving expert or whatever", "tokens": [300, 935, 281, 20833, 291, 458, 6434, 1460, 322, 257, 422, 11, 426, 11, 1783, 5844, 420, 8148, 5844, 420, 2035], "temperature": 0.0, "avg_logprob": -0.15805915061463702, "compression_ratio": 1.631336405529954, "no_speech_prob": 2.812994353007525e-06}, {"id": 339, "seek": 226144, "start": 2276.96, "end": 2281.92, "text": " and there are various systems you can use to like O, N, X runtime and AWS SageMaker", "tokens": [293, 456, 366, 3683, 3652, 291, 393, 764, 281, 411, 422, 11, 426, 11, 1783, 34474, 293, 17650, 33812, 44, 4003], "temperature": 0.0, "avg_logprob": -0.15805915061463702, "compression_ratio": 1.631336405529954, "no_speech_prob": 2.812994353007525e-06}, {"id": 340, "seek": 226144, "start": 2281.92, "end": 2287.78, "text": " where you can kind of say here's my O, N, X bundle when it'll serve it for you or whatever", "tokens": [689, 291, 393, 733, 295, 584, 510, 311, 452, 422, 11, 426, 11, 1783, 24438, 562, 309, 603, 4596, 309, 337, 291, 420, 2035], "temperature": 0.0, "avg_logprob": -0.15805915061463702, "compression_ratio": 1.631336405529954, "no_speech_prob": 2.812994353007525e-06}, {"id": 341, "seek": 228778, "start": 2287.78, "end": 2294.1200000000003, "text": " PyTorch also has a mobile framework same idea.", "tokens": [9953, 51, 284, 339, 611, 575, 257, 6013, 8388, 912, 1558, 13], "temperature": 0.0, "avg_logprob": -0.09651131215302841, "compression_ratio": 1.6265060240963856, "no_speech_prob": 1.586997342428731e-07}, {"id": 342, "seek": 228778, "start": 2294.1200000000003, "end": 2298.7200000000003, "text": " So all right so you've got I mean it's kind of funny we're talking about two different", "tokens": [407, 439, 558, 370, 291, 600, 658, 286, 914, 309, 311, 733, 295, 4074, 321, 434, 1417, 466, 732, 819], "temperature": 0.0, "avg_logprob": -0.09651131215302841, "compression_ratio": 1.6265060240963856, "no_speech_prob": 1.586997342428731e-07}, {"id": 343, "seek": 228778, "start": 2298.7200000000003, "end": 2303.84, "text": " kinds of deployment here one is deploying like a hobby application you know that you're", "tokens": [3685, 295, 19317, 510, 472, 307, 34198, 411, 257, 18240, 3861, 291, 458, 300, 291, 434], "temperature": 0.0, "avg_logprob": -0.09651131215302841, "compression_ratio": 1.6265060240963856, "no_speech_prob": 1.586997342428731e-07}, {"id": 344, "seek": 228778, "start": 2303.84, "end": 2307.5600000000004, "text": " prototyping showing off to your friends to explaining to your colleagues how something", "tokens": [46219, 3381, 4099, 766, 281, 428, 1855, 281, 13468, 281, 428, 7734, 577, 746], "temperature": 0.0, "avg_logprob": -0.09651131215302841, "compression_ratio": 1.6265060240963856, "no_speech_prob": 1.586997342428731e-07}, {"id": 345, "seek": 228778, "start": 2307.5600000000004, "end": 2312.4, "text": " might work you know a little interactive analysis and that's one thing but maybe you're actually", "tokens": [1062, 589, 291, 458, 257, 707, 15141, 5215, 293, 300, 311, 472, 551, 457, 1310, 291, 434, 767], "temperature": 0.0, "avg_logprob": -0.09651131215302841, "compression_ratio": 1.6265060240963856, "no_speech_prob": 1.586997342428731e-07}, {"id": 346, "seek": 231240, "start": 2312.4, "end": 2319.04, "text": " prototyping something that you want to turn into a real product or an actual real part", "tokens": [46219, 3381, 746, 300, 291, 528, 281, 1261, 666, 257, 957, 1674, 420, 364, 3539, 957, 644], "temperature": 0.0, "avg_logprob": -0.1041327371989211, "compression_ratio": 1.6684782608695652, "no_speech_prob": 1.136558921643882e-06}, {"id": 347, "seek": 231240, "start": 2319.04, "end": 2328.96, "text": " of your company's operations when you're deploying you know something in real life there's all", "tokens": [295, 428, 2237, 311, 7705, 562, 291, 434, 34198, 291, 458, 746, 294, 957, 993, 456, 311, 439], "temperature": 0.0, "avg_logprob": -0.1041327371989211, "compression_ratio": 1.6684782608695652, "no_speech_prob": 1.136558921643882e-06}, {"id": 348, "seek": 231240, "start": 2328.96, "end": 2333.12, "text": " kinds of things you got to be careful of.", "tokens": [3685, 295, 721, 291, 658, 281, 312, 5026, 295, 13], "temperature": 0.0, "avg_logprob": -0.1041327371989211, "compression_ratio": 1.6684782608695652, "no_speech_prob": 1.136558921643882e-06}, {"id": 349, "seek": 231240, "start": 2333.12, "end": 2336.6, "text": " One example of something to be careful of is let's say you did exactly what we just", "tokens": [1485, 1365, 295, 746, 281, 312, 5026, 295, 307, 718, 311, 584, 291, 630, 2293, 437, 321, 445], "temperature": 0.0, "avg_logprob": -0.1041327371989211, "compression_ratio": 1.6684782608695652, "no_speech_prob": 1.136558921643882e-06}, {"id": 350, "seek": 233660, "start": 2336.6, "end": 2343.2799999999997, "text": " did which actually this is your homework is to create your own application right I want", "tokens": [630, 597, 767, 341, 307, 428, 14578, 307, 281, 1884, 428, 1065, 3861, 558, 286, 528], "temperature": 0.0, "avg_logprob": -0.11415008219276987, "compression_ratio": 1.7920792079207921, "no_speech_prob": 2.0377439113872242e-07}, {"id": 351, "seek": 233660, "start": 2343.2799999999997, "end": 2349.52, "text": " you to create your own image search application you can use my exact set of widgets and whatever", "tokens": [291, 281, 1884, 428, 1065, 3256, 3164, 3861, 291, 393, 764, 452, 1900, 992, 295, 43355, 293, 2035], "temperature": 0.0, "avg_logprob": -0.11415008219276987, "compression_ratio": 1.7920792079207921, "no_speech_prob": 2.0377439113872242e-07}, {"id": 352, "seek": 233660, "start": 2349.52, "end": 2354.36, "text": " if you want to but better still go to the iPy widgets website and see what other widgets", "tokens": [498, 291, 528, 281, 457, 1101, 920, 352, 281, 264, 5180, 88, 43355, 3144, 293, 536, 437, 661, 43355], "temperature": 0.0, "avg_logprob": -0.11415008219276987, "compression_ratio": 1.7920792079207921, "no_speech_prob": 2.0377439113872242e-07}, {"id": 353, "seek": 233660, "start": 2354.36, "end": 2359.72, "text": " they have and try and come up with something cool try and come you know try and show off", "tokens": [436, 362, 293, 853, 293, 808, 493, 365, 746, 1627, 853, 293, 808, 291, 458, 853, 293, 855, 766], "temperature": 0.0, "avg_logprob": -0.11415008219276987, "compression_ratio": 1.7920792079207921, "no_speech_prob": 2.0377439113872242e-07}, {"id": 354, "seek": 235972, "start": 2359.72, "end": 2367.7599999999998, "text": " as best as you can and show us on the forum now let's say you decided that you want to", "tokens": [382, 1151, 382, 291, 393, 293, 855, 505, 322, 264, 17542, 586, 718, 311, 584, 291, 3047, 300, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.0750042200088501, "compression_ratio": 1.7916666666666667, "no_speech_prob": 1.9333501768414862e-06}, {"id": 355, "seek": 235972, "start": 2367.7599999999998, "end": 2373.4399999999996, "text": " create an app that would help the users of your app decide if they have healthy skin", "tokens": [1884, 364, 724, 300, 576, 854, 264, 5022, 295, 428, 724, 4536, 498, 436, 362, 4627, 3178], "temperature": 0.0, "avg_logprob": -0.0750042200088501, "compression_ratio": 1.7916666666666667, "no_speech_prob": 1.9333501768414862e-06}, {"id": 356, "seek": 235972, "start": 2373.4399999999996, "end": 2378.12, "text": " or unhealthy skin so if you did the exact thing we just did rather than searching for", "tokens": [420, 29147, 3178, 370, 498, 291, 630, 264, 1900, 551, 321, 445, 630, 2831, 813, 10808, 337], "temperature": 0.0, "avg_logprob": -0.0750042200088501, "compression_ratio": 1.7916666666666667, "no_speech_prob": 1.9333501768414862e-06}, {"id": 357, "seek": 235972, "start": 2378.12, "end": 2383.7999999999997, "text": " grizzly bear and teddy bear and so forth on Bing you would search for healthy skin and", "tokens": [17865, 4313, 356, 6155, 293, 45116, 6155, 293, 370, 5220, 322, 30755, 291, 576, 3164, 337, 4627, 3178, 293], "temperature": 0.0, "avg_logprob": -0.0750042200088501, "compression_ratio": 1.7916666666666667, "no_speech_prob": 1.9333501768414862e-06}, {"id": 358, "seek": 238380, "start": 2383.8, "end": 2390.1200000000003, "text": " unhealthy skin right so here's what happens right if I and remember in our version we", "tokens": [29147, 3178, 558, 370, 510, 311, 437, 2314, 558, 498, 286, 293, 1604, 294, 527, 3037, 321], "temperature": 0.0, "avg_logprob": -0.09922609573755509, "compression_ratio": 1.736318407960199, "no_speech_prob": 1.6797179114291794e-06}, {"id": 359, "seek": 238380, "start": 2390.1200000000003, "end": 2395.48, "text": " never actually looked at Bing we just used the Bing API the image search API but behind", "tokens": [1128, 767, 2956, 412, 30755, 321, 445, 1143, 264, 30755, 9362, 264, 3256, 3164, 9362, 457, 2261], "temperature": 0.0, "avg_logprob": -0.09922609573755509, "compression_ratio": 1.736318407960199, "no_speech_prob": 1.6797179114291794e-06}, {"id": 360, "seek": 238380, "start": 2395.48, "end": 2401.2400000000002, "text": " the scenes it's just using the website right so if I click healthy if I type healthy skin", "tokens": [264, 8026, 309, 311, 445, 1228, 264, 3144, 558, 370, 498, 286, 2052, 4627, 498, 286, 2010, 4627, 3178], "temperature": 0.0, "avg_logprob": -0.09922609573755509, "compression_ratio": 1.736318407960199, "no_speech_prob": 1.6797179114291794e-06}, {"id": 361, "seek": 238380, "start": 2401.2400000000002, "end": 2410.3, "text": " and say search I actually discover that the definition of healthy skin is young white", "tokens": [293, 584, 3164, 286, 767, 4411, 300, 264, 7123, 295, 4627, 3178, 307, 2037, 2418], "temperature": 0.0, "avg_logprob": -0.09922609573755509, "compression_ratio": 1.736318407960199, "no_speech_prob": 1.6797179114291794e-06}, {"id": 362, "seek": 241030, "start": 2410.3, "end": 2419.1200000000003, "text": " women touching their face lovelingly so that's what your your healthy skin classifier would", "tokens": [2266, 11175, 641, 1851, 450, 779, 12163, 370, 300, 311, 437, 428, 428, 4627, 3178, 1508, 9902, 576], "temperature": 0.0, "avg_logprob": -0.11926862171718053, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.653680897106824e-06}, {"id": 363, "seek": 241030, "start": 2419.1200000000003, "end": 2427.1200000000003, "text": " learn to detect right and so this is so this is a great example from Deb Raji and you should", "tokens": [1466, 281, 5531, 558, 293, 370, 341, 307, 370, 341, 307, 257, 869, 1365, 490, 27347, 16745, 72, 293, 291, 820], "temperature": 0.0, "avg_logprob": -0.11926862171718053, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.653680897106824e-06}, {"id": 364, "seek": 241030, "start": 2427.1200000000003, "end": 2434.44, "text": " check out her paper actionable auditing for lots of cool insights about model bias but", "tokens": [1520, 484, 720, 3035, 45098, 2379, 1748, 337, 3195, 295, 1627, 14310, 466, 2316, 12577, 457], "temperature": 0.0, "avg_logprob": -0.11926862171718053, "compression_ratio": 1.5139664804469273, "no_speech_prob": 1.653680897106824e-06}, {"id": 365, "seek": 243444, "start": 2434.44, "end": 2440.32, "text": " I mean here's here's like a fascinating example of how if you weren't looking at your data", "tokens": [286, 914, 510, 311, 510, 311, 411, 257, 10343, 1365, 295, 577, 498, 291, 4999, 380, 1237, 412, 428, 1412], "temperature": 0.0, "avg_logprob": -0.07445933445390449, "compression_ratio": 1.7109004739336493, "no_speech_prob": 6.375533416758117e-07}, {"id": 366, "seek": 243444, "start": 2440.32, "end": 2447.32, "text": " carefully you you end up with something that doesn't at all actually solve the problem", "tokens": [7500, 291, 291, 917, 493, 365, 746, 300, 1177, 380, 412, 439, 767, 5039, 264, 1154], "temperature": 0.0, "avg_logprob": -0.07445933445390449, "compression_ratio": 1.7109004739336493, "no_speech_prob": 6.375533416758117e-07}, {"id": 367, "seek": 243444, "start": 2447.32, "end": 2458.68, "text": " you want to solve this is this is tricky right because the data that you train your algorithm", "tokens": [291, 528, 281, 5039, 341, 307, 341, 307, 12414, 558, 570, 264, 1412, 300, 291, 3847, 428, 9284], "temperature": 0.0, "avg_logprob": -0.07445933445390449, "compression_ratio": 1.7109004739336493, "no_speech_prob": 6.375533416758117e-07}, {"id": 368, "seek": 243444, "start": 2458.68, "end": 2463.64, "text": " on if you're building like a new product that didn't exist before by definition you don't", "tokens": [322, 498, 291, 434, 2390, 411, 257, 777, 1674, 300, 994, 380, 2514, 949, 538, 7123, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.07445933445390449, "compression_ratio": 1.7109004739336493, "no_speech_prob": 6.375533416758117e-07}, {"id": 369, "seek": 246364, "start": 2463.64, "end": 2468.3199999999997, "text": " have examples of the kind of data that's going to be used in real life right so you kind", "tokens": [362, 5110, 295, 264, 733, 295, 1412, 300, 311, 516, 281, 312, 1143, 294, 957, 993, 558, 370, 291, 733], "temperature": 0.0, "avg_logprob": -0.08650648316671682, "compression_ratio": 1.8020833333333333, "no_speech_prob": 1.5056943993840832e-06}, {"id": 370, "seek": 246364, "start": 2468.3199999999997, "end": 2474.52, "text": " of try to find some from somewhere and if they and if you do that through like a Google", "tokens": [295, 853, 281, 915, 512, 490, 4079, 293, 498, 436, 293, 498, 291, 360, 300, 807, 411, 257, 3329], "temperature": 0.0, "avg_logprob": -0.08650648316671682, "compression_ratio": 1.8020833333333333, "no_speech_prob": 1.5056943993840832e-06}, {"id": 371, "seek": 246364, "start": 2474.52, "end": 2480.04, "text": " search it's pretty likely you're not going to end up with a set of data that actually", "tokens": [3164, 309, 311, 1238, 3700, 291, 434, 406, 516, 281, 917, 493, 365, 257, 992, 295, 1412, 300, 767], "temperature": 0.0, "avg_logprob": -0.08650648316671682, "compression_ratio": 1.8020833333333333, "no_speech_prob": 1.5056943993840832e-06}, {"id": 372, "seek": 246364, "start": 2480.04, "end": 2490.4, "text": " reflects the kind of mix you would see in real life so you know the main thing here", "tokens": [18926, 264, 733, 295, 2890, 291, 576, 536, 294, 957, 993, 370, 291, 458, 264, 2135, 551, 510], "temperature": 0.0, "avg_logprob": -0.08650648316671682, "compression_ratio": 1.8020833333333333, "no_speech_prob": 1.5056943993840832e-06}, {"id": 373, "seek": 249040, "start": 2490.4, "end": 2495.28, "text": " is to say be careful right and and in particular for your test set you know that final set", "tokens": [307, 281, 584, 312, 5026, 558, 293, 293, 294, 1729, 337, 428, 1500, 992, 291, 458, 300, 2572, 992], "temperature": 0.0, "avg_logprob": -0.1312925967764347, "compression_ratio": 1.8237885462555066, "no_speech_prob": 1.1189395081601106e-06}, {"id": 374, "seek": 249040, "start": 2495.28, "end": 2502.28, "text": " that you check on really try hard to gather data that that reflects the real world so", "tokens": [300, 291, 1520, 322, 534, 853, 1152, 281, 5448, 1412, 300, 300, 18926, 264, 957, 1002, 370], "temperature": 0.0, "avg_logprob": -0.1312925967764347, "compression_ratio": 1.8237885462555066, "no_speech_prob": 1.1189395081601106e-06}, {"id": 375, "seek": 249040, "start": 2502.28, "end": 2507.28, "text": " like just you know for example for the healthy skin example you might go and actually talk", "tokens": [411, 445, 291, 458, 337, 1365, 337, 264, 4627, 3178, 1365, 291, 1062, 352, 293, 767, 751], "temperature": 0.0, "avg_logprob": -0.1312925967764347, "compression_ratio": 1.8237885462555066, "no_speech_prob": 1.1189395081601106e-06}, {"id": 376, "seek": 249040, "start": 2507.28, "end": 2511.28, "text": " to a dermatologist and try and find like 10 examples of healthy and unhealthy skin or", "tokens": [281, 257, 43706, 9201, 293, 853, 293, 915, 411, 1266, 5110, 295, 4627, 293, 29147, 3178, 420], "temperature": 0.0, "avg_logprob": -0.1312925967764347, "compression_ratio": 1.8237885462555066, "no_speech_prob": 1.1189395081601106e-06}, {"id": 377, "seek": 249040, "start": 2511.28, "end": 2519.32, "text": " something and that would be your kind of gold standard test.", "tokens": [746, 293, 300, 576, 312, 428, 733, 295, 3821, 3832, 1500, 13], "temperature": 0.0, "avg_logprob": -0.1312925967764347, "compression_ratio": 1.8237885462555066, "no_speech_prob": 1.1189395081601106e-06}, {"id": 378, "seek": 251932, "start": 2519.32, "end": 2524.38, "text": " There's all kinds of issues you have to think about in deployment I can't cover all of them", "tokens": [821, 311, 439, 3685, 295, 2663, 291, 362, 281, 519, 466, 294, 19317, 286, 393, 380, 2060, 439, 295, 552], "temperature": 0.0, "avg_logprob": -0.15213532780492028, "compression_ratio": 1.5594713656387664, "no_speech_prob": 3.0415792480198434e-06}, {"id": 379, "seek": 251932, "start": 2524.38, "end": 2531.88, "text": " I can tell you that this O'Reilly book called building machine learning powered applications", "tokens": [286, 393, 980, 291, 300, 341, 422, 6, 8524, 6917, 1446, 1219, 2390, 3479, 2539, 17786, 5821], "temperature": 0.0, "avg_logprob": -0.15213532780492028, "compression_ratio": 1.5594713656387664, "no_speech_prob": 3.0415792480198434e-06}, {"id": 380, "seek": 251932, "start": 2531.88, "end": 2539.7200000000003, "text": " is is a great resource and this is one of the reasons we don't go into detail about", "tokens": [307, 307, 257, 869, 7684, 293, 341, 307, 472, 295, 264, 4112, 321, 500, 380, 352, 666, 2607, 466], "temperature": 0.0, "avg_logprob": -0.15213532780492028, "compression_ratio": 1.5594713656387664, "no_speech_prob": 3.0415792480198434e-06}, {"id": 381, "seek": 251932, "start": 2539.7200000000003, "end": 2545.48, "text": " a P2 a B testing and when should we refresh our data and how do we monitor things and", "tokens": [257, 430, 17, 257, 363, 4997, 293, 562, 820, 321, 15134, 527, 1412, 293, 577, 360, 321, 6002, 721, 293], "temperature": 0.0, "avg_logprob": -0.15213532780492028, "compression_ratio": 1.5594713656387664, "no_speech_prob": 3.0415792480198434e-06}, {"id": 382, "seek": 254548, "start": 2545.48, "end": 2553.96, "text": " so forth is because that book's already been written so we don't want to rewrite it.", "tokens": [370, 5220, 307, 570, 300, 1446, 311, 1217, 668, 3720, 370, 321, 500, 380, 528, 281, 28132, 309, 13], "temperature": 0.0, "avg_logprob": -0.12098274674526481, "compression_ratio": 1.6495327102803738, "no_speech_prob": 2.260319661218091e-06}, {"id": 383, "seek": 254548, "start": 2553.96, "end": 2562.72, "text": " I do want to mention a particular area that I care a lot about though which is let's take", "tokens": [286, 360, 528, 281, 2152, 257, 1729, 1859, 300, 286, 1127, 257, 688, 466, 1673, 597, 307, 718, 311, 747], "temperature": 0.0, "avg_logprob": -0.12098274674526481, "compression_ratio": 1.6495327102803738, "no_speech_prob": 2.260319661218091e-06}, {"id": 384, "seek": 254548, "start": 2562.72, "end": 2567.28, "text": " this example let's say you're rolling out this bear detection system and it's going", "tokens": [341, 1365, 718, 311, 584, 291, 434, 9439, 484, 341, 6155, 17784, 1185, 293, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.12098274674526481, "compression_ratio": 1.6495327102803738, "no_speech_prob": 2.260319661218091e-06}, {"id": 385, "seek": 254548, "start": 2567.28, "end": 2573.16, "text": " to be attached to video cameras around a campsite it's going to warn campers of incoming bears", "tokens": [281, 312, 8570, 281, 960, 8622, 926, 257, 16573, 642, 309, 311, 516, 281, 12286, 2255, 433, 295, 22341, 17276], "temperature": 0.0, "avg_logprob": -0.12098274674526481, "compression_ratio": 1.6495327102803738, "no_speech_prob": 2.260319661218091e-06}, {"id": 386, "seek": 257316, "start": 2573.16, "end": 2578.8399999999997, "text": " so if we used a model that was trained with that data that we just looked at you know", "tokens": [370, 498, 321, 1143, 257, 2316, 300, 390, 8895, 365, 300, 1412, 300, 321, 445, 2956, 412, 291, 458], "temperature": 0.0, "avg_logprob": -0.09778164844123685, "compression_ratio": 1.8125, "no_speech_prob": 1.8738701328402385e-06}, {"id": 387, "seek": 257316, "start": 2578.8399999999997, "end": 2586.64, "text": " those are all very nicely taken pictures of pretty perfect bears right there's really", "tokens": [729, 366, 439, 588, 9594, 2726, 5242, 295, 1238, 2176, 17276, 558, 456, 311, 534], "temperature": 0.0, "avg_logprob": -0.09778164844123685, "compression_ratio": 1.8125, "no_speech_prob": 1.8738701328402385e-06}, {"id": 388, "seek": 257316, "start": 2586.64, "end": 2590.56, "text": " no relationship to the kinds of pictures you're actually going to have to be dealing with", "tokens": [572, 2480, 281, 264, 3685, 295, 5242, 291, 434, 767, 516, 281, 362, 281, 312, 6260, 365], "temperature": 0.0, "avg_logprob": -0.09778164844123685, "compression_ratio": 1.8125, "no_speech_prob": 1.8738701328402385e-06}, {"id": 389, "seek": 257316, "start": 2590.56, "end": 2595.08, "text": " in your in your campsite bear detector which has it's going to have video and not images", "tokens": [294, 428, 294, 428, 16573, 642, 6155, 25712, 597, 575, 309, 311, 516, 281, 362, 960, 293, 406, 5267], "temperature": 0.0, "avg_logprob": -0.09778164844123685, "compression_ratio": 1.8125, "no_speech_prob": 1.8738701328402385e-06}, {"id": 390, "seek": 257316, "start": 2595.08, "end": 2601.96, "text": " it's going to be nighttime it's going to be probably low resolution security cameras", "tokens": [309, 311, 516, 281, 312, 38595, 309, 311, 516, 281, 312, 1391, 2295, 8669, 3825, 8622], "temperature": 0.0, "avg_logprob": -0.09778164844123685, "compression_ratio": 1.8125, "no_speech_prob": 1.8738701328402385e-06}, {"id": 391, "seek": 260196, "start": 2601.96, "end": 2606.08, "text": " you need to make sure that the performance of the system is fast enough to tell you about", "tokens": [291, 643, 281, 652, 988, 300, 264, 3389, 295, 264, 1185, 307, 2370, 1547, 281, 980, 291, 466], "temperature": 0.0, "avg_logprob": -0.07621957922494539, "compression_ratio": 1.7543859649122806, "no_speech_prob": 1.7061740891222144e-06}, {"id": 392, "seek": 260196, "start": 2606.08, "end": 2611.6, "text": " it before the bear kills you you know there will be bears that are partially obscured", "tokens": [309, 949, 264, 6155, 14563, 291, 291, 458, 456, 486, 312, 17276, 300, 366, 18886, 22082, 3831], "temperature": 0.0, "avg_logprob": -0.07621957922494539, "compression_ratio": 1.7543859649122806, "no_speech_prob": 1.7061740891222144e-06}, {"id": 393, "seek": 260196, "start": 2611.6, "end": 2616.08, "text": " by bushes or in lots of shadow or whatever none of which are the kinds of things you", "tokens": [538, 34303, 420, 294, 3195, 295, 8576, 420, 2035, 6022, 295, 597, 366, 264, 3685, 295, 721, 291], "temperature": 0.0, "avg_logprob": -0.07621957922494539, "compression_ratio": 1.7543859649122806, "no_speech_prob": 1.7061740891222144e-06}, {"id": 394, "seek": 260196, "start": 2616.08, "end": 2619.92, "text": " would see normally in like internet pictures.", "tokens": [576, 536, 5646, 294, 411, 4705, 5242, 13], "temperature": 0.0, "avg_logprob": -0.07621957922494539, "compression_ratio": 1.7543859649122806, "no_speech_prob": 1.7061740891222144e-06}, {"id": 395, "seek": 260196, "start": 2619.92, "end": 2625.28, "text": " So what we call this we call this out of domain data out of domain data refers to a situation", "tokens": [407, 437, 321, 818, 341, 321, 818, 341, 484, 295, 9274, 1412, 484, 295, 9274, 1412, 14942, 281, 257, 2590], "temperature": 0.0, "avg_logprob": -0.07621957922494539, "compression_ratio": 1.7543859649122806, "no_speech_prob": 1.7061740891222144e-06}, {"id": 396, "seek": 262528, "start": 2625.28, "end": 2632.44, "text": " where the data that you are trying to do inference on is in some way different to the kind of", "tokens": [689, 264, 1412, 300, 291, 366, 1382, 281, 360, 38253, 322, 307, 294, 512, 636, 819, 281, 264, 733, 295], "temperature": 0.0, "avg_logprob": -0.049771768501005974, "compression_ratio": 1.6790697674418604, "no_speech_prob": 1.349698550257017e-06}, {"id": 397, "seek": 262528, "start": 2632.44, "end": 2642.1600000000003, "text": " data that you trained with and this is actually there's no perfect way to answer this question", "tokens": [1412, 300, 291, 8895, 365, 293, 341, 307, 767, 456, 311, 572, 2176, 636, 281, 1867, 341, 1168], "temperature": 0.0, "avg_logprob": -0.049771768501005974, "compression_ratio": 1.6790697674418604, "no_speech_prob": 1.349698550257017e-06}, {"id": 398, "seek": 262528, "start": 2642.1600000000003, "end": 2649.4, "text": " and when we look at ethics we'll talk about some really helpful ways to to minimize how", "tokens": [293, 562, 321, 574, 412, 19769, 321, 603, 751, 466, 512, 534, 4961, 2098, 281, 281, 17522, 577], "temperature": 0.0, "avg_logprob": -0.049771768501005974, "compression_ratio": 1.6790697674418604, "no_speech_prob": 1.349698550257017e-06}, {"id": 399, "seek": 262528, "start": 2649.4, "end": 2654.8, "text": " much this happens for example it turns out that having a diverse team is a great way", "tokens": [709, 341, 2314, 337, 1365, 309, 4523, 484, 300, 1419, 257, 9521, 1469, 307, 257, 869, 636], "temperature": 0.0, "avg_logprob": -0.049771768501005974, "compression_ratio": 1.6790697674418604, "no_speech_prob": 1.349698550257017e-06}, {"id": 400, "seek": 265480, "start": 2654.8, "end": 2662.88, "text": " to kind of avoid being surprised by the kinds of data that people end up coming up with", "tokens": [281, 733, 295, 5042, 885, 6100, 538, 264, 3685, 295, 1412, 300, 561, 917, 493, 1348, 493, 365], "temperature": 0.0, "avg_logprob": -0.06911684274673462, "compression_ratio": 1.7626262626262625, "no_speech_prob": 7.338187515415484e-07}, {"id": 401, "seek": 265480, "start": 2662.88, "end": 2669.54, "text": " but really it's just something you've got to be super thoughtful about very similar", "tokens": [457, 534, 309, 311, 445, 746, 291, 600, 658, 281, 312, 1687, 21566, 466, 588, 2531], "temperature": 0.0, "avg_logprob": -0.06911684274673462, "compression_ratio": 1.7626262626262625, "no_speech_prob": 7.338187515415484e-07}, {"id": 402, "seek": 265480, "start": 2669.54, "end": 2674.96, "text": " to that is something called domain shift and domain shift is where maybe you start out", "tokens": [281, 300, 307, 746, 1219, 9274, 5513, 293, 9274, 5513, 307, 689, 1310, 291, 722, 484], "temperature": 0.0, "avg_logprob": -0.06911684274673462, "compression_ratio": 1.7626262626262625, "no_speech_prob": 7.338187515415484e-07}, {"id": 403, "seek": 265480, "start": 2674.96, "end": 2681.36, "text": " with all of your data is in domain data but over time the kinds of data that you're seeing", "tokens": [365, 439, 295, 428, 1412, 307, 294, 9274, 1412, 457, 670, 565, 264, 3685, 295, 1412, 300, 291, 434, 2577], "temperature": 0.0, "avg_logprob": -0.06911684274673462, "compression_ratio": 1.7626262626262625, "no_speech_prob": 7.338187515415484e-07}, {"id": 404, "seek": 268136, "start": 2681.36, "end": 2689.52, "text": " changes and so over time maybe raccoons start invading your campsite and you weren't training", "tokens": [2962, 293, 370, 670, 565, 1310, 4129, 1291, 892, 722, 1048, 8166, 428, 16573, 642, 293, 291, 4999, 380, 3097], "temperature": 0.0, "avg_logprob": -0.15446078777313232, "compression_ratio": 1.7042801556420233, "no_speech_prob": 1.9947219698224217e-06}, {"id": 405, "seek": 268136, "start": 2689.52, "end": 2693.56, "text": " on raccoons before it was just a bear detector and so that's called domain shift and that's", "tokens": [322, 4129, 1291, 892, 949, 309, 390, 445, 257, 6155, 25712, 293, 370, 300, 311, 1219, 9274, 5513, 293, 300, 311], "temperature": 0.0, "avg_logprob": -0.15446078777313232, "compression_ratio": 1.7042801556420233, "no_speech_prob": 1.9947219698224217e-06}, {"id": 406, "seek": 268136, "start": 2693.56, "end": 2695.88, "text": " another thing that you have to be very careful of.", "tokens": [1071, 551, 300, 291, 362, 281, 312, 588, 5026, 295, 13], "temperature": 0.0, "avg_logprob": -0.15446078777313232, "compression_ratio": 1.7042801556420233, "no_speech_prob": 1.9947219698224217e-06}, {"id": 407, "seek": 268136, "start": 2695.88, "end": 2697.36, "text": " Rachel was your question?", "tokens": [14246, 390, 428, 1168, 30], "temperature": 0.0, "avg_logprob": -0.15446078777313232, "compression_ratio": 1.7042801556420233, "no_speech_prob": 1.9947219698224217e-06}, {"id": 408, "seek": 268136, "start": 2697.36, "end": 2703.7400000000002, "text": " No I was just going to add to that in saying that all data is biased so there's not kind", "tokens": [883, 286, 390, 445, 516, 281, 909, 281, 300, 294, 1566, 300, 439, 1412, 307, 28035, 370, 456, 311, 406, 733], "temperature": 0.0, "avg_logprob": -0.15446078777313232, "compression_ratio": 1.7042801556420233, "no_speech_prob": 1.9947219698224217e-06}, {"id": 409, "seek": 268136, "start": 2703.7400000000002, "end": 2710.4, "text": " of a you know a form of a de-biased data or perfectly representative in all cases data", "tokens": [295, 257, 291, 458, 257, 1254, 295, 257, 368, 12, 5614, 1937, 1412, 420, 6239, 12424, 294, 439, 3331, 1412], "temperature": 0.0, "avg_logprob": -0.15446078777313232, "compression_ratio": 1.7042801556420233, "no_speech_prob": 1.9947219698224217e-06}, {"id": 410, "seek": 271040, "start": 2710.4, "end": 2714.4, "text": " and that a lot of the proposals around addressing this have kind of been converging to this", "tokens": [293, 300, 257, 688, 295, 264, 20198, 926, 14329, 341, 362, 733, 295, 668, 9652, 3249, 281, 341], "temperature": 0.0, "avg_logprob": -0.09732318841494046, "compression_ratio": 1.8264462809917354, "no_speech_prob": 1.5204967894533183e-05}, {"id": 411, "seek": 271040, "start": 2714.4, "end": 2721.04, "text": " idea and that you see in papers like Timnit Gebru's data sheets for data sets of just", "tokens": [1558, 293, 300, 291, 536, 294, 10577, 411, 7172, 77, 270, 2876, 7294, 311, 1412, 15421, 337, 1412, 6352, 295, 445], "temperature": 0.0, "avg_logprob": -0.09732318841494046, "compression_ratio": 1.8264462809917354, "no_speech_prob": 1.5204967894533183e-05}, {"id": 412, "seek": 271040, "start": 2721.04, "end": 2726.64, "text": " writing down a lot of the details about your data set and how it was gathered and in which", "tokens": [3579, 760, 257, 688, 295, 264, 4365, 466, 428, 1412, 992, 293, 577, 309, 390, 13032, 293, 294, 597], "temperature": 0.0, "avg_logprob": -0.09732318841494046, "compression_ratio": 1.8264462809917354, "no_speech_prob": 1.5204967894533183e-05}, {"id": 413, "seek": 271040, "start": 2726.64, "end": 2732.64, "text": " situations it's appropriate to use and how it was maintained and so there that's not", "tokens": [6851, 309, 311, 6854, 281, 764, 293, 577, 309, 390, 17578, 293, 370, 456, 300, 311, 406], "temperature": 0.0, "avg_logprob": -0.09732318841494046, "compression_ratio": 1.8264462809917354, "no_speech_prob": 1.5204967894533183e-05}, {"id": 414, "seek": 271040, "start": 2732.64, "end": 2737.08, "text": " that you've totally eliminated bias but that you're just very aware of the attributes of", "tokens": [300, 291, 600, 3879, 20308, 12577, 457, 300, 291, 434, 445, 588, 3650, 295, 264, 17212, 295], "temperature": 0.0, "avg_logprob": -0.09732318841494046, "compression_ratio": 1.8264462809917354, "no_speech_prob": 1.5204967894533183e-05}, {"id": 415, "seek": 273708, "start": 2737.08, "end": 2741.44, "text": " your data set so that you won't be blindsided by them later and there have been kind of", "tokens": [428, 1412, 992, 370, 300, 291, 1582, 380, 312, 6865, 30941, 538, 552, 1780, 293, 456, 362, 668, 733, 295], "temperature": 0.0, "avg_logprob": -0.14921736162762309, "compression_ratio": 1.6167400881057268, "no_speech_prob": 3.4465419957996346e-06}, {"id": 416, "seek": 273708, "start": 2741.44, "end": 2746.56, "text": " several proposals in that school of thought which I which I really like around this idea", "tokens": [2940, 20198, 294, 300, 1395, 295, 1194, 597, 286, 597, 286, 534, 411, 926, 341, 1558], "temperature": 0.0, "avg_logprob": -0.14921736162762309, "compression_ratio": 1.6167400881057268, "no_speech_prob": 3.4465419957996346e-06}, {"id": 417, "seek": 273708, "start": 2746.56, "end": 2754.4, "text": " of just kind of understanding how your data was gathered and what its limitations are.", "tokens": [295, 445, 733, 295, 3701, 577, 428, 1412, 390, 13032, 293, 437, 1080, 15705, 366, 13], "temperature": 0.0, "avg_logprob": -0.14921736162762309, "compression_ratio": 1.6167400881057268, "no_speech_prob": 3.4465419957996346e-06}, {"id": 418, "seek": 273708, "start": 2754.4, "end": 2756.84, "text": " Thanks Rachel.", "tokens": [2561, 14246, 13], "temperature": 0.0, "avg_logprob": -0.14921736162762309, "compression_ratio": 1.6167400881057268, "no_speech_prob": 3.4465419957996346e-06}, {"id": 419, "seek": 273708, "start": 2756.84, "end": 2765.7999999999997, "text": " So a key problem here is that you can't know the entire behavior of your neural network.", "tokens": [407, 257, 2141, 1154, 510, 307, 300, 291, 393, 380, 458, 264, 2302, 5223, 295, 428, 18161, 3209, 13], "temperature": 0.0, "avg_logprob": -0.14921736162762309, "compression_ratio": 1.6167400881057268, "no_speech_prob": 3.4465419957996346e-06}, {"id": 420, "seek": 276580, "start": 2765.8, "end": 2770.92, "text": " With normal programming you typed in the if statements and the loops and whatever so in", "tokens": [2022, 2710, 9410, 291, 33941, 294, 264, 498, 12363, 293, 264, 16121, 293, 2035, 370, 294], "temperature": 0.0, "avg_logprob": -0.09770172946857957, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.0415567380259745e-06}, {"id": 421, "seek": 276580, "start": 2770.92, "end": 2775.1200000000003, "text": " theory you know what the hell it does although it's still sometimes surprising.", "tokens": [5261, 291, 458, 437, 264, 4921, 309, 775, 4878, 309, 311, 920, 2171, 8830, 13], "temperature": 0.0, "avg_logprob": -0.09770172946857957, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.0415567380259745e-06}, {"id": 422, "seek": 276580, "start": 2775.1200000000003, "end": 2780.2400000000002, "text": " In this case you you didn't tell it anything you just gave it examples to learn from and", "tokens": [682, 341, 1389, 291, 291, 994, 380, 980, 309, 1340, 291, 445, 2729, 309, 5110, 281, 1466, 490, 293], "temperature": 0.0, "avg_logprob": -0.09770172946857957, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.0415567380259745e-06}, {"id": 423, "seek": 276580, "start": 2780.2400000000002, "end": 2783.0800000000004, "text": " hope that it learned something useful.", "tokens": [1454, 300, 309, 3264, 746, 4420, 13], "temperature": 0.0, "avg_logprob": -0.09770172946857957, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.0415567380259745e-06}, {"id": 424, "seek": 276580, "start": 2783.0800000000004, "end": 2786.5, "text": " There are hundreds of millions of parameters in a lot of these neural networks and so there's", "tokens": [821, 366, 6779, 295, 6803, 295, 9834, 294, 257, 688, 295, 613, 18161, 9590, 293, 370, 456, 311], "temperature": 0.0, "avg_logprob": -0.09770172946857957, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.0415567380259745e-06}, {"id": 425, "seek": 276580, "start": 2786.5, "end": 2792.0800000000004, "text": " no way you can understand how they all combine with each other to create complex behavior.", "tokens": [572, 636, 291, 393, 1223, 577, 436, 439, 10432, 365, 1184, 661, 281, 1884, 3997, 5223, 13], "temperature": 0.0, "avg_logprob": -0.09770172946857957, "compression_ratio": 1.6842105263157894, "no_speech_prob": 3.0415567380259745e-06}, {"id": 426, "seek": 279208, "start": 2792.08, "end": 2798.68, "text": " So really like there's a natural compromise here is that we're trying to get sophisticated", "tokens": [407, 534, 411, 456, 311, 257, 3303, 18577, 510, 307, 300, 321, 434, 1382, 281, 483, 16950], "temperature": 0.0, "avg_logprob": -0.09248503152426187, "compression_ratio": 1.736040609137056, "no_speech_prob": 2.7420841774983273e-07}, {"id": 427, "seek": 279208, "start": 2798.68, "end": 2805.6, "text": " behavior so like like recognizing pictures sophisticated enough behavior we can't describe", "tokens": [5223, 370, 411, 411, 18538, 5242, 16950, 1547, 5223, 321, 393, 380, 6786], "temperature": 0.0, "avg_logprob": -0.09248503152426187, "compression_ratio": 1.736040609137056, "no_speech_prob": 2.7420841774983273e-07}, {"id": 428, "seek": 279208, "start": 2805.6, "end": 2811.2, "text": " it and so the natural downside is you can't expect the process that the thing is using", "tokens": [309, 293, 370, 264, 3303, 25060, 307, 291, 393, 380, 2066, 264, 1399, 300, 264, 551, 307, 1228], "temperature": 0.0, "avg_logprob": -0.09248503152426187, "compression_ratio": 1.736040609137056, "no_speech_prob": 2.7420841774983273e-07}, {"id": 429, "seek": 279208, "start": 2811.2, "end": 2815.68, "text": " to do that to be describable for you for you to be able to understand it.", "tokens": [281, 360, 300, 281, 312, 2189, 65, 712, 337, 291, 337, 291, 281, 312, 1075, 281, 1223, 309, 13], "temperature": 0.0, "avg_logprob": -0.09248503152426187, "compression_ratio": 1.736040609137056, "no_speech_prob": 2.7420841774983273e-07}, {"id": 430, "seek": 281568, "start": 2815.68, "end": 2822.08, "text": " So our recommendation for kind of dealing with these issues is a very careful deployment", "tokens": [407, 527, 11879, 337, 733, 295, 6260, 365, 613, 2663, 307, 257, 588, 5026, 19317], "temperature": 0.0, "avg_logprob": -0.09681692027082348, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.1365596037649084e-06}, {"id": 431, "seek": 281568, "start": 2822.08, "end": 2827.68, "text": " strategy which I've summarized in this little graph this little chart here.", "tokens": [5206, 597, 286, 600, 14611, 1602, 294, 341, 707, 4295, 341, 707, 6927, 510, 13], "temperature": 0.0, "avg_logprob": -0.09681692027082348, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.1365596037649084e-06}, {"id": 432, "seek": 281568, "start": 2827.68, "end": 2833.3599999999997, "text": " The idea would be first of all whatever it is that you're going to use the model for", "tokens": [440, 1558, 576, 312, 700, 295, 439, 2035, 309, 307, 300, 291, 434, 516, 281, 764, 264, 2316, 337], "temperature": 0.0, "avg_logprob": -0.09681692027082348, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.1365596037649084e-06}, {"id": 433, "seek": 281568, "start": 2833.3599999999997, "end": 2840.3799999999997, "text": " start out by doing it manually so have a have a park ranger watching for bears have the", "tokens": [722, 484, 538, 884, 309, 16945, 370, 362, 257, 362, 257, 3884, 367, 3176, 1976, 337, 17276, 362, 264], "temperature": 0.0, "avg_logprob": -0.09681692027082348, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.1365596037649084e-06}, {"id": 434, "seek": 281568, "start": 2840.3799999999997, "end": 2845.56, "text": " model running next to them and each time the park ranger sees a bear they can check the", "tokens": [2316, 2614, 958, 281, 552, 293, 1184, 565, 264, 3884, 367, 3176, 8194, 257, 6155, 436, 393, 1520, 264], "temperature": 0.0, "avg_logprob": -0.09681692027082348, "compression_ratio": 1.6732283464566928, "no_speech_prob": 1.1365596037649084e-06}, {"id": 435, "seek": 284556, "start": 2845.56, "end": 2848.9, "text": " model and see like did it seem to have picked it up.", "tokens": [2316, 293, 536, 411, 630, 309, 1643, 281, 362, 6183, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.11258930089522382, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.812512770513422e-07}, {"id": 436, "seek": 284556, "start": 2848.9, "end": 2853.36, "text": " So the model is not doing anything there's just a person who's like running it and seeing", "tokens": [407, 264, 2316, 307, 406, 884, 1340, 456, 311, 445, 257, 954, 567, 311, 411, 2614, 309, 293, 2577], "temperature": 0.0, "avg_logprob": -0.11258930089522382, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.812512770513422e-07}, {"id": 437, "seek": 284556, "start": 2853.36, "end": 2858.7999999999997, "text": " would have made sensible choices and once you're confident that it makes sense that", "tokens": [576, 362, 1027, 25380, 7994, 293, 1564, 291, 434, 6679, 300, 309, 1669, 2020, 300], "temperature": 0.0, "avg_logprob": -0.11258930089522382, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.812512770513422e-07}, {"id": 438, "seek": 284556, "start": 2858.7999999999997, "end": 2865.08, "text": " what it's doing seems reasonable in you know it's been as close to the real-life situation", "tokens": [437, 309, 311, 884, 2544, 10585, 294, 291, 458, 309, 311, 668, 382, 1998, 281, 264, 957, 12, 9073, 2590], "temperature": 0.0, "avg_logprob": -0.11258930089522382, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.812512770513422e-07}, {"id": 439, "seek": 284556, "start": 2865.08, "end": 2874.7999999999997, "text": " as possible then deploy it in a time and geography limited way so pick like one campsite not", "tokens": [382, 1944, 550, 7274, 309, 294, 257, 565, 293, 26695, 5567, 636, 370, 1888, 411, 472, 16573, 642, 406], "temperature": 0.0, "avg_logprob": -0.11258930089522382, "compression_ratio": 1.7226890756302522, "no_speech_prob": 4.812512770513422e-07}, {"id": 440, "seek": 287480, "start": 2874.8, "end": 2882.2000000000003, "text": " the entirety of California and do it for you know one day and have somebody watching it", "tokens": [264, 31557, 295, 5384, 293, 360, 309, 337, 291, 458, 472, 786, 293, 362, 2618, 1976, 309], "temperature": 0.0, "avg_logprob": -0.09118169148763021, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8573069812409813e-06}, {"id": 441, "seek": 287480, "start": 2882.2000000000003, "end": 2884.4, "text": " super carefully right.", "tokens": [1687, 7500, 558, 13], "temperature": 0.0, "avg_logprob": -0.09118169148763021, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8573069812409813e-06}, {"id": 442, "seek": 287480, "start": 2884.4, "end": 2889.04, "text": " So now the basic bear detection is being done by the bear detector but there's still somebody", "tokens": [407, 586, 264, 3875, 6155, 17784, 307, 885, 1096, 538, 264, 6155, 25712, 457, 456, 311, 920, 2618], "temperature": 0.0, "avg_logprob": -0.09118169148763021, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8573069812409813e-06}, {"id": 443, "seek": 287480, "start": 2889.04, "end": 2894.6000000000004, "text": " watching it pretty closely and it's only happening in one campsite for one day and so then as", "tokens": [1976, 309, 1238, 8185, 293, 309, 311, 787, 2737, 294, 472, 16573, 642, 337, 472, 786, 293, 370, 550, 382], "temperature": 0.0, "avg_logprob": -0.09118169148763021, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8573069812409813e-06}, {"id": 444, "seek": 287480, "start": 2894.6000000000004, "end": 2901.6400000000003, "text": " you say like okay we haven't destroyed our company yet so let's do two campsites for", "tokens": [291, 584, 411, 1392, 321, 2378, 380, 8937, 527, 2237, 1939, 370, 718, 311, 360, 732, 16573, 3324, 337], "temperature": 0.0, "avg_logprob": -0.09118169148763021, "compression_ratio": 1.7174887892376682, "no_speech_prob": 2.8573069812409813e-06}, {"id": 445, "seek": 290164, "start": 2901.64, "end": 2907.48, "text": " a week and then let's do you know the entirety of Marin for a month and so forth.", "tokens": [257, 1243, 293, 550, 718, 311, 360, 291, 458, 264, 31557, 295, 43016, 337, 257, 1618, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.1037749081123166, "compression_ratio": 1.7205882352941178, "no_speech_prob": 1.3496990050043678e-06}, {"id": 446, "seek": 290164, "start": 2907.48, "end": 2914.8799999999997, "text": " So this is actually what we did when I used to be at this company called optimal decisions", "tokens": [407, 341, 307, 767, 437, 321, 630, 562, 286, 1143, 281, 312, 412, 341, 2237, 1219, 16252, 5327], "temperature": 0.0, "avg_logprob": -0.1037749081123166, "compression_ratio": 1.7205882352941178, "no_speech_prob": 1.3496990050043678e-06}, {"id": 447, "seek": 290164, "start": 2914.8799999999997, "end": 2920.2799999999997, "text": " optimal decisions was a company that I founded to do insurance pricing and if you if you", "tokens": [16252, 5327, 390, 257, 2237, 300, 286, 13234, 281, 360, 7214, 17621, 293, 498, 291, 498, 291], "temperature": 0.0, "avg_logprob": -0.1037749081123166, "compression_ratio": 1.7205882352941178, "no_speech_prob": 1.3496990050043678e-06}, {"id": 448, "seek": 290164, "start": 2920.2799999999997, "end": 2927.52, "text": " change insurance prices by you know a percent or two in the wrong direction the wrong way", "tokens": [1319, 7214, 7901, 538, 291, 458, 257, 3043, 420, 732, 294, 264, 2085, 3513, 264, 2085, 636], "temperature": 0.0, "avg_logprob": -0.1037749081123166, "compression_ratio": 1.7205882352941178, "no_speech_prob": 1.3496990050043678e-06}, {"id": 449, "seek": 292752, "start": 2927.52, "end": 2932.68, "text": " you can basically destroy the whole company this has happened many times you know insurers", "tokens": [291, 393, 1936, 5293, 264, 1379, 2237, 341, 575, 2011, 867, 1413, 291, 458, 1028, 14198], "temperature": 0.0, "avg_logprob": -0.09721031188964843, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.6305063965660338e-09}, {"id": 450, "seek": 292752, "start": 2932.68, "end": 2940.0, "text": " are companies that set prices that's basically the product that they provide so when we deployed", "tokens": [366, 3431, 300, 992, 7901, 300, 311, 1936, 264, 1674, 300, 436, 2893, 370, 562, 321, 17826], "temperature": 0.0, "avg_logprob": -0.09721031188964843, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.6305063965660338e-09}, {"id": 451, "seek": 292752, "start": 2940.0, "end": 2945.28, "text": " new prices for optimal decisions we always did it by like saying like okay we're going", "tokens": [777, 7901, 337, 16252, 5327, 321, 1009, 630, 309, 538, 411, 1566, 411, 1392, 321, 434, 516], "temperature": 0.0, "avg_logprob": -0.09721031188964843, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.6305063965660338e-09}, {"id": 452, "seek": 292752, "start": 2945.28, "end": 2951.56, "text": " to do it for like five minutes or everybody whose name ends with a D you know so we'd", "tokens": [281, 360, 309, 337, 411, 1732, 2077, 420, 2201, 6104, 1315, 5314, 365, 257, 413, 291, 458, 370, 321, 1116], "temperature": 0.0, "avg_logprob": -0.09721031188964843, "compression_ratio": 1.6744186046511629, "no_speech_prob": 1.6305063965660338e-09}, {"id": 453, "seek": 295156, "start": 2951.56, "end": 2958.72, "text": " kind of try to find some group which hopefully would be fairly you know it'll be different", "tokens": [733, 295, 853, 281, 915, 512, 1594, 597, 4696, 576, 312, 6457, 291, 458, 309, 603, 312, 819], "temperature": 0.0, "avg_logprob": -0.0765105128288269, "compression_ratio": 1.6650717703349283, "no_speech_prob": 2.29589500122529e-06}, {"id": 454, "seek": 295156, "start": 2958.72, "end": 2962.56, "text": " but not too many of them and we'd gradually scale it up and you've got to make sure that", "tokens": [457, 406, 886, 867, 295, 552, 293, 321, 1116, 13145, 4373, 309, 493, 293, 291, 600, 658, 281, 652, 988, 300], "temperature": 0.0, "avg_logprob": -0.0765105128288269, "compression_ratio": 1.6650717703349283, "no_speech_prob": 2.29589500122529e-06}, {"id": 455, "seek": 295156, "start": 2962.56, "end": 2967.92, "text": " when you're doing this that you have a lot of really good reporting systems in place", "tokens": [562, 291, 434, 884, 341, 300, 291, 362, 257, 688, 295, 534, 665, 10031, 3652, 294, 1081], "temperature": 0.0, "avg_logprob": -0.0765105128288269, "compression_ratio": 1.6650717703349283, "no_speech_prob": 2.29589500122529e-06}, {"id": 456, "seek": 295156, "start": 2967.92, "end": 2973.72, "text": " that you can recognize are your customers yelling at you are your computers burning", "tokens": [300, 291, 393, 5521, 366, 428, 4581, 18381, 412, 291, 366, 428, 10807, 9488], "temperature": 0.0, "avg_logprob": -0.0765105128288269, "compression_ratio": 1.6650717703349283, "no_speech_prob": 2.29589500122529e-06}, {"id": 457, "seek": 297372, "start": 2973.72, "end": 2984.16, "text": " up you know are your are your computers burning up are your costs by running out of control", "tokens": [493, 291, 458, 366, 428, 366, 428, 10807, 9488, 493, 366, 428, 5497, 538, 2614, 484, 295, 1969], "temperature": 0.0, "avg_logprob": -0.18897631674101859, "compression_ratio": 1.6042780748663101, "no_speech_prob": 1.653682488722552e-06}, {"id": 458, "seek": 297372, "start": 2984.16, "end": 2992.64, "text": " and so forth so it really requires great reporting systems.", "tokens": [293, 370, 5220, 370, 309, 534, 7029, 869, 10031, 3652, 13], "temperature": 0.0, "avg_logprob": -0.18897631674101859, "compression_ratio": 1.6042780748663101, "no_speech_prob": 1.653682488722552e-06}, {"id": 459, "seek": 297372, "start": 2992.64, "end": 2997.48, "text": " This fast AI have methods built in that provide for incremental learning ie improving the", "tokens": [639, 2370, 7318, 362, 7150, 3094, 294, 300, 2893, 337, 35759, 2539, 43203, 11470, 264], "temperature": 0.0, "avg_logprob": -0.18897631674101859, "compression_ratio": 1.6042780748663101, "no_speech_prob": 1.653682488722552e-06}, {"id": 460, "seek": 297372, "start": 2997.48, "end": 3002.04, "text": " model slowly over time with a single data point each time.", "tokens": [2316, 5692, 670, 565, 365, 257, 2167, 1412, 935, 1184, 565, 13], "temperature": 0.0, "avg_logprob": -0.18897631674101859, "compression_ratio": 1.6042780748663101, "no_speech_prob": 1.653682488722552e-06}, {"id": 461, "seek": 300204, "start": 3002.04, "end": 3006.88, "text": " Yeah that's a great question so this is a little bit different which is this is really", "tokens": [865, 300, 311, 257, 869, 1168, 370, 341, 307, 257, 707, 857, 819, 597, 307, 341, 307, 534], "temperature": 0.0, "avg_logprob": -0.0689471314350764, "compression_ratio": 1.8049792531120332, "no_speech_prob": 5.6823469094524626e-06}, {"id": 462, "seek": 300204, "start": 3006.88, "end": 3012.68, "text": " about dealing with domain shift and similar issues by continuing to train your model as", "tokens": [466, 6260, 365, 9274, 5513, 293, 2531, 2663, 538, 9289, 281, 3847, 428, 2316, 382], "temperature": 0.0, "avg_logprob": -0.0689471314350764, "compression_ratio": 1.8049792531120332, "no_speech_prob": 5.6823469094524626e-06}, {"id": 463, "seek": 300204, "start": 3012.68, "end": 3019.36, "text": " you do inference and so the good news is you don't need anything special for that it's", "tokens": [291, 360, 38253, 293, 370, 264, 665, 2583, 307, 291, 500, 380, 643, 1340, 2121, 337, 300, 309, 311], "temperature": 0.0, "avg_logprob": -0.0689471314350764, "compression_ratio": 1.8049792531120332, "no_speech_prob": 5.6823469094524626e-06}, {"id": 464, "seek": 300204, "start": 3019.36, "end": 3024.52, "text": " basically just a transfer learning problem so you can do this in many different ways", "tokens": [1936, 445, 257, 5003, 2539, 1154, 370, 291, 393, 360, 341, 294, 867, 819, 2098], "temperature": 0.0, "avg_logprob": -0.0689471314350764, "compression_ratio": 1.8049792531120332, "no_speech_prob": 5.6823469094524626e-06}, {"id": 465, "seek": 300204, "start": 3024.52, "end": 3030.0, "text": " probably the easiest is just to say like okay each night probably the easiest is just to", "tokens": [1391, 264, 12889, 307, 445, 281, 584, 411, 1392, 1184, 1818, 1391, 264, 12889, 307, 445, 281], "temperature": 0.0, "avg_logprob": -0.0689471314350764, "compression_ratio": 1.8049792531120332, "no_speech_prob": 5.6823469094524626e-06}, {"id": 466, "seek": 303000, "start": 3030.0, "end": 3037.96, "text": " say okay each night you know at midnight we're going to set off a task which grabs all of", "tokens": [584, 1392, 1184, 1818, 291, 458, 412, 19006, 321, 434, 516, 281, 992, 766, 257, 5633, 597, 30028, 439, 295], "temperature": 0.0, "avg_logprob": -0.12374536693096161, "compression_ratio": 1.567251461988304, "no_speech_prob": 7.453741659446678e-07}, {"id": 467, "seek": 303000, "start": 3037.96, "end": 3047.4, "text": " the previous day's transactions as mini batches and trains another epoch and so yeah that", "tokens": [264, 3894, 786, 311, 16856, 382, 8382, 15245, 279, 293, 16329, 1071, 30992, 339, 293, 370, 1338, 300], "temperature": 0.0, "avg_logprob": -0.12374536693096161, "compression_ratio": 1.567251461988304, "no_speech_prob": 7.453741659446678e-07}, {"id": 468, "seek": 303000, "start": 3047.4, "end": 3053.08, "text": " actually works fine you can basically think of this as a fine-tuning approach where your", "tokens": [767, 1985, 2489, 291, 393, 1936, 519, 295, 341, 382, 257, 2489, 12, 83, 37726, 3109, 689, 428], "temperature": 0.0, "avg_logprob": -0.12374536693096161, "compression_ratio": 1.567251461988304, "no_speech_prob": 7.453741659446678e-07}, {"id": 469, "seek": 305308, "start": 3053.08, "end": 3060.36, "text": " pre-trained model is yesterday's model and your fine-tuning data is today's data.", "tokens": [659, 12, 17227, 2001, 2316, 307, 5186, 311, 2316, 293, 428, 2489, 12, 83, 37726, 1412, 307, 965, 311, 1412, 13], "temperature": 0.0, "avg_logprob": -0.07716191105726289, "compression_ratio": 1.72, "no_speech_prob": 6.681493118776416e-07}, {"id": 470, "seek": 305308, "start": 3060.36, "end": 3067.84, "text": " So as you roll out your model one thing to be thinking about super carefully is that", "tokens": [407, 382, 291, 3373, 484, 428, 2316, 472, 551, 281, 312, 1953, 466, 1687, 7500, 307, 300], "temperature": 0.0, "avg_logprob": -0.07716191105726289, "compression_ratio": 1.72, "no_speech_prob": 6.681493118776416e-07}, {"id": 471, "seek": 305308, "start": 3067.84, "end": 3073.6, "text": " it might change the behavior of the system that it's a part of and this can create something", "tokens": [309, 1062, 1319, 264, 5223, 295, 264, 1185, 300, 309, 311, 257, 644, 295, 293, 341, 393, 1884, 746], "temperature": 0.0, "avg_logprob": -0.07716191105726289, "compression_ratio": 1.72, "no_speech_prob": 6.681493118776416e-07}, {"id": 472, "seek": 305308, "start": 3073.6, "end": 3079.84, "text": " called a feedback loop and feedback loops are one of the most challenging things for", "tokens": [1219, 257, 5824, 6367, 293, 5824, 16121, 366, 472, 295, 264, 881, 7595, 721, 337], "temperature": 0.0, "avg_logprob": -0.07716191105726289, "compression_ratio": 1.72, "no_speech_prob": 6.681493118776416e-07}, {"id": 473, "seek": 307984, "start": 3079.84, "end": 3085.32, "text": " real-world model deployment particularly of machine learning models because they can take", "tokens": [957, 12, 13217, 2316, 19317, 4098, 295, 3479, 2539, 5245, 570, 436, 393, 747], "temperature": 0.0, "avg_logprob": -0.1134510647166859, "compression_ratio": 1.5082872928176796, "no_speech_prob": 8.186347031369223e-07}, {"id": 474, "seek": 307984, "start": 3085.32, "end": 3096.52, "text": " a very minor issue and explode it into a really big issue so for example think about a predictive", "tokens": [257, 588, 6696, 2734, 293, 21411, 309, 666, 257, 534, 955, 2734, 370, 337, 1365, 519, 466, 257, 35521], "temperature": 0.0, "avg_logprob": -0.1134510647166859, "compression_ratio": 1.5082872928176796, "no_speech_prob": 8.186347031369223e-07}, {"id": 475, "seek": 307984, "start": 3096.52, "end": 3104.56, "text": " policing algorithm it's an algorithm that was trained to recognize you know basically", "tokens": [28799, 9284, 309, 311, 364, 9284, 300, 390, 8895, 281, 5521, 291, 458, 1936], "temperature": 0.0, "avg_logprob": -0.1134510647166859, "compression_ratio": 1.5082872928176796, "no_speech_prob": 8.186347031369223e-07}, {"id": 476, "seek": 310456, "start": 3104.56, "end": 3112.0, "text": " trained on data that says whereabouts are arrests being made and then as you train that", "tokens": [8895, 322, 1412, 300, 1619, 689, 41620, 366, 48813, 885, 1027, 293, 550, 382, 291, 3847, 300], "temperature": 0.0, "avg_logprob": -0.05297702045763953, "compression_ratio": 1.6898734177215189, "no_speech_prob": 1.3925425719207851e-06}, {"id": 477, "seek": 310456, "start": 3112.0, "end": 3120.08, "text": " algorithm based on where arrests are being made then you put in place a system that sends", "tokens": [9284, 2361, 322, 689, 48813, 366, 885, 1027, 550, 291, 829, 294, 1081, 257, 1185, 300, 14790], "temperature": 0.0, "avg_logprob": -0.05297702045763953, "compression_ratio": 1.6898734177215189, "no_speech_prob": 1.3925425719207851e-06}, {"id": 478, "seek": 310456, "start": 3120.08, "end": 3126.6, "text": " police officers to places that the model says are likely to have crime which in this case", "tokens": [3804, 9199, 281, 3190, 300, 264, 2316, 1619, 366, 3700, 281, 362, 7206, 597, 294, 341, 1389], "temperature": 0.0, "avg_logprob": -0.05297702045763953, "compression_ratio": 1.6898734177215189, "no_speech_prob": 1.3925425719207851e-06}, {"id": 479, "seek": 312660, "start": 3126.6, "end": 3134.68, "text": " where were were there where were arrests so then more police go to that place find more", "tokens": [689, 645, 645, 456, 689, 645, 48813, 370, 550, 544, 3804, 352, 281, 300, 1081, 915, 544], "temperature": 0.0, "avg_logprob": -0.08461684596781828, "compression_ratio": 1.9823788546255507, "no_speech_prob": 5.507576588570373e-06}, {"id": 480, "seek": 312660, "start": 3134.68, "end": 3140.2799999999997, "text": " crime because the more police that are there the more they'll see they arrest more people", "tokens": [7206, 570, 264, 544, 3804, 300, 366, 456, 264, 544, 436, 603, 536, 436, 7823, 544, 561], "temperature": 0.0, "avg_logprob": -0.08461684596781828, "compression_ratio": 1.9823788546255507, "no_speech_prob": 5.507576588570373e-06}, {"id": 481, "seek": 312660, "start": 3140.2799999999997, "end": 3143.92, "text": " causing you know and then if you do this incremental learning like we're just talking about then", "tokens": [9853, 291, 458, 293, 550, 498, 291, 360, 341, 35759, 2539, 411, 321, 434, 445, 1417, 466, 550], "temperature": 0.0, "avg_logprob": -0.08461684596781828, "compression_ratio": 1.9823788546255507, "no_speech_prob": 5.507576588570373e-06}, {"id": 482, "seek": 312660, "start": 3143.92, "end": 3148.16, "text": " it's going to say oh there's actually even more crime here and so tomorrow it sends even", "tokens": [309, 311, 516, 281, 584, 1954, 456, 311, 767, 754, 544, 7206, 510, 293, 370, 4153, 309, 14790, 754], "temperature": 0.0, "avg_logprob": -0.08461684596781828, "compression_ratio": 1.9823788546255507, "no_speech_prob": 5.507576588570373e-06}, {"id": 483, "seek": 312660, "start": 3148.16, "end": 3154.52, "text": " more police and so in that situation you end up like the predictive policing algorithm", "tokens": [544, 3804, 293, 370, 294, 300, 2590, 291, 917, 493, 411, 264, 35521, 28799, 9284], "temperature": 0.0, "avg_logprob": -0.08461684596781828, "compression_ratio": 1.9823788546255507, "no_speech_prob": 5.507576588570373e-06}, {"id": 484, "seek": 315452, "start": 3154.52, "end": 3159.8, "text": " ends up kind of sending all of your police for one street block because at that point", "tokens": [5314, 493, 733, 295, 7750, 439, 295, 428, 3804, 337, 472, 4838, 3461, 570, 412, 300, 935], "temperature": 0.0, "avg_logprob": -0.12328355740278195, "compression_ratio": 1.7692307692307692, "no_speech_prob": 5.093671916256426e-06}, {"id": 485, "seek": 315452, "start": 3159.8, "end": 3163.56, "text": " all of the arrests are happening there because that's the only place you have policemen right", "tokens": [439, 295, 264, 48813, 366, 2737, 456, 570, 300, 311, 264, 787, 1081, 291, 362, 6285, 14071, 558], "temperature": 0.0, "avg_logprob": -0.12328355740278195, "compression_ratio": 1.7692307692307692, "no_speech_prob": 5.093671916256426e-06}, {"id": 486, "seek": 315452, "start": 3163.56, "end": 3171.24, "text": " I should say police officers so there's actually a paper about this issue called to protect", "tokens": [286, 820, 584, 3804, 9199, 370, 456, 311, 767, 257, 3035, 466, 341, 2734, 1219, 281, 2371], "temperature": 0.0, "avg_logprob": -0.12328355740278195, "compression_ratio": 1.7692307692307692, "no_speech_prob": 5.093671916256426e-06}, {"id": 487, "seek": 315452, "start": 3171.24, "end": 3178.7, "text": " and serve and to protect and serve the authors write this really nice phrase predictive policing", "tokens": [293, 4596, 293, 281, 2371, 293, 4596, 264, 16552, 2464, 341, 534, 1481, 9535, 35521, 28799], "temperature": 0.0, "avg_logprob": -0.12328355740278195, "compression_ratio": 1.7692307692307692, "no_speech_prob": 5.093671916256426e-06}, {"id": 488, "seek": 317870, "start": 3178.7, "end": 3187.68, "text": " is aptly named it is predicting policing not predicting crime so if the initial model was", "tokens": [307, 29427, 356, 4926, 309, 307, 32884, 28799, 406, 32884, 7206, 370, 498, 264, 5883, 2316, 390], "temperature": 0.0, "avg_logprob": -0.09043708869389125, "compression_ratio": 1.623456790123457, "no_speech_prob": 2.3687887278356357e-06}, {"id": 489, "seek": 317870, "start": 3187.68, "end": 3195.16, "text": " perfect whatever the hell that even means but like it somehow sent police to exactly", "tokens": [2176, 2035, 264, 4921, 300, 754, 1355, 457, 411, 309, 6063, 2279, 3804, 281, 2293], "temperature": 0.0, "avg_logprob": -0.09043708869389125, "compression_ratio": 1.623456790123457, "no_speech_prob": 2.3687887278356357e-06}, {"id": 490, "seek": 317870, "start": 3195.16, "end": 3203.2, "text": " the best places to find crime based on the probability of crimes actually being in place", "tokens": [264, 1151, 3190, 281, 915, 7206, 2361, 322, 264, 8482, 295, 13916, 767, 885, 294, 1081], "temperature": 0.0, "avg_logprob": -0.09043708869389125, "compression_ratio": 1.623456790123457, "no_speech_prob": 2.3687887278356357e-06}, {"id": 491, "seek": 320320, "start": 3203.2, "end": 3211.72, "text": " I guess there's no problem right but as soon as there's any amount of bias right so for", "tokens": [286, 2041, 456, 311, 572, 1154, 558, 457, 382, 2321, 382, 456, 311, 604, 2372, 295, 12577, 558, 370, 337], "temperature": 0.0, "avg_logprob": -0.08053870499134064, "compression_ratio": 1.7032258064516128, "no_speech_prob": 2.4439832486677915e-06}, {"id": 492, "seek": 320320, "start": 3211.72, "end": 3219.66, "text": " example in the US there's a lot more arrests of black people than of white people even", "tokens": [1365, 294, 264, 2546, 456, 311, 257, 688, 544, 48813, 295, 2211, 561, 813, 295, 2418, 561, 754], "temperature": 0.0, "avg_logprob": -0.08053870499134064, "compression_ratio": 1.7032258064516128, "no_speech_prob": 2.4439832486677915e-06}, {"id": 493, "seek": 320320, "start": 3219.66, "end": 3225.4399999999996, "text": " for crimes where black people and white people are known to do them the same amount so in", "tokens": [337, 13916, 689, 2211, 561, 293, 2418, 561, 366, 2570, 281, 360, 552, 264, 912, 2372, 370, 294], "temperature": 0.0, "avg_logprob": -0.08053870499134064, "compression_ratio": 1.7032258064516128, "no_speech_prob": 2.4439832486677915e-06}, {"id": 494, "seek": 322544, "start": 3225.44, "end": 3233.16, "text": " the presence of this bias or any kind of bias you're kind of like setting off this this", "tokens": [264, 6814, 295, 341, 12577, 420, 604, 733, 295, 12577, 291, 434, 733, 295, 411, 3287, 766, 341, 341], "temperature": 0.0, "avg_logprob": -0.0859610088287838, "compression_ratio": 1.6518987341772151, "no_speech_prob": 1.4593700825571432e-06}, {"id": 495, "seek": 322544, "start": 3233.16, "end": 3244.48, "text": " domino chain of feedback loops where that bias will be exploded over time so you know", "tokens": [3285, 2982, 5021, 295, 5824, 16121, 689, 300, 12577, 486, 312, 27049, 670, 565, 370, 291, 458], "temperature": 0.0, "avg_logprob": -0.0859610088287838, "compression_ratio": 1.6518987341772151, "no_speech_prob": 1.4593700825571432e-06}, {"id": 496, "seek": 322544, "start": 3244.48, "end": 3250.12, "text": " one thing I like to think about is to think like well what would happen if this if this", "tokens": [472, 551, 286, 411, 281, 519, 466, 307, 281, 519, 411, 731, 437, 576, 1051, 498, 341, 498, 341], "temperature": 0.0, "avg_logprob": -0.0859610088287838, "compression_ratio": 1.6518987341772151, "no_speech_prob": 1.4593700825571432e-06}, {"id": 497, "seek": 325012, "start": 3250.12, "end": 3256.6, "text": " model was just really really really good so like who would be impacted you know what would", "tokens": [2316, 390, 445, 534, 534, 534, 665, 370, 411, 567, 576, 312, 15653, 291, 458, 437, 576], "temperature": 0.0, "avg_logprob": -0.07894205010455588, "compression_ratio": 2.0697674418604652, "no_speech_prob": 1.9333447198732756e-06}, {"id": 498, "seek": 325012, "start": 3256.6, "end": 3261.7999999999997, "text": " this extreme result look like how would you know what was really happening this incredibly", "tokens": [341, 8084, 1874, 574, 411, 577, 576, 291, 458, 437, 390, 534, 2737, 341, 6252], "temperature": 0.0, "avg_logprob": -0.07894205010455588, "compression_ratio": 2.0697674418604652, "no_speech_prob": 1.9333447198732756e-06}, {"id": 499, "seek": 325012, "start": 3261.7999999999997, "end": 3267.24, "text": " predictive algorithm that was like changing the behavior of yours if your police officers", "tokens": [35521, 9284, 300, 390, 411, 4473, 264, 5223, 295, 6342, 498, 428, 3804, 9199], "temperature": 0.0, "avg_logprob": -0.07894205010455588, "compression_ratio": 2.0697674418604652, "no_speech_prob": 1.9333447198732756e-06}, {"id": 500, "seek": 325012, "start": 3267.24, "end": 3273.56, "text": " or whatever you know what would that look like what would actually happen and then like", "tokens": [420, 2035, 291, 458, 437, 576, 300, 574, 411, 437, 576, 767, 1051, 293, 550, 411], "temperature": 0.0, "avg_logprob": -0.07894205010455588, "compression_ratio": 2.0697674418604652, "no_speech_prob": 1.9333447198732756e-06}, {"id": 501, "seek": 325012, "start": 3273.56, "end": 3278.3199999999997, "text": " think about like okay what could go wrong then what kind of rollout plan what kind of", "tokens": [519, 466, 411, 1392, 437, 727, 352, 2085, 550, 437, 733, 295, 3373, 346, 1393, 437, 733, 295], "temperature": 0.0, "avg_logprob": -0.07894205010455588, "compression_ratio": 2.0697674418604652, "no_speech_prob": 1.9333447198732756e-06}, {"id": 502, "seek": 327832, "start": 3278.32, "end": 3284.6400000000003, "text": " monitoring systems what kind of oversight could provide the circuit breaker because", "tokens": [11028, 3652, 437, 733, 295, 29146, 727, 2893, 264, 9048, 35375, 570], "temperature": 0.0, "avg_logprob": -0.11409679703090501, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.157344847044442e-06}, {"id": 503, "seek": 327832, "start": 3284.6400000000003, "end": 3288.56, "text": " that's what we really need here right is we need like nothing's going to be perfect you", "tokens": [300, 311, 437, 321, 534, 643, 510, 558, 307, 321, 643, 411, 1825, 311, 516, 281, 312, 2176, 291], "temperature": 0.0, "avg_logprob": -0.11409679703090501, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.157344847044442e-06}, {"id": 504, "seek": 327832, "start": 3288.56, "end": 3294.92, "text": " can't be sure that there's no feedback loops but what you can do is try to be sure that", "tokens": [393, 380, 312, 988, 300, 456, 311, 572, 5824, 16121, 457, 437, 291, 393, 360, 307, 853, 281, 312, 988, 300], "temperature": 0.0, "avg_logprob": -0.11409679703090501, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.157344847044442e-06}, {"id": 505, "seek": 327832, "start": 3294.92, "end": 3300.6400000000003, "text": " you see when the behavior of your system is behaving in a way that's not what you want", "tokens": [291, 536, 562, 264, 5223, 295, 428, 1185, 307, 35263, 294, 257, 636, 300, 311, 406, 437, 291, 528], "temperature": 0.0, "avg_logprob": -0.11409679703090501, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.157344847044442e-06}, {"id": 506, "seek": 327832, "start": 3300.6400000000003, "end": 3303.6400000000003, "text": " did you have anything to add to that Rachel", "tokens": [630, 291, 362, 1340, 281, 909, 281, 300, 14246], "temperature": 0.0, "avg_logprob": -0.11409679703090501, "compression_ratio": 1.7647058823529411, "no_speech_prob": 4.157344847044442e-06}, {"id": 507, "seek": 330364, "start": 3303.64, "end": 3311.16, "text": " I would add to that is that you're at risk of potentially having a feedback loop anytime", "tokens": [286, 576, 909, 281, 300, 307, 300, 291, 434, 412, 3148, 295, 7263, 1419, 257, 5824, 6367, 13038], "temperature": 0.0, "avg_logprob": -0.08011478424072266, "compression_ratio": 1.7707509881422925, "no_speech_prob": 1.3418869457382243e-05}, {"id": 508, "seek": 330364, "start": 3311.16, "end": 3316.16, "text": " that your model is kind of controlling what your next round of data looks like and I think", "tokens": [300, 428, 2316, 307, 733, 295, 14905, 437, 428, 958, 3098, 295, 1412, 1542, 411, 293, 286, 519], "temperature": 0.0, "avg_logprob": -0.08011478424072266, "compression_ratio": 1.7707509881422925, "no_speech_prob": 1.3418869457382243e-05}, {"id": 509, "seek": 330364, "start": 3316.16, "end": 3321.96, "text": " that's true for pretty much all products and that can be I think a hard jump from people", "tokens": [300, 311, 2074, 337, 1238, 709, 439, 3383, 293, 300, 393, 312, 286, 519, 257, 1152, 3012, 490, 561], "temperature": 0.0, "avg_logprob": -0.08011478424072266, "compression_ratio": 1.7707509881422925, "no_speech_prob": 1.3418869457382243e-05}, {"id": 510, "seek": 330364, "start": 3321.96, "end": 3326.2799999999997, "text": " people coming from kind of a science background where you may be thinking of data as I have", "tokens": [561, 1348, 490, 733, 295, 257, 3497, 3678, 689, 291, 815, 312, 1953, 295, 1412, 382, 286, 362], "temperature": 0.0, "avg_logprob": -0.08011478424072266, "compression_ratio": 1.7707509881422925, "no_speech_prob": 1.3418869457382243e-05}, {"id": 511, "seek": 330364, "start": 3326.2799999999997, "end": 3330.8399999999997, "text": " just observed some sort of experiment whereas kind of whenever you're you know building", "tokens": [445, 13095, 512, 1333, 295, 5120, 9735, 733, 295, 5699, 291, 434, 291, 458, 2390], "temperature": 0.0, "avg_logprob": -0.08011478424072266, "compression_ratio": 1.7707509881422925, "no_speech_prob": 1.3418869457382243e-05}, {"id": 512, "seek": 333084, "start": 3330.84, "end": 3335.0, "text": " something that interacts with the real world you are now also controlling what your future", "tokens": [746, 300, 43582, 365, 264, 957, 1002, 291, 366, 586, 611, 14905, 437, 428, 2027], "temperature": 0.0, "avg_logprob": -0.10382775907163266, "compression_ratio": 1.7102803738317758, "no_speech_prob": 1.2482669262681156e-06}, {"id": 513, "seek": 333084, "start": 3335.0, "end": 3339.88, "text": " data looks like based on kind of behavior of your your algorithm for the current current", "tokens": [1412, 1542, 411, 2361, 322, 733, 295, 5223, 295, 428, 428, 9284, 337, 264, 2190, 2190], "temperature": 0.0, "avg_logprob": -0.10382775907163266, "compression_ratio": 1.7102803738317758, "no_speech_prob": 1.2482669262681156e-06}, {"id": 514, "seek": 333084, "start": 3339.88, "end": 3350.08, "text": " round of data right so so given that you probably can't avoid feedback loops that you know the", "tokens": [3098, 295, 1412, 558, 370, 370, 2212, 300, 291, 1391, 393, 380, 5042, 5824, 16121, 300, 291, 458, 264], "temperature": 0.0, "avg_logprob": -0.10382775907163266, "compression_ratio": 1.7102803738317758, "no_speech_prob": 1.2482669262681156e-06}, {"id": 515, "seek": 333084, "start": 3350.08, "end": 3355.6000000000004, "text": " the thing you need to then really invest in is the human in the loop and so a lot of people", "tokens": [264, 551, 291, 643, 281, 550, 534, 1963, 294, 307, 264, 1952, 294, 264, 6367, 293, 370, 257, 688, 295, 561], "temperature": 0.0, "avg_logprob": -0.10382775907163266, "compression_ratio": 1.7102803738317758, "no_speech_prob": 1.2482669262681156e-06}, {"id": 516, "seek": 335560, "start": 3355.6, "end": 3361.4, "text": " like to focus on automating things which I find weird you know if you can decrease the", "tokens": [411, 281, 1879, 322, 3553, 990, 721, 597, 286, 915, 3657, 291, 458, 498, 291, 393, 11514, 264], "temperature": 0.0, "avg_logprob": -0.08968188461748142, "compression_ratio": 1.718146718146718, "no_speech_prob": 3.5008297345484607e-06}, {"id": 517, "seek": 335560, "start": 3361.4, "end": 3366.7999999999997, "text": " amount of human involvement by like 90% you've got almost all of the economic upside of automating", "tokens": [2372, 295, 1952, 17447, 538, 411, 4289, 4, 291, 600, 658, 1920, 439, 295, 264, 4836, 14119, 295, 3553, 990], "temperature": 0.0, "avg_logprob": -0.08968188461748142, "compression_ratio": 1.718146718146718, "no_speech_prob": 3.5008297345484607e-06}, {"id": 518, "seek": 335560, "start": 3366.7999999999997, "end": 3371.08, "text": " it completely but you still have the room to put human circuit breakers in place you", "tokens": [309, 2584, 457, 291, 920, 362, 264, 1808, 281, 829, 1952, 9048, 1821, 433, 294, 1081, 291], "temperature": 0.0, "avg_logprob": -0.08968188461748142, "compression_ratio": 1.718146718146718, "no_speech_prob": 3.5008297345484607e-06}, {"id": 519, "seek": 335560, "start": 3371.08, "end": 3376.6, "text": " need these appeals processes you need the monitoring you need you know humans involved", "tokens": [643, 613, 32603, 7555, 291, 643, 264, 11028, 291, 643, 291, 458, 6255, 3288], "temperature": 0.0, "avg_logprob": -0.08968188461748142, "compression_ratio": 1.718146718146718, "no_speech_prob": 3.5008297345484607e-06}, {"id": 520, "seek": 335560, "start": 3376.6, "end": 3385.48, "text": " to kind of go hey that's that's weird I don't think that's what we want okay yes Rachel", "tokens": [281, 733, 295, 352, 4177, 300, 311, 300, 311, 3657, 286, 500, 380, 519, 300, 311, 437, 321, 528, 1392, 2086, 14246], "temperature": 0.0, "avg_logprob": -0.08968188461748142, "compression_ratio": 1.718146718146718, "no_speech_prob": 3.5008297345484607e-06}, {"id": 521, "seek": 338548, "start": 3385.48, "end": 3389.88, "text": " and I just want more note about that those humans though do need to be integrated well", "tokens": [293, 286, 445, 528, 544, 3637, 466, 300, 729, 6255, 1673, 360, 643, 281, 312, 10919, 731], "temperature": 0.0, "avg_logprob": -0.10201067971711111, "compression_ratio": 1.810483870967742, "no_speech_prob": 3.90457807952771e-06}, {"id": 522, "seek": 338548, "start": 3389.88, "end": 3396.4, "text": " with kind of product and engineering and so one issue that comes up is that in many companies", "tokens": [365, 733, 295, 1674, 293, 7043, 293, 370, 472, 2734, 300, 1487, 493, 307, 300, 294, 867, 3431], "temperature": 0.0, "avg_logprob": -0.10201067971711111, "compression_ratio": 1.810483870967742, "no_speech_prob": 3.90457807952771e-06}, {"id": 523, "seek": 338548, "start": 3396.4, "end": 3400.96, "text": " I think that ends up kind of being underneath trust and safety handles a lot of sort of", "tokens": [286, 519, 300, 5314, 493, 733, 295, 885, 7223, 3361, 293, 4514, 18722, 257, 688, 295, 1333, 295], "temperature": 0.0, "avg_logprob": -0.10201067971711111, "compression_ratio": 1.810483870967742, "no_speech_prob": 3.90457807952771e-06}, {"id": 524, "seek": 338548, "start": 3400.96, "end": 3406.48, "text": " issues with how things can go wrong or how your platform can be abused and often trust", "tokens": [2663, 365, 577, 721, 393, 352, 2085, 420, 577, 428, 3663, 393, 312, 27075, 293, 2049, 3361], "temperature": 0.0, "avg_logprob": -0.10201067971711111, "compression_ratio": 1.810483870967742, "no_speech_prob": 3.90457807952771e-06}, {"id": 525, "seek": 338548, "start": 3406.48, "end": 3412.36, "text": " and safety is pretty siloed away from product and edge which actually kind of has the control", "tokens": [293, 4514, 307, 1238, 3425, 78, 292, 1314, 490, 1674, 293, 4691, 597, 767, 733, 295, 575, 264, 1969], "temperature": 0.0, "avg_logprob": -0.10201067971711111, "compression_ratio": 1.810483870967742, "no_speech_prob": 3.90457807952771e-06}, {"id": 526, "seek": 341236, "start": 3412.36, "end": 3416.92, "text": " over you know these decisions that really end up influencing them and so having the", "tokens": [670, 291, 458, 613, 5327, 300, 534, 917, 493, 40396, 552, 293, 370, 1419, 264], "temperature": 0.0, "avg_logprob": -0.0993268818690859, "compression_ratio": 1.9296296296296296, "no_speech_prob": 1.0511438404137152e-06}, {"id": 527, "seek": 341236, "start": 3416.92, "end": 3420.52, "text": " the engineers probably consider them to be pretty pretty annoying a lot of the time how", "tokens": [264, 11955, 1391, 1949, 552, 281, 312, 1238, 1238, 11304, 257, 688, 295, 264, 565, 577], "temperature": 0.0, "avg_logprob": -0.0993268818690859, "compression_ratio": 1.9296296296296296, "no_speech_prob": 1.0511438404137152e-06}, {"id": 528, "seek": 341236, "start": 3420.52, "end": 3424.7200000000003, "text": " they get in the way and get in the way of them getting software out the door yeah but", "tokens": [436, 483, 294, 264, 636, 293, 483, 294, 264, 636, 295, 552, 1242, 4722, 484, 264, 2853, 1338, 457], "temperature": 0.0, "avg_logprob": -0.0993268818690859, "compression_ratio": 1.9296296296296296, "no_speech_prob": 1.0511438404137152e-06}, {"id": 529, "seek": 341236, "start": 3424.7200000000003, "end": 3428.1200000000003, "text": " like the kind of the more integration you can have between those I think it's helpful", "tokens": [411, 264, 733, 295, 264, 544, 10980, 291, 393, 362, 1296, 729, 286, 519, 309, 311, 4961], "temperature": 0.0, "avg_logprob": -0.0993268818690859, "compression_ratio": 1.9296296296296296, "no_speech_prob": 1.0511438404137152e-06}, {"id": 530, "seek": 341236, "start": 3428.1200000000003, "end": 3433.0, "text": " for the kind of the people building the product to see what is going wrong and what can go", "tokens": [337, 264, 733, 295, 264, 561, 2390, 264, 1674, 281, 536, 437, 307, 516, 2085, 293, 437, 393, 352], "temperature": 0.0, "avg_logprob": -0.0993268818690859, "compression_ratio": 1.9296296296296296, "no_speech_prob": 1.0511438404137152e-06}, {"id": 531, "seek": 341236, "start": 3433.0, "end": 3437.0, "text": " wrong if the engineers are actually on top of that they're actually seeing these these", "tokens": [2085, 498, 264, 11955, 366, 767, 322, 1192, 295, 300, 436, 434, 767, 2577, 613, 613], "temperature": 0.0, "avg_logprob": -0.0993268818690859, "compression_ratio": 1.9296296296296296, "no_speech_prob": 1.0511438404137152e-06}, {"id": 532, "seek": 343700, "start": 3437.0, "end": 3442.76, "text": " things happening that it's not some kind of abstract problem anymore so you know at this", "tokens": [721, 2737, 300, 309, 311, 406, 512, 733, 295, 12649, 1154, 3602, 370, 291, 458, 412, 341], "temperature": 0.0, "avg_logprob": -0.09868359256100345, "compression_ratio": 1.748792270531401, "no_speech_prob": 5.86277428737958e-06}, {"id": 533, "seek": 343700, "start": 3442.76, "end": 3451.12, "text": " point now that we've got to the end of chapter 2 you actually know a lot more than most people", "tokens": [935, 586, 300, 321, 600, 658, 281, 264, 917, 295, 7187, 568, 291, 767, 458, 257, 688, 544, 813, 881, 561], "temperature": 0.0, "avg_logprob": -0.09868359256100345, "compression_ratio": 1.748792270531401, "no_speech_prob": 5.86277428737958e-06}, {"id": 534, "seek": 343700, "start": 3451.12, "end": 3457.26, "text": " about about deep learning and actually about some pretty important foundations of machine", "tokens": [466, 466, 2452, 2539, 293, 767, 466, 512, 1238, 1021, 22467, 295, 3479], "temperature": 0.0, "avg_logprob": -0.09868359256100345, "compression_ratio": 1.748792270531401, "no_speech_prob": 5.86277428737958e-06}, {"id": 535, "seek": 343700, "start": 3457.26, "end": 3461.88, "text": " learning more generally and of data products more generally so there was a great time to", "tokens": [2539, 544, 5101, 293, 295, 1412, 3383, 544, 5101, 370, 456, 390, 257, 869, 565, 281], "temperature": 0.0, "avg_logprob": -0.09868359256100345, "compression_ratio": 1.748792270531401, "no_speech_prob": 5.86277428737958e-06}, {"id": 536, "seek": 346188, "start": 3461.88, "end": 3473.2400000000002, "text": " think about writing so sometimes we have a formatted text that doesn't quite format correctly", "tokens": [519, 466, 3579, 370, 2171, 321, 362, 257, 1254, 32509, 2487, 300, 1177, 380, 1596, 7877, 8944], "temperature": 0.0, "avg_logprob": -0.17081740365099551, "compression_ratio": 1.6449704142011834, "no_speech_prob": 1.8738631979431375e-06}, {"id": 537, "seek": 346188, "start": 3473.2400000000002, "end": 3478.08, "text": " in Tripita notebook by the way it only formats correctly in in the book book so that's what", "tokens": [294, 33141, 2786, 21060, 538, 264, 636, 309, 787, 25879, 8944, 294, 294, 264, 1446, 1446, 370, 300, 311, 437], "temperature": 0.0, "avg_logprob": -0.17081740365099551, "compression_ratio": 1.6449704142011834, "no_speech_prob": 1.8738631979431375e-06}, {"id": 538, "seek": 346188, "start": 3478.08, "end": 3490.44, "text": " it means when you see this kind of pre-formatted text so the the idea here is to think about", "tokens": [309, 1355, 562, 291, 536, 341, 733, 295, 659, 12, 837, 32509, 2487, 370, 264, 264, 1558, 510, 307, 281, 519, 466], "temperature": 0.0, "avg_logprob": -0.17081740365099551, "compression_ratio": 1.6449704142011834, "no_speech_prob": 1.8738631979431375e-06}, {"id": 539, "seek": 349044, "start": 3490.44, "end": 3496.88, "text": " starting writing at this point before you go too much further Rachel.", "tokens": [2891, 3579, 412, 341, 935, 949, 291, 352, 886, 709, 3052, 14246, 13], "temperature": 0.0, "avg_logprob": -0.18762361242416056, "compression_ratio": 1.6892430278884463, "no_speech_prob": 7.721836300333962e-05}, {"id": 540, "seek": 349044, "start": 3496.88, "end": 3504.52, "text": " There was a question oh okay let's hit the question question is I am I assume there are", "tokens": [821, 390, 257, 1168, 1954, 1392, 718, 311, 2045, 264, 1168, 1168, 307, 286, 669, 286, 6552, 456, 366], "temperature": 0.0, "avg_logprob": -0.18762361242416056, "compression_ratio": 1.6892430278884463, "no_speech_prob": 7.721836300333962e-05}, {"id": 541, "seek": 349044, "start": 3504.52, "end": 3510.2000000000003, "text": " fast AI type ways of keeping a nightly updated transfer learning setup well could there be", "tokens": [2370, 7318, 2010, 2098, 295, 5145, 257, 1818, 356, 10588, 5003, 2539, 8657, 731, 727, 456, 312], "temperature": 0.0, "avg_logprob": -0.18762361242416056, "compression_ratio": 1.6892430278884463, "no_speech_prob": 7.721836300333962e-05}, {"id": 542, "seek": 349044, "start": 3510.2000000000003, "end": 3514.76, "text": " one of the fast AI version 4 notebooks have an example of the nightly transfer learning", "tokens": [472, 295, 264, 2370, 7318, 3037, 1017, 43782, 362, 364, 1365, 295, 264, 1818, 356, 5003, 2539], "temperature": 0.0, "avg_logprob": -0.18762361242416056, "compression_ratio": 1.6892430278884463, "no_speech_prob": 7.721836300333962e-05}, {"id": 543, "seek": 349044, "start": 3514.76, "end": 3519.92, "text": " training like the previous person asked I would be interested in knowing how to do that", "tokens": [3097, 411, 264, 3894, 954, 2351, 286, 576, 312, 3102, 294, 5276, 577, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.18762361242416056, "compression_ratio": 1.6892430278884463, "no_speech_prob": 7.721836300333962e-05}, {"id": 544, "seek": 351992, "start": 3519.92, "end": 3522.04, "text": " most effectively with fast AI.", "tokens": [881, 8659, 365, 2370, 7318, 13], "temperature": 0.0, "avg_logprob": -0.1630315466241522, "compression_ratio": 1.6493506493506493, "no_speech_prob": 2.046238660113886e-05}, {"id": 545, "seek": 351992, "start": 3522.04, "end": 3528.16, "text": " Sure so I guess my view is there's nothing faster specific about that at all so I actually", "tokens": [4894, 370, 286, 2041, 452, 1910, 307, 456, 311, 1825, 4663, 2685, 466, 300, 412, 439, 370, 286, 767], "temperature": 0.0, "avg_logprob": -0.1630315466241522, "compression_ratio": 1.6493506493506493, "no_speech_prob": 2.046238660113886e-05}, {"id": 546, "seek": 351992, "start": 3528.16, "end": 3532.6800000000003, "text": " suggest you read Emanuel's book that book I showed you to understand the kind of the", "tokens": [3402, 291, 1401, 462, 31385, 311, 1446, 300, 1446, 286, 4712, 291, 281, 1223, 264, 733, 295, 264], "temperature": 0.0, "avg_logprob": -0.1630315466241522, "compression_ratio": 1.6493506493506493, "no_speech_prob": 2.046238660113886e-05}, {"id": 547, "seek": 351992, "start": 3532.6800000000003, "end": 3537.8, "text": " ideas and if people are interested in this I can also point you at some academic research", "tokens": [3487, 293, 498, 561, 366, 3102, 294, 341, 286, 393, 611, 935, 291, 412, 512, 7778, 2132], "temperature": 0.0, "avg_logprob": -0.1630315466241522, "compression_ratio": 1.6493506493506493, "no_speech_prob": 2.046238660113886e-05}, {"id": 548, "seek": 351992, "start": 3537.8, "end": 3542.48, "text": " about this as well and there's not as much as that there should be but there is some", "tokens": [466, 341, 382, 731, 293, 456, 311, 406, 382, 709, 382, 300, 456, 820, 312, 457, 456, 307, 512], "temperature": 0.0, "avg_logprob": -0.1630315466241522, "compression_ratio": 1.6493506493506493, "no_speech_prob": 2.046238660113886e-05}, {"id": 549, "seek": 354248, "start": 3542.48, "end": 3551.16, "text": " there is some good work in this area. Okay so the reason we mentioned writing at this", "tokens": [456, 307, 512, 665, 589, 294, 341, 1859, 13, 1033, 370, 264, 1778, 321, 2835, 3579, 412, 341], "temperature": 0.0, "avg_logprob": -0.09375121675688645, "compression_ratio": 1.6267281105990783, "no_speech_prob": 5.014690032112412e-06}, {"id": 550, "seek": 354248, "start": 3551.16, "end": 3558.4, "text": " point in our journey is because you know things are going to start to get more and more heavy", "tokens": [935, 294, 527, 4671, 307, 570, 291, 458, 721, 366, 516, 281, 722, 281, 483, 544, 293, 544, 4676], "temperature": 0.0, "avg_logprob": -0.09375121675688645, "compression_ratio": 1.6267281105990783, "no_speech_prob": 5.014690032112412e-06}, {"id": 551, "seek": 354248, "start": 3558.4, "end": 3563.36, "text": " more and more complicated and a really good way to make sure that you're on top of it", "tokens": [544, 293, 544, 6179, 293, 257, 534, 665, 636, 281, 652, 988, 300, 291, 434, 322, 1192, 295, 309], "temperature": 0.0, "avg_logprob": -0.09375121675688645, "compression_ratio": 1.6267281105990783, "no_speech_prob": 5.014690032112412e-06}, {"id": 552, "seek": 354248, "start": 3563.36, "end": 3569.44, "text": " is to try to write down what you've learnt. So sorry I wasn't sharing the right part of", "tokens": [307, 281, 853, 281, 2464, 760, 437, 291, 600, 18991, 13, 407, 2597, 286, 2067, 380, 5414, 264, 558, 644, 295], "temperature": 0.0, "avg_logprob": -0.09375121675688645, "compression_ratio": 1.6267281105990783, "no_speech_prob": 5.014690032112412e-06}, {"id": 553, "seek": 356944, "start": 3569.44, "end": 3574.16, "text": " the screen before but this is what I was describing in terms of the pre-formatted text which doesn't", "tokens": [264, 2568, 949, 457, 341, 307, 437, 286, 390, 16141, 294, 2115, 295, 264, 659, 12, 837, 32509, 2487, 597, 1177, 380], "temperature": 0.0, "avg_logprob": -0.11733568960161352, "compression_ratio": 1.4972972972972973, "no_speech_prob": 1.16592909762403e-05}, {"id": 554, "seek": 356944, "start": 3574.16, "end": 3585.64, "text": " look correct. So Rachel actually has this great article that you should check out which", "tokens": [574, 3006, 13, 407, 14246, 767, 575, 341, 869, 7222, 300, 291, 820, 1520, 484, 597], "temperature": 0.0, "avg_logprob": -0.11733568960161352, "compression_ratio": 1.4972972972972973, "no_speech_prob": 1.16592909762403e-05}, {"id": 555, "seek": 356944, "start": 3585.64, "end": 3593.28, "text": " is why you should blog and I will say it's sort of her saying because I have it in front", "tokens": [307, 983, 291, 820, 6968, 293, 286, 486, 584, 309, 311, 1333, 295, 720, 1566, 570, 286, 362, 309, 294, 1868], "temperature": 0.0, "avg_logprob": -0.11733568960161352, "compression_ratio": 1.4972972972972973, "no_speech_prob": 1.16592909762403e-05}, {"id": 556, "seek": 359328, "start": 3593.28, "end": 3599.6800000000003, "text": " of me and she doesn't, weird as it is. So Rachel says that the top advice she would", "tokens": [295, 385, 293, 750, 1177, 380, 11, 3657, 382, 309, 307, 13, 407, 14246, 1619, 300, 264, 1192, 5192, 750, 576], "temperature": 0.0, "avg_logprob": -0.1288402451409234, "compression_ratio": 1.5890410958904109, "no_speech_prob": 2.6841528324439423e-06}, {"id": 557, "seek": 359328, "start": 3599.6800000000003, "end": 3605.36, "text": " give her younger self is to start blogging sooner. So Rachel has a math PhD and this", "tokens": [976, 720, 7037, 2698, 307, 281, 722, 6968, 3249, 15324, 13, 407, 14246, 575, 257, 5221, 14476, 293, 341], "temperature": 0.0, "avg_logprob": -0.1288402451409234, "compression_ratio": 1.5890410958904109, "no_speech_prob": 2.6841528324439423e-06}, {"id": 558, "seek": 359328, "start": 3605.36, "end": 3609.28, "text": " kind of idea of like blogging was not exactly something I think they had a lot of in the", "tokens": [733, 295, 1558, 295, 411, 6968, 3249, 390, 406, 2293, 746, 286, 519, 436, 632, 257, 688, 295, 294, 264], "temperature": 0.0, "avg_logprob": -0.1288402451409234, "compression_ratio": 1.5890410958904109, "no_speech_prob": 2.6841528324439423e-06}, {"id": 559, "seek": 359328, "start": 3609.28, "end": 3619.0400000000004, "text": " PhD program but actually it's like it's a really great way of finding jobs in fact most of", "tokens": [14476, 1461, 457, 767, 309, 311, 411, 309, 311, 257, 534, 869, 636, 295, 5006, 4782, 294, 1186, 881, 295], "temperature": 0.0, "avg_logprob": -0.1288402451409234, "compression_ratio": 1.5890410958904109, "no_speech_prob": 2.6841528324439423e-06}, {"id": 560, "seek": 361904, "start": 3619.04, "end": 3626.2, "text": " my students who have got the best jobs are students that have good blog posts. The thing", "tokens": [452, 1731, 567, 362, 658, 264, 1151, 4782, 366, 1731, 300, 362, 665, 6968, 12300, 13, 440, 551], "temperature": 0.0, "avg_logprob": -0.13302902741865677, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.9479699605872156e-06}, {"id": 561, "seek": 361904, "start": 3626.2, "end": 3631.44, "text": " I really love is that it helps you learn by writing down it's kind of synthesizes your", "tokens": [286, 534, 959, 307, 300, 309, 3665, 291, 1466, 538, 3579, 760, 309, 311, 733, 295, 26617, 5660, 428], "temperature": 0.0, "avg_logprob": -0.13302902741865677, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.9479699605872156e-06}, {"id": 562, "seek": 361904, "start": 3631.44, "end": 3641.44, "text": " ideas and yeah you know there's lots of reasons to blog. So there's actually something really", "tokens": [3487, 293, 1338, 291, 458, 456, 311, 3195, 295, 4112, 281, 6968, 13, 407, 456, 311, 767, 746, 534], "temperature": 0.0, "avg_logprob": -0.13302902741865677, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.9479699605872156e-06}, {"id": 563, "seek": 361904, "start": 3641.44, "end": 3647.52, "text": " cool I want to show you. Yeah. I was also just going to note I have a second post called", "tokens": [1627, 286, 528, 281, 855, 291, 13, 865, 13, 286, 390, 611, 445, 516, 281, 3637, 286, 362, 257, 1150, 2183, 1219], "temperature": 0.0, "avg_logprob": -0.13302902741865677, "compression_ratio": 1.6574074074074074, "no_speech_prob": 2.9479699605872156e-06}, {"id": 564, "seek": 364752, "start": 3647.52, "end": 3653.12, "text": " advice for better blog post that's a little bit more advanced which I'll post a link to", "tokens": [5192, 337, 1101, 6968, 2183, 300, 311, 257, 707, 857, 544, 7339, 597, 286, 603, 2183, 257, 2113, 281], "temperature": 0.0, "avg_logprob": -0.08913040161132812, "compression_ratio": 1.7450980392156863, "no_speech_prob": 7.296288003999507e-06}, {"id": 565, "seek": 364752, "start": 3653.12, "end": 3659.08, "text": " as well and that talks about some common pitfalls that I've seen in many in many blog posts", "tokens": [382, 731, 293, 300, 6686, 466, 512, 2689, 10147, 18542, 300, 286, 600, 1612, 294, 867, 294, 867, 6968, 12300], "temperature": 0.0, "avg_logprob": -0.08913040161132812, "compression_ratio": 1.7450980392156863, "no_speech_prob": 7.296288003999507e-06}, {"id": 566, "seek": 364752, "start": 3659.08, "end": 3663.16, "text": " and kind of the importance of putting putting the time in to do it well and some things", "tokens": [293, 733, 295, 264, 7379, 295, 3372, 3372, 264, 565, 294, 281, 360, 309, 731, 293, 512, 721], "temperature": 0.0, "avg_logprob": -0.08913040161132812, "compression_ratio": 1.7450980392156863, "no_speech_prob": 7.296288003999507e-06}, {"id": 567, "seek": 364752, "start": 3663.16, "end": 3668.04, "text": " to think about. So I'll share that post as well. Thanks Rachel. So one reason that sometimes", "tokens": [281, 519, 466, 13, 407, 286, 603, 2073, 300, 2183, 382, 731, 13, 2561, 14246, 13, 407, 472, 1778, 300, 2171], "temperature": 0.0, "avg_logprob": -0.08913040161132812, "compression_ratio": 1.7450980392156863, "no_speech_prob": 7.296288003999507e-06}, {"id": 568, "seek": 364752, "start": 3668.04, "end": 3674.7599999999998, "text": " people don't blog is because it's kind of annoying to figure out how to particularly", "tokens": [561, 500, 380, 6968, 307, 570, 309, 311, 733, 295, 11304, 281, 2573, 484, 577, 281, 4098], "temperature": 0.0, "avg_logprob": -0.08913040161132812, "compression_ratio": 1.7450980392156863, "no_speech_prob": 7.296288003999507e-06}, {"id": 569, "seek": 367476, "start": 3674.76, "end": 3679.1600000000003, "text": " because I think the thing that a lot of you will want to blog about is cool stuff that", "tokens": [570, 286, 519, 264, 551, 300, 257, 688, 295, 291, 486, 528, 281, 6968, 466, 307, 1627, 1507, 300], "temperature": 0.0, "avg_logprob": -0.16504676775498825, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.4060825580818346e-06}, {"id": 570, "seek": 367476, "start": 3679.1600000000003, "end": 3685.0800000000004, "text": " you're building in Jupyter Notebooks. So we've actually teamed up with a guy called Hamel", "tokens": [291, 434, 2390, 294, 22125, 88, 391, 11633, 15170, 13, 407, 321, 600, 767, 47426, 493, 365, 257, 2146, 1219, 8234, 338], "temperature": 0.0, "avg_logprob": -0.16504676775498825, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.4060825580818346e-06}, {"id": 571, "seek": 367476, "start": 3685.0800000000004, "end": 3694.48, "text": " Hussain and and with GitHub to create this free product as usual with fast AI no ads", "tokens": [389, 2023, 491, 293, 293, 365, 23331, 281, 1884, 341, 1737, 1674, 382, 7713, 365, 2370, 7318, 572, 10342], "temperature": 0.0, "avg_logprob": -0.16504676775498825, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.4060825580818346e-06}, {"id": 572, "seek": 367476, "start": 3694.48, "end": 3703.8, "text": " no anything called fast pages where you can actually blog with Jupyter Notebooks and so", "tokens": [572, 1340, 1219, 2370, 7183, 689, 291, 393, 767, 6968, 365, 22125, 88, 391, 11633, 15170, 293, 370], "temperature": 0.0, "avg_logprob": -0.16504676775498825, "compression_ratio": 1.6232558139534883, "no_speech_prob": 2.4060825580818346e-06}, {"id": 573, "seek": 370380, "start": 3703.8, "end": 3708.6600000000003, "text": " you can go to fast pages and see for yourself how to do it but the basic idea is that like", "tokens": [291, 393, 352, 281, 2370, 7183, 293, 536, 337, 1803, 577, 281, 360, 309, 457, 264, 3875, 1558, 307, 300, 411], "temperature": 0.0, "avg_logprob": -0.1143965548779591, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.936875939165475e-06}, {"id": 574, "seek": 370380, "start": 3708.6600000000003, "end": 3717.92, "text": " you literally click one button it sets up a blog for you and then you dump your notebooks", "tokens": [291, 3736, 2052, 472, 2960, 309, 6352, 493, 257, 6968, 337, 291, 293, 550, 291, 11430, 428, 43782], "temperature": 0.0, "avg_logprob": -0.1143965548779591, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.936875939165475e-06}, {"id": 575, "seek": 370380, "start": 3717.92, "end": 3725.32, "text": " into a folder called underscore notebooks and they get turned into blog posts. It's", "tokens": [666, 257, 10820, 1219, 37556, 43782, 293, 436, 483, 3574, 666, 6968, 12300, 13, 467, 311], "temperature": 0.0, "avg_logprob": -0.1143965548779591, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.936875939165475e-06}, {"id": 576, "seek": 370380, "start": 3725.32, "end": 3732.28, "text": " basically like magic and Hamel's done this amazing job of this and so this means that", "tokens": [1936, 411, 5585, 293, 8234, 338, 311, 1096, 341, 2243, 1691, 295, 341, 293, 370, 341, 1355, 300], "temperature": 0.0, "avg_logprob": -0.1143965548779591, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.936875939165475e-06}, {"id": 577, "seek": 373228, "start": 3732.28, "end": 3738.88, "text": " you can create blog posts where you've got charts and tables and images you know where", "tokens": [291, 393, 1884, 6968, 12300, 689, 291, 600, 658, 17767, 293, 8020, 293, 5267, 291, 458, 689], "temperature": 0.0, "avg_logprob": -0.10712303834802964, "compression_ratio": 1.5936073059360731, "no_speech_prob": 1.963786871783668e-06}, {"id": 578, "seek": 373228, "start": 3738.88, "end": 3745.44, "text": " they're all actually the output of Jupyter Notebook along with all the markdown formatted", "tokens": [436, 434, 439, 767, 264, 5598, 295, 22125, 88, 391, 11633, 2939, 2051, 365, 439, 264, 1491, 5093, 1254, 32509], "temperature": 0.0, "avg_logprob": -0.10712303834802964, "compression_ratio": 1.5936073059360731, "no_speech_prob": 1.963786871783668e-06}, {"id": 579, "seek": 373228, "start": 3745.44, "end": 3752.7400000000002, "text": " text headings and so forth and hyperlinks and the whole thing. So this is a great way", "tokens": [2487, 1378, 1109, 293, 370, 5220, 293, 9848, 75, 16431, 293, 264, 1379, 551, 13, 407, 341, 307, 257, 869, 636], "temperature": 0.0, "avg_logprob": -0.10712303834802964, "compression_ratio": 1.5936073059360731, "no_speech_prob": 1.963786871783668e-06}, {"id": 580, "seek": 373228, "start": 3752.7400000000002, "end": 3759.6800000000003, "text": " to start writing about what you're learning about here. So something that Rachel and I", "tokens": [281, 722, 3579, 466, 437, 291, 434, 2539, 466, 510, 13, 407, 746, 300, 14246, 293, 286], "temperature": 0.0, "avg_logprob": -0.10712303834802964, "compression_ratio": 1.5936073059360731, "no_speech_prob": 1.963786871783668e-06}, {"id": 581, "seek": 375968, "start": 3759.68, "end": 3768.2799999999997, "text": " both feel strongly about when it comes to blogging is this which is don't try to think", "tokens": [1293, 841, 10613, 466, 562, 309, 1487, 281, 6968, 3249, 307, 341, 597, 307, 500, 380, 853, 281, 519], "temperature": 0.0, "avg_logprob": -0.08345580668676467, "compression_ratio": 1.6666666666666667, "no_speech_prob": 8.059411698013719e-07}, {"id": 582, "seek": 375968, "start": 3768.2799999999997, "end": 3773.9199999999996, "text": " about the absolute most advanced thing you know and try to write a blog post that would", "tokens": [466, 264, 8236, 881, 7339, 551, 291, 458, 293, 853, 281, 2464, 257, 6968, 2183, 300, 576], "temperature": 0.0, "avg_logprob": -0.08345580668676467, "compression_ratio": 1.6666666666666667, "no_speech_prob": 8.059411698013719e-07}, {"id": 583, "seek": 375968, "start": 3773.9199999999996, "end": 3781.22, "text": " impress Jeff Hinton right because most people are not Jeff Hinton so like a you probably", "tokens": [6729, 7506, 389, 12442, 558, 570, 881, 561, 366, 406, 7506, 389, 12442, 370, 411, 257, 291, 1391], "temperature": 0.0, "avg_logprob": -0.08345580668676467, "compression_ratio": 1.6666666666666667, "no_speech_prob": 8.059411698013719e-07}, {"id": 584, "seek": 375968, "start": 3781.22, "end": 3785.58, "text": " won't do a good job because you're trying to like log for somebody who's more got more", "tokens": [1582, 380, 360, 257, 665, 1691, 570, 291, 434, 1382, 281, 411, 3565, 337, 2618, 567, 311, 544, 658, 544], "temperature": 0.0, "avg_logprob": -0.08345580668676467, "compression_ratio": 1.6666666666666667, "no_speech_prob": 8.059411698013719e-07}, {"id": 585, "seek": 378558, "start": 3785.58, "end": 3792.4, "text": " expertise than you and be you've got a small audience now right actually there's far more", "tokens": [11769, 813, 291, 293, 312, 291, 600, 658, 257, 1359, 4034, 586, 558, 767, 456, 311, 1400, 544], "temperature": 0.0, "avg_logprob": -0.09190715789794922, "compression_ratio": 1.8553719008264462, "no_speech_prob": 1.0511416803637985e-06}, {"id": 586, "seek": 378558, "start": 3792.4, "end": 3797.64, "text": " people that are not very familiar with deep learning than people who are they try to think", "tokens": [561, 300, 366, 406, 588, 4963, 365, 2452, 2539, 813, 561, 567, 366, 436, 853, 281, 519], "temperature": 0.0, "avg_logprob": -0.09190715789794922, "compression_ratio": 1.8553719008264462, "no_speech_prob": 1.0511416803637985e-06}, {"id": 587, "seek": 378558, "start": 3797.64, "end": 3802.5, "text": " you know and you really understand what it's like what it was like six months ago to be", "tokens": [291, 458, 293, 291, 534, 1223, 437, 309, 311, 411, 437, 309, 390, 411, 2309, 2493, 2057, 281, 312], "temperature": 0.0, "avg_logprob": -0.09190715789794922, "compression_ratio": 1.8553719008264462, "no_speech_prob": 1.0511416803637985e-06}, {"id": 588, "seek": 378558, "start": 3802.5, "end": 3807.16, "text": " you because you were there six months ago so try and write something which the six months", "tokens": [291, 570, 291, 645, 456, 2309, 2493, 2057, 370, 853, 293, 2464, 746, 597, 264, 2309, 2493], "temperature": 0.0, "avg_logprob": -0.09190715789794922, "compression_ratio": 1.8553719008264462, "no_speech_prob": 1.0511416803637985e-06}, {"id": 589, "seek": 378558, "start": 3807.16, "end": 3812.68, "text": " ago version of you would have been like super interesting full of little tidbits you would", "tokens": [2057, 3037, 295, 291, 576, 362, 668, 411, 1687, 1880, 1577, 295, 707, 9422, 34010, 291, 576], "temperature": 0.0, "avg_logprob": -0.09190715789794922, "compression_ratio": 1.8553719008264462, "no_speech_prob": 1.0511416803637985e-06}, {"id": 590, "seek": 381268, "start": 3812.68, "end": 3817.96, "text": " have loved you know that you would have that would have delighted you that six months ago", "tokens": [362, 4333, 291, 458, 300, 291, 576, 362, 300, 576, 362, 18783, 291, 300, 2309, 2493, 2057], "temperature": 0.0, "avg_logprob": -0.10714097670566888, "compression_ratio": 1.7794117647058822, "no_speech_prob": 9.476394779994735e-08}, {"id": 591, "seek": 381268, "start": 3817.96, "end": 3827.2799999999997, "text": " version of you. Okay so once again don't move on until you've had a go at the questionnaire", "tokens": [3037, 295, 291, 13, 1033, 370, 1564, 797, 500, 380, 1286, 322, 1826, 291, 600, 632, 257, 352, 412, 264, 44702], "temperature": 0.0, "avg_logprob": -0.10714097670566888, "compression_ratio": 1.7794117647058822, "no_speech_prob": 9.476394779994735e-08}, {"id": 592, "seek": 381268, "start": 3827.2799999999997, "end": 3835.12, "text": " to make sure that you you know understand the key things we think that you need to understand", "tokens": [281, 652, 988, 300, 291, 291, 458, 1223, 264, 2141, 721, 321, 519, 300, 291, 643, 281, 1223], "temperature": 0.0, "avg_logprob": -0.10714097670566888, "compression_ratio": 1.7794117647058822, "no_speech_prob": 9.476394779994735e-08}, {"id": 593, "seek": 381268, "start": 3835.12, "end": 3839.7599999999998, "text": " and yeah have a think about these further research questions as well because they might", "tokens": [293, 1338, 362, 257, 519, 466, 613, 3052, 2132, 1651, 382, 731, 570, 436, 1062], "temperature": 0.0, "avg_logprob": -0.10714097670566888, "compression_ratio": 1.7794117647058822, "no_speech_prob": 9.476394779994735e-08}, {"id": 594, "seek": 383976, "start": 3839.76, "end": 3844.96, "text": " help you to engage more closely with material. So let's have a break and we'll come back", "tokens": [854, 291, 281, 4683, 544, 8185, 365, 2527, 13, 407, 718, 311, 362, 257, 1821, 293, 321, 603, 808, 646], "temperature": 0.0, "avg_logprob": -0.07664751628088573, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.4823477840764099e-06}, {"id": 595, "seek": 383976, "start": 3844.96, "end": 3858.1600000000003, "text": " in five minutes time. So welcome back everybody this is a interesting moment in the course", "tokens": [294, 1732, 2077, 565, 13, 407, 2928, 646, 2201, 341, 307, 257, 1880, 1623, 294, 264, 1164], "temperature": 0.0, "avg_logprob": -0.07664751628088573, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.4823477840764099e-06}, {"id": 596, "seek": 383976, "start": 3858.1600000000003, "end": 3865.0, "text": " because we're kind of jumping from the part of the course which is you know very heavily", "tokens": [570, 321, 434, 733, 295, 11233, 490, 264, 644, 295, 264, 1164, 597, 307, 291, 458, 588, 10950], "temperature": 0.0, "avg_logprob": -0.07664751628088573, "compression_ratio": 1.5141242937853108, "no_speech_prob": 1.4823477840764099e-06}, {"id": 597, "seek": 386500, "start": 3865.0, "end": 3872.88, "text": " around kind of the kind of the structure of like what are we trying to do with machine", "tokens": [926, 733, 295, 264, 733, 295, 264, 3877, 295, 411, 437, 366, 321, 1382, 281, 360, 365, 3479], "temperature": 0.0, "avg_logprob": -0.09301712399437315, "compression_ratio": 1.8031088082901554, "no_speech_prob": 1.593597153259907e-05}, {"id": 598, "seek": 386500, "start": 3872.88, "end": 3877.96, "text": " learning and what are the kind of the pieces and what do we need to know to make everything", "tokens": [2539, 293, 437, 366, 264, 733, 295, 264, 3755, 293, 437, 360, 321, 643, 281, 458, 281, 652, 1203], "temperature": 0.0, "avg_logprob": -0.09301712399437315, "compression_ratio": 1.8031088082901554, "no_speech_prob": 1.593597153259907e-05}, {"id": 599, "seek": 386500, "start": 3877.96, "end": 3884.48, "text": " kind of work together. There was a bit of code but not masses there was basically no", "tokens": [733, 295, 589, 1214, 13, 821, 390, 257, 857, 295, 3089, 457, 406, 23935, 456, 390, 1936, 572], "temperature": 0.0, "avg_logprob": -0.09301712399437315, "compression_ratio": 1.8031088082901554, "no_speech_prob": 1.593597153259907e-05}, {"id": 600, "seek": 386500, "start": 3884.48, "end": 3892.56, "text": " math and we kind of wanted to put that at the start for everybody who's not you know", "tokens": [5221, 293, 321, 733, 295, 1415, 281, 829, 300, 412, 264, 722, 337, 2201, 567, 311, 406, 291, 458], "temperature": 0.0, "avg_logprob": -0.09301712399437315, "compression_ratio": 1.8031088082901554, "no_speech_prob": 1.593597153259907e-05}, {"id": 601, "seek": 389256, "start": 3892.56, "end": 3900.44, "text": " who's kind of wanting to an understanding of these issues without necessarily wanting", "tokens": [567, 311, 733, 295, 7935, 281, 364, 3701, 295, 613, 2663, 1553, 4725, 7935], "temperature": 0.0, "avg_logprob": -0.12716893304752397, "compression_ratio": 1.755, "no_speech_prob": 1.6441832485725172e-05}, {"id": 602, "seek": 389256, "start": 3900.44, "end": 3904.56, "text": " to kind of dive deep into the code and the math themselves and now we're getting into", "tokens": [281, 733, 295, 9192, 2452, 666, 264, 3089, 293, 264, 5221, 2969, 293, 586, 321, 434, 1242, 666], "temperature": 0.0, "avg_logprob": -0.12716893304752397, "compression_ratio": 1.755, "no_speech_prob": 1.6441832485725172e-05}, {"id": 603, "seek": 389256, "start": 3904.56, "end": 3912.0, "text": " the diving deep part. If you're not interested in that diving deep yourself you might want", "tokens": [264, 20241, 2452, 644, 13, 759, 291, 434, 406, 3102, 294, 300, 20241, 2452, 1803, 291, 1062, 528], "temperature": 0.0, "avg_logprob": -0.12716893304752397, "compression_ratio": 1.755, "no_speech_prob": 1.6441832485725172e-05}, {"id": 604, "seek": 389256, "start": 3912.0, "end": 3918.0, "text": " to skip to the next lesson about ethics where we you know is kind of that rounds out the", "tokens": [281, 10023, 281, 264, 958, 6898, 466, 19769, 689, 321, 291, 458, 307, 733, 295, 300, 13757, 484, 264], "temperature": 0.0, "avg_logprob": -0.12716893304752397, "compression_ratio": 1.755, "no_speech_prob": 1.6441832485725172e-05}, {"id": 605, "seek": 391800, "start": 3918.0, "end": 3927.4, "text": " kind of you know slightly less technical material. So what we're going to look at here is we're", "tokens": [733, 295, 291, 458, 4748, 1570, 6191, 2527, 13, 407, 437, 321, 434, 516, 281, 574, 412, 510, 307, 321, 434], "temperature": 0.0, "avg_logprob": -0.11100896947524126, "compression_ratio": 1.8256410256410256, "no_speech_prob": 3.6119442938797874e-06}, {"id": 606, "seek": 391800, "start": 3927.4, "end": 3935.24, "text": " going to look at what we think of as kind of a toy problem but just a few years ago", "tokens": [516, 281, 574, 412, 437, 321, 519, 295, 382, 733, 295, 257, 12058, 1154, 457, 445, 257, 1326, 924, 2057], "temperature": 0.0, "avg_logprob": -0.11100896947524126, "compression_ratio": 1.8256410256410256, "no_speech_prob": 3.6119442938797874e-06}, {"id": 607, "seek": 391800, "start": 3935.24, "end": 3940.64, "text": " is considered a pretty challenging problem and the problem is recognizing handwritten", "tokens": [307, 4888, 257, 1238, 7595, 1154, 293, 264, 1154, 307, 18538, 1011, 26859], "temperature": 0.0, "avg_logprob": -0.11100896947524126, "compression_ratio": 1.8256410256410256, "no_speech_prob": 3.6119442938797874e-06}, {"id": 608, "seek": 391800, "start": 3940.64, "end": 3947.76, "text": " digits and we're going to try and do it from scratch right and we're going to try and look", "tokens": [27011, 293, 321, 434, 516, 281, 853, 293, 360, 309, 490, 8459, 558, 293, 321, 434, 516, 281, 853, 293, 574], "temperature": 0.0, "avg_logprob": -0.11100896947524126, "compression_ratio": 1.8256410256410256, "no_speech_prob": 3.6119442938797874e-06}, {"id": 609, "seek": 394776, "start": 3947.76, "end": 3954.1600000000003, "text": " at a number of different ways to do it. So we're going to have a look at a data set called", "tokens": [412, 257, 1230, 295, 819, 2098, 281, 360, 309, 13, 407, 321, 434, 516, 281, 362, 257, 574, 412, 257, 1412, 992, 1219], "temperature": 0.0, "avg_logprob": -0.11975200087935836, "compression_ratio": 1.6532846715328466, "no_speech_prob": 2.6016061838163296e-06}, {"id": 610, "seek": 394776, "start": 3954.1600000000003, "end": 3959.0400000000004, "text": " MNIST and so if you've done any machine learning before you may well have come across MNIST.", "tokens": [376, 45, 19756, 293, 370, 498, 291, 600, 1096, 604, 3479, 2539, 949, 291, 815, 731, 362, 808, 2108, 376, 45, 19756, 13], "temperature": 0.0, "avg_logprob": -0.11975200087935836, "compression_ratio": 1.6532846715328466, "no_speech_prob": 2.6016061838163296e-06}, {"id": 611, "seek": 394776, "start": 3959.0400000000004, "end": 3964.5200000000004, "text": " It contains handwritten digits and it was collated into a machine learning data set", "tokens": [467, 8306, 1011, 26859, 27011, 293, 309, 390, 1263, 770, 666, 257, 3479, 2539, 1412, 992], "temperature": 0.0, "avg_logprob": -0.11975200087935836, "compression_ratio": 1.6532846715328466, "no_speech_prob": 2.6016061838163296e-06}, {"id": 612, "seek": 394776, "start": 3964.5200000000004, "end": 3970.0800000000004, "text": " by a guy called John Lacoon and some colleagues and they use that to demonstrate I'm one of", "tokens": [538, 257, 2146, 1219, 2619, 40113, 4106, 293, 512, 7734, 293, 436, 764, 300, 281, 11698, 286, 478, 472, 295], "temperature": 0.0, "avg_logprob": -0.11975200087935836, "compression_ratio": 1.6532846715328466, "no_speech_prob": 2.6016061838163296e-06}, {"id": 613, "seek": 394776, "start": 3970.0800000000004, "end": 3975.2400000000002, "text": " the you know probably the first computer system to provide really practically useful scalable", "tokens": [264, 291, 458, 1391, 264, 700, 3820, 1185, 281, 2893, 534, 15667, 4420, 38481], "temperature": 0.0, "avg_logprob": -0.11975200087935836, "compression_ratio": 1.6532846715328466, "no_speech_prob": 2.6016061838163296e-06}, {"id": 614, "seek": 397524, "start": 3975.24, "end": 3982.2, "text": " recognition of handwritten digits. Lynette 5 with the system was actually used to automatically", "tokens": [11150, 295, 1011, 26859, 27011, 13, 15214, 3007, 1025, 365, 264, 1185, 390, 767, 1143, 281, 6772], "temperature": 0.0, "avg_logprob": -0.11539677367813286, "compression_ratio": 1.5603448275862069, "no_speech_prob": 1.903372663036862e-06}, {"id": 615, "seek": 397524, "start": 3982.2, "end": 3992.2, "text": " process like 10% of the checks in the US. So one of the things that really helps I think", "tokens": [1399, 411, 1266, 4, 295, 264, 13834, 294, 264, 2546, 13, 407, 472, 295, 264, 721, 300, 534, 3665, 286, 519], "temperature": 0.0, "avg_logprob": -0.11539677367813286, "compression_ratio": 1.5603448275862069, "no_speech_prob": 1.903372663036862e-06}, {"id": 616, "seek": 397524, "start": 3992.2, "end": 3997.3199999999997, "text": " when building a new model is to kind of start with something simple and gradually scale", "tokens": [562, 2390, 257, 777, 2316, 307, 281, 733, 295, 722, 365, 746, 2199, 293, 13145, 4373], "temperature": 0.0, "avg_logprob": -0.11539677367813286, "compression_ratio": 1.5603448275862069, "no_speech_prob": 1.903372663036862e-06}, {"id": 617, "seek": 397524, "start": 3997.3199999999997, "end": 4004.04, "text": " it up. So we've created an even simpler version of MNIST which we call MNIST sample which", "tokens": [309, 493, 13, 407, 321, 600, 2942, 364, 754, 18587, 3037, 295, 376, 45, 19756, 597, 321, 818, 376, 45, 19756, 6889, 597], "temperature": 0.0, "avg_logprob": -0.11539677367813286, "compression_ratio": 1.5603448275862069, "no_speech_prob": 1.903372663036862e-06}, {"id": 618, "seek": 400404, "start": 4004.04, "end": 4008.88, "text": " only has threes and sevens. Okay so this is a good starting point to make sure that we", "tokens": [787, 575, 258, 4856, 293, 3407, 82, 13, 1033, 370, 341, 307, 257, 665, 2891, 935, 281, 652, 988, 300, 321], "temperature": 0.0, "avg_logprob": -0.13589270571444897, "compression_ratio": 1.554585152838428, "no_speech_prob": 1.191105184261687e-06}, {"id": 619, "seek": 400404, "start": 4008.88, "end": 4013.0, "text": " can kind of do something easy. I picked threes and sevens MNIST sample because they're very", "tokens": [393, 733, 295, 360, 746, 1858, 13, 286, 6183, 258, 4856, 293, 3407, 82, 376, 45, 19756, 6889, 570, 436, 434, 588], "temperature": 0.0, "avg_logprob": -0.13589270571444897, "compression_ratio": 1.554585152838428, "no_speech_prob": 1.191105184261687e-06}, {"id": 620, "seek": 400404, "start": 4013.0, "end": 4017.08, "text": " different. I feel like if we can't do this we're going to have trouble recognizing every", "tokens": [819, 13, 286, 841, 411, 498, 321, 393, 380, 360, 341, 321, 434, 516, 281, 362, 5253, 18538, 633], "temperature": 0.0, "avg_logprob": -0.13589270571444897, "compression_ratio": 1.554585152838428, "no_speech_prob": 1.191105184261687e-06}, {"id": 621, "seek": 400404, "start": 4017.08, "end": 4029.24, "text": " digit. So step one is to call untar data. Untar data is the fast AI function which takes", "tokens": [14293, 13, 407, 1823, 472, 307, 281, 818, 1701, 289, 1412, 13, 8256, 289, 1412, 307, 264, 2370, 7318, 2445, 597, 2516], "temperature": 0.0, "avg_logprob": -0.13589270571444897, "compression_ratio": 1.554585152838428, "no_speech_prob": 1.191105184261687e-06}, {"id": 622, "seek": 402924, "start": 4029.24, "end": 4035.7599999999998, "text": " a URL, checks whether you've already downloaded it. If you haven't it downloads it, checks", "tokens": [257, 12905, 11, 13834, 1968, 291, 600, 1217, 21748, 309, 13, 759, 291, 2378, 380, 309, 36553, 309, 11, 13834], "temperature": 0.0, "avg_logprob": -0.16087028342233578, "compression_ratio": 1.705128205128205, "no_speech_prob": 1.1015922609658446e-06}, {"id": 623, "seek": 402924, "start": 4035.7599999999998, "end": 4040.04, "text": " whether you've already uncompressed it. If you haven't it uncompresses it and then it", "tokens": [1968, 291, 600, 1217, 8585, 79, 3805, 309, 13, 759, 291, 2378, 380, 309, 8585, 11637, 279, 309, 293, 550, 309], "temperature": 0.0, "avg_logprob": -0.16087028342233578, "compression_ratio": 1.705128205128205, "no_speech_prob": 1.1015922609658446e-06}, {"id": 624, "seek": 402924, "start": 4040.04, "end": 4048.68, "text": " finally returns the path of where that ended up. So you can see here is he URLs dot MNIST", "tokens": [2721, 11247, 264, 3100, 295, 689, 300, 4590, 493, 13, 407, 291, 393, 536, 510, 307, 415, 43267, 5893, 376, 45, 19756], "temperature": 0.0, "avg_logprob": -0.16087028342233578, "compression_ratio": 1.705128205128205, "no_speech_prob": 1.1015922609658446e-06}, {"id": 625, "seek": 404868, "start": 4048.68, "end": 4060.3999999999996, "text": " sample. So you could just hit tab to get autocomplete. It's just some location right. It doesn't", "tokens": [6889, 13, 407, 291, 727, 445, 2045, 4421, 281, 483, 45833, 298, 17220, 13, 467, 311, 445, 512, 4914, 558, 13, 467, 1177, 380], "temperature": 0.0, "avg_logprob": -0.17539313260246725, "compression_ratio": 1.5568181818181819, "no_speech_prob": 9.72153202383197e-07}, {"id": 626, "seek": 404868, "start": 4060.3999999999996, "end": 4067.7599999999998, "text": " really matter where it is. And so then when we call that I've already downloaded it and", "tokens": [534, 1871, 689, 309, 307, 13, 400, 370, 550, 562, 321, 818, 300, 286, 600, 1217, 21748, 309, 293], "temperature": 0.0, "avg_logprob": -0.17539313260246725, "compression_ratio": 1.5568181818181819, "no_speech_prob": 9.72153202383197e-07}, {"id": 627, "seek": 404868, "start": 4067.7599999999998, "end": 4071.08, "text": " already uncompressed it because I've already ran this once before so it happened straight", "tokens": [1217, 8585, 79, 3805, 309, 570, 286, 600, 1217, 5872, 341, 1564, 949, 370, 309, 2011, 2997], "temperature": 0.0, "avg_logprob": -0.17539313260246725, "compression_ratio": 1.5568181818181819, "no_speech_prob": 9.72153202383197e-07}, {"id": 628, "seek": 407108, "start": 4071.08, "end": 4079.56, "text": " away and so path shows me where it is. Now in this case path is dot and the reason path", "tokens": [1314, 293, 370, 3100, 3110, 385, 689, 309, 307, 13, 823, 294, 341, 1389, 3100, 307, 5893, 293, 264, 1778, 3100], "temperature": 0.0, "avg_logprob": -0.1257618056403266, "compression_ratio": 1.6878048780487804, "no_speech_prob": 1.1544600511115277e-06}, {"id": 629, "seek": 407108, "start": 4079.56, "end": 4086.04, "text": " is dot is because I've used a special base path attribute to path to tell it kind of", "tokens": [307, 5893, 307, 570, 286, 600, 1143, 257, 2121, 3096, 3100, 19667, 281, 3100, 281, 980, 309, 733, 295], "temperature": 0.0, "avg_logprob": -0.1257618056403266, "compression_ratio": 1.6878048780487804, "no_speech_prob": 1.1544600511115277e-06}, {"id": 630, "seek": 407108, "start": 4086.04, "end": 4091.6, "text": " like where's my where's my starting point you know and and that's used to print. So", "tokens": [411, 689, 311, 452, 689, 311, 452, 2891, 935, 291, 458, 293, 293, 300, 311, 1143, 281, 4482, 13, 407], "temperature": 0.0, "avg_logprob": -0.1257618056403266, "compression_ratio": 1.6878048780487804, "no_speech_prob": 1.1544600511115277e-06}, {"id": 631, "seek": 407108, "start": 4091.6, "end": 4098.24, "text": " when I go here ls which prints a list of files these are all relative to where I actually", "tokens": [562, 286, 352, 510, 287, 82, 597, 22305, 257, 1329, 295, 7098, 613, 366, 439, 4972, 281, 689, 286, 767], "temperature": 0.0, "avg_logprob": -0.1257618056403266, "compression_ratio": 1.6878048780487804, "no_speech_prob": 1.1544600511115277e-06}, {"id": 632, "seek": 409824, "start": 4098.24, "end": 4103.5199999999995, "text": " untarget this to. So it just makes it a lot easier not to have to see the whole set of", "tokens": [1701, 289, 847, 341, 281, 13, 407, 309, 445, 1669, 309, 257, 688, 3571, 406, 281, 362, 281, 536, 264, 1379, 992, 295], "temperature": 0.0, "avg_logprob": -0.2103794624930934, "compression_ratio": 1.5380116959064327, "no_speech_prob": 3.611973852457595e-06}, {"id": 633, "seek": 409824, "start": 4103.5199999999995, "end": 4119.44, "text": " parent path folders. Ls is actually so path is a let's see what kind of type it is. So", "tokens": [2596, 3100, 31082, 13, 441, 82, 307, 767, 370, 3100, 307, 257, 718, 311, 536, 437, 733, 295, 2010, 309, 307, 13, 407], "temperature": 0.0, "avg_logprob": -0.2103794624930934, "compression_ratio": 1.5380116959064327, "no_speech_prob": 3.611973852457595e-06}, {"id": 634, "seek": 409824, "start": 4119.44, "end": 4126.84, "text": " it's a pathlib path object. Pathlib is part of the Python standard library. It's a really", "tokens": [309, 311, 257, 3100, 38270, 3100, 2657, 13, 21914, 38270, 307, 644, 295, 264, 15329, 3832, 6405, 13, 467, 311, 257, 534], "temperature": 0.0, "avg_logprob": -0.2103794624930934, "compression_ratio": 1.5380116959064327, "no_speech_prob": 3.611973852457595e-06}, {"id": 635, "seek": 412684, "start": 4126.84, "end": 4133.34, "text": " very very very nice library but it doesn't actually have ls where there are libraries", "tokens": [588, 588, 588, 1481, 6405, 457, 309, 1177, 380, 767, 362, 287, 82, 689, 456, 366, 15148], "temperature": 0.0, "avg_logprob": -0.11239634062114515, "compression_ratio": 1.851063829787234, "no_speech_prob": 3.844920229312265e-06}, {"id": 636, "seek": 412684, "start": 4133.34, "end": 4137.4800000000005, "text": " that we find super helpful but they don't have exactly the things we want. We liberally", "tokens": [300, 321, 915, 1687, 4961, 457, 436, 500, 380, 362, 2293, 264, 721, 321, 528, 13, 492, 6774, 379], "temperature": 0.0, "avg_logprob": -0.11239634062114515, "compression_ratio": 1.851063829787234, "no_speech_prob": 3.844920229312265e-06}, {"id": 637, "seek": 412684, "start": 4137.4800000000005, "end": 4148.12, "text": " add the things we want to them. So we add ls. So if you want to find out what ls is", "tokens": [909, 264, 721, 321, 528, 281, 552, 13, 407, 321, 909, 287, 82, 13, 407, 498, 291, 528, 281, 915, 484, 437, 287, 82, 307], "temperature": 0.0, "avg_logprob": -0.11239634062114515, "compression_ratio": 1.851063829787234, "no_speech_prob": 3.844920229312265e-06}, {"id": 638, "seek": 412684, "start": 4148.12, "end": 4151.96, "text": " you know there's as we've mentioned there's a few ways you can do it. You can pop a question", "tokens": [291, 458, 456, 311, 382, 321, 600, 2835, 456, 311, 257, 1326, 2098, 291, 393, 360, 309, 13, 509, 393, 1665, 257, 1168], "temperature": 0.0, "avg_logprob": -0.11239634062114515, "compression_ratio": 1.851063829787234, "no_speech_prob": 3.844920229312265e-06}, {"id": 639, "seek": 412684, "start": 4151.96, "end": 4156.68, "text": " mark there and that will show you where it comes from. So there's actually a library", "tokens": [1491, 456, 293, 300, 486, 855, 291, 689, 309, 1487, 490, 13, 407, 456, 311, 767, 257, 6405], "temperature": 0.0, "avg_logprob": -0.11239634062114515, "compression_ratio": 1.851063829787234, "no_speech_prob": 3.844920229312265e-06}, {"id": 640, "seek": 415668, "start": 4156.68, "end": 4164.16, "text": " called fastcore which is a lot of the foundational stuff in fast AI that is not dependent on", "tokens": [1219, 2370, 12352, 597, 307, 257, 688, 295, 264, 32195, 1507, 294, 2370, 7318, 300, 307, 406, 12334, 322], "temperature": 0.0, "avg_logprob": -0.14934944576687284, "compression_ratio": 1.6164383561643836, "no_speech_prob": 7.112429329936276e-07}, {"id": 641, "seek": 415668, "start": 4164.16, "end": 4172.0, "text": " PyTorch or pandas or any of these big heavy libraries. So this is part of fastcore and", "tokens": [9953, 51, 284, 339, 420, 4565, 296, 420, 604, 295, 613, 955, 4676, 15148, 13, 407, 341, 307, 644, 295, 2370, 12352, 293], "temperature": 0.0, "avg_logprob": -0.14934944576687284, "compression_ratio": 1.6164383561643836, "no_speech_prob": 7.112429329936276e-07}, {"id": 642, "seek": 415668, "start": 4172.0, "end": 4175.04, "text": " if you want to see exactly what it does you of course remember you can put in a second", "tokens": [498, 291, 528, 281, 536, 2293, 437, 309, 775, 291, 295, 1164, 1604, 291, 393, 829, 294, 257, 1150], "temperature": 0.0, "avg_logprob": -0.14934944576687284, "compression_ratio": 1.6164383561643836, "no_speech_prob": 7.112429329936276e-07}, {"id": 643, "seek": 415668, "start": 4175.04, "end": 4183.08, "text": " question mark to get the source code and as you can see there's not much source code to", "tokens": [1168, 1491, 281, 483, 264, 4009, 3089, 293, 382, 291, 393, 536, 456, 311, 406, 709, 4009, 3089, 281], "temperature": 0.0, "avg_logprob": -0.14934944576687284, "compression_ratio": 1.6164383561643836, "no_speech_prob": 7.112429329936276e-07}, {"id": 644, "seek": 418308, "start": 4183.08, "end": 4191.64, "text": " do it and you know maybe most importantly please don't forget about doc because really", "tokens": [360, 309, 293, 291, 458, 1310, 881, 8906, 1767, 500, 380, 2870, 466, 3211, 570, 534], "temperature": 0.0, "avg_logprob": -0.18930815033993478, "compression_ratio": 1.4942528735632183, "no_speech_prob": 5.507566129381303e-06}, {"id": 645, "seek": 418308, "start": 4191.64, "end": 4195.88, "text": " importantly that gives you this show in docs link which you can click on to get to the", "tokens": [8906, 300, 2709, 291, 341, 855, 294, 45623, 2113, 597, 291, 393, 2052, 322, 281, 483, 281, 264], "temperature": 0.0, "avg_logprob": -0.18930815033993478, "compression_ratio": 1.4942528735632183, "no_speech_prob": 5.507566129381303e-06}, {"id": 646, "seek": 418308, "start": 4195.88, "end": 4207.24, "text": " documentation to see examples, pictures if relevant, tutorials, tests and so forth. So", "tokens": [14333, 281, 536, 5110, 11, 5242, 498, 7340, 11, 17616, 11, 6921, 293, 370, 5220, 13, 407], "temperature": 0.0, "avg_logprob": -0.18930815033993478, "compression_ratio": 1.4942528735632183, "no_speech_prob": 5.507566129381303e-06}, {"id": 647, "seek": 420724, "start": 4207.24, "end": 4213.32, "text": " what's so when you're looking at a new data set you kind of just I always start with just", "tokens": [437, 311, 370, 562, 291, 434, 1237, 412, 257, 777, 1412, 992, 291, 733, 295, 445, 286, 1009, 722, 365, 445], "temperature": 0.0, "avg_logprob": -0.11447786291440327, "compression_ratio": 1.7475247524752475, "no_speech_prob": 4.181181623152952e-07}, {"id": 648, "seek": 420724, "start": 4213.32, "end": 4219.36, "text": " ls see what's in it and I can see here there's a train folder and there's a valid folder", "tokens": [287, 82, 536, 437, 311, 294, 309, 293, 286, 393, 536, 510, 456, 311, 257, 3847, 10820, 293, 456, 311, 257, 7363, 10820], "temperature": 0.0, "avg_logprob": -0.11447786291440327, "compression_ratio": 1.7475247524752475, "no_speech_prob": 4.181181623152952e-07}, {"id": 649, "seek": 420724, "start": 4219.36, "end": 4226.5199999999995, "text": " that's pretty normal. So let's look at ls on the train folder and it's got a folder", "tokens": [300, 311, 1238, 2710, 13, 407, 718, 311, 574, 412, 287, 82, 322, 264, 3847, 10820, 293, 309, 311, 658, 257, 10820], "temperature": 0.0, "avg_logprob": -0.11447786291440327, "compression_ratio": 1.7475247524752475, "no_speech_prob": 4.181181623152952e-07}, {"id": 650, "seek": 420724, "start": 4226.5199999999995, "end": 4233.08, "text": " called 7 and a folder called 3 and so this is looking quite a lot like our bare classifier", "tokens": [1219, 1614, 293, 257, 10820, 1219, 805, 293, 370, 341, 307, 1237, 1596, 257, 688, 411, 527, 6949, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.11447786291440327, "compression_ratio": 1.7475247524752475, "no_speech_prob": 4.181181623152952e-07}, {"id": 651, "seek": 423308, "start": 4233.08, "end": 4240.0, "text": " data set we downloaded each set of images into a folder based on what its label was.", "tokens": [1412, 992, 321, 21748, 1184, 992, 295, 5267, 666, 257, 10820, 2361, 322, 437, 1080, 7645, 390, 13], "temperature": 0.0, "avg_logprob": -0.10209065173045699, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.989710819496395e-07}, {"id": 652, "seek": 423308, "start": 4240.0, "end": 4245.12, "text": " This is doing it at another level though the first level of the folder hierarchy is it", "tokens": [639, 307, 884, 309, 412, 1071, 1496, 1673, 264, 700, 1496, 295, 264, 10820, 22333, 307, 309], "temperature": 0.0, "avg_logprob": -0.10209065173045699, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.989710819496395e-07}, {"id": 653, "seek": 423308, "start": 4245.12, "end": 4251.32, "text": " training or valid and the second level is what's the label and this is the most common", "tokens": [3097, 420, 7363, 293, 264, 1150, 1496, 307, 437, 311, 264, 7645, 293, 341, 307, 264, 881, 2689], "temperature": 0.0, "avg_logprob": -0.10209065173045699, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.989710819496395e-07}, {"id": 654, "seek": 423308, "start": 4251.32, "end": 4261.46, "text": " way for image data sets to be distributed. So let's have a look let's just create something", "tokens": [636, 337, 3256, 1412, 6352, 281, 312, 12631, 13, 407, 718, 311, 362, 257, 574, 718, 311, 445, 1884, 746], "temperature": 0.0, "avg_logprob": -0.10209065173045699, "compression_ratio": 1.674641148325359, "no_speech_prob": 3.989710819496395e-07}, {"id": 655, "seek": 426146, "start": 4261.46, "end": 4267.84, "text": " called threes that contains all of the contents of three directory training and let's just", "tokens": [1219, 258, 4856, 300, 8306, 439, 295, 264, 15768, 295, 1045, 21120, 3097, 293, 718, 311, 445], "temperature": 0.0, "avg_logprob": -0.1410368372885029, "compression_ratio": 1.7537688442211055, "no_speech_prob": 1.4367469702847302e-06}, {"id": 656, "seek": 426146, "start": 4267.84, "end": 4272.0, "text": " sort them so that this is consistent do the same for sevens and let's just look at the", "tokens": [1333, 552, 370, 300, 341, 307, 8398, 360, 264, 912, 337, 3407, 82, 293, 718, 311, 445, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.1410368372885029, "compression_ratio": 1.7537688442211055, "no_speech_prob": 1.4367469702847302e-06}, {"id": 657, "seek": 426146, "start": 4272.0, "end": 4278.88, "text": " threes and you can see there's just they're just numbered. All right so let's grab one", "tokens": [258, 4856, 293, 291, 393, 536, 456, 311, 445, 436, 434, 445, 40936, 13, 1057, 558, 370, 718, 311, 4444, 472], "temperature": 0.0, "avg_logprob": -0.1410368372885029, "compression_ratio": 1.7537688442211055, "no_speech_prob": 1.4367469702847302e-06}, {"id": 658, "seek": 426146, "start": 4278.88, "end": 4287.4800000000005, "text": " of those open it and take a look. Okay so there's the picture of a three and so what", "tokens": [295, 729, 1269, 309, 293, 747, 257, 574, 13, 1033, 370, 456, 311, 264, 3036, 295, 257, 1045, 293, 370, 437], "temperature": 0.0, "avg_logprob": -0.1410368372885029, "compression_ratio": 1.7537688442211055, "no_speech_prob": 1.4367469702847302e-06}, {"id": 659, "seek": 428748, "start": 4287.48, "end": 4298.919999999999, "text": " is that really? Not three, I am three. So PIO is the Python imaging library it's the", "tokens": [307, 300, 534, 30, 1726, 1045, 11, 286, 669, 1045, 13, 407, 430, 15167, 307, 264, 15329, 25036, 6405, 309, 311, 264], "temperature": 0.0, "avg_logprob": -0.21170620123545328, "compression_ratio": 1.335820895522388, "no_speech_prob": 1.9142865426147182e-07}, {"id": 660, "seek": 428748, "start": 4298.919999999999, "end": 4309.679999999999, "text": " most popular library by far for working with images on Python and it's a PNG not surprisingly.", "tokens": [881, 3743, 6405, 538, 1400, 337, 1364, 365, 5267, 322, 15329, 293, 309, 311, 257, 430, 30237, 406, 17600, 13], "temperature": 0.0, "avg_logprob": -0.21170620123545328, "compression_ratio": 1.335820895522388, "no_speech_prob": 1.9142865426147182e-07}, {"id": 661, "seek": 430968, "start": 4309.68, "end": 4317.68, "text": " So Jupyter Notebook knows how to display many different types and you can actually tell", "tokens": [407, 22125, 88, 391, 11633, 2939, 3255, 577, 281, 4674, 867, 819, 3467, 293, 291, 393, 767, 980], "temperature": 0.0, "avg_logprob": -0.09578242391910192, "compression_ratio": 1.7622950819672132, "no_speech_prob": 2.3454325059901748e-07}, {"id": 662, "seek": 430968, "start": 4317.68, "end": 4321.900000000001, "text": " if you create a new type you can tell it how to display your type and so PIO comes with", "tokens": [498, 291, 1884, 257, 777, 2010, 291, 393, 980, 309, 577, 281, 4674, 428, 2010, 293, 370, 430, 15167, 1487, 365], "temperature": 0.0, "avg_logprob": -0.09578242391910192, "compression_ratio": 1.7622950819672132, "no_speech_prob": 2.3454325059901748e-07}, {"id": 663, "seek": 430968, "start": 4321.900000000001, "end": 4327.200000000001, "text": " something that will automatically display the image like so. What I want to do here", "tokens": [746, 300, 486, 6772, 4674, 264, 3256, 411, 370, 13, 708, 286, 528, 281, 360, 510], "temperature": 0.0, "avg_logprob": -0.09578242391910192, "compression_ratio": 1.7622950819672132, "no_speech_prob": 2.3454325059901748e-07}, {"id": 664, "seek": 430968, "start": 4327.200000000001, "end": 4333.6, "text": " though is to look at like how are we going to treat this as numbers right and so one", "tokens": [1673, 307, 281, 574, 412, 411, 577, 366, 321, 516, 281, 2387, 341, 382, 3547, 558, 293, 370, 472], "temperature": 0.0, "avg_logprob": -0.09578242391910192, "compression_ratio": 1.7622950819672132, "no_speech_prob": 2.3454325059901748e-07}, {"id": 665, "seek": 430968, "start": 4333.6, "end": 4338.72, "text": " easy way to treat things as numbers is to turn it into an array. The array is part of", "tokens": [1858, 636, 281, 2387, 721, 382, 3547, 307, 281, 1261, 309, 666, 364, 10225, 13, 440, 10225, 307, 644, 295], "temperature": 0.0, "avg_logprob": -0.09578242391910192, "compression_ratio": 1.7622950819672132, "no_speech_prob": 2.3454325059901748e-07}, {"id": 666, "seek": 433872, "start": 4338.72, "end": 4350.240000000001, "text": " NumPy which is the most popular array programming library for Python and so if we pass our PIO", "tokens": [22592, 47, 88, 597, 307, 264, 881, 3743, 10225, 9410, 6405, 337, 15329, 293, 370, 498, 321, 1320, 527, 430, 15167], "temperature": 0.0, "avg_logprob": -0.08614566408354661, "compression_ratio": 1.6985645933014355, "no_speech_prob": 1.0348513796998304e-06}, {"id": 667, "seek": 433872, "start": 4350.240000000001, "end": 4356.2, "text": " image object to array it just converts the image into a bunch of numbers and the truth", "tokens": [3256, 2657, 281, 10225, 309, 445, 38874, 264, 3256, 666, 257, 3840, 295, 3547, 293, 264, 3494], "temperature": 0.0, "avg_logprob": -0.08614566408354661, "compression_ratio": 1.6985645933014355, "no_speech_prob": 1.0348513796998304e-06}, {"id": 668, "seek": 433872, "start": 4356.2, "end": 4360.280000000001, "text": " is it was a bunch of numbers the whole time it was actually stored as a bunch of numbers", "tokens": [307, 309, 390, 257, 3840, 295, 3547, 264, 1379, 565, 309, 390, 767, 12187, 382, 257, 3840, 295, 3547], "temperature": 0.0, "avg_logprob": -0.08614566408354661, "compression_ratio": 1.6985645933014355, "no_speech_prob": 1.0348513796998304e-06}, {"id": 669, "seek": 433872, "start": 4360.280000000001, "end": 4365.16, "text": " on disk it's just that there's this magic thing in Jupyter that knows how to display", "tokens": [322, 12355, 309, 311, 445, 300, 456, 311, 341, 5585, 551, 294, 22125, 88, 391, 300, 3255, 577, 281, 4674], "temperature": 0.0, "avg_logprob": -0.08614566408354661, "compression_ratio": 1.6985645933014355, "no_speech_prob": 1.0348513796998304e-06}, {"id": 670, "seek": 436516, "start": 4365.16, "end": 4371.28, "text": " those numbers on the screen. So when we say array turning it back into a NumPy array we're", "tokens": [729, 3547, 322, 264, 2568, 13, 407, 562, 321, 584, 10225, 6246, 309, 646, 666, 257, 22592, 47, 88, 10225, 321, 434], "temperature": 0.0, "avg_logprob": -0.0961560075933283, "compression_ratio": 1.7003891050583657, "no_speech_prob": 4.313909300890373e-07}, {"id": 671, "seek": 436516, "start": 4371.28, "end": 4375.72, "text": " kind of removing this ability for Jupyter Notebook to know how to display it like a", "tokens": [733, 295, 12720, 341, 3485, 337, 22125, 88, 391, 11633, 2939, 281, 458, 577, 281, 4674, 309, 411, 257], "temperature": 0.0, "avg_logprob": -0.0961560075933283, "compression_ratio": 1.7003891050583657, "no_speech_prob": 4.313909300890373e-07}, {"id": 672, "seek": 436516, "start": 4375.72, "end": 4381.36, "text": " picture. So once I do this we can then index into that array and create everything from", "tokens": [3036, 13, 407, 1564, 286, 360, 341, 321, 393, 550, 8186, 666, 300, 10225, 293, 1884, 1203, 490], "temperature": 0.0, "avg_logprob": -0.0961560075933283, "compression_ratio": 1.7003891050583657, "no_speech_prob": 4.313909300890373e-07}, {"id": 673, "seek": 436516, "start": 4381.36, "end": 4386.88, "text": " the grab everything all the rows from 4 up to but not including 10 and all the columns", "tokens": [264, 4444, 1203, 439, 264, 13241, 490, 1017, 493, 281, 457, 406, 3009, 1266, 293, 439, 264, 13766], "temperature": 0.0, "avg_logprob": -0.0961560075933283, "compression_ratio": 1.7003891050583657, "no_speech_prob": 4.313909300890373e-07}, {"id": 674, "seek": 436516, "start": 4386.88, "end": 4394.2, "text": " from 4 up to and not including 10 and here are some numbers and they are 8-bit unsigned", "tokens": [490, 1017, 493, 281, 293, 406, 3009, 1266, 293, 510, 366, 512, 3547, 293, 436, 366, 1649, 12, 5260, 2693, 16690], "temperature": 0.0, "avg_logprob": -0.0961560075933283, "compression_ratio": 1.7003891050583657, "no_speech_prob": 4.313909300890373e-07}, {"id": 675, "seek": 439420, "start": 4394.2, "end": 4400.72, "text": " integers so they are between 0 and 255. So an image just like everything on a computer", "tokens": [41674, 370, 436, 366, 1296, 1958, 293, 3552, 20, 13, 407, 364, 3256, 445, 411, 1203, 322, 257, 3820], "temperature": 0.0, "avg_logprob": -0.08419913388370129, "compression_ratio": 1.5610859728506787, "no_speech_prob": 8.579224868299207e-07}, {"id": 676, "seek": 439420, "start": 4400.72, "end": 4407.96, "text": " is just a bunch of numbers and therefore we can compute with it. We could do the same", "tokens": [307, 445, 257, 3840, 295, 3547, 293, 4412, 321, 393, 14722, 365, 309, 13, 492, 727, 360, 264, 912], "temperature": 0.0, "avg_logprob": -0.08419913388370129, "compression_ratio": 1.5610859728506787, "no_speech_prob": 8.579224868299207e-07}, {"id": 677, "seek": 439420, "start": 4407.96, "end": 4414.28, "text": " thing but instead of saying array we could say tensor. Now a tensor is basically the", "tokens": [551, 457, 2602, 295, 1566, 10225, 321, 727, 584, 40863, 13, 823, 257, 40863, 307, 1936, 264], "temperature": 0.0, "avg_logprob": -0.08419913388370129, "compression_ratio": 1.5610859728506787, "no_speech_prob": 8.579224868299207e-07}, {"id": 678, "seek": 439420, "start": 4414.28, "end": 4421.12, "text": " PyTorch version of a NumPy array and so you can see it looks it's exactly the same code", "tokens": [9953, 51, 284, 339, 3037, 295, 257, 22592, 47, 88, 10225, 293, 370, 291, 393, 536, 309, 1542, 309, 311, 2293, 264, 912, 3089], "temperature": 0.0, "avg_logprob": -0.08419913388370129, "compression_ratio": 1.5610859728506787, "no_speech_prob": 8.579224868299207e-07}, {"id": 679, "seek": 442112, "start": 4421.12, "end": 4425.96, "text": " as above but I've just replaced array with tensor and the output looks almost exactly", "tokens": [382, 3673, 457, 286, 600, 445, 10772, 10225, 365, 40863, 293, 264, 5598, 1542, 1920, 2293], "temperature": 0.0, "avg_logprob": -0.06600224210860882, "compression_ratio": 1.68348623853211, "no_speech_prob": 7.690370580348826e-07}, {"id": 680, "seek": 442112, "start": 4425.96, "end": 4431.64, "text": " the same except it replaces array with tensor and so you'll see this that basically a PyTorch", "tokens": [264, 912, 3993, 309, 46734, 10225, 365, 40863, 293, 370, 291, 603, 536, 341, 300, 1936, 257, 9953, 51, 284, 339], "temperature": 0.0, "avg_logprob": -0.06600224210860882, "compression_ratio": 1.68348623853211, "no_speech_prob": 7.690370580348826e-07}, {"id": 681, "seek": 442112, "start": 4431.64, "end": 4440.5199999999995, "text": " tensor and a NumPy array behave nearly identically much if not most of the time but the key thing", "tokens": [40863, 293, 257, 22592, 47, 88, 10225, 15158, 6217, 2473, 984, 709, 498, 406, 881, 295, 264, 565, 457, 264, 2141, 551], "temperature": 0.0, "avg_logprob": -0.06600224210860882, "compression_ratio": 1.68348623853211, "no_speech_prob": 7.690370580348826e-07}, {"id": 682, "seek": 442112, "start": 4440.5199999999995, "end": 4449.8, "text": " is that a PyTorch tensor can also be computed on a GPU not just a CPU. So in our work and", "tokens": [307, 300, 257, 9953, 51, 284, 339, 40863, 393, 611, 312, 40610, 322, 257, 18407, 406, 445, 257, 13199, 13, 407, 294, 527, 589, 293], "temperature": 0.0, "avg_logprob": -0.06600224210860882, "compression_ratio": 1.68348623853211, "no_speech_prob": 7.690370580348826e-07}, {"id": 683, "seek": 444980, "start": 4449.8, "end": 4455.84, "text": " in the book and in the notebooks and in our code we tend to use tensors PyTorch tensors", "tokens": [294, 264, 1446, 293, 294, 264, 43782, 293, 294, 527, 3089, 321, 3928, 281, 764, 10688, 830, 9953, 51, 284, 339, 10688, 830], "temperature": 0.0, "avg_logprob": -0.06138872889290869, "compression_ratio": 1.742063492063492, "no_speech_prob": 1.7603391597731388e-06}, {"id": 684, "seek": 444980, "start": 4455.84, "end": 4459.76, "text": " much more often than NumPy arrays because they kind of have nearly all the benefits", "tokens": [709, 544, 2049, 813, 22592, 47, 88, 41011, 570, 436, 733, 295, 362, 6217, 439, 264, 5311], "temperature": 0.0, "avg_logprob": -0.06138872889290869, "compression_ratio": 1.742063492063492, "no_speech_prob": 1.7603391597731388e-06}, {"id": 685, "seek": 444980, "start": 4459.76, "end": 4464.92, "text": " of NumPy arrays plus all the benefits of GPU computation and they've got a whole lot of", "tokens": [295, 22592, 47, 88, 41011, 1804, 439, 264, 5311, 295, 18407, 24903, 293, 436, 600, 658, 257, 1379, 688, 295], "temperature": 0.0, "avg_logprob": -0.06138872889290869, "compression_ratio": 1.742063492063492, "no_speech_prob": 1.7603391597731388e-06}, {"id": 686, "seek": 444980, "start": 4464.92, "end": 4474.12, "text": " extra functionality as well. A lot of people who have used Python for a long time always", "tokens": [2857, 14980, 382, 731, 13, 316, 688, 295, 561, 567, 362, 1143, 15329, 337, 257, 938, 565, 1009], "temperature": 0.0, "avg_logprob": -0.06138872889290869, "compression_ratio": 1.742063492063492, "no_speech_prob": 1.7603391597731388e-06}, {"id": 687, "seek": 444980, "start": 4474.12, "end": 4478.8, "text": " jump into NumPy because that's what they're used to. If that's you you might want to start", "tokens": [3012, 666, 22592, 47, 88, 570, 300, 311, 437, 436, 434, 1143, 281, 13, 759, 300, 311, 291, 291, 1062, 528, 281, 722], "temperature": 0.0, "avg_logprob": -0.06138872889290869, "compression_ratio": 1.742063492063492, "no_speech_prob": 1.7603391597731388e-06}, {"id": 688, "seek": 447880, "start": 4478.8, "end": 4484.0, "text": " considering jumping into tensor like wherever you used to write array start writing tensor", "tokens": [8079, 11233, 666, 40863, 411, 8660, 291, 1143, 281, 2464, 10225, 722, 3579, 40863], "temperature": 0.0, "avg_logprob": -0.10080990490612683, "compression_ratio": 1.8024193548387097, "no_speech_prob": 4.356863883003825e-06}, {"id": 689, "seek": 447880, "start": 4484.0, "end": 4487.76, "text": " and just see what happens because you might be surprised at how many things you can speed", "tokens": [293, 445, 536, 437, 2314, 570, 291, 1062, 312, 6100, 412, 577, 867, 721, 291, 393, 3073], "temperature": 0.0, "avg_logprob": -0.10080990490612683, "compression_ratio": 1.8024193548387097, "no_speech_prob": 4.356863883003825e-06}, {"id": 690, "seek": 447880, "start": 4487.76, "end": 4496.76, "text": " up or do more easily. So let's grab that that three image turn it into a tensor and so that's", "tokens": [493, 420, 360, 544, 3612, 13, 407, 718, 311, 4444, 300, 300, 1045, 3256, 1261, 309, 666, 257, 40863, 293, 370, 300, 311], "temperature": 0.0, "avg_logprob": -0.10080990490612683, "compression_ratio": 1.8024193548387097, "no_speech_prob": 4.356863883003825e-06}, {"id": 691, "seek": 447880, "start": 4496.76, "end": 4502.56, "text": " going to be three image tensor that's why I've got im3t. Okay and let's grab a bit of", "tokens": [516, 281, 312, 1045, 3256, 40863, 300, 311, 983, 286, 600, 658, 566, 18, 83, 13, 1033, 293, 718, 311, 4444, 257, 857, 295], "temperature": 0.0, "avg_logprob": -0.10080990490612683, "compression_ratio": 1.8024193548387097, "no_speech_prob": 4.356863883003825e-06}, {"id": 692, "seek": 447880, "start": 4502.56, "end": 4507.6, "text": " it okay and turn it into a pandas data frame and the only reason I'm turning it into a", "tokens": [309, 1392, 293, 1261, 309, 666, 257, 4565, 296, 1412, 3920, 293, 264, 787, 1778, 286, 478, 6246, 309, 666, 257], "temperature": 0.0, "avg_logprob": -0.10080990490612683, "compression_ratio": 1.8024193548387097, "no_speech_prob": 4.356863883003825e-06}, {"id": 693, "seek": 450760, "start": 4507.6, "end": 4512.280000000001, "text": " pandas data frame is that pandas has a very convenient thing called background gradient", "tokens": [4565, 296, 1412, 3920, 307, 300, 4565, 296, 575, 257, 588, 10851, 551, 1219, 3678, 16235], "temperature": 0.0, "avg_logprob": -0.14081947758512678, "compression_ratio": 1.83402489626556, "no_speech_prob": 1.0030123576143524e-06}, {"id": 694, "seek": 450760, "start": 4512.280000000001, "end": 4519.1, "text": " that turns a background into a gradient as you can see. So here is the top bit of three", "tokens": [300, 4523, 257, 3678, 666, 257, 16235, 382, 291, 393, 536, 13, 407, 510, 307, 264, 1192, 857, 295, 1045], "temperature": 0.0, "avg_logprob": -0.14081947758512678, "compression_ratio": 1.83402489626556, "no_speech_prob": 1.0030123576143524e-06}, {"id": 695, "seek": 450760, "start": 4519.1, "end": 4526.0, "text": " you can see that the zeros of the whites and the numbers near 255 are the blacks and there's", "tokens": [291, 393, 536, 300, 264, 35193, 295, 264, 21909, 293, 264, 3547, 2651, 3552, 20, 366, 264, 30720, 293, 456, 311], "temperature": 0.0, "avg_logprob": -0.14081947758512678, "compression_ratio": 1.83402489626556, "no_speech_prob": 1.0030123576143524e-06}, {"id": 696, "seek": 450760, "start": 4526.0, "end": 4530.84, "text": " some what's it bits in the middle which are which are gray. So here we have we can see", "tokens": [512, 437, 311, 309, 9239, 294, 264, 2808, 597, 366, 597, 366, 10855, 13, 407, 510, 321, 362, 321, 393, 536], "temperature": 0.0, "avg_logprob": -0.14081947758512678, "compression_ratio": 1.83402489626556, "no_speech_prob": 1.0030123576143524e-06}, {"id": 697, "seek": 450760, "start": 4530.84, "end": 4536.900000000001, "text": " what's going on when our images which are numbers actually get displayed on the screen", "tokens": [437, 311, 516, 322, 562, 527, 5267, 597, 366, 3547, 767, 483, 16372, 322, 264, 2568], "temperature": 0.0, "avg_logprob": -0.14081947758512678, "compression_ratio": 1.83402489626556, "no_speech_prob": 1.0030123576143524e-06}, {"id": 698, "seek": 453690, "start": 4536.9, "end": 4543.5599999999995, "text": " it's just it's just doing this. And so I'm just showing a subset here the actual full", "tokens": [309, 311, 445, 309, 311, 445, 884, 341, 13, 400, 370, 286, 478, 445, 4099, 257, 25993, 510, 264, 3539, 1577], "temperature": 0.0, "avg_logprob": -0.14183386752479954, "compression_ratio": 1.5681818181818181, "no_speech_prob": 8.446217520940991e-07}, {"id": 699, "seek": 453690, "start": 4543.5599999999995, "end": 4551.96, "text": " number in mnist is a 28 by 28 pixel square so that's 768 pixels. So that's super tiny", "tokens": [1230, 294, 275, 77, 468, 307, 257, 7562, 538, 7562, 19261, 3732, 370, 300, 311, 24733, 23, 18668, 13, 407, 300, 311, 1687, 5870], "temperature": 0.0, "avg_logprob": -0.14183386752479954, "compression_ratio": 1.5681818181818181, "no_speech_prob": 8.446217520940991e-07}, {"id": 700, "seek": 453690, "start": 4551.96, "end": 4557.08, "text": " right where my mobile phone I don't know how many megapixels it is but it's millions of", "tokens": [558, 689, 452, 6013, 2593, 286, 500, 380, 458, 577, 867, 34733, 970, 1625, 309, 307, 457, 309, 311, 6803, 295], "temperature": 0.0, "avg_logprob": -0.14183386752479954, "compression_ratio": 1.5681818181818181, "no_speech_prob": 8.446217520940991e-07}, {"id": 701, "seek": 453690, "start": 4557.08, "end": 4565.2, "text": " pixels so it's nice to start with something simple and small. Okay so here's our goal", "tokens": [18668, 370, 309, 311, 1481, 281, 722, 365, 746, 2199, 293, 1359, 13, 1033, 370, 510, 311, 527, 3387], "temperature": 0.0, "avg_logprob": -0.14183386752479954, "compression_ratio": 1.5681818181818181, "no_speech_prob": 8.446217520940991e-07}, {"id": 702, "seek": 456520, "start": 4565.2, "end": 4572.4, "text": " create a model but by model it has been some kind of computer program learnt from data", "tokens": [1884, 257, 2316, 457, 538, 2316, 309, 575, 668, 512, 733, 295, 3820, 1461, 18991, 490, 1412], "temperature": 0.0, "avg_logprob": -0.1298518074883355, "compression_ratio": 1.6952380952380952, "no_speech_prob": 4.029439423902659e-06}, {"id": 703, "seek": 456520, "start": 4572.4, "end": 4577.08, "text": " that can recognize threes versus sevens. You could think of it as a three detector is it", "tokens": [300, 393, 5521, 258, 4856, 5717, 3407, 82, 13, 509, 727, 519, 295, 309, 382, 257, 1045, 25712, 307, 309], "temperature": 0.0, "avg_logprob": -0.1298518074883355, "compression_ratio": 1.6952380952380952, "no_speech_prob": 4.029439423902659e-06}, {"id": 704, "seek": 456520, "start": 4577.08, "end": 4583.5599999999995, "text": " a three because if it's not a three it's a seven. So have it stop here pause the video", "tokens": [257, 1045, 570, 498, 309, 311, 406, 257, 1045, 309, 311, 257, 3407, 13, 407, 362, 309, 1590, 510, 10465, 264, 960], "temperature": 0.0, "avg_logprob": -0.1298518074883355, "compression_ratio": 1.6952380952380952, "no_speech_prob": 4.029439423902659e-06}, {"id": 705, "seek": 456520, "start": 4583.5599999999995, "end": 4588.98, "text": " and have a think how would you do it how would you like you don't need to know anything about", "tokens": [293, 362, 257, 519, 577, 576, 291, 360, 309, 577, 576, 291, 411, 291, 500, 380, 643, 281, 458, 1340, 466], "temperature": 0.0, "avg_logprob": -0.1298518074883355, "compression_ratio": 1.6952380952380952, "no_speech_prob": 4.029439423902659e-06}, {"id": 706, "seek": 458898, "start": 4588.98, "end": 4596.48, "text": " neural networks or anything else how might you just with common sense build a tree detector.", "tokens": [18161, 9590, 420, 1340, 1646, 577, 1062, 291, 445, 365, 2689, 2020, 1322, 257, 4230, 25712, 13], "temperature": 0.0, "avg_logprob": -0.14795070470765578, "compression_ratio": 1.6136363636363635, "no_speech_prob": 2.058041445707204e-06}, {"id": 707, "seek": 458898, "start": 4596.48, "end": 4603.959999999999, "text": " Okay so I hope you grabbed a piece of paper pen jotted some notes down. I'll tell you", "tokens": [1033, 370, 286, 1454, 291, 18607, 257, 2522, 295, 3035, 3435, 361, 11252, 512, 5570, 760, 13, 286, 603, 980, 291], "temperature": 0.0, "avg_logprob": -0.14795070470765578, "compression_ratio": 1.6136363636363635, "no_speech_prob": 2.058041445707204e-06}, {"id": 708, "seek": 458898, "start": 4603.959999999999, "end": 4610.639999999999, "text": " the first idea that came into my head was what if we grab every single three in the", "tokens": [264, 700, 1558, 300, 1361, 666, 452, 1378, 390, 437, 498, 321, 4444, 633, 2167, 1045, 294, 264], "temperature": 0.0, "avg_logprob": -0.14795070470765578, "compression_ratio": 1.6136363636363635, "no_speech_prob": 2.058041445707204e-06}, {"id": 709, "seek": 458898, "start": 4610.639999999999, "end": 4618.959999999999, "text": " data set and take the average of the pixels. So what's the average of this pixel the average", "tokens": [1412, 992, 293, 747, 264, 4274, 295, 264, 18668, 13, 407, 437, 311, 264, 4274, 295, 341, 19261, 264, 4274], "temperature": 0.0, "avg_logprob": -0.14795070470765578, "compression_ratio": 1.6136363636363635, "no_speech_prob": 2.058041445707204e-06}, {"id": 710, "seek": 461896, "start": 4618.96, "end": 4623.32, "text": " of this pixel the average of this pixel the average of this pixel right and so there'll", "tokens": [295, 341, 19261, 264, 4274, 295, 341, 19261, 264, 4274, 295, 341, 19261, 558, 293, 370, 456, 603], "temperature": 0.0, "avg_logprob": -0.11003001169724898, "compression_ratio": 1.8936170212765957, "no_speech_prob": 2.156805976483156e-06}, {"id": 711, "seek": 461896, "start": 4623.32, "end": 4630.96, "text": " be a 28 by 28 picture which is the average of all of the threes and that would be like", "tokens": [312, 257, 7562, 538, 7562, 3036, 597, 307, 264, 4274, 295, 439, 295, 264, 258, 4856, 293, 300, 576, 312, 411], "temperature": 0.0, "avg_logprob": -0.11003001169724898, "compression_ratio": 1.8936170212765957, "no_speech_prob": 2.156805976483156e-06}, {"id": 712, "seek": 461896, "start": 4630.96, "end": 4637.16, "text": " the ideal three and then we'll do the same for sevens and then so when we then grab something", "tokens": [264, 7157, 1045, 293, 550, 321, 603, 360, 264, 912, 337, 3407, 82, 293, 550, 370, 562, 321, 550, 4444, 746], "temperature": 0.0, "avg_logprob": -0.11003001169724898, "compression_ratio": 1.8936170212765957, "no_speech_prob": 2.156805976483156e-06}, {"id": 713, "seek": 461896, "start": 4637.16, "end": 4644.2, "text": " from the validation set to classify we'll say like oh is this image closer to the ideal", "tokens": [490, 264, 24071, 992, 281, 33872, 321, 603, 584, 411, 1954, 307, 341, 3256, 4966, 281, 264, 7157], "temperature": 0.0, "avg_logprob": -0.11003001169724898, "compression_ratio": 1.8936170212765957, "no_speech_prob": 2.156805976483156e-06}, {"id": 714, "seek": 464420, "start": 4644.2, "end": 4651.0, "text": " threes the ideal three the mean of the threes or the ideal seven. This is my idea and so", "tokens": [258, 4856, 264, 7157, 1045, 264, 914, 295, 264, 258, 4856, 420, 264, 7157, 3407, 13, 639, 307, 452, 1558, 293, 370], "temperature": 0.0, "avg_logprob": -0.09516309534461753, "compression_ratio": 1.7450980392156863, "no_speech_prob": 2.902305823226925e-06}, {"id": 715, "seek": 464420, "start": 4651.0, "end": 4656.24, "text": " I'm going to call this the pixel similarity approach. I'm describing this as a baseline", "tokens": [286, 478, 516, 281, 818, 341, 264, 19261, 32194, 3109, 13, 286, 478, 16141, 341, 382, 257, 20518], "temperature": 0.0, "avg_logprob": -0.09516309534461753, "compression_ratio": 1.7450980392156863, "no_speech_prob": 2.902305823226925e-06}, {"id": 716, "seek": 464420, "start": 4656.24, "end": 4661.5199999999995, "text": " a baseline is like a super simple model that should be pretty easy to program from scratch", "tokens": [257, 20518, 307, 411, 257, 1687, 2199, 2316, 300, 820, 312, 1238, 1858, 281, 1461, 490, 8459], "temperature": 0.0, "avg_logprob": -0.09516309534461753, "compression_ratio": 1.7450980392156863, "no_speech_prob": 2.902305823226925e-06}, {"id": 717, "seek": 464420, "start": 4661.5199999999995, "end": 4665.36, "text": " with very little magic you know maybe it's just a bunch of kind of simple averages simple", "tokens": [365, 588, 707, 5585, 291, 458, 1310, 309, 311, 445, 257, 3840, 295, 733, 295, 2199, 42257, 2199], "temperature": 0.0, "avg_logprob": -0.09516309534461753, "compression_ratio": 1.7450980392156863, "no_speech_prob": 2.902305823226925e-06}, {"id": 718, "seek": 464420, "start": 4665.36, "end": 4671.04, "text": " arithmetic which you're super confident is going to be better than better than a random", "tokens": [42973, 597, 291, 434, 1687, 6679, 307, 516, 281, 312, 1101, 813, 1101, 813, 257, 4974], "temperature": 0.0, "avg_logprob": -0.09516309534461753, "compression_ratio": 1.7450980392156863, "no_speech_prob": 2.902305823226925e-06}, {"id": 719, "seek": 467104, "start": 4671.04, "end": 4678.28, "text": " model right and one of the biggest mistakes I see in even experienced practitioners is", "tokens": [2316, 558, 293, 472, 295, 264, 3880, 8038, 286, 536, 294, 754, 6751, 25742, 307], "temperature": 0.0, "avg_logprob": -0.10141589317792728, "compression_ratio": 1.7647058823529411, "no_speech_prob": 1.7880619225252303e-06}, {"id": 720, "seek": 467104, "start": 4678.28, "end": 4684.0, "text": " that they fail to create a baseline and so then they build some fancy Bayesian model", "tokens": [300, 436, 3061, 281, 1884, 257, 20518, 293, 370, 550, 436, 1322, 512, 10247, 7840, 42434, 2316], "temperature": 0.0, "avg_logprob": -0.10141589317792728, "compression_ratio": 1.7647058823529411, "no_speech_prob": 1.7880619225252303e-06}, {"id": 721, "seek": 467104, "start": 4684.0, "end": 4692.34, "text": " or or some fancy they create some fancy Bayesian model or some fancy neural network and they", "tokens": [420, 420, 512, 10247, 436, 1884, 512, 10247, 7840, 42434, 2316, 420, 512, 10247, 18161, 3209, 293, 436], "temperature": 0.0, "avg_logprob": -0.10141589317792728, "compression_ratio": 1.7647058823529411, "no_speech_prob": 1.7880619225252303e-06}, {"id": 722, "seek": 467104, "start": 4692.34, "end": 4697.54, "text": " go wow Jeremy look at my amazingly great model and I'll say like how do you know it's amazingly", "tokens": [352, 6076, 17809, 574, 412, 452, 31762, 869, 2316, 293, 286, 603, 584, 411, 577, 360, 291, 458, 309, 311, 31762], "temperature": 0.0, "avg_logprob": -0.10141589317792728, "compression_ratio": 1.7647058823529411, "no_speech_prob": 1.7880619225252303e-06}, {"id": 723, "seek": 469754, "start": 4697.54, "end": 4702.84, "text": " great and I say oh look the accuracy is 80% and then I'll say okay let's see what happens", "tokens": [869, 293, 286, 584, 1954, 574, 264, 14170, 307, 4688, 4, 293, 550, 286, 603, 584, 1392, 718, 311, 536, 437, 2314], "temperature": 0.0, "avg_logprob": -0.08280132081773546, "compression_ratio": 1.5757575757575757, "no_speech_prob": 1.9333544969413197e-06}, {"id": 724, "seek": 469754, "start": 4702.84, "end": 4711.0, "text": " if we create a model where we always predict the mean oh look that's 85% and people get", "tokens": [498, 321, 1884, 257, 2316, 689, 321, 1009, 6069, 264, 914, 1954, 574, 300, 311, 14695, 4, 293, 561, 483], "temperature": 0.0, "avg_logprob": -0.08280132081773546, "compression_ratio": 1.5757575757575757, "no_speech_prob": 1.9333544969413197e-06}, {"id": 725, "seek": 469754, "start": 4711.0, "end": 4715.88, "text": " pretty disheartened when they discover this right and so make sure you start with a reasonable", "tokens": [1238, 717, 12864, 5320, 562, 436, 4411, 341, 558, 293, 370, 652, 988, 291, 722, 365, 257, 10585], "temperature": 0.0, "avg_logprob": -0.08280132081773546, "compression_ratio": 1.5757575757575757, "no_speech_prob": 1.9333544969413197e-06}, {"id": 726, "seek": 469754, "start": 4715.88, "end": 4724.32, "text": " baseline and then gradually build on top of it. So we need to get the average of the pixels", "tokens": [20518, 293, 550, 13145, 1322, 322, 1192, 295, 309, 13, 407, 321, 643, 281, 483, 264, 4274, 295, 264, 18668], "temperature": 0.0, "avg_logprob": -0.08280132081773546, "compression_ratio": 1.5757575757575757, "no_speech_prob": 1.9333544969413197e-06}, {"id": 727, "seek": 472432, "start": 4724.32, "end": 4730.36, "text": " so we're going to learn some nice Python programming tricks to do this so the first thing we need", "tokens": [370, 321, 434, 516, 281, 1466, 512, 1481, 15329, 9410, 11733, 281, 360, 341, 370, 264, 700, 551, 321, 643], "temperature": 0.0, "avg_logprob": -0.11598799979850037, "compression_ratio": 1.7341772151898733, "no_speech_prob": 7.64650303608505e-06}, {"id": 728, "seek": 472432, "start": 4730.36, "end": 4741.24, "text": " to do is we need a list of all of the sevens so remember we've got the sevens maybe it's", "tokens": [281, 360, 307, 321, 643, 257, 1329, 295, 439, 295, 264, 3407, 82, 370, 1604, 321, 600, 658, 264, 3407, 82, 1310, 309, 311], "temperature": 0.0, "avg_logprob": -0.11598799979850037, "compression_ratio": 1.7341772151898733, "no_speech_prob": 7.64650303608505e-06}, {"id": 729, "seek": 472432, "start": 4741.24, "end": 4748.48, "text": " just a list of file names right and so for each of those file names in the sevens let's", "tokens": [445, 257, 1329, 295, 3991, 5288, 558, 293, 370, 337, 1184, 295, 729, 3991, 5288, 294, 264, 3407, 82, 718, 311], "temperature": 0.0, "avg_logprob": -0.11598799979850037, "compression_ratio": 1.7341772151898733, "no_speech_prob": 7.64650303608505e-06}, {"id": 730, "seek": 474848, "start": 4748.48, "end": 4754.16, "text": " image dot open that file just like we did before to get a PIO object and let's convert", "tokens": [3256, 5893, 1269, 300, 3991, 445, 411, 321, 630, 949, 281, 483, 257, 430, 15167, 2657, 293, 718, 311, 7620], "temperature": 0.0, "avg_logprob": -0.1024237043074979, "compression_ratio": 1.763157894736842, "no_speech_prob": 3.340527655382175e-06}, {"id": 731, "seek": 474848, "start": 4754.16, "end": 4759.5599999999995, "text": " that into a tensor. So this thing here is called a list comprehension so if you haven't seen", "tokens": [300, 666, 257, 40863, 13, 407, 341, 551, 510, 307, 1219, 257, 1329, 44991, 370, 498, 291, 2378, 380, 1612], "temperature": 0.0, "avg_logprob": -0.1024237043074979, "compression_ratio": 1.763157894736842, "no_speech_prob": 3.340527655382175e-06}, {"id": 732, "seek": 474848, "start": 4759.5599999999995, "end": 4765.2, "text": " this before this is one of the most powerful and useful tools in Python. If you've done", "tokens": [341, 949, 341, 307, 472, 295, 264, 881, 4005, 293, 4420, 3873, 294, 15329, 13, 759, 291, 600, 1096], "temperature": 0.0, "avg_logprob": -0.1024237043074979, "compression_ratio": 1.763157894736842, "no_speech_prob": 3.340527655382175e-06}, {"id": 733, "seek": 474848, "start": 4765.2, "end": 4768.839999999999, "text": " something with C sharp it's a little bit like link it's not as powerful as link but it's", "tokens": [746, 365, 383, 8199, 309, 311, 257, 707, 857, 411, 2113, 309, 311, 406, 382, 4005, 382, 2113, 457, 309, 311], "temperature": 0.0, "avg_logprob": -0.1024237043074979, "compression_ratio": 1.763157894736842, "no_speech_prob": 3.340527655382175e-06}, {"id": 734, "seek": 474848, "start": 4768.839999999999, "end": 4774.44, "text": " a similar idea if you've done some functional programming in in JavaScript it's a bit like", "tokens": [257, 2531, 1558, 498, 291, 600, 1096, 512, 11745, 9410, 294, 294, 15778, 309, 311, 257, 857, 411], "temperature": 0.0, "avg_logprob": -0.1024237043074979, "compression_ratio": 1.763157894736842, "no_speech_prob": 3.340527655382175e-06}, {"id": 735, "seek": 474848, "start": 4774.44, "end": 4778.16, "text": " some of the things you can do with that too but basically we're just going to go through", "tokens": [512, 295, 264, 721, 291, 393, 360, 365, 300, 886, 457, 1936, 321, 434, 445, 516, 281, 352, 807], "temperature": 0.0, "avg_logprob": -0.1024237043074979, "compression_ratio": 1.763157894736842, "no_speech_prob": 3.340527655382175e-06}, {"id": 736, "seek": 477816, "start": 4778.16, "end": 4785.88, "text": " this collection each item will become called O and then it will be passed to this function", "tokens": [341, 5765, 1184, 3174, 486, 1813, 1219, 422, 293, 550, 309, 486, 312, 4678, 281, 341, 2445], "temperature": 0.0, "avg_logprob": -0.09339912547621616, "compression_ratio": 1.7821782178217822, "no_speech_prob": 1.3496986639438546e-06}, {"id": 737, "seek": 477816, "start": 4785.88, "end": 4790.12, "text": " which opens it up and turns it into a tensor and then it will be collated all back into", "tokens": [597, 9870, 309, 493, 293, 4523, 309, 666, 257, 40863, 293, 550, 309, 486, 312, 1263, 770, 439, 646, 666], "temperature": 0.0, "avg_logprob": -0.09339912547621616, "compression_ratio": 1.7821782178217822, "no_speech_prob": 1.3496986639438546e-06}, {"id": 738, "seek": 477816, "start": 4790.12, "end": 4801.24, "text": " a list and so this will be all of the sevens as tensors. So Silva and I use list and dictionary", "tokens": [257, 1329, 293, 370, 341, 486, 312, 439, 295, 264, 3407, 82, 382, 10688, 830, 13, 407, 50171, 293, 286, 764, 1329, 293, 25890], "temperature": 0.0, "avg_logprob": -0.09339912547621616, "compression_ratio": 1.7821782178217822, "no_speech_prob": 1.3496986639438546e-06}, {"id": 739, "seek": 477816, "start": 4801.24, "end": 4806.4, "text": " comprehensions every day and so you should definitely spend some time checking it out", "tokens": [10753, 8302, 633, 786, 293, 370, 291, 820, 2138, 3496, 512, 565, 8568, 309, 484], "temperature": 0.0, "avg_logprob": -0.09339912547621616, "compression_ratio": 1.7821782178217822, "no_speech_prob": 1.3496986639438546e-06}, {"id": 740, "seek": 480640, "start": 4806.4, "end": 4815.599999999999, "text": " if you haven't already. So now that we've got a list of all of the threes as tensors", "tokens": [498, 291, 2378, 380, 1217, 13, 407, 586, 300, 321, 600, 658, 257, 1329, 295, 439, 295, 264, 258, 4856, 382, 10688, 830], "temperature": 0.0, "avg_logprob": -0.09536016953958047, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.419883742277307e-07}, {"id": 741, "seek": 480640, "start": 4815.599999999999, "end": 4823.32, "text": " let's just grab one of them and display it. So remember this is a tensor not a PIO image", "tokens": [718, 311, 445, 4444, 472, 295, 552, 293, 4674, 309, 13, 407, 1604, 341, 307, 257, 40863, 406, 257, 430, 15167, 3256], "temperature": 0.0, "avg_logprob": -0.09536016953958047, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.419883742277307e-07}, {"id": 742, "seek": 480640, "start": 4823.32, "end": 4832.08, "text": " object so Jupyter doesn't know how to display it so we have to use some command to display", "tokens": [2657, 370, 22125, 88, 391, 1177, 380, 458, 577, 281, 4674, 309, 370, 321, 362, 281, 764, 512, 5622, 281, 4674], "temperature": 0.0, "avg_logprob": -0.09536016953958047, "compression_ratio": 1.5172413793103448, "no_speech_prob": 2.419883742277307e-07}, {"id": 743, "seek": 483208, "start": 4832.08, "end": 4840.04, "text": " it and show image is a fast AI command that displays a tensor and so here is our three.", "tokens": [309, 293, 855, 3256, 307, 257, 2370, 7318, 5622, 300, 20119, 257, 40863, 293, 370, 510, 307, 527, 1045, 13], "temperature": 0.0, "avg_logprob": -0.09906450907389323, "compression_ratio": 1.6748466257668713, "no_speech_prob": 2.1355386081722827e-07}, {"id": 744, "seek": 483208, "start": 4840.04, "end": 4848.08, "text": " So we need to get the average of all of those threes so to get the average the first thing", "tokens": [407, 321, 643, 281, 483, 264, 4274, 295, 439, 295, 729, 258, 4856, 370, 281, 483, 264, 4274, 264, 700, 551], "temperature": 0.0, "avg_logprob": -0.09906450907389323, "compression_ratio": 1.6748466257668713, "no_speech_prob": 2.1355386081722827e-07}, {"id": 745, "seek": 483208, "start": 4848.08, "end": 4855.5599999999995, "text": " we need to do is to turn change this so it's not a list but it's a tensor itself but currently", "tokens": [321, 643, 281, 360, 307, 281, 1261, 1319, 341, 370, 309, 311, 406, 257, 1329, 457, 309, 311, 257, 40863, 2564, 457, 4362], "temperature": 0.0, "avg_logprob": -0.09906450907389323, "compression_ratio": 1.6748466257668713, "no_speech_prob": 2.1355386081722827e-07}, {"id": 746, "seek": 485556, "start": 4855.56, "end": 4870.400000000001, "text": " three tensors one as a shape which is 28 by 28. So this is this is the rows by columns", "tokens": [1045, 10688, 830, 472, 382, 257, 3909, 597, 307, 7562, 538, 7562, 13, 407, 341, 307, 341, 307, 264, 13241, 538, 13766], "temperature": 0.0, "avg_logprob": -0.15493059158325195, "compression_ratio": 1.5917159763313609, "no_speech_prob": 4.0525421241000004e-07}, {"id": 747, "seek": 485556, "start": 4870.400000000001, "end": 4880.780000000001, "text": " the size of this thing right but three tensors itself is just a list so I can't really easily", "tokens": [264, 2744, 295, 341, 551, 558, 457, 1045, 10688, 830, 2564, 307, 445, 257, 1329, 370, 286, 393, 380, 534, 3612], "temperature": 0.0, "avg_logprob": -0.15493059158325195, "compression_ratio": 1.5917159763313609, "no_speech_prob": 4.0525421241000004e-07}, {"id": 748, "seek": 485556, "start": 4880.780000000001, "end": 4885.240000000001, "text": " do mathematical computations on that. So what we could do is we could stack all of these", "tokens": [360, 18894, 2807, 763, 322, 300, 13, 407, 437, 321, 727, 360, 307, 321, 727, 8630, 439, 295, 613], "temperature": 0.0, "avg_logprob": -0.15493059158325195, "compression_ratio": 1.5917159763313609, "no_speech_prob": 4.0525421241000004e-07}, {"id": 749, "seek": 488524, "start": 4885.24, "end": 4894.44, "text": " 28 by 28 images on top of each other to create a like a 3d cube of images and that's still", "tokens": [7562, 538, 7562, 5267, 322, 1192, 295, 1184, 661, 281, 1884, 257, 411, 257, 805, 67, 13728, 295, 5267, 293, 300, 311, 920], "temperature": 0.0, "avg_logprob": -0.10423658318715552, "compression_ratio": 1.5568181818181819, "no_speech_prob": 1.0845153610716807e-06}, {"id": 750, "seek": 488524, "start": 4894.44, "end": 4900.0, "text": " called a tensor so a tensor can have as many of these axes or dimensions as you like and", "tokens": [1219, 257, 40863, 370, 257, 40863, 393, 362, 382, 867, 295, 613, 35387, 420, 12819, 382, 291, 411, 293], "temperature": 0.0, "avg_logprob": -0.10423658318715552, "compression_ratio": 1.5568181818181819, "no_speech_prob": 1.0845153610716807e-06}, {"id": 751, "seek": 488524, "start": 4900.0, "end": 4908.0, "text": " to stack them up you use funnily enough stack. So this is going to turn the list into a tensor", "tokens": [281, 8630, 552, 493, 291, 764, 1019, 77, 953, 1547, 8630, 13, 407, 341, 307, 516, 281, 1261, 264, 1329, 666, 257, 40863], "temperature": 0.0, "avg_logprob": -0.10423658318715552, "compression_ratio": 1.5568181818181819, "no_speech_prob": 1.0845153610716807e-06}, {"id": 752, "seek": 490800, "start": 4908.0, "end": 4916.8, "text": " and as you can see the shape of it is now 6131 by 28 by 28 so it's kind of like a cube", "tokens": [293, 382, 291, 393, 536, 264, 3909, 295, 309, 307, 586, 1386, 7668, 16, 538, 7562, 538, 7562, 370, 309, 311, 733, 295, 411, 257, 13728], "temperature": 0.0, "avg_logprob": -0.08186018161284618, "compression_ratio": 1.5843373493975903, "no_speech_prob": 4.116360798889218e-07}, {"id": 753, "seek": 490800, "start": 4916.8, "end": 4929.28, "text": " of height 6131 by 28 by 28. The other thing we want to do is if we're going to take the", "tokens": [295, 6681, 1386, 7668, 16, 538, 7562, 538, 7562, 13, 440, 661, 551, 321, 528, 281, 360, 307, 498, 321, 434, 516, 281, 747, 264], "temperature": 0.0, "avg_logprob": -0.08186018161284618, "compression_ratio": 1.5843373493975903, "no_speech_prob": 4.116360798889218e-07}, {"id": 754, "seek": 490800, "start": 4929.28, "end": 4935.6, "text": " mean we want to turn them into floating point values because we we don't want to kind of", "tokens": [914, 321, 528, 281, 1261, 552, 666, 12607, 935, 4190, 570, 321, 321, 500, 380, 528, 281, 733, 295], "temperature": 0.0, "avg_logprob": -0.08186018161284618, "compression_ratio": 1.5843373493975903, "no_speech_prob": 4.116360798889218e-07}, {"id": 755, "seek": 493560, "start": 4935.6, "end": 4942.200000000001, "text": " have integers rounding off. The other thing to know is that it's just as kind of a standard", "tokens": [362, 41674, 48237, 766, 13, 440, 661, 551, 281, 458, 307, 300, 309, 311, 445, 382, 733, 295, 257, 3832], "temperature": 0.0, "avg_logprob": -0.12314350340101454, "compression_ratio": 1.6143497757847534, "no_speech_prob": 5.043469286647451e-07}, {"id": 756, "seek": 493560, "start": 4942.200000000001, "end": 4948.72, "text": " in computer vision that when you're working with floats that you expect them to be between", "tokens": [294, 3820, 5201, 300, 562, 291, 434, 1364, 365, 37878, 300, 291, 2066, 552, 281, 312, 1296], "temperature": 0.0, "avg_logprob": -0.12314350340101454, "compression_ratio": 1.6143497757847534, "no_speech_prob": 5.043469286647451e-07}, {"id": 757, "seek": 493560, "start": 4948.72, "end": 4955.92, "text": " zero and one so we just divide by 255 because they were between zero and 255 before. So", "tokens": [4018, 293, 472, 370, 321, 445, 9845, 538, 3552, 20, 570, 436, 645, 1296, 4018, 293, 3552, 20, 949, 13, 407], "temperature": 0.0, "avg_logprob": -0.12314350340101454, "compression_ratio": 1.6143497757847534, "no_speech_prob": 5.043469286647451e-07}, {"id": 758, "seek": 493560, "start": 4955.92, "end": 4965.4800000000005, "text": " this is a pretty standard way to kind of represent a bunch of images in PyTorch. So these", "tokens": [341, 307, 257, 1238, 3832, 636, 281, 733, 295, 2906, 257, 3840, 295, 5267, 294, 9953, 51, 284, 339, 13, 407, 613], "temperature": 0.0, "avg_logprob": -0.12314350340101454, "compression_ratio": 1.6143497757847534, "no_speech_prob": 5.043469286647451e-07}, {"id": 759, "seek": 496548, "start": 4965.48, "end": 4974.12, "text": " three things here are called the axes first axis second axis third axis and overall we", "tokens": [1045, 721, 510, 366, 1219, 264, 35387, 700, 10298, 1150, 10298, 2636, 10298, 293, 4787, 321], "temperature": 0.0, "avg_logprob": -0.16235099205603967, "compression_ratio": 1.6477987421383649, "no_speech_prob": 3.7853094454476377e-06}, {"id": 760, "seek": 496548, "start": 4974.12, "end": 4982.719999999999, "text": " would say that this is a rank 3 tensor because it has three axes so the this one here was", "tokens": [576, 584, 300, 341, 307, 257, 6181, 805, 40863, 570, 309, 575, 1045, 35387, 370, 264, 341, 472, 510, 390], "temperature": 0.0, "avg_logprob": -0.16235099205603967, "compression_ratio": 1.6477987421383649, "no_speech_prob": 3.7853094454476377e-06}, {"id": 761, "seek": 496548, "start": 4982.719999999999, "end": 4991.32, "text": " a rank 2 tensor it has two axes. So you can get the rank from a tensor by just taking", "tokens": [257, 6181, 568, 40863, 309, 575, 732, 35387, 13, 407, 291, 393, 483, 264, 6181, 490, 257, 40863, 538, 445, 1940], "temperature": 0.0, "avg_logprob": -0.16235099205603967, "compression_ratio": 1.6477987421383649, "no_speech_prob": 3.7853094454476377e-06}, {"id": 762, "seek": 499132, "start": 4991.32, "end": 5003.0, "text": " the length of its shape 1 2 3 3. You can also get that from the word I've been using the", "tokens": [264, 4641, 295, 1080, 3909, 502, 568, 805, 805, 13, 509, 393, 611, 483, 300, 490, 264, 1349, 286, 600, 668, 1228, 264], "temperature": 0.0, "avg_logprob": -0.24113382233513725, "compression_ratio": 1.6257668711656441, "no_speech_prob": 1.4367477660925942e-06}, {"id": 763, "seek": 499132, "start": 5003.0, "end": 5011.0, "text": " word axis you can also use the word dimension I think numpy tends to call it axis PyTorch", "tokens": [1349, 10298, 291, 393, 611, 764, 264, 1349, 10139, 286, 519, 1031, 8200, 12258, 281, 818, 309, 10298, 9953, 51, 284, 339], "temperature": 0.0, "avg_logprob": -0.24113382233513725, "compression_ratio": 1.6257668711656441, "no_speech_prob": 1.4367477660925942e-06}, {"id": 764, "seek": 499132, "start": 5011.0, "end": 5021.28, "text": " tends to call it dimension so the rank is also the number of dimensions and in. So you", "tokens": [12258, 281, 818, 309, 10139, 370, 264, 6181, 307, 611, 264, 1230, 295, 12819, 293, 294, 13, 407, 291], "temperature": 0.0, "avg_logprob": -0.24113382233513725, "compression_ratio": 1.6257668711656441, "no_speech_prob": 1.4367477660925942e-06}, {"id": 765, "seek": 502128, "start": 5021.28, "end": 5026.5199999999995, "text": " need to make sure that you remember this word rank is the number of axes or dimensions in", "tokens": [643, 281, 652, 988, 300, 291, 1604, 341, 1349, 6181, 307, 264, 1230, 295, 35387, 420, 12819, 294], "temperature": 0.0, "avg_logprob": -0.09361002024482279, "compression_ratio": 1.6832298136645962, "no_speech_prob": 6.0488778217404615e-06}, {"id": 766, "seek": 502128, "start": 5026.5199999999995, "end": 5039.16, "text": " a tensor and the shape is a list containing the size of each axis in a tensor. So we can", "tokens": [257, 40863, 293, 264, 3909, 307, 257, 1329, 19273, 264, 2744, 295, 1184, 10298, 294, 257, 40863, 13, 407, 321, 393], "temperature": 0.0, "avg_logprob": -0.09361002024482279, "compression_ratio": 1.6832298136645962, "no_speech_prob": 6.0488778217404615e-06}, {"id": 767, "seek": 502128, "start": 5039.16, "end": 5049.48, "text": " now say stack threes dot mean now if we just say stack threes dot mean that returns a single", "tokens": [586, 584, 8630, 258, 4856, 5893, 914, 586, 498, 321, 445, 584, 8630, 258, 4856, 5893, 914, 300, 11247, 257, 2167], "temperature": 0.0, "avg_logprob": -0.09361002024482279, "compression_ratio": 1.6832298136645962, "no_speech_prob": 6.0488778217404615e-06}, {"id": 768, "seek": 504948, "start": 5049.48, "end": 5055.799999999999, "text": " number that's the average pixel across that whole cube that whole rank 3 tensor but if", "tokens": [1230, 300, 311, 264, 4274, 19261, 2108, 300, 1379, 13728, 300, 1379, 6181, 805, 40863, 457, 498], "temperature": 0.0, "avg_logprob": -0.15894263723622198, "compression_ratio": 1.6481481481481481, "no_speech_prob": 2.8130098144174553e-06}, {"id": 769, "seek": 504948, "start": 5055.799999999999, "end": 5064.959999999999, "text": " we say mean 0 that is take the mean over this axis that's the mean across the images right", "tokens": [321, 584, 914, 1958, 300, 307, 747, 264, 914, 670, 341, 10298, 300, 311, 264, 914, 2108, 264, 5267, 558], "temperature": 0.0, "avg_logprob": -0.15894263723622198, "compression_ratio": 1.6481481481481481, "no_speech_prob": 2.8130098144174553e-06}, {"id": 770, "seek": 504948, "start": 5064.959999999999, "end": 5077.759999999999, "text": " and so that's now 28 by 28 again because we kind of like reduced over this 6131 6131 axis", "tokens": [293, 370, 300, 311, 586, 7562, 538, 7562, 797, 570, 321, 733, 295, 411, 9212, 670, 341, 1386, 7668, 16, 1386, 7668, 16, 10298], "temperature": 0.0, "avg_logprob": -0.15894263723622198, "compression_ratio": 1.6481481481481481, "no_speech_prob": 2.8130098144174553e-06}, {"id": 771, "seek": 507776, "start": 5077.76, "end": 5084.4400000000005, "text": " we took the mean across that axis and so we can show that image and here is our ideal", "tokens": [321, 1890, 264, 914, 2108, 300, 10298, 293, 370, 321, 393, 855, 300, 3256, 293, 510, 307, 527, 7157], "temperature": 0.0, "avg_logprob": -0.1138279413439564, "compression_ratio": 1.7810945273631842, "no_speech_prob": 3.1381368899019435e-06}, {"id": 772, "seek": 507776, "start": 5084.4400000000005, "end": 5094.320000000001, "text": " 3. So here's the ideal 7 using the same approach right so now let's just grab a 3 there's just", "tokens": [805, 13, 407, 510, 311, 264, 7157, 1614, 1228, 264, 912, 3109, 558, 370, 586, 718, 311, 445, 4444, 257, 805, 456, 311, 445], "temperature": 0.0, "avg_logprob": -0.1138279413439564, "compression_ratio": 1.7810945273631842, "no_speech_prob": 3.1381368899019435e-06}, {"id": 773, "seek": 507776, "start": 5094.320000000001, "end": 5099.96, "text": " any old 3 here it is and what I'm going to do is I'm going to say well is this 3 more", "tokens": [604, 1331, 805, 510, 309, 307, 293, 437, 286, 478, 516, 281, 360, 307, 286, 478, 516, 281, 584, 731, 307, 341, 805, 544], "temperature": 0.0, "avg_logprob": -0.1138279413439564, "compression_ratio": 1.7810945273631842, "no_speech_prob": 3.1381368899019435e-06}, {"id": 774, "seek": 507776, "start": 5099.96, "end": 5105.06, "text": " similar to the perfect 3 or is it more similar to the perfect 7 and whichever one it's more", "tokens": [2531, 281, 264, 2176, 805, 420, 307, 309, 544, 2531, 281, 264, 2176, 1614, 293, 24123, 472, 309, 311, 544], "temperature": 0.0, "avg_logprob": -0.1138279413439564, "compression_ratio": 1.7810945273631842, "no_speech_prob": 3.1381368899019435e-06}, {"id": 775, "seek": 510506, "start": 5105.06, "end": 5113.52, "text": " similar to I'm going to assume that's that's the answer. So we can't just say look at each", "tokens": [2531, 281, 286, 478, 516, 281, 6552, 300, 311, 300, 311, 264, 1867, 13, 407, 321, 393, 380, 445, 584, 574, 412, 1184], "temperature": 0.0, "avg_logprob": -0.09470414579584358, "compression_ratio": 1.9120879120879122, "no_speech_prob": 8.446214110335859e-07}, {"id": 776, "seek": 510506, "start": 5113.52, "end": 5121.240000000001, "text": " pixel and say what's the difference between this pixel you know 0 0 here and 0 0 here", "tokens": [19261, 293, 584, 437, 311, 264, 2649, 1296, 341, 19261, 291, 458, 1958, 1958, 510, 293, 1958, 1958, 510], "temperature": 0.0, "avg_logprob": -0.09470414579584358, "compression_ratio": 1.9120879120879122, "no_speech_prob": 8.446214110335859e-07}, {"id": 777, "seek": 510506, "start": 5121.240000000001, "end": 5126.080000000001, "text": " and then 0 1 here and then 0 1 here and take the average the reason we can't just take", "tokens": [293, 550, 1958, 502, 510, 293, 550, 1958, 502, 510, 293, 747, 264, 4274, 264, 1778, 321, 393, 380, 445, 747], "temperature": 0.0, "avg_logprob": -0.09470414579584358, "compression_ratio": 1.9120879120879122, "no_speech_prob": 8.446214110335859e-07}, {"id": 778, "seek": 510506, "start": 5126.080000000001, "end": 5129.160000000001, "text": " the average is that there's positives and negatives and they're going to average out", "tokens": [264, 4274, 307, 300, 456, 311, 35127, 293, 40019, 293, 436, 434, 516, 281, 4274, 484], "temperature": 0.0, "avg_logprob": -0.09470414579584358, "compression_ratio": 1.9120879120879122, "no_speech_prob": 8.446214110335859e-07}, {"id": 779, "seek": 512916, "start": 5129.16, "end": 5136.4, "text": " to nothing right so I actually need them all to be positive numbers so there's two ways", "tokens": [281, 1825, 558, 370, 286, 767, 643, 552, 439, 281, 312, 3353, 3547, 370, 456, 311, 732, 2098], "temperature": 0.0, "avg_logprob": -0.11456384497173762, "compression_ratio": 1.6624203821656052, "no_speech_prob": 1.9333540421939688e-06}, {"id": 780, "seek": 512916, "start": 5136.4, "end": 5141.5599999999995, "text": " to make them all positive numbers I could take the absolute value which simply means", "tokens": [281, 652, 552, 439, 3353, 3547, 286, 727, 747, 264, 8236, 2158, 597, 2935, 1355], "temperature": 0.0, "avg_logprob": -0.11456384497173762, "compression_ratio": 1.6624203821656052, "no_speech_prob": 1.9333540421939688e-06}, {"id": 781, "seek": 512916, "start": 5141.5599999999995, "end": 5148.32, "text": " remove the minus signs okay and then I could take the average of those that's called the", "tokens": [4159, 264, 3175, 7880, 1392, 293, 550, 286, 727, 747, 264, 4274, 295, 729, 300, 311, 1219, 264], "temperature": 0.0, "avg_logprob": -0.11456384497173762, "compression_ratio": 1.6624203821656052, "no_speech_prob": 1.9333540421939688e-06}, {"id": 782, "seek": 514832, "start": 5148.32, "end": 5159.759999999999, "text": " mean absolute difference or L1 norm or I could take the square of each difference and then", "tokens": [914, 8236, 2649, 420, 441, 16, 2026, 420, 286, 727, 747, 264, 3732, 295, 1184, 2649, 293, 550], "temperature": 0.0, "avg_logprob": -0.08877684789545395, "compression_ratio": 1.7417218543046358, "no_speech_prob": 2.4824773845466552e-06}, {"id": 783, "seek": 514832, "start": 5159.759999999999, "end": 5164.24, "text": " take the mean of that and then at the end I could take the square root kind of undoes", "tokens": [747, 264, 914, 295, 300, 293, 550, 412, 264, 917, 286, 727, 747, 264, 3732, 5593, 733, 295, 23779, 279], "temperature": 0.0, "avg_logprob": -0.08877684789545395, "compression_ratio": 1.7417218543046358, "no_speech_prob": 2.4824773845466552e-06}, {"id": 784, "seek": 514832, "start": 5164.24, "end": 5172.88, "text": " the squaring and that's called the root mean squared error or L2. So let's have a look", "tokens": [264, 2339, 1921, 293, 300, 311, 1219, 264, 5593, 914, 8889, 6713, 420, 441, 17, 13, 407, 718, 311, 362, 257, 574], "temperature": 0.0, "avg_logprob": -0.08877684789545395, "compression_ratio": 1.7417218543046358, "no_speech_prob": 2.4824773845466552e-06}, {"id": 785, "seek": 517288, "start": 5172.88, "end": 5181.2, "text": " let's take a 3 and subtract from it the mean of the 3s and take the absolute value and", "tokens": [718, 311, 747, 257, 805, 293, 16390, 490, 309, 264, 914, 295, 264, 805, 82, 293, 747, 264, 8236, 2158, 293], "temperature": 0.0, "avg_logprob": -0.11733277638753255, "compression_ratio": 1.778894472361809, "no_speech_prob": 1.3287757383295684e-06}, {"id": 786, "seek": 517288, "start": 5181.2, "end": 5189.84, "text": " take the mean and call that the distance using absolute value of the 3 to a 3 and that there", "tokens": [747, 264, 914, 293, 818, 300, 264, 4560, 1228, 8236, 2158, 295, 264, 805, 281, 257, 805, 293, 300, 456], "temperature": 0.0, "avg_logprob": -0.11733277638753255, "compression_ratio": 1.778894472361809, "no_speech_prob": 1.3287757383295684e-06}, {"id": 787, "seek": 517288, "start": 5189.84, "end": 5196.16, "text": " is the number 0.1 right so this is the mean absolute difference or L1 norm so when you", "tokens": [307, 264, 1230, 1958, 13, 16, 558, 370, 341, 307, 264, 914, 8236, 2649, 420, 441, 16, 2026, 370, 562, 291], "temperature": 0.0, "avg_logprob": -0.11733277638753255, "compression_ratio": 1.778894472361809, "no_speech_prob": 1.3287757383295684e-06}, {"id": 788, "seek": 517288, "start": 5196.16, "end": 5201.32, "text": " see a word like L1 norm if you haven't seen it before it may sound pretty fancy but all", "tokens": [536, 257, 1349, 411, 441, 16, 2026, 498, 291, 2378, 380, 1612, 309, 949, 309, 815, 1626, 1238, 10247, 457, 439], "temperature": 0.0, "avg_logprob": -0.11733277638753255, "compression_ratio": 1.778894472361809, "no_speech_prob": 1.3287757383295684e-06}, {"id": 789, "seek": 520132, "start": 5201.32, "end": 5209.16, "text": " these math terms that we see you know you can turn them into a tiny bit of code right", "tokens": [613, 5221, 2115, 300, 321, 536, 291, 458, 291, 393, 1261, 552, 666, 257, 5870, 857, 295, 3089, 558], "temperature": 0.0, "avg_logprob": -0.10655641020014045, "compression_ratio": 1.7524752475247525, "no_speech_prob": 6.375540806402569e-07}, {"id": 790, "seek": 520132, "start": 5209.16, "end": 5215.12, "text": " it's it's you know don't let the mathy bits fool you that they're often like in code it's", "tokens": [309, 311, 309, 311, 291, 458, 500, 380, 718, 264, 5221, 88, 9239, 7979, 291, 300, 436, 434, 2049, 411, 294, 3089, 309, 311], "temperature": 0.0, "avg_logprob": -0.10655641020014045, "compression_ratio": 1.7524752475247525, "no_speech_prob": 6.375540806402569e-07}, {"id": 791, "seek": 520132, "start": 5215.12, "end": 5219.2, "text": " just very obvious what they mean where else with math you just you just have to learn", "tokens": [445, 588, 6322, 437, 436, 914, 689, 1646, 365, 5221, 291, 445, 291, 445, 362, 281, 1466], "temperature": 0.0, "avg_logprob": -0.10655641020014045, "compression_ratio": 1.7524752475247525, "no_speech_prob": 6.375540806402569e-07}, {"id": 792, "seek": 520132, "start": 5219.2, "end": 5227.0, "text": " it or learn how to Google it so here the same version for squaring take the difference where", "tokens": [309, 420, 1466, 577, 281, 3329, 309, 370, 510, 264, 912, 3037, 337, 2339, 1921, 747, 264, 2649, 689], "temperature": 0.0, "avg_logprob": -0.10655641020014045, "compression_ratio": 1.7524752475247525, "no_speech_prob": 6.375540806402569e-07}, {"id": 793, "seek": 522700, "start": 5227.0, "end": 5233.08, "text": " it take the mean and then take the square root. So then we'll do the same thing for", "tokens": [309, 747, 264, 914, 293, 550, 747, 264, 3732, 5593, 13, 407, 550, 321, 603, 360, 264, 912, 551, 337], "temperature": 0.0, "avg_logprob": -0.11863677006847453, "compression_ratio": 2.070588235294118, "no_speech_prob": 1.4823548326603486e-06}, {"id": 794, "seek": 522700, "start": 5233.08, "end": 5240.2, "text": " our 3 this time we'll compare it to the mean of the 7s right so the distance from a 3 to", "tokens": [527, 805, 341, 565, 321, 603, 6794, 309, 281, 264, 914, 295, 264, 1614, 82, 558, 370, 264, 4560, 490, 257, 805, 281], "temperature": 0.0, "avg_logprob": -0.11863677006847453, "compression_ratio": 2.070588235294118, "no_speech_prob": 1.4823548326603486e-06}, {"id": 795, "seek": 522700, "start": 5240.2, "end": 5246.48, "text": " the mean of the 3s with in terms of absolute was 0.1 and the distance from a 3 to the mean", "tokens": [264, 914, 295, 264, 805, 82, 365, 294, 2115, 295, 8236, 390, 1958, 13, 16, 293, 264, 4560, 490, 257, 805, 281, 264, 914], "temperature": 0.0, "avg_logprob": -0.11863677006847453, "compression_ratio": 2.070588235294118, "no_speech_prob": 1.4823548326603486e-06}, {"id": 796, "seek": 522700, "start": 5246.48, "end": 5254.08, "text": " of the 7s was 0.15 so it's closer to the mean of the 3s than it is to the mean of the 7s", "tokens": [295, 264, 1614, 82, 390, 1958, 13, 5211, 370, 309, 311, 4966, 281, 264, 914, 295, 264, 805, 82, 813, 309, 307, 281, 264, 914, 295, 264, 1614, 82], "temperature": 0.0, "avg_logprob": -0.11863677006847453, "compression_ratio": 2.070588235294118, "no_speech_prob": 1.4823548326603486e-06}, {"id": 797, "seek": 525408, "start": 5254.08, "end": 5262.04, "text": " so we guess therefore that this is a 3 based on the mean absolute difference same thing", "tokens": [370, 321, 2041, 4412, 300, 341, 307, 257, 805, 2361, 322, 264, 914, 8236, 2649, 912, 551], "temperature": 0.0, "avg_logprob": -0.1587419980837975, "compression_ratio": 1.6826923076923077, "no_speech_prob": 8.714327464076632e-07}, {"id": 798, "seek": 525408, "start": 5262.04, "end": 5267.92, "text": " with RMSE root mean squared error would be to compare this value with this value and", "tokens": [365, 23790, 5879, 5593, 914, 8889, 6713, 576, 312, 281, 6794, 341, 2158, 365, 341, 2158, 293], "temperature": 0.0, "avg_logprob": -0.1587419980837975, "compression_ratio": 1.6826923076923077, "no_speech_prob": 8.714327464076632e-07}, {"id": 799, "seek": 525408, "start": 5267.92, "end": 5274.44, "text": " again root means squared error it's closer to the mean 3 than to the mean 7 so this is", "tokens": [797, 5593, 1355, 8889, 6713, 309, 311, 4966, 281, 264, 914, 805, 813, 281, 264, 914, 1614, 370, 341, 307], "temperature": 0.0, "avg_logprob": -0.1587419980837975, "compression_ratio": 1.6826923076923077, "no_speech_prob": 8.714327464076632e-07}, {"id": 800, "seek": 525408, "start": 5274.44, "end": 5281.24, "text": " like a machine learning model kind of it's a data driven model which attempts to recognize", "tokens": [411, 257, 3479, 2539, 2316, 733, 295, 309, 311, 257, 1412, 9555, 2316, 597, 15257, 281, 5521], "temperature": 0.0, "avg_logprob": -0.1587419980837975, "compression_ratio": 1.6826923076923077, "no_speech_prob": 8.714327464076632e-07}, {"id": 801, "seek": 528124, "start": 5281.24, "end": 5287.639999999999, "text": " 3s versus 7s and so this is a good baseline I mean it's it's a reasonable baseline it's", "tokens": [805, 82, 5717, 1614, 82, 293, 370, 341, 307, 257, 665, 20518, 286, 914, 309, 311, 309, 311, 257, 10585, 20518, 309, 311], "temperature": 0.0, "avg_logprob": -0.11512037004743303, "compression_ratio": 1.65625, "no_speech_prob": 1.4144742408461752e-06}, {"id": 802, "seek": 528124, "start": 5287.639999999999, "end": 5297.32, "text": " going to be better than random we don't actually have to write out minus abs mean we can just", "tokens": [516, 281, 312, 1101, 813, 4974, 321, 500, 380, 767, 362, 281, 2464, 484, 3175, 1950, 914, 321, 393, 445], "temperature": 0.0, "avg_logprob": -0.11512037004743303, "compression_ratio": 1.65625, "no_speech_prob": 1.4144742408461752e-06}, {"id": 803, "seek": 528124, "start": 5297.32, "end": 5306.639999999999, "text": " actually use L1 loss L1 loss does exactly that we don't have to write minus squared", "tokens": [767, 764, 441, 16, 4470, 441, 16, 4470, 775, 2293, 300, 321, 500, 380, 362, 281, 2464, 3175, 8889], "temperature": 0.0, "avg_logprob": -0.11512037004743303, "compression_ratio": 1.65625, "no_speech_prob": 1.4144742408461752e-06}, {"id": 804, "seek": 530664, "start": 5306.64, "end": 5311.400000000001, "text": " we can just write MSC loss that doesn't do the square root by default so we have to pop", "tokens": [321, 393, 445, 2464, 7395, 34, 4470, 300, 1177, 380, 360, 264, 3732, 5593, 538, 7576, 370, 321, 362, 281, 1665], "temperature": 0.0, "avg_logprob": -0.11340188432013852, "compression_ratio": 1.6063348416289593, "no_speech_prob": 2.684192168089794e-06}, {"id": 805, "seek": 530664, "start": 5311.400000000001, "end": 5321.88, "text": " that in okay and as you can see they're exactly the same numbers it's very important before", "tokens": [300, 294, 1392, 293, 382, 291, 393, 536, 436, 434, 2293, 264, 912, 3547, 309, 311, 588, 1021, 949], "temperature": 0.0, "avg_logprob": -0.11340188432013852, "compression_ratio": 1.6063348416289593, "no_speech_prob": 2.684192168089794e-06}, {"id": 806, "seek": 530664, "start": 5321.88, "end": 5326.84, "text": " we kind of go too much further to make sure we're very comfortable working with arrays", "tokens": [321, 733, 295, 352, 886, 709, 3052, 281, 652, 988, 321, 434, 588, 4619, 1364, 365, 41011], "temperature": 0.0, "avg_logprob": -0.11340188432013852, "compression_ratio": 1.6063348416289593, "no_speech_prob": 2.684192168089794e-06}, {"id": 807, "seek": 530664, "start": 5326.84, "end": 5334.160000000001, "text": " and tensors and you know they're so similar so we could start with a list of lists right", "tokens": [293, 10688, 830, 293, 291, 458, 436, 434, 370, 2531, 370, 321, 727, 722, 365, 257, 1329, 295, 14511, 558], "temperature": 0.0, "avg_logprob": -0.11340188432013852, "compression_ratio": 1.6063348416289593, "no_speech_prob": 2.684192168089794e-06}, {"id": 808, "seek": 533416, "start": 5334.16, "end": 5342.92, "text": " which is kind of a matrix we can convert it into an array or into a tensor we can display", "tokens": [597, 307, 733, 295, 257, 8141, 321, 393, 7620, 309, 666, 364, 10225, 420, 666, 257, 40863, 321, 393, 4674], "temperature": 0.0, "avg_logprob": -0.05064168709975023, "compression_ratio": 1.7435897435897436, "no_speech_prob": 9.132539844358689e-07}, {"id": 809, "seek": 533416, "start": 5342.92, "end": 5351.5599999999995, "text": " it and they look almost the same you can index into a single row you can index into a single", "tokens": [309, 293, 436, 574, 1920, 264, 912, 291, 393, 8186, 666, 257, 2167, 5386, 291, 393, 8186, 666, 257, 2167], "temperature": 0.0, "avg_logprob": -0.05064168709975023, "compression_ratio": 1.7435897435897436, "no_speech_prob": 9.132539844358689e-07}, {"id": 810, "seek": 533416, "start": 5351.5599999999995, "end": 5360.44, "text": " column and so it's important to know this is very important colon means every row because", "tokens": [7738, 293, 370, 309, 311, 1021, 281, 458, 341, 307, 588, 1021, 8255, 1355, 633, 5386, 570], "temperature": 0.0, "avg_logprob": -0.05064168709975023, "compression_ratio": 1.7435897435897436, "no_speech_prob": 9.132539844358689e-07}, {"id": 811, "seek": 536044, "start": 5360.44, "end": 5366.04, "text": " I put it in the first spot right so if I put it in the second spot it would mean every", "tokens": [286, 829, 309, 294, 264, 700, 4008, 558, 370, 498, 286, 829, 309, 294, 264, 1150, 4008, 309, 576, 914, 633], "temperature": 0.0, "avg_logprob": -0.0699558908289129, "compression_ratio": 1.7572815533980584, "no_speech_prob": 1.0087585877727179e-07}, {"id": 812, "seek": 536044, "start": 5366.04, "end": 5377.36, "text": " column and so therefore comma colon is exactly the same as removing it so it just turns out", "tokens": [7738, 293, 370, 4412, 22117, 8255, 307, 2293, 264, 912, 382, 12720, 309, 370, 309, 445, 4523, 484], "temperature": 0.0, "avg_logprob": -0.0699558908289129, "compression_ratio": 1.7572815533980584, "no_speech_prob": 1.0087585877727179e-07}, {"id": 813, "seek": 536044, "start": 5377.36, "end": 5383.0599999999995, "text": " you can always remove colons that are at the end because they're kind of they're just implied", "tokens": [291, 393, 1009, 4159, 1173, 892, 300, 366, 412, 264, 917, 570, 436, 434, 733, 295, 436, 434, 445, 32614], "temperature": 0.0, "avg_logprob": -0.0699558908289129, "compression_ratio": 1.7572815533980584, "no_speech_prob": 1.0087585877727179e-07}, {"id": 814, "seek": 536044, "start": 5383.0599999999995, "end": 5388.86, "text": " right you never have to and I often kind of put them in anyway because just kind of makes", "tokens": [558, 291, 1128, 362, 281, 293, 286, 2049, 733, 295, 829, 552, 294, 4033, 570, 445, 733, 295, 1669], "temperature": 0.0, "avg_logprob": -0.0699558908289129, "compression_ratio": 1.7572815533980584, "no_speech_prob": 1.0087585877727179e-07}, {"id": 815, "seek": 538886, "start": 5388.86, "end": 5396.299999999999, "text": " it a bit more obvious how these things kind of match up or how they differ you can combine", "tokens": [309, 257, 857, 544, 6322, 577, 613, 721, 733, 295, 2995, 493, 420, 577, 436, 743, 291, 393, 10432], "temperature": 0.0, "avg_logprob": -0.16422367095947266, "compression_ratio": 1.7427184466019416, "no_speech_prob": 2.1907769678364275e-06}, {"id": 816, "seek": 538886, "start": 5396.299999999999, "end": 5401.78, "text": " them together so give me the first row and everything from the first up to but not including", "tokens": [552, 1214, 370, 976, 385, 264, 700, 5386, 293, 1203, 490, 264, 700, 493, 281, 457, 406, 3009], "temperature": 0.0, "avg_logprob": -0.16422367095947266, "compression_ratio": 1.7427184466019416, "no_speech_prob": 2.1907769678364275e-06}, {"id": 817, "seek": 538886, "start": 5401.78, "end": 5409.839999999999, "text": " the third column right so there's that five six you can add stuff to them you can check", "tokens": [264, 2636, 7738, 558, 370, 456, 311, 300, 1732, 2309, 291, 393, 909, 1507, 281, 552, 291, 393, 1520], "temperature": 0.0, "avg_logprob": -0.16422367095947266, "compression_ratio": 1.7427184466019416, "no_speech_prob": 2.1907769678364275e-06}, {"id": 818, "seek": 538886, "start": 5409.839999999999, "end": 5417.96, "text": " their type notice that this is different to the Python of cozy the Python type the type", "tokens": [641, 2010, 3449, 300, 341, 307, 819, 281, 264, 15329, 295, 29414, 264, 15329, 2010, 264, 2010], "temperature": 0.0, "avg_logprob": -0.16422367095947266, "compression_ratio": 1.7427184466019416, "no_speech_prob": 2.1907769678364275e-06}, {"id": 819, "seek": 541796, "start": 5417.96, "end": 5423.4800000000005, "text": " is a function just tells you it's a tensor if you want to know what kind of tensor you", "tokens": [307, 257, 2445, 445, 5112, 291, 309, 311, 257, 40863, 498, 291, 528, 281, 458, 437, 733, 295, 40863, 291], "temperature": 0.0, "avg_logprob": -0.08554866749753234, "compression_ratio": 1.7259615384615385, "no_speech_prob": 1.7603391597731388e-06}, {"id": 820, "seek": 541796, "start": 5423.4800000000005, "end": 5431.34, "text": " have to use type as a method so it's a long tensor you can multiply them by a float turns", "tokens": [362, 281, 764, 2010, 382, 257, 3170, 370, 309, 311, 257, 938, 40863, 291, 393, 12972, 552, 538, 257, 15706, 4523], "temperature": 0.0, "avg_logprob": -0.08554866749753234, "compression_ratio": 1.7259615384615385, "no_speech_prob": 1.7603391597731388e-06}, {"id": 821, "seek": 541796, "start": 5431.34, "end": 5435.0, "text": " it into a float you know to have a fiddle around if you haven't done much stuff with", "tokens": [309, 666, 257, 15706, 291, 458, 281, 362, 257, 24553, 2285, 926, 498, 291, 2378, 380, 1096, 709, 1507, 365], "temperature": 0.0, "avg_logprob": -0.08554866749753234, "compression_ratio": 1.7259615384615385, "no_speech_prob": 1.7603391597731388e-06}, {"id": 822, "seek": 541796, "start": 5435.0, "end": 5444.4, "text": " numpy or pytorch before this is a good opportunity to just go crazy try things out try try things", "tokens": [1031, 8200, 420, 25878, 284, 339, 949, 341, 307, 257, 665, 2650, 281, 445, 352, 3219, 853, 721, 484, 853, 853, 721], "temperature": 0.0, "avg_logprob": -0.08554866749753234, "compression_ratio": 1.7259615384615385, "no_speech_prob": 1.7603391597731388e-06}, {"id": 823, "seek": 544440, "start": 5444.4, "end": 5453.0199999999995, "text": " that you think might not work and see if you actually get an error message you know so", "tokens": [300, 291, 519, 1062, 406, 589, 293, 536, 498, 291, 767, 483, 364, 6713, 3636, 291, 458, 370], "temperature": 0.0, "avg_logprob": -0.09063827423822313, "compression_ratio": 1.4836065573770492, "no_speech_prob": 8.315269610648102e-07}, {"id": 824, "seek": 544440, "start": 5453.0199999999995, "end": 5461.299999999999, "text": " we now want to find out how good is our model our model that involves just comparing something", "tokens": [321, 586, 528, 281, 915, 484, 577, 665, 307, 527, 2316, 527, 2316, 300, 11626, 445, 15763, 746], "temperature": 0.0, "avg_logprob": -0.09063827423822313, "compression_ratio": 1.4836065573770492, "no_speech_prob": 8.315269610648102e-07}, {"id": 825, "seek": 546130, "start": 5461.3, "end": 5474.96, "text": " to to the domain so we should not compare you should not check how good our model is", "tokens": [281, 281, 264, 9274, 370, 321, 820, 406, 6794, 291, 820, 406, 1520, 577, 665, 527, 2316, 307], "temperature": 0.0, "avg_logprob": -0.10406235803531695, "compression_ratio": 1.8421052631578947, "no_speech_prob": 4.0525392819290573e-07}, {"id": 826, "seek": 546130, "start": 5474.96, "end": 5479.4400000000005, "text": " on the training set as we've discussed we should check it on a validation set and we", "tokens": [322, 264, 3097, 992, 382, 321, 600, 7152, 321, 820, 1520, 309, 322, 257, 24071, 992, 293, 321], "temperature": 0.0, "avg_logprob": -0.10406235803531695, "compression_ratio": 1.8421052631578947, "no_speech_prob": 4.0525392819290573e-07}, {"id": 827, "seek": 546130, "start": 5479.4400000000005, "end": 5485.6, "text": " already have a validation set it's everything inside the valid directory so let's go ahead", "tokens": [1217, 362, 257, 24071, 992, 309, 311, 1203, 1854, 264, 7363, 21120, 370, 718, 311, 352, 2286], "temperature": 0.0, "avg_logprob": -0.10406235803531695, "compression_ratio": 1.8421052631578947, "no_speech_prob": 4.0525392819290573e-07}, {"id": 828, "seek": 546130, "start": 5485.6, "end": 5489.76, "text": " and like combine all those steps before let's go through everything in the validation set", "tokens": [293, 411, 10432, 439, 729, 4439, 949, 718, 311, 352, 807, 1203, 294, 264, 24071, 992], "temperature": 0.0, "avg_logprob": -0.10406235803531695, "compression_ratio": 1.8421052631578947, "no_speech_prob": 4.0525392819290573e-07}, {"id": 829, "seek": 548976, "start": 5489.76, "end": 5498.280000000001, "text": " three LS open them turn them into a tensor stack them all up turn them into floats divide", "tokens": [1045, 36657, 1269, 552, 1261, 552, 666, 257, 40863, 8630, 552, 439, 493, 1261, 552, 666, 37878, 9845], "temperature": 0.0, "avg_logprob": -0.0937029614168055, "compression_ratio": 1.552325581395349, "no_speech_prob": 7.690364327572752e-07}, {"id": 830, "seek": 548976, "start": 5498.280000000001, "end": 5506.8, "text": " by 255 okay let's do the same for sevens so we're just putting all the steps we did before", "tokens": [538, 3552, 20, 1392, 718, 311, 360, 264, 912, 337, 3407, 82, 370, 321, 434, 445, 3372, 439, 264, 4439, 321, 630, 949], "temperature": 0.0, "avg_logprob": -0.0937029614168055, "compression_ratio": 1.552325581395349, "no_speech_prob": 7.690364327572752e-07}, {"id": 831, "seek": 548976, "start": 5506.8, "end": 5514.96, "text": " into a couple of lines I always try to print out shapes like all the time because if a", "tokens": [666, 257, 1916, 295, 3876, 286, 1009, 853, 281, 4482, 484, 10854, 411, 439, 264, 565, 570, 498, 257], "temperature": 0.0, "avg_logprob": -0.0937029614168055, "compression_ratio": 1.552325581395349, "no_speech_prob": 7.690364327572752e-07}, {"id": 832, "seek": 551496, "start": 5514.96, "end": 5521.76, "text": " shape is not what you expected then you can you know get weird things going on so the", "tokens": [3909, 307, 406, 437, 291, 5176, 550, 291, 393, 291, 458, 483, 3657, 721, 516, 322, 370, 264], "temperature": 0.0, "avg_logprob": -0.08577943226647755, "compression_ratio": 1.6730769230769231, "no_speech_prob": 3.866962288157083e-07}, {"id": 833, "seek": 551496, "start": 5521.76, "end": 5527.04, "text": " idea is we want some function is three that will return true if we think something is", "tokens": [1558, 307, 321, 528, 512, 2445, 307, 1045, 300, 486, 2736, 2074, 498, 321, 519, 746, 307], "temperature": 0.0, "avg_logprob": -0.08577943226647755, "compression_ratio": 1.6730769230769231, "no_speech_prob": 3.866962288157083e-07}, {"id": 834, "seek": 551496, "start": 5527.04, "end": 5536.04, "text": " a three so to do that we have to decide whether our digit that we're testing on is closer", "tokens": [257, 1045, 370, 281, 360, 300, 321, 362, 281, 4536, 1968, 527, 14293, 300, 321, 434, 4997, 322, 307, 4966], "temperature": 0.0, "avg_logprob": -0.08577943226647755, "compression_ratio": 1.6730769230769231, "no_speech_prob": 3.866962288157083e-07}, {"id": 835, "seek": 553604, "start": 5536.04, "end": 5547.12, "text": " to the ideal three or the ideal seven so let's create a little function that returns takes", "tokens": [281, 264, 7157, 1045, 420, 264, 7157, 3407, 370, 718, 311, 1884, 257, 707, 2445, 300, 11247, 2516], "temperature": 0.0, "avg_logprob": -0.152950270134106, "compression_ratio": 1.8714285714285714, "no_speech_prob": 2.3454325059901748e-07}, {"id": 836, "seek": 553604, "start": 5547.12, "end": 5554.12, "text": " the difference between two things takes the absolute value and then takes the mean so", "tokens": [264, 2649, 1296, 732, 721, 2516, 264, 8236, 2158, 293, 550, 2516, 264, 914, 370], "temperature": 0.0, "avg_logprob": -0.152950270134106, "compression_ratio": 1.8714285714285714, "no_speech_prob": 2.3454325059901748e-07}, {"id": 837, "seek": 553604, "start": 5554.12, "end": 5559.4, "text": " we're going to create this function amnest distance that takes the difference between", "tokens": [321, 434, 516, 281, 1884, 341, 2445, 669, 77, 377, 4560, 300, 2516, 264, 2649, 1296], "temperature": 0.0, "avg_logprob": -0.152950270134106, "compression_ratio": 1.8714285714285714, "no_speech_prob": 2.3454325059901748e-07}, {"id": 838, "seek": 555940, "start": 5559.4, "end": 5565.879999999999, "text": " two answers takes their absolute value and then takes the mean and it takes the mean", "tokens": [732, 6338, 2516, 641, 8236, 2158, 293, 550, 2516, 264, 914, 293, 309, 2516, 264, 914], "temperature": 0.0, "avg_logprob": -0.11476266768670851, "compression_ratio": 2.0, "no_speech_prob": 1.414473103977798e-06}, {"id": 839, "seek": 555940, "start": 5565.879999999999, "end": 5575.08, "text": " and look at this we've got minus this time it takes the mean over the last over the second", "tokens": [293, 574, 412, 341, 321, 600, 658, 3175, 341, 565, 309, 2516, 264, 914, 670, 264, 1036, 670, 264, 1150], "temperature": 0.0, "avg_logprob": -0.11476266768670851, "compression_ratio": 2.0, "no_speech_prob": 1.414473103977798e-06}, {"id": 840, "seek": 555940, "start": 5575.08, "end": 5584.44, "text": " last and third last sorry the last and second last dimensions so this is going to take the", "tokens": [1036, 293, 2636, 1036, 2597, 264, 1036, 293, 1150, 1036, 12819, 370, 341, 307, 516, 281, 747, 264], "temperature": 0.0, "avg_logprob": -0.11476266768670851, "compression_ratio": 2.0, "no_speech_prob": 1.414473103977798e-06}, {"id": 841, "seek": 558444, "start": 5584.44, "end": 5593.0, "text": " mean across the kind of x and y axes and so here you can see it's returning a single number", "tokens": [914, 2108, 264, 733, 295, 2031, 293, 288, 35387, 293, 370, 510, 291, 393, 536, 309, 311, 12678, 257, 2167, 1230], "temperature": 0.0, "avg_logprob": -0.11351734610164867, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.6028066056605894e-06}, {"id": 842, "seek": 558444, "start": 5593.0, "end": 5599.2, "text": " which is the distance of a three from the mean three so that's the same as the value", "tokens": [597, 307, 264, 4560, 295, 257, 1045, 490, 264, 914, 1045, 370, 300, 311, 264, 912, 382, 264, 2158], "temperature": 0.0, "avg_logprob": -0.11351734610164867, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.6028066056605894e-06}, {"id": 843, "seek": 558444, "start": 5599.2, "end": 5607.24, "text": " that we got earlier point one one one four so we need to do this for every image in the", "tokens": [300, 321, 658, 3071, 935, 472, 472, 472, 1451, 370, 321, 643, 281, 360, 341, 337, 633, 3256, 294, 264], "temperature": 0.0, "avg_logprob": -0.11351734610164867, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.6028066056605894e-06}, {"id": 844, "seek": 558444, "start": 5607.24, "end": 5612.04, "text": " validation set because we're trying to find the overall metric remember the metric is", "tokens": [24071, 992, 570, 321, 434, 1382, 281, 915, 264, 4787, 20678, 1604, 264, 20678, 307], "temperature": 0.0, "avg_logprob": -0.11351734610164867, "compression_ratio": 1.6908212560386473, "no_speech_prob": 1.6028066056605894e-06}, {"id": 845, "seek": 561204, "start": 5612.04, "end": 5618.36, "text": " the thing we look at to say how good is our model so here's something crazy we can call", "tokens": [264, 551, 321, 574, 412, 281, 584, 577, 665, 307, 527, 2316, 370, 510, 311, 746, 3219, 321, 393, 818], "temperature": 0.0, "avg_logprob": -0.09223445745614858, "compression_ratio": 1.5476190476190477, "no_speech_prob": 7.934485779514944e-07}, {"id": 846, "seek": 561204, "start": 5618.36, "end": 5627.8, "text": " amnest distance not just on r3 but are on the entire validation set against the main", "tokens": [669, 77, 377, 4560, 406, 445, 322, 367, 18, 457, 366, 322, 264, 2302, 24071, 992, 1970, 264, 2135], "temperature": 0.0, "avg_logprob": -0.09223445745614858, "compression_ratio": 1.5476190476190477, "no_speech_prob": 7.934485779514944e-07}, {"id": 847, "seek": 561204, "start": 5627.8, "end": 5634.8, "text": " three so that's wild like there's no normal programming that we would do where we could", "tokens": [1045, 370, 300, 311, 4868, 411, 456, 311, 572, 2710, 9410, 300, 321, 576, 360, 689, 321, 727], "temperature": 0.0, "avg_logprob": -0.09223445745614858, "compression_ratio": 1.5476190476190477, "no_speech_prob": 7.934485779514944e-07}, {"id": 848, "seek": 563480, "start": 5634.8, "end": 5644.6, "text": " somehow pass in either a matrix or a rank three tensor and somehow it works both times", "tokens": [6063, 1320, 294, 2139, 257, 8141, 420, 257, 6181, 1045, 40863, 293, 6063, 309, 1985, 1293, 1413], "temperature": 0.0, "avg_logprob": -0.08744477389151589, "compression_ratio": 1.6566265060240963, "no_speech_prob": 5.368744950828841e-07}, {"id": 849, "seek": 563480, "start": 5644.6, "end": 5654.16, "text": " and what actually happened here is that instead of returning a single number it returned 1010", "tokens": [293, 437, 767, 2011, 510, 307, 300, 2602, 295, 12678, 257, 2167, 1230, 309, 8752, 1266, 3279], "temperature": 0.0, "avg_logprob": -0.08744477389151589, "compression_ratio": 1.6566265060240963, "no_speech_prob": 5.368744950828841e-07}, {"id": 850, "seek": 563480, "start": 5654.16, "end": 5662.16, "text": " numbers and it did this because it used something called broadcasting and broadcasting is like", "tokens": [3547, 293, 309, 630, 341, 570, 309, 1143, 746, 1219, 30024, 293, 30024, 307, 411], "temperature": 0.0, "avg_logprob": -0.08744477389151589, "compression_ratio": 1.6566265060240963, "no_speech_prob": 5.368744950828841e-07}, {"id": 851, "seek": 566216, "start": 5662.16, "end": 5668.68, "text": " the super special magic trick that lets you make python into a very very high performance", "tokens": [264, 1687, 2121, 5585, 4282, 300, 6653, 291, 652, 38797, 666, 257, 588, 588, 1090, 3389], "temperature": 0.0, "avg_logprob": -0.10142222011790555, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3497004829332582e-06}, {"id": 852, "seek": 566216, "start": 5668.68, "end": 5675.96, "text": " language and in fact if you do this broadcasting on GPU tensors and pytorch it actually does", "tokens": [2856, 293, 294, 1186, 498, 291, 360, 341, 30024, 322, 18407, 10688, 830, 293, 25878, 284, 339, 309, 767, 775], "temperature": 0.0, "avg_logprob": -0.10142222011790555, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3497004829332582e-06}, {"id": 853, "seek": 566216, "start": 5675.96, "end": 5683.04, "text": " this operation on the GPU even though you wrote it in python here's what happens look", "tokens": [341, 6916, 322, 264, 18407, 754, 1673, 291, 4114, 309, 294, 38797, 510, 311, 437, 2314, 574], "temperature": 0.0, "avg_logprob": -0.10142222011790555, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3497004829332582e-06}, {"id": 854, "seek": 566216, "start": 5683.04, "end": 5690.32, "text": " here this a minus b so we're doing a minus b on two things we've got first of all valid", "tokens": [510, 341, 257, 3175, 272, 370, 321, 434, 884, 257, 3175, 272, 322, 732, 721, 321, 600, 658, 700, 295, 439, 7363], "temperature": 0.0, "avg_logprob": -0.10142222011790555, "compression_ratio": 1.6108597285067874, "no_speech_prob": 1.3497004829332582e-06}, {"id": 855, "seek": 569032, "start": 5690.32, "end": 5700.84, "text": " three tens or valid three tensor is a thousand or so images right and remember that main", "tokens": [1045, 10688, 420, 7363, 1045, 40863, 307, 257, 4714, 420, 370, 5267, 558, 293, 1604, 300, 2135], "temperature": 0.0, "avg_logprob": -0.13823121633285132, "compression_ratio": 1.6, "no_speech_prob": 2.6841935323318467e-06}, {"id": 856, "seek": 569032, "start": 5700.84, "end": 5713.46, "text": " three is just our single ideal three so what is something of this shape minus something", "tokens": [1045, 307, 445, 527, 2167, 7157, 1045, 370, 437, 307, 746, 295, 341, 3909, 3175, 746], "temperature": 0.0, "avg_logprob": -0.13823121633285132, "compression_ratio": 1.6, "no_speech_prob": 2.6841935323318467e-06}, {"id": 857, "seek": 571346, "start": 5713.46, "end": 5721.0, "text": " of this shape well broadcasting means that if this shape doesn't match this shape like", "tokens": [295, 341, 3909, 731, 30024, 1355, 300, 498, 341, 3909, 1177, 380, 2995, 341, 3909, 411], "temperature": 0.0, "avg_logprob": -0.07010678775974961, "compression_ratio": 1.696774193548387, "no_speech_prob": 5.539164362744486e-07}, {"id": 858, "seek": 571346, "start": 5721.0, "end": 5726.36, "text": " if they did match it would just subtract every corresponding item but because they don't", "tokens": [498, 436, 630, 2995, 309, 576, 445, 16390, 633, 11760, 3174, 457, 570, 436, 500, 380], "temperature": 0.0, "avg_logprob": -0.07010678775974961, "compression_ratio": 1.696774193548387, "no_speech_prob": 5.539164362744486e-07}, {"id": 859, "seek": 571346, "start": 5726.36, "end": 5735.04, "text": " match it's a it actually acts as if there's a thousand and ten versions of this so it's", "tokens": [2995, 309, 311, 257, 309, 767, 10672, 382, 498, 456, 311, 257, 4714, 293, 2064, 9606, 295, 341, 370, 309, 311], "temperature": 0.0, "avg_logprob": -0.07010678775974961, "compression_ratio": 1.696774193548387, "no_speech_prob": 5.539164362744486e-07}, {"id": 860, "seek": 573504, "start": 5735.04, "end": 5744.44, "text": " actually going to subtract this from every single one of these right so broadcasting", "tokens": [767, 516, 281, 16390, 341, 490, 633, 2167, 472, 295, 613, 558, 370, 30024], "temperature": 0.0, "avg_logprob": -0.0799874750773112, "compression_ratio": 1.8235294117647058, "no_speech_prob": 8.1863481682376e-07}, {"id": 861, "seek": 573504, "start": 5744.44, "end": 5750.0199999999995, "text": " let's look at some examples so broadcasting requires us to first of all understand the", "tokens": [718, 311, 574, 412, 512, 5110, 370, 30024, 7029, 505, 281, 700, 295, 439, 1223, 264], "temperature": 0.0, "avg_logprob": -0.0799874750773112, "compression_ratio": 1.8235294117647058, "no_speech_prob": 8.1863481682376e-07}, {"id": 862, "seek": 573504, "start": 5750.0199999999995, "end": 5755.56, "text": " idea of element-wise operations this is an element-wise operation here is a rank one", "tokens": [1558, 295, 4478, 12, 3711, 7705, 341, 307, 364, 4478, 12, 3711, 6916, 510, 307, 257, 6181, 472], "temperature": 0.0, "avg_logprob": -0.0799874750773112, "compression_ratio": 1.8235294117647058, "no_speech_prob": 8.1863481682376e-07}, {"id": 863, "seek": 573504, "start": 5755.56, "end": 5762.2, "text": " tensor of size three and another rank one tensor of size three so we would say these", "tokens": [40863, 295, 2744, 1045, 293, 1071, 6181, 472, 40863, 295, 2744, 1045, 370, 321, 576, 584, 613], "temperature": 0.0, "avg_logprob": -0.0799874750773112, "compression_ratio": 1.8235294117647058, "no_speech_prob": 8.1863481682376e-07}, {"id": 864, "seek": 576220, "start": 5762.2, "end": 5768.2, "text": " sizes match they're the same and so when I add one two three to one one one I get back", "tokens": [11602, 2995, 436, 434, 264, 912, 293, 370, 562, 286, 909, 472, 732, 1045, 281, 472, 472, 472, 286, 483, 646], "temperature": 0.0, "avg_logprob": -0.09850043342227027, "compression_ratio": 1.5485714285714285, "no_speech_prob": 5.989265901007457e-07}, {"id": 865, "seek": 576220, "start": 5768.2, "end": 5774.599999999999, "text": " two three four it just takes the corresponding items and adds them together so that's called", "tokens": [732, 1045, 1451, 309, 445, 2516, 264, 11760, 4754, 293, 10860, 552, 1214, 370, 300, 311, 1219], "temperature": 0.0, "avg_logprob": -0.09850043342227027, "compression_ratio": 1.5485714285714285, "no_speech_prob": 5.989265901007457e-07}, {"id": 866, "seek": 576220, "start": 5774.599999999999, "end": 5789.679999999999, "text": " element-wise operations so when I have different shapes as we described before what it ends", "tokens": [4478, 12, 3711, 7705, 370, 562, 286, 362, 819, 10854, 382, 321, 7619, 949, 437, 309, 5314], "temperature": 0.0, "avg_logprob": -0.09850043342227027, "compression_ratio": 1.5485714285714285, "no_speech_prob": 5.989265901007457e-07}, {"id": 867, "seek": 578968, "start": 5789.68, "end": 5797.52, "text": " up doing is it basically copies this this number a thousand and ten times and it acts", "tokens": [493, 884, 307, 309, 1936, 14341, 341, 341, 1230, 257, 4714, 293, 2064, 1413, 293, 309, 10672], "temperature": 0.0, "avg_logprob": -0.07676114806209702, "compression_ratio": 1.9659090909090908, "no_speech_prob": 1.3287749425217044e-06}, {"id": 868, "seek": 578968, "start": 5797.52, "end": 5807.4800000000005, "text": " as if we had said valid three tens minus a thousand and ten copies of mean three as it", "tokens": [382, 498, 321, 632, 848, 7363, 1045, 10688, 3175, 257, 4714, 293, 2064, 14341, 295, 914, 1045, 382, 309], "temperature": 0.0, "avg_logprob": -0.07676114806209702, "compression_ratio": 1.9659090909090908, "no_speech_prob": 1.3287749425217044e-06}, {"id": 869, "seek": 578968, "start": 5807.4800000000005, "end": 5812.68, "text": " says here it doesn't actually copy mean three a thousand and ten times it just pretends", "tokens": [1619, 510, 309, 1177, 380, 767, 5055, 914, 1045, 257, 4714, 293, 2064, 1413, 309, 445, 1162, 2581], "temperature": 0.0, "avg_logprob": -0.07676114806209702, "compression_ratio": 1.9659090909090908, "no_speech_prob": 1.3287749425217044e-06}, {"id": 870, "seek": 578968, "start": 5812.68, "end": 5816.52, "text": " that it did right it just acts as if it did so basically kind of loops back around to", "tokens": [300, 309, 630, 558, 309, 445, 10672, 382, 498, 309, 630, 370, 1936, 733, 295, 16121, 646, 926, 281], "temperature": 0.0, "avg_logprob": -0.07676114806209702, "compression_ratio": 1.9659090909090908, "no_speech_prob": 1.3287749425217044e-06}, {"id": 871, "seek": 581652, "start": 5816.52, "end": 5823.76, "text": " the start again and again and it does the whole thing and see or encoder on the GPU", "tokens": [264, 722, 797, 293, 797, 293, 309, 775, 264, 1379, 551, 293, 536, 420, 2058, 19866, 322, 264, 18407], "temperature": 0.0, "avg_logprob": -0.1477067768573761, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.520939853591699e-07}, {"id": 872, "seek": 581652, "start": 5823.76, "end": 5831.4400000000005, "text": " so then we see absolute value right so let's go back up here after we do the minus we go", "tokens": [370, 550, 321, 536, 8236, 2158, 558, 370, 718, 311, 352, 646, 493, 510, 934, 321, 360, 264, 3175, 321, 352], "temperature": 0.0, "avg_logprob": -0.1477067768573761, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.520939853591699e-07}, {"id": 873, "seek": 581652, "start": 5831.4400000000005, "end": 5842.200000000001, "text": " absolute value so what happens when we call absolute value on something of size 10 10", "tokens": [8236, 2158, 370, 437, 2314, 562, 321, 818, 8236, 2158, 322, 746, 295, 2744, 1266, 1266], "temperature": 0.0, "avg_logprob": -0.1477067768573761, "compression_ratio": 1.6329113924050633, "no_speech_prob": 4.520939853591699e-07}, {"id": 874, "seek": 584220, "start": 5842.2, "end": 5851.8, "text": " by 28 by 28 just cause absolute value on each underlying thing and then finally we call", "tokens": [538, 7562, 538, 7562, 445, 3082, 8236, 2158, 322, 1184, 14217, 551, 293, 550, 2721, 321, 818], "temperature": 0.0, "avg_logprob": -0.1409557686477411, "compression_ratio": 1.5900621118012421, "no_speech_prob": 2.657723428001191e-07}, {"id": 875, "seek": 584220, "start": 5851.8, "end": 5858.08, "text": " mean minus one is the last element always in Python minus two is the second last so", "tokens": [914, 3175, 472, 307, 264, 1036, 4478, 1009, 294, 15329, 3175, 732, 307, 264, 1150, 1036, 370], "temperature": 0.0, "avg_logprob": -0.1409557686477411, "compression_ratio": 1.5900621118012421, "no_speech_prob": 2.657723428001191e-07}, {"id": 876, "seek": 584220, "start": 5858.08, "end": 5864.88, "text": " this is taking the mean over the last two axes and so then it's going to return just", "tokens": [341, 307, 1940, 264, 914, 670, 264, 1036, 732, 35387, 293, 370, 550, 309, 311, 516, 281, 2736, 445], "temperature": 0.0, "avg_logprob": -0.1409557686477411, "compression_ratio": 1.5900621118012421, "no_speech_prob": 2.657723428001191e-07}, {"id": 877, "seek": 586488, "start": 5864.88, "end": 5872.88, "text": " the first axis so we're going to end up with a thousand and ten means for a thousand and", "tokens": [264, 700, 10298, 370, 321, 434, 516, 281, 917, 493, 365, 257, 4714, 293, 2064, 1355, 337, 257, 4714, 293], "temperature": 0.0, "avg_logprob": -0.12818907224214993, "compression_ratio": 1.6728395061728396, "no_speech_prob": 4.737901520002197e-07}, {"id": 878, "seek": 586488, "start": 5872.88, "end": 5876.68, "text": " ten distances which is exactly what we want we want to know how far away is our each of", "tokens": [2064, 22182, 597, 307, 2293, 437, 321, 528, 321, 528, 281, 458, 577, 1400, 1314, 307, 527, 1184, 295], "temperature": 0.0, "avg_logprob": -0.12818907224214993, "compression_ratio": 1.6728395061728396, "no_speech_prob": 4.737901520002197e-07}, {"id": 879, "seek": 586488, "start": 5876.68, "end": 5887.4400000000005, "text": " our validation items away from the the ideal three so then we can create our is three function", "tokens": [527, 24071, 4754, 1314, 490, 264, 264, 7157, 1045, 370, 550, 321, 393, 1884, 527, 307, 1045, 2445], "temperature": 0.0, "avg_logprob": -0.12818907224214993, "compression_ratio": 1.6728395061728396, "no_speech_prob": 4.737901520002197e-07}, {"id": 880, "seek": 588744, "start": 5887.44, "end": 5896.0, "text": " which is hey is the distance between the number in question and the perfect three less than", "tokens": [597, 307, 4177, 307, 264, 4560, 1296, 264, 1230, 294, 1168, 293, 264, 2176, 1045, 1570, 813], "temperature": 0.0, "avg_logprob": -0.12771693769707737, "compression_ratio": 2.0344827586206895, "no_speech_prob": 2.813010723912157e-06}, {"id": 881, "seek": 588744, "start": 5896.0, "end": 5901.5599999999995, "text": " the distance between the number in question and the perfect seven if it is it's a three", "tokens": [264, 4560, 1296, 264, 1230, 294, 1168, 293, 264, 2176, 3407, 498, 309, 307, 309, 311, 257, 1045], "temperature": 0.0, "avg_logprob": -0.12771693769707737, "compression_ratio": 2.0344827586206895, "no_speech_prob": 2.813010723912157e-06}, {"id": 882, "seek": 588744, "start": 5901.5599999999995, "end": 5908.759999999999, "text": " right so our three that was that actual three we had is it a three yes okay and then we", "tokens": [558, 370, 527, 1045, 300, 390, 300, 3539, 1045, 321, 632, 307, 309, 257, 1045, 2086, 1392, 293, 550, 321], "temperature": 0.0, "avg_logprob": -0.12771693769707737, "compression_ratio": 2.0344827586206895, "no_speech_prob": 2.813010723912157e-06}, {"id": 883, "seek": 588744, "start": 5908.759999999999, "end": 5917.16, "text": " can turn that into a float and yes becomes one thanks to broadcasting we can do it for", "tokens": [393, 1261, 300, 666, 257, 15706, 293, 2086, 3643, 472, 3231, 281, 30024, 321, 393, 360, 309, 337], "temperature": 0.0, "avg_logprob": -0.12771693769707737, "compression_ratio": 2.0344827586206895, "no_speech_prob": 2.813010723912157e-06}, {"id": 884, "seek": 591716, "start": 5917.16, "end": 5925.599999999999, "text": " that entire set right so this is so cool we basically get rid of loops in in in in this", "tokens": [300, 2302, 992, 558, 370, 341, 307, 370, 1627, 321, 1936, 483, 3973, 295, 16121, 294, 294, 294, 294, 341], "temperature": 0.0, "avg_logprob": -0.07059011459350586, "compression_ratio": 1.7241379310344827, "no_speech_prob": 1.2289166306800325e-06}, {"id": 885, "seek": 591716, "start": 5925.599999999999, "end": 5931.12, "text": " kind of programming you should have very few very very few loops loops make things much", "tokens": [733, 295, 9410, 291, 820, 362, 588, 1326, 588, 588, 1326, 16121, 16121, 652, 721, 709], "temperature": 0.0, "avg_logprob": -0.07059011459350586, "compression_ratio": 1.7241379310344827, "no_speech_prob": 1.2289166306800325e-06}, {"id": 886, "seek": 591716, "start": 5931.12, "end": 5937.4, "text": " harder to read and and hundreds of thousands of times slower on the GPU potentially tens", "tokens": [6081, 281, 1401, 293, 293, 6779, 295, 5383, 295, 1413, 14009, 322, 264, 18407, 7263, 10688], "temperature": 0.0, "avg_logprob": -0.07059011459350586, "compression_ratio": 1.7241379310344827, "no_speech_prob": 1.2289166306800325e-06}, {"id": 887, "seek": 591716, "start": 5937.4, "end": 5944.98, "text": " of millions of times slower so we can just say is three on our whole valid three tens", "tokens": [295, 6803, 295, 1413, 14009, 370, 321, 393, 445, 584, 307, 1045, 322, 527, 1379, 7363, 1045, 10688], "temperature": 0.0, "avg_logprob": -0.07059011459350586, "compression_ratio": 1.7241379310344827, "no_speech_prob": 1.2289166306800325e-06}, {"id": 888, "seek": 594498, "start": 5944.98, "end": 5949.04, "text": " and then turn that into float and then take the mean so that's going to be the accuracy", "tokens": [293, 550, 1261, 300, 666, 15706, 293, 550, 747, 264, 914, 370, 300, 311, 516, 281, 312, 264, 14170], "temperature": 0.0, "avg_logprob": -0.1042236328125, "compression_ratio": 1.988888888888889, "no_speech_prob": 1.067700509338465e-06}, {"id": 889, "seek": 594498, "start": 5949.04, "end": 5955.839999999999, "text": " of the threes on average and here's the accuracy of the sevens it's just one minus that so", "tokens": [295, 264, 258, 4856, 322, 4274, 293, 510, 311, 264, 14170, 295, 264, 3407, 82, 309, 311, 445, 472, 3175, 300, 370], "temperature": 0.0, "avg_logprob": -0.1042236328125, "compression_ratio": 1.988888888888889, "no_speech_prob": 1.067700509338465e-06}, {"id": 890, "seek": 594498, "start": 5955.839999999999, "end": 5960.639999999999, "text": " the accuracy across threes is about 91 and a bit percent the accuracy on sevens is about", "tokens": [264, 14170, 2108, 258, 4856, 307, 466, 31064, 293, 257, 857, 3043, 264, 14170, 322, 3407, 82, 307, 466], "temperature": 0.0, "avg_logprob": -0.1042236328125, "compression_ratio": 1.988888888888889, "no_speech_prob": 1.067700509338465e-06}, {"id": 891, "seek": 594498, "start": 5960.639999999999, "end": 5969.599999999999, "text": " 98 percent and the average of those two is about 95 percent so here we have a model that's", "tokens": [20860, 3043, 293, 264, 4274, 295, 729, 732, 307, 466, 13420, 3043, 370, 510, 321, 362, 257, 2316, 300, 311], "temperature": 0.0, "avg_logprob": -0.1042236328125, "compression_ratio": 1.988888888888889, "no_speech_prob": 1.067700509338465e-06}, {"id": 892, "seek": 596960, "start": 5969.6, "end": 5976.84, "text": " 95 percent accurate at recognizing threes from sevens it might surprise you that we", "tokens": [13420, 3043, 8559, 412, 18538, 258, 4856, 490, 3407, 82, 309, 1062, 6365, 291, 300, 321], "temperature": 0.0, "avg_logprob": -0.11273760265774196, "compression_ratio": 1.5614035087719298, "no_speech_prob": 2.190774694099673e-06}, {"id": 893, "seek": 596960, "start": 5976.84, "end": 5987.92, "text": " can do that using nothing but arithmetic right so that's what I mean by getting a good baseline", "tokens": [393, 360, 300, 1228, 1825, 457, 42973, 558, 370, 300, 311, 437, 286, 914, 538, 1242, 257, 665, 20518], "temperature": 0.0, "avg_logprob": -0.11273760265774196, "compression_ratio": 1.5614035087719298, "no_speech_prob": 2.190774694099673e-06}, {"id": 894, "seek": 596960, "start": 5987.92, "end": 5997.04, "text": " now the thing is it's not obvious how we kind of improve this right I mean the thing is", "tokens": [586, 264, 551, 307, 309, 311, 406, 6322, 577, 321, 733, 295, 3470, 341, 558, 286, 914, 264, 551, 307], "temperature": 0.0, "avg_logprob": -0.11273760265774196, "compression_ratio": 1.5614035087719298, "no_speech_prob": 2.190774694099673e-06}, {"id": 895, "seek": 599704, "start": 5997.04, "end": 6004.28, "text": " it doesn't match Arthur Samuel's description of machine learning right this is not something", "tokens": [309, 1177, 380, 2995, 19624, 23036, 311, 3855, 295, 3479, 2539, 558, 341, 307, 406, 746], "temperature": 0.0, "avg_logprob": -0.07352836926778157, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.6119654396316037e-06}, {"id": 896, "seek": 599704, "start": 6004.28, "end": 6011.24, "text": " where there's a function which has some parameters which we're testing against some kind of measure", "tokens": [689, 456, 311, 257, 2445, 597, 575, 512, 9834, 597, 321, 434, 4997, 1970, 512, 733, 295, 3481], "temperature": 0.0, "avg_logprob": -0.07352836926778157, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.6119654396316037e-06}, {"id": 897, "seek": 599704, "start": 6011.24, "end": 6016.12, "text": " of fitness and then using that to like improve the parameters iteratively we kind of we just", "tokens": [295, 15303, 293, 550, 1228, 300, 281, 411, 3470, 264, 9834, 17138, 19020, 321, 733, 295, 321, 445], "temperature": 0.0, "avg_logprob": -0.07352836926778157, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.6119654396316037e-06}, {"id": 898, "seek": 599704, "start": 6016.12, "end": 6024.4, "text": " did one step and that's that right so we want to try and do it in this way where we arrange", "tokens": [630, 472, 1823, 293, 300, 311, 300, 558, 370, 321, 528, 281, 853, 293, 360, 309, 294, 341, 636, 689, 321, 9424], "temperature": 0.0, "avg_logprob": -0.07352836926778157, "compression_ratio": 1.7136363636363636, "no_speech_prob": 3.6119654396316037e-06}, {"id": 899, "seek": 602440, "start": 6024.4, "end": 6029.08, "text": " for some automatic means of testing the effectiveness of he called it a weight assignment we'd call", "tokens": [337, 512, 12509, 1355, 295, 4997, 264, 21208, 295, 415, 1219, 309, 257, 3364, 15187, 321, 1116, 818], "temperature": 0.0, "avg_logprob": -0.0919282039006551, "compression_ratio": 1.892116182572614, "no_speech_prob": 3.6119731703365687e-06}, {"id": 900, "seek": 602440, "start": 6029.08, "end": 6034.24, "text": " it a parameter assignment in terms of performance and a mechanism for alterating altering the", "tokens": [309, 257, 13075, 15187, 294, 2115, 295, 3389, 293, 257, 7513, 337, 11337, 990, 11337, 278, 264], "temperature": 0.0, "avg_logprob": -0.0919282039006551, "compression_ratio": 1.892116182572614, "no_speech_prob": 3.6119731703365687e-06}, {"id": 901, "seek": 602440, "start": 6034.24, "end": 6039.48, "text": " weight assignment to maximize the performance that we want to do it that way right because", "tokens": [3364, 15187, 281, 19874, 264, 3389, 300, 321, 528, 281, 360, 309, 300, 636, 558, 570], "temperature": 0.0, "avg_logprob": -0.0919282039006551, "compression_ratio": 1.892116182572614, "no_speech_prob": 3.6119731703365687e-06}, {"id": 902, "seek": 602440, "start": 6039.48, "end": 6044.78, "text": " we know from from chapter one from lesson one but if we do it that way we have this", "tokens": [321, 458, 490, 490, 7187, 472, 490, 6898, 472, 457, 498, 321, 360, 309, 300, 636, 321, 362, 341], "temperature": 0.0, "avg_logprob": -0.0919282039006551, "compression_ratio": 1.892116182572614, "no_speech_prob": 3.6119731703365687e-06}, {"id": 903, "seek": 602440, "start": 6044.78, "end": 6051.92, "text": " like magic box right called machine learning that can do you know particularly combined", "tokens": [411, 5585, 2424, 558, 1219, 3479, 2539, 300, 393, 360, 291, 458, 4098, 9354], "temperature": 0.0, "avg_logprob": -0.0919282039006551, "compression_ratio": 1.892116182572614, "no_speech_prob": 3.6119731703365687e-06}, {"id": 904, "seek": 605192, "start": 6051.92, "end": 6059.24, "text": " with neural nets should be able to solve any problem in theory if you can at least find", "tokens": [365, 18161, 36170, 820, 312, 1075, 281, 5039, 604, 1154, 294, 5261, 498, 291, 393, 412, 1935, 915], "temperature": 0.0, "avg_logprob": -0.07323457400004069, "compression_ratio": 1.5662650602409638, "no_speech_prob": 4.592130551372975e-07}, {"id": 905, "seek": 605192, "start": 6059.24, "end": 6068.62, "text": " the right set of weights so we need something that we can get better and better to learn", "tokens": [264, 558, 992, 295, 17443, 370, 321, 643, 746, 300, 321, 393, 483, 1101, 293, 1101, 281, 1466], "temperature": 0.0, "avg_logprob": -0.07323457400004069, "compression_ratio": 1.5662650602409638, "no_speech_prob": 4.592130551372975e-07}, {"id": 906, "seek": 605192, "start": 6068.62, "end": 6077.76, "text": " so let's think about a function which has parameters so instead of finding an ideal", "tokens": [370, 718, 311, 519, 466, 257, 2445, 597, 575, 9834, 370, 2602, 295, 5006, 364, 7157], "temperature": 0.0, "avg_logprob": -0.07323457400004069, "compression_ratio": 1.5662650602409638, "no_speech_prob": 4.592130551372975e-07}, {"id": 907, "seek": 607776, "start": 6077.76, "end": 6087.400000000001, "text": " image and seeing how far away something is from the ideal image", "tokens": [3256, 293, 2577, 577, 1400, 1314, 746, 307, 490, 264, 7157, 3256], "temperature": 0.0, "avg_logprob": -0.0708002860729511, "compression_ratio": 1.7814207650273224, "no_speech_prob": 2.6016095944214612e-06}, {"id": 908, "seek": 607776, "start": 6087.400000000001, "end": 6091.4400000000005, "text": " so instead of like having something where we test how far away we are from an ideal", "tokens": [370, 2602, 295, 411, 1419, 746, 689, 321, 1500, 577, 1400, 1314, 321, 366, 490, 364, 7157], "temperature": 0.0, "avg_logprob": -0.0708002860729511, "compression_ratio": 1.7814207650273224, "no_speech_prob": 2.6016095944214612e-06}, {"id": 909, "seek": 607776, "start": 6091.4400000000005, "end": 6098.68, "text": " image what we could instead do is come up with a set of weights for each pixel so we're", "tokens": [3256, 437, 321, 727, 2602, 360, 307, 808, 493, 365, 257, 992, 295, 17443, 337, 1184, 19261, 370, 321, 434], "temperature": 0.0, "avg_logprob": -0.0708002860729511, "compression_ratio": 1.7814207650273224, "no_speech_prob": 2.6016095944214612e-06}, {"id": 910, "seek": 607776, "start": 6098.68, "end": 6105.320000000001, "text": " trying to find out if something is the number three and so we know that like in the places", "tokens": [1382, 281, 915, 484, 498, 746, 307, 264, 1230, 1045, 293, 370, 321, 458, 300, 411, 294, 264, 3190], "temperature": 0.0, "avg_logprob": -0.0708002860729511, "compression_ratio": 1.7814207650273224, "no_speech_prob": 2.6016095944214612e-06}, {"id": 911, "seek": 610532, "start": 6105.32, "end": 6110.2, "text": " that you would expect to find three pixels you could give those like high weights so", "tokens": [300, 291, 576, 2066, 281, 915, 1045, 18668, 291, 727, 976, 729, 411, 1090, 17443, 370], "temperature": 0.0, "avg_logprob": -0.12208846678216774, "compression_ratio": 1.7258883248730965, "no_speech_prob": 1.5534964177277288e-06}, {"id": 912, "seek": 610532, "start": 6110.2, "end": 6116.28, "text": " you can say hey if there's a dot in those places we give it like a high score and if", "tokens": [291, 393, 584, 4177, 498, 456, 311, 257, 5893, 294, 729, 3190, 321, 976, 309, 411, 257, 1090, 6175, 293, 498], "temperature": 0.0, "avg_logprob": -0.12208846678216774, "compression_ratio": 1.7258883248730965, "no_speech_prob": 1.5534964177277288e-06}, {"id": 913, "seek": 610532, "start": 6116.28, "end": 6120.84, "text": " there's dots in other places we'll give it like a low score but we can actually come", "tokens": [456, 311, 15026, 294, 661, 3190, 321, 603, 976, 309, 411, 257, 2295, 6175, 457, 321, 393, 767, 808], "temperature": 0.0, "avg_logprob": -0.12208846678216774, "compression_ratio": 1.7258883248730965, "no_speech_prob": 1.5534964177277288e-06}, {"id": 914, "seek": 610532, "start": 6120.84, "end": 6126.82, "text": " up with a function where the probability of something being an woman's case let's say", "tokens": [493, 365, 257, 2445, 689, 264, 8482, 295, 746, 885, 364, 3059, 311, 1389, 718, 311, 584], "temperature": 0.0, "avg_logprob": -0.12208846678216774, "compression_ratio": 1.7258883248730965, "no_speech_prob": 1.5534964177277288e-06}, {"id": 915, "seek": 612682, "start": 6126.82, "end": 6136.36, "text": " an eight is equal to the pixels in the image multiplied by some set of weights and then", "tokens": [364, 3180, 307, 2681, 281, 264, 18668, 294, 264, 3256, 17207, 538, 512, 992, 295, 17443, 293, 550], "temperature": 0.0, "avg_logprob": -0.10227318415566096, "compression_ratio": 1.6751592356687899, "no_speech_prob": 5.368742677092087e-07}, {"id": 916, "seek": 612682, "start": 6136.36, "end": 6146.96, "text": " we sum them up right so then anywhere where our the image we're looking at you know as", "tokens": [321, 2408, 552, 493, 558, 370, 550, 4992, 689, 527, 264, 3256, 321, 434, 1237, 412, 291, 458, 382], "temperature": 0.0, "avg_logprob": -0.10227318415566096, "compression_ratio": 1.6751592356687899, "no_speech_prob": 5.368742677092087e-07}, {"id": 917, "seek": 612682, "start": 6146.96, "end": 6152.719999999999, "text": " pixels where there are high weights it's going to end up with a high probability so here", "tokens": [18668, 689, 456, 366, 1090, 17443, 309, 311, 516, 281, 917, 493, 365, 257, 1090, 8482, 370, 510], "temperature": 0.0, "avg_logprob": -0.10227318415566096, "compression_ratio": 1.6751592356687899, "no_speech_prob": 5.368742677092087e-07}, {"id": 918, "seek": 615272, "start": 6152.72, "end": 6159.96, "text": " x is the image that we're interested in and we're just going to represent it as a vector", "tokens": [2031, 307, 264, 3256, 300, 321, 434, 3102, 294, 293, 321, 434, 445, 516, 281, 2906, 309, 382, 257, 8062], "temperature": 0.0, "avg_logprob": -0.09755204380422398, "compression_ratio": 1.7105263157894737, "no_speech_prob": 9.276355399379099e-07}, {"id": 919, "seek": 615272, "start": 6159.96, "end": 6167.360000000001, "text": " so let's just have all the rows stacked up end to end into a single long line so we're", "tokens": [370, 718, 311, 445, 362, 439, 264, 13241, 28867, 493, 917, 281, 917, 666, 257, 2167, 938, 1622, 370, 321, 434], "temperature": 0.0, "avg_logprob": -0.09755204380422398, "compression_ratio": 1.7105263157894737, "no_speech_prob": 9.276355399379099e-07}, {"id": 920, "seek": 615272, "start": 6167.360000000001, "end": 6173.64, "text": " going to use an approach where we're going to start with a vector w so a vector is a", "tokens": [516, 281, 764, 364, 3109, 689, 321, 434, 516, 281, 722, 365, 257, 8062, 261, 370, 257, 8062, 307, 257], "temperature": 0.0, "avg_logprob": -0.09755204380422398, "compression_ratio": 1.7105263157894737, "no_speech_prob": 9.276355399379099e-07}, {"id": 921, "seek": 617364, "start": 6173.64, "end": 6183.12, "text": " rank one tensor okay we're going to start with a vector w that's going to contain random", "tokens": [6181, 472, 40863, 1392, 321, 434, 516, 281, 722, 365, 257, 8062, 261, 300, 311, 516, 281, 5304, 4974], "temperature": 0.0, "avg_logprob": -0.12425961802082677, "compression_ratio": 1.5393258426966292, "no_speech_prob": 5.896412176298327e-07}, {"id": 922, "seek": 617364, "start": 6183.12, "end": 6188.08, "text": " weights random parameters depending on whether you use the Arthur Samuel version of the terminology", "tokens": [17443, 4974, 9834, 5413, 322, 1968, 291, 764, 264, 19624, 23036, 3037, 295, 264, 27575], "temperature": 0.0, "avg_logprob": -0.12425961802082677, "compression_ratio": 1.5393258426966292, "no_speech_prob": 5.896412176298327e-07}, {"id": 923, "seek": 617364, "start": 6188.08, "end": 6197.38, "text": " or not and so we'll then predict whether a number appears to be a three or a seven by", "tokens": [420, 406, 293, 370, 321, 603, 550, 6069, 1968, 257, 1230, 7038, 281, 312, 257, 1045, 420, 257, 3407, 538], "temperature": 0.0, "avg_logprob": -0.12425961802082677, "compression_ratio": 1.5393258426966292, "no_speech_prob": 5.896412176298327e-07}, {"id": 924, "seek": 619738, "start": 6197.38, "end": 6207.32, "text": " using this tiny little function and then we will figure out how good the model is so we", "tokens": [1228, 341, 5870, 707, 2445, 293, 550, 321, 486, 2573, 484, 577, 665, 264, 2316, 307, 370, 321], "temperature": 0.0, "avg_logprob": -0.08542886147132286, "compression_ratio": 1.78125, "no_speech_prob": 4.664448738367355e-07}, {"id": 925, "seek": 619738, "start": 6207.32, "end": 6215.0, "text": " will calculate like how accurate it is or something like that yeah this is the loss", "tokens": [486, 8873, 411, 577, 8559, 309, 307, 420, 746, 411, 300, 1338, 341, 307, 264, 4470], "temperature": 0.0, "avg_logprob": -0.08542886147132286, "compression_ratio": 1.78125, "no_speech_prob": 4.664448738367355e-07}, {"id": 926, "seek": 619738, "start": 6215.0, "end": 6218.56, "text": " and then the key step is we're then going to calculate the gradient now the gradient", "tokens": [293, 550, 264, 2141, 1823, 307, 321, 434, 550, 516, 281, 8873, 264, 16235, 586, 264, 16235], "temperature": 0.0, "avg_logprob": -0.08542886147132286, "compression_ratio": 1.78125, "no_speech_prob": 4.664448738367355e-07}, {"id": 927, "seek": 619738, "start": 6218.56, "end": 6224.08, "text": " is something that measures for each weight if I made it a little bit bigger would the", "tokens": [307, 746, 300, 8000, 337, 1184, 3364, 498, 286, 1027, 309, 257, 707, 857, 3801, 576, 264], "temperature": 0.0, "avg_logprob": -0.08542886147132286, "compression_ratio": 1.78125, "no_speech_prob": 4.664448738367355e-07}, {"id": 928, "seek": 622408, "start": 6224.08, "end": 6230.0, "text": " loss get better or worse if I made it a little bit smaller would the loss get better or worse", "tokens": [4470, 483, 1101, 420, 5324, 498, 286, 1027, 309, 257, 707, 857, 4356, 576, 264, 4470, 483, 1101, 420, 5324], "temperature": 0.0, "avg_logprob": -0.0828241330605966, "compression_ratio": 2.157142857142857, "no_speech_prob": 4.181183612672612e-07}, {"id": 929, "seek": 622408, "start": 6230.0, "end": 6233.96, "text": " and so if we do that for every weight we can decide for every weight whether we should", "tokens": [293, 370, 498, 321, 360, 300, 337, 633, 3364, 321, 393, 4536, 337, 633, 3364, 1968, 321, 820], "temperature": 0.0, "avg_logprob": -0.0828241330605966, "compression_ratio": 2.157142857142857, "no_speech_prob": 4.181183612672612e-07}, {"id": 930, "seek": 622408, "start": 6233.96, "end": 6240.4, "text": " make that weight a bit bigger or a bit smaller so that's called the gradient right so once", "tokens": [652, 300, 3364, 257, 857, 3801, 420, 257, 857, 4356, 370, 300, 311, 1219, 264, 16235, 558, 370, 1564], "temperature": 0.0, "avg_logprob": -0.0828241330605966, "compression_ratio": 2.157142857142857, "no_speech_prob": 4.181183612672612e-07}, {"id": 931, "seek": 622408, "start": 6240.4, "end": 6249.08, "text": " we have the gradient we then step is the word we use a step we change all the weights up", "tokens": [321, 362, 264, 16235, 321, 550, 1823, 307, 264, 1349, 321, 764, 257, 1823, 321, 1319, 439, 264, 17443, 493], "temperature": 0.0, "avg_logprob": -0.0828241330605966, "compression_ratio": 2.157142857142857, "no_speech_prob": 4.181183612672612e-07}, {"id": 932, "seek": 622408, "start": 6249.08, "end": 6252.72, "text": " a little bit for the ones where the gradient we should said we should make them a bit higher", "tokens": [257, 707, 857, 337, 264, 2306, 689, 264, 16235, 321, 820, 848, 321, 820, 652, 552, 257, 857, 2946], "temperature": 0.0, "avg_logprob": -0.0828241330605966, "compression_ratio": 2.157142857142857, "no_speech_prob": 4.181183612672612e-07}, {"id": 933, "seek": 625272, "start": 6252.72, "end": 6258.04, "text": " and down a little bit for all the ones where the gradient said they should be a bit lower", "tokens": [293, 760, 257, 707, 857, 337, 439, 264, 2306, 689, 264, 16235, 848, 436, 820, 312, 257, 857, 3126], "temperature": 0.0, "avg_logprob": -0.08671781493396294, "compression_ratio": 1.7738693467336684, "no_speech_prob": 5.122890911479772e-07}, {"id": 934, "seek": 625272, "start": 6258.04, "end": 6263.64, "text": " so now it should be a tiny bit better and then we go back to step two and calculate", "tokens": [370, 586, 309, 820, 312, 257, 5870, 857, 1101, 293, 550, 321, 352, 646, 281, 1823, 732, 293, 8873], "temperature": 0.0, "avg_logprob": -0.08671781493396294, "compression_ratio": 1.7738693467336684, "no_speech_prob": 5.122890911479772e-07}, {"id": 935, "seek": 625272, "start": 6263.64, "end": 6271.56, "text": " a new set of predictions using this formula calculate the gradient again set the weights", "tokens": [257, 777, 992, 295, 21264, 1228, 341, 8513, 8873, 264, 16235, 797, 992, 264, 17443], "temperature": 0.0, "avg_logprob": -0.08671781493396294, "compression_ratio": 1.7738693467336684, "no_speech_prob": 5.122890911479772e-07}, {"id": 936, "seek": 625272, "start": 6271.56, "end": 6275.4800000000005, "text": " keep doing that so this is basically the flow chart and then at some point when we're sick", "tokens": [1066, 884, 300, 370, 341, 307, 1936, 264, 3095, 6927, 293, 550, 412, 512, 935, 562, 321, 434, 4998], "temperature": 0.0, "avg_logprob": -0.08671781493396294, "compression_ratio": 1.7738693467336684, "no_speech_prob": 5.122890911479772e-07}, {"id": 937, "seek": 627548, "start": 6275.48, "end": 6285.28, "text": " of waiting or when the loss gets good enough we'll stop so these seven steps one two three", "tokens": [295, 3806, 420, 562, 264, 4470, 2170, 665, 1547, 321, 603, 1590, 370, 613, 3407, 4439, 472, 732, 1045], "temperature": 0.0, "avg_logprob": -0.1012136278481319, "compression_ratio": 1.6923076923076923, "no_speech_prob": 8.851558277456206e-07}, {"id": 938, "seek": 627548, "start": 6285.28, "end": 6294.16, "text": " four five six seven these seven steps are the key to training all deep learning models", "tokens": [1451, 1732, 2309, 3407, 613, 3407, 4439, 366, 264, 2141, 281, 3097, 439, 2452, 2539, 5245], "temperature": 0.0, "avg_logprob": -0.1012136278481319, "compression_ratio": 1.6923076923076923, "no_speech_prob": 8.851558277456206e-07}, {"id": 939, "seek": 627548, "start": 6294.16, "end": 6298.16, "text": " this technique is called stochastic gradient descent well it's called gradient descent", "tokens": [341, 6532, 307, 1219, 342, 8997, 2750, 16235, 23475, 731, 309, 311, 1219, 16235, 23475], "temperature": 0.0, "avg_logprob": -0.1012136278481319, "compression_ratio": 1.6923076923076923, "no_speech_prob": 8.851558277456206e-07}, {"id": 940, "seek": 629816, "start": 6298.16, "end": 6305.9, "text": " we'll see the stochastic bit very soon and for each of these seven steps there's lots", "tokens": [321, 603, 536, 264, 342, 8997, 2750, 857, 588, 2321, 293, 337, 1184, 295, 613, 3407, 4439, 456, 311, 3195], "temperature": 0.0, "avg_logprob": -0.11921262180103975, "compression_ratio": 1.7587939698492463, "no_speech_prob": 1.1365616501279874e-06}, {"id": 941, "seek": 629816, "start": 6305.9, "end": 6312.08, "text": " of choices around exactly how to do it right we've just kind of hand waved a lot like what", "tokens": [295, 7994, 926, 2293, 577, 281, 360, 309, 558, 321, 600, 445, 733, 295, 1011, 261, 12865, 257, 688, 411, 437], "temperature": 0.0, "avg_logprob": -0.11921262180103975, "compression_ratio": 1.7587939698492463, "no_speech_prob": 1.1365616501279874e-06}, {"id": 942, "seek": 629816, "start": 6312.08, "end": 6316.099999999999, "text": " kind of random initialization and how do you calculate the gradient and exactly what step", "tokens": [733, 295, 4974, 5883, 2144, 293, 577, 360, 291, 8873, 264, 16235, 293, 2293, 437, 1823], "temperature": 0.0, "avg_logprob": -0.11921262180103975, "compression_ratio": 1.7587939698492463, "no_speech_prob": 1.1365616501279874e-06}, {"id": 943, "seek": 629816, "start": 6316.099999999999, "end": 6320.08, "text": " do you take based on the gradient and how do you decide when to stop blah blah blah", "tokens": [360, 291, 747, 2361, 322, 264, 16235, 293, 577, 360, 291, 4536, 562, 281, 1590, 12288, 12288, 12288], "temperature": 0.0, "avg_logprob": -0.11921262180103975, "compression_ratio": 1.7587939698492463, "no_speech_prob": 1.1365616501279874e-06}, {"id": 944, "seek": 632008, "start": 6320.08, "end": 6330.04, "text": " blah so in this in this course we're going to be like learning about you know these steps", "tokens": [12288, 370, 294, 341, 294, 341, 1164, 321, 434, 516, 281, 312, 411, 2539, 466, 291, 458, 613, 4439], "temperature": 0.0, "avg_logprob": -0.08185051001754462, "compression_ratio": 1.908296943231441, "no_speech_prob": 2.6016123229055665e-06}, {"id": 945, "seek": 632008, "start": 6330.04, "end": 6333.48, "text": " you know that's kind of part one you know the other big part is like well what's the", "tokens": [291, 458, 300, 311, 733, 295, 644, 472, 291, 458, 264, 661, 955, 644, 307, 411, 731, 437, 311, 264], "temperature": 0.0, "avg_logprob": -0.08185051001754462, "compression_ratio": 1.908296943231441, "no_speech_prob": 2.6016123229055665e-06}, {"id": 946, "seek": 632008, "start": 6333.48, "end": 6337.68, "text": " actual function neural network so how do we train the thing and what is the thing that", "tokens": [3539, 2445, 18161, 3209, 370, 577, 360, 321, 3847, 264, 551, 293, 437, 307, 264, 551, 300], "temperature": 0.0, "avg_logprob": -0.08185051001754462, "compression_ratio": 1.908296943231441, "no_speech_prob": 2.6016123229055665e-06}, {"id": 947, "seek": 632008, "start": 6337.68, "end": 6343.92, "text": " we train so we initialize parameters with random values we need some function that's", "tokens": [321, 3847, 370, 321, 5883, 1125, 9834, 365, 4974, 4190, 321, 643, 512, 2445, 300, 311], "temperature": 0.0, "avg_logprob": -0.08185051001754462, "compression_ratio": 1.908296943231441, "no_speech_prob": 2.6016123229055665e-06}, {"id": 948, "seek": 632008, "start": 6343.92, "end": 6349.32, "text": " going to be the loss function that will return a number that's small if the performance of", "tokens": [516, 281, 312, 264, 4470, 2445, 300, 486, 2736, 257, 1230, 300, 311, 1359, 498, 264, 3389, 295], "temperature": 0.0, "avg_logprob": -0.08185051001754462, "compression_ratio": 1.908296943231441, "no_speech_prob": 2.6016123229055665e-06}, {"id": 949, "seek": 634932, "start": 6349.32, "end": 6354.679999999999, "text": " the model is good it's some way to figure out whether the weight should be increased", "tokens": [264, 2316, 307, 665, 309, 311, 512, 636, 281, 2573, 484, 1968, 264, 3364, 820, 312, 6505], "temperature": 0.0, "avg_logprob": -0.11806023257902298, "compression_ratio": 1.5925925925925926, "no_speech_prob": 5.989266469441645e-07}, {"id": 950, "seek": 634932, "start": 6354.679999999999, "end": 6361.639999999999, "text": " a bit or decreased a bit and then we need to decide like when to stop which would have", "tokens": [257, 857, 420, 24436, 257, 857, 293, 550, 321, 643, 281, 4536, 411, 562, 281, 1590, 597, 576, 362], "temperature": 0.0, "avg_logprob": -0.11806023257902298, "compression_ratio": 1.5925925925925926, "no_speech_prob": 5.989266469441645e-07}, {"id": 951, "seek": 634932, "start": 6361.639999999999, "end": 6371.0, "text": " say let's just do a certain number of epochs so let's like go even simpler right we're", "tokens": [584, 718, 311, 445, 360, 257, 1629, 1230, 295, 30992, 28346, 370, 718, 311, 411, 352, 754, 18587, 558, 321, 434], "temperature": 0.0, "avg_logprob": -0.11806023257902298, "compression_ratio": 1.5925925925925926, "no_speech_prob": 5.989266469441645e-07}, {"id": 952, "seek": 634932, "start": 6371.0, "end": 6375.759999999999, "text": " not even going to do MNIST we're going to start with this function x squared okay and", "tokens": [406, 754, 516, 281, 360, 376, 45, 19756, 321, 434, 516, 281, 722, 365, 341, 2445, 2031, 8889, 1392, 293], "temperature": 0.0, "avg_logprob": -0.11806023257902298, "compression_ratio": 1.5925925925925926, "no_speech_prob": 5.989266469441645e-07}, {"id": 953, "seek": 637576, "start": 6375.76, "end": 6380.84, "text": " in faster.ai we've created a tiny little thing called plot function that plots a function", "tokens": [294, 4663, 13, 1301, 321, 600, 2942, 257, 5870, 707, 551, 1219, 7542, 2445, 300, 28609, 257, 2445], "temperature": 0.0, "avg_logprob": -0.10752221439661605, "compression_ratio": 2.0057471264367814, "no_speech_prob": 1.3081754559607361e-06}, {"id": 954, "seek": 637576, "start": 6380.84, "end": 6391.400000000001, "text": " all right so there's our function f and what we're going to do is we're going to try to", "tokens": [439, 558, 370, 456, 311, 527, 2445, 283, 293, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 853, 281], "temperature": 0.0, "avg_logprob": -0.10752221439661605, "compression_ratio": 2.0057471264367814, "no_speech_prob": 1.3081754559607361e-06}, {"id": 955, "seek": 637576, "start": 6391.400000000001, "end": 6397.360000000001, "text": " find this is our loss function so we're going to try and find the bottom point right so", "tokens": [915, 341, 307, 527, 4470, 2445, 370, 321, 434, 516, 281, 853, 293, 915, 264, 2767, 935, 558, 370], "temperature": 0.0, "avg_logprob": -0.10752221439661605, "compression_ratio": 2.0057471264367814, "no_speech_prob": 1.3081754559607361e-06}, {"id": 956, "seek": 637576, "start": 6397.360000000001, "end": 6402.64, "text": " we're going to try and figure out what is the x value which is at the bottom so our", "tokens": [321, 434, 516, 281, 853, 293, 2573, 484, 437, 307, 264, 2031, 2158, 597, 307, 412, 264, 2767, 370, 527], "temperature": 0.0, "avg_logprob": -0.10752221439661605, "compression_ratio": 2.0057471264367814, "no_speech_prob": 1.3081754559607361e-06}, {"id": 957, "seek": 640264, "start": 6402.64, "end": 6410.280000000001, "text": " seven-step procedure requires us to start out by initializing so we need to pick some", "tokens": [3407, 12, 16792, 10747, 7029, 505, 281, 722, 484, 538, 5883, 3319, 370, 321, 643, 281, 1888, 512], "temperature": 0.0, "avg_logprob": -0.11936881624419114, "compression_ratio": 1.7009803921568627, "no_speech_prob": 1.76034109244938e-06}, {"id": 958, "seek": 640264, "start": 6410.280000000001, "end": 6415.12, "text": " value right so the value we pick with this say oh let's just randomly pick minus one", "tokens": [2158, 558, 370, 264, 2158, 321, 1888, 365, 341, 584, 1954, 718, 311, 445, 16979, 1888, 3175, 472], "temperature": 0.0, "avg_logprob": -0.11936881624419114, "compression_ratio": 1.7009803921568627, "no_speech_prob": 1.76034109244938e-06}, {"id": 959, "seek": 640264, "start": 6415.12, "end": 6422.92, "text": " and a half great so now we need to know if I increase x a bit does my remember this is", "tokens": [293, 257, 1922, 869, 370, 586, 321, 643, 281, 458, 498, 286, 3488, 2031, 257, 857, 775, 452, 1604, 341, 307], "temperature": 0.0, "avg_logprob": -0.11936881624419114, "compression_ratio": 1.7009803921568627, "no_speech_prob": 1.76034109244938e-06}, {"id": 960, "seek": 640264, "start": 6422.92, "end": 6429.400000000001, "text": " my loss does my loss get a bit better remember better is smaller or a bit worse so we can", "tokens": [452, 4470, 775, 452, 4470, 483, 257, 857, 1101, 1604, 1101, 307, 4356, 420, 257, 857, 5324, 370, 321, 393], "temperature": 0.0, "avg_logprob": -0.11936881624419114, "compression_ratio": 1.7009803921568627, "no_speech_prob": 1.76034109244938e-06}, {"id": 961, "seek": 642940, "start": 6429.4, "end": 6434.28, "text": " do that easily enough we can just try a slightly higher x and a slightly lower x and see what", "tokens": [360, 300, 3612, 1547, 321, 393, 445, 853, 257, 4748, 2946, 2031, 293, 257, 4748, 3126, 2031, 293, 536, 437], "temperature": 0.0, "avg_logprob": -0.07304200460744459, "compression_ratio": 1.8556701030927836, "no_speech_prob": 3.05902176478412e-07}, {"id": 962, "seek": 642940, "start": 6434.28, "end": 6440.5599999999995, "text": " happens right and you can see it's just the slope right the slope at this point tells", "tokens": [2314, 558, 293, 291, 393, 536, 309, 311, 445, 264, 13525, 558, 264, 13525, 412, 341, 935, 5112], "temperature": 0.0, "avg_logprob": -0.07304200460744459, "compression_ratio": 1.8556701030927836, "no_speech_prob": 3.05902176478412e-07}, {"id": 963, "seek": 642940, "start": 6440.5599999999995, "end": 6447.96, "text": " you that if I increase x by a bit then my loss will decrease because that is the slope", "tokens": [291, 300, 498, 286, 3488, 2031, 538, 257, 857, 550, 452, 4470, 486, 11514, 570, 300, 307, 264, 13525], "temperature": 0.0, "avg_logprob": -0.07304200460744459, "compression_ratio": 1.8556701030927836, "no_speech_prob": 3.05902176478412e-07}, {"id": 964, "seek": 642940, "start": 6447.96, "end": 6457.679999999999, "text": " at this point so if we change our our weight our parameter just a little bit in the direction", "tokens": [412, 341, 935, 370, 498, 321, 1319, 527, 527, 3364, 527, 13075, 445, 257, 707, 857, 294, 264, 3513], "temperature": 0.0, "avg_logprob": -0.07304200460744459, "compression_ratio": 1.8556701030927836, "no_speech_prob": 3.05902176478412e-07}, {"id": 965, "seek": 645768, "start": 6457.68, "end": 6463.320000000001, "text": " of the slope right so here is the direction of the slope and so here's the new value at", "tokens": [295, 264, 13525, 558, 370, 510, 307, 264, 3513, 295, 264, 13525, 293, 370, 510, 311, 264, 777, 2158, 412], "temperature": 0.0, "avg_logprob": -0.08955268426374956, "compression_ratio": 1.7738693467336684, "no_speech_prob": 5.285508564156771e-07}, {"id": 966, "seek": 645768, "start": 6463.320000000001, "end": 6469.08, "text": " that point right and then do it again and then do it again eventually we'll get to the", "tokens": [300, 935, 558, 293, 550, 360, 309, 797, 293, 550, 360, 309, 797, 4728, 321, 603, 483, 281, 264], "temperature": 0.0, "avg_logprob": -0.08955268426374956, "compression_ratio": 1.7738693467336684, "no_speech_prob": 5.285508564156771e-07}, {"id": 967, "seek": 645768, "start": 6469.08, "end": 6476.9400000000005, "text": " bottom of this curve right so this idea goes all the way back to Isaac Newton at the very", "tokens": [2767, 295, 341, 7605, 558, 370, 341, 1558, 1709, 439, 264, 636, 646, 281, 22505, 19541, 412, 264, 588], "temperature": 0.0, "avg_logprob": -0.08955268426374956, "compression_ratio": 1.7738693467336684, "no_speech_prob": 5.285508564156771e-07}, {"id": 968, "seek": 645768, "start": 6476.9400000000005, "end": 6484.04, "text": " least and this basic idea is called Newton's method so a key thing we need to be able to", "tokens": [1935, 293, 341, 3875, 1558, 307, 1219, 19541, 311, 3170, 370, 257, 2141, 551, 321, 643, 281, 312, 1075, 281], "temperature": 0.0, "avg_logprob": -0.08955268426374956, "compression_ratio": 1.7738693467336684, "no_speech_prob": 5.285508564156771e-07}, {"id": 969, "seek": 648404, "start": 6484.04, "end": 6495.04, "text": " do is to calculate this slope and the bad news is do that we need calculus at least", "tokens": [360, 307, 281, 8873, 341, 13525, 293, 264, 1578, 2583, 307, 360, 300, 321, 643, 33400, 412, 1935], "temperature": 0.0, "avg_logprob": -0.0909491777420044, "compression_ratio": 1.82010582010582, "no_speech_prob": 8.990953688226e-07}, {"id": 970, "seek": 648404, "start": 6495.04, "end": 6499.0, "text": " that's bad news for me because I've never been a fan of calculus we have to calculate", "tokens": [300, 311, 1578, 2583, 337, 385, 570, 286, 600, 1128, 668, 257, 3429, 295, 33400, 321, 362, 281, 8873], "temperature": 0.0, "avg_logprob": -0.0909491777420044, "compression_ratio": 1.82010582010582, "no_speech_prob": 8.990953688226e-07}, {"id": 971, "seek": 648404, "start": 6499.0, "end": 6506.28, "text": " the derivative here's the good news though maybe you spent ages in school learning how", "tokens": [264, 13760, 510, 311, 264, 665, 2583, 1673, 1310, 291, 4418, 12357, 294, 1395, 2539, 577], "temperature": 0.0, "avg_logprob": -0.0909491777420044, "compression_ratio": 1.82010582010582, "no_speech_prob": 8.990953688226e-07}, {"id": 972, "seek": 648404, "start": 6506.28, "end": 6511.96, "text": " to calculate derivatives you don't have to anymore the computer does it for you and the", "tokens": [281, 8873, 33733, 291, 500, 380, 362, 281, 3602, 264, 3820, 775, 309, 337, 291, 293, 264], "temperature": 0.0, "avg_logprob": -0.0909491777420044, "compression_ratio": 1.82010582010582, "no_speech_prob": 8.990953688226e-07}, {"id": 973, "seek": 651196, "start": 6511.96, "end": 6518.28, "text": " computer does it fast it uses all of those methods that you learned at school and it", "tokens": [3820, 775, 309, 2370, 309, 4960, 439, 295, 729, 7150, 300, 291, 3264, 412, 1395, 293, 309], "temperature": 0.0, "avg_logprob": -0.07462695001185625, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.786730182284373e-07}, {"id": 974, "seek": 651196, "start": 6518.28, "end": 6524.84, "text": " had a whole lot more like clever tricks for speeding them up and it just does it all automatically", "tokens": [632, 257, 1379, 688, 544, 411, 13494, 11733, 337, 35593, 552, 493, 293, 309, 445, 775, 309, 439, 6772], "temperature": 0.0, "avg_logprob": -0.07462695001185625, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.786730182284373e-07}, {"id": 975, "seek": 651196, "start": 6524.84, "end": 6529.76, "text": " so for example it knows I don't know if you remember this from high school that the derivative", "tokens": [370, 337, 1365, 309, 3255, 286, 500, 380, 458, 498, 291, 1604, 341, 490, 1090, 1395, 300, 264, 13760], "temperature": 0.0, "avg_logprob": -0.07462695001185625, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.786730182284373e-07}, {"id": 976, "seek": 651196, "start": 6529.76, "end": 6536.04, "text": " of x squared is 2x it's just something it knows it's part of its kind of bag of tricks", "tokens": [295, 2031, 8889, 307, 568, 87, 309, 311, 445, 746, 309, 3255, 309, 311, 644, 295, 1080, 733, 295, 3411, 295, 11733], "temperature": 0.0, "avg_logprob": -0.07462695001185625, "compression_ratio": 1.6666666666666667, "no_speech_prob": 6.786730182284373e-07}, {"id": 977, "seek": 653604, "start": 6536.04, "end": 6544.6, "text": " right so so PyTorch knows that PyTorch has an engine built in that can take derivatives", "tokens": [558, 370, 370, 9953, 51, 284, 339, 3255, 300, 9953, 51, 284, 339, 575, 364, 2848, 3094, 294, 300, 393, 747, 33733], "temperature": 0.0, "avg_logprob": -0.13351581345743208, "compression_ratio": 1.5406976744186047, "no_speech_prob": 1.1610737971068374e-07}, {"id": 978, "seek": 653604, "start": 6544.6, "end": 6554.96, "text": " and find the gradient of functions so to do that we start with a tensor let's say and", "tokens": [293, 915, 264, 16235, 295, 6828, 370, 281, 360, 300, 321, 722, 365, 257, 40863, 718, 311, 584, 293], "temperature": 0.0, "avg_logprob": -0.13351581345743208, "compression_ratio": 1.5406976744186047, "no_speech_prob": 1.1610737971068374e-07}, {"id": 979, "seek": 653604, "start": 6554.96, "end": 6560.8, "text": " in this case we're going to modify this tensor with this special method called requiresGrad", "tokens": [294, 341, 1389, 321, 434, 516, 281, 16927, 341, 40863, 365, 341, 2121, 3170, 1219, 7029, 38, 6206], "temperature": 0.0, "avg_logprob": -0.13351581345743208, "compression_ratio": 1.5406976744186047, "no_speech_prob": 1.1610737971068374e-07}, {"id": 980, "seek": 656080, "start": 6560.8, "end": 6567.84, "text": " and what this does is it tells PyTorch that anytime I do a calculation with this xt it", "tokens": [293, 437, 341, 775, 307, 309, 5112, 9953, 51, 284, 339, 300, 13038, 286, 360, 257, 17108, 365, 341, 220, 734, 309], "temperature": 0.0, "avg_logprob": -0.13543925124607728, "compression_ratio": 1.791044776119403, "no_speech_prob": 7.453762123077468e-07}, {"id": 981, "seek": 656080, "start": 6567.84, "end": 6572.8, "text": " should remember what calculation it does so that I can take the derivative later.", "tokens": [820, 1604, 437, 17108, 309, 775, 370, 300, 286, 393, 747, 264, 13760, 1780, 13], "temperature": 0.0, "avg_logprob": -0.13543925124607728, "compression_ratio": 1.791044776119403, "no_speech_prob": 7.453762123077468e-07}, {"id": 982, "seek": 656080, "start": 6572.8, "end": 6580.400000000001, "text": " You see the underscore at the end an underscore at the end of a method in PyTorch means that", "tokens": [509, 536, 264, 37556, 412, 264, 917, 364, 37556, 412, 264, 917, 295, 257, 3170, 294, 9953, 51, 284, 339, 1355, 300], "temperature": 0.0, "avg_logprob": -0.13543925124607728, "compression_ratio": 1.791044776119403, "no_speech_prob": 7.453762123077468e-07}, {"id": 983, "seek": 656080, "start": 6580.400000000001, "end": 6588.4800000000005, "text": " this is called an in-place operation it actually modifies this so requiresGrad underscore modifies", "tokens": [341, 307, 1219, 364, 294, 12, 6742, 6916, 309, 767, 1072, 11221, 341, 370, 7029, 38, 6206, 37556, 1072, 11221], "temperature": 0.0, "avg_logprob": -0.13543925124607728, "compression_ratio": 1.791044776119403, "no_speech_prob": 7.453762123077468e-07}, {"id": 984, "seek": 658848, "start": 6588.48, "end": 6593.839999999999, "text": " this tensor to tell PyTorch that we want to be calculating gradients on it so that means", "tokens": [341, 40863, 281, 980, 9953, 51, 284, 339, 300, 321, 528, 281, 312, 28258, 2771, 2448, 322, 309, 370, 300, 1355], "temperature": 0.0, "avg_logprob": -0.1185691081560575, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.2289166306800325e-06}, {"id": 985, "seek": 658848, "start": 6593.839999999999, "end": 6598.4, "text": " it's just going to have to keep track of all of the computations we do so that it can calculate", "tokens": [309, 311, 445, 516, 281, 362, 281, 1066, 2837, 295, 439, 295, 264, 2807, 763, 321, 360, 370, 300, 309, 393, 8873], "temperature": 0.0, "avg_logprob": -0.1185691081560575, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.2289166306800325e-06}, {"id": 986, "seek": 658848, "start": 6598.4, "end": 6603.4, "text": " the derivative later.", "tokens": [264, 13760, 1780, 13], "temperature": 0.0, "avg_logprob": -0.1185691081560575, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.2289166306800325e-06}, {"id": 987, "seek": 658848, "start": 6603.4, "end": 6611.7, "text": " Okay so we've got the number 3 and let's say we then call f on it remember f is just squaring", "tokens": [1033, 370, 321, 600, 658, 264, 1230, 805, 293, 718, 311, 584, 321, 550, 818, 283, 322, 309, 1604, 283, 307, 445, 2339, 1921], "temperature": 0.0, "avg_logprob": -0.1185691081560575, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.2289166306800325e-06}, {"id": 988, "seek": 658848, "start": 6611.7, "end": 6618.4, "text": " it so 3 squared is 9 but the value is not just 9 it's 9 accompanied with a grad of", "tokens": [309, 370, 805, 8889, 307, 1722, 457, 264, 2158, 307, 406, 445, 1722, 309, 311, 1722, 24202, 365, 257, 2771, 295], "temperature": 0.0, "avg_logprob": -0.1185691081560575, "compression_ratio": 1.6724890829694323, "no_speech_prob": 1.2289166306800325e-06}, {"id": 989, "seek": 661840, "start": 6618.4, "end": 6623.96, "text": " grad function which is that it's it knows that a power operation has been taken so we", "tokens": [2771, 2445, 597, 307, 300, 309, 311, 309, 3255, 300, 257, 1347, 6916, 575, 668, 2726, 370, 321], "temperature": 0.0, "avg_logprob": -0.11835606892903645, "compression_ratio": 1.7044334975369457, "no_speech_prob": 6.375544785441889e-07}, {"id": 990, "seek": 661840, "start": 6623.96, "end": 6632.78, "text": " can now call a special method backward and backward which refers to back propagation", "tokens": [393, 586, 818, 257, 2121, 3170, 23897, 293, 23897, 597, 14942, 281, 646, 38377], "temperature": 0.0, "avg_logprob": -0.11835606892903645, "compression_ratio": 1.7044334975369457, "no_speech_prob": 6.375544785441889e-07}, {"id": 991, "seek": 661840, "start": 6632.78, "end": 6638.799999999999, "text": " which we'll learn about which basically means take the derivative and so once it does that", "tokens": [597, 321, 603, 1466, 466, 597, 1936, 1355, 747, 264, 13760, 293, 370, 1564, 309, 775, 300], "temperature": 0.0, "avg_logprob": -0.11835606892903645, "compression_ratio": 1.7044334975369457, "no_speech_prob": 6.375544785441889e-07}, {"id": 992, "seek": 661840, "start": 6638.799999999999, "end": 6646.32, "text": " we can now look inside xt because we said requiresGrad and find out its gradient and", "tokens": [321, 393, 586, 574, 1854, 220, 734, 570, 321, 848, 7029, 38, 6206, 293, 915, 484, 1080, 16235, 293], "temperature": 0.0, "avg_logprob": -0.11835606892903645, "compression_ratio": 1.7044334975369457, "no_speech_prob": 6.375544785441889e-07}, {"id": 993, "seek": 664632, "start": 6646.32, "end": 6656.24, "text": " remember the derivative of x squared is 2x in this case that was 3 2 times 3 is 6 right", "tokens": [1604, 264, 13760, 295, 2031, 8889, 307, 568, 87, 294, 341, 1389, 300, 390, 805, 568, 1413, 805, 307, 1386, 558], "temperature": 0.0, "avg_logprob": -0.11983111284781194, "compression_ratio": 1.543859649122807, "no_speech_prob": 5.805000000691507e-07}, {"id": 994, "seek": 664632, "start": 6656.24, "end": 6662.799999999999, "text": " so we didn't have to figure out the derivative we just call backward and then get the grad", "tokens": [370, 321, 994, 380, 362, 281, 2573, 484, 264, 13760, 321, 445, 818, 23897, 293, 550, 483, 264, 2771], "temperature": 0.0, "avg_logprob": -0.11983111284781194, "compression_ratio": 1.543859649122807, "no_speech_prob": 5.805000000691507e-07}, {"id": 995, "seek": 664632, "start": 6662.799999999999, "end": 6672.44, "text": " attribute to get the derivative so that's how easy it is to do calculus in PyTorch so", "tokens": [19667, 281, 483, 264, 13760, 370, 300, 311, 577, 1858, 309, 307, 281, 360, 33400, 294, 9953, 51, 284, 339, 370], "temperature": 0.0, "avg_logprob": -0.11983111284781194, "compression_ratio": 1.543859649122807, "no_speech_prob": 5.805000000691507e-07}, {"id": 996, "seek": 667244, "start": 6672.44, "end": 6679.679999999999, "text": " what you need to know about calculus is not how to take a derivative but what it means", "tokens": [437, 291, 643, 281, 458, 466, 33400, 307, 406, 577, 281, 747, 257, 13760, 457, 437, 309, 1355], "temperature": 0.0, "avg_logprob": -0.12947936230395213, "compression_ratio": 1.6210526315789473, "no_speech_prob": 4.888299258709594e-07}, {"id": 997, "seek": 667244, "start": 6679.679999999999, "end": 6688.0, "text": " and what it means is it's a slope at some point.", "tokens": [293, 437, 309, 1355, 307, 309, 311, 257, 13525, 412, 512, 935, 13], "temperature": 0.0, "avg_logprob": -0.12947936230395213, "compression_ratio": 1.6210526315789473, "no_speech_prob": 4.888299258709594e-07}, {"id": 998, "seek": 667244, "start": 6688.0, "end": 6693.799999999999, "text": " Now here's something interesting let's not just take 3 but let's take a rank 1 tensor", "tokens": [823, 510, 311, 746, 1880, 718, 311, 406, 445, 747, 805, 457, 718, 311, 747, 257, 6181, 502, 40863], "temperature": 0.0, "avg_logprob": -0.12947936230395213, "compression_ratio": 1.6210526315789473, "no_speech_prob": 4.888299258709594e-07}, {"id": 999, "seek": 667244, "start": 6693.799999999999, "end": 6701.919999999999, "text": " also known as a vector 3 4 10 and let's add some to our f function so it's going to go", "tokens": [611, 2570, 382, 257, 8062, 805, 1017, 1266, 293, 718, 311, 909, 512, 281, 527, 283, 2445, 370, 309, 311, 516, 281, 352], "temperature": 0.0, "avg_logprob": -0.12947936230395213, "compression_ratio": 1.6210526315789473, "no_speech_prob": 4.888299258709594e-07}, {"id": 1000, "seek": 670192, "start": 6701.92, "end": 6712.8, "text": " x squared dot sum and now we can take f of this vector get back 125 and then we can say", "tokens": [2031, 8889, 5893, 2408, 293, 586, 321, 393, 747, 283, 295, 341, 8062, 483, 646, 25276, 293, 550, 321, 393, 584], "temperature": 0.0, "avg_logprob": -0.09723536173502605, "compression_ratio": 1.5221238938053097, "no_speech_prob": 3.576358551526937e-07}, {"id": 1001, "seek": 670192, "start": 6712.8, "end": 6726.24, "text": " backward and grad and look 2x 2x 2x right so we can calculate this is this is vector", "tokens": [23897, 293, 2771, 293, 574, 568, 87, 568, 87, 568, 87, 558, 370, 321, 393, 8873, 341, 307, 341, 307, 8062], "temperature": 0.0, "avg_logprob": -0.09723536173502605, "compression_ratio": 1.5221238938053097, "no_speech_prob": 3.576358551526937e-07}, {"id": 1002, "seek": 672624, "start": 6726.24, "end": 6734.5199999999995, "text": " calculus right we're getting the gradient for every element of a vector with the same", "tokens": [33400, 558, 321, 434, 1242, 264, 16235, 337, 633, 4478, 295, 257, 8062, 365, 264, 912], "temperature": 0.0, "avg_logprob": -0.1485695992746661, "compression_ratio": 1.569767441860465, "no_speech_prob": 5.539167773349618e-07}, {"id": 1003, "seek": 672624, "start": 6734.5199999999995, "end": 6743.099999999999, "text": " two lines of code so that's kind of all you need to know about calculus right and if this", "tokens": [732, 3876, 295, 3089, 370, 300, 311, 733, 295, 439, 291, 643, 281, 458, 466, 33400, 558, 293, 498, 341], "temperature": 0.0, "avg_logprob": -0.1485695992746661, "compression_ratio": 1.569767441860465, "no_speech_prob": 5.539167773349618e-07}, {"id": 1004, "seek": 672624, "start": 6743.099999999999, "end": 6752.48, "text": " is if this idea that a derivative for gradient is a slope is unfamiliar check out Khan Academy", "tokens": [307, 498, 341, 1558, 300, 257, 13760, 337, 16235, 307, 257, 13525, 307, 29415, 1520, 484, 18136, 11735], "temperature": 0.0, "avg_logprob": -0.1485695992746661, "compression_ratio": 1.569767441860465, "no_speech_prob": 5.539167773349618e-07}, {"id": 1005, "seek": 675248, "start": 6752.48, "end": 6756.24, "text": " they have some great introductory calculus and don't forget you can skip all the bits", "tokens": [436, 362, 512, 869, 39048, 33400, 293, 500, 380, 2870, 291, 393, 10023, 439, 264, 9239], "temperature": 0.0, "avg_logprob": -0.05563342571258545, "compression_ratio": 1.8333333333333333, "no_speech_prob": 3.8070120922384376e-07}, {"id": 1006, "seek": 675248, "start": 6756.24, "end": 6762.24, "text": " where they teach you how to calculate the gradients yourself.", "tokens": [689, 436, 2924, 291, 577, 281, 8873, 264, 2771, 2448, 1803, 13], "temperature": 0.0, "avg_logprob": -0.05563342571258545, "compression_ratio": 1.8333333333333333, "no_speech_prob": 3.8070120922384376e-07}, {"id": 1007, "seek": 675248, "start": 6762.24, "end": 6767.12, "text": " So now that we know how to calculate the gradient that is the slope of the function that tells", "tokens": [407, 586, 300, 321, 458, 577, 281, 8873, 264, 16235, 300, 307, 264, 13525, 295, 264, 2445, 300, 5112], "temperature": 0.0, "avg_logprob": -0.05563342571258545, "compression_ratio": 1.8333333333333333, "no_speech_prob": 3.8070120922384376e-07}, {"id": 1008, "seek": 675248, "start": 6767.12, "end": 6775.28, "text": " us if we change our input a little bit how will our output change correspondingly that's", "tokens": [505, 498, 321, 1319, 527, 4846, 257, 707, 857, 577, 486, 527, 5598, 1319, 11760, 356, 300, 311], "temperature": 0.0, "avg_logprob": -0.05563342571258545, "compression_ratio": 1.8333333333333333, "no_speech_prob": 3.8070120922384376e-07}, {"id": 1009, "seek": 675248, "start": 6775.28, "end": 6781.44, "text": " what a slope is right and so that tells us that every one of our parameters if we know", "tokens": [437, 257, 13525, 307, 558, 293, 370, 300, 5112, 505, 300, 633, 472, 295, 527, 9834, 498, 321, 458], "temperature": 0.0, "avg_logprob": -0.05563342571258545, "compression_ratio": 1.8333333333333333, "no_speech_prob": 3.8070120922384376e-07}, {"id": 1010, "seek": 678144, "start": 6781.44, "end": 6786.639999999999, "text": " their gradients then we know if we change that parameter up a bit or down a bit how", "tokens": [641, 2771, 2448, 550, 321, 458, 498, 321, 1319, 300, 13075, 493, 257, 857, 420, 760, 257, 857, 577], "temperature": 0.0, "avg_logprob": -0.0881995522832296, "compression_ratio": 1.7738693467336684, "no_speech_prob": 7.112431035238842e-07}, {"id": 1011, "seek": 678144, "start": 6786.639999999999, "end": 6792.839999999999, "text": " will it change our loss so therefore we then know how to change our parameters so what", "tokens": [486, 309, 1319, 527, 4470, 370, 4412, 321, 550, 458, 577, 281, 1319, 527, 9834, 370, 437], "temperature": 0.0, "avg_logprob": -0.0881995522832296, "compression_ratio": 1.7738693467336684, "no_speech_prob": 7.112431035238842e-07}, {"id": 1012, "seek": 678144, "start": 6792.839999999999, "end": 6802.679999999999, "text": " we do is let's say all of our weights are called W we just subtract off them the gradients", "tokens": [321, 360, 307, 718, 311, 584, 439, 295, 527, 17443, 366, 1219, 343, 321, 445, 16390, 766, 552, 264, 2771, 2448], "temperature": 0.0, "avg_logprob": -0.0881995522832296, "compression_ratio": 1.7738693467336684, "no_speech_prob": 7.112431035238842e-07}, {"id": 1013, "seek": 678144, "start": 6802.679999999999, "end": 6809.5599999999995, "text": " multiplied by some small number and that small number is often a number between about point", "tokens": [17207, 538, 512, 1359, 1230, 293, 300, 1359, 1230, 307, 2049, 257, 1230, 1296, 466, 935], "temperature": 0.0, "avg_logprob": -0.0881995522832296, "compression_ratio": 1.7738693467336684, "no_speech_prob": 7.112431035238842e-07}, {"id": 1014, "seek": 680956, "start": 6809.56, "end": 6818.68, "text": " 001 and point one and it's called the learning rate right and this here is the essence of", "tokens": [7143, 16, 293, 935, 472, 293, 309, 311, 1219, 264, 2539, 3314, 558, 293, 341, 510, 307, 264, 12801, 295], "temperature": 0.0, "avg_logprob": -0.1384396945728975, "compression_ratio": 2.0335195530726256, "no_speech_prob": 5.122893753650715e-07}, {"id": 1015, "seek": 680956, "start": 6818.68, "end": 6826.0, "text": " gradient descent so if you pick a learning rate that's very small then you take the slope", "tokens": [16235, 23475, 370, 498, 291, 1888, 257, 2539, 3314, 300, 311, 588, 1359, 550, 291, 747, 264, 13525], "temperature": 0.0, "avg_logprob": -0.1384396945728975, "compression_ratio": 2.0335195530726256, "no_speech_prob": 5.122893753650715e-07}, {"id": 1016, "seek": 680956, "start": 6826.0, "end": 6830.4800000000005, "text": " and you take a really small step in that direction and another small step another small step", "tokens": [293, 291, 747, 257, 534, 1359, 1823, 294, 300, 3513, 293, 1071, 1359, 1823, 1071, 1359, 1823], "temperature": 0.0, "avg_logprob": -0.1384396945728975, "compression_ratio": 2.0335195530726256, "no_speech_prob": 5.122893753650715e-07}, {"id": 1017, "seek": 680956, "start": 6830.4800000000005, "end": 6835.6, "text": " another small steps and it's going to take forever to get to the end if you pick a learning", "tokens": [1071, 1359, 4439, 293, 309, 311, 516, 281, 747, 5680, 281, 483, 281, 264, 917, 498, 291, 1888, 257, 2539], "temperature": 0.0, "avg_logprob": -0.1384396945728975, "compression_ratio": 2.0335195530726256, "no_speech_prob": 5.122893753650715e-07}, {"id": 1018, "seek": 683560, "start": 6835.6, "end": 6843.04, "text": " rate that's too big you jump way too far each time and again it's going to take forever", "tokens": [3314, 300, 311, 886, 955, 291, 3012, 636, 886, 1400, 1184, 565, 293, 797, 309, 311, 516, 281, 747, 5680], "temperature": 0.0, "avg_logprob": -0.10077402668614541, "compression_ratio": 1.8736842105263158, "no_speech_prob": 2.2380281450296025e-07}, {"id": 1019, "seek": 683560, "start": 6843.04, "end": 6848.96, "text": " and in fact in this case sorry this case we're assuming we're starting here and it's actually", "tokens": [293, 294, 1186, 294, 341, 1389, 2597, 341, 1389, 321, 434, 11926, 321, 434, 2891, 510, 293, 309, 311, 767], "temperature": 0.0, "avg_logprob": -0.10077402668614541, "compression_ratio": 1.8736842105263158, "no_speech_prob": 2.2380281450296025e-07}, {"id": 1020, "seek": 683560, "start": 6848.96, "end": 6856.280000000001, "text": " it's so big that it got worse and worse or here's one where we start here and it's like", "tokens": [309, 311, 370, 955, 300, 309, 658, 5324, 293, 5324, 420, 510, 311, 472, 689, 321, 722, 510, 293, 309, 311, 411], "temperature": 0.0, "avg_logprob": -0.10077402668614541, "compression_ratio": 1.8736842105263158, "no_speech_prob": 2.2380281450296025e-07}, {"id": 1021, "seek": 683560, "start": 6856.280000000001, "end": 6860.8, "text": " it's not so big it gets worse and worse but it just takes a long time to bounce in and", "tokens": [309, 311, 406, 370, 955, 309, 2170, 5324, 293, 5324, 457, 309, 445, 2516, 257, 938, 565, 281, 15894, 294, 293], "temperature": 0.0, "avg_logprob": -0.10077402668614541, "compression_ratio": 1.8736842105263158, "no_speech_prob": 2.2380281450296025e-07}, {"id": 1022, "seek": 686080, "start": 6860.8, "end": 6867.76, "text": " out right so picking a good learning rate is really important both to making sure that", "tokens": [484, 558, 370, 8867, 257, 665, 2539, 3314, 307, 534, 1021, 1293, 281, 1455, 988, 300], "temperature": 0.0, "avg_logprob": -0.10904366471046625, "compression_ratio": 1.7211538461538463, "no_speech_prob": 1.1430730495476382e-07}, {"id": 1023, "seek": 686080, "start": 6867.76, "end": 6872.8, "text": " it's even possible to solve the problem and that it's possible to solve it in a reasonable", "tokens": [309, 311, 754, 1944, 281, 5039, 264, 1154, 293, 300, 309, 311, 1944, 281, 5039, 309, 294, 257, 10585], "temperature": 0.0, "avg_logprob": -0.10904366471046625, "compression_ratio": 1.7211538461538463, "no_speech_prob": 1.1430730495476382e-07}, {"id": 1024, "seek": 686080, "start": 6872.8, "end": 6877.52, "text": " amount of time so we'll be learning about picking how to pick learning rates in this", "tokens": [2372, 295, 565, 370, 321, 603, 312, 2539, 466, 8867, 577, 281, 1888, 2539, 6846, 294, 341], "temperature": 0.0, "avg_logprob": -0.10904366471046625, "compression_ratio": 1.7211538461538463, "no_speech_prob": 1.1430730495476382e-07}, {"id": 1025, "seek": 686080, "start": 6877.52, "end": 6882.28, "text": " course.", "tokens": [1164, 13], "temperature": 0.0, "avg_logprob": -0.10904366471046625, "compression_ratio": 1.7211538461538463, "no_speech_prob": 1.1430730495476382e-07}, {"id": 1026, "seek": 686080, "start": 6882.28, "end": 6890.08, "text": " So let's try this let's try using gradient descent I said SGD that's not quite accurate", "tokens": [407, 718, 311, 853, 341, 718, 311, 853, 1228, 16235, 23475, 286, 848, 34520, 35, 300, 311, 406, 1596, 8559], "temperature": 0.0, "avg_logprob": -0.10904366471046625, "compression_ratio": 1.7211538461538463, "no_speech_prob": 1.1430730495476382e-07}, {"id": 1027, "seek": 689008, "start": 6890.08, "end": 6895.76, "text": " it's just going to be gradient descent to solve an actual problem so the problem we're", "tokens": [309, 311, 445, 516, 281, 312, 16235, 23475, 281, 5039, 364, 3539, 1154, 370, 264, 1154, 321, 434], "temperature": 0.0, "avg_logprob": -0.07722914984466833, "compression_ratio": 2.0, "no_speech_prob": 1.5056975826155394e-06}, {"id": 1028, "seek": 689008, "start": 6895.76, "end": 6902.88, "text": " going to solve is let's imagine you were watching a roller coaster go over the top of a hump", "tokens": [516, 281, 5039, 307, 718, 311, 3811, 291, 645, 1976, 257, 15948, 28442, 352, 670, 264, 1192, 295, 257, 47093], "temperature": 0.0, "avg_logprob": -0.07722914984466833, "compression_ratio": 2.0, "no_speech_prob": 1.5056975826155394e-06}, {"id": 1029, "seek": 689008, "start": 6902.88, "end": 6910.2, "text": " right so as it comes out of the previous hill it's going super fast and it's going up the", "tokens": [558, 370, 382, 309, 1487, 484, 295, 264, 3894, 10997, 309, 311, 516, 1687, 2370, 293, 309, 311, 516, 493, 264], "temperature": 0.0, "avg_logprob": -0.07722914984466833, "compression_ratio": 2.0, "no_speech_prob": 1.5056975826155394e-06}, {"id": 1030, "seek": 689008, "start": 6910.2, "end": 6915.6, "text": " hill and it's going slower and slower and slower until it gets to the top of the hump", "tokens": [10997, 293, 309, 311, 516, 14009, 293, 14009, 293, 14009, 1826, 309, 2170, 281, 264, 1192, 295, 264, 47093], "temperature": 0.0, "avg_logprob": -0.07722914984466833, "compression_ratio": 2.0, "no_speech_prob": 1.5056975826155394e-06}, {"id": 1031, "seek": 689008, "start": 6915.6, "end": 6919.14, "text": " and then it goes down the other side it goes faster and faster and faster so if you like", "tokens": [293, 550, 309, 1709, 760, 264, 661, 1252, 309, 1709, 4663, 293, 4663, 293, 4663, 370, 498, 291, 411], "temperature": 0.0, "avg_logprob": -0.07722914984466833, "compression_ratio": 2.0, "no_speech_prob": 1.5056975826155394e-06}, {"id": 1032, "seek": 691914, "start": 6919.14, "end": 6924.360000000001, "text": " had a stopwatch or whatever or a sudden watch some kind of speedometer and you are measuring", "tokens": [632, 257, 1590, 15219, 420, 2035, 420, 257, 3990, 1159, 512, 733, 295, 3073, 13606, 293, 291, 366, 13389], "temperature": 0.0, "avg_logprob": -0.09240292113961525, "compression_ratio": 1.752, "no_speech_prob": 4.520934453466907e-07}, {"id": 1033, "seek": 691914, "start": 6924.360000000001, "end": 6930.64, "text": " it just by hand at kind of equal time points you might end up with something that looks", "tokens": [309, 445, 538, 1011, 412, 733, 295, 2681, 565, 2793, 291, 1062, 917, 493, 365, 746, 300, 1542], "temperature": 0.0, "avg_logprob": -0.09240292113961525, "compression_ratio": 1.752, "no_speech_prob": 4.520934453466907e-07}, {"id": 1034, "seek": 691914, "start": 6930.64, "end": 6937.12, "text": " a bit like this right and so the way I did this was I just grabbed a range just grabs", "tokens": [257, 857, 411, 341, 558, 293, 370, 264, 636, 286, 630, 341, 390, 286, 445, 18607, 257, 3613, 445, 30028], "temperature": 0.0, "avg_logprob": -0.09240292113961525, "compression_ratio": 1.752, "no_speech_prob": 4.520934453466907e-07}, {"id": 1035, "seek": 691914, "start": 6937.12, "end": 6941.56, "text": " the numbers from not up to but not including 20 right so these are the time periods at", "tokens": [264, 3547, 490, 406, 493, 281, 457, 406, 3009, 945, 558, 370, 613, 366, 264, 565, 13804, 412], "temperature": 0.0, "avg_logprob": -0.09240292113961525, "compression_ratio": 1.752, "no_speech_prob": 4.520934453466907e-07}, {"id": 1036, "seek": 691914, "start": 6941.56, "end": 6948.360000000001, "text": " which I'm taking my speed measurement and then I've just got some quadratic function", "tokens": [597, 286, 478, 1940, 452, 3073, 13160, 293, 550, 286, 600, 445, 658, 512, 37262, 2445], "temperature": 0.0, "avg_logprob": -0.09240292113961525, "compression_ratio": 1.752, "no_speech_prob": 4.520934453466907e-07}, {"id": 1037, "seek": 694836, "start": 6948.36, "end": 6953.759999999999, "text": " here and multiply it by 3 and then square it and then add one whatever right and then", "tokens": [510, 293, 12972, 309, 538, 805, 293, 550, 3732, 309, 293, 550, 909, 472, 2035, 558, 293, 550], "temperature": 0.0, "avg_logprob": -0.1131686730818315, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.1544592553036637e-06}, {"id": 1038, "seek": 694836, "start": 6953.759999999999, "end": 6962.48, "text": " I also actually sorry I take my time minus 9.5 square it times 0.75 add one and then", "tokens": [286, 611, 767, 2597, 286, 747, 452, 565, 3175, 1722, 13, 20, 3732, 309, 1413, 1958, 13, 11901, 909, 472, 293, 550], "temperature": 0.0, "avg_logprob": -0.1131686730818315, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.1544592553036637e-06}, {"id": 1039, "seek": 694836, "start": 6962.48, "end": 6968.12, "text": " I add a random number to that or add a random number to every observation so I end up with", "tokens": [286, 909, 257, 4974, 1230, 281, 300, 420, 909, 257, 4974, 1230, 281, 633, 14816, 370, 286, 917, 493, 365], "temperature": 0.0, "avg_logprob": -0.1131686730818315, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.1544592553036637e-06}, {"id": 1040, "seek": 694836, "start": 6968.12, "end": 6972.28, "text": " a quadratic function which is a bit bumpy so this is kind of like what it might look", "tokens": [257, 37262, 2445, 597, 307, 257, 857, 49400, 370, 341, 307, 733, 295, 411, 437, 309, 1062, 574], "temperature": 0.0, "avg_logprob": -0.1131686730818315, "compression_ratio": 1.7128712871287128, "no_speech_prob": 1.1544592553036637e-06}, {"id": 1041, "seek": 697228, "start": 6972.28, "end": 6981.16, "text": " like in real life because my speedometer kind of testing is not perfect.", "tokens": [411, 294, 957, 993, 570, 452, 3073, 13606, 733, 295, 4997, 307, 406, 2176, 13], "temperature": 0.0, "avg_logprob": -0.1652886620883284, "compression_ratio": 1.5870967741935484, "no_speech_prob": 7.93448748481751e-07}, {"id": 1042, "seek": 697228, "start": 6981.16, "end": 6987.4, "text": " Alright so we want to create a function that estimates at any time what is the speed of", "tokens": [2798, 370, 321, 528, 281, 1884, 257, 2445, 300, 20561, 412, 604, 565, 437, 307, 264, 3073, 295], "temperature": 0.0, "avg_logprob": -0.1652886620883284, "compression_ratio": 1.5870967741935484, "no_speech_prob": 7.93448748481751e-07}, {"id": 1043, "seek": 697228, "start": 6987.4, "end": 6995.4, "text": " the roller coaster so we start by guessing what function it might be so we guess that", "tokens": [264, 15948, 28442, 370, 321, 722, 538, 17939, 437, 2445, 309, 1062, 312, 370, 321, 2041, 300], "temperature": 0.0, "avg_logprob": -0.1652886620883284, "compression_ratio": 1.5870967741935484, "no_speech_prob": 7.93448748481751e-07}, {"id": 1044, "seek": 699540, "start": 6995.4, "end": 7002.08, "text": " it's a function a times time squared plus b times time plus c you might remember from", "tokens": [309, 311, 257, 2445, 257, 1413, 565, 8889, 1804, 272, 1413, 565, 1804, 269, 291, 1062, 1604, 490], "temperature": 0.0, "avg_logprob": -0.08810034820011683, "compression_ratio": 1.859375, "no_speech_prob": 6.475943905570603e-07}, {"id": 1045, "seek": 699540, "start": 7002.08, "end": 7010.28, "text": " school is quarter quadratic so let's create a function right and so let's create it using", "tokens": [1395, 307, 6555, 37262, 370, 718, 311, 1884, 257, 2445, 558, 293, 370, 718, 311, 1884, 309, 1228], "temperature": 0.0, "avg_logprob": -0.08810034820011683, "compression_ratio": 1.859375, "no_speech_prob": 6.475943905570603e-07}, {"id": 1046, "seek": 699540, "start": 7010.28, "end": 7013.639999999999, "text": " kind of the Arthur Samuels technique the machine learning technique this function is going", "tokens": [733, 295, 264, 19624, 4832, 84, 1625, 6532, 264, 3479, 2539, 6532, 341, 2445, 307, 516], "temperature": 0.0, "avg_logprob": -0.08810034820011683, "compression_ratio": 1.859375, "no_speech_prob": 6.475943905570603e-07}, {"id": 1047, "seek": 699540, "start": 7013.639999999999, "end": 7019.5599999999995, "text": " to take two things it's going to take an input which in this case is a time and it's going", "tokens": [281, 747, 732, 721, 309, 311, 516, 281, 747, 364, 4846, 597, 294, 341, 1389, 307, 257, 565, 293, 309, 311, 516], "temperature": 0.0, "avg_logprob": -0.08810034820011683, "compression_ratio": 1.859375, "no_speech_prob": 6.475943905570603e-07}, {"id": 1048, "seek": 701956, "start": 7019.56, "end": 7027.080000000001, "text": " to take some parameters and the parameters are a b and c so in in Python you can split", "tokens": [281, 747, 512, 9834, 293, 264, 9834, 366, 257, 272, 293, 269, 370, 294, 294, 15329, 291, 393, 7472], "temperature": 0.0, "avg_logprob": -0.12647465453750786, "compression_ratio": 1.74, "no_speech_prob": 5.453288736134709e-07}, {"id": 1049, "seek": 701956, "start": 7027.080000000001, "end": 7033.120000000001, "text": " out a list or a collection into its components like so and then here's that function.", "tokens": [484, 257, 1329, 420, 257, 5765, 666, 1080, 6677, 411, 370, 293, 550, 510, 311, 300, 2445, 13], "temperature": 0.0, "avg_logprob": -0.12647465453750786, "compression_ratio": 1.74, "no_speech_prob": 5.453288736134709e-07}, {"id": 1050, "seek": 701956, "start": 7033.120000000001, "end": 7038.320000000001, "text": " So we're not just trying to find any function in the world we're just trying to find some", "tokens": [407, 321, 434, 406, 445, 1382, 281, 915, 604, 2445, 294, 264, 1002, 321, 434, 445, 1382, 281, 915, 512], "temperature": 0.0, "avg_logprob": -0.12647465453750786, "compression_ratio": 1.74, "no_speech_prob": 5.453288736134709e-07}, {"id": 1051, "seek": 701956, "start": 7038.320000000001, "end": 7045.84, "text": " function which is a quadratic by finding an a in a b and a c so the the Arthur Samuel", "tokens": [2445, 597, 307, 257, 37262, 538, 5006, 364, 257, 294, 257, 272, 293, 257, 269, 370, 264, 264, 19624, 23036], "temperature": 0.0, "avg_logprob": -0.12647465453750786, "compression_ratio": 1.74, "no_speech_prob": 5.453288736134709e-07}, {"id": 1052, "seek": 704584, "start": 7045.84, "end": 7051.8, "text": " technique for doing this is to next up come up with a loss function come up with a measurement", "tokens": [6532, 337, 884, 341, 307, 281, 958, 493, 808, 493, 365, 257, 4470, 2445, 808, 493, 365, 257, 13160], "temperature": 0.0, "avg_logprob": -0.08730809267829447, "compression_ratio": 1.7772511848341233, "no_speech_prob": 3.4465695080143632e-06}, {"id": 1053, "seek": 704584, "start": 7051.8, "end": 7060.12, "text": " of how good we are so if we've got some predictions that come out of our function and the targets", "tokens": [295, 577, 665, 321, 366, 370, 498, 321, 600, 658, 512, 21264, 300, 808, 484, 295, 527, 2445, 293, 264, 12911], "temperature": 0.0, "avg_logprob": -0.08730809267829447, "compression_ratio": 1.7772511848341233, "no_speech_prob": 3.4465695080143632e-06}, {"id": 1054, "seek": 704584, "start": 7060.12, "end": 7068.64, "text": " which are these you know actual values then we could just do the mean squared error okay", "tokens": [597, 366, 613, 291, 458, 3539, 4190, 550, 321, 727, 445, 360, 264, 914, 8889, 6713, 1392], "temperature": 0.0, "avg_logprob": -0.08730809267829447, "compression_ratio": 1.7772511848341233, "no_speech_prob": 3.4465695080143632e-06}, {"id": 1055, "seek": 704584, "start": 7068.64, "end": 7075.08, "text": " so here's that mean squared error we saw before the difference squared and then take the mean", "tokens": [370, 510, 311, 300, 914, 8889, 6713, 321, 1866, 949, 264, 2649, 8889, 293, 550, 747, 264, 914], "temperature": 0.0, "avg_logprob": -0.08730809267829447, "compression_ratio": 1.7772511848341233, "no_speech_prob": 3.4465695080143632e-06}, {"id": 1056, "seek": 707508, "start": 7075.08, "end": 7080.68, "text": " so now we need to go through our seven-step process we want to come up with a set of three", "tokens": [370, 586, 321, 643, 281, 352, 807, 527, 3407, 12, 16792, 1399, 321, 528, 281, 808, 493, 365, 257, 992, 295, 1045], "temperature": 0.0, "avg_logprob": -0.07784276130871895, "compression_ratio": 1.7294117647058824, "no_speech_prob": 1.4593737205359503e-06}, {"id": 1057, "seek": 707508, "start": 7080.68, "end": 7086.36, "text": " parameters a b and c which are as good as possible the step one is to initialize a b", "tokens": [9834, 257, 272, 293, 269, 597, 366, 382, 665, 382, 1944, 264, 1823, 472, 307, 281, 5883, 1125, 257, 272], "temperature": 0.0, "avg_logprob": -0.07784276130871895, "compression_ratio": 1.7294117647058824, "no_speech_prob": 1.4593737205359503e-06}, {"id": 1058, "seek": 707508, "start": 7086.36, "end": 7092.04, "text": " and c to random values so this is how you get random values three of them in PyTorch", "tokens": [293, 269, 281, 4974, 4190, 370, 341, 307, 577, 291, 483, 4974, 4190, 1045, 295, 552, 294, 9953, 51, 284, 339], "temperature": 0.0, "avg_logprob": -0.07784276130871895, "compression_ratio": 1.7294117647058824, "no_speech_prob": 1.4593737205359503e-06}, {"id": 1059, "seek": 707508, "start": 7092.04, "end": 7095.48, "text": " and remember we're going to be adjusting them so we have to tell PyTorch that we want the", "tokens": [293, 1604, 321, 434, 516, 281, 312, 23559, 552, 370, 321, 362, 281, 980, 9953, 51, 284, 339, 300, 321, 528, 264], "temperature": 0.0, "avg_logprob": -0.07784276130871895, "compression_ratio": 1.7294117647058824, "no_speech_prob": 1.4593737205359503e-06}, {"id": 1060, "seek": 707508, "start": 7095.48, "end": 7103.64, "text": " gradients I'm just going to save those away so I can check them later and then I calculate", "tokens": [2771, 2448, 286, 478, 445, 516, 281, 3155, 729, 1314, 370, 286, 393, 1520, 552, 1780, 293, 550, 286, 8873], "temperature": 0.0, "avg_logprob": -0.07784276130871895, "compression_ratio": 1.7294117647058824, "no_speech_prob": 1.4593737205359503e-06}, {"id": 1061, "seek": 710364, "start": 7103.64, "end": 7113.8, "text": " the predictions using that function f which was this and then let's create a little function", "tokens": [264, 21264, 1228, 300, 2445, 283, 597, 390, 341, 293, 550, 718, 311, 1884, 257, 707, 2445], "temperature": 0.0, "avg_logprob": -0.11349097887674968, "compression_ratio": 1.7707006369426752, "no_speech_prob": 7.571143214590847e-07}, {"id": 1062, "seek": 710364, "start": 7113.8, "end": 7120.12, "text": " which just plots how good at this point our predictions so here is a function that prints", "tokens": [597, 445, 28609, 577, 665, 412, 341, 935, 527, 21264, 370, 510, 307, 257, 2445, 300, 22305], "temperature": 0.0, "avg_logprob": -0.11349097887674968, "compression_ratio": 1.7707006369426752, "no_speech_prob": 7.571143214590847e-07}, {"id": 1063, "seek": 710364, "start": 7120.12, "end": 7128.88, "text": " in red our predictions and in blue our targets so that looks pretty terrible so let's calculate", "tokens": [294, 2182, 527, 21264, 293, 294, 3344, 527, 12911, 370, 300, 1542, 1238, 6237, 370, 718, 311, 8873], "temperature": 0.0, "avg_logprob": -0.11349097887674968, "compression_ratio": 1.7707006369426752, "no_speech_prob": 7.571143214590847e-07}, {"id": 1064, "seek": 712888, "start": 7128.88, "end": 7137.16, "text": " the loss using that MSE function we wrote okay so now we want to improve this so calculate", "tokens": [264, 4470, 1228, 300, 376, 5879, 2445, 321, 4114, 1392, 370, 586, 321, 528, 281, 3470, 341, 370, 8873], "temperature": 0.0, "avg_logprob": -0.08093059808015823, "compression_ratio": 1.5549132947976878, "no_speech_prob": 1.7159557330614916e-07}, {"id": 1065, "seek": 712888, "start": 7137.16, "end": 7142.68, "text": " the gradients using the two steps we saw call backward and then get grad and this says that", "tokens": [264, 2771, 2448, 1228, 264, 732, 4439, 321, 1866, 818, 23897, 293, 550, 483, 2771, 293, 341, 1619, 300], "temperature": 0.0, "avg_logprob": -0.08093059808015823, "compression_ratio": 1.5549132947976878, "no_speech_prob": 1.7159557330614916e-07}, {"id": 1066, "seek": 712888, "start": 7142.68, "end": 7152.64, "text": " each of our parameters has a gradient that's negative let's pick a learning rate of 10", "tokens": [1184, 295, 527, 9834, 575, 257, 16235, 300, 311, 3671, 718, 311, 1888, 257, 2539, 3314, 295, 1266], "temperature": 0.0, "avg_logprob": -0.08093059808015823, "compression_ratio": 1.5549132947976878, "no_speech_prob": 1.7159557330614916e-07}, {"id": 1067, "seek": 715264, "start": 7152.64, "end": 7160.72, "text": " to the minus 5 so we multiply that by 10 to the minus 5 and step the weights and remember", "tokens": [281, 264, 3175, 1025, 370, 321, 12972, 300, 538, 1266, 281, 264, 3175, 1025, 293, 1823, 264, 17443, 293, 1604], "temperature": 0.0, "avg_logprob": -0.0983592310259419, "compression_ratio": 1.7533333333333334, "no_speech_prob": 8.315275294989988e-07}, {"id": 1068, "seek": 715264, "start": 7160.72, "end": 7168.68, "text": " step the weights means minus equals learning rate times the gradient there's a wonderful", "tokens": [1823, 264, 17443, 1355, 3175, 6915, 2539, 3314, 1413, 264, 16235, 456, 311, 257, 3715], "temperature": 0.0, "avg_logprob": -0.0983592310259419, "compression_ratio": 1.7533333333333334, "no_speech_prob": 8.315275294989988e-07}, {"id": 1069, "seek": 715264, "start": 7168.68, "end": 7174.64, "text": " trick here which I've called dot data the reason I've called dot data is dot data is", "tokens": [4282, 510, 597, 286, 600, 1219, 5893, 1412, 264, 1778, 286, 600, 1219, 5893, 1412, 307, 5893, 1412, 307], "temperature": 0.0, "avg_logprob": -0.0983592310259419, "compression_ratio": 1.7533333333333334, "no_speech_prob": 8.315275294989988e-07}, {"id": 1070, "seek": 717464, "start": 7174.64, "end": 7183.08, "text": " a special attribute in PyTorch which if you use it then the gradient is not calculated", "tokens": [257, 2121, 19667, 294, 9953, 51, 284, 339, 597, 498, 291, 764, 309, 550, 264, 16235, 307, 406, 15598], "temperature": 0.0, "avg_logprob": -0.0691084689404591, "compression_ratio": 1.87434554973822, "no_speech_prob": 4.2470276184758404e-07}, {"id": 1071, "seek": 717464, "start": 7183.08, "end": 7188.76, "text": " and we certainly wouldn't want the gradient to be calculated of the actual step we're", "tokens": [293, 321, 3297, 2759, 380, 528, 264, 16235, 281, 312, 15598, 295, 264, 3539, 1823, 321, 434], "temperature": 0.0, "avg_logprob": -0.0691084689404591, "compression_ratio": 1.87434554973822, "no_speech_prob": 4.2470276184758404e-07}, {"id": 1072, "seek": 717464, "start": 7188.76, "end": 7195.96, "text": " doing we only want the gradient to be calculated of our function f right so when we step the", "tokens": [884, 321, 787, 528, 264, 16235, 281, 312, 15598, 295, 527, 2445, 283, 558, 370, 562, 321, 1823, 264], "temperature": 0.0, "avg_logprob": -0.0691084689404591, "compression_ratio": 1.87434554973822, "no_speech_prob": 4.2470276184758404e-07}, {"id": 1073, "seek": 717464, "start": 7195.96, "end": 7203.38, "text": " weights we have to use this special dot data attribute after we do that delete the gradients", "tokens": [17443, 321, 362, 281, 764, 341, 2121, 5893, 1412, 19667, 934, 321, 360, 300, 12097, 264, 2771, 2448], "temperature": 0.0, "avg_logprob": -0.0691084689404591, "compression_ratio": 1.87434554973822, "no_speech_prob": 4.2470276184758404e-07}, {"id": 1074, "seek": 720338, "start": 7203.38, "end": 7213.28, "text": " that we already had and let's see if loss improved so the loss before was 25,800 now", "tokens": [300, 321, 1217, 632, 293, 718, 311, 536, 498, 4470, 9689, 370, 264, 4470, 949, 390, 3552, 11, 14423, 586], "temperature": 0.0, "avg_logprob": -0.0899062797204772, "compression_ratio": 1.4829545454545454, "no_speech_prob": 1.1015946483894368e-06}, {"id": 1075, "seek": 720338, "start": 7213.28, "end": 7223.08, "text": " it's 5,400 and the plot has gone from something that goes down to minus 300 oh to something", "tokens": [309, 311, 1025, 11, 13741, 293, 264, 7542, 575, 2780, 490, 746, 300, 1709, 760, 281, 3175, 6641, 1954, 281, 746], "temperature": 0.0, "avg_logprob": -0.0899062797204772, "compression_ratio": 1.4829545454545454, "no_speech_prob": 1.1015946483894368e-06}, {"id": 1076, "seek": 720338, "start": 7223.08, "end": 7228.66, "text": " that looks much better so let's do that a few times so I just grabbed those previous", "tokens": [300, 1542, 709, 1101, 370, 718, 311, 360, 300, 257, 1326, 1413, 370, 286, 445, 18607, 729, 3894], "temperature": 0.0, "avg_logprob": -0.0899062797204772, "compression_ratio": 1.4829545454545454, "no_speech_prob": 1.1015946483894368e-06}, {"id": 1077, "seek": 722866, "start": 7228.66, "end": 7234.8, "text": " lines of code and pasted them all into a single cell okay so preds loss backward data grad", "tokens": [3876, 295, 3089, 293, 1791, 292, 552, 439, 666, 257, 2167, 2815, 1392, 370, 3852, 82, 4470, 23897, 1412, 2771], "temperature": 0.0, "avg_logprob": -0.08354660914494441, "compression_ratio": 1.7727272727272727, "no_speech_prob": 4.0525452504880377e-07}, {"id": 1078, "seek": 722866, "start": 7234.8, "end": 7242.32, "text": " is none and then from time to time print the loss out and repeat that ten times and look", "tokens": [307, 6022, 293, 550, 490, 565, 281, 565, 4482, 264, 4470, 484, 293, 7149, 300, 2064, 1413, 293, 574], "temperature": 0.0, "avg_logprob": -0.08354660914494441, "compression_ratio": 1.7727272727272727, "no_speech_prob": 4.0525452504880377e-07}, {"id": 1079, "seek": 722866, "start": 7242.32, "end": 7252.96, "text": " getting better and better and so we can actually look at it getting better and better so this", "tokens": [1242, 1101, 293, 1101, 293, 370, 321, 393, 767, 574, 412, 309, 1242, 1101, 293, 1101, 370, 341], "temperature": 0.0, "avg_logprob": -0.08354660914494441, "compression_ratio": 1.7727272727272727, "no_speech_prob": 4.0525452504880377e-07}, {"id": 1080, "seek": 725296, "start": 7252.96, "end": 7261.84, "text": " is pretty cool right we have a technique this is the Arthur Samuel technique for finding", "tokens": [307, 1238, 1627, 558, 321, 362, 257, 6532, 341, 307, 264, 19624, 23036, 6532, 337, 5006], "temperature": 0.0, "avg_logprob": -0.07715522197254918, "compression_ratio": 1.5681818181818181, "no_speech_prob": 8.18635669475043e-07}, {"id": 1081, "seek": 725296, "start": 7261.84, "end": 7269.2, "text": " a set of parameters that continuously improves by getting feedback from the result of measuring", "tokens": [257, 992, 295, 9834, 300, 15684, 24771, 538, 1242, 5824, 490, 264, 1874, 295, 13389], "temperature": 0.0, "avg_logprob": -0.07715522197254918, "compression_ratio": 1.5681818181818181, "no_speech_prob": 8.18635669475043e-07}, {"id": 1082, "seek": 725296, "start": 7269.2, "end": 7278.36, "text": " some loss function so that was kind of the key step right this this is the gradient descent", "tokens": [512, 4470, 2445, 370, 300, 390, 733, 295, 264, 2141, 1823, 558, 341, 341, 307, 264, 16235, 23475], "temperature": 0.0, "avg_logprob": -0.07715522197254918, "compression_ratio": 1.5681818181818181, "no_speech_prob": 8.18635669475043e-07}, {"id": 1083, "seek": 727836, "start": 7278.36, "end": 7284.339999999999, "text": " method so you should make sure that you kind of go back and feel super comfortable with", "tokens": [3170, 370, 291, 820, 652, 988, 300, 291, 733, 295, 352, 646, 293, 841, 1687, 4619, 365], "temperature": 0.0, "avg_logprob": -0.08297523498535156, "compression_ratio": 1.8158995815899581, "no_speech_prob": 3.041589252461563e-06}, {"id": 1084, "seek": 727836, "start": 7284.339999999999, "end": 7288.599999999999, "text": " what's happened and you know if you're not feeling comfortable that that's fine right", "tokens": [437, 311, 2011, 293, 291, 458, 498, 291, 434, 406, 2633, 4619, 300, 300, 311, 2489, 558], "temperature": 0.0, "avg_logprob": -0.08297523498535156, "compression_ratio": 1.8158995815899581, "no_speech_prob": 3.041589252461563e-06}, {"id": 1085, "seek": 727836, "start": 7288.599999999999, "end": 7295.48, "text": " if it's been a while or if you've never done this kind of gradient descent before this", "tokens": [498, 309, 311, 668, 257, 1339, 420, 498, 291, 600, 1128, 1096, 341, 733, 295, 16235, 23475, 949, 341], "temperature": 0.0, "avg_logprob": -0.08297523498535156, "compression_ratio": 1.8158995815899581, "no_speech_prob": 3.041589252461563e-06}, {"id": 1086, "seek": 727836, "start": 7295.48, "end": 7300.88, "text": " might feel super unfamiliar so kind of try to find the first cell in this notebook where", "tokens": [1062, 841, 1687, 29415, 370, 733, 295, 853, 281, 915, 264, 700, 2815, 294, 341, 21060, 689], "temperature": 0.0, "avg_logprob": -0.08297523498535156, "compression_ratio": 1.8158995815899581, "no_speech_prob": 3.041589252461563e-06}, {"id": 1087, "seek": 727836, "start": 7300.88, "end": 7306.679999999999, "text": " you don't fully understand what it's doing and then like stop and figure it out like", "tokens": [291, 500, 380, 4498, 1223, 437, 309, 311, 884, 293, 550, 411, 1590, 293, 2573, 309, 484, 411], "temperature": 0.0, "avg_logprob": -0.08297523498535156, "compression_ratio": 1.8158995815899581, "no_speech_prob": 3.041589252461563e-06}, {"id": 1088, "seek": 730668, "start": 7306.68, "end": 7313.88, "text": " look at everything that's going on do some experiments do some reading until you understand", "tokens": [574, 412, 1203, 300, 311, 516, 322, 360, 512, 12050, 360, 512, 3760, 1826, 291, 1223], "temperature": 0.0, "avg_logprob": -0.10493030399084091, "compression_ratio": 1.5423728813559323, "no_speech_prob": 2.7852703965436376e-07}, {"id": 1089, "seek": 730668, "start": 7313.88, "end": 7326.4800000000005, "text": " that cell where you were stuck before you move forwards so let's now apply this to MNIST", "tokens": [300, 2815, 689, 291, 645, 5541, 949, 291, 1286, 30126, 370, 718, 311, 586, 3079, 341, 281, 376, 45, 19756], "temperature": 0.0, "avg_logprob": -0.10493030399084091, "compression_ratio": 1.5423728813559323, "no_speech_prob": 2.7852703965436376e-07}, {"id": 1090, "seek": 730668, "start": 7326.4800000000005, "end": 7333.280000000001, "text": " so for MNIST we want to use this exact technique and there's basically nothing extra we have", "tokens": [370, 337, 376, 45, 19756, 321, 528, 281, 764, 341, 1900, 6532, 293, 456, 311, 1936, 1825, 2857, 321, 362], "temperature": 0.0, "avg_logprob": -0.10493030399084091, "compression_ratio": 1.5423728813559323, "no_speech_prob": 2.7852703965436376e-07}, {"id": 1091, "seek": 733328, "start": 7333.28, "end": 7343.639999999999, "text": " to do except one thing we need a loss function and the metric that we've been using is the", "tokens": [281, 360, 3993, 472, 551, 321, 643, 257, 4470, 2445, 293, 264, 20678, 300, 321, 600, 668, 1228, 307, 264], "temperature": 0.0, "avg_logprob": -0.06231950578235444, "compression_ratio": 1.7047619047619047, "no_speech_prob": 7.571141509288282e-07}, {"id": 1092, "seek": 733328, "start": 7343.639999999999, "end": 7350.12, "text": " error rate or the accuracy it's like how often are we correct right and and that's the thing", "tokens": [6713, 3314, 420, 264, 14170, 309, 311, 411, 577, 2049, 366, 321, 3006, 558, 293, 293, 300, 311, 264, 551], "temperature": 0.0, "avg_logprob": -0.06231950578235444, "compression_ratio": 1.7047619047619047, "no_speech_prob": 7.571141509288282e-07}, {"id": 1093, "seek": 733328, "start": 7350.12, "end": 7356.759999999999, "text": " that we're actually trying to make good our metric but we've got a very serious problem", "tokens": [300, 321, 434, 767, 1382, 281, 652, 665, 527, 20678, 457, 321, 600, 658, 257, 588, 3156, 1154], "temperature": 0.0, "avg_logprob": -0.06231950578235444, "compression_ratio": 1.7047619047619047, "no_speech_prob": 7.571141509288282e-07}, {"id": 1094, "seek": 733328, "start": 7356.759999999999, "end": 7363.0, "text": " which is remember we need to calculate the gradient to figure out how we should change", "tokens": [597, 307, 1604, 321, 643, 281, 8873, 264, 16235, 281, 2573, 484, 577, 321, 820, 1319], "temperature": 0.0, "avg_logprob": -0.06231950578235444, "compression_ratio": 1.7047619047619047, "no_speech_prob": 7.571141509288282e-07}, {"id": 1095, "seek": 736300, "start": 7363.0, "end": 7368.08, "text": " our parameters and the gradient is the slope or the steepness which you might remember", "tokens": [527, 9834, 293, 264, 16235, 307, 264, 13525, 420, 264, 16841, 1287, 597, 291, 1062, 1604], "temperature": 0.0, "avg_logprob": -0.13766095724450536, "compression_ratio": 1.6990291262135921, "no_speech_prob": 1.5294094737328123e-06}, {"id": 1096, "seek": 736300, "start": 7368.08, "end": 7376.2, "text": " from school is defined as rise over run it's y new minus y old divided by x new minus x", "tokens": [490, 1395, 307, 7642, 382, 6272, 670, 1190, 309, 311, 288, 777, 3175, 288, 1331, 6666, 538, 2031, 777, 3175, 2031], "temperature": 0.0, "avg_logprob": -0.13766095724450536, "compression_ratio": 1.6990291262135921, "no_speech_prob": 1.5294094737328123e-06}, {"id": 1097, "seek": 736300, "start": 7376.2, "end": 7385.2, "text": " old so the gradients actually defined when x new is is very very close to x old meaning", "tokens": [1331, 370, 264, 2771, 2448, 767, 7642, 562, 2031, 777, 307, 307, 588, 588, 1998, 281, 2031, 1331, 3620], "temperature": 0.0, "avg_logprob": -0.13766095724450536, "compression_ratio": 1.6990291262135921, "no_speech_prob": 1.5294094737328123e-06}, {"id": 1098, "seek": 736300, "start": 7385.2, "end": 7392.88, "text": " their difference is very small but think about it accuracy if I change a parameter by a", "tokens": [641, 2649, 307, 588, 1359, 457, 519, 466, 309, 14170, 498, 286, 1319, 257, 13075, 538, 257], "temperature": 0.0, "avg_logprob": -0.13766095724450536, "compression_ratio": 1.6990291262135921, "no_speech_prob": 1.5294094737328123e-06}, {"id": 1099, "seek": 739288, "start": 7392.88, "end": 7399.4800000000005, "text": " tiny tiny tiny amount the accuracy might not change at all because there might not be any", "tokens": [5870, 5870, 5870, 2372, 264, 14170, 1062, 406, 1319, 412, 439, 570, 456, 1062, 406, 312, 604], "temperature": 0.0, "avg_logprob": -0.10907642140107997, "compression_ratio": 1.9052631578947368, "no_speech_prob": 3.689878838031291e-07}, {"id": 1100, "seek": 739288, "start": 7399.4800000000005, "end": 7406.24, "text": " three that we now predict as a seven or any seven that we now predict as a three because", "tokens": [1045, 300, 321, 586, 6069, 382, 257, 3407, 420, 604, 3407, 300, 321, 586, 6069, 382, 257, 1045, 570], "temperature": 0.0, "avg_logprob": -0.10907642140107997, "compression_ratio": 1.9052631578947368, "no_speech_prob": 3.689878838031291e-07}, {"id": 1101, "seek": 739288, "start": 7406.24, "end": 7413.32, "text": " we change the parameter by such a small amount so it's it's it's possible in fact it's certain", "tokens": [321, 1319, 264, 13075, 538, 1270, 257, 1359, 2372, 370, 309, 311, 309, 311, 309, 311, 1944, 294, 1186, 309, 311, 1629], "temperature": 0.0, "avg_logprob": -0.10907642140107997, "compression_ratio": 1.9052631578947368, "no_speech_prob": 3.689878838031291e-07}, {"id": 1102, "seek": 739288, "start": 7413.32, "end": 7420.400000000001, "text": " that the gradient is zero at many places and that means that our parameters aren't going", "tokens": [300, 264, 16235, 307, 4018, 412, 867, 3190, 293, 300, 1355, 300, 527, 9834, 3212, 380, 516], "temperature": 0.0, "avg_logprob": -0.10907642140107997, "compression_ratio": 1.9052631578947368, "no_speech_prob": 3.689878838031291e-07}, {"id": 1103, "seek": 742040, "start": 7420.4, "end": 7425.879999999999, "text": " to change at all because learning rate times gradient is still zero when the gradient zero", "tokens": [281, 1319, 412, 439, 570, 2539, 3314, 1413, 16235, 307, 920, 4018, 562, 264, 16235, 4018], "temperature": 0.0, "avg_logprob": -0.0948952871655661, "compression_ratio": 1.7402597402597402, "no_speech_prob": 2.069837279350395e-07}, {"id": 1104, "seek": 742040, "start": 7425.879999999999, "end": 7436.839999999999, "text": " for any learning rate so this is why the loss function and the metric are not always the", "tokens": [337, 604, 2539, 3314, 370, 341, 307, 983, 264, 4470, 2445, 293, 264, 20678, 366, 406, 1009, 264], "temperature": 0.0, "avg_logprob": -0.0948952871655661, "compression_ratio": 1.7402597402597402, "no_speech_prob": 2.069837279350395e-07}, {"id": 1105, "seek": 742040, "start": 7436.839999999999, "end": 7448.2, "text": " same thing we can't use a metric as our loss if that metric has a gradient of zero so we", "tokens": [912, 551, 321, 393, 380, 764, 257, 20678, 382, 527, 4470, 498, 300, 20678, 575, 257, 16235, 295, 4018, 370, 321], "temperature": 0.0, "avg_logprob": -0.0948952871655661, "compression_ratio": 1.7402597402597402, "no_speech_prob": 2.069837279350395e-07}, {"id": 1106, "seek": 744820, "start": 7448.2, "end": 7456.88, "text": " need something different so we want to find something that kind of is pretty similar to", "tokens": [643, 746, 819, 370, 321, 528, 281, 915, 746, 300, 733, 295, 307, 1238, 2531, 281], "temperature": 0.0, "avg_logprob": -0.07795441352714927, "compression_ratio": 1.6835443037974684, "no_speech_prob": 1.4677348758596054e-07}, {"id": 1107, "seek": 744820, "start": 7456.88, "end": 7462.34, "text": " the accuracy in that like as the accuracy gets better this ideal function we want gets", "tokens": [264, 14170, 294, 300, 411, 382, 264, 14170, 2170, 1101, 341, 7157, 2445, 321, 528, 2170], "temperature": 0.0, "avg_logprob": -0.07795441352714927, "compression_ratio": 1.6835443037974684, "no_speech_prob": 1.4677348758596054e-07}, {"id": 1108, "seek": 744820, "start": 7462.34, "end": 7473.08, "text": " better as well but it should not have a gradient of zero so let's think about that function", "tokens": [1101, 382, 731, 457, 309, 820, 406, 362, 257, 16235, 295, 4018, 370, 718, 311, 519, 466, 300, 2445], "temperature": 0.0, "avg_logprob": -0.07795441352714927, "compression_ratio": 1.6835443037974684, "no_speech_prob": 1.4677348758596054e-07}, {"id": 1109, "seek": 747308, "start": 7473.08, "end": 7483.84, "text": " suppose we had three images actually you know what this is actually probably a good time", "tokens": [7297, 321, 632, 1045, 5267, 767, 291, 458, 437, 341, 307, 767, 1391, 257, 665, 565], "temperature": 0.0, "avg_logprob": -0.06536001543844899, "compression_ratio": 1.6646341463414633, "no_speech_prob": 6.179388947202824e-07}, {"id": 1110, "seek": 747308, "start": 7483.84, "end": 7488.92, "text": " to stop because actually you know we've kind of we've got to the point here where we understand", "tokens": [281, 1590, 570, 767, 291, 458, 321, 600, 733, 295, 321, 600, 658, 281, 264, 935, 510, 689, 321, 1223], "temperature": 0.0, "avg_logprob": -0.06536001543844899, "compression_ratio": 1.6646341463414633, "no_speech_prob": 6.179388947202824e-07}, {"id": 1111, "seek": 747308, "start": 7488.92, "end": 7496.8, "text": " gradient descent we kind of know how to do it with a simple loss function and I actually", "tokens": [16235, 23475, 321, 733, 295, 458, 577, 281, 360, 309, 365, 257, 2199, 4470, 2445, 293, 286, 767], "temperature": 0.0, "avg_logprob": -0.06536001543844899, "compression_ratio": 1.6646341463414633, "no_speech_prob": 6.179388947202824e-07}, {"id": 1112, "seek": 749680, "start": 7496.8, "end": 7503.24, "text": " think before we start looking at the MNIST loss function we shouldn't move on because", "tokens": [519, 949, 321, 722, 1237, 412, 264, 376, 45, 19756, 4470, 2445, 321, 4659, 380, 1286, 322, 570], "temperature": 0.0, "avg_logprob": -0.08363274931907654, "compression_ratio": 1.674641148325359, "no_speech_prob": 6.681508466499508e-07}, {"id": 1113, "seek": 749680, "start": 7503.24, "end": 7508.360000000001, "text": " we've got so much so much assignments to do for this week already so we've got build your", "tokens": [321, 600, 658, 370, 709, 370, 709, 22546, 281, 360, 337, 341, 1243, 1217, 370, 321, 600, 658, 1322, 428], "temperature": 0.0, "avg_logprob": -0.08363274931907654, "compression_ratio": 1.674641148325359, "no_speech_prob": 6.681508466499508e-07}, {"id": 1114, "seek": 749680, "start": 7508.360000000001, "end": 7514.12, "text": " web application and we've got go step through step through this notebook to make sure you", "tokens": [3670, 3861, 293, 321, 600, 658, 352, 1823, 807, 1823, 807, 341, 21060, 281, 652, 988, 291], "temperature": 0.0, "avg_logprob": -0.08363274931907654, "compression_ratio": 1.674641148325359, "no_speech_prob": 6.681508466499508e-07}, {"id": 1115, "seek": 749680, "start": 7514.12, "end": 7521.68, "text": " fully understand it so I actually think we should probably stop right here before we", "tokens": [4498, 1223, 309, 370, 286, 767, 519, 321, 820, 1391, 1590, 558, 510, 949, 321], "temperature": 0.0, "avg_logprob": -0.08363274931907654, "compression_ratio": 1.674641148325359, "no_speech_prob": 6.681508466499508e-07}, {"id": 1116, "seek": 752168, "start": 7521.68, "end": 7530.360000000001, "text": " make things too crazy so before I do Rachel are there any questions okay great all right", "tokens": [652, 721, 886, 3219, 370, 949, 286, 360, 14246, 366, 456, 604, 1651, 1392, 869, 439, 558], "temperature": 0.0, "avg_logprob": -0.08527290530321074, "compression_ratio": 1.6017699115044248, "no_speech_prob": 8.31526620004297e-07}, {"id": 1117, "seek": 752168, "start": 7530.360000000001, "end": 7534.68, "text": " well thanks everybody I'm sorry for that last minute change of tack there but I think this", "tokens": [731, 3231, 2201, 286, 478, 2597, 337, 300, 1036, 3456, 1319, 295, 9426, 456, 457, 286, 519, 341], "temperature": 0.0, "avg_logprob": -0.08527290530321074, "compression_ratio": 1.6017699115044248, "no_speech_prob": 8.31526620004297e-07}, {"id": 1118, "seek": 752168, "start": 7534.68, "end": 7540.360000000001, "text": " is going to make sense so I hope you have a lot of fun with your web applications try", "tokens": [307, 516, 281, 652, 2020, 370, 286, 1454, 291, 362, 257, 688, 295, 1019, 365, 428, 3670, 5821, 853], "temperature": 0.0, "avg_logprob": -0.08527290530321074, "compression_ratio": 1.6017699115044248, "no_speech_prob": 8.31526620004297e-07}, {"id": 1119, "seek": 752168, "start": 7540.360000000001, "end": 7546.52, "text": " and think of something that's really fun really interesting it doesn't have to be like important", "tokens": [293, 519, 295, 746, 300, 311, 534, 1019, 534, 1880, 309, 1177, 380, 362, 281, 312, 411, 1021], "temperature": 0.0, "avg_logprob": -0.08527290530321074, "compression_ratio": 1.6017699115044248, "no_speech_prob": 8.31526620004297e-07}, {"id": 1120, "seek": 754652, "start": 7546.52, "end": 7552.56, "text": " it could just be some you know cute thing we've had students before a student that I", "tokens": [309, 727, 445, 312, 512, 291, 458, 4052, 551, 321, 600, 632, 1731, 949, 257, 3107, 300, 286], "temperature": 0.0, "avg_logprob": -0.12333181576851086, "compression_ratio": 1.6926829268292682, "no_speech_prob": 3.7852851164643653e-06}, {"id": 1121, "seek": 754652, "start": 7552.56, "end": 7558.400000000001, "text": " think he said he had 16 different cousins and he created something that would classify", "tokens": [519, 415, 848, 415, 632, 3165, 819, 29246, 293, 415, 2942, 746, 300, 576, 33872], "temperature": 0.0, "avg_logprob": -0.12333181576851086, "compression_ratio": 1.6926829268292682, "no_speech_prob": 3.7852851164643653e-06}, {"id": 1122, "seek": 754652, "start": 7558.400000000001, "end": 7566.56, "text": " a photo based on which of his cousins as for like his fiance meeting his family you know", "tokens": [257, 5052, 2361, 322, 597, 295, 702, 29246, 382, 337, 411, 702, 46552, 3440, 702, 1605, 291, 458], "temperature": 0.0, "avg_logprob": -0.12333181576851086, "compression_ratio": 1.6926829268292682, "no_speech_prob": 3.7852851164643653e-06}, {"id": 1123, "seek": 754652, "start": 7566.56, "end": 7573.240000000001, "text": " you can come up with anything you like but you know yeah show off your application and", "tokens": [291, 393, 808, 493, 365, 1340, 291, 411, 457, 291, 458, 1338, 855, 766, 428, 3861, 293], "temperature": 0.0, "avg_logprob": -0.12333181576851086, "compression_ratio": 1.6926829268292682, "no_speech_prob": 3.7852851164643653e-06}, {"id": 1124, "seek": 757324, "start": 7573.24, "end": 7577.24, "text": " maybe have a look around at what I pay widgets can do and try and come up with something", "tokens": [1310, 362, 257, 574, 926, 412, 437, 286, 1689, 43355, 393, 360, 293, 853, 293, 808, 493, 365, 746], "temperature": 0.0, "avg_logprob": -0.13130648136138917, "compression_ratio": 1.3934426229508197, "no_speech_prob": 1.4969135008868761e-05}, {"id": 1125, "seek": 757724, "start": 7577.24, "end": 7604.12, "text": " that you think is pretty cool all right thanks everybody I will see you next week.", "tokens": [50364, 300, 291, 519, 307, 1238, 1627, 439, 558, 3231, 2201, 286, 486, 536, 291, 958, 1243, 13, 51708], "temperature": 0.0, "avg_logprob": -0.2817181825637817, "compression_ratio": 1.0789473684210527, "no_speech_prob": 5.142728696228005e-05}], "language": "en"}