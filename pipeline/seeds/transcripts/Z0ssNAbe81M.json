{"text": " Welcome to part 2 of Deep Learning for Coders. Part 1 was Practical Deep Learning for Coders. Part 2 is not Impractical Deep Learning for Coders, but it is a little different as we'll discuss. This is probably a really dumb idea, but last year I started not starting part 2 with part 2 lesson 1, but part 2 lesson 8 because it's kind of part of the same sequence. So I've done that again, but sometimes I'll probably forget and call things lesson 1. So part 2 lesson 1 and part 2 lesson 8 are the same thing if I ever make that mistake. So we're going to be talking about object detection today, which refers to not just finding out what a picture is a picture of, but also whereabouts that thing is. But in general, the idea of each lesson in this part is not so much because I particularly want you to care about object detection, but rather because I'm trying to pick topics which allow me to teach you some foundational skills that you haven't got yet. So for example, object detection is going to be all about creating much richer convolutional network structures which have a lot more interesting stuff going on, and a lot more stuff going on in the fastai library that we have to customize to get there. So at the end of these 7 weeks, I can't possibly cover the hundreds of interesting things that people are doing with deep learning right now. But the good news is that all of those hundreds of things you'll see once you read the papers, like minor tweaks on a reasonably small number of concepts. So we covered a bunch of those concepts in part 1, and we're going to go a lot deeper into those concepts and build on them to get to some deeper concepts in part 2. So in terms of what we covered in part 1, there's a few key takeaways. We'll go through each of these takeaways in turn. One is the idea, and you might have seen recently Jan Lekoon's been promoting the idea that we don't call this deep learning, but differentiable programming. And the idea is that you'll have noticed all the stuff we did in part 1 was really about setting up a differentiable function and a loss function that describes how good the parameters are, and then pressing go, and it kind of makes it work. And so I think it's quite a good way of thinking about it, differentiable programming, this idea that if you can configure a loss function that describes, scores how good something is at doing your task, and you have a reasonably flexible neural network architecture, you're kind of done. So that's one key way of thinking about this. This example here comes from playground.tensorflow.org, which is a cool website where you can play interactively with creating your own little differentiable functions manually. The second thing then we learned is about transfer learning. And it's basically that transfer learning is the most important single thing to be able to do to use deep learning effectively. Nearly all courses, nearly all papers, nearly everything in deep learning, education and research focuses on starting with random weights, which is ridiculous because you almost never would want to or need to do that. You would only want to or need to do that if nobody had ever trained a model on a vaguely similar set of data with an even remotely connected kind of problem to solve as what you're doing now, which almost never happens. So this is where the Fast.ai library and the stuff we talk about in this class is vastly different to any other library or course, is that it's all focused on transfer learning and it turns out that you do a lot of things quite differently. So the basic idea of transfer learning is here's a network that does thing A, remove the last layer or so, replace it with a few random layers at the end, fine-tune those layers to do thing B, taking advantage of the features that the original network learned, and then optionally fine-tune the whole thing end-to-end. And you've now got something which probably uses orders of magnitude less data than if you started with random weights, it's probably a lot more accurate and probably trained a lot faster. We didn't talk a hell of a lot about architecture design in part 1, and that's because kind of architecture design is getting less and less interesting. There's a pretty small range of architectures that generally work pretty well quite a lot of the time. We've been focusing on using CNNs for generally fixed-size, somehow ordered data, RNNs for sequences that have some kind of state, fiddling around a tiny bit with activation functions like softmax if you've got a single categorical outcome, sigmoid if you've got multiple outcomes, and so forth. Some of the architecture design we'll be doing in this part gets kind of more interesting, particularly this first session about object detection. But on the whole, I think we probably spend less time talking about architecture design than most courses or papers because it's generally not the hard bit. The third thing we looked at was how to avoid overfitting. The general idea that I tried to explain is the way I like to build a model is to first of all create something that's definitely terribly overparameterized, will massively overfit for sure, train it and make sure it does overfit. At that point, you know, I've got a model that is capable of reflecting the training set. And then it's as simple as doing these things to then reduce that overfitting. If you don't start with something that's overfitting, then you're kind of lost. So you start with something that's overfitting, and then to make it overfit less, you can add more data, you can add more data augmentation, you can do things like more batch norm layers or dense nets or various things that can handle less data. You can add regularization like weight decay and dropout. And then finally, this is often the thing people do first, but this should be the thing you do last, is reduce the complexity of your architecture, have less layers or less activations. We talked quite a bit about embeddings, both for NLP and the general idea of any kind of category of data as being something you can now model with neural nets. It's been interesting to see how since part 1 came out, at which point there were almost no examples of papers or blogs or anything about using tabular data or categorical data in deep learning, suddenly it's kind of taken off and it's kind of everywhere. So this is becoming a more and more popular approach. It's still little enough known that when I say to people, we use neural nets for time series and tabular data analysis, it's often like, wait, really? But it's definitely not such a far out idea. There are more and more resources available, including recent Kaggle competition winning approaches using this technique. So part 1, which particularly had those 5 messages, really was all about introducing you to best practices in deep learning. And so it's like trying to show you techniques which were mature enough that they definitely work reasonably reliably for practical real-world problems, and that I had researched and tuned enough over a quite long period of time that I could kind of say, here's a sequence of steps and architectures and whatever, if you use this, you'll almost certainly get pretty good results, and then kind of put that into the fast AI library in a way that you could do that pretty quickly and easily. So that's kind of what practical deep learning for coders was designed to do. So this part 2 is cutting edge deep learning for coders. And what that means is, I often don't know the exact best parameters, architecture details and so forth to solve a particular problem. We don't necessarily know if it's going to solve a problem well enough to be practically useful. It almost certainly won't be integrated well enough into fast AI, or any library that you can just press a few buttons and it'll start working. It's all about stuff which I'm not going to teach it unless I'm very confident that it either is now or will be soon a very practically useful technique. So I don't take stuff which just appeared and I don't know enough about it to know what the trajectory is going to be. So if I'm teaching it in this course, I'm saying this either works well in the research literature now and is going to be well worth learning about, or we're pretty close to being there, but it's going to take a lot of tweaking often and experimenting to get it to work on your particular problem because we don't know the details well enough to know how to make it work for every dataset or every example. So it's kind of exciting to be working at this point. It means that rather than fast AI and PyTorch being obscure black boxes which you just know these recipes for, you're going to learn the details of them well enough that you can customize them exactly the way you want, that you can debug them, that you can read the source code of them to see what's happening, and so forth. And so if you're not pretty confident of object-oriented Python and stuff like that, then that's something you're going to want to focus on studying during this course, because we assume that, I'm not going to be spending time on that. But I will be trying to introduce you to some tools that I think are particularly helpful, like the Python debugger, like how to use your editor to jump through the code, stuff like that. In fact, in general, there will be a lot more detailed specific code walkthroughs, coding technique discussions, as well as more detailed walkthroughs of papers and the math. And so anytime we cover one of these things, if you notice something where you're like, this is assuming some knowledge that I don't have, that's fine. It just means that's something you could ask on the forum and say, hey, Jeremy was talking about static methods in Python, I don't really know what a static method is, or why he was using it here, can somebody give me some resources. These are kind of things that are not rocket science, just because you don't happen to have come across it yet doesn't mean it's hard. It's just something you need to learn. I will mention that as I cover these research-level topics and develop these courses, I often refer to code that academics have put up to go along with their papers, or example code that somebody else has written on GitHub. I nearly always find that there's some massive critical flaw in them. So be careful of taking code from online resources and assuming that if it doesn't work for you that you've made a mistake or something. This kind of research-level code, it's just good enough that they were able to run their particular experiments every second Tuesday or something. So you should be ready to do some debugging. So on that sense, I just wanted to remind you about something from our old course wiki that we sometimes talk about, which is people often ask what should I do after the lesson, how do I know if I've got it. We basically have this thing called how to use the provided notebooks. The idea is this. Don't open up the notebook, shift enter, shift enter, shift enter, until a bug appears and then go to the forums and say the notebook's broken. The idea of the notebook is to kind of be like a little crutch to help you get through each step. So you start with an empty notebook and think, I now want to complete this process. And that might initially require you alt-tabbing or whatever, command-tabbing to the notebook and reading it, figuring out what it says, but whatever you do, don't copy and paste it to your notebook. Type it out yourself. So try to make sure you can repeat the process, and as you're typing it out, you need to be thinking what am I typing, why am I typing it. So if you can get to the point where you can solve an object detection problem yourself in a new empty notebook, even if it's using the exact same dataset we used in the course, that's a great sign that you're getting it. That'll take a while, but the idea is that by practicing the second time you try to do it, the third time you try to do it, you'll check the notebook less and less. And if there's anything in the notebook where you think, if you think I don't know what it's doing, I hope to teach you enough techniques in this course, in this class, that you'll know how to experiment to find out what it's doing. So you shouldn't have to ask that. But you may well want to ask, why is it doing that? That's the conceptual bit, and that's something you may need to go to the forums and say, before this step, Jeremy had done this, after this step, Jeremy had done that. There's this bit in the middle where he does this other thing, I don't quite know why. So then you can try and say, here are my hypotheses as to why, try and work through it as much as possible. That way you'll both be helping yourself and other people will help you fill in the gaps. Alright, if you wish, and you have the financial resources, now is a good time to build a deep learning box for yourself. When I say a good time, I don't mean a good time in the history of the pricing of GPUs. GPUs are currently by far the most expensive they've ever been, as I say this, because of the cryptocurrency mining boom. I mean it's a good time in your study cycle. The fact is, if you're paying somewhere between $0.60 and $0.90 an hour for doing your deep learning on a cloud provider, particularly if you're still on a K80, like an Amazon P2, or Google Colab actually, now lets you train on a K80 for free. But those are very slow GPUs. You can buy one that's going to be 3 times faster for maybe $600, $700. You need a box to put it in, of course. But the example in the bottom right here from the forum was something that somebody put together in last year's course, so like a year ago they were able to put together a pretty decent box for a bit over $500. Generally speaking you're probably looking at more like $1,000 or $1,500. I created a new forum thread where you can talk about options and parts and ask questions and so forth. If you can afford it, right now the GTX 1080 Ti is almost certainly what you want in terms of the best price performance mix. If you can't afford it, a 1070 is fine. If you can't afford that, you should probably be looking for a secondhand 980 or a secondhand 970, something like that. If you can afford to spend more money, it's worth getting a second GPU so you can do what I do, which is to have one GPU training and another GPU which I'm running an interactive Jupyter Notebook session in. RAM is very useful. Try and get 32GB if you can. RAM is not terribly expensive. A lot of people find that they're vendor or purchasing to buy one of these business class Xeon CPUs, that's a total waste of time. You can get one of the Intel i5 or i7 consumer CPUs, far, far cheaper, but actually a lot of them are faster. Often you'll hear CPU speed doesn't matter. If you're doing computer vision, that's definitely not true. It's very common now with these 1080 Ti's and so forth to find that the speed of the data augmentation is actually the slow bit that's happening on the CPU, so it's worth getting a decent CPU. Again, your GPU, if it's running quickly but the hard drive's not fast enough to give it data, then that's a waste as well. So if you can afford an NVMe drive that's super, super fast, you don't have to get a big one. You can just get a little one, just copy your current set of data onto and have some big RAID array that sits there for the rest of your data when you're not using it. There's a slightly arcane thing about PCI lanes, which is basically the size of the highway that connects your GPU to your computer. A lot of people claim that you need to have 16 lanes to feed your GPU. It actually turns out, based on some analysis that I've seen recently, that that's not true. You need 8 lanes for GPU. So again, hopefully help you save some money on your motherboard. If you've never heard of PCI lanes before, trust me, by the end of putting together this box you'll be sick of hearing about them. You can buy all the parts and put it together yourself. It's not that hard, it can be a useful learning experience, it can also be frustrating and annoying. So you can always go to central computers and they'll put it together for you. There's lots of online vendors that will do the same thing. I generally make sure it turns on and runs properly, generally not much of a markup. We're going to be doing a lot of reading papers. Basically each week we'll be implementing a paper or a few papers. And if you haven't looked at papers before, they look something like on the left. That thing on the left is an extract from the paper that implements Atom. You may also have seen Atom as a single Excel formula on the spreadsheet. The difference is in academic papers, people love to use Greek letters. They also hate to refactor. So you'll often see a page-long formula where when you actually look at it carefully, you'll realize the same sub-equation appears 8 times. They didn't think to say above it let t equal this sub-equation. I don't know why this is a thing. I guess all this is to say, once you've read and understood a paper, you then go back to it and you look at it and you're just like, wow, how did they make such a simple thing so complicated. Like Atom is like momentum on the gradient and momentum on the square root of the gradient. That's it. And it's this big long thing. The other reason it's a big long thing is because they have things like this where they have theorems and corollaries and stuff where they're saying, here's our theoretical reasoning behind why this ought to work, or whatever. And for whatever reason, a lot of conferences and journals don't like to accept papers that don't have a lot of this theoretical justification. Jeffrey Hinton's talked about this a bit, how particularly a decade or two ago when no conferences would really accept any neural network papers, then there was this one abstract theoretical result that came out where suddenly they could show this practically unimplemented important but theoretically interesting thing and then suddenly they could then start submitting things to journals because they have this theoretical justification. So academic papers are a bit weird, but in the end it's the way that the research community communicates their findings and so we need to learn to read them. But something that can be a great thing to do is to take a paper, put in the effort to understand it, and then write a blog where you explain it in code and normal English. And lots of people who do that end up getting quite a following, end up getting some pretty great job offers and so forth because it's such a useful skill to be able to show, I can understand these papers, I can implement them in code, I can explain them in English. One thing I will mention is it's very hard to read or understand something which you can't vocalize, which means if you don't know the names of the Greek letters, it sounds weird, but it's actually very difficult to understand, remember, take in a formula that appears again and again that's got like squiggle. You need to know that that squiggle is called delta or that squiggle is called sigma or whatever. So spending some time learning the names of the Greek letters sounds like a strange thing to do, but suddenly you don't look at these things anymore and go like squiggle A over squiggle B plus other weird squiggle looks like a Y thing. They've all got names. So now that we're kind of at the cutting edge stage, a lot of the stuff we'll be learning this class is stuff that almost nobody else knows about. So that's a great opportunity for you to be the first person to create an understandable and generalizable code library that implements it, or the first person to write a blog post that explains it in clear English, or the first person to try applying it to this slightly different area that's obviously going to work just as well, or whatever. So when we say cutting edge research, that doesn't mean you have to come up with the next batch norm or the next atom or the next diluted convolution. It can mean like, take this thing that was used for translation and apply it to this very similar other parallel NLP task, or take this thing that was tested on skin lesions and trusted on this data set of this other kind of lesion, or whatever. That kind of stuff is super great learning experience and incredibly useful because for the vast majority of the world that knows nothing about this whole field, it just looks like magic. You'll be like, hey, I've for the first time shown greater than 90% accuracy at finding this kind of lesion in this kind of data. So when I say experiment in your area of expertise, one of the things we particularly look for in this class is to bring in people who are pretty good at something else. Pretty good at meteorology, pretty good at de novo drug design, or pretty good at goat dairy farming, or whatever. So probably the thing you can do the best would be to take that thing you're already pretty good at and add on these new skills. Because otherwise, if you're trying to go into some different domain, you're going to have to figure out how do I get data for that domain, how do I know what interesting problems to solve in that domain, and so forth. Where else often it'll seem pretty trivial to you to take this technique and apply it to this data set that you've already got sitting on your hard drive, but that's often going to be the super interesting thing for the rest of the world to see. That's interesting when you apply it to meteorology data and you use this RNN or whatever, it allows you to forecast over larger areas or longer time periods. So communicating what you're doing is super helpful. We've talked about that before. I know something that a lot of people on the forums ask people who have already written a blog, often people on the forum will be like, how did you get up the guts to do that, or what was the process you got to before you decided to start publishing something or whatever. The answer is always the same. It's always just, I was sure I wasn't good enough to do it, I felt terrified and intimidated of doing it, but I wrote it and posted it anyway. There's never a time I think any of us actually feel like we're not total frauds and impostors, but we know more about what we're doing than us of 6 months ago. And there's somebody else in the world who knows as much as you did 6 months ago, so if you write something now that would have helped you of 6 months ago, you're helping some people. And honestly if you wait another 6 months, then the you of 12 months ago probably won't even understand that anymore because it's too advanced now. It's great to communicate wherever you're up to in a way that you think would be helpful to the person you were before you knew that thing. And of course something that the forums have been useful for is getting feedback about drafts. If you post a draft of something that you're thinking of releasing, then other folks here can point out things that they find unclear or they think they need some corrections or whatever. So the overarching theme of part 2 I've described as generative models, but unfortunately then Rachel asked me this afternoon exactly what I meant by generative models and I realize I don't really know. So what I really mean is in part 1, the output of our neural networks is generally like a number or a category, whereas the outputs of a lot of the stuff in part 2 are going to be like a whole lot of things, like the top left and bottom right location of every object in an image along with what the object is, or a complete picture with a class of every single pixel in that picture, or an enhanced super resolution version of the input image, or the entire original input paragraph translated into French. It's kind of like, often it just requires some different ways of thinking about things and some kind of different architectures and so forth. So that's kind of like the main theme of the kind of techniques we'll be looking at. The vast majority, possibly all of the data we'll be looking at will be either text or image data. It would be fairly trivial to do most of these things with audio as well, it's just not something I've spent much time on myself yet. Somebody asked on the forum about what can we do more stuff with time series and tabular data, and my answer was, I've already taught you everything I know about that and I'm not sure there's much else to say, particularly if you check out the machine learning course, which goes into a lot of that in a lot more detail. So I don't feel like there's more stuff to tell you. I think that's a super important area, but I think we're done. We'll be looking at some larger datasets, both in terms of the number of objects in the dataset and the size of each of those objects. For those of you that are working with limited computational resources, please don't let that put you off. Feel free to replace it with something smaller and simpler. In fact, when I was designing this course, I did quite a lot of it in Australia when I went to visit my mom, and my mom decided to book a nice holiday house for us with fast WiFi. We turned up to the holiday house with fast WiFi, and indeed it did have WiFi, but the WiFi was not connected to the Internet. So I called up the agent and I said, I found the ADSL router and it's got an ADSL thing plugged in, and I followed the cable down and the other end of the cable has nothing to plug into. So she called the people renting the house, the owner, and called me back the next day and she said, actually the town I'm in is called Point Leo. Actually Point Leo has no Internet. And so the good old Australian government had decided to replace ADSL in Point Leo with a new national broadband network, and therefore they had disconnected ADSL that had not yet connected the national broadband network. So we had fast WiFi, which we could use to Skype chat from one side of the house to the other, but I had no Internet. Luckily I did have a new Surface Book 15-inch which has a GTX 1070 in it, and so I wrote a large amount of this course entirely on my laptop, which means I had to practice with relatively small resources. I mean not tiny, but 16GB RAM and 6GB GPU. And it was all in Windows, by the way. So I can tell you that most of this course works well on Windows, on a laptop. So you can always use smaller batch sizes, you can use a cut down version of the dataset, whatever. But if you have the resources, you'll get better results if you can use the bigger datasets when they're available. Now is a good time to take a somewhat early break so we can fix the forums. Let's come back at 7.25. So let's start talking about object detection. And so here is an example of object detection. And so hopefully you'll see two main differences from what we're used to when it comes to classification. The first is that we have got multiple things that we're classifying, which is not unheard of. We did that in the planet satellite data, for example. What is kind of unheard of is that as well as saying what we see, we've also got what's called bounding boxes around what we see. A bounding box has a very specific definition, which is it's a box, it's a rectangle. And the rectangle has the object entirely fitting within it, but it's no bigger than it has to be. You'll see this bounding box is perhaps, for the horse at least, slightly imperfect in that it looks like there's a bit of tail here, so it probably should be a bit wider, and maybe there's even a little bit of hoof here, maybe it should be a bit longer. So the bounding boxes won't be perfect, but they're generally pretty good in most datasets that you can find. So our job will be to take data that has been labeled in this way and on data that is unlabeled to generate the classes of the objects and for each one of those there are bounding boxes. One thing I'll note to start with is that labeling this kind of data is generally more expensive. It's generally quicker to say horse, person, person, horse, car, dog, jumbo jet, than it is to say if there's a whole horse race going on to label the exact location of every rider and of every horse. And then of course it also depends what classes you want to label. You want to label every fence post or whatever. But generally, just like in ImageNet, it's not like tell me any object you see in this picture. In ImageNet, it's like here are the 1000 classes that we ask you to look for, tell us which one of those 1000 classes you find. For these object detection datasets, it's a list of object classes that we want you to tell us about and find every single one of them of any type in the picture along with where they are. So in this case, why isn't there tree or jump labeled? That's because for this particular dataset, they weren't one of the classes that the annotators were asked to find and therefore not part of this particular problem. So that's kind of the specification of the object detection problem. So let me describe stage 1. And stage 1 is actually going to be surprisingly straightforward. And we're going to start at the top and work down. We're going to start out by classifying the largest object in each image. So we're going to try and say person. Actually this one is wrong. Dog is not the largest object. Sofa is the largest object. So here's an example of a misclassified one. Bird, correct. Person, correct. That will be the first thing we try to do. That's not going to require anything new, so it'll just be a bit of a warm-up for us. The second thing will be to tell us the location of the largest object in each image. Again, here this is actually incorrect. It should have labeled the sofa, but you can see where it's coming from. And then finally we will try to do both at the same time, which is to label what it is and where it is for the largest thing in the picture. And this is going to be relatively straightforward. So it'll be a good warm-up to get us going again. But what I'm going to do is I'm going to use it as an opportunity to show you some useful coding techniques and a couple of little FastAI anti-details before we then get onto multi-label classification and then multiple object classification. So let's start here. The notebook that we're using is Pascal. All of the notebooks are in the DL2 folder. One thing you'll see in some of my notebooks is torch.cuda.setdevice. You may have even seen it in the last part, just in case you're wondering why that's there. I have 4 GPUs on the university server that I use, so I can put a number from 0 to 3 in here to pick one. This is how I prefer to use multiple GPUs rather than run a model on multiple GPUs, which doesn't always speed it up that much and is kind of awkward. I generally like to have different GPUs running different things. So in this case, I was running something in this on device 1 and doing something else on another notebook in device 2. Now obviously if you see this in a notebook left behind, that was a mistake. If you don't have more than one GPU, you're going to get an error. So you can just change it to 0 or delete that line entirely. So there's a number of standard object detection datasets, just like ImageNet is a standard object classification dataset. And kind of the old classic ImageNet equivalent if you like is Pascal VOC. The actual main website for it is like, I don't know, it's running on somebody's coffee warmer or something. It goes down all the time every time he makes coffee. So some folks have mirrored it, which is very kind of them, so you might find it easier to grab from the mirror. You'll see when you download it that there's a 2007 dataset, a 2012 dataset, that they basically were like academic competitions in those different years, just like the ImageNet dataset we tend to use is actually the ImageNet 2012 competition dataset. We'll be using the 2007 version in this particular notebook. Feel free to use the 2012 instead, it's a bit bigger, you might get better results. A lot of people, in fact most people now in research papers actually combine the two. You do have to be careful because there's some leakage between the validation sets between the two. If you decide to do that, make sure you do some reading about the dataset to make sure you know how to combine them correctly. The first thing you'll notice in terms of coding here is this. We haven't used this before. I'm going to be using this all the time now. This is part of the Python 3 standard library called pathlib, and it's super handy. It basically gives you an object-oriented access to a directory or a file. So you can see if I go path.something, there's lots of things I can do. One of them is iterative directory. However, path.iterate directory returns that. Hopefully you've come across generators by now because we did quite a lot of stuff that used them behind the scenes without talking about them too much. But basically a generator is something in Python 3 which you can iterate over. So basically you can go for O in that print. Or of course you could do the same thing as a list comprehension. Or you can just stick the word list around it to turn a generator into a list. So anytime you see me put list around something, that's normally because it returned a generator. It's not particularly interesting. The reason that things generally return generators is what if the directory had 10 million items in? You don't necessarily want a 10 million long list, so with a for loop, you'll just grab one, do the thing, throw it away, grab the second, throw it away. It lets you do things lazily. You'll see that the things that's returning aren't actually strings, but they're some kind of object. If you're using Windows, it'll be a Windows path. On Linux, it'll be a POSIX path. Most of the time you can use them as if they were strings. So most like if you pass it to any of the os.path.whatever functions in Python, it'll just work. But some external libraries, it won't work. So that's fine. If you grab one of these, let's say o equals, let's just grab one of these. So in general, you can change data types in Python just by naming the data type that you want and treating it like a function, and that will cast it. So anytime you try to use one of these pathlib objects and you pass it to something which says I was affecting a string, this is not a string, that's how you do it. So you'll see there's quite a lot of convenient things you can do. One kind of fun thing is the slash operator is not divided by, but it's path slash. So like they've overridden the slash operator in Python so that it works. So you can say path slash whatever, and that gets you. See how that's not inside a string? So this is actually applying not the division operator, but the overridden slash operator, which means get a child thing in that path. And you'll see if you run that, it doesn't return a string, it returns a pathlib object. And so one of the things a pathlib object can do is it has an open method. So it's actually pretty cool once you start getting the hang of it. And you'll also find that the open method takes all the kind of arguments you're familiar with, you can say right or binary or encoding or whatever. So in this case, I want to load up these JSON files which contain not the images, but the bounding boxes and the classes of the objects. And so in Python, the easiest way to do that is with the JSON library, or there's some faster API equivalent versions, but this is pretty small so you won't need them. And you go JSON.load and you pass it an open file object. And so the easy way to do that since we're using pathlib is just go path.open. So these JSON files that we're going to look inside in a moment, if you haven't used them before, JSON is JavaScript object notation. It's kind of the most standard way to pass around hierarchical structured data now. Obviously not just with JavaScript. You'll see I've got some JSON files in here. They actually did not come from the mirror I mentioned. The original Pascal annotations were in XML format, but cool kids can't use XML anymore. We have to use JSON, so somebody's converted them all to JSON, and so you'll find the second link here has all the JSON files. So if you just pop them in the same location that I've put them here, everything will work for you. So these annotation files, JSONs, basically contain a dictionary. Once you open up the JSON, it becomes a Python dictionary, and they've got a few different things in. The first is we can look at images. It's got a list of all of the images, how big they are, and a unique ID for each one. One thing you'll notice here is I've taken the word images and put it inside a constant called images. That may seem kind of weird, but if you're using a notebook or any kind of IDE or whatever, this now means I can tab complete all of my strings and I won't accidentally type it slightly wrong. That's a handy trick. So here's the contents of the first few things in the images. More interestingly, here are some of the annotations. So you'll see basically an annotation contains a bounding box, and the bounding box tells you the column and row of the top left, and its height and width. And then it tells you that that particular bounding box is for this particular image. So you'd have to join that up to over here to find it's actually 012.jpg, and it's of category ID 7. It also, for some of them at least, has a polygon segmentation, not just a bounding box. We're not going to be using that. Some of them have an ignore flag, so we'll ignore the ignore flags. Some of them have something telling you it's a crowd of that object, not just one of them. So that's what these annotations look like. So then you saw here there's a category ID, so then we can look at the categories. Here's a few examples. Basically each ID has a name. Here we go. So what I did then was turn this categories list into a dictionary from ID to name. I created a dictionary from ID to name of the image file names, and I created a list of all of the image IDs just to make life easier. So generally when you're working with a new dataset, or at least when I work with a new dataset, I try to make it look the way I would want it to if I designed that dataset. And so the steps you see here, and you'll see in each class, are basically like the sequence of steps I took as I started working with this new dataset, except without the thousands of screw-ups that I did. I find the one thing people most comment on when they see me working in real-time, having seen my classes, is like, wow, you actually don't know what you're doing, do you? It's like 99% of the things I do don't work, and then the small percentage of the things that do work end up here. So I mentioned that because machine learning, and particularly deep learning, is kind of incredibly frustrating. Because in theory, you just define the correct loss function and a flexible enough architecture, and you press train, and you're done. But if that was actually all at talk, then nothing would take any time. The problem is that all the steps along the way until it works, it doesn't work. You know, like it goes straight to infinity, or it crashes with an incorrect tensor size, or whatever. And I will endeavor to show you some kind of debugging techniques as we go, but it's one of the hardest things to teach, because like, I don't know, maybe I just haven't quite figured it out yet. But the main thing it requires is tenacity, I find, like the biggest difference between the people I've worked with who are super effective and the ones who don't seem to go very far, has never been about intellect. It's always been about sticking with it, basically never giving up. So it's particularly important with this kind of deep learning stuff, because you don't get that continuous reward cycle, like with normal programming, you've got like 12 things to do until you've got your flash endpoint staged up, you know, and at each stage, it's like okay, we've successfully processed in the JSON, and now we've successfully got the callback from that promise, and now we've successfully created the authentication system. Like you know, it's this constant sequence of stuff that works. Whereas generally with training a model, it's a constant stream of like, it doesn't work, it doesn't work, it doesn't work, until eventually it does. So it's kind of annoying. Okay, so let's now look at the images. So you'll find inside the VOC dev kit, there's 2007 and 2012 directories, and in there, there's a whole bunch of stuff that's mainly these XML files, the one we care about with the JPEG images. And so again, here you've got the use of pathlibs slash operator, and inside there's a few examples of the images. So what I wanted to do was to create a dictionary where the key was the image ID, and the value was a list of all of its annotations. So basically what I wanted to do was go through each of the annotations, that doesn't say to ignore it, and append it, the bounding box and the class, to the appropriate dictionary item, where that dictionary item is a list. But the annoying thing is, of course, is that if that dictionary item doesn't exist yet, then there's no list to append to. So one super handy trick in Python is that there's a class called collections.defaultDict, which is just like a dictionary, but if you try and access a key that doesn't exist, it magically makes itself exist, and it sets itself equal to the return value of this function. Now, this could be the name of some function that you've defined, or it can be a lambda function. A lambda function simply means it's a function that you define in place. We'll be seeing lots of them. So here's an example of a function. All the arguments to the function are listed on the left, so there's no arguments to the function. And lambda functions are special, you don't have to write return, as a return is assumed. So in this case, this is a lambda function that takes no arguments and returns an empty list. So in other words, every time I try and access something in train annotations that doesn't exist, it now does exist and it's an empty list, which means I can append to it. One comment on variable naming is, when I read through these notebooks, I'll generally try and speak out the English words that the variable name is a mnemonic for. A reasonable question would be, why didn't I write the full name of the variable in English rather than using a short mnemonic. It's a personal preference I have based on a number of programming communities where the basic kind of thesis is that the more that you can see in a single kind of eye grab of the screen, the more you can understand intuitively at one go. Every time you have to, your eye has to jump around, it's kind of like a context change that reduces your understanding. It's a style of programming I found super helpful, and so generally speaking, I try to, I particularly try to reduce the vertical height so things don't scroll off the screen, but I also try to reduce the size of things so that there's a mnemonic there, which if you know it's training annotations, it doesn't take long for you to see training annotations, but you don't have to write the whole thing out. So I'm not saying you have to do it this way, I'm just saying there's some very large programming communities, some of which have been around for 50 or 60 years, which have used this approach, and I find it works well. It's interesting to compare, I guess my philosophy is somewhere between math and Java. In math, everything's a single character. The same single character can be used in the same paper for 5 different things, and depending on whether it's in italics or boldface capitals, it's another 5 different things. I find that less than ideal. In Java, you know, variable names sometimes require a few pages to print out, and I find that less than ideal as well. So for me, I personally like names which are short enough to not take too much of my perception to see at once, but long enough to have a mnemonic. Also, however, a lot of the time, the variable will be describing a mathematical object as it exists in a paper, and there isn't really an English name for it, and so in those cases I will use the same, often single letter that the paper uses. And so if you see something called delta or A or something, and it's like something inside an equation from a paper, I generally try to use the same thing. By no means do you have to do the same thing. I will say, however, if you contribute to Fast.ai, I'm not particularly fastidious about coding style or whatever, but if you write things more like the way I do than the way Java people do, I'll certainly appreciate it. So by the end of this, we now have a dictionary from file names to a tuple, and so here's an example of looking up that dictionary, and we get back a bounding box and a class. You'll see when I create the bounding box, I've done a couple of things. The first is I've switched the x and y coordinates. The reason for this, I think we mentioned this briefly in the last course, the kind of computer vision world, when you say like my screen is 640x480, that's width by height, whereas the math world, when you say my array is 640x480, it's rows by columns, ie height by width. So you'll see that a lot of things like PIL, or Pillow Image Library, and Python tend to do things in this kind of width by height, or columns by rows way, NumPy is the opposite way around. So again, my view is, don't put up with this kind of incredibly annoying inconsistency, fix it. So I've decided, fastai is the NumPy pie torch way, is the right way, so I'm always rows by columns. So you'll see here I've switched my rows of columns. I've also decided that we're going to do things by describing the top left xy coordinate and the bottom right xy coordinate with a bounding box, rather than the xy and the height width. So you'll see here I'm just converting the height and width to the top left and bottom right. So again, I often find dealing with junior programmers, in particular junior data scientists, that they kind of get given data sets that are in shitty formats, or crappy APIs, and they just act as if everything has to be that way. But your life will be much easier if you take a couple of moments to make things consistent and make them the way you want them to be. So earlier on I took all of our classes and created a categories list. And so if we look up category number 7, which is what this is, category number 7 is a car. Let's have a look at another example. Image number 17 has 2 bounding boxes. One of them is of type 15, one is of type 13. That is a person and a horse. So this would be much easier to understand if we can see a picture of these things. So let's create some pictures. So having just turned our height, width stuff into top left, bottom right stuff, we're now going to create a method to do the exact opposite, because any time I want to call some library that expects the opposite, I'm going to need to pass it in the opposite. So here is something that converts a bounding box to a height and width, bbhw, bounding box to height and width. So it's again reversing the order and giving us the height and width. So we can now open an image in order to display it. And where we're going to get to is we're going to get it to show this. That's that car. So one thing that I often get asked on the forums or through github is like, well, how did I find out about this open image thing? Where did it come from? What does it mean? Who uses it? And so I wanted to just take a moment, because one of the things we're going to be doing a lot, and I know a lot of you aren't professional coders, you have backgrounds in statistics or you know, meteorology or physics or whatever, and I apologize for those of you that are professional coders, you know this already, you need, because we're going to be doing a lot of stuff with the fastai library and other libraries, you need to be able to navigate very quickly through them. And so let me give you a quick overview of how to navigate through code. And for those of you that haven't used an editor properly before, this is going to blow your minds. For those of you that have, you're going to be like, check this out guys, check this out. For the demo I'm going to show you in Visual Studio Code. Personally my view is that on pretty much every platform, unless you're prepared to put in the decades of your life to learn BIM or Emax well, Visual Studio Code is probably the best editor out there. It's free, it's open source. There are other perfectly good ones as well. Also, if you download a recent version of Anaconda, it will offer to install Visual Studio Code for you. It integrates with Anaconda, sets it up with your Python interpreter, and comes with the Python extensions and everything. So it's a good choice if you're not sure. If you've got some other editor you like, search for the right keywords. So if I fire up Visual Studio Code, the first thing to do of course is do a git clone of the Fastai library to your laptop. You'll find in the root of the repo, as well as the environment.yml file that sets up a conda environment for GPU, one of the students has been kind enough to create an environment-cpu.yml file. Perhaps one of you that knows how to do this can add some notes to the wiki. But basically you can use that to create a local CPU-only Fastai installation. The reason you might want to do that is so that as you navigate the code, you'll be able to navigate into PyTorch, you'll see all the stuff is there. So I open up Visual Studio Code, and it's as simple as saying, open folder, and then you can just point it at the Fastai GitHub folder that you just downloaded. And so the next thing you need to do is to set up Visual Studio Code to say, I want to use the Fastai conda environment, please. So the way you do that is with the select interpreter command. And there's a really nice idea which is kind of like the best of both worlds between a command line interface and a GUI. This is the only command you need to know, Ctrl-Shift-P. You hit Ctrl-Shift-P, and then you start typing what you want to do, and watch what happens. Ctrl-Shift-P, I want to change my interpreter. And it appears. If you're not sure, you can try a few different things. So here we are, Python select interpreter. And you can see generally you can type stuff in, it'll give you a list of things if you can. And so here's a list of all of the environments and interpreters I have set up, and here's my Fastai environment. So that's basically the only setup that you have to do. The only other thing you might want to do is to know there's an integrated terminal. So if you hit Ctrl-Backtick, it brings up the terminal. And the first time you do it, it'll ask you what terminal do you want. If you're on Windows, it'll be like PowerShell or Command Prompt or Bash. If you're on Linux, you've got multiple shells installed, it'll ask. So as you can see, I've got it set up to use Bash. And you'll see it automatically goes to the directory that I'm in. So the main thing we wanted to do right now was find out what open underscore image is. So the only thing you need to know to do that is Ctrl-T. If you hit Ctrl-T, you can now type the name of a class, a function, pretty much anything, and you can find out about it. So open image, you can see it appears. And it's kind of cool if there's something that's got like camel case capitalized or something with underscore, you can just type the first few letters of each bit. So I could be like open image, for example. I do that, and it's found the function. It's also found some other things that match. There it is. So that's kind of a good way. You can see exactly where it's come from, and you can find out exactly what it is. And then the next thing I guess would be like, well, what's it used for? So if it's used inside Fast.ai, you could say find references, which is Shift-F12. Open image, Shift-F12. And it brings up something saying, oh, it's used twice in this code base. And I can go and I can have a look at each of those examples. If it's used in multiple different files, it'll tell you the multiple different files that it's used in. Another thing that's really handy then is as you look at the code, you'll find that certain bits of the code call other parts of the code. So for example, if you're inside files dataset, and you're like, oh, this is calling something called open image, what is that? Well, you can wave your pointer over it, and it'll give you the doc string. Or you can hit F12, and it jumps straight to its definition. So like often it's easy to get a bit lost in things call things call things, and if you have to manually go to each bit, it's infuriating. Whereas this way, it's always one button away. Control T to go to something that you specifically know the name of, or F12 to jump to the definition of something that you're clicking on. When you're done, you probably want to go back where you came from. So whatever you use, BIM, Emacs, Atom, whatever, they all have this functionality as long as you have an appropriate extension installed. If you use PyCharm, you can get that for free. That doesn't need any extensions because it's Python. Whatever you're using, you want to know how to do this stuff. Finally, I'll mention there's a nice thing called ZenMode, Control KZ, which basically gets rid of everything else so you can focus. But it does keep this nice little thing on the right-hand side, which kind of shows you where you're at. So that's something that you should practice if you haven't played around with it before during the week because we're increasingly going to be digging deeper and deeper into faster Ion PyTorch libraries. As I say, if you're already a professional coder, know all this stuff, apologies for telling you stuff you already know. So we're going to, well actually, since we did that, let's just talk about Open Image. You'll see that we're using CV2. CV2 is the library, is actually the OpenCV library. You might wonder why we're using OpenCV. And I want to explain some of the innards of Fast.ai to you because some of them are kind of interesting and might be helpful to you. The standard PyTorchVision library actually uses PyTorch tenses for all of its data augmentation and stuff like that. A lot of people use Pillow, the standard Python limiting library. I did a lot of testing of all of these. I found OpenCV was about 5-10 times faster than TorchVision. So early on, I actually teamed up with one of the students from an earlier class to do the Planet Labs satellite competition back when that was on. And we used TorchVision and because it was so slow, we could only get like 25% GPU utilization because we were doing a lot of data augmentation. And so then I used the profiler to find out what was going on and realized it was all in TorchVision. Pillow or PIL is quite a bit faster, but it's not as fast as OpenCV. It also is not nearly as thread safe. So I actually talked to the guy who developed the thing that, Python has this thing called the global interpreter lock, which basically means that two threads can't do Pythonic things at the same time. It makes Python a really shitty language actually for modern programming, but we're stuck with it. So I spoke to the guy on Twitter who actually made it so that OpenCV releases the GIL. So one of the reasons the fast AL library is so amazingly fast is because we don't use multiple processes like every other library does for our data augmentation. We actually do multiple threads. And the reason we can do multiple threads is because we use OpenCV. Unfortunately OpenCV is like a really shitty API, it's kind of inscrutable, a lot of stuff it does is poorly documented. When I say poorly documented, it's documented, but like in really obtuse kind of ways. So that's why I try to make it so like no one using fast AI needs to know that it's using OpenCV. Like if you want to open an image, do you really need to know that you have to pass these flags to open to actually make it work? Do you actually need to know that if the reading fails, it doesn't show an exception, it just silently returns none? It's these kinds of things that we try to do to actually make it work nicely. But as you start to dig into it, you'll find yourself in these places and you'll want to know why. And I mention this in particular to say, don't start using, you know, high torch your data augmentation, don't start bringing in pillow, you'll find suddenly things slow down horribly or the multi-threading won't work anymore or whatever. I try to stick to using OpenCV for your processing. Okay, so we've got our image, we're just going to use it to demonstrate the Pascal library. And so the next thing I wanted to show you in terms of like important coding stuff we're going to be using throughout this course is using Matplotlib a lot better. So Matplotlib is so named because it was originally a clone of Matlab's plotting library. Unfortunately, Matlab's plotting library is awful. But at the time, it was what everybody knew. So at some point, the Matplotlib folks realized, or they probably always knew, that the Matlab plotting library is awful. So they added a second API to it, which was an object-oriented API. Unfortunately, because nobody who originally learned Matplotlib learned the OO API, they then taught the next generation of people the old Matlab-style API. And now there's basically no examples or tutorials online I'm aware of that use the much, much better, easier to understand, simpler OO API. So one of the things I'm going to try and show you, because plotting is so important in deep learning, is how to use this API. And I've discovered some simple little tricks. One simple little trick is plot.subplots is just a super handy wrapper. I'm going to use it lots, right? And what it does is it returns two things. One of the things you probably won't care about. The other thing is an axes object. And basically anywhere where you used to say plt.something, you now say ax.something, and it will now do that plotting to that particular subplot. So a lot of the time you'll use this, or I'll use this during this course, to kind of plot multiple plots that we can compare next to each other. But even in this case, I'm creating a single plot. But it's just nice to only know one thing, rather than lots of things. So regardless of whether you're doing one plot or lots of plots, I always start now with this, plot.subplots. And the nice thing is that this way I can pass in an axes object if I want to plot it into a figure I've already created, or if it hasn't been passed in, I can create one. So this is also a nice way to make your matplotlib functions really versatile. You'll kind of see this used throughout this course. So now rather than plot.imshow, it's ax.imshow. And then rather than kind of weird stateful setting things in the odd-style API, you can now use OOs, get access that returns an object, set visible, sets a property. It's all pretty normal, straightforward stuff. So once you start getting the hang of a small number of these OO matplotlib things, hopefully you'll find life a lot easier. So I'm going to show you a few right now. So let me show you a cool example, what I think is a cool example. So one thing that kind of drives me crazy with people putting text on images, whether it be subtitles on TV, or people doing stuff with computer vision, is that it's like white text on a white background, or black text on a dark background, and you can't read it. And so a really simple thing that I like to do every time I draw on an image is to either make my text and boxes white with a little black border, or vice versa. And so here's a cool little thing you can do in matplotlib. You can take a matplotlib plotting object, and you can go set path effects, and say add a black stroke around it. And you can see that then when you draw that, it doesn't matter that here it's white on a white background, or here it's on a black background, it's equally visible. And I know it's a simple little thing, but it kind of just makes life so much better when you can actually see your bounding boxes and actually read the text. So you can see, rather than just saying add a rectangle, I get the object that it creates, and then pass that object to draw an outline. Now everything I do, I'm going to get this nice path effect on it. You can see matplotlib is a perfectly convenient way of drawing stuff. So when I want to draw a rectangle, matplotlib calls that a patch, and then you can pass in all different kinds of patches. So here's, again, rather than having to remember all that every time, please stick it in a function. And now you can use that function every time. You don't have to put it in a library somewhere. I always put lots of functions inside my notebook. If I use it in like 3 notebooks, then I know it's useful enough that I'll stick it in a separate library. You can draw text. And notice all of these take an axis object, so this is always going to be added to whatever thing I want to add it to. So I can add text, and draw an outline around it. So having done all that, I can now take my show image, and notice here the show image, if you didn't pass it an axis, it returns the axis it created. So show image returns the axis that image is on, I then turn my bounding box into height and width for this particular image's bounding box. I can then draw the rectangle. I can then draw the text in the top left corner, so remember the bounding box x and y are the first 2 coordinates, so b, colon, 2 is the top left. This is the, remember the tuple contains 2 things, the bounding box and then the class, so this is the class. And then to get the text of it, I just pass it into my categories list, and there we go. So now that I've got all that set up, I can use that for all of my object detection stuff from here on. What I really want to do though is to package all that up, so here it is, packaging it all up, so here's something that draws an image with some annotations, so it shows the image, it goes through each annotation, turns it into height and width, draws a rectangle, draws a text. If you haven't seen this before, each annotation remember contains a bounding box and a class, so rather than going for O in ANN and then going O0, O1, I can destructure it. This is a destructuring assignment, so if you put something, something on the left, then that's going to put the 2 parts of a tuple or a list into those 2 things. So for the bounding box and the class in the annotations, go ahead and do all that, and so then I can then say, okay, draw an image at a particular index by grabbing the image ID, opening it up, and then calling that draw, and so it's tested out, and there it is. So that kind of seems like quite a few steps, but to me, when you're working with a new dataset, getting to the point that you can rapidly explore it, it pays off. You'll see as we start building our model, we're going to keep using these functions now to kind of see how things are going. So step 1 from our presentation is to do a classifier. And so I think it's always good, like for me, I didn't really have much experience before I started preparing this course a few months ago in doing this kind of object detection stuff, so I was like, alright, I want to get this feeling of, even though it's deep learning, of continual progress. So I'm like, what can I make work? I thought, alright, why don't I find the biggest object in each image and classify it. I know how to do that. So it's like, this is one of the biggest problems I find, particularly with the younger students, is they figure out the whole big solution they want, generally which involves a whole lot of new speculative ideas that nobody's ever tried before, and they spend 6 months doing it, and then the day before the presentation, none of it works, and they're screwed. Where else, like I've talked about my approach to Kaggle competitions before, which is like half an hour every day. At the end of that half an hour, submit something, and try and make it a little bit better than yesterday's. So I've kind of tried to do the same thing in preparing this lesson, which is try to create something that's a bit better than the last thing. So the easiest thing I could come up with was my largest item classifier. So the first thing I needed to do was to go through each of the bounding boxes in an image and get the largest one. So I actually didn't write that first, I actually wrote this first. So normally I pretend that somebody else has created the exact API I want, and then go back and write it. So I wrote this line first, and it's like, okay I need something which takes all of the bounding boxes for a particular image and finds the largest, and well, that's pretty straightforward. I can just sort the bounding boxes, and here again we've got a lambda function. So again, if you haven't used lambda functions before, this is something you should study during the week. They're used all over the place to quickly define a function, like a once-off function. And in this case, the Python built-in sorted function lets you pass in a function to say how do you decide whether something's earlier or later in the sort order. And so in this case, I took the product of the last two items of my bounding box list, i.e. the bottom right-hand corner, minus the first two items of my bounding box list, i.e. the top left corner. So bottom right minus top left is the size, the two sizes, and if you take the product of those two things, you get the size of the bounding box. And so then that's the function, do that in descending order. I mean often you can take something that's going to be a few lines of code and turn it into one line of code, and sometimes you can take that too far, but for me, I like to do that where I reasonably can, because again, it means rather than having to understand a whole big chain of things, my brain can just say, I can just look at that at once and say, okay, there it is. And also I find that over time, my brain kind of builds up this little library of idioms, you know, and more and more things I can look at a single line and know what's going on. So this now is a dictionary, and it's a dictionary because this is a dictionary comprehension. A dictionary comprehension is just like a list comprehension. I'm going to use it a lot in this part of the course, except it goes inside curly brackets and it's got a key colon value. So here the key is going to be the image ID and the value is the largest bound box. So now that we've got that, we can look at an example. And here's an example of the largest bounding box for this image. So obviously there's a lot of objects here. 3 bicycles and 3 people, but here's the largest bounding box. I feel like this ought to go without saying, but it definitely needs to be said because so many people don't do it. You need to look at every stage when you've got any kind of processing pipeline, if you're as bad at coding as I am, everything you do will be wrong the first time you do it. But there's lots of people that are as bad as me at coding, and yet lots of people write lines and lines of code assuming they're all correct, and then at the very end they've got a mistake and they don't know where it came from. Particularly when you're working with images or text, things that humans can look at and understand, keep looking at it. So here I have it, that looks like the biggest thing, and that certainly looks like a person. So let's move on. Here's another nice thing in pathlib, make directory. So that's a handy little method. So I'm going to create a path called CSV, which is a path to my large objects CSV file. Why am I going to create a CSV file? Pure laziness, right? We have an image classifier.from.csv. I could go through a whole lot of work to create a custom data set and blah blah blah to use this particular format I have. But why? You know, it's so easy to create the CSV, chuck it inside a temporary folder, and then use something that already has. So this is kind of something I've seen a lot of times on the forum, is people will say like how do I convert this weird structure into a way that fast AI can accept it, and then normally somebody on the forum will say like print it to a CSV file. So that's a good simple tip. And the easiest way to create a CSV file is to create a pandas data frame. So here's my pandas data frame. I can just give it a dictionary with the name of a column and the list of things in that column, so there's the file name, there's the category, and then you'll see here why do I have this? I've already named the columns in the dictionary, why is it here? Because the order of columns matters, and a dictionary does not have an order. So this says the file name comes first and the category comes second. So that's a good trick to creating your CSVs. So now it's just dogs and cats. I have a CSV file, it contains a bunch of file names, and for each one it contains the plus of that object. So this is the same two lines of code you've seen a thousand times. What we will do though is to take a look at this. The one thing that's different is crop type. So you might remember the default strategy for creating a 224x224 image in Fast AI is to first of all resize it so the largest side, sorry the smallest side is 224, and then to take a random crop, assuming it's rectangular, a random square crop during training, and then during validation we take the center crop unless we use data augmentation, in which case we do a few random crops. For bounding boxes we don't want to do that because unlike an image net where the thing we care about is pretty much in the middle and it's pretty big, a lot of the stuff in object detection is quite small and close to the edge. So we could crop it out and that would be bad. So when you create your transforms you can choose crop type equals crop type.no, and no means don't crop, and therefore to make it square instead it squishes it. So you'll see this guy now looks kind of a bit strangely wide, and that's because he's been squished like this rather than cropped. Generally speaking a lot of computer vision models work a little bit better if you crop rather than squish, but they still work pretty well if you squish. In this case we definitely don't want to crop, so this is perfectly fine. If you had very long or very tall images, such that if a human looked at the squashed version and thought that looks really weird, then that might be difficult to model. But in this case we're just like, looks a little bit strange, but it's fine. So the computer won't mind. Okay, so I'm going to kind of quite often just dig a little bit into some more depths of fast AI in PyTorch, and in this case I want to just look at data loaders a little bit more. So you already know that, let's just make sure this is all run, so you already know that inside a model data object, there's lots of model data subclasses like image classifier data, we have a bunch of things which include a training data loader and a training data set. And we'll talk much more about this soon. But the main thing to know about a data loader is that it's an iterator, that each time you grab the next iteration of stuff from it, you get a mini-batch. And the mini-batch you get is of whatever size you asked for, and by default the batch size is 64. You can ask for whatever you like. However, in Python, the way you grab the next thing from an iterator is with next, but you can't just do that. Why can't you just do that? The reason you can't do that is because you need to say, start a new epoch now. In general, this isn't just in PyTorch, but for any Python iterator, you kind of need to say, start at the beginning of the sequence please. And so the way you do that, and this is a general Python concept, is you write iter. And iter says, please grab an iterator out of this object. Specifically, as we'll learn later, it means this class has to have defined an __iter__method, which returns some different object, which then has an __next__method. So that's how I do that. And so if you want to grab just a single batch, this is how you do it. x, y equals next, iter, data loader. x, y because our data loaders, our data sets behind the data loaders always have an x, the independent, and a y, the dependent variable. So here we can grab a mini-batch of x's and y's. And now I'm going to pass that to that show image command we had earlier. But we can't send that straight to show image. For example, here it is. For one thing, it's not a NumPy array, it's not on the CPU, and its shape is all wrong. It's not 224x224x3, it's 3x224x224. Furthermore, these are not numbers between 0 and 1. Why not? Because remember, all of the standard ImageNet pre-trained models expect our data to have been normalized to have a 0 mean and a 1 standard deviation. So if you look inside, let's use Visual Studio code for this, since that's what we've been doing. So if you look inside, transformsFromModel, so Ctrl T, transformsFromModel, TFM, which in turn calls transforms, so F12. And here you can see normalize, and it normalizes with some set of image statistics, and the set of image statistics, they're basically hard-coded. This is the ImageNet statistics, this is statistics used for inception models. So there's a whole bunch of stuff that's been done to the input to get it ready to be passed to a pre-trained model. So we have a function called denorm for denormalize. It doesn't only denormalize, it also fixes up the dimension order and all that stuff. And the denormalization depends on the transform. And the dataset knows what transform was used to create it, so that's why you have to go modelData.and then someDataSet.denorm, and that's a function that's stored for you that will undo everything. And then you can pass that, a mini-batch, but you have to turn it into NumPy first. So this is like all the stuff that you need to be able to do to grab batches and look at them. And so after you've done all that, you can show the image and we've got back our list. So that's looking good. So in the end, we've just got the standard 4 lines of code. We've got our transforms, we've got our modelData, convoluna.pre-trained, we're using a ResNet34 here, we're going to add accuracy as a metric, fix some optimization function, do an LR find, and that looks kind of weird, not particularly helpful. Normally we would expect to see an uptick on the right. The reason we don't see it is because we intentionally remove the first few points and the last few points. The reason is that often the last few points shoot so high up towards infinity that you basically can't see anything. So the vast majority of the time, removing the last few points is a good idea. However, when you've got very few mini-batches, sometimes it's not a good idea. And so a lot of people ask this on the forum, here's how you fix it. Just say skip, by default it skips 10 at the start, so in this case we just say 5, by default it skips 5 at the end, we'll just say 1. So now we can see the shape properly. If your dataset's really tiny, you may need to use a smaller batch size. Like if you only have 3 or 4 batches worth, there's nothing to see. But in this case, it's fine, we just have to plot a little bit more. So we pick our learning rate, we say fit, after one epoch, just training the last layer, it's 80%. Let's unfreeze a couple of layers, do another epoch, 82%. Freeze the whole thing, not really improving. Why are we stuck at 80%? It kind of makes sense, right? Unlike ImageNet or Dogs vs Cats where each image has one major thing, they were picked because they have one major thing, and the one major thing is what you're asked to look for, a lot of the Pascal dataset has lots of little things. And so a largest classifier is not necessarily going to do great. But of course, we really need to be able to see the results, to see whether it makes sense. So we're going to write something that creates this. And in this case, I'm kind of like, after working with this a while, I know what the 20 Pascal classes are. So I know there's a person and a bicycle class, I know there's a dog and a sofa class, so I know this is wrong, it should be sofa, but that's correct. Bird, yes, yes. Chair, that's wrong. I think the table is bigger. Motorbike is correct because there's no cactus. That should be a bus. Person is correct. Bird is correct. Car is correct. Plant is correct. Car is correct. So it's looking pretty good. So when you see a piece of code like this, if you're not familiar with all the steps to get there, it can be a little overwhelming. And I feel the same way when I see a few lines of code and something I'm not familiar with, I feel overwhelmed as well. But it turns out there's two ways to make it super, super simple to understand the code. Or there's one high-level way. The high-level way is run each line of code step at step, print out the inputs, print out the outputs. Most of the time, that'll be enough. If there's a line of code where you don't understand how the outputs relate to the inputs, go and have a look for the source. So now all you need to know is what are the two ways you can step through the lines of code one at a time. The way I use perhaps the most often is to take the contents of the loop, copy it, create a cell above it, paste it, outdent it, write i equals 0, and then put them all in separate cells and then run each one one at a time, printing out the input samples. I know that's obvious, but the number of times I actually see people do that when they ask me for help is basically zero, because if they had done that, they wouldn't be asking for help. Another method that's super handy, and there's particular situations where it's super super handy, is to use the Python debugger. Who here has used a debugger before? So half to two-thirds. So for the other half of you, this will be life-changing. Actually a guy I know this morning who's actually a deep learning researcher wrote on Twitter and his message on Twitter was, how come nobody told me about the Python debugger before my life has changed? And like this guy's an expert, but because nobody teaches basic software engineering skills in academic courses, nobody thought to say to him, hey Mark, do you know what? There's something that shows you everything your code does one step at a time. So I replied on Twitter and I said, good news Mark, not only that, every single language in existence in every single operating system also has a debugger, and if you Google for language name debugger, it will tell you how to use it. So there's a meta piece of information for you. In Python, the standard debugger is called PDB. And there's two main ways to use it. The first is to go into your code, and the reason I'm mentioning this now is because during the next few weeks, if you're anything like me, 99% of the time you'll be in a situation where your code's not working. And very often it'll have been on the 14th mini-batch inside the forward method of your custom module. It's like, what do you do? And the answer is, you go inside your module and you write that. And if you know it's only happening on the 14th iteration, you type if i equals 13. So you can set a conditional breakpoint. PDB is the Python debugger, fastai imports it for you, if you get the message that PDB is not there, then you can just say import PDB. So let's try that. It's not the most user-friendly experience. It just pops up a box. But the first cool thing to notice is, holy shit, the debugger even works in a notebook. So that's pretty nifty. It'll also work in the terminal. And so what can you do? You can type h for help. And there are plenty of tutorials here. The main thing to know is this is one of these situations where you definitely want to know the one-letter mnemonics. So you could type next, but you definitely want to type in. You could type continue, but you definitely want to type c. I've listed the main ones you need. So what I can do now that I'm sitting here is, it shows me the line, it's about to run. So one thing I might want to do is to print out something. And I can write any Python expression and hit enter and find it. So that's a useful thing to do. I might want to find out more about, where am I in the code more generally? I just want to see this line, but what's the before it and after it? In this case I want l for list. And so you can see I'm about to run that line. These are the lines above it and below it. So I might be now like, okay, let's run this line and see what happens. So go to the next line, hit n. And you can see now it's about to run the next line. One handy tip, you don't even have to type n. If you just hit enter, it repeats the last thing you did. So I now should have a thing called b. Unfortunately, single letters are often used for debugger commands. So if I just type b, it'll run the b command rather than print b for me. So to force it to print, you use p. Print b. So there's a bird. All right, fine, let's do next again. At this point, if I hit next, it'll draw the text. But I don't want to just draw the text. I want to know how it's going to draw the text. So I don't want to go next over it. I want to s-step into it. So if I now hit s-step into it, I'm now inside drawText. And I now hit n. I can see drawText and so forth. And then I'm like, okay, I know everything I want to know about this. I will continue until I hit the next breakpoint. So c will continue until I'm back at the breakpoint again. What if I was zipping along, and this happens quite often, that like, let's step into denorm. Here I am inside denorm. And what will often happen is if you're debugging something in your PyTorch module, and it's hit an exception, and you're trying to debug, you'll find yourself like 6 layers deep inside PyTorch. But you want to actually see back up what's happening where you called it from. So in this case, I'm inside this property, but I actually want to know what was going on up the call stack. I just hit u, and that doesn't actually run anything. It just changes the context of the debugger to show me what called it. And now I can type, you know, things to find out about that environment. And then if I'm going to go down again, it's d. So I'm not going to show you everything about the debugger, but I just showed you all of those commands. Right? Yes, Aza? Something that we found helpful as we've been doing this is using from ipython.core.debugger imports that trace, and then you get it all prettily colored. You do indeed. Excellent tip. Let's learn about some of our students here. Aza, tell us, I know you're doing an interesting project. Can you tell us about it? Hello, everyone. I'm Aza, here with my collaborator, Britt, and we're using this kind of stuff to try to build a Google Translate for animal communication. So that involves playing around a lot with unsupervised machine neural translation and doing it on top of audio. Where do you get data for that from? That's sort of the hard problem. So there you have to go and we're talking to a number of researchers to try to collect and collate large data sets, but if we can't get it that way, we're thinking about building a living library of the audio of the species of Earth. That involves going out and collecting 100,000 hours of gelato monkey vocalizations. I didn't know that. That's kind of cool. All right. That's great. So let's get rid of that set trace. The other place that the debugger comes in, particularly handy, is, as I say, if you've got an exception. Particularly if it's deep inside Pipeswatch. So if I went i times 100 here, obviously that's going to be an exception. I've got rid of the set trace. So if I run this now, something's wrong. Now in this case, it's easy to see what's wrong. But often it's not, so what do I do? I run the debug, pops open the debugger, at the point the exception happens. So now I can check, okay, preds dot, well, I don't know, len preds 64, i times 100, got to print that because i is a command, 100, oh, no wonder. You can go down, you can go up, you can list, whatever. So I do all of my development, both of the library and of the lessons in Jupyter Notebook. I do it all interactively, and I use percent debug all the time, along with this idea of copying stuff out of a function and putting it into separate cells, running it step by step. There are similar things you can do inside, for example, Visual Studio Code. There's actually a Jupyter extension, which lets you select any line of code inside Visual Studio Code, and it'll say run in Jupyter, and it'll run it in Jupyter and create a little window showing you the output. There's neat little stuff like that. Personally, I think Jupyter Notebook is better. And perhaps by the time you watch this on the video, Jupyter Lab will be the main thing. Jupyter Lab is like the next version of Jupyter Notebook, but pretty similar. Wow, I just broke it totally. We know exactly how to fix it, so we'll worry about that another time. We'll debug it this evening. So to kind of do the next stage, we want to create the bounding box. And now creating the bounding box around the largest object may seem like something you haven't done before, but actually it's totally something you've done before. And the reason it's something you've done before is we know that we can create a regression rather than a classification neural net. In other words, a classification neural net is just one that has a sigmoid or softmax output and that we use a cross-entropy or binary cross-entropy negative log likelihood loss function. That's basically what makes it a classifier. If we don't have the softmax of sigmoid at the end, and we use mean squared error as a loss function, it's now a regression model. So we can now use it to predict a continuous number rather than a category. We also know that we can have multiple outputs, like in the planet competition we did a multiple object classification. What if we combine the two ideas and do a multiple column regression? So in this case we've got 4 numbers, top, left, x, and y, bottom, right, x, and y, and we could create a neural net with 4 activations. We could have no softmax or sigmoid and use a mean squared error loss function. And this is kind of like where you're thinking about it like differentiable programming. It's not like how do I create a bounding box model. It's like, alright, what do I need? I need 4 numbers. Therefore I need a neural network with 4 activations. That's half of what I need to know. The other half I need to know is a loss function. In other words, what's a function that when it is lower means that the 4 numbers are better? Because if I can do those 2 things, I'm done. Well if the x is close to the first activation and the y is close to the second and so forth, then I'm done. So that's it. I just need to create a model with 4 activations with a mean squared error loss function and that should be it. Right? Like we don't need anything new. So let's try it. So again, we'll use a CSV. And if you remember from part 1, to do a multiple label classification, your multiple labels have to be space-separated and then your file name is comma-separated. So I'll take my largest item dictionary, create a bunch of bounding boxes for each one separated by a space using a list comprehension. I'll then create a data frame like I did before. I'll turn that into a CSV and now I've got something that's got the file name and the 4 bounding box coordinates. I will then pass that to from CSV. Again I will use crop type equals crop type.no. Next week we'll look at transform type.coordinate. For now just realize that when we're doing scaling and data augmentation, that needs to happen to the bounding boxes, not just to the images. With classifier data.csv, it gets us to a situation where we can now grab one mini-batch of data, we can denormalize it, we can turn the bounding box back into a height width so that we can show it, and here it is. Remember we're not doing classification so I don't know what kind of thing this is, it's just a thing, but there is the thing. So I now want to create a convnet based on resnet34, but I don't want to add the standard set of fully connected layers that create a classifier. I want to just add a single linear layer with 4 outputs. So Fast.ai has this concept of a custom head. If you say my model has a custom head, the head being the thing that's added to the top of the model, then it's not going to create any of that fully connected network for you, it's not going to add the adaptive average pooling for you, but instead it will add whatever model you ask for. So in this case I've created a tiny model, it's a model that flattens out the previous layer. So remember normally you would have a 7x7x512 previous layer in resnet34, so it just flattens that out into a single vector of length 25088, and then I just add a linear layer that goes from 25088 to 4. There's my 4 output. So that's the simplest possible final layer you could add. I stick that on top of my pre-trained resnet34 model, so this is exactly the same as usual except I've just got this custom head. Optimize it with Adam, use a criteria. I'm actually not going to use MSC, I'm going to use L1 loss. So I can't remember if we covered this last week, we can revise it next week if we didn't, but L1 loss means rather than adding up the squared errors, add up the absolute values of the errors. So it's like it's normally actually what you want. Adding up the squared errors really penalizes bad misses by too much. So L1 loss is generally better to work with. Okay, I'll come back to this next week, but basically you can see what we do now is we do our LR find, find our learning rate, learn for a while, freeze2-2, learn a bit more, freeze2-3, learn a bit more, and you can see this validation loss, which remember is the absolute value, mean of the absolute value of pixels we're off by gets lower and lower, and then when we're done, we can print out the bounding boxes, and lo and behold, it's done a damn good job. So we'll revise this a bit more next week, but you can see this idea of like if I said to you before this class, do you know how to create a bounding box model, you might have said, no, nobody's taught me that. But the question actually is, can you create a model with 4 continuous outputs? Yes. Can you create a loss function that is lower if those 4 outputs are near to 4 other numbers? Yes. Then you're done. Now you'll see if I scroll a bit further down, it starts looking a bit crappy any time we've got more than one object. And that's not surprising. Because how the hell do you decide which bird, so it's just said I'll just pick the middle, which cow, I'll pick the middle. How much of this is actually potted plant, I'll pick the middle. This one it could probably improve, but it's got close to the car, but it's a pretty weird car. But nonetheless, for the ones that are reasonably clear, I would say it's done a pretty good job. So that's time for this week. I think it's been a kind of gentle introduction for the first lesson. If you're a professional coder, there's probably not heaps of new stuff here for you. And so in that case I would suggest practicing learning about bounding boxes and stuff. If you aren't so experienced with things like debuggers and matplotlib API and stuff like that, there's going to be a lot for you to practice, because we're going to be really assuming you know it well from next week. Thanks everybody, see you next Monday.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.82, "text": " Welcome to part 2 of Deep Learning for Coders.", "tokens": [4027, 281, 644, 568, 295, 14895, 15205, 337, 383, 378, 433, 13], "temperature": 0.0, "avg_logprob": -0.21964791241814108, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.004005563911050558}, {"id": 1, "seek": 0, "start": 7.82, "end": 10.38, "text": " Part 1 was Practical Deep Learning for Coders.", "tokens": [4100, 502, 390, 19170, 804, 14895, 15205, 337, 383, 378, 433, 13], "temperature": 0.0, "avg_logprob": -0.21964791241814108, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.004005563911050558}, {"id": 2, "seek": 0, "start": 10.38, "end": 16.68, "text": " Part 2 is not Impractical Deep Learning for Coders, but it is a little different as we'll", "tokens": [4100, 568, 307, 406, 4331, 42559, 804, 14895, 15205, 337, 383, 378, 433, 11, 457, 309, 307, 257, 707, 819, 382, 321, 603], "temperature": 0.0, "avg_logprob": -0.21964791241814108, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.004005563911050558}, {"id": 3, "seek": 0, "start": 16.68, "end": 17.68, "text": " discuss.", "tokens": [2248, 13], "temperature": 0.0, "avg_logprob": -0.21964791241814108, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.004005563911050558}, {"id": 4, "seek": 0, "start": 17.68, "end": 24.02, "text": " This is probably a really dumb idea, but last year I started not starting part 2 with part", "tokens": [639, 307, 1391, 257, 534, 10316, 1558, 11, 457, 1036, 1064, 286, 1409, 406, 2891, 644, 568, 365, 644], "temperature": 0.0, "avg_logprob": -0.21964791241814108, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.004005563911050558}, {"id": 5, "seek": 0, "start": 24.02, "end": 29.66, "text": " 2 lesson 1, but part 2 lesson 8 because it's kind of part of the same sequence.", "tokens": [568, 6898, 502, 11, 457, 644, 568, 6898, 1649, 570, 309, 311, 733, 295, 644, 295, 264, 912, 8310, 13], "temperature": 0.0, "avg_logprob": -0.21964791241814108, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.004005563911050558}, {"id": 6, "seek": 2966, "start": 29.66, "end": 34.96, "text": " So I've done that again, but sometimes I'll probably forget and call things lesson 1.", "tokens": [407, 286, 600, 1096, 300, 797, 11, 457, 2171, 286, 603, 1391, 2870, 293, 818, 721, 6898, 502, 13], "temperature": 0.0, "avg_logprob": -0.12950928631950828, "compression_ratio": 1.6076555023923444, "no_speech_prob": 9.169713302981108e-05}, {"id": 7, "seek": 2966, "start": 34.96, "end": 39.96, "text": " So part 2 lesson 1 and part 2 lesson 8 are the same thing if I ever make that mistake.", "tokens": [407, 644, 568, 6898, 502, 293, 644, 568, 6898, 1649, 366, 264, 912, 551, 498, 286, 1562, 652, 300, 6146, 13], "temperature": 0.0, "avg_logprob": -0.12950928631950828, "compression_ratio": 1.6076555023923444, "no_speech_prob": 9.169713302981108e-05}, {"id": 8, "seek": 2966, "start": 39.96, "end": 45.28, "text": " So we're going to be talking about object detection today, which refers to not just", "tokens": [407, 321, 434, 516, 281, 312, 1417, 466, 2657, 17784, 965, 11, 597, 14942, 281, 406, 445], "temperature": 0.0, "avg_logprob": -0.12950928631950828, "compression_ratio": 1.6076555023923444, "no_speech_prob": 9.169713302981108e-05}, {"id": 9, "seek": 2966, "start": 45.28, "end": 51.120000000000005, "text": " finding out what a picture is a picture of, but also whereabouts that thing is.", "tokens": [5006, 484, 437, 257, 3036, 307, 257, 3036, 295, 11, 457, 611, 689, 41620, 300, 551, 307, 13], "temperature": 0.0, "avg_logprob": -0.12950928631950828, "compression_ratio": 1.6076555023923444, "no_speech_prob": 9.169713302981108e-05}, {"id": 10, "seek": 5112, "start": 51.12, "end": 60.76, "text": " But in general, the idea of each lesson in this part is not so much because I particularly", "tokens": [583, 294, 2674, 11, 264, 1558, 295, 1184, 6898, 294, 341, 644, 307, 406, 370, 709, 570, 286, 4098], "temperature": 0.0, "avg_logprob": -0.11220439476302907, "compression_ratio": 1.6111111111111112, "no_speech_prob": 3.26985573337879e-05}, {"id": 11, "seek": 5112, "start": 60.76, "end": 66.67999999999999, "text": " want you to care about object detection, but rather because I'm trying to pick topics which", "tokens": [528, 291, 281, 1127, 466, 2657, 17784, 11, 457, 2831, 570, 286, 478, 1382, 281, 1888, 8378, 597], "temperature": 0.0, "avg_logprob": -0.11220439476302907, "compression_ratio": 1.6111111111111112, "no_speech_prob": 3.26985573337879e-05}, {"id": 12, "seek": 5112, "start": 66.67999999999999, "end": 72.08, "text": " allow me to teach you some foundational skills that you haven't got yet.", "tokens": [2089, 385, 281, 2924, 291, 512, 32195, 3942, 300, 291, 2378, 380, 658, 1939, 13], "temperature": 0.0, "avg_logprob": -0.11220439476302907, "compression_ratio": 1.6111111111111112, "no_speech_prob": 3.26985573337879e-05}, {"id": 13, "seek": 5112, "start": 72.08, "end": 80.0, "text": " So for example, object detection is going to be all about creating much richer convolutional", "tokens": [407, 337, 1365, 11, 2657, 17784, 307, 516, 281, 312, 439, 466, 4084, 709, 29021, 45216, 304], "temperature": 0.0, "avg_logprob": -0.11220439476302907, "compression_ratio": 1.6111111111111112, "no_speech_prob": 3.26985573337879e-05}, {"id": 14, "seek": 8000, "start": 80.0, "end": 85.08, "text": " network structures which have a lot more interesting stuff going on, and a lot more stuff going", "tokens": [3209, 9227, 597, 362, 257, 688, 544, 1880, 1507, 516, 322, 11, 293, 257, 688, 544, 1507, 516], "temperature": 0.0, "avg_logprob": -0.20345124491938837, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.3922744730953127e-05}, {"id": 15, "seek": 8000, "start": 85.08, "end": 89.44, "text": " on in the fastai library that we have to customize to get there.", "tokens": [322, 294, 264, 2370, 1301, 6405, 300, 321, 362, 281, 19734, 281, 483, 456, 13], "temperature": 0.0, "avg_logprob": -0.20345124491938837, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.3922744730953127e-05}, {"id": 16, "seek": 8000, "start": 89.44, "end": 95.0, "text": " So at the end of these 7 weeks, I can't possibly cover the hundreds of interesting things that", "tokens": [407, 412, 264, 917, 295, 613, 1614, 3259, 11, 286, 393, 380, 6264, 2060, 264, 6779, 295, 1880, 721, 300], "temperature": 0.0, "avg_logprob": -0.20345124491938837, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.3922744730953127e-05}, {"id": 17, "seek": 8000, "start": 95.0, "end": 98.48, "text": " people are doing with deep learning right now.", "tokens": [561, 366, 884, 365, 2452, 2539, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.20345124491938837, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.3922744730953127e-05}, {"id": 18, "seek": 8000, "start": 98.48, "end": 104.28, "text": " But the good news is that all of those hundreds of things you'll see once you read the papers,", "tokens": [583, 264, 665, 2583, 307, 300, 439, 295, 729, 6779, 295, 721, 291, 603, 536, 1564, 291, 1401, 264, 10577, 11], "temperature": 0.0, "avg_logprob": -0.20345124491938837, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.3922744730953127e-05}, {"id": 19, "seek": 8000, "start": 104.28, "end": 108.48, "text": " like minor tweaks on a reasonably small number of concepts.", "tokens": [411, 6696, 46664, 322, 257, 23551, 1359, 1230, 295, 10392, 13], "temperature": 0.0, "avg_logprob": -0.20345124491938837, "compression_ratio": 1.7509578544061302, "no_speech_prob": 2.3922744730953127e-05}, {"id": 20, "seek": 10848, "start": 108.48, "end": 112.80000000000001, "text": " So we covered a bunch of those concepts in part 1, and we're going to go a lot deeper", "tokens": [407, 321, 5343, 257, 3840, 295, 729, 10392, 294, 644, 502, 11, 293, 321, 434, 516, 281, 352, 257, 688, 7731], "temperature": 0.0, "avg_logprob": -0.17704145431518556, "compression_ratio": 1.7104072398190044, "no_speech_prob": 8.664258530188818e-06}, {"id": 21, "seek": 10848, "start": 112.80000000000001, "end": 120.16, "text": " into those concepts and build on them to get to some deeper concepts in part 2.", "tokens": [666, 729, 10392, 293, 1322, 322, 552, 281, 483, 281, 512, 7731, 10392, 294, 644, 568, 13], "temperature": 0.0, "avg_logprob": -0.17704145431518556, "compression_ratio": 1.7104072398190044, "no_speech_prob": 8.664258530188818e-06}, {"id": 22, "seek": 10848, "start": 120.16, "end": 128.6, "text": " So in terms of what we covered in part 1, there's a few key takeaways.", "tokens": [407, 294, 2115, 295, 437, 321, 5343, 294, 644, 502, 11, 456, 311, 257, 1326, 2141, 45584, 13], "temperature": 0.0, "avg_logprob": -0.17704145431518556, "compression_ratio": 1.7104072398190044, "no_speech_prob": 8.664258530188818e-06}, {"id": 23, "seek": 10848, "start": 128.6, "end": 132.32, "text": " We'll go through each of these takeaways in turn.", "tokens": [492, 603, 352, 807, 1184, 295, 613, 45584, 294, 1261, 13], "temperature": 0.0, "avg_logprob": -0.17704145431518556, "compression_ratio": 1.7104072398190044, "no_speech_prob": 8.664258530188818e-06}, {"id": 24, "seek": 10848, "start": 132.32, "end": 137.84, "text": " One is the idea, and you might have seen recently Jan Lekoon's been promoting the idea that", "tokens": [1485, 307, 264, 1558, 11, 293, 291, 1062, 362, 1612, 3938, 4956, 441, 916, 4106, 311, 668, 16383, 264, 1558, 300], "temperature": 0.0, "avg_logprob": -0.17704145431518556, "compression_ratio": 1.7104072398190044, "no_speech_prob": 8.664258530188818e-06}, {"id": 25, "seek": 13784, "start": 137.84, "end": 143.16, "text": " we don't call this deep learning, but differentiable programming.", "tokens": [321, 500, 380, 818, 341, 2452, 2539, 11, 457, 819, 9364, 9410, 13], "temperature": 0.0, "avg_logprob": -0.1551931484325512, "compression_ratio": 1.5824742268041236, "no_speech_prob": 2.178237264160998e-05}, {"id": 26, "seek": 13784, "start": 143.16, "end": 149.72, "text": " And the idea is that you'll have noticed all the stuff we did in part 1 was really about", "tokens": [400, 264, 1558, 307, 300, 291, 603, 362, 5694, 439, 264, 1507, 321, 630, 294, 644, 502, 390, 534, 466], "temperature": 0.0, "avg_logprob": -0.1551931484325512, "compression_ratio": 1.5824742268041236, "no_speech_prob": 2.178237264160998e-05}, {"id": 27, "seek": 13784, "start": 149.72, "end": 157.46, "text": " setting up a differentiable function and a loss function that describes how good the", "tokens": [3287, 493, 257, 819, 9364, 2445, 293, 257, 4470, 2445, 300, 15626, 577, 665, 264], "temperature": 0.0, "avg_logprob": -0.1551931484325512, "compression_ratio": 1.5824742268041236, "no_speech_prob": 2.178237264160998e-05}, {"id": 28, "seek": 13784, "start": 157.46, "end": 164.32, "text": " parameters are, and then pressing go, and it kind of makes it work.", "tokens": [9834, 366, 11, 293, 550, 12417, 352, 11, 293, 309, 733, 295, 1669, 309, 589, 13], "temperature": 0.0, "avg_logprob": -0.1551931484325512, "compression_ratio": 1.5824742268041236, "no_speech_prob": 2.178237264160998e-05}, {"id": 29, "seek": 16432, "start": 164.32, "end": 168.68, "text": " And so I think it's quite a good way of thinking about it, differentiable programming, this", "tokens": [400, 370, 286, 519, 309, 311, 1596, 257, 665, 636, 295, 1953, 466, 309, 11, 819, 9364, 9410, 11, 341], "temperature": 0.0, "avg_logprob": -0.13143876158160928, "compression_ratio": 1.5904761904761904, "no_speech_prob": 1.0451346497575287e-05}, {"id": 30, "seek": 16432, "start": 168.68, "end": 178.16, "text": " idea that if you can configure a loss function that describes, scores how good something", "tokens": [1558, 300, 498, 291, 393, 22162, 257, 4470, 2445, 300, 15626, 11, 13444, 577, 665, 746], "temperature": 0.0, "avg_logprob": -0.13143876158160928, "compression_ratio": 1.5904761904761904, "no_speech_prob": 1.0451346497575287e-05}, {"id": 31, "seek": 16432, "start": 178.16, "end": 184.32, "text": " is at doing your task, and you have a reasonably flexible neural network architecture, you're", "tokens": [307, 412, 884, 428, 5633, 11, 293, 291, 362, 257, 23551, 11358, 18161, 3209, 9482, 11, 291, 434], "temperature": 0.0, "avg_logprob": -0.13143876158160928, "compression_ratio": 1.5904761904761904, "no_speech_prob": 1.0451346497575287e-05}, {"id": 32, "seek": 16432, "start": 184.32, "end": 186.76, "text": " kind of done.", "tokens": [733, 295, 1096, 13], "temperature": 0.0, "avg_logprob": -0.13143876158160928, "compression_ratio": 1.5904761904761904, "no_speech_prob": 1.0451346497575287e-05}, {"id": 33, "seek": 16432, "start": 186.76, "end": 190.0, "text": " So that's one key way of thinking about this.", "tokens": [407, 300, 311, 472, 2141, 636, 295, 1953, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.13143876158160928, "compression_ratio": 1.5904761904761904, "no_speech_prob": 1.0451346497575287e-05}, {"id": 34, "seek": 19000, "start": 190.0, "end": 195.28, "text": " This example here comes from playground.tensorflow.org, which is a cool website where you can play", "tokens": [639, 1365, 510, 1487, 490, 24646, 13, 83, 23153, 10565, 13, 4646, 11, 597, 307, 257, 1627, 3144, 689, 291, 393, 862], "temperature": 0.0, "avg_logprob": -0.14856968463306697, "compression_ratio": 1.5825242718446602, "no_speech_prob": 6.339092124107992e-06}, {"id": 35, "seek": 19000, "start": 195.28, "end": 204.48, "text": " interactively with creating your own little differentiable functions manually.", "tokens": [4648, 3413, 365, 4084, 428, 1065, 707, 819, 9364, 6828, 16945, 13], "temperature": 0.0, "avg_logprob": -0.14856968463306697, "compression_ratio": 1.5825242718446602, "no_speech_prob": 6.339092124107992e-06}, {"id": 36, "seek": 19000, "start": 204.48, "end": 209.04, "text": " The second thing then we learned is about transfer learning.", "tokens": [440, 1150, 551, 550, 321, 3264, 307, 466, 5003, 2539, 13], "temperature": 0.0, "avg_logprob": -0.14856968463306697, "compression_ratio": 1.5825242718446602, "no_speech_prob": 6.339092124107992e-06}, {"id": 37, "seek": 19000, "start": 209.04, "end": 215.6, "text": " And it's basically that transfer learning is the most important single thing to be able", "tokens": [400, 309, 311, 1936, 300, 5003, 2539, 307, 264, 881, 1021, 2167, 551, 281, 312, 1075], "temperature": 0.0, "avg_logprob": -0.14856968463306697, "compression_ratio": 1.5825242718446602, "no_speech_prob": 6.339092124107992e-06}, {"id": 38, "seek": 21560, "start": 215.6, "end": 220.48, "text": " to do to use deep learning effectively.", "tokens": [281, 360, 281, 764, 2452, 2539, 8659, 13], "temperature": 0.0, "avg_logprob": -0.1514129520934305, "compression_ratio": 1.7009803921568627, "no_speech_prob": 2.812993670886499e-06}, {"id": 39, "seek": 21560, "start": 220.48, "end": 226.48, "text": " Nearly all courses, nearly all papers, nearly everything in deep learning, education and", "tokens": [38000, 439, 7712, 11, 6217, 439, 10577, 11, 6217, 1203, 294, 2452, 2539, 11, 3309, 293], "temperature": 0.0, "avg_logprob": -0.1514129520934305, "compression_ratio": 1.7009803921568627, "no_speech_prob": 2.812993670886499e-06}, {"id": 40, "seek": 21560, "start": 226.48, "end": 235.95999999999998, "text": " research focuses on starting with random weights, which is ridiculous because you almost never", "tokens": [2132, 16109, 322, 2891, 365, 4974, 17443, 11, 597, 307, 11083, 570, 291, 1920, 1128], "temperature": 0.0, "avg_logprob": -0.1514129520934305, "compression_ratio": 1.7009803921568627, "no_speech_prob": 2.812993670886499e-06}, {"id": 41, "seek": 21560, "start": 235.95999999999998, "end": 238.72, "text": " would want to or need to do that.", "tokens": [576, 528, 281, 420, 643, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.1514129520934305, "compression_ratio": 1.7009803921568627, "no_speech_prob": 2.812993670886499e-06}, {"id": 42, "seek": 21560, "start": 238.72, "end": 244.88, "text": " You would only want to or need to do that if nobody had ever trained a model on a vaguely", "tokens": [509, 576, 787, 528, 281, 420, 643, 281, 360, 300, 498, 5079, 632, 1562, 8895, 257, 2316, 322, 257, 13501, 48863], "temperature": 0.0, "avg_logprob": -0.1514129520934305, "compression_ratio": 1.7009803921568627, "no_speech_prob": 2.812993670886499e-06}, {"id": 43, "seek": 24488, "start": 244.88, "end": 251.68, "text": " similar set of data with an even remotely connected kind of problem to solve as what", "tokens": [2531, 992, 295, 1412, 365, 364, 754, 20824, 4582, 733, 295, 1154, 281, 5039, 382, 437], "temperature": 0.0, "avg_logprob": -0.1866015996018501, "compression_ratio": 1.527363184079602, "no_speech_prob": 2.9022733087913366e-06}, {"id": 44, "seek": 24488, "start": 251.68, "end": 258.0, "text": " you're doing now, which almost never happens.", "tokens": [291, 434, 884, 586, 11, 597, 1920, 1128, 2314, 13], "temperature": 0.0, "avg_logprob": -0.1866015996018501, "compression_ratio": 1.527363184079602, "no_speech_prob": 2.9022733087913366e-06}, {"id": 45, "seek": 24488, "start": 258.0, "end": 264.36, "text": " So this is where the Fast.ai library and the stuff we talk about in this class is vastly", "tokens": [407, 341, 307, 689, 264, 15968, 13, 1301, 6405, 293, 264, 1507, 321, 751, 466, 294, 341, 1508, 307, 41426], "temperature": 0.0, "avg_logprob": -0.1866015996018501, "compression_ratio": 1.527363184079602, "no_speech_prob": 2.9022733087913366e-06}, {"id": 46, "seek": 24488, "start": 264.36, "end": 270.84, "text": " different to any other library or course, is that it's all focused on transfer learning", "tokens": [819, 281, 604, 661, 6405, 420, 1164, 11, 307, 300, 309, 311, 439, 5178, 322, 5003, 2539], "temperature": 0.0, "avg_logprob": -0.1866015996018501, "compression_ratio": 1.527363184079602, "no_speech_prob": 2.9022733087913366e-06}, {"id": 47, "seek": 27084, "start": 270.84, "end": 276.0, "text": " and it turns out that you do a lot of things quite differently.", "tokens": [293, 309, 4523, 484, 300, 291, 360, 257, 688, 295, 721, 1596, 7614, 13], "temperature": 0.0, "avg_logprob": -0.12084720611572265, "compression_ratio": 1.6754385964912282, "no_speech_prob": 8.267788871307857e-06}, {"id": 48, "seek": 27084, "start": 276.0, "end": 281.71999999999997, "text": " So the basic idea of transfer learning is here's a network that does thing A, remove", "tokens": [407, 264, 3875, 1558, 295, 5003, 2539, 307, 510, 311, 257, 3209, 300, 775, 551, 316, 11, 4159], "temperature": 0.0, "avg_logprob": -0.12084720611572265, "compression_ratio": 1.6754385964912282, "no_speech_prob": 8.267788871307857e-06}, {"id": 49, "seek": 27084, "start": 281.71999999999997, "end": 289.71999999999997, "text": " the last layer or so, replace it with a few random layers at the end, fine-tune those", "tokens": [264, 1036, 4583, 420, 370, 11, 7406, 309, 365, 257, 1326, 4974, 7914, 412, 264, 917, 11, 2489, 12, 83, 2613, 729], "temperature": 0.0, "avg_logprob": -0.12084720611572265, "compression_ratio": 1.6754385964912282, "no_speech_prob": 8.267788871307857e-06}, {"id": 50, "seek": 27084, "start": 289.71999999999997, "end": 296.47999999999996, "text": " layers to do thing B, taking advantage of the features that the original network learned,", "tokens": [7914, 281, 360, 551, 363, 11, 1940, 5002, 295, 264, 4122, 300, 264, 3380, 3209, 3264, 11], "temperature": 0.0, "avg_logprob": -0.12084720611572265, "compression_ratio": 1.6754385964912282, "no_speech_prob": 8.267788871307857e-06}, {"id": 51, "seek": 27084, "start": 296.47999999999996, "end": 299.88, "text": " and then optionally fine-tune the whole thing end-to-end.", "tokens": [293, 550, 3614, 379, 2489, 12, 83, 2613, 264, 1379, 551, 917, 12, 1353, 12, 521, 13], "temperature": 0.0, "avg_logprob": -0.12084720611572265, "compression_ratio": 1.6754385964912282, "no_speech_prob": 8.267788871307857e-06}, {"id": 52, "seek": 29988, "start": 299.88, "end": 305.12, "text": " And you've now got something which probably uses orders of magnitude less data than if", "tokens": [400, 291, 600, 586, 658, 746, 597, 1391, 4960, 9470, 295, 15668, 1570, 1412, 813, 498], "temperature": 0.0, "avg_logprob": -0.2354920088355221, "compression_ratio": 1.4814814814814814, "no_speech_prob": 2.7264459276921116e-06}, {"id": 53, "seek": 29988, "start": 305.12, "end": 312.56, "text": " you started with random weights, it's probably a lot more accurate and probably trained a", "tokens": [291, 1409, 365, 4974, 17443, 11, 309, 311, 1391, 257, 688, 544, 8559, 293, 1391, 8895, 257], "temperature": 0.0, "avg_logprob": -0.2354920088355221, "compression_ratio": 1.4814814814814814, "no_speech_prob": 2.7264459276921116e-06}, {"id": 54, "seek": 29988, "start": 312.56, "end": 319.44, "text": " lot faster.", "tokens": [688, 4663, 13], "temperature": 0.0, "avg_logprob": -0.2354920088355221, "compression_ratio": 1.4814814814814814, "no_speech_prob": 2.7264459276921116e-06}, {"id": 55, "seek": 29988, "start": 319.44, "end": 325.76, "text": " We didn't talk a hell of a lot about architecture design in part 1, and that's because kind", "tokens": [492, 994, 380, 751, 257, 4921, 295, 257, 688, 466, 9482, 1715, 294, 644, 502, 11, 293, 300, 311, 570, 733], "temperature": 0.0, "avg_logprob": -0.2354920088355221, "compression_ratio": 1.4814814814814814, "no_speech_prob": 2.7264459276921116e-06}, {"id": 56, "seek": 32576, "start": 325.76, "end": 330.0, "text": " of architecture design is getting less and less interesting.", "tokens": [295, 9482, 1715, 307, 1242, 1570, 293, 1570, 1880, 13], "temperature": 0.0, "avg_logprob": -0.17710175571671452, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.0952976481348742e-05}, {"id": 57, "seek": 32576, "start": 330.0, "end": 336.96, "text": " There's a pretty small range of architectures that generally work pretty well quite a lot", "tokens": [821, 311, 257, 1238, 1359, 3613, 295, 6331, 1303, 300, 5101, 589, 1238, 731, 1596, 257, 688], "temperature": 0.0, "avg_logprob": -0.17710175571671452, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.0952976481348742e-05}, {"id": 58, "seek": 32576, "start": 336.96, "end": 338.08, "text": " of the time.", "tokens": [295, 264, 565, 13], "temperature": 0.0, "avg_logprob": -0.17710175571671452, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.0952976481348742e-05}, {"id": 59, "seek": 32576, "start": 338.08, "end": 347.88, "text": " We've been focusing on using CNNs for generally fixed-size, somehow ordered data, RNNs for", "tokens": [492, 600, 668, 8416, 322, 1228, 24859, 82, 337, 5101, 6806, 12, 27553, 11, 6063, 8866, 1412, 11, 45702, 45, 82, 337], "temperature": 0.0, "avg_logprob": -0.17710175571671452, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.0952976481348742e-05}, {"id": 60, "seek": 32576, "start": 347.88, "end": 354.2, "text": " sequences that have some kind of state, fiddling around a tiny bit with activation functions", "tokens": [22978, 300, 362, 512, 733, 295, 1785, 11, 283, 14273, 1688, 926, 257, 5870, 857, 365, 24433, 6828], "temperature": 0.0, "avg_logprob": -0.17710175571671452, "compression_ratio": 1.591743119266055, "no_speech_prob": 1.0952976481348742e-05}, {"id": 61, "seek": 35420, "start": 354.2, "end": 361.0, "text": " like softmax if you've got a single categorical outcome, sigmoid if you've got multiple outcomes,", "tokens": [411, 2787, 41167, 498, 291, 600, 658, 257, 2167, 19250, 804, 9700, 11, 4556, 3280, 327, 498, 291, 600, 658, 3866, 10070, 11], "temperature": 0.0, "avg_logprob": -0.2171883288724923, "compression_ratio": 1.6168224299065421, "no_speech_prob": 9.080353265744634e-06}, {"id": 62, "seek": 35420, "start": 361.0, "end": 363.84, "text": " and so forth.", "tokens": [293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.2171883288724923, "compression_ratio": 1.6168224299065421, "no_speech_prob": 9.080353265744634e-06}, {"id": 63, "seek": 35420, "start": 363.84, "end": 369.15999999999997, "text": " Some of the architecture design we'll be doing in this part gets kind of more interesting,", "tokens": [2188, 295, 264, 9482, 1715, 321, 603, 312, 884, 294, 341, 644, 2170, 733, 295, 544, 1880, 11], "temperature": 0.0, "avg_logprob": -0.2171883288724923, "compression_ratio": 1.6168224299065421, "no_speech_prob": 9.080353265744634e-06}, {"id": 64, "seek": 35420, "start": 369.15999999999997, "end": 373.2, "text": " particularly this first session about object detection.", "tokens": [4098, 341, 700, 5481, 466, 2657, 17784, 13], "temperature": 0.0, "avg_logprob": -0.2171883288724923, "compression_ratio": 1.6168224299065421, "no_speech_prob": 9.080353265744634e-06}, {"id": 65, "seek": 35420, "start": 373.2, "end": 378.4, "text": " But on the whole, I think we probably spend less time talking about architecture design", "tokens": [583, 322, 264, 1379, 11, 286, 519, 321, 1391, 3496, 1570, 565, 1417, 466, 9482, 1715], "temperature": 0.0, "avg_logprob": -0.2171883288724923, "compression_ratio": 1.6168224299065421, "no_speech_prob": 9.080353265744634e-06}, {"id": 66, "seek": 37840, "start": 378.4, "end": 387.4, "text": " than most courses or papers because it's generally not the hard bit.", "tokens": [813, 881, 7712, 420, 10577, 570, 309, 311, 5101, 406, 264, 1152, 857, 13], "temperature": 0.0, "avg_logprob": -0.19081680194751635, "compression_ratio": 1.530612244897959, "no_speech_prob": 1.1659348274406511e-05}, {"id": 67, "seek": 37840, "start": 387.4, "end": 391.71999999999997, "text": " The third thing we looked at was how to avoid overfitting.", "tokens": [440, 2636, 551, 321, 2956, 412, 390, 577, 281, 5042, 670, 69, 2414, 13], "temperature": 0.0, "avg_logprob": -0.19081680194751635, "compression_ratio": 1.530612244897959, "no_speech_prob": 1.1659348274406511e-05}, {"id": 68, "seek": 37840, "start": 391.71999999999997, "end": 398.35999999999996, "text": " The general idea that I tried to explain is the way I like to build a model is to first", "tokens": [440, 2674, 1558, 300, 286, 3031, 281, 2903, 307, 264, 636, 286, 411, 281, 1322, 257, 2316, 307, 281, 700], "temperature": 0.0, "avg_logprob": -0.19081680194751635, "compression_ratio": 1.530612244897959, "no_speech_prob": 1.1659348274406511e-05}, {"id": 69, "seek": 37840, "start": 398.35999999999996, "end": 404.15999999999997, "text": " of all create something that's definitely terribly overparameterized, will massively", "tokens": [295, 439, 1884, 746, 300, 311, 2138, 22903, 670, 2181, 335, 2398, 1602, 11, 486, 29379], "temperature": 0.0, "avg_logprob": -0.19081680194751635, "compression_ratio": 1.530612244897959, "no_speech_prob": 1.1659348274406511e-05}, {"id": 70, "seek": 40416, "start": 404.16, "end": 408.72, "text": " overfit for sure, train it and make sure it does overfit.", "tokens": [670, 6845, 337, 988, 11, 3847, 309, 293, 652, 988, 309, 775, 670, 6845, 13], "temperature": 0.0, "avg_logprob": -0.17225060896439987, "compression_ratio": 1.8679245283018868, "no_speech_prob": 2.2473714125226252e-05}, {"id": 71, "seek": 40416, "start": 408.72, "end": 413.20000000000005, "text": " At that point, you know, I've got a model that is capable of reflecting the training", "tokens": [1711, 300, 935, 11, 291, 458, 11, 286, 600, 658, 257, 2316, 300, 307, 8189, 295, 23543, 264, 3097], "temperature": 0.0, "avg_logprob": -0.17225060896439987, "compression_ratio": 1.8679245283018868, "no_speech_prob": 2.2473714125226252e-05}, {"id": 72, "seek": 40416, "start": 413.20000000000005, "end": 414.20000000000005, "text": " set.", "tokens": [992, 13], "temperature": 0.0, "avg_logprob": -0.17225060896439987, "compression_ratio": 1.8679245283018868, "no_speech_prob": 2.2473714125226252e-05}, {"id": 73, "seek": 40416, "start": 414.20000000000005, "end": 420.56, "text": " And then it's as simple as doing these things to then reduce that overfitting.", "tokens": [400, 550, 309, 311, 382, 2199, 382, 884, 613, 721, 281, 550, 5407, 300, 670, 69, 2414, 13], "temperature": 0.0, "avg_logprob": -0.17225060896439987, "compression_ratio": 1.8679245283018868, "no_speech_prob": 2.2473714125226252e-05}, {"id": 74, "seek": 40416, "start": 420.56, "end": 425.84000000000003, "text": " If you don't start with something that's overfitting, then you're kind of lost.", "tokens": [759, 291, 500, 380, 722, 365, 746, 300, 311, 670, 69, 2414, 11, 550, 291, 434, 733, 295, 2731, 13], "temperature": 0.0, "avg_logprob": -0.17225060896439987, "compression_ratio": 1.8679245283018868, "no_speech_prob": 2.2473714125226252e-05}, {"id": 75, "seek": 40416, "start": 425.84000000000003, "end": 430.12, "text": " So you start with something that's overfitting, and then to make it overfit less, you can", "tokens": [407, 291, 722, 365, 746, 300, 311, 670, 69, 2414, 11, 293, 550, 281, 652, 309, 670, 6845, 1570, 11, 291, 393], "temperature": 0.0, "avg_logprob": -0.17225060896439987, "compression_ratio": 1.8679245283018868, "no_speech_prob": 2.2473714125226252e-05}, {"id": 76, "seek": 43012, "start": 430.12, "end": 439.76, "text": " add more data, you can add more data augmentation, you can do things like more batch norm layers", "tokens": [909, 544, 1412, 11, 291, 393, 909, 544, 1412, 14501, 19631, 11, 291, 393, 360, 721, 411, 544, 15245, 2026, 7914], "temperature": 0.0, "avg_logprob": -0.14518691398002007, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.241137579199858e-05}, {"id": 77, "seek": 43012, "start": 439.76, "end": 446.36, "text": " or dense nets or various things that can handle less data.", "tokens": [420, 18011, 36170, 420, 3683, 721, 300, 393, 4813, 1570, 1412, 13], "temperature": 0.0, "avg_logprob": -0.14518691398002007, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.241137579199858e-05}, {"id": 78, "seek": 43012, "start": 446.36, "end": 451.24, "text": " You can add regularization like weight decay and dropout.", "tokens": [509, 393, 909, 3890, 2144, 411, 3364, 21039, 293, 3270, 346, 13], "temperature": 0.0, "avg_logprob": -0.14518691398002007, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.241137579199858e-05}, {"id": 79, "seek": 43012, "start": 451.24, "end": 455.36, "text": " And then finally, this is often the thing people do first, but this should be the thing", "tokens": [400, 550, 2721, 11, 341, 307, 2049, 264, 551, 561, 360, 700, 11, 457, 341, 820, 312, 264, 551], "temperature": 0.0, "avg_logprob": -0.14518691398002007, "compression_ratio": 1.6722222222222223, "no_speech_prob": 1.241137579199858e-05}, {"id": 80, "seek": 45536, "start": 455.36, "end": 467.6, "text": " you do last, is reduce the complexity of your architecture, have less layers or less activations.", "tokens": [291, 360, 1036, 11, 307, 5407, 264, 14024, 295, 428, 9482, 11, 362, 1570, 7914, 420, 1570, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.1367355225578187, "compression_ratio": 1.4333333333333333, "no_speech_prob": 3.5008199574804166e-06}, {"id": 81, "seek": 45536, "start": 467.6, "end": 474.44, "text": " We talked quite a bit about embeddings, both for NLP and the general idea of any kind of", "tokens": [492, 2825, 1596, 257, 857, 466, 12240, 29432, 11, 1293, 337, 426, 45196, 293, 264, 2674, 1558, 295, 604, 733, 295], "temperature": 0.0, "avg_logprob": -0.1367355225578187, "compression_ratio": 1.4333333333333333, "no_speech_prob": 3.5008199574804166e-06}, {"id": 82, "seek": 45536, "start": 474.44, "end": 478.44, "text": " category of data as being something you can now model with neural nets.", "tokens": [7719, 295, 1412, 382, 885, 746, 291, 393, 586, 2316, 365, 18161, 36170, 13], "temperature": 0.0, "avg_logprob": -0.1367355225578187, "compression_ratio": 1.4333333333333333, "no_speech_prob": 3.5008199574804166e-06}, {"id": 83, "seek": 47844, "start": 478.44, "end": 485.6, "text": " It's been interesting to see how since part 1 came out, at which point there were almost", "tokens": [467, 311, 668, 1880, 281, 536, 577, 1670, 644, 502, 1361, 484, 11, 412, 597, 935, 456, 645, 1920], "temperature": 0.0, "avg_logprob": -0.14515276590983073, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.048848263162654e-06}, {"id": 84, "seek": 47844, "start": 485.6, "end": 494.4, "text": " no examples of papers or blogs or anything about using tabular data or categorical data", "tokens": [572, 5110, 295, 10577, 420, 31038, 420, 1340, 466, 1228, 4421, 1040, 1412, 420, 19250, 804, 1412], "temperature": 0.0, "avg_logprob": -0.14515276590983073, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.048848263162654e-06}, {"id": 85, "seek": 47844, "start": 494.4, "end": 501.08, "text": " in deep learning, suddenly it's kind of taken off and it's kind of everywhere.", "tokens": [294, 2452, 2539, 11, 5800, 309, 311, 733, 295, 2726, 766, 293, 309, 311, 733, 295, 5315, 13], "temperature": 0.0, "avg_logprob": -0.14515276590983073, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.048848263162654e-06}, {"id": 86, "seek": 47844, "start": 501.08, "end": 505.04, "text": " So this is becoming a more and more popular approach.", "tokens": [407, 341, 307, 5617, 257, 544, 293, 544, 3743, 3109, 13], "temperature": 0.0, "avg_logprob": -0.14515276590983073, "compression_ratio": 1.537313432835821, "no_speech_prob": 6.048848263162654e-06}, {"id": 87, "seek": 50504, "start": 505.04, "end": 511.88, "text": " It's still little enough known that when I say to people, we use neural nets for time", "tokens": [467, 311, 920, 707, 1547, 2570, 300, 562, 286, 584, 281, 561, 11, 321, 764, 18161, 36170, 337, 565], "temperature": 0.0, "avg_logprob": -0.2777172187706093, "compression_ratio": 1.4813084112149533, "no_speech_prob": 2.355218748562038e-05}, {"id": 88, "seek": 50504, "start": 511.88, "end": 516.96, "text": " series and tabular data analysis, it's often like, wait, really?", "tokens": [2638, 293, 4421, 1040, 1412, 5215, 11, 309, 311, 2049, 411, 11, 1699, 11, 534, 30], "temperature": 0.0, "avg_logprob": -0.2777172187706093, "compression_ratio": 1.4813084112149533, "no_speech_prob": 2.355218748562038e-05}, {"id": 89, "seek": 50504, "start": 516.96, "end": 520.6, "text": " But it's definitely not such a far out idea.", "tokens": [583, 309, 311, 2138, 406, 1270, 257, 1400, 484, 1558, 13], "temperature": 0.0, "avg_logprob": -0.2777172187706093, "compression_ratio": 1.4813084112149533, "no_speech_prob": 2.355218748562038e-05}, {"id": 90, "seek": 50504, "start": 520.6, "end": 527.8000000000001, "text": " There are more and more resources available, including recent Kaggle competition winning", "tokens": [821, 366, 544, 293, 544, 3593, 2435, 11, 3009, 5162, 48751, 22631, 6211, 8224], "temperature": 0.0, "avg_logprob": -0.2777172187706093, "compression_ratio": 1.4813084112149533, "no_speech_prob": 2.355218748562038e-05}, {"id": 91, "seek": 50504, "start": 527.8000000000001, "end": 533.2, "text": " approaches using this technique.", "tokens": [11587, 1228, 341, 6532, 13], "temperature": 0.0, "avg_logprob": -0.2777172187706093, "compression_ratio": 1.4813084112149533, "no_speech_prob": 2.355218748562038e-05}, {"id": 92, "seek": 53320, "start": 533.2, "end": 542.2800000000001, "text": " So part 1, which particularly had those 5 messages, really was all about introducing", "tokens": [407, 644, 502, 11, 597, 4098, 632, 729, 1025, 7897, 11, 534, 390, 439, 466, 15424], "temperature": 0.0, "avg_logprob": -0.15217528051259566, "compression_ratio": 1.3647798742138364, "no_speech_prob": 2.9479826935130404e-06}, {"id": 93, "seek": 53320, "start": 542.2800000000001, "end": 547.08, "text": " you to best practices in deep learning.", "tokens": [291, 281, 1151, 7525, 294, 2452, 2539, 13], "temperature": 0.0, "avg_logprob": -0.15217528051259566, "compression_ratio": 1.3647798742138364, "no_speech_prob": 2.9479826935130404e-06}, {"id": 94, "seek": 53320, "start": 547.08, "end": 557.32, "text": " And so it's like trying to show you techniques which were mature enough that they definitely", "tokens": [400, 370, 309, 311, 411, 1382, 281, 855, 291, 7512, 597, 645, 14442, 1547, 300, 436, 2138], "temperature": 0.0, "avg_logprob": -0.15217528051259566, "compression_ratio": 1.3647798742138364, "no_speech_prob": 2.9479826935130404e-06}, {"id": 95, "seek": 55732, "start": 557.32, "end": 566.36, "text": " work reasonably reliably for practical real-world problems, and that I had researched and tuned", "tokens": [589, 23551, 49927, 337, 8496, 957, 12, 13217, 2740, 11, 293, 300, 286, 632, 37098, 293, 10870], "temperature": 0.0, "avg_logprob": -0.22518435944902135, "compression_ratio": 1.6708860759493671, "no_speech_prob": 4.0928484850155655e-06}, {"id": 96, "seek": 55732, "start": 566.36, "end": 570.9200000000001, "text": " enough over a quite long period of time that I could kind of say, here's a sequence of", "tokens": [1547, 670, 257, 1596, 938, 2896, 295, 565, 300, 286, 727, 733, 295, 584, 11, 510, 311, 257, 8310, 295], "temperature": 0.0, "avg_logprob": -0.22518435944902135, "compression_ratio": 1.6708860759493671, "no_speech_prob": 4.0928484850155655e-06}, {"id": 97, "seek": 55732, "start": 570.9200000000001, "end": 576.9200000000001, "text": " steps and architectures and whatever, if you use this, you'll almost certainly get pretty", "tokens": [4439, 293, 6331, 1303, 293, 2035, 11, 498, 291, 764, 341, 11, 291, 603, 1920, 3297, 483, 1238], "temperature": 0.0, "avg_logprob": -0.22518435944902135, "compression_ratio": 1.6708860759493671, "no_speech_prob": 4.0928484850155655e-06}, {"id": 98, "seek": 55732, "start": 576.9200000000001, "end": 583.6, "text": " good results, and then kind of put that into the fast AI library in a way that you could", "tokens": [665, 3542, 11, 293, 550, 733, 295, 829, 300, 666, 264, 2370, 7318, 6405, 294, 257, 636, 300, 291, 727], "temperature": 0.0, "avg_logprob": -0.22518435944902135, "compression_ratio": 1.6708860759493671, "no_speech_prob": 4.0928484850155655e-06}, {"id": 99, "seek": 55732, "start": 583.6, "end": 585.4000000000001, "text": " do that pretty quickly and easily.", "tokens": [360, 300, 1238, 2661, 293, 3612, 13], "temperature": 0.0, "avg_logprob": -0.22518435944902135, "compression_ratio": 1.6708860759493671, "no_speech_prob": 4.0928484850155655e-06}, {"id": 100, "seek": 58540, "start": 585.4, "end": 592.76, "text": " So that's kind of what practical deep learning for coders was designed to do.", "tokens": [407, 300, 311, 733, 295, 437, 8496, 2452, 2539, 337, 17656, 433, 390, 4761, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.15015838958404876, "compression_ratio": 1.6486486486486487, "no_speech_prob": 2.769379307210329e-06}, {"id": 101, "seek": 58540, "start": 592.76, "end": 597.0, "text": " So this part 2 is cutting edge deep learning for coders.", "tokens": [407, 341, 644, 568, 307, 6492, 4691, 2452, 2539, 337, 17656, 433, 13], "temperature": 0.0, "avg_logprob": -0.15015838958404876, "compression_ratio": 1.6486486486486487, "no_speech_prob": 2.769379307210329e-06}, {"id": 102, "seek": 58540, "start": 597.0, "end": 606.26, "text": " And what that means is, I often don't know the exact best parameters, architecture details", "tokens": [400, 437, 300, 1355, 307, 11, 286, 2049, 500, 380, 458, 264, 1900, 1151, 9834, 11, 9482, 4365], "temperature": 0.0, "avg_logprob": -0.15015838958404876, "compression_ratio": 1.6486486486486487, "no_speech_prob": 2.769379307210329e-06}, {"id": 103, "seek": 58540, "start": 606.26, "end": 608.8, "text": " and so forth to solve a particular problem.", "tokens": [293, 370, 5220, 281, 5039, 257, 1729, 1154, 13], "temperature": 0.0, "avg_logprob": -0.15015838958404876, "compression_ratio": 1.6486486486486487, "no_speech_prob": 2.769379307210329e-06}, {"id": 104, "seek": 58540, "start": 608.8, "end": 613.3199999999999, "text": " We don't necessarily know if it's going to solve a problem well enough to be practically", "tokens": [492, 500, 380, 4725, 458, 498, 309, 311, 516, 281, 5039, 257, 1154, 731, 1547, 281, 312, 15667], "temperature": 0.0, "avg_logprob": -0.15015838958404876, "compression_ratio": 1.6486486486486487, "no_speech_prob": 2.769379307210329e-06}, {"id": 105, "seek": 58540, "start": 613.3199999999999, "end": 615.18, "text": " useful.", "tokens": [4420, 13], "temperature": 0.0, "avg_logprob": -0.15015838958404876, "compression_ratio": 1.6486486486486487, "no_speech_prob": 2.769379307210329e-06}, {"id": 106, "seek": 61518, "start": 615.18, "end": 620.04, "text": " It almost certainly won't be integrated well enough into fast AI, or any library that you", "tokens": [467, 1920, 3297, 1582, 380, 312, 10919, 731, 1547, 666, 2370, 7318, 11, 420, 604, 6405, 300, 291], "temperature": 0.0, "avg_logprob": -0.16293920229559075, "compression_ratio": 1.4776119402985075, "no_speech_prob": 7.296287549252156e-06}, {"id": 107, "seek": 61518, "start": 620.04, "end": 624.0799999999999, "text": " can just press a few buttons and it'll start working.", "tokens": [393, 445, 1886, 257, 1326, 9905, 293, 309, 603, 722, 1364, 13], "temperature": 0.0, "avg_logprob": -0.16293920229559075, "compression_ratio": 1.4776119402985075, "no_speech_prob": 7.296287549252156e-06}, {"id": 108, "seek": 61518, "start": 624.0799999999999, "end": 631.8, "text": " It's all about stuff which I'm not going to teach it unless I'm very confident that it", "tokens": [467, 311, 439, 466, 1507, 597, 286, 478, 406, 516, 281, 2924, 309, 5969, 286, 478, 588, 6679, 300, 309], "temperature": 0.0, "avg_logprob": -0.16293920229559075, "compression_ratio": 1.4776119402985075, "no_speech_prob": 7.296287549252156e-06}, {"id": 109, "seek": 61518, "start": 631.8, "end": 638.9399999999999, "text": " either is now or will be soon a very practically useful technique.", "tokens": [2139, 307, 586, 420, 486, 312, 2321, 257, 588, 15667, 4420, 6532, 13], "temperature": 0.0, "avg_logprob": -0.16293920229559075, "compression_ratio": 1.4776119402985075, "no_speech_prob": 7.296287549252156e-06}, {"id": 110, "seek": 63894, "start": 638.94, "end": 646.44, "text": " So I don't take stuff which just appeared and I don't know enough about it to know what", "tokens": [407, 286, 500, 380, 747, 1507, 597, 445, 8516, 293, 286, 500, 380, 458, 1547, 466, 309, 281, 458, 437], "temperature": 0.0, "avg_logprob": -0.17830070341476287, "compression_ratio": 1.7244444444444444, "no_speech_prob": 1.0616025065246504e-05}, {"id": 111, "seek": 63894, "start": 646.44, "end": 647.5200000000001, "text": " the trajectory is going to be.", "tokens": [264, 21512, 307, 516, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.17830070341476287, "compression_ratio": 1.7244444444444444, "no_speech_prob": 1.0616025065246504e-05}, {"id": 112, "seek": 63894, "start": 647.5200000000001, "end": 655.08, "text": " So if I'm teaching it in this course, I'm saying this either works well in the research", "tokens": [407, 498, 286, 478, 4571, 309, 294, 341, 1164, 11, 286, 478, 1566, 341, 2139, 1985, 731, 294, 264, 2132], "temperature": 0.0, "avg_logprob": -0.17830070341476287, "compression_ratio": 1.7244444444444444, "no_speech_prob": 1.0616025065246504e-05}, {"id": 113, "seek": 63894, "start": 655.08, "end": 659.44, "text": " literature now and is going to be well worth learning about, or we're pretty close to being", "tokens": [10394, 586, 293, 307, 516, 281, 312, 731, 3163, 2539, 466, 11, 420, 321, 434, 1238, 1998, 281, 885], "temperature": 0.0, "avg_logprob": -0.17830070341476287, "compression_ratio": 1.7244444444444444, "no_speech_prob": 1.0616025065246504e-05}, {"id": 114, "seek": 63894, "start": 659.44, "end": 666.2, "text": " there, but it's going to take a lot of tweaking often and experimenting to get it to work", "tokens": [456, 11, 457, 309, 311, 516, 281, 747, 257, 688, 295, 6986, 2456, 2049, 293, 29070, 281, 483, 309, 281, 589], "temperature": 0.0, "avg_logprob": -0.17830070341476287, "compression_ratio": 1.7244444444444444, "no_speech_prob": 1.0616025065246504e-05}, {"id": 115, "seek": 66620, "start": 666.2, "end": 672.24, "text": " on your particular problem because we don't know the details well enough to know how to", "tokens": [322, 428, 1729, 1154, 570, 321, 500, 380, 458, 264, 4365, 731, 1547, 281, 458, 577, 281], "temperature": 0.0, "avg_logprob": -0.1598430906023298, "compression_ratio": 1.461139896373057, "no_speech_prob": 1.1125490345875733e-05}, {"id": 116, "seek": 66620, "start": 672.24, "end": 676.4000000000001, "text": " make it work for every dataset or every example.", "tokens": [652, 309, 589, 337, 633, 28872, 420, 633, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1598430906023298, "compression_ratio": 1.461139896373057, "no_speech_prob": 1.1125490345875733e-05}, {"id": 117, "seek": 66620, "start": 676.4000000000001, "end": 685.12, "text": " So it's kind of exciting to be working at this point.", "tokens": [407, 309, 311, 733, 295, 4670, 281, 312, 1364, 412, 341, 935, 13], "temperature": 0.0, "avg_logprob": -0.1598430906023298, "compression_ratio": 1.461139896373057, "no_speech_prob": 1.1125490345875733e-05}, {"id": 118, "seek": 66620, "start": 685.12, "end": 694.1400000000001, "text": " It means that rather than fast AI and PyTorch being obscure black boxes which you just know", "tokens": [467, 1355, 300, 2831, 813, 2370, 7318, 293, 9953, 51, 284, 339, 885, 34443, 2211, 9002, 597, 291, 445, 458], "temperature": 0.0, "avg_logprob": -0.1598430906023298, "compression_ratio": 1.461139896373057, "no_speech_prob": 1.1125490345875733e-05}, {"id": 119, "seek": 69414, "start": 694.14, "end": 700.88, "text": " these recipes for, you're going to learn the details of them well enough that you can customize", "tokens": [613, 13035, 337, 11, 291, 434, 516, 281, 1466, 264, 4365, 295, 552, 731, 1547, 300, 291, 393, 19734], "temperature": 0.0, "avg_logprob": -0.11050872343132295, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.5612557692511473e-06}, {"id": 120, "seek": 69414, "start": 700.88, "end": 706.24, "text": " them exactly the way you want, that you can debug them, that you can read the source code", "tokens": [552, 2293, 264, 636, 291, 528, 11, 300, 291, 393, 24083, 552, 11, 300, 291, 393, 1401, 264, 4009, 3089], "temperature": 0.0, "avg_logprob": -0.11050872343132295, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.5612557692511473e-06}, {"id": 121, "seek": 69414, "start": 706.24, "end": 710.0, "text": " of them to see what's happening, and so forth.", "tokens": [295, 552, 281, 536, 437, 311, 2737, 11, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.11050872343132295, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.5612557692511473e-06}, {"id": 122, "seek": 69414, "start": 710.0, "end": 719.42, "text": " And so if you're not pretty confident of object-oriented Python and stuff like that, then that's something", "tokens": [400, 370, 498, 291, 434, 406, 1238, 6679, 295, 2657, 12, 27414, 15329, 293, 1507, 411, 300, 11, 550, 300, 311, 746], "temperature": 0.0, "avg_logprob": -0.11050872343132295, "compression_ratio": 1.661764705882353, "no_speech_prob": 2.5612557692511473e-06}, {"id": 123, "seek": 71942, "start": 719.42, "end": 727.56, "text": " you're going to want to focus on studying during this course, because we assume that,", "tokens": [291, 434, 516, 281, 528, 281, 1879, 322, 7601, 1830, 341, 1164, 11, 570, 321, 6552, 300, 11], "temperature": 0.0, "avg_logprob": -0.1700555071418668, "compression_ratio": 1.5490196078431373, "no_speech_prob": 1.0451397429278586e-05}, {"id": 124, "seek": 71942, "start": 727.56, "end": 731.8399999999999, "text": " I'm not going to be spending time on that.", "tokens": [286, 478, 406, 516, 281, 312, 6434, 565, 322, 300, 13], "temperature": 0.0, "avg_logprob": -0.1700555071418668, "compression_ratio": 1.5490196078431373, "no_speech_prob": 1.0451397429278586e-05}, {"id": 125, "seek": 71942, "start": 731.8399999999999, "end": 738.38, "text": " But I will be trying to introduce you to some tools that I think are particularly helpful,", "tokens": [583, 286, 486, 312, 1382, 281, 5366, 291, 281, 512, 3873, 300, 286, 519, 366, 4098, 4961, 11], "temperature": 0.0, "avg_logprob": -0.1700555071418668, "compression_ratio": 1.5490196078431373, "no_speech_prob": 1.0451397429278586e-05}, {"id": 126, "seek": 71942, "start": 738.38, "end": 743.5999999999999, "text": " like the Python debugger, like how to use your editor to jump through the code, stuff", "tokens": [411, 264, 15329, 24083, 1321, 11, 411, 577, 281, 764, 428, 9839, 281, 3012, 807, 264, 3089, 11, 1507], "temperature": 0.0, "avg_logprob": -0.1700555071418668, "compression_ratio": 1.5490196078431373, "no_speech_prob": 1.0451397429278586e-05}, {"id": 127, "seek": 71942, "start": 743.5999999999999, "end": 744.5999999999999, "text": " like that.", "tokens": [411, 300, 13], "temperature": 0.0, "avg_logprob": -0.1700555071418668, "compression_ratio": 1.5490196078431373, "no_speech_prob": 1.0451397429278586e-05}, {"id": 128, "seek": 74460, "start": 744.6, "end": 751.96, "text": " In fact, in general, there will be a lot more detailed specific code walkthroughs, coding", "tokens": [682, 1186, 11, 294, 2674, 11, 456, 486, 312, 257, 688, 544, 9942, 2685, 3089, 1792, 11529, 82, 11, 17720], "temperature": 0.0, "avg_logprob": -0.24014993361484857, "compression_ratio": 1.5980392156862746, "no_speech_prob": 2.4439661956421332e-06}, {"id": 129, "seek": 74460, "start": 751.96, "end": 760.9200000000001, "text": " technique discussions, as well as more detailed walkthroughs of papers and the math.", "tokens": [6532, 11088, 11, 382, 731, 382, 544, 9942, 1792, 11529, 82, 295, 10577, 293, 264, 5221, 13], "temperature": 0.0, "avg_logprob": -0.24014993361484857, "compression_ratio": 1.5980392156862746, "no_speech_prob": 2.4439661956421332e-06}, {"id": 130, "seek": 74460, "start": 760.9200000000001, "end": 767.24, "text": " And so anytime we cover one of these things, if you notice something where you're like,", "tokens": [400, 370, 13038, 321, 2060, 472, 295, 613, 721, 11, 498, 291, 3449, 746, 689, 291, 434, 411, 11], "temperature": 0.0, "avg_logprob": -0.24014993361484857, "compression_ratio": 1.5980392156862746, "no_speech_prob": 2.4439661956421332e-06}, {"id": 131, "seek": 74460, "start": 767.24, "end": 772.1600000000001, "text": " this is assuming some knowledge that I don't have, that's fine.", "tokens": [341, 307, 11926, 512, 3601, 300, 286, 500, 380, 362, 11, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.24014993361484857, "compression_ratio": 1.5980392156862746, "no_speech_prob": 2.4439661956421332e-06}, {"id": 132, "seek": 77216, "start": 772.16, "end": 778.26, "text": " It just means that's something you could ask on the forum and say, hey, Jeremy was talking", "tokens": [467, 445, 1355, 300, 311, 746, 291, 727, 1029, 322, 264, 17542, 293, 584, 11, 4177, 11, 17809, 390, 1417], "temperature": 0.0, "avg_logprob": -0.2615145547049386, "compression_ratio": 1.6612244897959183, "no_speech_prob": 9.665905054134782e-06}, {"id": 133, "seek": 77216, "start": 778.26, "end": 785.36, "text": " about static methods in Python, I don't really know what a static method is, or why he was", "tokens": [466, 13437, 7150, 294, 15329, 11, 286, 500, 380, 534, 458, 437, 257, 13437, 3170, 307, 11, 420, 983, 415, 390], "temperature": 0.0, "avg_logprob": -0.2615145547049386, "compression_ratio": 1.6612244897959183, "no_speech_prob": 9.665905054134782e-06}, {"id": 134, "seek": 77216, "start": 785.36, "end": 788.3199999999999, "text": " using it here, can somebody give me some resources.", "tokens": [1228, 309, 510, 11, 393, 2618, 976, 385, 512, 3593, 13], "temperature": 0.0, "avg_logprob": -0.2615145547049386, "compression_ratio": 1.6612244897959183, "no_speech_prob": 9.665905054134782e-06}, {"id": 135, "seek": 77216, "start": 788.3199999999999, "end": 792.36, "text": " These are kind of things that are not rocket science, just because you don't happen to", "tokens": [1981, 366, 733, 295, 721, 300, 366, 406, 13012, 3497, 11, 445, 570, 291, 500, 380, 1051, 281], "temperature": 0.0, "avg_logprob": -0.2615145547049386, "compression_ratio": 1.6612244897959183, "no_speech_prob": 9.665905054134782e-06}, {"id": 136, "seek": 77216, "start": 792.36, "end": 795.04, "text": " have come across it yet doesn't mean it's hard.", "tokens": [362, 808, 2108, 309, 1939, 1177, 380, 914, 309, 311, 1152, 13], "temperature": 0.0, "avg_logprob": -0.2615145547049386, "compression_ratio": 1.6612244897959183, "no_speech_prob": 9.665905054134782e-06}, {"id": 137, "seek": 77216, "start": 795.04, "end": 800.9599999999999, "text": " It's just something you need to learn.", "tokens": [467, 311, 445, 746, 291, 643, 281, 1466, 13], "temperature": 0.0, "avg_logprob": -0.2615145547049386, "compression_ratio": 1.6612244897959183, "no_speech_prob": 9.665905054134782e-06}, {"id": 138, "seek": 80096, "start": 800.96, "end": 809.48, "text": " I will mention that as I cover these research-level topics and develop these courses, I often", "tokens": [286, 486, 2152, 300, 382, 286, 2060, 613, 2132, 12, 12418, 8378, 293, 1499, 613, 7712, 11, 286, 2049], "temperature": 0.0, "avg_logprob": -0.14303916433583136, "compression_ratio": 1.5103092783505154, "no_speech_prob": 8.267797056760173e-06}, {"id": 139, "seek": 80096, "start": 809.48, "end": 816.0, "text": " refer to code that academics have put up to go along with their papers, or example code", "tokens": [2864, 281, 3089, 300, 25695, 362, 829, 493, 281, 352, 2051, 365, 641, 10577, 11, 420, 1365, 3089], "temperature": 0.0, "avg_logprob": -0.14303916433583136, "compression_ratio": 1.5103092783505154, "no_speech_prob": 8.267797056760173e-06}, {"id": 140, "seek": 80096, "start": 816.0, "end": 818.52, "text": " that somebody else has written on GitHub.", "tokens": [300, 2618, 1646, 575, 3720, 322, 23331, 13], "temperature": 0.0, "avg_logprob": -0.14303916433583136, "compression_ratio": 1.5103092783505154, "no_speech_prob": 8.267797056760173e-06}, {"id": 141, "seek": 80096, "start": 818.52, "end": 825.44, "text": " I nearly always find that there's some massive critical flaw in them.", "tokens": [286, 6217, 1009, 915, 300, 456, 311, 512, 5994, 4924, 13717, 294, 552, 13], "temperature": 0.0, "avg_logprob": -0.14303916433583136, "compression_ratio": 1.5103092783505154, "no_speech_prob": 8.267797056760173e-06}, {"id": 142, "seek": 82544, "start": 825.44, "end": 834.6800000000001, "text": " So be careful of taking code from online resources and assuming that if it doesn't work for you", "tokens": [407, 312, 5026, 295, 1940, 3089, 490, 2950, 3593, 293, 11926, 300, 498, 309, 1177, 380, 589, 337, 291], "temperature": 0.0, "avg_logprob": -0.1740415891011556, "compression_ratio": 1.5053191489361701, "no_speech_prob": 5.255273663351545e-06}, {"id": 143, "seek": 82544, "start": 834.6800000000001, "end": 836.7600000000001, "text": " that you've made a mistake or something.", "tokens": [300, 291, 600, 1027, 257, 6146, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.1740415891011556, "compression_ratio": 1.5053191489361701, "no_speech_prob": 5.255273663351545e-06}, {"id": 144, "seek": 82544, "start": 836.7600000000001, "end": 842.4000000000001, "text": " This kind of research-level code, it's just good enough that they were able to run their", "tokens": [639, 733, 295, 2132, 12, 12418, 3089, 11, 309, 311, 445, 665, 1547, 300, 436, 645, 1075, 281, 1190, 641], "temperature": 0.0, "avg_logprob": -0.1740415891011556, "compression_ratio": 1.5053191489361701, "no_speech_prob": 5.255273663351545e-06}, {"id": 145, "seek": 82544, "start": 842.4000000000001, "end": 849.36, "text": " particular experiments every second Tuesday or something.", "tokens": [1729, 12050, 633, 1150, 10017, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.1740415891011556, "compression_ratio": 1.5053191489361701, "no_speech_prob": 5.255273663351545e-06}, {"id": 146, "seek": 84936, "start": 849.36, "end": 858.5600000000001, "text": " So you should be ready to do some debugging.", "tokens": [407, 291, 820, 312, 1919, 281, 360, 512, 45592, 13], "temperature": 0.0, "avg_logprob": -0.21079392994151397, "compression_ratio": 1.4911242603550297, "no_speech_prob": 1.4738764548383188e-05}, {"id": 147, "seek": 84936, "start": 858.5600000000001, "end": 865.12, "text": " So on that sense, I just wanted to remind you about something from our old course wiki", "tokens": [407, 322, 300, 2020, 11, 286, 445, 1415, 281, 4160, 291, 466, 746, 490, 527, 1331, 1164, 261, 9850], "temperature": 0.0, "avg_logprob": -0.21079392994151397, "compression_ratio": 1.4911242603550297, "no_speech_prob": 1.4738764548383188e-05}, {"id": 148, "seek": 84936, "start": 865.12, "end": 871.48, "text": " that we sometimes talk about, which is people often ask what should I do after the lesson,", "tokens": [300, 321, 2171, 751, 466, 11, 597, 307, 561, 2049, 1029, 437, 820, 286, 360, 934, 264, 6898, 11], "temperature": 0.0, "avg_logprob": -0.21079392994151397, "compression_ratio": 1.4911242603550297, "no_speech_prob": 1.4738764548383188e-05}, {"id": 149, "seek": 84936, "start": 871.48, "end": 876.72, "text": " how do I know if I've got it.", "tokens": [577, 360, 286, 458, 498, 286, 600, 658, 309, 13], "temperature": 0.0, "avg_logprob": -0.21079392994151397, "compression_ratio": 1.4911242603550297, "no_speech_prob": 1.4738764548383188e-05}, {"id": 150, "seek": 87672, "start": 876.72, "end": 881.0, "text": " We basically have this thing called how to use the provided notebooks.", "tokens": [492, 1936, 362, 341, 551, 1219, 577, 281, 764, 264, 5649, 43782, 13], "temperature": 0.0, "avg_logprob": -0.19742534377358176, "compression_ratio": 1.736842105263158, "no_speech_prob": 7.253823423525319e-05}, {"id": 151, "seek": 87672, "start": 881.0, "end": 883.0, "text": " The idea is this.", "tokens": [440, 1558, 307, 341, 13], "temperature": 0.0, "avg_logprob": -0.19742534377358176, "compression_ratio": 1.736842105263158, "no_speech_prob": 7.253823423525319e-05}, {"id": 152, "seek": 87672, "start": 883.0, "end": 890.8000000000001, "text": " Don't open up the notebook, shift enter, shift enter, shift enter, until a bug appears and", "tokens": [1468, 380, 1269, 493, 264, 21060, 11, 5513, 3242, 11, 5513, 3242, 11, 5513, 3242, 11, 1826, 257, 7426, 7038, 293], "temperature": 0.0, "avg_logprob": -0.19742534377358176, "compression_ratio": 1.736842105263158, "no_speech_prob": 7.253823423525319e-05}, {"id": 153, "seek": 87672, "start": 890.8000000000001, "end": 895.08, "text": " then go to the forums and say the notebook's broken.", "tokens": [550, 352, 281, 264, 26998, 293, 584, 264, 21060, 311, 5463, 13], "temperature": 0.0, "avg_logprob": -0.19742534377358176, "compression_ratio": 1.736842105263158, "no_speech_prob": 7.253823423525319e-05}, {"id": 154, "seek": 87672, "start": 895.08, "end": 900.88, "text": " The idea of the notebook is to kind of be like a little crutch to help you get through", "tokens": [440, 1558, 295, 264, 21060, 307, 281, 733, 295, 312, 411, 257, 707, 941, 9349, 281, 854, 291, 483, 807], "temperature": 0.0, "avg_logprob": -0.19742534377358176, "compression_ratio": 1.736842105263158, "no_speech_prob": 7.253823423525319e-05}, {"id": 155, "seek": 87672, "start": 900.88, "end": 901.88, "text": " each step.", "tokens": [1184, 1823, 13], "temperature": 0.0, "avg_logprob": -0.19742534377358176, "compression_ratio": 1.736842105263158, "no_speech_prob": 7.253823423525319e-05}, {"id": 156, "seek": 90188, "start": 901.88, "end": 909.12, "text": " So you start with an empty notebook and think, I now want to complete this process.", "tokens": [407, 291, 722, 365, 364, 6707, 21060, 293, 519, 11, 286, 586, 528, 281, 3566, 341, 1399, 13], "temperature": 0.0, "avg_logprob": -0.21613897928377476, "compression_ratio": 1.5968586387434556, "no_speech_prob": 4.495144366956083e-06}, {"id": 157, "seek": 90188, "start": 909.12, "end": 916.96, "text": " And that might initially require you alt-tabbing or whatever, command-tabbing to the notebook", "tokens": [400, 300, 1062, 9105, 3651, 291, 4955, 12, 83, 455, 4324, 420, 2035, 11, 5622, 12, 83, 455, 4324, 281, 264, 21060], "temperature": 0.0, "avg_logprob": -0.21613897928377476, "compression_ratio": 1.5968586387434556, "no_speech_prob": 4.495144366956083e-06}, {"id": 158, "seek": 90188, "start": 916.96, "end": 921.28, "text": " and reading it, figuring out what it says, but whatever you do, don't copy and paste", "tokens": [293, 3760, 309, 11, 15213, 484, 437, 309, 1619, 11, 457, 2035, 291, 360, 11, 500, 380, 5055, 293, 9163], "temperature": 0.0, "avg_logprob": -0.21613897928377476, "compression_ratio": 1.5968586387434556, "no_speech_prob": 4.495144366956083e-06}, {"id": 159, "seek": 90188, "start": 921.28, "end": 923.04, "text": " it to your notebook.", "tokens": [309, 281, 428, 21060, 13], "temperature": 0.0, "avg_logprob": -0.21613897928377476, "compression_ratio": 1.5968586387434556, "no_speech_prob": 4.495144366956083e-06}, {"id": 160, "seek": 90188, "start": 923.04, "end": 926.44, "text": " Type it out yourself.", "tokens": [15576, 309, 484, 1803, 13], "temperature": 0.0, "avg_logprob": -0.21613897928377476, "compression_ratio": 1.5968586387434556, "no_speech_prob": 4.495144366956083e-06}, {"id": 161, "seek": 92644, "start": 926.44, "end": 932.84, "text": " So try to make sure you can repeat the process, and as you're typing it out, you need to be", "tokens": [407, 853, 281, 652, 988, 291, 393, 7149, 264, 1399, 11, 293, 382, 291, 434, 18444, 309, 484, 11, 291, 643, 281, 312], "temperature": 0.0, "avg_logprob": -0.18545899788538614, "compression_ratio": 1.6822429906542056, "no_speech_prob": 3.393136239537853e-06}, {"id": 162, "seek": 92644, "start": 932.84, "end": 936.1600000000001, "text": " thinking what am I typing, why am I typing it.", "tokens": [1953, 437, 669, 286, 18444, 11, 983, 669, 286, 18444, 309, 13], "temperature": 0.0, "avg_logprob": -0.18545899788538614, "compression_ratio": 1.6822429906542056, "no_speech_prob": 3.393136239537853e-06}, {"id": 163, "seek": 92644, "start": 936.1600000000001, "end": 944.6, "text": " So if you can get to the point where you can solve an object detection problem yourself", "tokens": [407, 498, 291, 393, 483, 281, 264, 935, 689, 291, 393, 5039, 364, 2657, 17784, 1154, 1803], "temperature": 0.0, "avg_logprob": -0.18545899788538614, "compression_ratio": 1.6822429906542056, "no_speech_prob": 3.393136239537853e-06}, {"id": 164, "seek": 92644, "start": 944.6, "end": 950.84, "text": " in a new empty notebook, even if it's using the exact same dataset we used in the course,", "tokens": [294, 257, 777, 6707, 21060, 11, 754, 498, 309, 311, 1228, 264, 1900, 912, 28872, 321, 1143, 294, 264, 1164, 11], "temperature": 0.0, "avg_logprob": -0.18545899788538614, "compression_ratio": 1.6822429906542056, "no_speech_prob": 3.393136239537853e-06}, {"id": 165, "seek": 92644, "start": 950.84, "end": 953.32, "text": " that's a great sign that you're getting it.", "tokens": [300, 311, 257, 869, 1465, 300, 291, 434, 1242, 309, 13], "temperature": 0.0, "avg_logprob": -0.18545899788538614, "compression_ratio": 1.6822429906542056, "no_speech_prob": 3.393136239537853e-06}, {"id": 166, "seek": 95332, "start": 953.32, "end": 958.88, "text": " That'll take a while, but the idea is that by practicing the second time you try to do", "tokens": [663, 603, 747, 257, 1339, 11, 457, 264, 1558, 307, 300, 538, 11350, 264, 1150, 565, 291, 853, 281, 360], "temperature": 0.0, "avg_logprob": -0.21103374223063762, "compression_ratio": 1.8059701492537314, "no_speech_prob": 1.1300657206447795e-05}, {"id": 167, "seek": 95332, "start": 958.88, "end": 964.4000000000001, "text": " it, the third time you try to do it, you'll check the notebook less and less.", "tokens": [309, 11, 264, 2636, 565, 291, 853, 281, 360, 309, 11, 291, 603, 1520, 264, 21060, 1570, 293, 1570, 13], "temperature": 0.0, "avg_logprob": -0.21103374223063762, "compression_ratio": 1.8059701492537314, "no_speech_prob": 1.1300657206447795e-05}, {"id": 168, "seek": 95332, "start": 964.4000000000001, "end": 968.84, "text": " And if there's anything in the notebook where you think, if you think I don't know what", "tokens": [400, 498, 456, 311, 1340, 294, 264, 21060, 689, 291, 519, 11, 498, 291, 519, 286, 500, 380, 458, 437], "temperature": 0.0, "avg_logprob": -0.21103374223063762, "compression_ratio": 1.8059701492537314, "no_speech_prob": 1.1300657206447795e-05}, {"id": 169, "seek": 95332, "start": 968.84, "end": 974.1600000000001, "text": " it's doing, I hope to teach you enough techniques in this course, in this class, that you'll", "tokens": [309, 311, 884, 11, 286, 1454, 281, 2924, 291, 1547, 7512, 294, 341, 1164, 11, 294, 341, 1508, 11, 300, 291, 603], "temperature": 0.0, "avg_logprob": -0.21103374223063762, "compression_ratio": 1.8059701492537314, "no_speech_prob": 1.1300657206447795e-05}, {"id": 170, "seek": 95332, "start": 974.1600000000001, "end": 977.2, "text": " know how to experiment to find out what it's doing.", "tokens": [458, 577, 281, 5120, 281, 915, 484, 437, 309, 311, 884, 13], "temperature": 0.0, "avg_logprob": -0.21103374223063762, "compression_ratio": 1.8059701492537314, "no_speech_prob": 1.1300657206447795e-05}, {"id": 171, "seek": 95332, "start": 977.2, "end": 979.6800000000001, "text": " So you shouldn't have to ask that.", "tokens": [407, 291, 4659, 380, 362, 281, 1029, 300, 13], "temperature": 0.0, "avg_logprob": -0.21103374223063762, "compression_ratio": 1.8059701492537314, "no_speech_prob": 1.1300657206447795e-05}, {"id": 172, "seek": 95332, "start": 979.6800000000001, "end": 982.6800000000001, "text": " But you may well want to ask, why is it doing that?", "tokens": [583, 291, 815, 731, 528, 281, 1029, 11, 983, 307, 309, 884, 300, 30], "temperature": 0.0, "avg_logprob": -0.21103374223063762, "compression_ratio": 1.8059701492537314, "no_speech_prob": 1.1300657206447795e-05}, {"id": 173, "seek": 98268, "start": 982.68, "end": 989.52, "text": " That's the conceptual bit, and that's something you may need to go to the forums and say,", "tokens": [663, 311, 264, 24106, 857, 11, 293, 300, 311, 746, 291, 815, 643, 281, 352, 281, 264, 26998, 293, 584, 11], "temperature": 0.0, "avg_logprob": -0.23519060792041427, "compression_ratio": 1.790513833992095, "no_speech_prob": 7.254038064274937e-05}, {"id": 174, "seek": 98268, "start": 989.52, "end": 994.4399999999999, "text": " before this step, Jeremy had done this, after this step, Jeremy had done that.", "tokens": [949, 341, 1823, 11, 17809, 632, 1096, 341, 11, 934, 341, 1823, 11, 17809, 632, 1096, 300, 13], "temperature": 0.0, "avg_logprob": -0.23519060792041427, "compression_ratio": 1.790513833992095, "no_speech_prob": 7.254038064274937e-05}, {"id": 175, "seek": 98268, "start": 994.4399999999999, "end": 998.76, "text": " There's this bit in the middle where he does this other thing, I don't quite know why.", "tokens": [821, 311, 341, 857, 294, 264, 2808, 689, 415, 775, 341, 661, 551, 11, 286, 500, 380, 1596, 458, 983, 13], "temperature": 0.0, "avg_logprob": -0.23519060792041427, "compression_ratio": 1.790513833992095, "no_speech_prob": 7.254038064274937e-05}, {"id": 176, "seek": 98268, "start": 998.76, "end": 1002.68, "text": " So then you can try and say, here are my hypotheses as to why, try and work through it as much", "tokens": [407, 550, 291, 393, 853, 293, 584, 11, 510, 366, 452, 49969, 382, 281, 983, 11, 853, 293, 589, 807, 309, 382, 709], "temperature": 0.0, "avg_logprob": -0.23519060792041427, "compression_ratio": 1.790513833992095, "no_speech_prob": 7.254038064274937e-05}, {"id": 177, "seek": 98268, "start": 1002.68, "end": 1005.3199999999999, "text": " as possible.", "tokens": [382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.23519060792041427, "compression_ratio": 1.790513833992095, "no_speech_prob": 7.254038064274937e-05}, {"id": 178, "seek": 98268, "start": 1005.3199999999999, "end": 1011.8, "text": " That way you'll both be helping yourself and other people will help you fill in the gaps.", "tokens": [663, 636, 291, 603, 1293, 312, 4315, 1803, 293, 661, 561, 486, 854, 291, 2836, 294, 264, 15031, 13], "temperature": 0.0, "avg_logprob": -0.23519060792041427, "compression_ratio": 1.790513833992095, "no_speech_prob": 7.254038064274937e-05}, {"id": 179, "seek": 101180, "start": 1011.8, "end": 1019.3199999999999, "text": " Alright, if you wish, and you have the financial resources, now is a good time to build a deep", "tokens": [2798, 11, 498, 291, 3172, 11, 293, 291, 362, 264, 4669, 3593, 11, 586, 307, 257, 665, 565, 281, 1322, 257, 2452], "temperature": 0.0, "avg_logprob": -0.17191081100635314, "compression_ratio": 1.5837320574162679, "no_speech_prob": 8.939514373196289e-06}, {"id": 180, "seek": 101180, "start": 1019.3199999999999, "end": 1022.0, "text": " learning box for yourself.", "tokens": [2539, 2424, 337, 1803, 13], "temperature": 0.0, "avg_logprob": -0.17191081100635314, "compression_ratio": 1.5837320574162679, "no_speech_prob": 8.939514373196289e-06}, {"id": 181, "seek": 101180, "start": 1022.0, "end": 1026.6, "text": " When I say a good time, I don't mean a good time in the history of the pricing of GPUs.", "tokens": [1133, 286, 584, 257, 665, 565, 11, 286, 500, 380, 914, 257, 665, 565, 294, 264, 2503, 295, 264, 17621, 295, 18407, 82, 13], "temperature": 0.0, "avg_logprob": -0.17191081100635314, "compression_ratio": 1.5837320574162679, "no_speech_prob": 8.939514373196289e-06}, {"id": 182, "seek": 101180, "start": 1026.6, "end": 1031.48, "text": " GPUs are currently by far the most expensive they've ever been, as I say this, because", "tokens": [18407, 82, 366, 4362, 538, 1400, 264, 881, 5124, 436, 600, 1562, 668, 11, 382, 286, 584, 341, 11, 570], "temperature": 0.0, "avg_logprob": -0.17191081100635314, "compression_ratio": 1.5837320574162679, "no_speech_prob": 8.939514373196289e-06}, {"id": 183, "seek": 101180, "start": 1031.48, "end": 1037.9199999999998, "text": " of the cryptocurrency mining boom.", "tokens": [295, 264, 28809, 15512, 9351, 13], "temperature": 0.0, "avg_logprob": -0.17191081100635314, "compression_ratio": 1.5837320574162679, "no_speech_prob": 8.939514373196289e-06}, {"id": 184, "seek": 103792, "start": 1037.92, "end": 1042.16, "text": " I mean it's a good time in your study cycle.", "tokens": [286, 914, 309, 311, 257, 665, 565, 294, 428, 2979, 6586, 13], "temperature": 0.0, "avg_logprob": -0.20564358733421148, "compression_ratio": 1.3980582524271845, "no_speech_prob": 1.2805242477043066e-05}, {"id": 185, "seek": 103792, "start": 1042.16, "end": 1051.72, "text": " The fact is, if you're paying somewhere between $0.60 and $0.90 an hour for doing your deep", "tokens": [440, 1186, 307, 11, 498, 291, 434, 6229, 4079, 1296, 1848, 15, 13, 4550, 293, 1848, 15, 13, 7771, 364, 1773, 337, 884, 428, 2452], "temperature": 0.0, "avg_logprob": -0.20564358733421148, "compression_ratio": 1.3980582524271845, "no_speech_prob": 1.2805242477043066e-05}, {"id": 186, "seek": 103792, "start": 1051.72, "end": 1059.44, "text": " learning on a cloud provider, particularly if you're still on a K80, like an Amazon P2,", "tokens": [2539, 322, 257, 4588, 12398, 11, 4098, 498, 291, 434, 920, 322, 257, 591, 4702, 11, 411, 364, 6795, 430, 17, 11], "temperature": 0.0, "avg_logprob": -0.20564358733421148, "compression_ratio": 1.3980582524271845, "no_speech_prob": 1.2805242477043066e-05}, {"id": 187, "seek": 103792, "start": 1059.44, "end": 1066.76, "text": " or Google Colab actually, now lets you train on a K80 for free.", "tokens": [420, 3329, 4004, 455, 767, 11, 586, 6653, 291, 3847, 322, 257, 591, 4702, 337, 1737, 13], "temperature": 0.0, "avg_logprob": -0.20564358733421148, "compression_ratio": 1.3980582524271845, "no_speech_prob": 1.2805242477043066e-05}, {"id": 188, "seek": 106676, "start": 1066.76, "end": 1070.48, "text": " But those are very slow GPUs.", "tokens": [583, 729, 366, 588, 2964, 18407, 82, 13], "temperature": 0.0, "avg_logprob": -0.21085982487119478, "compression_ratio": 1.4834123222748816, "no_speech_prob": 1.0451474736328237e-05}, {"id": 189, "seek": 106676, "start": 1070.48, "end": 1080.96, "text": " You can buy one that's going to be 3 times faster for maybe $600, $700.", "tokens": [509, 393, 2256, 472, 300, 311, 516, 281, 312, 805, 1413, 4663, 337, 1310, 1848, 15707, 11, 1848, 18197, 13], "temperature": 0.0, "avg_logprob": -0.21085982487119478, "compression_ratio": 1.4834123222748816, "no_speech_prob": 1.0451474736328237e-05}, {"id": 190, "seek": 106676, "start": 1080.96, "end": 1084.96, "text": " You need a box to put it in, of course.", "tokens": [509, 643, 257, 2424, 281, 829, 309, 294, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.21085982487119478, "compression_ratio": 1.4834123222748816, "no_speech_prob": 1.0451474736328237e-05}, {"id": 191, "seek": 106676, "start": 1084.96, "end": 1089.4, "text": " But the example in the bottom right here from the forum was something that somebody put", "tokens": [583, 264, 1365, 294, 264, 2767, 558, 510, 490, 264, 17542, 390, 746, 300, 2618, 829], "temperature": 0.0, "avg_logprob": -0.21085982487119478, "compression_ratio": 1.4834123222748816, "no_speech_prob": 1.0451474736328237e-05}, {"id": 192, "seek": 106676, "start": 1089.4, "end": 1093.8799999999999, "text": " together in last year's course, so like a year ago they were able to put together a", "tokens": [1214, 294, 1036, 1064, 311, 1164, 11, 370, 411, 257, 1064, 2057, 436, 645, 1075, 281, 829, 1214, 257], "temperature": 0.0, "avg_logprob": -0.21085982487119478, "compression_ratio": 1.4834123222748816, "no_speech_prob": 1.0451474736328237e-05}, {"id": 193, "seek": 109388, "start": 1093.88, "end": 1098.4, "text": " pretty decent box for a bit over $500.", "tokens": [1238, 8681, 2424, 337, 257, 857, 670, 1848, 7526, 13], "temperature": 0.0, "avg_logprob": -0.18931212632552438, "compression_ratio": 1.4678111587982832, "no_speech_prob": 9.223322194884531e-06}, {"id": 194, "seek": 109388, "start": 1098.4, "end": 1101.6000000000001, "text": " Generally speaking you're probably looking at more like $1,000 or $1,500.", "tokens": [21082, 4124, 291, 434, 1391, 1237, 412, 544, 411, 1848, 16, 11, 1360, 420, 1848, 16, 11, 7526, 13], "temperature": 0.0, "avg_logprob": -0.18931212632552438, "compression_ratio": 1.4678111587982832, "no_speech_prob": 9.223322194884531e-06}, {"id": 195, "seek": 109388, "start": 1101.6000000000001, "end": 1109.24, "text": " I created a new forum thread where you can talk about options and parts and ask questions", "tokens": [286, 2942, 257, 777, 17542, 7207, 689, 291, 393, 751, 466, 3956, 293, 3166, 293, 1029, 1651], "temperature": 0.0, "avg_logprob": -0.18931212632552438, "compression_ratio": 1.4678111587982832, "no_speech_prob": 9.223322194884531e-06}, {"id": 196, "seek": 109388, "start": 1109.24, "end": 1113.48, "text": " and so forth.", "tokens": [293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.18931212632552438, "compression_ratio": 1.4678111587982832, "no_speech_prob": 9.223322194884531e-06}, {"id": 197, "seek": 109388, "start": 1113.48, "end": 1120.2, "text": " If you can afford it, right now the GTX 1080 Ti is almost certainly what you want in terms", "tokens": [759, 291, 393, 6157, 309, 11, 558, 586, 264, 17530, 55, 24547, 20456, 307, 1920, 3297, 437, 291, 528, 294, 2115], "temperature": 0.0, "avg_logprob": -0.18931212632552438, "compression_ratio": 1.4678111587982832, "no_speech_prob": 9.223322194884531e-06}, {"id": 198, "seek": 109388, "start": 1120.2, "end": 1123.2, "text": " of the best price performance mix.", "tokens": [295, 264, 1151, 3218, 3389, 2890, 13], "temperature": 0.0, "avg_logprob": -0.18931212632552438, "compression_ratio": 1.4678111587982832, "no_speech_prob": 9.223322194884531e-06}, {"id": 199, "seek": 112320, "start": 1123.2, "end": 1126.72, "text": " If you can't afford it, a 1070 is fine.", "tokens": [759, 291, 393, 380, 6157, 309, 11, 257, 1266, 5867, 307, 2489, 13], "temperature": 0.0, "avg_logprob": -0.1509315916832457, "compression_ratio": 1.6568627450980393, "no_speech_prob": 5.093662821309408e-06}, {"id": 200, "seek": 112320, "start": 1126.72, "end": 1131.92, "text": " If you can't afford that, you should probably be looking for a secondhand 980 or a secondhand", "tokens": [759, 291, 393, 380, 6157, 300, 11, 291, 820, 1391, 312, 1237, 337, 257, 1150, 5543, 1722, 4702, 420, 257, 1150, 5543], "temperature": 0.0, "avg_logprob": -0.1509315916832457, "compression_ratio": 1.6568627450980393, "no_speech_prob": 5.093662821309408e-06}, {"id": 201, "seek": 112320, "start": 1131.92, "end": 1135.52, "text": " 970, something like that.", "tokens": [1722, 5867, 11, 746, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.1509315916832457, "compression_ratio": 1.6568627450980393, "no_speech_prob": 5.093662821309408e-06}, {"id": 202, "seek": 112320, "start": 1135.52, "end": 1140.8400000000001, "text": " If you can afford to spend more money, it's worth getting a second GPU so you can do what", "tokens": [759, 291, 393, 6157, 281, 3496, 544, 1460, 11, 309, 311, 3163, 1242, 257, 1150, 18407, 370, 291, 393, 360, 437], "temperature": 0.0, "avg_logprob": -0.1509315916832457, "compression_ratio": 1.6568627450980393, "no_speech_prob": 5.093662821309408e-06}, {"id": 203, "seek": 112320, "start": 1140.8400000000001, "end": 1147.92, "text": " I do, which is to have one GPU training and another GPU which I'm running an interactive", "tokens": [286, 360, 11, 597, 307, 281, 362, 472, 18407, 3097, 293, 1071, 18407, 597, 286, 478, 2614, 364, 15141], "temperature": 0.0, "avg_logprob": -0.1509315916832457, "compression_ratio": 1.6568627450980393, "no_speech_prob": 5.093662821309408e-06}, {"id": 204, "seek": 114792, "start": 1147.92, "end": 1154.1000000000001, "text": " Jupyter Notebook session in.", "tokens": [22125, 88, 391, 11633, 2939, 5481, 294, 13], "temperature": 0.0, "avg_logprob": -0.22654266357421876, "compression_ratio": 1.449339207048458, "no_speech_prob": 9.223335837305058e-06}, {"id": 205, "seek": 114792, "start": 1154.1000000000001, "end": 1156.3200000000002, "text": " RAM is very useful.", "tokens": [14561, 307, 588, 4420, 13], "temperature": 0.0, "avg_logprob": -0.22654266357421876, "compression_ratio": 1.449339207048458, "no_speech_prob": 9.223335837305058e-06}, {"id": 206, "seek": 114792, "start": 1156.3200000000002, "end": 1158.04, "text": " Try and get 32GB if you can.", "tokens": [6526, 293, 483, 8858, 8769, 498, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.22654266357421876, "compression_ratio": 1.449339207048458, "no_speech_prob": 9.223335837305058e-06}, {"id": 207, "seek": 114792, "start": 1158.04, "end": 1162.6000000000001, "text": " RAM is not terribly expensive.", "tokens": [14561, 307, 406, 22903, 5124, 13], "temperature": 0.0, "avg_logprob": -0.22654266357421876, "compression_ratio": 1.449339207048458, "no_speech_prob": 9.223335837305058e-06}, {"id": 208, "seek": 114792, "start": 1162.6000000000001, "end": 1166.96, "text": " A lot of people find that they're vendor or purchasing to buy one of these business class", "tokens": [316, 688, 295, 561, 915, 300, 436, 434, 24321, 420, 20906, 281, 2256, 472, 295, 613, 1606, 1508], "temperature": 0.0, "avg_logprob": -0.22654266357421876, "compression_ratio": 1.449339207048458, "no_speech_prob": 9.223335837305058e-06}, {"id": 209, "seek": 114792, "start": 1166.96, "end": 1170.4, "text": " Xeon CPUs, that's a total waste of time.", "tokens": [1783, 27015, 13199, 82, 11, 300, 311, 257, 3217, 5964, 295, 565, 13], "temperature": 0.0, "avg_logprob": -0.22654266357421876, "compression_ratio": 1.449339207048458, "no_speech_prob": 9.223335837305058e-06}, {"id": 210, "seek": 114792, "start": 1170.4, "end": 1176.28, "text": " You can get one of the Intel i5 or i7 consumer CPUs, far, far cheaper, but actually a lot", "tokens": [509, 393, 483, 472, 295, 264, 19762, 741, 20, 420, 741, 22, 9711, 13199, 82, 11, 1400, 11, 1400, 12284, 11, 457, 767, 257, 688], "temperature": 0.0, "avg_logprob": -0.22654266357421876, "compression_ratio": 1.449339207048458, "no_speech_prob": 9.223335837305058e-06}, {"id": 211, "seek": 117628, "start": 1176.28, "end": 1179.52, "text": " of them are faster.", "tokens": [295, 552, 366, 4663, 13], "temperature": 0.0, "avg_logprob": -0.2037840152005537, "compression_ratio": 1.5984251968503937, "no_speech_prob": 1.4970824850024655e-05}, {"id": 212, "seek": 117628, "start": 1179.52, "end": 1182.6, "text": " Often you'll hear CPU speed doesn't matter.", "tokens": [20043, 291, 603, 1568, 13199, 3073, 1177, 380, 1871, 13], "temperature": 0.0, "avg_logprob": -0.2037840152005537, "compression_ratio": 1.5984251968503937, "no_speech_prob": 1.4970824850024655e-05}, {"id": 213, "seek": 117628, "start": 1182.6, "end": 1185.6399999999999, "text": " If you're doing computer vision, that's definitely not true.", "tokens": [759, 291, 434, 884, 3820, 5201, 11, 300, 311, 2138, 406, 2074, 13], "temperature": 0.0, "avg_logprob": -0.2037840152005537, "compression_ratio": 1.5984251968503937, "no_speech_prob": 1.4970824850024655e-05}, {"id": 214, "seek": 117628, "start": 1185.6399999999999, "end": 1190.3999999999999, "text": " It's very common now with these 1080 Ti's and so forth to find that the speed of the", "tokens": [467, 311, 588, 2689, 586, 365, 613, 24547, 20456, 311, 293, 370, 5220, 281, 915, 300, 264, 3073, 295, 264], "temperature": 0.0, "avg_logprob": -0.2037840152005537, "compression_ratio": 1.5984251968503937, "no_speech_prob": 1.4970824850024655e-05}, {"id": 215, "seek": 117628, "start": 1190.3999999999999, "end": 1194.92, "text": " data augmentation is actually the slow bit that's happening on the CPU, so it's worth", "tokens": [1412, 14501, 19631, 307, 767, 264, 2964, 857, 300, 311, 2737, 322, 264, 13199, 11, 370, 309, 311, 3163], "temperature": 0.0, "avg_logprob": -0.2037840152005537, "compression_ratio": 1.5984251968503937, "no_speech_prob": 1.4970824850024655e-05}, {"id": 216, "seek": 117628, "start": 1194.92, "end": 1198.52, "text": " getting a decent CPU.", "tokens": [1242, 257, 8681, 13199, 13], "temperature": 0.0, "avg_logprob": -0.2037840152005537, "compression_ratio": 1.5984251968503937, "no_speech_prob": 1.4970824850024655e-05}, {"id": 217, "seek": 117628, "start": 1198.52, "end": 1205.24, "text": " Again, your GPU, if it's running quickly but the hard drive's not fast enough to give it", "tokens": [3764, 11, 428, 18407, 11, 498, 309, 311, 2614, 2661, 457, 264, 1152, 3332, 311, 406, 2370, 1547, 281, 976, 309], "temperature": 0.0, "avg_logprob": -0.2037840152005537, "compression_ratio": 1.5984251968503937, "no_speech_prob": 1.4970824850024655e-05}, {"id": 218, "seek": 120524, "start": 1205.24, "end": 1208.0, "text": " data, then that's a waste as well.", "tokens": [1412, 11, 550, 300, 311, 257, 5964, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17624794995343243, "compression_ratio": 1.5767634854771784, "no_speech_prob": 9.972873158403672e-06}, {"id": 219, "seek": 120524, "start": 1208.0, "end": 1212.0, "text": " So if you can afford an NVMe drive that's super, super fast, you don't have to get a", "tokens": [407, 498, 291, 393, 6157, 364, 46512, 12671, 3332, 300, 311, 1687, 11, 1687, 2370, 11, 291, 500, 380, 362, 281, 483, 257], "temperature": 0.0, "avg_logprob": -0.17624794995343243, "compression_ratio": 1.5767634854771784, "no_speech_prob": 9.972873158403672e-06}, {"id": 220, "seek": 120524, "start": 1212.0, "end": 1213.0, "text": " big one.", "tokens": [955, 472, 13], "temperature": 0.0, "avg_logprob": -0.17624794995343243, "compression_ratio": 1.5767634854771784, "no_speech_prob": 9.972873158403672e-06}, {"id": 221, "seek": 120524, "start": 1213.0, "end": 1217.88, "text": " You can just get a little one, just copy your current set of data onto and have some big", "tokens": [509, 393, 445, 483, 257, 707, 472, 11, 445, 5055, 428, 2190, 992, 295, 1412, 3911, 293, 362, 512, 955], "temperature": 0.0, "avg_logprob": -0.17624794995343243, "compression_ratio": 1.5767634854771784, "no_speech_prob": 9.972873158403672e-06}, {"id": 222, "seek": 120524, "start": 1217.88, "end": 1224.84, "text": " RAID array that sits there for the rest of your data when you're not using it.", "tokens": [14626, 2777, 10225, 300, 12696, 456, 337, 264, 1472, 295, 428, 1412, 562, 291, 434, 406, 1228, 309, 13], "temperature": 0.0, "avg_logprob": -0.17624794995343243, "compression_ratio": 1.5767634854771784, "no_speech_prob": 9.972873158403672e-06}, {"id": 223, "seek": 120524, "start": 1224.84, "end": 1231.8, "text": " There's a slightly arcane thing about PCI lanes, which is basically the size of the", "tokens": [821, 311, 257, 4748, 10346, 1929, 551, 466, 6465, 40, 25397, 11, 597, 307, 1936, 264, 2744, 295, 264], "temperature": 0.0, "avg_logprob": -0.17624794995343243, "compression_ratio": 1.5767634854771784, "no_speech_prob": 9.972873158403672e-06}, {"id": 224, "seek": 123180, "start": 1231.8, "end": 1238.6399999999999, "text": " highway that connects your GPU to your computer.", "tokens": [17205, 300, 16967, 428, 18407, 281, 428, 3820, 13], "temperature": 0.0, "avg_logprob": -0.23160053204886522, "compression_ratio": 1.5124378109452736, "no_speech_prob": 1.2805332517018542e-05}, {"id": 225, "seek": 123180, "start": 1238.6399999999999, "end": 1244.9199999999998, "text": " A lot of people claim that you need to have 16 lanes to feed your GPU.", "tokens": [316, 688, 295, 561, 3932, 300, 291, 643, 281, 362, 3165, 25397, 281, 3154, 428, 18407, 13], "temperature": 0.0, "avg_logprob": -0.23160053204886522, "compression_ratio": 1.5124378109452736, "no_speech_prob": 1.2805332517018542e-05}, {"id": 226, "seek": 123180, "start": 1244.9199999999998, "end": 1254.04, "text": " It actually turns out, based on some analysis that I've seen recently, that that's not true.", "tokens": [467, 767, 4523, 484, 11, 2361, 322, 512, 5215, 300, 286, 600, 1612, 3938, 11, 300, 300, 311, 406, 2074, 13], "temperature": 0.0, "avg_logprob": -0.23160053204886522, "compression_ratio": 1.5124378109452736, "no_speech_prob": 1.2805332517018542e-05}, {"id": 227, "seek": 123180, "start": 1254.04, "end": 1256.72, "text": " You need 8 lanes for GPU.", "tokens": [509, 643, 1649, 25397, 337, 18407, 13], "temperature": 0.0, "avg_logprob": -0.23160053204886522, "compression_ratio": 1.5124378109452736, "no_speech_prob": 1.2805332517018542e-05}, {"id": 228, "seek": 123180, "start": 1256.72, "end": 1260.52, "text": " So again, hopefully help you save some money on your motherboard.", "tokens": [407, 797, 11, 4696, 854, 291, 3155, 512, 1460, 322, 428, 32916, 13], "temperature": 0.0, "avg_logprob": -0.23160053204886522, "compression_ratio": 1.5124378109452736, "no_speech_prob": 1.2805332517018542e-05}, {"id": 229, "seek": 126052, "start": 1260.52, "end": 1265.4, "text": " If you've never heard of PCI lanes before, trust me, by the end of putting together this", "tokens": [759, 291, 600, 1128, 2198, 295, 6465, 40, 25397, 949, 11, 3361, 385, 11, 538, 264, 917, 295, 3372, 1214, 341], "temperature": 0.0, "avg_logprob": -0.15983610754614477, "compression_ratio": 1.6705882352941177, "no_speech_prob": 6.962191037018783e-06}, {"id": 230, "seek": 126052, "start": 1265.4, "end": 1271.76, "text": " box you'll be sick of hearing about them.", "tokens": [2424, 291, 603, 312, 4998, 295, 4763, 466, 552, 13], "temperature": 0.0, "avg_logprob": -0.15983610754614477, "compression_ratio": 1.6705882352941177, "no_speech_prob": 6.962191037018783e-06}, {"id": 231, "seek": 126052, "start": 1271.76, "end": 1273.76, "text": " You can buy all the parts and put it together yourself.", "tokens": [509, 393, 2256, 439, 264, 3166, 293, 829, 309, 1214, 1803, 13], "temperature": 0.0, "avg_logprob": -0.15983610754614477, "compression_ratio": 1.6705882352941177, "no_speech_prob": 6.962191037018783e-06}, {"id": 232, "seek": 126052, "start": 1273.76, "end": 1279.0, "text": " It's not that hard, it can be a useful learning experience, it can also be frustrating and", "tokens": [467, 311, 406, 300, 1152, 11, 309, 393, 312, 257, 4420, 2539, 1752, 11, 309, 393, 611, 312, 16522, 293], "temperature": 0.0, "avg_logprob": -0.15983610754614477, "compression_ratio": 1.6705882352941177, "no_speech_prob": 6.962191037018783e-06}, {"id": 233, "seek": 126052, "start": 1279.0, "end": 1280.0, "text": " annoying.", "tokens": [11304, 13], "temperature": 0.0, "avg_logprob": -0.15983610754614477, "compression_ratio": 1.6705882352941177, "no_speech_prob": 6.962191037018783e-06}, {"id": 234, "seek": 126052, "start": 1280.0, "end": 1284.16, "text": " So you can always go to central computers and they'll put it together for you.", "tokens": [407, 291, 393, 1009, 352, 281, 5777, 10807, 293, 436, 603, 829, 309, 1214, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.15983610754614477, "compression_ratio": 1.6705882352941177, "no_speech_prob": 6.962191037018783e-06}, {"id": 235, "seek": 126052, "start": 1284.16, "end": 1286.8, "text": " There's lots of online vendors that will do the same thing.", "tokens": [821, 311, 3195, 295, 2950, 22056, 300, 486, 360, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.15983610754614477, "compression_ratio": 1.6705882352941177, "no_speech_prob": 6.962191037018783e-06}, {"id": 236, "seek": 128680, "start": 1286.8, "end": 1297.6399999999999, "text": " I generally make sure it turns on and runs properly, generally not much of a markup.", "tokens": [286, 5101, 652, 988, 309, 4523, 322, 293, 6676, 6108, 11, 5101, 406, 709, 295, 257, 1491, 1010, 13], "temperature": 0.0, "avg_logprob": -0.18990346659784732, "compression_ratio": 1.640552995391705, "no_speech_prob": 9.36861033551395e-06}, {"id": 237, "seek": 128680, "start": 1297.6399999999999, "end": 1300.56, "text": " We're going to be doing a lot of reading papers.", "tokens": [492, 434, 516, 281, 312, 884, 257, 688, 295, 3760, 10577, 13], "temperature": 0.0, "avg_logprob": -0.18990346659784732, "compression_ratio": 1.640552995391705, "no_speech_prob": 9.36861033551395e-06}, {"id": 238, "seek": 128680, "start": 1300.56, "end": 1304.9199999999998, "text": " Basically each week we'll be implementing a paper or a few papers.", "tokens": [8537, 1184, 1243, 321, 603, 312, 18114, 257, 3035, 420, 257, 1326, 10577, 13], "temperature": 0.0, "avg_logprob": -0.18990346659784732, "compression_ratio": 1.640552995391705, "no_speech_prob": 9.36861033551395e-06}, {"id": 239, "seek": 128680, "start": 1304.9199999999998, "end": 1309.76, "text": " And if you haven't looked at papers before, they look something like on the left.", "tokens": [400, 498, 291, 2378, 380, 2956, 412, 10577, 949, 11, 436, 574, 746, 411, 322, 264, 1411, 13], "temperature": 0.0, "avg_logprob": -0.18990346659784732, "compression_ratio": 1.640552995391705, "no_speech_prob": 9.36861033551395e-06}, {"id": 240, "seek": 128680, "start": 1309.76, "end": 1315.36, "text": " That thing on the left is an extract from the paper that implements Atom.", "tokens": [663, 551, 322, 264, 1411, 307, 364, 8947, 490, 264, 3035, 300, 704, 17988, 1711, 298, 13], "temperature": 0.0, "avg_logprob": -0.18990346659784732, "compression_ratio": 1.640552995391705, "no_speech_prob": 9.36861033551395e-06}, {"id": 241, "seek": 131536, "start": 1315.36, "end": 1323.1999999999998, "text": " You may also have seen Atom as a single Excel formula on the spreadsheet.", "tokens": [509, 815, 611, 362, 1612, 1711, 298, 382, 257, 2167, 19060, 8513, 322, 264, 27733, 13], "temperature": 0.0, "avg_logprob": -0.20763091099115066, "compression_ratio": 1.4904761904761905, "no_speech_prob": 2.642569143063156e-06}, {"id": 242, "seek": 131536, "start": 1323.1999999999998, "end": 1328.84, "text": " The difference is in academic papers, people love to use Greek letters.", "tokens": [440, 2649, 307, 294, 7778, 10577, 11, 561, 959, 281, 764, 10281, 7825, 13], "temperature": 0.0, "avg_logprob": -0.20763091099115066, "compression_ratio": 1.4904761904761905, "no_speech_prob": 2.642569143063156e-06}, {"id": 243, "seek": 131536, "start": 1328.84, "end": 1331.6, "text": " They also hate to refactor.", "tokens": [814, 611, 4700, 281, 1895, 15104, 13], "temperature": 0.0, "avg_logprob": -0.20763091099115066, "compression_ratio": 1.4904761904761905, "no_speech_prob": 2.642569143063156e-06}, {"id": 244, "seek": 131536, "start": 1331.6, "end": 1337.1599999999999, "text": " So you'll often see a page-long formula where when you actually look at it carefully, you'll", "tokens": [407, 291, 603, 2049, 536, 257, 3028, 12, 13025, 8513, 689, 562, 291, 767, 574, 412, 309, 7500, 11, 291, 603], "temperature": 0.0, "avg_logprob": -0.20763091099115066, "compression_ratio": 1.4904761904761905, "no_speech_prob": 2.642569143063156e-06}, {"id": 245, "seek": 131536, "start": 1337.1599999999999, "end": 1341.76, "text": " realize the same sub-equation appears 8 times.", "tokens": [4325, 264, 912, 1422, 12, 12816, 399, 7038, 1649, 1413, 13], "temperature": 0.0, "avg_logprob": -0.20763091099115066, "compression_ratio": 1.4904761904761905, "no_speech_prob": 2.642569143063156e-06}, {"id": 246, "seek": 134176, "start": 1341.76, "end": 1348.24, "text": " They didn't think to say above it let t equal this sub-equation.", "tokens": [814, 994, 380, 519, 281, 584, 3673, 309, 718, 256, 2681, 341, 1422, 12, 12816, 399, 13], "temperature": 0.0, "avg_logprob": -0.20284242408220157, "compression_ratio": 1.5591397849462365, "no_speech_prob": 1.0953000128210988e-05}, {"id": 247, "seek": 134176, "start": 1348.24, "end": 1353.92, "text": " I don't know why this is a thing.", "tokens": [286, 500, 380, 458, 983, 341, 307, 257, 551, 13], "temperature": 0.0, "avg_logprob": -0.20284242408220157, "compression_ratio": 1.5591397849462365, "no_speech_prob": 1.0953000128210988e-05}, {"id": 248, "seek": 134176, "start": 1353.92, "end": 1360.2, "text": " I guess all this is to say, once you've read and understood a paper, you then go back to", "tokens": [286, 2041, 439, 341, 307, 281, 584, 11, 1564, 291, 600, 1401, 293, 7320, 257, 3035, 11, 291, 550, 352, 646, 281], "temperature": 0.0, "avg_logprob": -0.20284242408220157, "compression_ratio": 1.5591397849462365, "no_speech_prob": 1.0953000128210988e-05}, {"id": 249, "seek": 134176, "start": 1360.2, "end": 1365.04, "text": " it and you look at it and you're just like, wow, how did they make such a simple thing", "tokens": [309, 293, 291, 574, 412, 309, 293, 291, 434, 445, 411, 11, 6076, 11, 577, 630, 436, 652, 1270, 257, 2199, 551], "temperature": 0.0, "avg_logprob": -0.20284242408220157, "compression_ratio": 1.5591397849462365, "no_speech_prob": 1.0953000128210988e-05}, {"id": 250, "seek": 134176, "start": 1365.04, "end": 1366.44, "text": " so complicated.", "tokens": [370, 6179, 13], "temperature": 0.0, "avg_logprob": -0.20284242408220157, "compression_ratio": 1.5591397849462365, "no_speech_prob": 1.0953000128210988e-05}, {"id": 251, "seek": 136644, "start": 1366.44, "end": 1377.24, "text": " Like Atom is like momentum on the gradient and momentum on the square root of the gradient.", "tokens": [1743, 1711, 298, 307, 411, 11244, 322, 264, 16235, 293, 11244, 322, 264, 3732, 5593, 295, 264, 16235, 13], "temperature": 0.0, "avg_logprob": -0.24604015764982803, "compression_ratio": 1.8316326530612246, "no_speech_prob": 5.338129540177761e-06}, {"id": 252, "seek": 136644, "start": 1377.24, "end": 1378.24, "text": " That's it.", "tokens": [663, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.24604015764982803, "compression_ratio": 1.8316326530612246, "no_speech_prob": 5.338129540177761e-06}, {"id": 253, "seek": 136644, "start": 1378.24, "end": 1380.2, "text": " And it's this big long thing.", "tokens": [400, 309, 311, 341, 955, 938, 551, 13], "temperature": 0.0, "avg_logprob": -0.24604015764982803, "compression_ratio": 1.8316326530612246, "no_speech_prob": 5.338129540177761e-06}, {"id": 254, "seek": 136644, "start": 1380.2, "end": 1383.2, "text": " The other reason it's a big long thing is because they have things like this where they", "tokens": [440, 661, 1778, 309, 311, 257, 955, 938, 551, 307, 570, 436, 362, 721, 411, 341, 689, 436], "temperature": 0.0, "avg_logprob": -0.24604015764982803, "compression_ratio": 1.8316326530612246, "no_speech_prob": 5.338129540177761e-06}, {"id": 255, "seek": 136644, "start": 1383.2, "end": 1390.7, "text": " have theorems and corollaries and stuff where they're saying, here's our theoretical reasoning", "tokens": [362, 10299, 2592, 293, 1181, 1833, 4889, 293, 1507, 689, 436, 434, 1566, 11, 510, 311, 527, 20864, 21577], "temperature": 0.0, "avg_logprob": -0.24604015764982803, "compression_ratio": 1.8316326530612246, "no_speech_prob": 5.338129540177761e-06}, {"id": 256, "seek": 136644, "start": 1390.7, "end": 1394.2, "text": " behind why this ought to work, or whatever.", "tokens": [2261, 983, 341, 13416, 281, 589, 11, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.24604015764982803, "compression_ratio": 1.8316326530612246, "no_speech_prob": 5.338129540177761e-06}, {"id": 257, "seek": 139420, "start": 1394.2, "end": 1400.28, "text": " And for whatever reason, a lot of conferences and journals don't like to accept papers that", "tokens": [400, 337, 2035, 1778, 11, 257, 688, 295, 22032, 293, 29621, 500, 380, 411, 281, 3241, 10577, 300], "temperature": 0.0, "avg_logprob": -0.19499308268229168, "compression_ratio": 1.688259109311741, "no_speech_prob": 4.565938979794737e-06}, {"id": 258, "seek": 139420, "start": 1400.28, "end": 1403.32, "text": " don't have a lot of this theoretical justification.", "tokens": [500, 380, 362, 257, 688, 295, 341, 20864, 31591, 13], "temperature": 0.0, "avg_logprob": -0.19499308268229168, "compression_ratio": 1.688259109311741, "no_speech_prob": 4.565938979794737e-06}, {"id": 259, "seek": 139420, "start": 1403.32, "end": 1409.2, "text": " Jeffrey Hinton's talked about this a bit, how particularly a decade or two ago when", "tokens": [28721, 389, 12442, 311, 2825, 466, 341, 257, 857, 11, 577, 4098, 257, 10378, 420, 732, 2057, 562], "temperature": 0.0, "avg_logprob": -0.19499308268229168, "compression_ratio": 1.688259109311741, "no_speech_prob": 4.565938979794737e-06}, {"id": 260, "seek": 139420, "start": 1409.2, "end": 1416.52, "text": " no conferences would really accept any neural network papers, then there was this one abstract", "tokens": [572, 22032, 576, 534, 3241, 604, 18161, 3209, 10577, 11, 550, 456, 390, 341, 472, 12649], "temperature": 0.0, "avg_logprob": -0.19499308268229168, "compression_ratio": 1.688259109311741, "no_speech_prob": 4.565938979794737e-06}, {"id": 261, "seek": 139420, "start": 1416.52, "end": 1424.16, "text": " theoretical result that came out where suddenly they could show this practically unimplemented", "tokens": [20864, 1874, 300, 1361, 484, 689, 5800, 436, 727, 855, 341, 15667, 517, 332, 781, 14684], "temperature": 0.0, "avg_logprob": -0.19499308268229168, "compression_ratio": 1.688259109311741, "no_speech_prob": 4.565938979794737e-06}, {"id": 262, "seek": 142416, "start": 1424.16, "end": 1427.8400000000001, "text": " important but theoretically interesting thing and then suddenly they could then start submitting", "tokens": [1021, 457, 29400, 1880, 551, 293, 550, 5800, 436, 727, 550, 722, 31836], "temperature": 0.0, "avg_logprob": -0.20278614891899957, "compression_ratio": 1.7372881355932204, "no_speech_prob": 1.147864168160595e-05}, {"id": 263, "seek": 142416, "start": 1427.8400000000001, "end": 1432.44, "text": " things to journals because they have this theoretical justification.", "tokens": [721, 281, 29621, 570, 436, 362, 341, 20864, 31591, 13], "temperature": 0.0, "avg_logprob": -0.20278614891899957, "compression_ratio": 1.7372881355932204, "no_speech_prob": 1.147864168160595e-05}, {"id": 264, "seek": 142416, "start": 1432.44, "end": 1440.3600000000001, "text": " So academic papers are a bit weird, but in the end it's the way that the research community", "tokens": [407, 7778, 10577, 366, 257, 857, 3657, 11, 457, 294, 264, 917, 309, 311, 264, 636, 300, 264, 2132, 1768], "temperature": 0.0, "avg_logprob": -0.20278614891899957, "compression_ratio": 1.7372881355932204, "no_speech_prob": 1.147864168160595e-05}, {"id": 265, "seek": 142416, "start": 1440.3600000000001, "end": 1447.24, "text": " communicates their findings and so we need to learn to read them.", "tokens": [3363, 1024, 641, 16483, 293, 370, 321, 643, 281, 1466, 281, 1401, 552, 13], "temperature": 0.0, "avg_logprob": -0.20278614891899957, "compression_ratio": 1.7372881355932204, "no_speech_prob": 1.147864168160595e-05}, {"id": 266, "seek": 142416, "start": 1447.24, "end": 1451.92, "text": " But something that can be a great thing to do is to take a paper, put in the effort to", "tokens": [583, 746, 300, 393, 312, 257, 869, 551, 281, 360, 307, 281, 747, 257, 3035, 11, 829, 294, 264, 4630, 281], "temperature": 0.0, "avg_logprob": -0.20278614891899957, "compression_ratio": 1.7372881355932204, "no_speech_prob": 1.147864168160595e-05}, {"id": 267, "seek": 145192, "start": 1451.92, "end": 1461.3200000000002, "text": " understand it, and then write a blog where you explain it in code and normal English.", "tokens": [1223, 309, 11, 293, 550, 2464, 257, 6968, 689, 291, 2903, 309, 294, 3089, 293, 2710, 3669, 13], "temperature": 0.0, "avg_logprob": -0.17043647100759107, "compression_ratio": 1.6761904761904762, "no_speech_prob": 3.219174323021434e-05}, {"id": 268, "seek": 145192, "start": 1461.3200000000002, "end": 1467.64, "text": " And lots of people who do that end up getting quite a following, end up getting some pretty", "tokens": [400, 3195, 295, 561, 567, 360, 300, 917, 493, 1242, 1596, 257, 3480, 11, 917, 493, 1242, 512, 1238], "temperature": 0.0, "avg_logprob": -0.17043647100759107, "compression_ratio": 1.6761904761904762, "no_speech_prob": 3.219174323021434e-05}, {"id": 269, "seek": 145192, "start": 1467.64, "end": 1473.6000000000001, "text": " great job offers and so forth because it's such a useful skill to be able to show, I", "tokens": [869, 1691, 7736, 293, 370, 5220, 570, 309, 311, 1270, 257, 4420, 5389, 281, 312, 1075, 281, 855, 11, 286], "temperature": 0.0, "avg_logprob": -0.17043647100759107, "compression_ratio": 1.6761904761904762, "no_speech_prob": 3.219174323021434e-05}, {"id": 270, "seek": 145192, "start": 1473.6000000000001, "end": 1481.72, "text": " can understand these papers, I can implement them in code, I can explain them in English.", "tokens": [393, 1223, 613, 10577, 11, 286, 393, 4445, 552, 294, 3089, 11, 286, 393, 2903, 552, 294, 3669, 13], "temperature": 0.0, "avg_logprob": -0.17043647100759107, "compression_ratio": 1.6761904761904762, "no_speech_prob": 3.219174323021434e-05}, {"id": 271, "seek": 148172, "start": 1481.72, "end": 1488.68, "text": " One thing I will mention is it's very hard to read or understand something which you", "tokens": [1485, 551, 286, 486, 2152, 307, 309, 311, 588, 1152, 281, 1401, 420, 1223, 746, 597, 291], "temperature": 0.0, "avg_logprob": -0.16645476397346048, "compression_ratio": 1.6859504132231404, "no_speech_prob": 4.908516348223202e-05}, {"id": 272, "seek": 148172, "start": 1488.68, "end": 1494.88, "text": " can't vocalize, which means if you don't know the names of the Greek letters, it sounds", "tokens": [393, 380, 11657, 1125, 11, 597, 1355, 498, 291, 500, 380, 458, 264, 5288, 295, 264, 10281, 7825, 11, 309, 3263], "temperature": 0.0, "avg_logprob": -0.16645476397346048, "compression_ratio": 1.6859504132231404, "no_speech_prob": 4.908516348223202e-05}, {"id": 273, "seek": 148172, "start": 1494.88, "end": 1501.28, "text": " weird, but it's actually very difficult to understand, remember, take in a formula that", "tokens": [3657, 11, 457, 309, 311, 767, 588, 2252, 281, 1223, 11, 1604, 11, 747, 294, 257, 8513, 300], "temperature": 0.0, "avg_logprob": -0.16645476397346048, "compression_ratio": 1.6859504132231404, "no_speech_prob": 4.908516348223202e-05}, {"id": 274, "seek": 148172, "start": 1501.28, "end": 1505.72, "text": " appears again and again that's got like squiggle.", "tokens": [7038, 797, 293, 797, 300, 311, 658, 411, 2339, 19694, 13], "temperature": 0.0, "avg_logprob": -0.16645476397346048, "compression_ratio": 1.6859504132231404, "no_speech_prob": 4.908516348223202e-05}, {"id": 275, "seek": 148172, "start": 1505.72, "end": 1509.24, "text": " You need to know that that squiggle is called delta or that squiggle is called sigma or", "tokens": [509, 643, 281, 458, 300, 300, 2339, 19694, 307, 1219, 8289, 420, 300, 2339, 19694, 307, 1219, 12771, 420], "temperature": 0.0, "avg_logprob": -0.16645476397346048, "compression_ratio": 1.6859504132231404, "no_speech_prob": 4.908516348223202e-05}, {"id": 276, "seek": 148172, "start": 1509.24, "end": 1510.24, "text": " whatever.", "tokens": [2035, 13], "temperature": 0.0, "avg_logprob": -0.16645476397346048, "compression_ratio": 1.6859504132231404, "no_speech_prob": 4.908516348223202e-05}, {"id": 277, "seek": 151024, "start": 1510.24, "end": 1514.76, "text": " So spending some time learning the names of the Greek letters sounds like a strange thing", "tokens": [407, 6434, 512, 565, 2539, 264, 5288, 295, 264, 10281, 7825, 3263, 411, 257, 5861, 551], "temperature": 0.0, "avg_logprob": -0.18816793229844836, "compression_ratio": 1.6186046511627907, "no_speech_prob": 1.2606719792529475e-05}, {"id": 278, "seek": 151024, "start": 1514.76, "end": 1518.6, "text": " to do, but suddenly you don't look at these things anymore and go like squiggle A over", "tokens": [281, 360, 11, 457, 5800, 291, 500, 380, 574, 412, 613, 721, 3602, 293, 352, 411, 2339, 19694, 316, 670], "temperature": 0.0, "avg_logprob": -0.18816793229844836, "compression_ratio": 1.6186046511627907, "no_speech_prob": 1.2606719792529475e-05}, {"id": 279, "seek": 151024, "start": 1518.6, "end": 1523.36, "text": " squiggle B plus other weird squiggle looks like a Y thing.", "tokens": [2339, 19694, 363, 1804, 661, 3657, 2339, 19694, 1542, 411, 257, 398, 551, 13], "temperature": 0.0, "avg_logprob": -0.18816793229844836, "compression_ratio": 1.6186046511627907, "no_speech_prob": 1.2606719792529475e-05}, {"id": 280, "seek": 151024, "start": 1523.36, "end": 1529.52, "text": " They've all got names.", "tokens": [814, 600, 439, 658, 5288, 13], "temperature": 0.0, "avg_logprob": -0.18816793229844836, "compression_ratio": 1.6186046511627907, "no_speech_prob": 1.2606719792529475e-05}, {"id": 281, "seek": 151024, "start": 1529.52, "end": 1536.6, "text": " So now that we're kind of at the cutting edge stage, a lot of the stuff we'll be learning", "tokens": [407, 586, 300, 321, 434, 733, 295, 412, 264, 6492, 4691, 3233, 11, 257, 688, 295, 264, 1507, 321, 603, 312, 2539], "temperature": 0.0, "avg_logprob": -0.18816793229844836, "compression_ratio": 1.6186046511627907, "no_speech_prob": 1.2606719792529475e-05}, {"id": 282, "seek": 153660, "start": 1536.6, "end": 1543.84, "text": " this class is stuff that almost nobody else knows about.", "tokens": [341, 1508, 307, 1507, 300, 1920, 5079, 1646, 3255, 466, 13], "temperature": 0.0, "avg_logprob": -0.1578523698060409, "compression_ratio": 1.7136752136752136, "no_speech_prob": 1.4510070286632981e-05}, {"id": 283, "seek": 153660, "start": 1543.84, "end": 1551.32, "text": " So that's a great opportunity for you to be the first person to create an understandable", "tokens": [407, 300, 311, 257, 869, 2650, 337, 291, 281, 312, 264, 700, 954, 281, 1884, 364, 25648], "temperature": 0.0, "avg_logprob": -0.1578523698060409, "compression_ratio": 1.7136752136752136, "no_speech_prob": 1.4510070286632981e-05}, {"id": 284, "seek": 153660, "start": 1551.32, "end": 1555.8799999999999, "text": " and generalizable code library that implements it, or the first person to write a blog post", "tokens": [293, 2674, 22395, 3089, 6405, 300, 704, 17988, 309, 11, 420, 264, 700, 954, 281, 2464, 257, 6968, 2183], "temperature": 0.0, "avg_logprob": -0.1578523698060409, "compression_ratio": 1.7136752136752136, "no_speech_prob": 1.4510070286632981e-05}, {"id": 285, "seek": 153660, "start": 1555.8799999999999, "end": 1560.9599999999998, "text": " that explains it in clear English, or the first person to try applying it to this slightly", "tokens": [300, 13948, 309, 294, 1850, 3669, 11, 420, 264, 700, 954, 281, 853, 9275, 309, 281, 341, 4748], "temperature": 0.0, "avg_logprob": -0.1578523698060409, "compression_ratio": 1.7136752136752136, "no_speech_prob": 1.4510070286632981e-05}, {"id": 286, "seek": 153660, "start": 1560.9599999999998, "end": 1566.28, "text": " different area that's obviously going to work just as well, or whatever.", "tokens": [819, 1859, 300, 311, 2745, 516, 281, 589, 445, 382, 731, 11, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1578523698060409, "compression_ratio": 1.7136752136752136, "no_speech_prob": 1.4510070286632981e-05}, {"id": 287, "seek": 156628, "start": 1566.28, "end": 1572.92, "text": " So when we say cutting edge research, that doesn't mean you have to come up with the", "tokens": [407, 562, 321, 584, 6492, 4691, 2132, 11, 300, 1177, 380, 914, 291, 362, 281, 808, 493, 365, 264], "temperature": 0.0, "avg_logprob": -0.15956411361694336, "compression_ratio": 1.62, "no_speech_prob": 1.0952931006613653e-05}, {"id": 288, "seek": 156628, "start": 1572.92, "end": 1578.56, "text": " next batch norm or the next atom or the next diluted convolution.", "tokens": [958, 15245, 2026, 420, 264, 958, 12018, 420, 264, 958, 11504, 4866, 45216, 13], "temperature": 0.0, "avg_logprob": -0.15956411361694336, "compression_ratio": 1.62, "no_speech_prob": 1.0952931006613653e-05}, {"id": 289, "seek": 156628, "start": 1578.56, "end": 1587.12, "text": " It can mean like, take this thing that was used for translation and apply it to this", "tokens": [467, 393, 914, 411, 11, 747, 341, 551, 300, 390, 1143, 337, 12853, 293, 3079, 309, 281, 341], "temperature": 0.0, "avg_logprob": -0.15956411361694336, "compression_ratio": 1.62, "no_speech_prob": 1.0952931006613653e-05}, {"id": 290, "seek": 156628, "start": 1587.12, "end": 1593.96, "text": " very similar other parallel NLP task, or take this thing that was tested on skin lesions", "tokens": [588, 2531, 661, 8952, 426, 45196, 5633, 11, 420, 747, 341, 551, 300, 390, 8246, 322, 3178, 1512, 626], "temperature": 0.0, "avg_logprob": -0.15956411361694336, "compression_ratio": 1.62, "no_speech_prob": 1.0952931006613653e-05}, {"id": 291, "seek": 159396, "start": 1593.96, "end": 1599.08, "text": " and trusted on this data set of this other kind of lesion, or whatever.", "tokens": [293, 16034, 322, 341, 1412, 992, 295, 341, 661, 733, 295, 1512, 313, 11, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.18615554627918063, "compression_ratio": 1.52863436123348, "no_speech_prob": 8.397987585340161e-06}, {"id": 292, "seek": 159396, "start": 1599.08, "end": 1605.64, "text": " That kind of stuff is super great learning experience and incredibly useful because for", "tokens": [663, 733, 295, 1507, 307, 1687, 869, 2539, 1752, 293, 6252, 4420, 570, 337], "temperature": 0.0, "avg_logprob": -0.18615554627918063, "compression_ratio": 1.52863436123348, "no_speech_prob": 8.397987585340161e-06}, {"id": 293, "seek": 159396, "start": 1605.64, "end": 1610.68, "text": " the vast majority of the world that knows nothing about this whole field, it just looks", "tokens": [264, 8369, 6286, 295, 264, 1002, 300, 3255, 1825, 466, 341, 1379, 2519, 11, 309, 445, 1542], "temperature": 0.0, "avg_logprob": -0.18615554627918063, "compression_ratio": 1.52863436123348, "no_speech_prob": 8.397987585340161e-06}, {"id": 294, "seek": 159396, "start": 1610.68, "end": 1611.68, "text": " like magic.", "tokens": [411, 5585, 13], "temperature": 0.0, "avg_logprob": -0.18615554627918063, "compression_ratio": 1.52863436123348, "no_speech_prob": 8.397987585340161e-06}, {"id": 295, "seek": 159396, "start": 1611.68, "end": 1618.4, "text": " You'll be like, hey, I've for the first time shown greater than 90% accuracy at finding", "tokens": [509, 603, 312, 411, 11, 4177, 11, 286, 600, 337, 264, 700, 565, 4898, 5044, 813, 4289, 4, 14170, 412, 5006], "temperature": 0.0, "avg_logprob": -0.18615554627918063, "compression_ratio": 1.52863436123348, "no_speech_prob": 8.397987585340161e-06}, {"id": 296, "seek": 161840, "start": 1618.4, "end": 1627.64, "text": " this kind of lesion in this kind of data.", "tokens": [341, 733, 295, 1512, 313, 294, 341, 733, 295, 1412, 13], "temperature": 0.0, "avg_logprob": -0.15703807053742586, "compression_ratio": 1.4859154929577465, "no_speech_prob": 3.785304897974129e-06}, {"id": 297, "seek": 161840, "start": 1627.64, "end": 1633.5600000000002, "text": " So when I say experiment in your area of expertise, one of the things we particularly look for", "tokens": [407, 562, 286, 584, 5120, 294, 428, 1859, 295, 11769, 11, 472, 295, 264, 721, 321, 4098, 574, 337], "temperature": 0.0, "avg_logprob": -0.15703807053742586, "compression_ratio": 1.4859154929577465, "no_speech_prob": 3.785304897974129e-06}, {"id": 298, "seek": 161840, "start": 1633.5600000000002, "end": 1641.24, "text": " in this class is to bring in people who are pretty good at something else.", "tokens": [294, 341, 1508, 307, 281, 1565, 294, 561, 567, 366, 1238, 665, 412, 746, 1646, 13], "temperature": 0.0, "avg_logprob": -0.15703807053742586, "compression_ratio": 1.4859154929577465, "no_speech_prob": 3.785304897974129e-06}, {"id": 299, "seek": 164124, "start": 1641.24, "end": 1651.0, "text": " Pretty good at meteorology, pretty good at de novo drug design, or pretty good at goat", "tokens": [10693, 665, 412, 25313, 1793, 11, 1238, 665, 412, 368, 18246, 4110, 1715, 11, 420, 1238, 665, 412, 23608], "temperature": 0.0, "avg_logprob": -0.26430759732685394, "compression_ratio": 1.62, "no_speech_prob": 1.3709528730032616e-06}, {"id": 300, "seek": 164124, "start": 1651.0, "end": 1660.0, "text": " dairy farming, or whatever.", "tokens": [21276, 16557, 11, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.26430759732685394, "compression_ratio": 1.62, "no_speech_prob": 1.3709528730032616e-06}, {"id": 301, "seek": 164124, "start": 1660.0, "end": 1666.0, "text": " So probably the thing you can do the best would be to take that thing you're already", "tokens": [407, 1391, 264, 551, 291, 393, 360, 264, 1151, 576, 312, 281, 747, 300, 551, 291, 434, 1217], "temperature": 0.0, "avg_logprob": -0.26430759732685394, "compression_ratio": 1.62, "no_speech_prob": 1.3709528730032616e-06}, {"id": 302, "seek": 164124, "start": 1666.0, "end": 1669.4, "text": " pretty good at and add on these new skills.", "tokens": [1238, 665, 412, 293, 909, 322, 613, 777, 3942, 13], "temperature": 0.0, "avg_logprob": -0.26430759732685394, "compression_ratio": 1.62, "no_speech_prob": 1.3709528730032616e-06}, {"id": 303, "seek": 166940, "start": 1669.4, "end": 1673.5600000000002, "text": " Because otherwise, if you're trying to go into some different domain, you're going to", "tokens": [1436, 5911, 11, 498, 291, 434, 1382, 281, 352, 666, 512, 819, 9274, 11, 291, 434, 516, 281], "temperature": 0.0, "avg_logprob": -0.19722595549466318, "compression_ratio": 1.7846153846153847, "no_speech_prob": 3.071764876949601e-05}, {"id": 304, "seek": 166940, "start": 1673.5600000000002, "end": 1677.1200000000001, "text": " have to figure out how do I get data for that domain, how do I know what interesting problems", "tokens": [362, 281, 2573, 484, 577, 360, 286, 483, 1412, 337, 300, 9274, 11, 577, 360, 286, 458, 437, 1880, 2740], "temperature": 0.0, "avg_logprob": -0.19722595549466318, "compression_ratio": 1.7846153846153847, "no_speech_prob": 3.071764876949601e-05}, {"id": 305, "seek": 166940, "start": 1677.1200000000001, "end": 1680.68, "text": " to solve in that domain, and so forth.", "tokens": [281, 5039, 294, 300, 9274, 11, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.19722595549466318, "compression_ratio": 1.7846153846153847, "no_speech_prob": 3.071764876949601e-05}, {"id": 306, "seek": 166940, "start": 1680.68, "end": 1685.48, "text": " Where else often it'll seem pretty trivial to you to take this technique and apply it", "tokens": [2305, 1646, 2049, 309, 603, 1643, 1238, 26703, 281, 291, 281, 747, 341, 6532, 293, 3079, 309], "temperature": 0.0, "avg_logprob": -0.19722595549466318, "compression_ratio": 1.7846153846153847, "no_speech_prob": 3.071764876949601e-05}, {"id": 307, "seek": 166940, "start": 1685.48, "end": 1689.0800000000002, "text": " to this data set that you've already got sitting on your hard drive, but that's often going", "tokens": [281, 341, 1412, 992, 300, 291, 600, 1217, 658, 3798, 322, 428, 1152, 3332, 11, 457, 300, 311, 2049, 516], "temperature": 0.0, "avg_logprob": -0.19722595549466318, "compression_ratio": 1.7846153846153847, "no_speech_prob": 3.071764876949601e-05}, {"id": 308, "seek": 166940, "start": 1689.0800000000002, "end": 1694.4, "text": " to be the super interesting thing for the rest of the world to see.", "tokens": [281, 312, 264, 1687, 1880, 551, 337, 264, 1472, 295, 264, 1002, 281, 536, 13], "temperature": 0.0, "avg_logprob": -0.19722595549466318, "compression_ratio": 1.7846153846153847, "no_speech_prob": 3.071764876949601e-05}, {"id": 309, "seek": 169440, "start": 1694.4, "end": 1701.44, "text": " That's interesting when you apply it to meteorology data and you use this RNN or whatever, it", "tokens": [663, 311, 1880, 562, 291, 3079, 309, 281, 25313, 1793, 1412, 293, 291, 764, 341, 45702, 45, 420, 2035, 11, 309], "temperature": 0.0, "avg_logprob": -0.2356388236902937, "compression_ratio": 1.5114155251141552, "no_speech_prob": 5.6823710110620596e-06}, {"id": 310, "seek": 169440, "start": 1701.44, "end": 1710.64, "text": " allows you to forecast over larger areas or longer time periods.", "tokens": [4045, 291, 281, 14330, 670, 4833, 3179, 420, 2854, 565, 13804, 13], "temperature": 0.0, "avg_logprob": -0.2356388236902937, "compression_ratio": 1.5114155251141552, "no_speech_prob": 5.6823710110620596e-06}, {"id": 311, "seek": 169440, "start": 1710.64, "end": 1714.6000000000001, "text": " So communicating what you're doing is super helpful.", "tokens": [407, 17559, 437, 291, 434, 884, 307, 1687, 4961, 13], "temperature": 0.0, "avg_logprob": -0.2356388236902937, "compression_ratio": 1.5114155251141552, "no_speech_prob": 5.6823710110620596e-06}, {"id": 312, "seek": 169440, "start": 1714.6000000000001, "end": 1717.3600000000001, "text": " We've talked about that before.", "tokens": [492, 600, 2825, 466, 300, 949, 13], "temperature": 0.0, "avg_logprob": -0.2356388236902937, "compression_ratio": 1.5114155251141552, "no_speech_prob": 5.6823710110620596e-06}, {"id": 313, "seek": 169440, "start": 1717.3600000000001, "end": 1722.64, "text": " I know something that a lot of people on the forums ask people who have already written", "tokens": [286, 458, 746, 300, 257, 688, 295, 561, 322, 264, 26998, 1029, 561, 567, 362, 1217, 3720], "temperature": 0.0, "avg_logprob": -0.2356388236902937, "compression_ratio": 1.5114155251141552, "no_speech_prob": 5.6823710110620596e-06}, {"id": 314, "seek": 172264, "start": 1722.64, "end": 1729.4, "text": " a blog, often people on the forum will be like, how did you get up the guts to do that,", "tokens": [257, 6968, 11, 2049, 561, 322, 264, 17542, 486, 312, 411, 11, 577, 630, 291, 483, 493, 264, 28560, 281, 360, 300, 11], "temperature": 0.0, "avg_logprob": -0.225386078824702, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.183194611570798e-06}, {"id": 315, "seek": 172264, "start": 1729.4, "end": 1733.1000000000001, "text": " or what was the process you got to before you decided to start publishing something", "tokens": [420, 437, 390, 264, 1399, 291, 658, 281, 949, 291, 3047, 281, 722, 17832, 746], "temperature": 0.0, "avg_logprob": -0.225386078824702, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.183194611570798e-06}, {"id": 316, "seek": 172264, "start": 1733.1000000000001, "end": 1734.1000000000001, "text": " or whatever.", "tokens": [420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.225386078824702, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.183194611570798e-06}, {"id": 317, "seek": 172264, "start": 1734.1000000000001, "end": 1736.6000000000001, "text": " The answer is always the same.", "tokens": [440, 1867, 307, 1009, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.225386078824702, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.183194611570798e-06}, {"id": 318, "seek": 172264, "start": 1736.6000000000001, "end": 1744.68, "text": " It's always just, I was sure I wasn't good enough to do it, I felt terrified and intimidated", "tokens": [467, 311, 1009, 445, 11, 286, 390, 988, 286, 2067, 380, 665, 1547, 281, 360, 309, 11, 286, 2762, 23051, 293, 40234], "temperature": 0.0, "avg_logprob": -0.225386078824702, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.183194611570798e-06}, {"id": 319, "seek": 172264, "start": 1744.68, "end": 1748.68, "text": " of doing it, but I wrote it and posted it anyway.", "tokens": [295, 884, 309, 11, 457, 286, 4114, 309, 293, 9437, 309, 4033, 13], "temperature": 0.0, "avg_logprob": -0.225386078824702, "compression_ratio": 1.6422018348623852, "no_speech_prob": 7.183194611570798e-06}, {"id": 320, "seek": 174868, "start": 1748.68, "end": 1756.68, "text": " There's never a time I think any of us actually feel like we're not total frauds and impostors,", "tokens": [821, 311, 1128, 257, 565, 286, 519, 604, 295, 505, 767, 841, 411, 321, 434, 406, 3217, 14560, 82, 293, 47804, 830, 11], "temperature": 0.0, "avg_logprob": -0.14297476268949963, "compression_ratio": 1.7385159010600706, "no_speech_prob": 2.977231088152621e-05}, {"id": 321, "seek": 174868, "start": 1756.68, "end": 1761.92, "text": " but we know more about what we're doing than us of 6 months ago.", "tokens": [457, 321, 458, 544, 466, 437, 321, 434, 884, 813, 505, 295, 1386, 2493, 2057, 13], "temperature": 0.0, "avg_logprob": -0.14297476268949963, "compression_ratio": 1.7385159010600706, "no_speech_prob": 2.977231088152621e-05}, {"id": 322, "seek": 174868, "start": 1761.92, "end": 1765.3200000000002, "text": " And there's somebody else in the world who knows as much as you did 6 months ago, so", "tokens": [400, 456, 311, 2618, 1646, 294, 264, 1002, 567, 3255, 382, 709, 382, 291, 630, 1386, 2493, 2057, 11, 370], "temperature": 0.0, "avg_logprob": -0.14297476268949963, "compression_ratio": 1.7385159010600706, "no_speech_prob": 2.977231088152621e-05}, {"id": 323, "seek": 174868, "start": 1765.3200000000002, "end": 1769.48, "text": " if you write something now that would have helped you of 6 months ago, you're helping", "tokens": [498, 291, 2464, 746, 586, 300, 576, 362, 4254, 291, 295, 1386, 2493, 2057, 11, 291, 434, 4315], "temperature": 0.0, "avg_logprob": -0.14297476268949963, "compression_ratio": 1.7385159010600706, "no_speech_prob": 2.977231088152621e-05}, {"id": 324, "seek": 174868, "start": 1769.48, "end": 1770.48, "text": " some people.", "tokens": [512, 561, 13], "temperature": 0.0, "avg_logprob": -0.14297476268949963, "compression_ratio": 1.7385159010600706, "no_speech_prob": 2.977231088152621e-05}, {"id": 325, "seek": 174868, "start": 1770.48, "end": 1775.5600000000002, "text": " And honestly if you wait another 6 months, then the you of 12 months ago probably won't", "tokens": [400, 6095, 498, 291, 1699, 1071, 1386, 2493, 11, 550, 264, 291, 295, 2272, 2493, 2057, 1391, 1582, 380], "temperature": 0.0, "avg_logprob": -0.14297476268949963, "compression_ratio": 1.7385159010600706, "no_speech_prob": 2.977231088152621e-05}, {"id": 326, "seek": 174868, "start": 1775.5600000000002, "end": 1778.48, "text": " even understand that anymore because it's too advanced now.", "tokens": [754, 1223, 300, 3602, 570, 309, 311, 886, 7339, 586, 13], "temperature": 0.0, "avg_logprob": -0.14297476268949963, "compression_ratio": 1.7385159010600706, "no_speech_prob": 2.977231088152621e-05}, {"id": 327, "seek": 177848, "start": 1778.48, "end": 1786.28, "text": " It's great to communicate wherever you're up to in a way that you think would be helpful", "tokens": [467, 311, 869, 281, 7890, 8660, 291, 434, 493, 281, 294, 257, 636, 300, 291, 519, 576, 312, 4961], "temperature": 0.0, "avg_logprob": -0.19407498530852488, "compression_ratio": 1.62, "no_speech_prob": 3.071699757128954e-05}, {"id": 328, "seek": 177848, "start": 1786.28, "end": 1791.56, "text": " to the person you were before you knew that thing.", "tokens": [281, 264, 954, 291, 645, 949, 291, 2586, 300, 551, 13], "temperature": 0.0, "avg_logprob": -0.19407498530852488, "compression_ratio": 1.62, "no_speech_prob": 3.071699757128954e-05}, {"id": 329, "seek": 177848, "start": 1791.56, "end": 1796.72, "text": " And of course something that the forums have been useful for is getting feedback about", "tokens": [400, 295, 1164, 746, 300, 264, 26998, 362, 668, 4420, 337, 307, 1242, 5824, 466], "temperature": 0.0, "avg_logprob": -0.19407498530852488, "compression_ratio": 1.62, "no_speech_prob": 3.071699757128954e-05}, {"id": 330, "seek": 177848, "start": 1796.72, "end": 1800.16, "text": " drafts.", "tokens": [11206, 82, 13], "temperature": 0.0, "avg_logprob": -0.19407498530852488, "compression_ratio": 1.62, "no_speech_prob": 3.071699757128954e-05}, {"id": 331, "seek": 177848, "start": 1800.16, "end": 1807.08, "text": " If you post a draft of something that you're thinking of releasing, then other folks here", "tokens": [759, 291, 2183, 257, 11206, 295, 746, 300, 291, 434, 1953, 295, 16327, 11, 550, 661, 4024, 510], "temperature": 0.0, "avg_logprob": -0.19407498530852488, "compression_ratio": 1.62, "no_speech_prob": 3.071699757128954e-05}, {"id": 332, "seek": 180708, "start": 1807.08, "end": 1812.6, "text": " can point out things that they find unclear or they think they need some corrections or", "tokens": [393, 935, 484, 721, 300, 436, 915, 25636, 420, 436, 519, 436, 643, 512, 36406, 420], "temperature": 0.0, "avg_logprob": -0.3141761779785156, "compression_ratio": 1.5625, "no_speech_prob": 6.048880095477216e-06}, {"id": 333, "seek": 180708, "start": 1812.6, "end": 1813.6, "text": " whatever.", "tokens": [2035, 13], "temperature": 0.0, "avg_logprob": -0.3141761779785156, "compression_ratio": 1.5625, "no_speech_prob": 6.048880095477216e-06}, {"id": 334, "seek": 180708, "start": 1813.6, "end": 1823.6399999999999, "text": " So the overarching theme of part 2 I've described as generative models, but unfortunately then", "tokens": [407, 264, 45501, 6314, 295, 644, 568, 286, 600, 7619, 382, 1337, 1166, 5245, 11, 457, 7015, 550], "temperature": 0.0, "avg_logprob": -0.3141761779785156, "compression_ratio": 1.5625, "no_speech_prob": 6.048880095477216e-06}, {"id": 335, "seek": 180708, "start": 1823.6399999999999, "end": 1827.1599999999999, "text": " Rachel asked me this afternoon exactly what I meant by generative models and I realize", "tokens": [14246, 2351, 385, 341, 6499, 2293, 437, 286, 4140, 538, 1337, 1166, 5245, 293, 286, 4325], "temperature": 0.0, "avg_logprob": -0.3141761779785156, "compression_ratio": 1.5625, "no_speech_prob": 6.048880095477216e-06}, {"id": 336, "seek": 180708, "start": 1827.1599999999999, "end": 1830.0, "text": " I don't really know.", "tokens": [286, 500, 380, 534, 458, 13], "temperature": 0.0, "avg_logprob": -0.3141761779785156, "compression_ratio": 1.5625, "no_speech_prob": 6.048880095477216e-06}, {"id": 337, "seek": 183000, "start": 1830.0, "end": 1839.68, "text": " So what I really mean is in part 1, the output of our neural networks is generally like a", "tokens": [407, 437, 286, 534, 914, 307, 294, 644, 502, 11, 264, 5598, 295, 527, 18161, 9590, 307, 5101, 411, 257], "temperature": 0.0, "avg_logprob": -0.21520504806980942, "compression_ratio": 1.5757575757575757, "no_speech_prob": 5.862753369001439e-06}, {"id": 338, "seek": 183000, "start": 1839.68, "end": 1849.48, "text": " number or a category, whereas the outputs of a lot of the stuff in part 2 are going", "tokens": [1230, 420, 257, 7719, 11, 9735, 264, 23930, 295, 257, 688, 295, 264, 1507, 294, 644, 568, 366, 516], "temperature": 0.0, "avg_logprob": -0.21520504806980942, "compression_ratio": 1.5757575757575757, "no_speech_prob": 5.862753369001439e-06}, {"id": 339, "seek": 183000, "start": 1849.48, "end": 1857.8, "text": " to be like a whole lot of things, like the top left and bottom right location of every", "tokens": [281, 312, 411, 257, 1379, 688, 295, 721, 11, 411, 264, 1192, 1411, 293, 2767, 558, 4914, 295, 633], "temperature": 0.0, "avg_logprob": -0.21520504806980942, "compression_ratio": 1.5757575757575757, "no_speech_prob": 5.862753369001439e-06}, {"id": 340, "seek": 185780, "start": 1857.8, "end": 1863.8999999999999, "text": " object in an image along with what the object is, or a complete picture with a class of", "tokens": [2657, 294, 364, 3256, 2051, 365, 437, 264, 2657, 307, 11, 420, 257, 3566, 3036, 365, 257, 1508, 295], "temperature": 0.0, "avg_logprob": -0.13863947608254173, "compression_ratio": 1.5769230769230769, "no_speech_prob": 1.6441550542367622e-05}, {"id": 341, "seek": 185780, "start": 1863.8999999999999, "end": 1871.96, "text": " every single pixel in that picture, or an enhanced super resolution version of the input", "tokens": [633, 2167, 19261, 294, 300, 3036, 11, 420, 364, 21191, 1687, 8669, 3037, 295, 264, 4846], "temperature": 0.0, "avg_logprob": -0.13863947608254173, "compression_ratio": 1.5769230769230769, "no_speech_prob": 1.6441550542367622e-05}, {"id": 342, "seek": 185780, "start": 1871.96, "end": 1883.36, "text": " image, or the entire original input paragraph translated into French.", "tokens": [3256, 11, 420, 264, 2302, 3380, 4846, 18865, 16805, 666, 5522, 13], "temperature": 0.0, "avg_logprob": -0.13863947608254173, "compression_ratio": 1.5769230769230769, "no_speech_prob": 1.6441550542367622e-05}, {"id": 343, "seek": 188336, "start": 1883.36, "end": 1891.04, "text": " It's kind of like, often it just requires some different ways of thinking about things", "tokens": [467, 311, 733, 295, 411, 11, 2049, 309, 445, 7029, 512, 819, 2098, 295, 1953, 466, 721], "temperature": 0.0, "avg_logprob": -0.15809765094664038, "compression_ratio": 1.7473118279569892, "no_speech_prob": 1.0129784641321748e-05}, {"id": 344, "seek": 188336, "start": 1891.04, "end": 1894.0, "text": " and some kind of different architectures and so forth.", "tokens": [293, 512, 733, 295, 819, 6331, 1303, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.15809765094664038, "compression_ratio": 1.7473118279569892, "no_speech_prob": 1.0129784641321748e-05}, {"id": 345, "seek": 188336, "start": 1894.0, "end": 1901.3999999999999, "text": " So that's kind of like the main theme of the kind of techniques we'll be looking at.", "tokens": [407, 300, 311, 733, 295, 411, 264, 2135, 6314, 295, 264, 733, 295, 7512, 321, 603, 312, 1237, 412, 13], "temperature": 0.0, "avg_logprob": -0.15809765094664038, "compression_ratio": 1.7473118279569892, "no_speech_prob": 1.0129784641321748e-05}, {"id": 346, "seek": 188336, "start": 1901.3999999999999, "end": 1907.76, "text": " The vast majority, possibly all of the data we'll be looking at will be either text or", "tokens": [440, 8369, 6286, 11, 6264, 439, 295, 264, 1412, 321, 603, 312, 1237, 412, 486, 312, 2139, 2487, 420], "temperature": 0.0, "avg_logprob": -0.15809765094664038, "compression_ratio": 1.7473118279569892, "no_speech_prob": 1.0129784641321748e-05}, {"id": 347, "seek": 188336, "start": 1907.76, "end": 1911.84, "text": " image data.", "tokens": [3256, 1412, 13], "temperature": 0.0, "avg_logprob": -0.15809765094664038, "compression_ratio": 1.7473118279569892, "no_speech_prob": 1.0129784641321748e-05}, {"id": 348, "seek": 191184, "start": 1911.84, "end": 1919.6, "text": " It would be fairly trivial to do most of these things with audio as well, it's just not something", "tokens": [467, 576, 312, 6457, 26703, 281, 360, 881, 295, 613, 721, 365, 6278, 382, 731, 11, 309, 311, 445, 406, 746], "temperature": 0.0, "avg_logprob": -0.14547377884990037, "compression_ratio": 1.6144578313253013, "no_speech_prob": 8.013411388674285e-06}, {"id": 349, "seek": 191184, "start": 1919.6, "end": 1923.3999999999999, "text": " I've spent much time on myself yet.", "tokens": [286, 600, 4418, 709, 565, 322, 2059, 1939, 13], "temperature": 0.0, "avg_logprob": -0.14547377884990037, "compression_ratio": 1.6144578313253013, "no_speech_prob": 8.013411388674285e-06}, {"id": 350, "seek": 191184, "start": 1923.3999999999999, "end": 1927.52, "text": " Somebody asked on the forum about what can we do more stuff with time series and tabular", "tokens": [13463, 2351, 322, 264, 17542, 466, 437, 393, 321, 360, 544, 1507, 365, 565, 2638, 293, 4421, 1040], "temperature": 0.0, "avg_logprob": -0.14547377884990037, "compression_ratio": 1.6144578313253013, "no_speech_prob": 8.013411388674285e-06}, {"id": 351, "seek": 191184, "start": 1927.52, "end": 1933.9599999999998, "text": " data, and my answer was, I've already taught you everything I know about that and I'm not", "tokens": [1412, 11, 293, 452, 1867, 390, 11, 286, 600, 1217, 5928, 291, 1203, 286, 458, 466, 300, 293, 286, 478, 406], "temperature": 0.0, "avg_logprob": -0.14547377884990037, "compression_ratio": 1.6144578313253013, "no_speech_prob": 8.013411388674285e-06}, {"id": 352, "seek": 191184, "start": 1933.9599999999998, "end": 1941.08, "text": " sure there's much else to say, particularly if you check out the machine learning course,", "tokens": [988, 456, 311, 709, 1646, 281, 584, 11, 4098, 498, 291, 1520, 484, 264, 3479, 2539, 1164, 11], "temperature": 0.0, "avg_logprob": -0.14547377884990037, "compression_ratio": 1.6144578313253013, "no_speech_prob": 8.013411388674285e-06}, {"id": 353, "seek": 194108, "start": 1941.08, "end": 1943.48, "text": " which goes into a lot of that in a lot more detail.", "tokens": [597, 1709, 666, 257, 688, 295, 300, 294, 257, 688, 544, 2607, 13], "temperature": 0.0, "avg_logprob": -0.1830428327832903, "compression_ratio": 1.5729166666666667, "no_speech_prob": 2.931035305664409e-05}, {"id": 354, "seek": 194108, "start": 1943.48, "end": 1947.4399999999998, "text": " So I don't feel like there's more stuff to tell you.", "tokens": [407, 286, 500, 380, 841, 411, 456, 311, 544, 1507, 281, 980, 291, 13], "temperature": 0.0, "avg_logprob": -0.1830428327832903, "compression_ratio": 1.5729166666666667, "no_speech_prob": 2.931035305664409e-05}, {"id": 355, "seek": 194108, "start": 1947.4399999999998, "end": 1954.6799999999998, "text": " I think that's a super important area, but I think we're done.", "tokens": [286, 519, 300, 311, 257, 1687, 1021, 1859, 11, 457, 286, 519, 321, 434, 1096, 13], "temperature": 0.0, "avg_logprob": -0.1830428327832903, "compression_ratio": 1.5729166666666667, "no_speech_prob": 2.931035305664409e-05}, {"id": 356, "seek": 194108, "start": 1954.6799999999998, "end": 1964.0, "text": " We'll be looking at some larger datasets, both in terms of the number of objects in", "tokens": [492, 603, 312, 1237, 412, 512, 4833, 42856, 11, 1293, 294, 2115, 295, 264, 1230, 295, 6565, 294], "temperature": 0.0, "avg_logprob": -0.1830428327832903, "compression_ratio": 1.5729166666666667, "no_speech_prob": 2.931035305664409e-05}, {"id": 357, "seek": 194108, "start": 1964.0, "end": 1967.6, "text": " the dataset and the size of each of those objects.", "tokens": [264, 28872, 293, 264, 2744, 295, 1184, 295, 729, 6565, 13], "temperature": 0.0, "avg_logprob": -0.1830428327832903, "compression_ratio": 1.5729166666666667, "no_speech_prob": 2.931035305664409e-05}, {"id": 358, "seek": 196760, "start": 1967.6, "end": 1971.6799999999998, "text": " For those of you that are working with limited computational resources, please don't let", "tokens": [1171, 729, 295, 291, 300, 366, 1364, 365, 5567, 28270, 3593, 11, 1767, 500, 380, 718], "temperature": 0.0, "avg_logprob": -0.1682766751126126, "compression_ratio": 1.6653846153846155, "no_speech_prob": 1.8058046407531947e-05}, {"id": 359, "seek": 196760, "start": 1971.6799999999998, "end": 1972.6799999999998, "text": " that put you off.", "tokens": [300, 829, 291, 766, 13], "temperature": 0.0, "avg_logprob": -0.1682766751126126, "compression_ratio": 1.6653846153846155, "no_speech_prob": 1.8058046407531947e-05}, {"id": 360, "seek": 196760, "start": 1972.6799999999998, "end": 1976.52, "text": " Feel free to replace it with something smaller and simpler.", "tokens": [14113, 1737, 281, 7406, 309, 365, 746, 4356, 293, 18587, 13], "temperature": 0.0, "avg_logprob": -0.1682766751126126, "compression_ratio": 1.6653846153846155, "no_speech_prob": 1.8058046407531947e-05}, {"id": 361, "seek": 196760, "start": 1976.52, "end": 1982.28, "text": " In fact, when I was designing this course, I did quite a lot of it in Australia when", "tokens": [682, 1186, 11, 562, 286, 390, 14685, 341, 1164, 11, 286, 630, 1596, 257, 688, 295, 309, 294, 7060, 562], "temperature": 0.0, "avg_logprob": -0.1682766751126126, "compression_ratio": 1.6653846153846155, "no_speech_prob": 1.8058046407531947e-05}, {"id": 362, "seek": 196760, "start": 1982.28, "end": 1989.76, "text": " I went to visit my mom, and my mom decided to book a nice holiday house for us with fast", "tokens": [286, 1437, 281, 3441, 452, 1225, 11, 293, 452, 1225, 3047, 281, 1446, 257, 1481, 9960, 1782, 337, 505, 365, 2370], "temperature": 0.0, "avg_logprob": -0.1682766751126126, "compression_ratio": 1.6653846153846155, "no_speech_prob": 1.8058046407531947e-05}, {"id": 363, "seek": 196760, "start": 1989.76, "end": 1990.76, "text": " WiFi.", "tokens": [32885, 13], "temperature": 0.0, "avg_logprob": -0.1682766751126126, "compression_ratio": 1.6653846153846155, "no_speech_prob": 1.8058046407531947e-05}, {"id": 364, "seek": 196760, "start": 1990.76, "end": 1997.3999999999999, "text": " We turned up to the holiday house with fast WiFi, and indeed it did have WiFi, but the", "tokens": [492, 3574, 493, 281, 264, 9960, 1782, 365, 2370, 32885, 11, 293, 6451, 309, 630, 362, 32885, 11, 457, 264], "temperature": 0.0, "avg_logprob": -0.1682766751126126, "compression_ratio": 1.6653846153846155, "no_speech_prob": 1.8058046407531947e-05}, {"id": 365, "seek": 199740, "start": 1997.4, "end": 2002.4, "text": " WiFi was not connected to the Internet.", "tokens": [32885, 390, 406, 4582, 281, 264, 7703, 13], "temperature": 0.0, "avg_logprob": -0.1923422420726103, "compression_ratio": 1.621761658031088, "no_speech_prob": 3.1690702599007636e-05}, {"id": 366, "seek": 199740, "start": 2002.4, "end": 2010.6000000000001, "text": " So I called up the agent and I said, I found the ADSL router and it's got an ADSL thing", "tokens": [407, 286, 1219, 493, 264, 9461, 293, 286, 848, 11, 286, 1352, 264, 9135, 47012, 22492, 293, 309, 311, 658, 364, 9135, 47012, 551], "temperature": 0.0, "avg_logprob": -0.1923422420726103, "compression_ratio": 1.621761658031088, "no_speech_prob": 3.1690702599007636e-05}, {"id": 367, "seek": 199740, "start": 2010.6000000000001, "end": 2013.68, "text": " plugged in, and I followed the cable down and the other end of the cable has nothing", "tokens": [25679, 294, 11, 293, 286, 6263, 264, 8220, 760, 293, 264, 661, 917, 295, 264, 8220, 575, 1825], "temperature": 0.0, "avg_logprob": -0.1923422420726103, "compression_ratio": 1.621761658031088, "no_speech_prob": 3.1690702599007636e-05}, {"id": 368, "seek": 199740, "start": 2013.68, "end": 2016.0, "text": " to plug into.", "tokens": [281, 5452, 666, 13], "temperature": 0.0, "avg_logprob": -0.1923422420726103, "compression_ratio": 1.621761658031088, "no_speech_prob": 3.1690702599007636e-05}, {"id": 369, "seek": 199740, "start": 2016.0, "end": 2026.4, "text": " So she called the people renting the house, the owner, and called me back the next day", "tokens": [407, 750, 1219, 264, 561, 40598, 264, 1782, 11, 264, 7289, 11, 293, 1219, 385, 646, 264, 958, 786], "temperature": 0.0, "avg_logprob": -0.1923422420726103, "compression_ratio": 1.621761658031088, "no_speech_prob": 3.1690702599007636e-05}, {"id": 370, "seek": 202640, "start": 2026.4, "end": 2030.6000000000001, "text": " and she said, actually the town I'm in is called Point Leo.", "tokens": [293, 750, 848, 11, 767, 264, 3954, 286, 478, 294, 307, 1219, 12387, 19344, 13], "temperature": 0.0, "avg_logprob": -0.20713660643272794, "compression_ratio": 1.6875, "no_speech_prob": 4.006008384749293e-05}, {"id": 371, "seek": 202640, "start": 2030.6000000000001, "end": 2037.4, "text": " Actually Point Leo has no Internet.", "tokens": [5135, 12387, 19344, 575, 572, 7703, 13], "temperature": 0.0, "avg_logprob": -0.20713660643272794, "compression_ratio": 1.6875, "no_speech_prob": 4.006008384749293e-05}, {"id": 372, "seek": 202640, "start": 2037.4, "end": 2042.4, "text": " And so the good old Australian government had decided to replace ADSL in Point Leo with", "tokens": [400, 370, 264, 665, 1331, 13337, 2463, 632, 3047, 281, 7406, 9135, 47012, 294, 12387, 19344, 365], "temperature": 0.0, "avg_logprob": -0.20713660643272794, "compression_ratio": 1.6875, "no_speech_prob": 4.006008384749293e-05}, {"id": 373, "seek": 202640, "start": 2042.4, "end": 2047.8600000000001, "text": " a new national broadband network, and therefore they had disconnected ADSL that had not yet", "tokens": [257, 777, 4048, 37718, 3209, 11, 293, 4412, 436, 632, 29426, 9135, 47012, 300, 632, 406, 1939], "temperature": 0.0, "avg_logprob": -0.20713660643272794, "compression_ratio": 1.6875, "no_speech_prob": 4.006008384749293e-05}, {"id": 374, "seek": 202640, "start": 2047.8600000000001, "end": 2050.32, "text": " connected the national broadband network.", "tokens": [4582, 264, 4048, 37718, 3209, 13], "temperature": 0.0, "avg_logprob": -0.20713660643272794, "compression_ratio": 1.6875, "no_speech_prob": 4.006008384749293e-05}, {"id": 375, "seek": 202640, "start": 2050.32, "end": 2056.12, "text": " So we had fast WiFi, which we could use to Skype chat from one side of the house to the", "tokens": [407, 321, 632, 2370, 32885, 11, 597, 321, 727, 764, 281, 31743, 5081, 490, 472, 1252, 295, 264, 1782, 281, 264], "temperature": 0.0, "avg_logprob": -0.20713660643272794, "compression_ratio": 1.6875, "no_speech_prob": 4.006008384749293e-05}, {"id": 376, "seek": 205612, "start": 2056.12, "end": 2058.3199999999997, "text": " other, but I had no Internet.", "tokens": [661, 11, 457, 286, 632, 572, 7703, 13], "temperature": 0.0, "avg_logprob": -0.2223564001230093, "compression_ratio": 1.3371428571428572, "no_speech_prob": 2.9771974368486553e-05}, {"id": 377, "seek": 205612, "start": 2058.3199999999997, "end": 2068.7599999999998, "text": " Luckily I did have a new Surface Book 15-inch which has a GTX 1070 in it, and so I wrote", "tokens": [19726, 286, 630, 362, 257, 777, 36052, 9476, 2119, 12, 12415, 597, 575, 257, 17530, 55, 1266, 5867, 294, 309, 11, 293, 370, 286, 4114], "temperature": 0.0, "avg_logprob": -0.2223564001230093, "compression_ratio": 1.3371428571428572, "no_speech_prob": 2.9771974368486553e-05}, {"id": 378, "seek": 205612, "start": 2068.7599999999998, "end": 2074.7599999999998, "text": " a large amount of this course entirely on my laptop, which means I had to practice with", "tokens": [257, 2416, 2372, 295, 341, 1164, 7696, 322, 452, 10732, 11, 597, 1355, 286, 632, 281, 3124, 365], "temperature": 0.0, "avg_logprob": -0.2223564001230093, "compression_ratio": 1.3371428571428572, "no_speech_prob": 2.9771974368486553e-05}, {"id": 379, "seek": 205612, "start": 2074.7599999999998, "end": 2077.44, "text": " relatively small resources.", "tokens": [7226, 1359, 3593, 13], "temperature": 0.0, "avg_logprob": -0.2223564001230093, "compression_ratio": 1.3371428571428572, "no_speech_prob": 2.9771974368486553e-05}, {"id": 380, "seek": 207744, "start": 2077.44, "end": 2088.44, "text": " I mean not tiny, but 16GB RAM and 6GB GPU.", "tokens": [286, 914, 406, 5870, 11, 457, 3165, 8769, 14561, 293, 1386, 8769, 18407, 13], "temperature": 0.0, "avg_logprob": -0.2337148069131254, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.198443639324978e-05}, {"id": 381, "seek": 207744, "start": 2088.44, "end": 2090.04, "text": " And it was all in Windows, by the way.", "tokens": [400, 309, 390, 439, 294, 8591, 11, 538, 264, 636, 13], "temperature": 0.0, "avg_logprob": -0.2337148069131254, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.198443639324978e-05}, {"id": 382, "seek": 207744, "start": 2090.04, "end": 2097.04, "text": " So I can tell you that most of this course works well on Windows, on a laptop.", "tokens": [407, 286, 393, 980, 291, 300, 881, 295, 341, 1164, 1985, 731, 322, 8591, 11, 322, 257, 10732, 13], "temperature": 0.0, "avg_logprob": -0.2337148069131254, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.198443639324978e-05}, {"id": 383, "seek": 207744, "start": 2097.04, "end": 2101.36, "text": " So you can always use smaller batch sizes, you can use a cut down version of the dataset,", "tokens": [407, 291, 393, 1009, 764, 4356, 15245, 11602, 11, 291, 393, 764, 257, 1723, 760, 3037, 295, 264, 28872, 11], "temperature": 0.0, "avg_logprob": -0.2337148069131254, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.198443639324978e-05}, {"id": 384, "seek": 207744, "start": 2101.36, "end": 2102.36, "text": " whatever.", "tokens": [2035, 13], "temperature": 0.0, "avg_logprob": -0.2337148069131254, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.198443639324978e-05}, {"id": 385, "seek": 207744, "start": 2102.36, "end": 2106.28, "text": " But if you have the resources, you'll get better results if you can use the bigger datasets", "tokens": [583, 498, 291, 362, 264, 3593, 11, 291, 603, 483, 1101, 3542, 498, 291, 393, 764, 264, 3801, 42856], "temperature": 0.0, "avg_logprob": -0.2337148069131254, "compression_ratio": 1.5714285714285714, "no_speech_prob": 4.198443639324978e-05}, {"id": 386, "seek": 210628, "start": 2106.28, "end": 2107.28, "text": " when they're available.", "tokens": [562, 436, 434, 2435, 13], "temperature": 0.0, "avg_logprob": -0.2932940721511841, "compression_ratio": 1.1481481481481481, "no_speech_prob": 3.2697527785785496e-05}, {"id": 387, "seek": 210628, "start": 2107.28, "end": 2127.0, "text": " Now is a good time to take a somewhat early break so we can fix the forums.", "tokens": [823, 307, 257, 665, 565, 281, 747, 257, 8344, 2440, 1821, 370, 321, 393, 3191, 264, 26998, 13], "temperature": 0.0, "avg_logprob": -0.2932940721511841, "compression_ratio": 1.1481481481481481, "no_speech_prob": 3.2697527785785496e-05}, {"id": 388, "seek": 210628, "start": 2127.0, "end": 2133.5800000000004, "text": " Let's come back at 7.25.", "tokens": [961, 311, 808, 646, 412, 1614, 13, 6074, 13], "temperature": 0.0, "avg_logprob": -0.2932940721511841, "compression_ratio": 1.1481481481481481, "no_speech_prob": 3.2697527785785496e-05}, {"id": 389, "seek": 213358, "start": 2133.58, "end": 2137.64, "text": " So let's start talking about object detection.", "tokens": [407, 718, 311, 722, 1417, 466, 2657, 17784, 13], "temperature": 0.0, "avg_logprob": -0.14872438257390802, "compression_ratio": 1.6308411214953271, "no_speech_prob": 8.091769268503413e-05}, {"id": 390, "seek": 213358, "start": 2137.64, "end": 2141.34, "text": " And so here is an example of object detection.", "tokens": [400, 370, 510, 307, 364, 1365, 295, 2657, 17784, 13], "temperature": 0.0, "avg_logprob": -0.14872438257390802, "compression_ratio": 1.6308411214953271, "no_speech_prob": 8.091769268503413e-05}, {"id": 391, "seek": 213358, "start": 2141.34, "end": 2149.48, "text": " And so hopefully you'll see two main differences from what we're used to when it comes to classification.", "tokens": [400, 370, 4696, 291, 603, 536, 732, 2135, 7300, 490, 437, 321, 434, 1143, 281, 562, 309, 1487, 281, 21538, 13], "temperature": 0.0, "avg_logprob": -0.14872438257390802, "compression_ratio": 1.6308411214953271, "no_speech_prob": 8.091769268503413e-05}, {"id": 392, "seek": 213358, "start": 2149.48, "end": 2156.88, "text": " The first is that we have got multiple things that we're classifying, which is not unheard", "tokens": [440, 700, 307, 300, 321, 362, 658, 3866, 721, 300, 321, 434, 1508, 5489, 11, 597, 307, 406, 517, 42915], "temperature": 0.0, "avg_logprob": -0.14872438257390802, "compression_ratio": 1.6308411214953271, "no_speech_prob": 8.091769268503413e-05}, {"id": 393, "seek": 213358, "start": 2156.88, "end": 2157.88, "text": " of.", "tokens": [295, 13], "temperature": 0.0, "avg_logprob": -0.14872438257390802, "compression_ratio": 1.6308411214953271, "no_speech_prob": 8.091769268503413e-05}, {"id": 394, "seek": 213358, "start": 2157.88, "end": 2161.84, "text": " We did that in the planet satellite data, for example.", "tokens": [492, 630, 300, 294, 264, 5054, 16016, 1412, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.14872438257390802, "compression_ratio": 1.6308411214953271, "no_speech_prob": 8.091769268503413e-05}, {"id": 395, "seek": 216184, "start": 2161.84, "end": 2166.88, "text": " What is kind of unheard of is that as well as saying what we see, we've also got what's", "tokens": [708, 307, 733, 295, 517, 42915, 295, 307, 300, 382, 731, 382, 1566, 437, 321, 536, 11, 321, 600, 611, 658, 437, 311], "temperature": 0.0, "avg_logprob": -0.11763282255692915, "compression_ratio": 1.6613756613756614, "no_speech_prob": 4.785054898093222e-06}, {"id": 396, "seek": 216184, "start": 2166.88, "end": 2170.2400000000002, "text": " called bounding boxes around what we see.", "tokens": [1219, 5472, 278, 9002, 926, 437, 321, 536, 13], "temperature": 0.0, "avg_logprob": -0.11763282255692915, "compression_ratio": 1.6613756613756614, "no_speech_prob": 4.785054898093222e-06}, {"id": 397, "seek": 216184, "start": 2170.2400000000002, "end": 2179.56, "text": " A bounding box has a very specific definition, which is it's a box, it's a rectangle.", "tokens": [316, 5472, 278, 2424, 575, 257, 588, 2685, 7123, 11, 597, 307, 309, 311, 257, 2424, 11, 309, 311, 257, 21930, 13], "temperature": 0.0, "avg_logprob": -0.11763282255692915, "compression_ratio": 1.6613756613756614, "no_speech_prob": 4.785054898093222e-06}, {"id": 398, "seek": 216184, "start": 2179.56, "end": 2187.8, "text": " And the rectangle has the object entirely fitting within it, but it's no bigger than", "tokens": [400, 264, 21930, 575, 264, 2657, 7696, 15669, 1951, 309, 11, 457, 309, 311, 572, 3801, 813], "temperature": 0.0, "avg_logprob": -0.11763282255692915, "compression_ratio": 1.6613756613756614, "no_speech_prob": 4.785054898093222e-06}, {"id": 399, "seek": 216184, "start": 2187.8, "end": 2189.84, "text": " it has to be.", "tokens": [309, 575, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.11763282255692915, "compression_ratio": 1.6613756613756614, "no_speech_prob": 4.785054898093222e-06}, {"id": 400, "seek": 218984, "start": 2189.84, "end": 2196.28, "text": " You'll see this bounding box is perhaps, for the horse at least, slightly imperfect in", "tokens": [509, 603, 536, 341, 5472, 278, 2424, 307, 4317, 11, 337, 264, 6832, 412, 1935, 11, 4748, 26714, 294], "temperature": 0.0, "avg_logprob": -0.16096782684326172, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.339133051369572e-06}, {"id": 401, "seek": 218984, "start": 2196.28, "end": 2200.8, "text": " that it looks like there's a bit of tail here, so it probably should be a bit wider, and", "tokens": [300, 309, 1542, 411, 456, 311, 257, 857, 295, 6838, 510, 11, 370, 309, 1391, 820, 312, 257, 857, 11842, 11, 293], "temperature": 0.0, "avg_logprob": -0.16096782684326172, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.339133051369572e-06}, {"id": 402, "seek": 218984, "start": 2200.8, "end": 2204.4, "text": " maybe there's even a little bit of hoof here, maybe it should be a bit longer.", "tokens": [1310, 456, 311, 754, 257, 707, 857, 295, 44974, 510, 11, 1310, 309, 820, 312, 257, 857, 2854, 13], "temperature": 0.0, "avg_logprob": -0.16096782684326172, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.339133051369572e-06}, {"id": 403, "seek": 218984, "start": 2204.4, "end": 2210.32, "text": " So the bounding boxes won't be perfect, but they're generally pretty good in most datasets", "tokens": [407, 264, 5472, 278, 9002, 1582, 380, 312, 2176, 11, 457, 436, 434, 5101, 1238, 665, 294, 881, 42856], "temperature": 0.0, "avg_logprob": -0.16096782684326172, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.339133051369572e-06}, {"id": 404, "seek": 218984, "start": 2210.32, "end": 2213.36, "text": " that you can find.", "tokens": [300, 291, 393, 915, 13], "temperature": 0.0, "avg_logprob": -0.16096782684326172, "compression_ratio": 1.6774193548387097, "no_speech_prob": 6.339133051369572e-06}, {"id": 405, "seek": 221336, "start": 2213.36, "end": 2221.76, "text": " So our job will be to take data that has been labeled in this way and on data that is unlabeled", "tokens": [407, 527, 1691, 486, 312, 281, 747, 1412, 300, 575, 668, 21335, 294, 341, 636, 293, 322, 1412, 300, 307, 32118, 18657, 292], "temperature": 0.0, "avg_logprob": -0.13990848594241673, "compression_ratio": 1.5865921787709498, "no_speech_prob": 3.9896929138194537e-07}, {"id": 406, "seek": 221336, "start": 2221.76, "end": 2231.1200000000003, "text": " to generate the classes of the objects and for each one of those there are bounding boxes.", "tokens": [281, 8460, 264, 5359, 295, 264, 6565, 293, 337, 1184, 472, 295, 729, 456, 366, 5472, 278, 9002, 13], "temperature": 0.0, "avg_logprob": -0.13990848594241673, "compression_ratio": 1.5865921787709498, "no_speech_prob": 3.9896929138194537e-07}, {"id": 407, "seek": 221336, "start": 2231.1200000000003, "end": 2236.92, "text": " One thing I'll note to start with is that labeling this kind of data is generally more", "tokens": [1485, 551, 286, 603, 3637, 281, 722, 365, 307, 300, 40244, 341, 733, 295, 1412, 307, 5101, 544], "temperature": 0.0, "avg_logprob": -0.13990848594241673, "compression_ratio": 1.5865921787709498, "no_speech_prob": 3.9896929138194537e-07}, {"id": 408, "seek": 221336, "start": 2236.92, "end": 2238.5, "text": " expensive.", "tokens": [5124, 13], "temperature": 0.0, "avg_logprob": -0.13990848594241673, "compression_ratio": 1.5865921787709498, "no_speech_prob": 3.9896929138194537e-07}, {"id": 409, "seek": 223850, "start": 2238.5, "end": 2244.52, "text": " It's generally quicker to say horse, person, person, horse, car, dog, jumbo jet, than it", "tokens": [467, 311, 5101, 16255, 281, 584, 6832, 11, 954, 11, 954, 11, 6832, 11, 1032, 11, 3000, 11, 29067, 1763, 14452, 11, 813, 309], "temperature": 0.0, "avg_logprob": -0.22365848316865808, "compression_ratio": 1.6578947368421053, "no_speech_prob": 8.059435003815452e-07}, {"id": 410, "seek": 223850, "start": 2244.52, "end": 2251.76, "text": " is to say if there's a whole horse race going on to label the exact location of every rider", "tokens": [307, 281, 584, 498, 456, 311, 257, 1379, 6832, 4569, 516, 322, 281, 7645, 264, 1900, 4914, 295, 633, 25419], "temperature": 0.0, "avg_logprob": -0.22365848316865808, "compression_ratio": 1.6578947368421053, "no_speech_prob": 8.059435003815452e-07}, {"id": 411, "seek": 223850, "start": 2251.76, "end": 2253.66, "text": " and of every horse.", "tokens": [293, 295, 633, 6832, 13], "temperature": 0.0, "avg_logprob": -0.22365848316865808, "compression_ratio": 1.6578947368421053, "no_speech_prob": 8.059435003815452e-07}, {"id": 412, "seek": 223850, "start": 2253.66, "end": 2257.64, "text": " And then of course it also depends what classes you want to label.", "tokens": [400, 550, 295, 1164, 309, 611, 5946, 437, 5359, 291, 528, 281, 7645, 13], "temperature": 0.0, "avg_logprob": -0.22365848316865808, "compression_ratio": 1.6578947368421053, "no_speech_prob": 8.059435003815452e-07}, {"id": 413, "seek": 223850, "start": 2257.64, "end": 2260.8, "text": " You want to label every fence post or whatever.", "tokens": [509, 528, 281, 7645, 633, 15422, 2183, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.22365848316865808, "compression_ratio": 1.6578947368421053, "no_speech_prob": 8.059435003815452e-07}, {"id": 414, "seek": 226080, "start": 2260.8, "end": 2269.2400000000002, "text": " But generally, just like in ImageNet, it's not like tell me any object you see in this", "tokens": [583, 5101, 11, 445, 411, 294, 29903, 31890, 11, 309, 311, 406, 411, 980, 385, 604, 2657, 291, 536, 294, 341], "temperature": 0.0, "avg_logprob": -0.21390894234898578, "compression_ratio": 1.6684782608695652, "no_speech_prob": 3.2887328416109085e-06}, {"id": 415, "seek": 226080, "start": 2269.2400000000002, "end": 2270.2400000000002, "text": " picture.", "tokens": [3036, 13], "temperature": 0.0, "avg_logprob": -0.21390894234898578, "compression_ratio": 1.6684782608695652, "no_speech_prob": 3.2887328416109085e-06}, {"id": 416, "seek": 226080, "start": 2270.2400000000002, "end": 2276.88, "text": " In ImageNet, it's like here are the 1000 classes that we ask you to look for, tell us which", "tokens": [682, 29903, 31890, 11, 309, 311, 411, 510, 366, 264, 9714, 5359, 300, 321, 1029, 291, 281, 574, 337, 11, 980, 505, 597], "temperature": 0.0, "avg_logprob": -0.21390894234898578, "compression_ratio": 1.6684782608695652, "no_speech_prob": 3.2887328416109085e-06}, {"id": 417, "seek": 226080, "start": 2276.88, "end": 2282.0, "text": " one of those 1000 classes you find.", "tokens": [472, 295, 729, 9714, 5359, 291, 915, 13], "temperature": 0.0, "avg_logprob": -0.21390894234898578, "compression_ratio": 1.6684782608695652, "no_speech_prob": 3.2887328416109085e-06}, {"id": 418, "seek": 226080, "start": 2282.0, "end": 2288.28, "text": " For these object detection datasets, it's a list of object classes that we want you", "tokens": [1171, 613, 2657, 17784, 42856, 11, 309, 311, 257, 1329, 295, 2657, 5359, 300, 321, 528, 291], "temperature": 0.0, "avg_logprob": -0.21390894234898578, "compression_ratio": 1.6684782608695652, "no_speech_prob": 3.2887328416109085e-06}, {"id": 419, "seek": 228828, "start": 2288.28, "end": 2293.52, "text": " to tell us about and find every single one of them of any type in the picture along with", "tokens": [281, 980, 505, 466, 293, 915, 633, 2167, 472, 295, 552, 295, 604, 2010, 294, 264, 3036, 2051, 365], "temperature": 0.0, "avg_logprob": -0.15271693468093872, "compression_ratio": 1.7130434782608697, "no_speech_prob": 2.482452146068681e-06}, {"id": 420, "seek": 228828, "start": 2293.52, "end": 2294.52, "text": " where they are.", "tokens": [689, 436, 366, 13], "temperature": 0.0, "avg_logprob": -0.15271693468093872, "compression_ratio": 1.7130434782608697, "no_speech_prob": 2.482452146068681e-06}, {"id": 421, "seek": 228828, "start": 2294.52, "end": 2299.28, "text": " So in this case, why isn't there tree or jump labeled?", "tokens": [407, 294, 341, 1389, 11, 983, 1943, 380, 456, 4230, 420, 3012, 21335, 30], "temperature": 0.0, "avg_logprob": -0.15271693468093872, "compression_ratio": 1.7130434782608697, "no_speech_prob": 2.482452146068681e-06}, {"id": 422, "seek": 228828, "start": 2299.28, "end": 2303.5600000000004, "text": " That's because for this particular dataset, they weren't one of the classes that the annotators", "tokens": [663, 311, 570, 337, 341, 1729, 28872, 11, 436, 4999, 380, 472, 295, 264, 5359, 300, 264, 25339, 3391], "temperature": 0.0, "avg_logprob": -0.15271693468093872, "compression_ratio": 1.7130434782608697, "no_speech_prob": 2.482452146068681e-06}, {"id": 423, "seek": 228828, "start": 2303.5600000000004, "end": 2307.84, "text": " were asked to find and therefore not part of this particular problem.", "tokens": [645, 2351, 281, 915, 293, 4412, 406, 644, 295, 341, 1729, 1154, 13], "temperature": 0.0, "avg_logprob": -0.15271693468093872, "compression_ratio": 1.7130434782608697, "no_speech_prob": 2.482452146068681e-06}, {"id": 424, "seek": 228828, "start": 2307.84, "end": 2314.92, "text": " So that's kind of the specification of the object detection problem.", "tokens": [407, 300, 311, 733, 295, 264, 31256, 295, 264, 2657, 17784, 1154, 13], "temperature": 0.0, "avg_logprob": -0.15271693468093872, "compression_ratio": 1.7130434782608697, "no_speech_prob": 2.482452146068681e-06}, {"id": 425, "seek": 231492, "start": 2314.92, "end": 2320.88, "text": " So let me describe stage 1.", "tokens": [407, 718, 385, 6786, 3233, 502, 13], "temperature": 0.0, "avg_logprob": -0.19798300893683182, "compression_ratio": 1.7958115183246073, "no_speech_prob": 4.092894869245356e-06}, {"id": 426, "seek": 231492, "start": 2320.88, "end": 2325.8, "text": " And stage 1 is actually going to be surprisingly straightforward.", "tokens": [400, 3233, 502, 307, 767, 516, 281, 312, 17600, 15325, 13], "temperature": 0.0, "avg_logprob": -0.19798300893683182, "compression_ratio": 1.7958115183246073, "no_speech_prob": 4.092894869245356e-06}, {"id": 427, "seek": 231492, "start": 2325.8, "end": 2328.56, "text": " And we're going to start at the top and work down.", "tokens": [400, 321, 434, 516, 281, 722, 412, 264, 1192, 293, 589, 760, 13], "temperature": 0.0, "avg_logprob": -0.19798300893683182, "compression_ratio": 1.7958115183246073, "no_speech_prob": 4.092894869245356e-06}, {"id": 428, "seek": 231492, "start": 2328.56, "end": 2335.4, "text": " We're going to start out by classifying the largest object in each image.", "tokens": [492, 434, 516, 281, 722, 484, 538, 1508, 5489, 264, 6443, 2657, 294, 1184, 3256, 13], "temperature": 0.0, "avg_logprob": -0.19798300893683182, "compression_ratio": 1.7958115183246073, "no_speech_prob": 4.092894869245356e-06}, {"id": 429, "seek": 231492, "start": 2335.4, "end": 2338.12, "text": " So we're going to try and say person.", "tokens": [407, 321, 434, 516, 281, 853, 293, 584, 954, 13], "temperature": 0.0, "avg_logprob": -0.19798300893683182, "compression_ratio": 1.7958115183246073, "no_speech_prob": 4.092894869245356e-06}, {"id": 430, "seek": 231492, "start": 2338.12, "end": 2339.7200000000003, "text": " Actually this one is wrong.", "tokens": [5135, 341, 472, 307, 2085, 13], "temperature": 0.0, "avg_logprob": -0.19798300893683182, "compression_ratio": 1.7958115183246073, "no_speech_prob": 4.092894869245356e-06}, {"id": 431, "seek": 231492, "start": 2339.7200000000003, "end": 2341.12, "text": " Dog is not the largest object.", "tokens": [13472, 307, 406, 264, 6443, 2657, 13], "temperature": 0.0, "avg_logprob": -0.19798300893683182, "compression_ratio": 1.7958115183246073, "no_speech_prob": 4.092894869245356e-06}, {"id": 432, "seek": 231492, "start": 2341.12, "end": 2342.12, "text": " Sofa is the largest object.", "tokens": [407, 11771, 307, 264, 6443, 2657, 13], "temperature": 0.0, "avg_logprob": -0.19798300893683182, "compression_ratio": 1.7958115183246073, "no_speech_prob": 4.092894869245356e-06}, {"id": 433, "seek": 234212, "start": 2342.12, "end": 2345.3599999999997, "text": " So here's an example of a misclassified one.", "tokens": [407, 510, 311, 364, 1365, 295, 257, 3346, 11665, 2587, 472, 13], "temperature": 0.0, "avg_logprob": -0.22788743315071897, "compression_ratio": 1.5905511811023623, "no_speech_prob": 3.1381368899019435e-06}, {"id": 434, "seek": 234212, "start": 2345.3599999999997, "end": 2346.3599999999997, "text": " Bird, correct.", "tokens": [15931, 11, 3006, 13], "temperature": 0.0, "avg_logprob": -0.22788743315071897, "compression_ratio": 1.5905511811023623, "no_speech_prob": 3.1381368899019435e-06}, {"id": 435, "seek": 234212, "start": 2346.3599999999997, "end": 2347.3599999999997, "text": " Person, correct.", "tokens": [8443, 11, 3006, 13], "temperature": 0.0, "avg_logprob": -0.22788743315071897, "compression_ratio": 1.5905511811023623, "no_speech_prob": 3.1381368899019435e-06}, {"id": 436, "seek": 234212, "start": 2347.3599999999997, "end": 2350.7999999999997, "text": " That will be the first thing we try to do.", "tokens": [663, 486, 312, 264, 700, 551, 321, 853, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.22788743315071897, "compression_ratio": 1.5905511811023623, "no_speech_prob": 3.1381368899019435e-06}, {"id": 437, "seek": 234212, "start": 2350.7999999999997, "end": 2355.6, "text": " That's not going to require anything new, so it'll just be a bit of a warm-up for us.", "tokens": [663, 311, 406, 516, 281, 3651, 1340, 777, 11, 370, 309, 603, 445, 312, 257, 857, 295, 257, 4561, 12, 1010, 337, 505, 13], "temperature": 0.0, "avg_logprob": -0.22788743315071897, "compression_ratio": 1.5905511811023623, "no_speech_prob": 3.1381368899019435e-06}, {"id": 438, "seek": 234212, "start": 2355.6, "end": 2363.44, "text": " The second thing will be to tell us the location of the largest object in each image.", "tokens": [440, 1150, 551, 486, 312, 281, 980, 505, 264, 4914, 295, 264, 6443, 2657, 294, 1184, 3256, 13], "temperature": 0.0, "avg_logprob": -0.22788743315071897, "compression_ratio": 1.5905511811023623, "no_speech_prob": 3.1381368899019435e-06}, {"id": 439, "seek": 234212, "start": 2363.44, "end": 2364.92, "text": " Again, here this is actually incorrect.", "tokens": [3764, 11, 510, 341, 307, 767, 18424, 13], "temperature": 0.0, "avg_logprob": -0.22788743315071897, "compression_ratio": 1.5905511811023623, "no_speech_prob": 3.1381368899019435e-06}, {"id": 440, "seek": 234212, "start": 2364.92, "end": 2369.64, "text": " It should have labeled the sofa, but you can see where it's coming from.", "tokens": [467, 820, 362, 21335, 264, 28668, 11, 457, 291, 393, 536, 689, 309, 311, 1348, 490, 13], "temperature": 0.0, "avg_logprob": -0.22788743315071897, "compression_ratio": 1.5905511811023623, "no_speech_prob": 3.1381368899019435e-06}, {"id": 441, "seek": 236964, "start": 2369.64, "end": 2374.3199999999997, "text": " And then finally we will try to do both at the same time, which is to label what it is", "tokens": [400, 550, 2721, 321, 486, 853, 281, 360, 1293, 412, 264, 912, 565, 11, 597, 307, 281, 7645, 437, 309, 307], "temperature": 0.0, "avg_logprob": -0.1804442353300996, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.7853067169635324e-06}, {"id": 442, "seek": 236964, "start": 2374.3199999999997, "end": 2378.4, "text": " and where it is for the largest thing in the picture.", "tokens": [293, 689, 309, 307, 337, 264, 6443, 551, 294, 264, 3036, 13], "temperature": 0.0, "avg_logprob": -0.1804442353300996, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.7853067169635324e-06}, {"id": 443, "seek": 236964, "start": 2378.4, "end": 2382.6, "text": " And this is going to be relatively straightforward.", "tokens": [400, 341, 307, 516, 281, 312, 7226, 15325, 13], "temperature": 0.0, "avg_logprob": -0.1804442353300996, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.7853067169635324e-06}, {"id": 444, "seek": 236964, "start": 2382.6, "end": 2385.64, "text": " So it'll be a good warm-up to get us going again.", "tokens": [407, 309, 603, 312, 257, 665, 4561, 12, 1010, 281, 483, 505, 516, 797, 13], "temperature": 0.0, "avg_logprob": -0.1804442353300996, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.7853067169635324e-06}, {"id": 445, "seek": 236964, "start": 2385.64, "end": 2391.72, "text": " But what I'm going to do is I'm going to use it as an opportunity to show you some useful", "tokens": [583, 437, 286, 478, 516, 281, 360, 307, 286, 478, 516, 281, 764, 309, 382, 364, 2650, 281, 855, 291, 512, 4420], "temperature": 0.0, "avg_logprob": -0.1804442353300996, "compression_ratio": 1.5885167464114833, "no_speech_prob": 3.7853067169635324e-06}, {"id": 446, "seek": 239172, "start": 2391.72, "end": 2402.24, "text": " coding techniques and a couple of little FastAI anti-details before we then get onto multi-label", "tokens": [17720, 7512, 293, 257, 1916, 295, 707, 15968, 48698, 6061, 12, 17863, 6227, 949, 321, 550, 483, 3911, 4825, 12, 75, 18657], "temperature": 0.0, "avg_logprob": -0.2735116923296893, "compression_ratio": 1.4172185430463575, "no_speech_prob": 6.747936822648626e-06}, {"id": 447, "seek": 239172, "start": 2402.24, "end": 2407.12, "text": " classification and then multiple object classification.", "tokens": [21538, 293, 550, 3866, 2657, 21538, 13], "temperature": 0.0, "avg_logprob": -0.2735116923296893, "compression_ratio": 1.4172185430463575, "no_speech_prob": 6.747936822648626e-06}, {"id": 448, "seek": 239172, "start": 2407.12, "end": 2408.64, "text": " So let's start here.", "tokens": [407, 718, 311, 722, 510, 13], "temperature": 0.0, "avg_logprob": -0.2735116923296893, "compression_ratio": 1.4172185430463575, "no_speech_prob": 6.747936822648626e-06}, {"id": 449, "seek": 239172, "start": 2408.64, "end": 2417.64, "text": " The notebook that we're using is Pascal.", "tokens": [440, 21060, 300, 321, 434, 1228, 307, 41723, 13], "temperature": 0.0, "avg_logprob": -0.2735116923296893, "compression_ratio": 1.4172185430463575, "no_speech_prob": 6.747936822648626e-06}, {"id": 450, "seek": 241764, "start": 2417.64, "end": 2422.2799999999997, "text": " All of the notebooks are in the DL2 folder.", "tokens": [1057, 295, 264, 43782, 366, 294, 264, 413, 43, 17, 10820, 13], "temperature": 0.0, "avg_logprob": -0.15838541536249667, "compression_ratio": 1.5737051792828685, "no_speech_prob": 2.668750130396802e-05}, {"id": 451, "seek": 241764, "start": 2422.2799999999997, "end": 2427.3199999999997, "text": " One thing you'll see in some of my notebooks is torch.cuda.setdevice.", "tokens": [1485, 551, 291, 603, 536, 294, 512, 295, 452, 43782, 307, 27822, 13, 66, 11152, 13, 3854, 40343, 573, 13], "temperature": 0.0, "avg_logprob": -0.15838541536249667, "compression_ratio": 1.5737051792828685, "no_speech_prob": 2.668750130396802e-05}, {"id": 452, "seek": 241764, "start": 2427.3199999999997, "end": 2430.8799999999997, "text": " You may have even seen it in the last part, just in case you're wondering why that's there.", "tokens": [509, 815, 362, 754, 1612, 309, 294, 264, 1036, 644, 11, 445, 294, 1389, 291, 434, 6359, 983, 300, 311, 456, 13], "temperature": 0.0, "avg_logprob": -0.15838541536249667, "compression_ratio": 1.5737051792828685, "no_speech_prob": 2.668750130396802e-05}, {"id": 453, "seek": 241764, "start": 2430.8799999999997, "end": 2437.6, "text": " I have 4 GPUs on the university server that I use, so I can put a number from 0 to 3 in", "tokens": [286, 362, 1017, 18407, 82, 322, 264, 5454, 7154, 300, 286, 764, 11, 370, 286, 393, 829, 257, 1230, 490, 1958, 281, 805, 294], "temperature": 0.0, "avg_logprob": -0.15838541536249667, "compression_ratio": 1.5737051792828685, "no_speech_prob": 2.668750130396802e-05}, {"id": 454, "seek": 241764, "start": 2437.6, "end": 2439.9, "text": " here to pick one.", "tokens": [510, 281, 1888, 472, 13], "temperature": 0.0, "avg_logprob": -0.15838541536249667, "compression_ratio": 1.5737051792828685, "no_speech_prob": 2.668750130396802e-05}, {"id": 455, "seek": 241764, "start": 2439.9, "end": 2444.64, "text": " This is how I prefer to use multiple GPUs rather than run a model on multiple GPUs,", "tokens": [639, 307, 577, 286, 4382, 281, 764, 3866, 18407, 82, 2831, 813, 1190, 257, 2316, 322, 3866, 18407, 82, 11], "temperature": 0.0, "avg_logprob": -0.15838541536249667, "compression_ratio": 1.5737051792828685, "no_speech_prob": 2.668750130396802e-05}, {"id": 456, "seek": 244464, "start": 2444.64, "end": 2448.2, "text": " which doesn't always speed it up that much and is kind of awkward.", "tokens": [597, 1177, 380, 1009, 3073, 309, 493, 300, 709, 293, 307, 733, 295, 11411, 13], "temperature": 0.0, "avg_logprob": -0.16499788333208132, "compression_ratio": 1.6888888888888889, "no_speech_prob": 7.766853741486557e-06}, {"id": 457, "seek": 244464, "start": 2448.2, "end": 2451.96, "text": " I generally like to have different GPUs running different things.", "tokens": [286, 5101, 411, 281, 362, 819, 18407, 82, 2614, 819, 721, 13], "temperature": 0.0, "avg_logprob": -0.16499788333208132, "compression_ratio": 1.6888888888888889, "no_speech_prob": 7.766853741486557e-06}, {"id": 458, "seek": 244464, "start": 2451.96, "end": 2459.24, "text": " So in this case, I was running something in this on device 1 and doing something else", "tokens": [407, 294, 341, 1389, 11, 286, 390, 2614, 746, 294, 341, 322, 4302, 502, 293, 884, 746, 1646], "temperature": 0.0, "avg_logprob": -0.16499788333208132, "compression_ratio": 1.6888888888888889, "no_speech_prob": 7.766853741486557e-06}, {"id": 459, "seek": 244464, "start": 2459.24, "end": 2461.2, "text": " on another notebook in device 2.", "tokens": [322, 1071, 21060, 294, 4302, 568, 13], "temperature": 0.0, "avg_logprob": -0.16499788333208132, "compression_ratio": 1.6888888888888889, "no_speech_prob": 7.766853741486557e-06}, {"id": 460, "seek": 244464, "start": 2461.2, "end": 2465.0, "text": " Now obviously if you see this in a notebook left behind, that was a mistake.", "tokens": [823, 2745, 498, 291, 536, 341, 294, 257, 21060, 1411, 2261, 11, 300, 390, 257, 6146, 13], "temperature": 0.0, "avg_logprob": -0.16499788333208132, "compression_ratio": 1.6888888888888889, "no_speech_prob": 7.766853741486557e-06}, {"id": 461, "seek": 244464, "start": 2465.0, "end": 2468.12, "text": " If you don't have more than one GPU, you're going to get an error.", "tokens": [759, 291, 500, 380, 362, 544, 813, 472, 18407, 11, 291, 434, 516, 281, 483, 364, 6713, 13], "temperature": 0.0, "avg_logprob": -0.16499788333208132, "compression_ratio": 1.6888888888888889, "no_speech_prob": 7.766853741486557e-06}, {"id": 462, "seek": 244464, "start": 2468.12, "end": 2473.72, "text": " So you can just change it to 0 or delete that line entirely.", "tokens": [407, 291, 393, 445, 1319, 309, 281, 1958, 420, 12097, 300, 1622, 7696, 13], "temperature": 0.0, "avg_logprob": -0.16499788333208132, "compression_ratio": 1.6888888888888889, "no_speech_prob": 7.766853741486557e-06}, {"id": 463, "seek": 247372, "start": 2473.72, "end": 2481.2, "text": " So there's a number of standard object detection datasets, just like ImageNet is a standard", "tokens": [407, 456, 311, 257, 1230, 295, 3832, 2657, 17784, 42856, 11, 445, 411, 29903, 31890, 307, 257, 3832], "temperature": 0.0, "avg_logprob": -0.24138639328327585, "compression_ratio": 1.4275362318840579, "no_speech_prob": 1.4738759091414977e-05}, {"id": 464, "seek": 247372, "start": 2481.2, "end": 2483.16, "text": " object classification dataset.", "tokens": [2657, 21538, 28872, 13], "temperature": 0.0, "avg_logprob": -0.24138639328327585, "compression_ratio": 1.4275362318840579, "no_speech_prob": 1.4738759091414977e-05}, {"id": 465, "seek": 247372, "start": 2483.16, "end": 2500.2599999999998, "text": " And kind of the old classic ImageNet equivalent if you like is Pascal VOC.", "tokens": [400, 733, 295, 264, 1331, 7230, 29903, 31890, 10344, 498, 291, 411, 307, 41723, 15216, 34, 13], "temperature": 0.0, "avg_logprob": -0.24138639328327585, "compression_ratio": 1.4275362318840579, "no_speech_prob": 1.4738759091414977e-05}, {"id": 466, "seek": 250026, "start": 2500.26, "end": 2507.28, "text": " The actual main website for it is like, I don't know, it's running on somebody's coffee", "tokens": [440, 3539, 2135, 3144, 337, 309, 307, 411, 11, 286, 500, 380, 458, 11, 309, 311, 2614, 322, 2618, 311, 4982], "temperature": 0.0, "avg_logprob": -0.21058223987447805, "compression_ratio": 1.583916083916084, "no_speech_prob": 9.972703992389143e-06}, {"id": 467, "seek": 250026, "start": 2507.28, "end": 2508.6400000000003, "text": " warmer or something.", "tokens": [21599, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.21058223987447805, "compression_ratio": 1.583916083916084, "no_speech_prob": 9.972703992389143e-06}, {"id": 468, "seek": 250026, "start": 2508.6400000000003, "end": 2512.36, "text": " It goes down all the time every time he makes coffee.", "tokens": [467, 1709, 760, 439, 264, 565, 633, 565, 415, 1669, 4982, 13], "temperature": 0.0, "avg_logprob": -0.21058223987447805, "compression_ratio": 1.583916083916084, "no_speech_prob": 9.972703992389143e-06}, {"id": 469, "seek": 250026, "start": 2512.36, "end": 2515.44, "text": " So some folks have mirrored it, which is very kind of them, so you might find it easier", "tokens": [407, 512, 4024, 362, 3149, 340, 986, 309, 11, 597, 307, 588, 733, 295, 552, 11, 370, 291, 1062, 915, 309, 3571], "temperature": 0.0, "avg_logprob": -0.21058223987447805, "compression_ratio": 1.583916083916084, "no_speech_prob": 9.972703992389143e-06}, {"id": 470, "seek": 250026, "start": 2515.44, "end": 2518.5200000000004, "text": " to grab from the mirror.", "tokens": [281, 4444, 490, 264, 8013, 13], "temperature": 0.0, "avg_logprob": -0.21058223987447805, "compression_ratio": 1.583916083916084, "no_speech_prob": 9.972703992389143e-06}, {"id": 471, "seek": 250026, "start": 2518.5200000000004, "end": 2525.32, "text": " You'll see when you download it that there's a 2007 dataset, a 2012 dataset, that they", "tokens": [509, 603, 536, 562, 291, 5484, 309, 300, 456, 311, 257, 12656, 28872, 11, 257, 9125, 28872, 11, 300, 436], "temperature": 0.0, "avg_logprob": -0.21058223987447805, "compression_ratio": 1.583916083916084, "no_speech_prob": 9.972703992389143e-06}, {"id": 472, "seek": 250026, "start": 2525.32, "end": 2529.48, "text": " basically were like academic competitions in those different years, just like the ImageNet", "tokens": [1936, 645, 411, 7778, 26185, 294, 729, 819, 924, 11, 445, 411, 264, 29903, 31890], "temperature": 0.0, "avg_logprob": -0.21058223987447805, "compression_ratio": 1.583916083916084, "no_speech_prob": 9.972703992389143e-06}, {"id": 473, "seek": 252948, "start": 2529.48, "end": 2534.84, "text": " dataset we tend to use is actually the ImageNet 2012 competition dataset.", "tokens": [28872, 321, 3928, 281, 764, 307, 767, 264, 29903, 31890, 9125, 6211, 28872, 13], "temperature": 0.0, "avg_logprob": -0.17658190383124597, "compression_ratio": 1.578125, "no_speech_prob": 1.1842845196952112e-05}, {"id": 474, "seek": 252948, "start": 2534.84, "end": 2541.84, "text": " We'll be using the 2007 version in this particular notebook.", "tokens": [492, 603, 312, 1228, 264, 12656, 3037, 294, 341, 1729, 21060, 13], "temperature": 0.0, "avg_logprob": -0.17658190383124597, "compression_ratio": 1.578125, "no_speech_prob": 1.1842845196952112e-05}, {"id": 475, "seek": 252948, "start": 2541.84, "end": 2546.36, "text": " Feel free to use the 2012 instead, it's a bit bigger, you might get better results.", "tokens": [14113, 1737, 281, 764, 264, 9125, 2602, 11, 309, 311, 257, 857, 3801, 11, 291, 1062, 483, 1101, 3542, 13], "temperature": 0.0, "avg_logprob": -0.17658190383124597, "compression_ratio": 1.578125, "no_speech_prob": 1.1842845196952112e-05}, {"id": 476, "seek": 252948, "start": 2546.36, "end": 2552.2, "text": " A lot of people, in fact most people now in research papers actually combine the two.", "tokens": [316, 688, 295, 561, 11, 294, 1186, 881, 561, 586, 294, 2132, 10577, 767, 10432, 264, 732, 13], "temperature": 0.0, "avg_logprob": -0.17658190383124597, "compression_ratio": 1.578125, "no_speech_prob": 1.1842845196952112e-05}, {"id": 477, "seek": 252948, "start": 2552.2, "end": 2556.4, "text": " You do have to be careful because there's some leakage between the validation sets between", "tokens": [509, 360, 362, 281, 312, 5026, 570, 456, 311, 512, 47799, 1296, 264, 24071, 6352, 1296], "temperature": 0.0, "avg_logprob": -0.17658190383124597, "compression_ratio": 1.578125, "no_speech_prob": 1.1842845196952112e-05}, {"id": 478, "seek": 252948, "start": 2556.4, "end": 2557.4, "text": " the two.", "tokens": [264, 732, 13], "temperature": 0.0, "avg_logprob": -0.17658190383124597, "compression_ratio": 1.578125, "no_speech_prob": 1.1842845196952112e-05}, {"id": 479, "seek": 255740, "start": 2557.4, "end": 2561.2000000000003, "text": " If you decide to do that, make sure you do some reading about the dataset to make sure", "tokens": [759, 291, 4536, 281, 360, 300, 11, 652, 988, 291, 360, 512, 3760, 466, 264, 28872, 281, 652, 988], "temperature": 0.0, "avg_logprob": -0.12008866956157069, "compression_ratio": 1.5701357466063348, "no_speech_prob": 1.045145108946599e-05}, {"id": 480, "seek": 255740, "start": 2561.2000000000003, "end": 2564.44, "text": " you know how to combine them correctly.", "tokens": [291, 458, 577, 281, 10432, 552, 8944, 13], "temperature": 0.0, "avg_logprob": -0.12008866956157069, "compression_ratio": 1.5701357466063348, "no_speech_prob": 1.045145108946599e-05}, {"id": 481, "seek": 255740, "start": 2564.44, "end": 2571.8, "text": " The first thing you'll notice in terms of coding here is this.", "tokens": [440, 700, 551, 291, 603, 3449, 294, 2115, 295, 17720, 510, 307, 341, 13], "temperature": 0.0, "avg_logprob": -0.12008866956157069, "compression_ratio": 1.5701357466063348, "no_speech_prob": 1.045145108946599e-05}, {"id": 482, "seek": 255740, "start": 2571.8, "end": 2572.8, "text": " We haven't used this before.", "tokens": [492, 2378, 380, 1143, 341, 949, 13], "temperature": 0.0, "avg_logprob": -0.12008866956157069, "compression_ratio": 1.5701357466063348, "no_speech_prob": 1.045145108946599e-05}, {"id": 483, "seek": 255740, "start": 2572.8, "end": 2575.2000000000003, "text": " I'm going to be using this all the time now.", "tokens": [286, 478, 516, 281, 312, 1228, 341, 439, 264, 565, 586, 13], "temperature": 0.0, "avg_logprob": -0.12008866956157069, "compression_ratio": 1.5701357466063348, "no_speech_prob": 1.045145108946599e-05}, {"id": 484, "seek": 255740, "start": 2575.2000000000003, "end": 2582.64, "text": " This is part of the Python 3 standard library called pathlib, and it's super handy.", "tokens": [639, 307, 644, 295, 264, 15329, 805, 3832, 6405, 1219, 3100, 38270, 11, 293, 309, 311, 1687, 13239, 13], "temperature": 0.0, "avg_logprob": -0.12008866956157069, "compression_ratio": 1.5701357466063348, "no_speech_prob": 1.045145108946599e-05}, {"id": 485, "seek": 258264, "start": 2582.64, "end": 2589.72, "text": " It basically gives you an object-oriented access to a directory or a file.", "tokens": [467, 1936, 2709, 291, 364, 2657, 12, 27414, 2105, 281, 257, 21120, 420, 257, 3991, 13], "temperature": 0.0, "avg_logprob": -0.1795361042022705, "compression_ratio": 1.3582089552238805, "no_speech_prob": 1.6028054687922122e-06}, {"id": 486, "seek": 258264, "start": 2589.72, "end": 2603.68, "text": " So you can see if I go path.something, there's lots of things I can do.", "tokens": [407, 291, 393, 536, 498, 286, 352, 3100, 13, 31681, 11, 456, 311, 3195, 295, 721, 286, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.1795361042022705, "compression_ratio": 1.3582089552238805, "no_speech_prob": 1.6028054687922122e-06}, {"id": 487, "seek": 258264, "start": 2603.68, "end": 2607.56, "text": " One of them is iterative directory.", "tokens": [1485, 295, 552, 307, 17138, 1166, 21120, 13], "temperature": 0.0, "avg_logprob": -0.1795361042022705, "compression_ratio": 1.3582089552238805, "no_speech_prob": 1.6028054687922122e-06}, {"id": 488, "seek": 260756, "start": 2607.56, "end": 2615.72, "text": " However, path.iterate directory returns that.", "tokens": [2908, 11, 3100, 13, 1681, 473, 21120, 11247, 300, 13], "temperature": 0.0, "avg_logprob": -0.17967399954795837, "compression_ratio": 1.4656084656084656, "no_speech_prob": 1.8448174614604795e-06}, {"id": 489, "seek": 260756, "start": 2615.72, "end": 2619.88, "text": " Hopefully you've come across generators by now because we did quite a lot of stuff that", "tokens": [10429, 291, 600, 808, 2108, 38662, 538, 586, 570, 321, 630, 1596, 257, 688, 295, 1507, 300], "temperature": 0.0, "avg_logprob": -0.17967399954795837, "compression_ratio": 1.4656084656084656, "no_speech_prob": 1.8448174614604795e-06}, {"id": 490, "seek": 260756, "start": 2619.88, "end": 2622.44, "text": " used them behind the scenes without talking about them too much.", "tokens": [1143, 552, 2261, 264, 8026, 1553, 1417, 466, 552, 886, 709, 13], "temperature": 0.0, "avg_logprob": -0.17967399954795837, "compression_ratio": 1.4656084656084656, "no_speech_prob": 1.8448174614604795e-06}, {"id": 491, "seek": 260756, "start": 2622.44, "end": 2631.32, "text": " But basically a generator is something in Python 3 which you can iterate over.", "tokens": [583, 1936, 257, 19265, 307, 746, 294, 15329, 805, 597, 291, 393, 44497, 670, 13], "temperature": 0.0, "avg_logprob": -0.17967399954795837, "compression_ratio": 1.4656084656084656, "no_speech_prob": 1.8448174614604795e-06}, {"id": 492, "seek": 263132, "start": 2631.32, "end": 2646.7200000000003, "text": " So basically you can go for O in that print.", "tokens": [407, 1936, 291, 393, 352, 337, 422, 294, 300, 4482, 13], "temperature": 0.0, "avg_logprob": -0.25223578176190775, "compression_ratio": 1.1956521739130435, "no_speech_prob": 6.144147846498527e-06}, {"id": 493, "seek": 263132, "start": 2646.7200000000003, "end": 2656.28, "text": " Or of course you could do the same thing as a list comprehension.", "tokens": [1610, 295, 1164, 291, 727, 360, 264, 912, 551, 382, 257, 1329, 44991, 13], "temperature": 0.0, "avg_logprob": -0.25223578176190775, "compression_ratio": 1.1956521739130435, "no_speech_prob": 6.144147846498527e-06}, {"id": 494, "seek": 265628, "start": 2656.28, "end": 2662.96, "text": " Or you can just stick the word list around it to turn a generator into a list.", "tokens": [1610, 291, 393, 445, 2897, 264, 1349, 1329, 926, 309, 281, 1261, 257, 19265, 666, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.18755139907201132, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.962193310755538e-06}, {"id": 495, "seek": 265628, "start": 2662.96, "end": 2668.6800000000003, "text": " So anytime you see me put list around something, that's normally because it returned a generator.", "tokens": [407, 13038, 291, 536, 385, 829, 1329, 926, 746, 11, 300, 311, 5646, 570, 309, 8752, 257, 19265, 13], "temperature": 0.0, "avg_logprob": -0.18755139907201132, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.962193310755538e-06}, {"id": 496, "seek": 265628, "start": 2668.6800000000003, "end": 2670.9, "text": " It's not particularly interesting.", "tokens": [467, 311, 406, 4098, 1880, 13], "temperature": 0.0, "avg_logprob": -0.18755139907201132, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.962193310755538e-06}, {"id": 497, "seek": 265628, "start": 2670.9, "end": 2677.1600000000003, "text": " The reason that things generally return generators is what if the directory had 10 million items", "tokens": [440, 1778, 300, 721, 5101, 2736, 38662, 307, 437, 498, 264, 21120, 632, 1266, 2459, 4754], "temperature": 0.0, "avg_logprob": -0.18755139907201132, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.962193310755538e-06}, {"id": 498, "seek": 265628, "start": 2677.1600000000003, "end": 2678.1600000000003, "text": " in?", "tokens": [294, 30], "temperature": 0.0, "avg_logprob": -0.18755139907201132, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.962193310755538e-06}, {"id": 499, "seek": 265628, "start": 2678.1600000000003, "end": 2682.96, "text": " You don't necessarily want a 10 million long list, so with a for loop, you'll just grab", "tokens": [509, 500, 380, 4725, 528, 257, 1266, 2459, 938, 1329, 11, 370, 365, 257, 337, 6367, 11, 291, 603, 445, 4444], "temperature": 0.0, "avg_logprob": -0.18755139907201132, "compression_ratio": 1.6597510373443984, "no_speech_prob": 6.962193310755538e-06}, {"id": 500, "seek": 268296, "start": 2682.96, "end": 2686.76, "text": " one, do the thing, throw it away, grab the second, throw it away.", "tokens": [472, 11, 360, 264, 551, 11, 3507, 309, 1314, 11, 4444, 264, 1150, 11, 3507, 309, 1314, 13], "temperature": 0.0, "avg_logprob": -0.2058623731136322, "compression_ratio": 1.7, "no_speech_prob": 6.438940999942133e-06}, {"id": 501, "seek": 268296, "start": 2686.76, "end": 2690.48, "text": " It lets you do things lazily.", "tokens": [467, 6653, 291, 360, 721, 19320, 953, 13], "temperature": 0.0, "avg_logprob": -0.2058623731136322, "compression_ratio": 1.7, "no_speech_prob": 6.438940999942133e-06}, {"id": 502, "seek": 268296, "start": 2690.48, "end": 2695.44, "text": " You'll see that the things that's returning aren't actually strings, but they're some", "tokens": [509, 603, 536, 300, 264, 721, 300, 311, 12678, 3212, 380, 767, 13985, 11, 457, 436, 434, 512], "temperature": 0.0, "avg_logprob": -0.2058623731136322, "compression_ratio": 1.7, "no_speech_prob": 6.438940999942133e-06}, {"id": 503, "seek": 268296, "start": 2695.44, "end": 2696.44, "text": " kind of object.", "tokens": [733, 295, 2657, 13], "temperature": 0.0, "avg_logprob": -0.2058623731136322, "compression_ratio": 1.7, "no_speech_prob": 6.438940999942133e-06}, {"id": 504, "seek": 268296, "start": 2696.44, "end": 2699.4, "text": " If you're using Windows, it'll be a Windows path.", "tokens": [759, 291, 434, 1228, 8591, 11, 309, 603, 312, 257, 8591, 3100, 13], "temperature": 0.0, "avg_logprob": -0.2058623731136322, "compression_ratio": 1.7, "no_speech_prob": 6.438940999942133e-06}, {"id": 505, "seek": 268296, "start": 2699.4, "end": 2702.56, "text": " On Linux, it'll be a POSIX path.", "tokens": [1282, 18734, 11, 309, 603, 312, 257, 430, 4367, 21124, 3100, 13], "temperature": 0.0, "avg_logprob": -0.2058623731136322, "compression_ratio": 1.7, "no_speech_prob": 6.438940999942133e-06}, {"id": 506, "seek": 268296, "start": 2702.56, "end": 2705.56, "text": " Most of the time you can use them as if they were strings.", "tokens": [4534, 295, 264, 565, 291, 393, 764, 552, 382, 498, 436, 645, 13985, 13], "temperature": 0.0, "avg_logprob": -0.2058623731136322, "compression_ratio": 1.7, "no_speech_prob": 6.438940999942133e-06}, {"id": 507, "seek": 268296, "start": 2705.56, "end": 2711.56, "text": " So most like if you pass it to any of the os.path.whatever functions in Python, it'll", "tokens": [407, 881, 411, 498, 291, 1320, 309, 281, 604, 295, 264, 3003, 13, 31852, 13, 1363, 7969, 6828, 294, 15329, 11, 309, 603], "temperature": 0.0, "avg_logprob": -0.2058623731136322, "compression_ratio": 1.7, "no_speech_prob": 6.438940999942133e-06}, {"id": 508, "seek": 271156, "start": 2711.56, "end": 2714.44, "text": " just work.", "tokens": [445, 589, 13], "temperature": 0.0, "avg_logprob": -0.19071580341884067, "compression_ratio": 1.5562913907284768, "no_speech_prob": 1.0129941074410453e-05}, {"id": 509, "seek": 271156, "start": 2714.44, "end": 2718.68, "text": " But some external libraries, it won't work.", "tokens": [583, 512, 8320, 15148, 11, 309, 1582, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.19071580341884067, "compression_ratio": 1.5562913907284768, "no_speech_prob": 1.0129941074410453e-05}, {"id": 510, "seek": 271156, "start": 2718.68, "end": 2720.12, "text": " So that's fine.", "tokens": [407, 300, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.19071580341884067, "compression_ratio": 1.5562913907284768, "no_speech_prob": 1.0129941074410453e-05}, {"id": 511, "seek": 271156, "start": 2720.12, "end": 2729.4, "text": " If you grab one of these, let's say o equals, let's just grab one of these.", "tokens": [759, 291, 4444, 472, 295, 613, 11, 718, 311, 584, 277, 6915, 11, 718, 311, 445, 4444, 472, 295, 613, 13], "temperature": 0.0, "avg_logprob": -0.19071580341884067, "compression_ratio": 1.5562913907284768, "no_speech_prob": 1.0129941074410453e-05}, {"id": 512, "seek": 271156, "start": 2729.4, "end": 2737.2799999999997, "text": " So in general, you can change data types in Python just by naming the data type that you", "tokens": [407, 294, 2674, 11, 291, 393, 1319, 1412, 3467, 294, 15329, 445, 538, 25290, 264, 1412, 2010, 300, 291], "temperature": 0.0, "avg_logprob": -0.19071580341884067, "compression_ratio": 1.5562913907284768, "no_speech_prob": 1.0129941074410453e-05}, {"id": 513, "seek": 273728, "start": 2737.28, "end": 2742.0, "text": " want and treating it like a function, and that will cast it.", "tokens": [528, 293, 15083, 309, 411, 257, 2445, 11, 293, 300, 486, 4193, 309, 13], "temperature": 0.0, "avg_logprob": -0.16106338742413098, "compression_ratio": 1.5449735449735449, "no_speech_prob": 5.33813454239862e-06}, {"id": 514, "seek": 273728, "start": 2742.0, "end": 2748.0600000000004, "text": " So anytime you try to use one of these pathlib objects and you pass it to something which", "tokens": [407, 13038, 291, 853, 281, 764, 472, 295, 613, 3100, 38270, 6565, 293, 291, 1320, 309, 281, 746, 597], "temperature": 0.0, "avg_logprob": -0.16106338742413098, "compression_ratio": 1.5449735449735449, "no_speech_prob": 5.33813454239862e-06}, {"id": 515, "seek": 273728, "start": 2748.0600000000004, "end": 2753.6000000000004, "text": " says I was affecting a string, this is not a string, that's how you do it.", "tokens": [1619, 286, 390, 17476, 257, 6798, 11, 341, 307, 406, 257, 6798, 11, 300, 311, 577, 291, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.16106338742413098, "compression_ratio": 1.5449735449735449, "no_speech_prob": 5.33813454239862e-06}, {"id": 516, "seek": 273728, "start": 2753.6000000000004, "end": 2755.84, "text": " So you'll see there's quite a lot of convenient things you can do.", "tokens": [407, 291, 603, 536, 456, 311, 1596, 257, 688, 295, 10851, 721, 291, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.16106338742413098, "compression_ratio": 1.5449735449735449, "no_speech_prob": 5.33813454239862e-06}, {"id": 517, "seek": 275584, "start": 2755.84, "end": 2768.04, "text": " One kind of fun thing is the slash operator is not divided by, but it's path slash.", "tokens": [1485, 733, 295, 1019, 551, 307, 264, 17330, 12973, 307, 406, 6666, 538, 11, 457, 309, 311, 3100, 17330, 13], "temperature": 0.0, "avg_logprob": -0.18602227628900764, "compression_ratio": 1.7208121827411167, "no_speech_prob": 1.451041316613555e-05}, {"id": 518, "seek": 275584, "start": 2768.04, "end": 2772.6000000000004, "text": " So like they've overridden the slash operator in Python so that it works.", "tokens": [407, 411, 436, 600, 670, 81, 6171, 264, 17330, 12973, 294, 15329, 370, 300, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.18602227628900764, "compression_ratio": 1.7208121827411167, "no_speech_prob": 1.451041316613555e-05}, {"id": 519, "seek": 275584, "start": 2772.6000000000004, "end": 2776.7200000000003, "text": " So you can say path slash whatever, and that gets you.", "tokens": [407, 291, 393, 584, 3100, 17330, 2035, 11, 293, 300, 2170, 291, 13], "temperature": 0.0, "avg_logprob": -0.18602227628900764, "compression_ratio": 1.7208121827411167, "no_speech_prob": 1.451041316613555e-05}, {"id": 520, "seek": 275584, "start": 2776.7200000000003, "end": 2778.96, "text": " See how that's not inside a string?", "tokens": [3008, 577, 300, 311, 406, 1854, 257, 6798, 30], "temperature": 0.0, "avg_logprob": -0.18602227628900764, "compression_ratio": 1.7208121827411167, "no_speech_prob": 1.451041316613555e-05}, {"id": 521, "seek": 275584, "start": 2778.96, "end": 2784.92, "text": " So this is actually applying not the division operator, but the overridden slash operator,", "tokens": [407, 341, 307, 767, 9275, 406, 264, 10044, 12973, 11, 457, 264, 670, 81, 6171, 17330, 12973, 11], "temperature": 0.0, "avg_logprob": -0.18602227628900764, "compression_ratio": 1.7208121827411167, "no_speech_prob": 1.451041316613555e-05}, {"id": 522, "seek": 278492, "start": 2784.92, "end": 2790.0, "text": " which means get a child thing in that path.", "tokens": [597, 1355, 483, 257, 1440, 551, 294, 300, 3100, 13], "temperature": 0.0, "avg_logprob": -0.13662470001535318, "compression_ratio": 1.721698113207547, "no_speech_prob": 9.516205864201766e-06}, {"id": 523, "seek": 278492, "start": 2790.0, "end": 2798.48, "text": " And you'll see if you run that, it doesn't return a string, it returns a pathlib object.", "tokens": [400, 291, 603, 536, 498, 291, 1190, 300, 11, 309, 1177, 380, 2736, 257, 6798, 11, 309, 11247, 257, 3100, 38270, 2657, 13], "temperature": 0.0, "avg_logprob": -0.13662470001535318, "compression_ratio": 1.721698113207547, "no_speech_prob": 9.516205864201766e-06}, {"id": 524, "seek": 278492, "start": 2798.48, "end": 2803.92, "text": " And so one of the things a pathlib object can do is it has an open method.", "tokens": [400, 370, 472, 295, 264, 721, 257, 3100, 38270, 2657, 393, 360, 307, 309, 575, 364, 1269, 3170, 13], "temperature": 0.0, "avg_logprob": -0.13662470001535318, "compression_ratio": 1.721698113207547, "no_speech_prob": 9.516205864201766e-06}, {"id": 525, "seek": 278492, "start": 2803.92, "end": 2808.44, "text": " So it's actually pretty cool once you start getting the hang of it.", "tokens": [407, 309, 311, 767, 1238, 1627, 1564, 291, 722, 1242, 264, 3967, 295, 309, 13], "temperature": 0.0, "avg_logprob": -0.13662470001535318, "compression_ratio": 1.721698113207547, "no_speech_prob": 9.516205864201766e-06}, {"id": 526, "seek": 278492, "start": 2808.44, "end": 2813.8, "text": " And you'll also find that the open method takes all the kind of arguments you're familiar", "tokens": [400, 291, 603, 611, 915, 300, 264, 1269, 3170, 2516, 439, 264, 733, 295, 12869, 291, 434, 4963], "temperature": 0.0, "avg_logprob": -0.13662470001535318, "compression_ratio": 1.721698113207547, "no_speech_prob": 9.516205864201766e-06}, {"id": 527, "seek": 281380, "start": 2813.8, "end": 2817.76, "text": " with, you can say right or binary or encoding or whatever.", "tokens": [365, 11, 291, 393, 584, 558, 420, 17434, 420, 43430, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.17143357594807943, "compression_ratio": 1.4764397905759161, "no_speech_prob": 3.611958391047665e-06}, {"id": 528, "seek": 281380, "start": 2817.76, "end": 2829.36, "text": " So in this case, I want to load up these JSON files which contain not the images, but the", "tokens": [407, 294, 341, 1389, 11, 286, 528, 281, 3677, 493, 613, 31828, 7098, 597, 5304, 406, 264, 5267, 11, 457, 264], "temperature": 0.0, "avg_logprob": -0.17143357594807943, "compression_ratio": 1.4764397905759161, "no_speech_prob": 3.611958391047665e-06}, {"id": 529, "seek": 281380, "start": 2829.36, "end": 2834.2000000000003, "text": " bounding boxes and the classes of the objects.", "tokens": [5472, 278, 9002, 293, 264, 5359, 295, 264, 6565, 13], "temperature": 0.0, "avg_logprob": -0.17143357594807943, "compression_ratio": 1.4764397905759161, "no_speech_prob": 3.611958391047665e-06}, {"id": 530, "seek": 281380, "start": 2834.2000000000003, "end": 2840.2000000000003, "text": " And so in Python, the easiest way to do that is with the JSON library, or there's some", "tokens": [400, 370, 294, 15329, 11, 264, 12889, 636, 281, 360, 300, 307, 365, 264, 31828, 6405, 11, 420, 456, 311, 512], "temperature": 0.0, "avg_logprob": -0.17143357594807943, "compression_ratio": 1.4764397905759161, "no_speech_prob": 3.611958391047665e-06}, {"id": 531, "seek": 284020, "start": 2840.2, "end": 2844.48, "text": " faster API equivalent versions, but this is pretty small so you won't need them.", "tokens": [4663, 9362, 10344, 9606, 11, 457, 341, 307, 1238, 1359, 370, 291, 1582, 380, 643, 552, 13], "temperature": 0.0, "avg_logprob": -0.19192032103842877, "compression_ratio": 1.5530973451327434, "no_speech_prob": 6.144141934782965e-06}, {"id": 532, "seek": 284020, "start": 2844.48, "end": 2850.12, "text": " And you go JSON.load and you pass it an open file object.", "tokens": [400, 291, 352, 31828, 13, 2907, 293, 291, 1320, 309, 364, 1269, 3991, 2657, 13], "temperature": 0.0, "avg_logprob": -0.19192032103842877, "compression_ratio": 1.5530973451327434, "no_speech_prob": 6.144141934782965e-06}, {"id": 533, "seek": 284020, "start": 2850.12, "end": 2856.16, "text": " And so the easy way to do that since we're using pathlib is just go path.open.", "tokens": [400, 370, 264, 1858, 636, 281, 360, 300, 1670, 321, 434, 1228, 3100, 38270, 307, 445, 352, 3100, 13, 15752, 13], "temperature": 0.0, "avg_logprob": -0.19192032103842877, "compression_ratio": 1.5530973451327434, "no_speech_prob": 6.144141934782965e-06}, {"id": 534, "seek": 284020, "start": 2856.16, "end": 2859.6, "text": " So these JSON files that we're going to look inside in a moment, if you haven't used them", "tokens": [407, 613, 31828, 7098, 300, 321, 434, 516, 281, 574, 1854, 294, 257, 1623, 11, 498, 291, 2378, 380, 1143, 552], "temperature": 0.0, "avg_logprob": -0.19192032103842877, "compression_ratio": 1.5530973451327434, "no_speech_prob": 6.144141934782965e-06}, {"id": 535, "seek": 284020, "start": 2859.6, "end": 2862.72, "text": " before, JSON is JavaScript object notation.", "tokens": [949, 11, 31828, 307, 15778, 2657, 24657, 13], "temperature": 0.0, "avg_logprob": -0.19192032103842877, "compression_ratio": 1.5530973451327434, "no_speech_prob": 6.144141934782965e-06}, {"id": 536, "seek": 286272, "start": 2862.72, "end": 2870.7999999999997, "text": " It's kind of the most standard way to pass around hierarchical structured data now.", "tokens": [467, 311, 733, 295, 264, 881, 3832, 636, 281, 1320, 926, 35250, 804, 18519, 1412, 586, 13], "temperature": 0.0, "avg_logprob": -0.19720840454101562, "compression_ratio": 1.5227272727272727, "no_speech_prob": 1.0129878319276031e-05}, {"id": 537, "seek": 286272, "start": 2870.7999999999997, "end": 2875.04, "text": " Obviously not just with JavaScript.", "tokens": [7580, 406, 445, 365, 15778, 13], "temperature": 0.0, "avg_logprob": -0.19720840454101562, "compression_ratio": 1.5227272727272727, "no_speech_prob": 1.0129878319276031e-05}, {"id": 538, "seek": 286272, "start": 2875.04, "end": 2876.9599999999996, "text": " You'll see I've got some JSON files in here.", "tokens": [509, 603, 536, 286, 600, 658, 512, 31828, 7098, 294, 510, 13], "temperature": 0.0, "avg_logprob": -0.19720840454101562, "compression_ratio": 1.5227272727272727, "no_speech_prob": 1.0129878319276031e-05}, {"id": 539, "seek": 286272, "start": 2876.9599999999996, "end": 2880.2799999999997, "text": " They actually did not come from the mirror I mentioned.", "tokens": [814, 767, 630, 406, 808, 490, 264, 8013, 286, 2835, 13], "temperature": 0.0, "avg_logprob": -0.19720840454101562, "compression_ratio": 1.5227272727272727, "no_speech_prob": 1.0129878319276031e-05}, {"id": 540, "seek": 286272, "start": 2880.2799999999997, "end": 2887.7599999999998, "text": " The original Pascal annotations were in XML format, but cool kids can't use XML anymore.", "tokens": [440, 3380, 41723, 25339, 763, 645, 294, 43484, 7877, 11, 457, 1627, 2301, 393, 380, 764, 43484, 3602, 13], "temperature": 0.0, "avg_logprob": -0.19720840454101562, "compression_ratio": 1.5227272727272727, "no_speech_prob": 1.0129878319276031e-05}, {"id": 541, "seek": 286272, "start": 2887.7599999999998, "end": 2892.48, "text": " We have to use JSON, so somebody's converted them all to JSON, and so you'll find the second", "tokens": [492, 362, 281, 764, 31828, 11, 370, 2618, 311, 16424, 552, 439, 281, 31828, 11, 293, 370, 291, 603, 915, 264, 1150], "temperature": 0.0, "avg_logprob": -0.19720840454101562, "compression_ratio": 1.5227272727272727, "no_speech_prob": 1.0129878319276031e-05}, {"id": 542, "seek": 289248, "start": 2892.48, "end": 2895.56, "text": " link here has all the JSON files.", "tokens": [2113, 510, 575, 439, 264, 31828, 7098, 13], "temperature": 0.0, "avg_logprob": -0.1944018446880838, "compression_ratio": 1.538812785388128, "no_speech_prob": 1.0451447451487184e-05}, {"id": 543, "seek": 289248, "start": 2895.56, "end": 2901.48, "text": " So if you just pop them in the same location that I've put them here, everything will work", "tokens": [407, 498, 291, 445, 1665, 552, 294, 264, 912, 4914, 300, 286, 600, 829, 552, 510, 11, 1203, 486, 589], "temperature": 0.0, "avg_logprob": -0.1944018446880838, "compression_ratio": 1.538812785388128, "no_speech_prob": 1.0451447451487184e-05}, {"id": 544, "seek": 289248, "start": 2901.48, "end": 2902.48, "text": " for you.", "tokens": [337, 291, 13], "temperature": 0.0, "avg_logprob": -0.1944018446880838, "compression_ratio": 1.538812785388128, "no_speech_prob": 1.0451447451487184e-05}, {"id": 545, "seek": 289248, "start": 2902.48, "end": 2910.56, "text": " So these annotation files, JSONs, basically contain a dictionary.", "tokens": [407, 613, 48654, 7098, 11, 31828, 82, 11, 1936, 5304, 257, 25890, 13], "temperature": 0.0, "avg_logprob": -0.1944018446880838, "compression_ratio": 1.538812785388128, "no_speech_prob": 1.0451447451487184e-05}, {"id": 546, "seek": 289248, "start": 2910.56, "end": 2914.76, "text": " Once you open up the JSON, it becomes a Python dictionary, and they've got a few different", "tokens": [3443, 291, 1269, 493, 264, 31828, 11, 309, 3643, 257, 15329, 25890, 11, 293, 436, 600, 658, 257, 1326, 819], "temperature": 0.0, "avg_logprob": -0.1944018446880838, "compression_ratio": 1.538812785388128, "no_speech_prob": 1.0451447451487184e-05}, {"id": 547, "seek": 289248, "start": 2914.76, "end": 2915.76, "text": " things in.", "tokens": [721, 294, 13], "temperature": 0.0, "avg_logprob": -0.1944018446880838, "compression_ratio": 1.538812785388128, "no_speech_prob": 1.0451447451487184e-05}, {"id": 548, "seek": 289248, "start": 2915.76, "end": 2920.44, "text": " The first is we can look at images.", "tokens": [440, 700, 307, 321, 393, 574, 412, 5267, 13], "temperature": 0.0, "avg_logprob": -0.1944018446880838, "compression_ratio": 1.538812785388128, "no_speech_prob": 1.0451447451487184e-05}, {"id": 549, "seek": 292044, "start": 2920.44, "end": 2926.0, "text": " It's got a list of all of the images, how big they are, and a unique ID for each one.", "tokens": [467, 311, 658, 257, 1329, 295, 439, 295, 264, 5267, 11, 577, 955, 436, 366, 11, 293, 257, 3845, 7348, 337, 1184, 472, 13], "temperature": 0.0, "avg_logprob": -0.1469470181511444, "compression_ratio": 1.5614754098360655, "no_speech_prob": 1.7778407709556632e-05}, {"id": 550, "seek": 292044, "start": 2926.0, "end": 2934.36, "text": " One thing you'll notice here is I've taken the word images and put it inside a constant", "tokens": [1485, 551, 291, 603, 3449, 510, 307, 286, 600, 2726, 264, 1349, 5267, 293, 829, 309, 1854, 257, 5754], "temperature": 0.0, "avg_logprob": -0.1469470181511444, "compression_ratio": 1.5614754098360655, "no_speech_prob": 1.7778407709556632e-05}, {"id": 551, "seek": 292044, "start": 2934.36, "end": 2935.36, "text": " called images.", "tokens": [1219, 5267, 13], "temperature": 0.0, "avg_logprob": -0.1469470181511444, "compression_ratio": 1.5614754098360655, "no_speech_prob": 1.7778407709556632e-05}, {"id": 552, "seek": 292044, "start": 2935.36, "end": 2941.52, "text": " That may seem kind of weird, but if you're using a notebook or any kind of IDE or whatever,", "tokens": [663, 815, 1643, 733, 295, 3657, 11, 457, 498, 291, 434, 1228, 257, 21060, 420, 604, 733, 295, 40930, 420, 2035, 11], "temperature": 0.0, "avg_logprob": -0.1469470181511444, "compression_ratio": 1.5614754098360655, "no_speech_prob": 1.7778407709556632e-05}, {"id": 553, "seek": 292044, "start": 2941.52, "end": 2947.84, "text": " this now means I can tab complete all of my strings and I won't accidentally type it slightly", "tokens": [341, 586, 1355, 286, 393, 4421, 3566, 439, 295, 452, 13985, 293, 286, 1582, 380, 15715, 2010, 309, 4748], "temperature": 0.0, "avg_logprob": -0.1469470181511444, "compression_ratio": 1.5614754098360655, "no_speech_prob": 1.7778407709556632e-05}, {"id": 554, "seek": 292044, "start": 2947.84, "end": 2948.84, "text": " wrong.", "tokens": [2085, 13], "temperature": 0.0, "avg_logprob": -0.1469470181511444, "compression_ratio": 1.5614754098360655, "no_speech_prob": 1.7778407709556632e-05}, {"id": 555, "seek": 294884, "start": 2948.84, "end": 2952.28, "text": " That's a handy trick.", "tokens": [663, 311, 257, 13239, 4282, 13], "temperature": 0.0, "avg_logprob": -0.2030792114062187, "compression_ratio": 1.6368715083798884, "no_speech_prob": 3.288738298579119e-06}, {"id": 556, "seek": 294884, "start": 2952.28, "end": 2956.6800000000003, "text": " So here's the contents of the first few things in the images.", "tokens": [407, 510, 311, 264, 15768, 295, 264, 700, 1326, 721, 294, 264, 5267, 13], "temperature": 0.0, "avg_logprob": -0.2030792114062187, "compression_ratio": 1.6368715083798884, "no_speech_prob": 3.288738298579119e-06}, {"id": 557, "seek": 294884, "start": 2956.6800000000003, "end": 2960.52, "text": " More interestingly, here are some of the annotations.", "tokens": [5048, 25873, 11, 510, 366, 512, 295, 264, 25339, 763, 13], "temperature": 0.0, "avg_logprob": -0.2030792114062187, "compression_ratio": 1.6368715083798884, "no_speech_prob": 3.288738298579119e-06}, {"id": 558, "seek": 294884, "start": 2960.52, "end": 2967.2000000000003, "text": " So you'll see basically an annotation contains a bounding box, and the bounding box tells", "tokens": [407, 291, 603, 536, 1936, 364, 48654, 8306, 257, 5472, 278, 2424, 11, 293, 264, 5472, 278, 2424, 5112], "temperature": 0.0, "avg_logprob": -0.2030792114062187, "compression_ratio": 1.6368715083798884, "no_speech_prob": 3.288738298579119e-06}, {"id": 559, "seek": 294884, "start": 2967.2000000000003, "end": 2977.1800000000003, "text": " you the column and row of the top left, and its height and width.", "tokens": [291, 264, 7738, 293, 5386, 295, 264, 1192, 1411, 11, 293, 1080, 6681, 293, 11402, 13], "temperature": 0.0, "avg_logprob": -0.2030792114062187, "compression_ratio": 1.6368715083798884, "no_speech_prob": 3.288738298579119e-06}, {"id": 560, "seek": 297718, "start": 2977.18, "end": 2983.2, "text": " And then it tells you that that particular bounding box is for this particular image.", "tokens": [400, 550, 309, 5112, 291, 300, 300, 1729, 5472, 278, 2424, 307, 337, 341, 1729, 3256, 13], "temperature": 0.0, "avg_logprob": -0.16165812380679018, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.436745037608489e-06}, {"id": 561, "seek": 297718, "start": 2983.2, "end": 2990.2, "text": " So you'd have to join that up to over here to find it's actually 012.jpg, and it's of", "tokens": [407, 291, 1116, 362, 281, 3917, 300, 493, 281, 670, 510, 281, 915, 309, 311, 767, 1958, 4762, 13, 73, 49861, 11, 293, 309, 311, 295], "temperature": 0.0, "avg_logprob": -0.16165812380679018, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.436745037608489e-06}, {"id": 562, "seek": 297718, "start": 2990.2, "end": 2994.24, "text": " category ID 7.", "tokens": [7719, 7348, 1614, 13], "temperature": 0.0, "avg_logprob": -0.16165812380679018, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.436745037608489e-06}, {"id": 563, "seek": 297718, "start": 2994.24, "end": 2998.3599999999997, "text": " It also, for some of them at least, has a polygon segmentation, not just a bounding", "tokens": [467, 611, 11, 337, 512, 295, 552, 412, 1935, 11, 575, 257, 48242, 9469, 399, 11, 406, 445, 257, 5472, 278], "temperature": 0.0, "avg_logprob": -0.16165812380679018, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.436745037608489e-06}, {"id": 564, "seek": 297718, "start": 2998.3599999999997, "end": 2999.3599999999997, "text": " box.", "tokens": [2424, 13], "temperature": 0.0, "avg_logprob": -0.16165812380679018, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.436745037608489e-06}, {"id": 565, "seek": 297718, "start": 2999.3599999999997, "end": 3002.64, "text": " We're not going to be using that.", "tokens": [492, 434, 406, 516, 281, 312, 1228, 300, 13], "temperature": 0.0, "avg_logprob": -0.16165812380679018, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.436745037608489e-06}, {"id": 566, "seek": 297718, "start": 3002.64, "end": 3006.3199999999997, "text": " Some of them have an ignore flag, so we'll ignore the ignore flags.", "tokens": [2188, 295, 552, 362, 364, 11200, 7166, 11, 370, 321, 603, 11200, 264, 11200, 23265, 13], "temperature": 0.0, "avg_logprob": -0.16165812380679018, "compression_ratio": 1.6391304347826088, "no_speech_prob": 1.436745037608489e-06}, {"id": 567, "seek": 300632, "start": 3006.32, "end": 3012.2400000000002, "text": " Some of them have something telling you it's a crowd of that object, not just one of them.", "tokens": [2188, 295, 552, 362, 746, 3585, 291, 309, 311, 257, 6919, 295, 300, 2657, 11, 406, 445, 472, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.24541222176900723, "compression_ratio": 1.5932203389830508, "no_speech_prob": 6.540400136145763e-06}, {"id": 568, "seek": 300632, "start": 3012.2400000000002, "end": 3016.1400000000003, "text": " So that's what these annotations look like.", "tokens": [407, 300, 311, 437, 613, 25339, 763, 574, 411, 13], "temperature": 0.0, "avg_logprob": -0.24541222176900723, "compression_ratio": 1.5932203389830508, "no_speech_prob": 6.540400136145763e-06}, {"id": 569, "seek": 300632, "start": 3016.1400000000003, "end": 3020.44, "text": " So then you saw here there's a category ID, so then we can look at the categories.", "tokens": [407, 550, 291, 1866, 510, 456, 311, 257, 7719, 7348, 11, 370, 550, 321, 393, 574, 412, 264, 10479, 13], "temperature": 0.0, "avg_logprob": -0.24541222176900723, "compression_ratio": 1.5932203389830508, "no_speech_prob": 6.540400136145763e-06}, {"id": 570, "seek": 300632, "start": 3020.44, "end": 3021.44, "text": " Here's a few examples.", "tokens": [1692, 311, 257, 1326, 5110, 13], "temperature": 0.0, "avg_logprob": -0.24541222176900723, "compression_ratio": 1.5932203389830508, "no_speech_prob": 6.540400136145763e-06}, {"id": 571, "seek": 300632, "start": 3021.44, "end": 3025.4, "text": " Basically each ID has a name.", "tokens": [8537, 1184, 7348, 575, 257, 1315, 13], "temperature": 0.0, "avg_logprob": -0.24541222176900723, "compression_ratio": 1.5932203389830508, "no_speech_prob": 6.540400136145763e-06}, {"id": 572, "seek": 300632, "start": 3025.4, "end": 3029.3, "text": " Here we go.", "tokens": [1692, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.24541222176900723, "compression_ratio": 1.5932203389830508, "no_speech_prob": 6.540400136145763e-06}, {"id": 573, "seek": 302930, "start": 3029.3, "end": 3037.0, "text": " So what I did then was turn this categories list into a dictionary from ID to name.", "tokens": [407, 437, 286, 630, 550, 390, 1261, 341, 10479, 1329, 666, 257, 25890, 490, 7348, 281, 1315, 13], "temperature": 0.0, "avg_logprob": -0.1878052964995179, "compression_ratio": 1.728813559322034, "no_speech_prob": 5.17389526066836e-06}, {"id": 574, "seek": 302930, "start": 3037.0, "end": 3044.0800000000004, "text": " I created a dictionary from ID to name of the image file names, and I created a list", "tokens": [286, 2942, 257, 25890, 490, 7348, 281, 1315, 295, 264, 3256, 3991, 5288, 11, 293, 286, 2942, 257, 1329], "temperature": 0.0, "avg_logprob": -0.1878052964995179, "compression_ratio": 1.728813559322034, "no_speech_prob": 5.17389526066836e-06}, {"id": 575, "seek": 302930, "start": 3044.0800000000004, "end": 3047.52, "text": " of all of the image IDs just to make life easier.", "tokens": [295, 439, 295, 264, 3256, 48212, 445, 281, 652, 993, 3571, 13], "temperature": 0.0, "avg_logprob": -0.1878052964995179, "compression_ratio": 1.728813559322034, "no_speech_prob": 5.17389526066836e-06}, {"id": 576, "seek": 302930, "start": 3047.52, "end": 3052.0800000000004, "text": " So generally when you're working with a new dataset, or at least when I work with a new", "tokens": [407, 5101, 562, 291, 434, 1364, 365, 257, 777, 28872, 11, 420, 412, 1935, 562, 286, 589, 365, 257, 777], "temperature": 0.0, "avg_logprob": -0.1878052964995179, "compression_ratio": 1.728813559322034, "no_speech_prob": 5.17389526066836e-06}, {"id": 577, "seek": 305208, "start": 3052.08, "end": 3062.08, "text": " dataset, I try to make it look the way I would want it to if I designed that dataset.", "tokens": [28872, 11, 286, 853, 281, 652, 309, 574, 264, 636, 286, 576, 528, 309, 281, 498, 286, 4761, 300, 28872, 13], "temperature": 0.0, "avg_logprob": -0.157717159816197, "compression_ratio": 1.5614973262032086, "no_speech_prob": 5.173872523300815e-06}, {"id": 578, "seek": 305208, "start": 3062.08, "end": 3068.08, "text": " And so the steps you see here, and you'll see in each class, are basically like the", "tokens": [400, 370, 264, 4439, 291, 536, 510, 11, 293, 291, 603, 536, 294, 1184, 1508, 11, 366, 1936, 411, 264], "temperature": 0.0, "avg_logprob": -0.157717159816197, "compression_ratio": 1.5614973262032086, "no_speech_prob": 5.173872523300815e-06}, {"id": 579, "seek": 305208, "start": 3068.08, "end": 3076.04, "text": " sequence of steps I took as I started working with this new dataset, except without the", "tokens": [8310, 295, 4439, 286, 1890, 382, 286, 1409, 1364, 365, 341, 777, 28872, 11, 3993, 1553, 264], "temperature": 0.0, "avg_logprob": -0.157717159816197, "compression_ratio": 1.5614973262032086, "no_speech_prob": 5.173872523300815e-06}, {"id": 580, "seek": 305208, "start": 3076.04, "end": 3081.6, "text": " thousands of screw-ups that I did.", "tokens": [5383, 295, 5630, 12, 7528, 300, 286, 630, 13], "temperature": 0.0, "avg_logprob": -0.157717159816197, "compression_ratio": 1.5614973262032086, "no_speech_prob": 5.173872523300815e-06}, {"id": 581, "seek": 308160, "start": 3081.6, "end": 3089.96, "text": " I find the one thing people most comment on when they see me working in real-time, having", "tokens": [286, 915, 264, 472, 551, 561, 881, 2871, 322, 562, 436, 536, 385, 1364, 294, 957, 12, 3766, 11, 1419], "temperature": 0.0, "avg_logprob": -0.1970510386457347, "compression_ratio": 1.6375545851528384, "no_speech_prob": 1.1300712685624603e-05}, {"id": 582, "seek": 308160, "start": 3089.96, "end": 3096.36, "text": " seen my classes, is like, wow, you actually don't know what you're doing, do you?", "tokens": [1612, 452, 5359, 11, 307, 411, 11, 6076, 11, 291, 767, 500, 380, 458, 437, 291, 434, 884, 11, 360, 291, 30], "temperature": 0.0, "avg_logprob": -0.1970510386457347, "compression_ratio": 1.6375545851528384, "no_speech_prob": 1.1300712685624603e-05}, {"id": 583, "seek": 308160, "start": 3096.36, "end": 3100.72, "text": " It's like 99% of the things I do don't work, and then the small percentage of the things", "tokens": [467, 311, 411, 11803, 4, 295, 264, 721, 286, 360, 500, 380, 589, 11, 293, 550, 264, 1359, 9668, 295, 264, 721], "temperature": 0.0, "avg_logprob": -0.1970510386457347, "compression_ratio": 1.6375545851528384, "no_speech_prob": 1.1300712685624603e-05}, {"id": 584, "seek": 308160, "start": 3100.72, "end": 3104.4, "text": " that do work end up here.", "tokens": [300, 360, 589, 917, 493, 510, 13], "temperature": 0.0, "avg_logprob": -0.1970510386457347, "compression_ratio": 1.6375545851528384, "no_speech_prob": 1.1300712685624603e-05}, {"id": 585, "seek": 308160, "start": 3104.4, "end": 3110.72, "text": " So I mentioned that because machine learning, and particularly deep learning, is kind of", "tokens": [407, 286, 2835, 300, 570, 3479, 2539, 11, 293, 4098, 2452, 2539, 11, 307, 733, 295], "temperature": 0.0, "avg_logprob": -0.1970510386457347, "compression_ratio": 1.6375545851528384, "no_speech_prob": 1.1300712685624603e-05}, {"id": 586, "seek": 311072, "start": 3110.72, "end": 3112.04, "text": " incredibly frustrating.", "tokens": [6252, 16522, 13], "temperature": 0.0, "avg_logprob": -0.23870733186796114, "compression_ratio": 1.5170731707317073, "no_speech_prob": 3.844921593554318e-06}, {"id": 587, "seek": 311072, "start": 3112.04, "end": 3120.08, "text": " Because in theory, you just define the correct loss function and a flexible enough architecture,", "tokens": [1436, 294, 5261, 11, 291, 445, 6964, 264, 3006, 4470, 2445, 293, 257, 11358, 1547, 9482, 11], "temperature": 0.0, "avg_logprob": -0.23870733186796114, "compression_ratio": 1.5170731707317073, "no_speech_prob": 3.844921593554318e-06}, {"id": 588, "seek": 311072, "start": 3120.08, "end": 3123.0, "text": " and you press train, and you're done.", "tokens": [293, 291, 1886, 3847, 11, 293, 291, 434, 1096, 13], "temperature": 0.0, "avg_logprob": -0.23870733186796114, "compression_ratio": 1.5170731707317073, "no_speech_prob": 3.844921593554318e-06}, {"id": 589, "seek": 311072, "start": 3123.0, "end": 3130.16, "text": " But if that was actually all at talk, then nothing would take any time.", "tokens": [583, 498, 300, 390, 767, 439, 412, 751, 11, 550, 1825, 576, 747, 604, 565, 13], "temperature": 0.0, "avg_logprob": -0.23870733186796114, "compression_ratio": 1.5170731707317073, "no_speech_prob": 3.844921593554318e-06}, {"id": 590, "seek": 311072, "start": 3130.16, "end": 3136.56, "text": " The problem is that all the steps along the way until it works, it doesn't work.", "tokens": [440, 1154, 307, 300, 439, 264, 4439, 2051, 264, 636, 1826, 309, 1985, 11, 309, 1177, 380, 589, 13], "temperature": 0.0, "avg_logprob": -0.23870733186796114, "compression_ratio": 1.5170731707317073, "no_speech_prob": 3.844921593554318e-06}, {"id": 591, "seek": 313656, "start": 3136.56, "end": 3143.48, "text": " You know, like it goes straight to infinity, or it crashes with an incorrect tensor size,", "tokens": [509, 458, 11, 411, 309, 1709, 2997, 281, 13202, 11, 420, 309, 28642, 365, 364, 18424, 40863, 2744, 11], "temperature": 0.0, "avg_logprob": -0.18358907699584961, "compression_ratio": 1.4679802955665024, "no_speech_prob": 8.398026693612337e-06}, {"id": 592, "seek": 313656, "start": 3143.48, "end": 3144.48, "text": " or whatever.", "tokens": [420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.18358907699584961, "compression_ratio": 1.4679802955665024, "no_speech_prob": 8.398026693612337e-06}, {"id": 593, "seek": 313656, "start": 3144.48, "end": 3151.48, "text": " And I will endeavor to show you some kind of debugging techniques as we go, but it's", "tokens": [400, 286, 486, 34975, 281, 855, 291, 512, 733, 295, 45592, 7512, 382, 321, 352, 11, 457, 309, 311], "temperature": 0.0, "avg_logprob": -0.18358907699584961, "compression_ratio": 1.4679802955665024, "no_speech_prob": 8.398026693612337e-06}, {"id": 594, "seek": 313656, "start": 3151.48, "end": 3157.04, "text": " one of the hardest things to teach, because like, I don't know, maybe I just haven't quite", "tokens": [472, 295, 264, 13158, 721, 281, 2924, 11, 570, 411, 11, 286, 500, 380, 458, 11, 1310, 286, 445, 2378, 380, 1596], "temperature": 0.0, "avg_logprob": -0.18358907699584961, "compression_ratio": 1.4679802955665024, "no_speech_prob": 8.398026693612337e-06}, {"id": 595, "seek": 313656, "start": 3157.04, "end": 3161.16, "text": " figured it out yet.", "tokens": [8932, 309, 484, 1939, 13], "temperature": 0.0, "avg_logprob": -0.18358907699584961, "compression_ratio": 1.4679802955665024, "no_speech_prob": 8.398026693612337e-06}, {"id": 596, "seek": 316116, "start": 3161.16, "end": 3168.08, "text": " But the main thing it requires is tenacity, I find, like the biggest difference between", "tokens": [583, 264, 2135, 551, 309, 7029, 307, 2064, 19008, 11, 286, 915, 11, 411, 264, 3880, 2649, 1296], "temperature": 0.0, "avg_logprob": -0.15063241894325513, "compression_ratio": 1.5654008438818565, "no_speech_prob": 1.1659366464300547e-05}, {"id": 597, "seek": 316116, "start": 3168.08, "end": 3172.56, "text": " the people I've worked with who are super effective and the ones who don't seem to go", "tokens": [264, 561, 286, 600, 2732, 365, 567, 366, 1687, 4942, 293, 264, 2306, 567, 500, 380, 1643, 281, 352], "temperature": 0.0, "avg_logprob": -0.15063241894325513, "compression_ratio": 1.5654008438818565, "no_speech_prob": 1.1659366464300547e-05}, {"id": 598, "seek": 316116, "start": 3172.56, "end": 3177.48, "text": " very far, has never been about intellect.", "tokens": [588, 1400, 11, 575, 1128, 668, 466, 10058, 13], "temperature": 0.0, "avg_logprob": -0.15063241894325513, "compression_ratio": 1.5654008438818565, "no_speech_prob": 1.1659366464300547e-05}, {"id": 599, "seek": 316116, "start": 3177.48, "end": 3184.44, "text": " It's always been about sticking with it, basically never giving up.", "tokens": [467, 311, 1009, 668, 466, 13465, 365, 309, 11, 1936, 1128, 2902, 493, 13], "temperature": 0.0, "avg_logprob": -0.15063241894325513, "compression_ratio": 1.5654008438818565, "no_speech_prob": 1.1659366464300547e-05}, {"id": 600, "seek": 316116, "start": 3184.44, "end": 3187.56, "text": " So it's particularly important with this kind of deep learning stuff, because you don't", "tokens": [407, 309, 311, 4098, 1021, 365, 341, 733, 295, 2452, 2539, 1507, 11, 570, 291, 500, 380], "temperature": 0.0, "avg_logprob": -0.15063241894325513, "compression_ratio": 1.5654008438818565, "no_speech_prob": 1.1659366464300547e-05}, {"id": 601, "seek": 318756, "start": 3187.56, "end": 3194.2, "text": " get that continuous reward cycle, like with normal programming, you've got like 12 things", "tokens": [483, 300, 10957, 7782, 6586, 11, 411, 365, 2710, 9410, 11, 291, 600, 658, 411, 2272, 721], "temperature": 0.0, "avg_logprob": -0.22225482054431028, "compression_ratio": 1.7242798353909465, "no_speech_prob": 4.0062346670310944e-05}, {"id": 602, "seek": 318756, "start": 3194.2, "end": 3198.72, "text": " to do until you've got your flash endpoint staged up, you know, and at each stage, it's", "tokens": [281, 360, 1826, 291, 600, 658, 428, 7319, 35795, 45178, 493, 11, 291, 458, 11, 293, 412, 1184, 3233, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.22225482054431028, "compression_ratio": 1.7242798353909465, "no_speech_prob": 4.0062346670310944e-05}, {"id": 603, "seek": 318756, "start": 3198.72, "end": 3204.48, "text": " like okay, we've successfully processed in the JSON, and now we've successfully got the", "tokens": [411, 1392, 11, 321, 600, 10727, 18846, 294, 264, 31828, 11, 293, 586, 321, 600, 10727, 658, 264], "temperature": 0.0, "avg_logprob": -0.22225482054431028, "compression_ratio": 1.7242798353909465, "no_speech_prob": 4.0062346670310944e-05}, {"id": 604, "seek": 318756, "start": 3204.48, "end": 3209.44, "text": " callback from that promise, and now we've successfully created the authentication system.", "tokens": [818, 3207, 490, 300, 6228, 11, 293, 586, 321, 600, 10727, 2942, 264, 26643, 1185, 13], "temperature": 0.0, "avg_logprob": -0.22225482054431028, "compression_ratio": 1.7242798353909465, "no_speech_prob": 4.0062346670310944e-05}, {"id": 605, "seek": 318756, "start": 3209.44, "end": 3213.32, "text": " Like you know, it's this constant sequence of stuff that works.", "tokens": [1743, 291, 458, 11, 309, 311, 341, 5754, 8310, 295, 1507, 300, 1985, 13], "temperature": 0.0, "avg_logprob": -0.22225482054431028, "compression_ratio": 1.7242798353909465, "no_speech_prob": 4.0062346670310944e-05}, {"id": 606, "seek": 321332, "start": 3213.32, "end": 3218.92, "text": " Whereas generally with training a model, it's a constant stream of like, it doesn't work,", "tokens": [13813, 5101, 365, 3097, 257, 2316, 11, 309, 311, 257, 5754, 4309, 295, 411, 11, 309, 1177, 380, 589, 11], "temperature": 0.0, "avg_logprob": -0.23469782935248482, "compression_ratio": 1.6230366492146597, "no_speech_prob": 9.368598512082826e-06}, {"id": 607, "seek": 321332, "start": 3218.92, "end": 3222.44, "text": " it doesn't work, it doesn't work, until eventually it does.", "tokens": [309, 1177, 380, 589, 11, 309, 1177, 380, 589, 11, 1826, 4728, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.23469782935248482, "compression_ratio": 1.6230366492146597, "no_speech_prob": 9.368598512082826e-06}, {"id": 608, "seek": 321332, "start": 3222.44, "end": 3225.84, "text": " So it's kind of annoying.", "tokens": [407, 309, 311, 733, 295, 11304, 13], "temperature": 0.0, "avg_logprob": -0.23469782935248482, "compression_ratio": 1.6230366492146597, "no_speech_prob": 9.368598512082826e-06}, {"id": 609, "seek": 321332, "start": 3225.84, "end": 3230.48, "text": " Okay, so let's now look at the images.", "tokens": [1033, 11, 370, 718, 311, 586, 574, 412, 264, 5267, 13], "temperature": 0.0, "avg_logprob": -0.23469782935248482, "compression_ratio": 1.6230366492146597, "no_speech_prob": 9.368598512082826e-06}, {"id": 610, "seek": 321332, "start": 3230.48, "end": 3240.76, "text": " So you'll find inside the VOC dev kit, there's 2007 and 2012 directories, and in there, there's", "tokens": [407, 291, 603, 915, 1854, 264, 15216, 34, 1905, 8260, 11, 456, 311, 12656, 293, 9125, 5391, 530, 11, 293, 294, 456, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.23469782935248482, "compression_ratio": 1.6230366492146597, "no_speech_prob": 9.368598512082826e-06}, {"id": 611, "seek": 324076, "start": 3240.76, "end": 3244.4, "text": " a whole bunch of stuff that's mainly these XML files, the one we care about with the", "tokens": [257, 1379, 3840, 295, 1507, 300, 311, 8704, 613, 43484, 7098, 11, 264, 472, 321, 1127, 466, 365, 264], "temperature": 0.0, "avg_logprob": -0.23284410875897074, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.1842985259136185e-05}, {"id": 612, "seek": 324076, "start": 3244.4, "end": 3247.1200000000003, "text": " JPEG images.", "tokens": [508, 5208, 38, 5267, 13], "temperature": 0.0, "avg_logprob": -0.23284410875897074, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.1842985259136185e-05}, {"id": 613, "seek": 324076, "start": 3247.1200000000003, "end": 3253.88, "text": " And so again, here you've got the use of pathlibs slash operator, and inside there's a few examples", "tokens": [400, 370, 797, 11, 510, 291, 600, 658, 264, 764, 295, 3100, 38270, 82, 17330, 12973, 11, 293, 1854, 456, 311, 257, 1326, 5110], "temperature": 0.0, "avg_logprob": -0.23284410875897074, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.1842985259136185e-05}, {"id": 614, "seek": 324076, "start": 3253.88, "end": 3257.1200000000003, "text": " of the images.", "tokens": [295, 264, 5267, 13], "temperature": 0.0, "avg_logprob": -0.23284410875897074, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.1842985259136185e-05}, {"id": 615, "seek": 324076, "start": 3257.1200000000003, "end": 3270.0400000000004, "text": " So what I wanted to do was to create a dictionary where the key was the image ID, and the value", "tokens": [407, 437, 286, 1415, 281, 360, 390, 281, 1884, 257, 25890, 689, 264, 2141, 390, 264, 3256, 7348, 11, 293, 264, 2158], "temperature": 0.0, "avg_logprob": -0.23284410875897074, "compression_ratio": 1.4666666666666666, "no_speech_prob": 1.1842985259136185e-05}, {"id": 616, "seek": 327004, "start": 3270.04, "end": 3273.9, "text": " was a list of all of its annotations.", "tokens": [390, 257, 1329, 295, 439, 295, 1080, 25339, 763, 13], "temperature": 0.0, "avg_logprob": -0.12968105588640486, "compression_ratio": 1.5975609756097562, "no_speech_prob": 9.080385098059196e-06}, {"id": 617, "seek": 327004, "start": 3273.9, "end": 3283.04, "text": " So basically what I wanted to do was go through each of the annotations, that doesn't say", "tokens": [407, 1936, 437, 286, 1415, 281, 360, 390, 352, 807, 1184, 295, 264, 25339, 763, 11, 300, 1177, 380, 584], "temperature": 0.0, "avg_logprob": -0.12968105588640486, "compression_ratio": 1.5975609756097562, "no_speech_prob": 9.080385098059196e-06}, {"id": 618, "seek": 327004, "start": 3283.04, "end": 3292.68, "text": " to ignore it, and append it, the bounding box and the class, to the appropriate dictionary", "tokens": [281, 11200, 309, 11, 293, 34116, 309, 11, 264, 5472, 278, 2424, 293, 264, 1508, 11, 281, 264, 6854, 25890], "temperature": 0.0, "avg_logprob": -0.12968105588640486, "compression_ratio": 1.5975609756097562, "no_speech_prob": 9.080385098059196e-06}, {"id": 619, "seek": 327004, "start": 3292.68, "end": 3297.2799999999997, "text": " item, where that dictionary item is a list.", "tokens": [3174, 11, 689, 300, 25890, 3174, 307, 257, 1329, 13], "temperature": 0.0, "avg_logprob": -0.12968105588640486, "compression_ratio": 1.5975609756097562, "no_speech_prob": 9.080385098059196e-06}, {"id": 620, "seek": 329728, "start": 3297.28, "end": 3303.1200000000003, "text": " But the annoying thing is, of course, is that if that dictionary item doesn't exist yet,", "tokens": [583, 264, 11304, 551, 307, 11, 295, 1164, 11, 307, 300, 498, 300, 25890, 3174, 1177, 380, 2514, 1939, 11], "temperature": 0.0, "avg_logprob": -0.14536455362149986, "compression_ratio": 1.673728813559322, "no_speech_prob": 1.3925427992944606e-06}, {"id": 621, "seek": 329728, "start": 3303.1200000000003, "end": 3305.76, "text": " then there's no list to append to.", "tokens": [550, 456, 311, 572, 1329, 281, 34116, 281, 13], "temperature": 0.0, "avg_logprob": -0.14536455362149986, "compression_ratio": 1.673728813559322, "no_speech_prob": 1.3925427992944606e-06}, {"id": 622, "seek": 329728, "start": 3305.76, "end": 3313.36, "text": " So one super handy trick in Python is that there's a class called collections.defaultDict,", "tokens": [407, 472, 1687, 13239, 4282, 294, 15329, 307, 300, 456, 311, 257, 1508, 1219, 16641, 13, 20595, 5107, 35, 985, 11], "temperature": 0.0, "avg_logprob": -0.14536455362149986, "compression_ratio": 1.673728813559322, "no_speech_prob": 1.3925427992944606e-06}, {"id": 623, "seek": 329728, "start": 3313.36, "end": 3320.0400000000004, "text": " which is just like a dictionary, but if you try and access a key that doesn't exist, it", "tokens": [597, 307, 445, 411, 257, 25890, 11, 457, 498, 291, 853, 293, 2105, 257, 2141, 300, 1177, 380, 2514, 11, 309], "temperature": 0.0, "avg_logprob": -0.14536455362149986, "compression_ratio": 1.673728813559322, "no_speech_prob": 1.3925427992944606e-06}, {"id": 624, "seek": 329728, "start": 3320.0400000000004, "end": 3326.84, "text": " magically makes itself exist, and it sets itself equal to the return value of this function.", "tokens": [39763, 1669, 2564, 2514, 11, 293, 309, 6352, 2564, 2681, 281, 264, 2736, 2158, 295, 341, 2445, 13], "temperature": 0.0, "avg_logprob": -0.14536455362149986, "compression_ratio": 1.673728813559322, "no_speech_prob": 1.3925427992944606e-06}, {"id": 625, "seek": 332684, "start": 3326.84, "end": 3333.6400000000003, "text": " Now, this could be the name of some function that you've defined, or it can be a lambda", "tokens": [823, 11, 341, 727, 312, 264, 1315, 295, 512, 2445, 300, 291, 600, 7642, 11, 420, 309, 393, 312, 257, 13607], "temperature": 0.0, "avg_logprob": -0.14315981613962273, "compression_ratio": 1.8805309734513274, "no_speech_prob": 4.86043791170232e-06}, {"id": 626, "seek": 332684, "start": 3333.6400000000003, "end": 3334.6400000000003, "text": " function.", "tokens": [2445, 13], "temperature": 0.0, "avg_logprob": -0.14315981613962273, "compression_ratio": 1.8805309734513274, "no_speech_prob": 4.86043791170232e-06}, {"id": 627, "seek": 332684, "start": 3334.6400000000003, "end": 3339.7200000000003, "text": " A lambda function simply means it's a function that you define in place.", "tokens": [316, 13607, 2445, 2935, 1355, 309, 311, 257, 2445, 300, 291, 6964, 294, 1081, 13], "temperature": 0.0, "avg_logprob": -0.14315981613962273, "compression_ratio": 1.8805309734513274, "no_speech_prob": 4.86043791170232e-06}, {"id": 628, "seek": 332684, "start": 3339.7200000000003, "end": 3342.0, "text": " We'll be seeing lots of them.", "tokens": [492, 603, 312, 2577, 3195, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.14315981613962273, "compression_ratio": 1.8805309734513274, "no_speech_prob": 4.86043791170232e-06}, {"id": 629, "seek": 332684, "start": 3342.0, "end": 3345.28, "text": " So here's an example of a function.", "tokens": [407, 510, 311, 364, 1365, 295, 257, 2445, 13], "temperature": 0.0, "avg_logprob": -0.14315981613962273, "compression_ratio": 1.8805309734513274, "no_speech_prob": 4.86043791170232e-06}, {"id": 630, "seek": 332684, "start": 3345.28, "end": 3348.8, "text": " All the arguments to the function are listed on the left, so there's no arguments to the", "tokens": [1057, 264, 12869, 281, 264, 2445, 366, 10052, 322, 264, 1411, 11, 370, 456, 311, 572, 12869, 281, 264], "temperature": 0.0, "avg_logprob": -0.14315981613962273, "compression_ratio": 1.8805309734513274, "no_speech_prob": 4.86043791170232e-06}, {"id": 631, "seek": 332684, "start": 3348.8, "end": 3350.1200000000003, "text": " function.", "tokens": [2445, 13], "temperature": 0.0, "avg_logprob": -0.14315981613962273, "compression_ratio": 1.8805309734513274, "no_speech_prob": 4.86043791170232e-06}, {"id": 632, "seek": 332684, "start": 3350.1200000000003, "end": 3355.36, "text": " And lambda functions are special, you don't have to write return, as a return is assumed.", "tokens": [400, 13607, 6828, 366, 2121, 11, 291, 500, 380, 362, 281, 2464, 2736, 11, 382, 257, 2736, 307, 15895, 13], "temperature": 0.0, "avg_logprob": -0.14315981613962273, "compression_ratio": 1.8805309734513274, "no_speech_prob": 4.86043791170232e-06}, {"id": 633, "seek": 335536, "start": 3355.36, "end": 3359.2400000000002, "text": " So in this case, this is a lambda function that takes no arguments and returns an empty", "tokens": [407, 294, 341, 1389, 11, 341, 307, 257, 13607, 2445, 300, 2516, 572, 12869, 293, 11247, 364, 6707], "temperature": 0.0, "avg_logprob": -0.12629939488002231, "compression_ratio": 1.5406976744186047, "no_speech_prob": 1.9333544969413197e-06}, {"id": 634, "seek": 335536, "start": 3359.2400000000002, "end": 3360.42, "text": " list.", "tokens": [1329, 13], "temperature": 0.0, "avg_logprob": -0.12629939488002231, "compression_ratio": 1.5406976744186047, "no_speech_prob": 1.9333544969413197e-06}, {"id": 635, "seek": 335536, "start": 3360.42, "end": 3368.36, "text": " So in other words, every time I try and access something in train annotations that doesn't", "tokens": [407, 294, 661, 2283, 11, 633, 565, 286, 853, 293, 2105, 746, 294, 3847, 25339, 763, 300, 1177, 380], "temperature": 0.0, "avg_logprob": -0.12629939488002231, "compression_ratio": 1.5406976744186047, "no_speech_prob": 1.9333544969413197e-06}, {"id": 636, "seek": 335536, "start": 3368.36, "end": 3378.26, "text": " exist, it now does exist and it's an empty list, which means I can append to it.", "tokens": [2514, 11, 309, 586, 775, 2514, 293, 309, 311, 364, 6707, 1329, 11, 597, 1355, 286, 393, 34116, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.12629939488002231, "compression_ratio": 1.5406976744186047, "no_speech_prob": 1.9333544969413197e-06}, {"id": 637, "seek": 337826, "start": 3378.26, "end": 3388.82, "text": " One comment on variable naming is, when I read through these notebooks, I'll generally", "tokens": [1485, 2871, 322, 7006, 25290, 307, 11, 562, 286, 1401, 807, 613, 43782, 11, 286, 603, 5101], "temperature": 0.0, "avg_logprob": -0.1339348309660611, "compression_ratio": 1.553191489361702, "no_speech_prob": 3.500845195958391e-06}, {"id": 638, "seek": 337826, "start": 3388.82, "end": 3395.2000000000003, "text": " try and speak out the English words that the variable name is a mnemonic for.", "tokens": [853, 293, 1710, 484, 264, 3669, 2283, 300, 264, 7006, 1315, 307, 257, 275, 25989, 11630, 337, 13], "temperature": 0.0, "avg_logprob": -0.1339348309660611, "compression_ratio": 1.553191489361702, "no_speech_prob": 3.500845195958391e-06}, {"id": 639, "seek": 337826, "start": 3395.2000000000003, "end": 3401.0200000000004, "text": " A reasonable question would be, why didn't I write the full name of the variable in English", "tokens": [316, 10585, 1168, 576, 312, 11, 983, 994, 380, 286, 2464, 264, 1577, 1315, 295, 264, 7006, 294, 3669], "temperature": 0.0, "avg_logprob": -0.1339348309660611, "compression_ratio": 1.553191489361702, "no_speech_prob": 3.500845195958391e-06}, {"id": 640, "seek": 337826, "start": 3401.0200000000004, "end": 3404.84, "text": " rather than using a short mnemonic.", "tokens": [2831, 813, 1228, 257, 2099, 275, 25989, 11630, 13], "temperature": 0.0, "avg_logprob": -0.1339348309660611, "compression_ratio": 1.553191489361702, "no_speech_prob": 3.500845195958391e-06}, {"id": 641, "seek": 340484, "start": 3404.84, "end": 3411.32, "text": " It's a personal preference I have based on a number of programming communities where", "tokens": [467, 311, 257, 2973, 17502, 286, 362, 2361, 322, 257, 1230, 295, 9410, 4456, 689], "temperature": 0.0, "avg_logprob": -0.13292055020387145, "compression_ratio": 1.662037037037037, "no_speech_prob": 1.9525296011124738e-05}, {"id": 642, "seek": 340484, "start": 3411.32, "end": 3419.32, "text": " the basic kind of thesis is that the more that you can see in a single kind of eye grab", "tokens": [264, 3875, 733, 295, 22288, 307, 300, 264, 544, 300, 291, 393, 536, 294, 257, 2167, 733, 295, 3313, 4444], "temperature": 0.0, "avg_logprob": -0.13292055020387145, "compression_ratio": 1.662037037037037, "no_speech_prob": 1.9525296011124738e-05}, {"id": 643, "seek": 340484, "start": 3419.32, "end": 3425.08, "text": " of the screen, the more you can understand intuitively at one go.", "tokens": [295, 264, 2568, 11, 264, 544, 291, 393, 1223, 46506, 412, 472, 352, 13], "temperature": 0.0, "avg_logprob": -0.13292055020387145, "compression_ratio": 1.662037037037037, "no_speech_prob": 1.9525296011124738e-05}, {"id": 644, "seek": 340484, "start": 3425.08, "end": 3429.7200000000003, "text": " Every time you have to, your eye has to jump around, it's kind of like a context change", "tokens": [2048, 565, 291, 362, 281, 11, 428, 3313, 575, 281, 3012, 926, 11, 309, 311, 733, 295, 411, 257, 4319, 1319], "temperature": 0.0, "avg_logprob": -0.13292055020387145, "compression_ratio": 1.662037037037037, "no_speech_prob": 1.9525296011124738e-05}, {"id": 645, "seek": 340484, "start": 3429.7200000000003, "end": 3432.52, "text": " that reduces your understanding.", "tokens": [300, 18081, 428, 3701, 13], "temperature": 0.0, "avg_logprob": -0.13292055020387145, "compression_ratio": 1.662037037037037, "no_speech_prob": 1.9525296011124738e-05}, {"id": 646, "seek": 343252, "start": 3432.52, "end": 3437.84, "text": " It's a style of programming I found super helpful, and so generally speaking, I try", "tokens": [467, 311, 257, 3758, 295, 9410, 286, 1352, 1687, 4961, 11, 293, 370, 5101, 4124, 11, 286, 853], "temperature": 0.0, "avg_logprob": -0.18614841431610343, "compression_ratio": 1.829090909090909, "no_speech_prob": 1.1300729966023937e-05}, {"id": 647, "seek": 343252, "start": 3437.84, "end": 3443.44, "text": " to, I particularly try to reduce the vertical height so things don't scroll off the screen,", "tokens": [281, 11, 286, 4098, 853, 281, 5407, 264, 9429, 6681, 370, 721, 500, 380, 11369, 766, 264, 2568, 11], "temperature": 0.0, "avg_logprob": -0.18614841431610343, "compression_ratio": 1.829090909090909, "no_speech_prob": 1.1300729966023937e-05}, {"id": 648, "seek": 343252, "start": 3443.44, "end": 3449.88, "text": " but I also try to reduce the size of things so that there's a mnemonic there, which if", "tokens": [457, 286, 611, 853, 281, 5407, 264, 2744, 295, 721, 370, 300, 456, 311, 257, 275, 25989, 11630, 456, 11, 597, 498], "temperature": 0.0, "avg_logprob": -0.18614841431610343, "compression_ratio": 1.829090909090909, "no_speech_prob": 1.1300729966023937e-05}, {"id": 649, "seek": 343252, "start": 3449.88, "end": 3455.36, "text": " you know it's training annotations, it doesn't take long for you to see training annotations,", "tokens": [291, 458, 309, 311, 3097, 25339, 763, 11, 309, 1177, 380, 747, 938, 337, 291, 281, 536, 3097, 25339, 763, 11], "temperature": 0.0, "avg_logprob": -0.18614841431610343, "compression_ratio": 1.829090909090909, "no_speech_prob": 1.1300729966023937e-05}, {"id": 650, "seek": 343252, "start": 3455.36, "end": 3458.12, "text": " but you don't have to write the whole thing out.", "tokens": [457, 291, 500, 380, 362, 281, 2464, 264, 1379, 551, 484, 13], "temperature": 0.0, "avg_logprob": -0.18614841431610343, "compression_ratio": 1.829090909090909, "no_speech_prob": 1.1300729966023937e-05}, {"id": 651, "seek": 343252, "start": 3458.12, "end": 3462.5, "text": " So I'm not saying you have to do it this way, I'm just saying there's some very large programming", "tokens": [407, 286, 478, 406, 1566, 291, 362, 281, 360, 309, 341, 636, 11, 286, 478, 445, 1566, 456, 311, 512, 588, 2416, 9410], "temperature": 0.0, "avg_logprob": -0.18614841431610343, "compression_ratio": 1.829090909090909, "no_speech_prob": 1.1300729966023937e-05}, {"id": 652, "seek": 346250, "start": 3462.5, "end": 3467.2, "text": " communities, some of which have been around for 50 or 60 years, which have used this approach,", "tokens": [4456, 11, 512, 295, 597, 362, 668, 926, 337, 2625, 420, 4060, 924, 11, 597, 362, 1143, 341, 3109, 11], "temperature": 0.0, "avg_logprob": -0.18131287126656037, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.9222788978368044e-05}, {"id": 653, "seek": 346250, "start": 3467.2, "end": 3471.38, "text": " and I find it works well.", "tokens": [293, 286, 915, 309, 1985, 731, 13], "temperature": 0.0, "avg_logprob": -0.18131287126656037, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.9222788978368044e-05}, {"id": 654, "seek": 346250, "start": 3471.38, "end": 3481.36, "text": " It's interesting to compare, I guess my philosophy is somewhere between math and Java.", "tokens": [467, 311, 1880, 281, 6794, 11, 286, 2041, 452, 10675, 307, 4079, 1296, 5221, 293, 10745, 13], "temperature": 0.0, "avg_logprob": -0.18131287126656037, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.9222788978368044e-05}, {"id": 655, "seek": 346250, "start": 3481.36, "end": 3485.28, "text": " In math, everything's a single character.", "tokens": [682, 5221, 11, 1203, 311, 257, 2167, 2517, 13], "temperature": 0.0, "avg_logprob": -0.18131287126656037, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.9222788978368044e-05}, {"id": 656, "seek": 346250, "start": 3485.28, "end": 3490.52, "text": " The same single character can be used in the same paper for 5 different things, and depending", "tokens": [440, 912, 2167, 2517, 393, 312, 1143, 294, 264, 912, 3035, 337, 1025, 819, 721, 11, 293, 5413], "temperature": 0.0, "avg_logprob": -0.18131287126656037, "compression_ratio": 1.573394495412844, "no_speech_prob": 1.9222788978368044e-05}, {"id": 657, "seek": 349052, "start": 3490.52, "end": 3496.44, "text": " on whether it's in italics or boldface capitals, it's another 5 different things.", "tokens": [322, 1968, 309, 311, 294, 22366, 1167, 420, 11928, 2868, 1410, 11118, 11, 309, 311, 1071, 1025, 819, 721, 13], "temperature": 0.0, "avg_logprob": -0.12766215967577557, "compression_ratio": 1.5853658536585367, "no_speech_prob": 6.144065082480665e-06}, {"id": 658, "seek": 349052, "start": 3496.44, "end": 3499.12, "text": " I find that less than ideal.", "tokens": [286, 915, 300, 1570, 813, 7157, 13], "temperature": 0.0, "avg_logprob": -0.12766215967577557, "compression_ratio": 1.5853658536585367, "no_speech_prob": 6.144065082480665e-06}, {"id": 659, "seek": 349052, "start": 3499.12, "end": 3504.7599999999998, "text": " In Java, you know, variable names sometimes require a few pages to print out, and I find", "tokens": [682, 10745, 11, 291, 458, 11, 7006, 5288, 2171, 3651, 257, 1326, 7183, 281, 4482, 484, 11, 293, 286, 915], "temperature": 0.0, "avg_logprob": -0.12766215967577557, "compression_ratio": 1.5853658536585367, "no_speech_prob": 6.144065082480665e-06}, {"id": 660, "seek": 349052, "start": 3504.7599999999998, "end": 3506.56, "text": " that less than ideal as well.", "tokens": [300, 1570, 813, 7157, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.12766215967577557, "compression_ratio": 1.5853658536585367, "no_speech_prob": 6.144065082480665e-06}, {"id": 661, "seek": 349052, "start": 3506.56, "end": 3517.6, "text": " So for me, I personally like names which are short enough to not take too much of my perception", "tokens": [407, 337, 385, 11, 286, 5665, 411, 5288, 597, 366, 2099, 1547, 281, 406, 747, 886, 709, 295, 452, 12860], "temperature": 0.0, "avg_logprob": -0.12766215967577557, "compression_ratio": 1.5853658536585367, "no_speech_prob": 6.144065082480665e-06}, {"id": 662, "seek": 351760, "start": 3517.6, "end": 3522.8399999999997, "text": " to see at once, but long enough to have a mnemonic.", "tokens": [281, 536, 412, 1564, 11, 457, 938, 1547, 281, 362, 257, 275, 25989, 11630, 13], "temperature": 0.0, "avg_logprob": -0.17357200384140015, "compression_ratio": 1.5128205128205128, "no_speech_prob": 6.643373126280494e-06}, {"id": 663, "seek": 351760, "start": 3522.8399999999997, "end": 3529.7999999999997, "text": " Also, however, a lot of the time, the variable will be describing a mathematical object as", "tokens": [2743, 11, 4461, 11, 257, 688, 295, 264, 565, 11, 264, 7006, 486, 312, 16141, 257, 18894, 2657, 382], "temperature": 0.0, "avg_logprob": -0.17357200384140015, "compression_ratio": 1.5128205128205128, "no_speech_prob": 6.643373126280494e-06}, {"id": 664, "seek": 351760, "start": 3529.7999999999997, "end": 3534.62, "text": " it exists in a paper, and there isn't really an English name for it, and so in those cases", "tokens": [309, 8198, 294, 257, 3035, 11, 293, 456, 1943, 380, 534, 364, 3669, 1315, 337, 309, 11, 293, 370, 294, 729, 3331], "temperature": 0.0, "avg_logprob": -0.17357200384140015, "compression_ratio": 1.5128205128205128, "no_speech_prob": 6.643373126280494e-06}, {"id": 665, "seek": 351760, "start": 3534.62, "end": 3540.12, "text": " I will use the same, often single letter that the paper uses.", "tokens": [286, 486, 764, 264, 912, 11, 2049, 2167, 5063, 300, 264, 3035, 4960, 13], "temperature": 0.0, "avg_logprob": -0.17357200384140015, "compression_ratio": 1.5128205128205128, "no_speech_prob": 6.643373126280494e-06}, {"id": 666, "seek": 354012, "start": 3540.12, "end": 3547.58, "text": " And so if you see something called delta or A or something, and it's like something inside", "tokens": [400, 370, 498, 291, 536, 746, 1219, 8289, 420, 316, 420, 746, 11, 293, 309, 311, 411, 746, 1854], "temperature": 0.0, "avg_logprob": -0.1562494123824919, "compression_ratio": 1.663716814159292, "no_speech_prob": 1.9222783521399833e-05}, {"id": 667, "seek": 354012, "start": 3547.58, "end": 3557.24, "text": " an equation from a paper, I generally try to use the same thing.", "tokens": [364, 5367, 490, 257, 3035, 11, 286, 5101, 853, 281, 764, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.1562494123824919, "compression_ratio": 1.663716814159292, "no_speech_prob": 1.9222783521399833e-05}, {"id": 668, "seek": 354012, "start": 3557.24, "end": 3558.96, "text": " By no means do you have to do the same thing.", "tokens": [3146, 572, 1355, 360, 291, 362, 281, 360, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.1562494123824919, "compression_ratio": 1.663716814159292, "no_speech_prob": 1.9222783521399833e-05}, {"id": 669, "seek": 354012, "start": 3558.96, "end": 3564.52, "text": " I will say, however, if you contribute to Fast.ai, I'm not particularly fastidious about", "tokens": [286, 486, 584, 11, 4461, 11, 498, 291, 10586, 281, 15968, 13, 1301, 11, 286, 478, 406, 4098, 2370, 327, 851, 466], "temperature": 0.0, "avg_logprob": -0.1562494123824919, "compression_ratio": 1.663716814159292, "no_speech_prob": 1.9222783521399833e-05}, {"id": 670, "seek": 354012, "start": 3564.52, "end": 3569.3599999999997, "text": " coding style or whatever, but if you write things more like the way I do than the way", "tokens": [17720, 3758, 420, 2035, 11, 457, 498, 291, 2464, 721, 544, 411, 264, 636, 286, 360, 813, 264, 636], "temperature": 0.0, "avg_logprob": -0.1562494123824919, "compression_ratio": 1.663716814159292, "no_speech_prob": 1.9222783521399833e-05}, {"id": 671, "seek": 356936, "start": 3569.36, "end": 3574.96, "text": " Java people do, I'll certainly appreciate it.", "tokens": [10745, 561, 360, 11, 286, 603, 3297, 4449, 309, 13], "temperature": 0.0, "avg_logprob": -0.1555649975696242, "compression_ratio": 1.5233160621761659, "no_speech_prob": 1.7778163964976557e-05}, {"id": 672, "seek": 356936, "start": 3574.96, "end": 3581.96, "text": " So by the end of this, we now have a dictionary from file names to a tuple, and so here's", "tokens": [407, 538, 264, 917, 295, 341, 11, 321, 586, 362, 257, 25890, 490, 3991, 5288, 281, 257, 2604, 781, 11, 293, 370, 510, 311], "temperature": 0.0, "avg_logprob": -0.1555649975696242, "compression_ratio": 1.5233160621761659, "no_speech_prob": 1.7778163964976557e-05}, {"id": 673, "seek": 356936, "start": 3581.96, "end": 3593.76, "text": " an example of looking up that dictionary, and we get back a bounding box and a class.", "tokens": [364, 1365, 295, 1237, 493, 300, 25890, 11, 293, 321, 483, 646, 257, 5472, 278, 2424, 293, 257, 1508, 13], "temperature": 0.0, "avg_logprob": -0.1555649975696242, "compression_ratio": 1.5233160621761659, "no_speech_prob": 1.7778163964976557e-05}, {"id": 674, "seek": 356936, "start": 3593.76, "end": 3597.52, "text": " You'll see when I create the bounding box, I've done a couple of things.", "tokens": [509, 603, 536, 562, 286, 1884, 264, 5472, 278, 2424, 11, 286, 600, 1096, 257, 1916, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.1555649975696242, "compression_ratio": 1.5233160621761659, "no_speech_prob": 1.7778163964976557e-05}, {"id": 675, "seek": 359752, "start": 3597.52, "end": 3601.2, "text": " The first is I've switched the x and y coordinates.", "tokens": [440, 700, 307, 286, 600, 16858, 264, 2031, 293, 288, 21056, 13], "temperature": 0.0, "avg_logprob": -0.21150138530325382, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.046249937848188e-05}, {"id": 676, "seek": 359752, "start": 3601.2, "end": 3604.7599999999998, "text": " The reason for this, I think we mentioned this briefly in the last course, the kind", "tokens": [440, 1778, 337, 341, 11, 286, 519, 321, 2835, 341, 10515, 294, 264, 1036, 1164, 11, 264, 733], "temperature": 0.0, "avg_logprob": -0.21150138530325382, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.046249937848188e-05}, {"id": 677, "seek": 359752, "start": 3604.7599999999998, "end": 3613.96, "text": " of computer vision world, when you say like my screen is 640x480, that's width by height,", "tokens": [295, 3820, 5201, 1002, 11, 562, 291, 584, 411, 452, 2568, 307, 1386, 5254, 87, 19, 4702, 11, 300, 311, 11402, 538, 6681, 11], "temperature": 0.0, "avg_logprob": -0.21150138530325382, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.046249937848188e-05}, {"id": 678, "seek": 359752, "start": 3613.96, "end": 3620.72, "text": " whereas the math world, when you say my array is 640x480, it's rows by columns, ie height", "tokens": [9735, 264, 5221, 1002, 11, 562, 291, 584, 452, 10225, 307, 1386, 5254, 87, 19, 4702, 11, 309, 311, 13241, 538, 13766, 11, 43203, 6681], "temperature": 0.0, "avg_logprob": -0.21150138530325382, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.046249937848188e-05}, {"id": 679, "seek": 359752, "start": 3620.72, "end": 3621.7599999999998, "text": " by width.", "tokens": [538, 11402, 13], "temperature": 0.0, "avg_logprob": -0.21150138530325382, "compression_ratio": 1.5776699029126213, "no_speech_prob": 2.046249937848188e-05}, {"id": 680, "seek": 362176, "start": 3621.76, "end": 3628.7200000000003, "text": " So you'll see that a lot of things like PIL, or Pillow Image Library, and Python tend to", "tokens": [407, 291, 603, 536, 300, 257, 688, 295, 721, 411, 430, 4620, 11, 420, 44656, 305, 29903, 12806, 11, 293, 15329, 3928, 281], "temperature": 0.0, "avg_logprob": -0.23256088438488187, "compression_ratio": 1.4540816326530612, "no_speech_prob": 4.565945801005e-06}, {"id": 681, "seek": 362176, "start": 3628.7200000000003, "end": 3634.76, "text": " do things in this kind of width by height, or columns by rows way, NumPy is the opposite", "tokens": [360, 721, 294, 341, 733, 295, 11402, 538, 6681, 11, 420, 13766, 538, 13241, 636, 11, 22592, 47, 88, 307, 264, 6182], "temperature": 0.0, "avg_logprob": -0.23256088438488187, "compression_ratio": 1.4540816326530612, "no_speech_prob": 4.565945801005e-06}, {"id": 682, "seek": 362176, "start": 3634.76, "end": 3635.76, "text": " way around.", "tokens": [636, 926, 13], "temperature": 0.0, "avg_logprob": -0.23256088438488187, "compression_ratio": 1.4540816326530612, "no_speech_prob": 4.565945801005e-06}, {"id": 683, "seek": 362176, "start": 3635.76, "end": 3644.1200000000003, "text": " So again, my view is, don't put up with this kind of incredibly annoying inconsistency,", "tokens": [407, 797, 11, 452, 1910, 307, 11, 500, 380, 829, 493, 365, 341, 733, 295, 6252, 11304, 22039, 468, 3020, 11], "temperature": 0.0, "avg_logprob": -0.23256088438488187, "compression_ratio": 1.4540816326530612, "no_speech_prob": 4.565945801005e-06}, {"id": 684, "seek": 362176, "start": 3644.1200000000003, "end": 3645.6800000000003, "text": " fix it.", "tokens": [3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.23256088438488187, "compression_ratio": 1.4540816326530612, "no_speech_prob": 4.565945801005e-06}, {"id": 685, "seek": 364568, "start": 3645.68, "end": 3654.2799999999997, "text": " So I've decided, fastai is the NumPy pie torch way, is the right way, so I'm always rows", "tokens": [407, 286, 600, 3047, 11, 2370, 1301, 307, 264, 22592, 47, 88, 1730, 27822, 636, 11, 307, 264, 558, 636, 11, 370, 286, 478, 1009, 13241], "temperature": 0.0, "avg_logprob": -0.23661365111668906, "compression_ratio": 1.645631067961165, "no_speech_prob": 2.156811660825042e-06}, {"id": 686, "seek": 364568, "start": 3654.2799999999997, "end": 3655.9199999999996, "text": " by columns.", "tokens": [538, 13766, 13], "temperature": 0.0, "avg_logprob": -0.23661365111668906, "compression_ratio": 1.645631067961165, "no_speech_prob": 2.156811660825042e-06}, {"id": 687, "seek": 364568, "start": 3655.9199999999996, "end": 3660.6, "text": " So you'll see here I've switched my rows of columns.", "tokens": [407, 291, 603, 536, 510, 286, 600, 16858, 452, 13241, 295, 13766, 13], "temperature": 0.0, "avg_logprob": -0.23661365111668906, "compression_ratio": 1.645631067961165, "no_speech_prob": 2.156811660825042e-06}, {"id": 688, "seek": 364568, "start": 3660.6, "end": 3668.2, "text": " I've also decided that we're going to do things by describing the top left xy coordinate and", "tokens": [286, 600, 611, 3047, 300, 321, 434, 516, 281, 360, 721, 538, 16141, 264, 1192, 1411, 2031, 88, 15670, 293], "temperature": 0.0, "avg_logprob": -0.23661365111668906, "compression_ratio": 1.645631067961165, "no_speech_prob": 2.156811660825042e-06}, {"id": 689, "seek": 364568, "start": 3668.2, "end": 3675.08, "text": " the bottom right xy coordinate with a bounding box, rather than the xy and the height width.", "tokens": [264, 2767, 558, 2031, 88, 15670, 365, 257, 5472, 278, 2424, 11, 2831, 813, 264, 2031, 88, 293, 264, 6681, 11402, 13], "temperature": 0.0, "avg_logprob": -0.23661365111668906, "compression_ratio": 1.645631067961165, "no_speech_prob": 2.156811660825042e-06}, {"id": 690, "seek": 367508, "start": 3675.08, "end": 3684.36, "text": " So you'll see here I'm just converting the height and width to the top left and bottom", "tokens": [407, 291, 603, 536, 510, 286, 478, 445, 29942, 264, 6681, 293, 11402, 281, 264, 1192, 1411, 293, 2767], "temperature": 0.0, "avg_logprob": -0.20431745170366647, "compression_ratio": 1.6, "no_speech_prob": 3.1692656193627045e-05}, {"id": 691, "seek": 367508, "start": 3684.36, "end": 3685.6, "text": " right.", "tokens": [558, 13], "temperature": 0.0, "avg_logprob": -0.20431745170366647, "compression_ratio": 1.6, "no_speech_prob": 3.1692656193627045e-05}, {"id": 692, "seek": 367508, "start": 3685.6, "end": 3691.4, "text": " So again, I often find dealing with junior programmers, in particular junior data scientists,", "tokens": [407, 797, 11, 286, 2049, 915, 6260, 365, 16195, 41504, 11, 294, 1729, 16195, 1412, 7708, 11], "temperature": 0.0, "avg_logprob": -0.20431745170366647, "compression_ratio": 1.6, "no_speech_prob": 3.1692656193627045e-05}, {"id": 693, "seek": 367508, "start": 3691.4, "end": 3696.6, "text": " that they kind of get given data sets that are in shitty formats, or crappy APIs, and", "tokens": [300, 436, 733, 295, 483, 2212, 1412, 6352, 300, 366, 294, 30748, 25879, 11, 420, 36531, 21445, 11, 293], "temperature": 0.0, "avg_logprob": -0.20431745170366647, "compression_ratio": 1.6, "no_speech_prob": 3.1692656193627045e-05}, {"id": 694, "seek": 367508, "start": 3696.6, "end": 3700.2, "text": " they just act as if everything has to be that way.", "tokens": [436, 445, 605, 382, 498, 1203, 575, 281, 312, 300, 636, 13], "temperature": 0.0, "avg_logprob": -0.20431745170366647, "compression_ratio": 1.6, "no_speech_prob": 3.1692656193627045e-05}, {"id": 695, "seek": 367508, "start": 3700.2, "end": 3704.92, "text": " But your life will be much easier if you take a couple of moments to make things consistent", "tokens": [583, 428, 993, 486, 312, 709, 3571, 498, 291, 747, 257, 1916, 295, 6065, 281, 652, 721, 8398], "temperature": 0.0, "avg_logprob": -0.20431745170366647, "compression_ratio": 1.6, "no_speech_prob": 3.1692656193627045e-05}, {"id": 696, "seek": 370492, "start": 3704.92, "end": 3711.32, "text": " and make them the way you want them to be.", "tokens": [293, 652, 552, 264, 636, 291, 528, 552, 281, 312, 13], "temperature": 0.0, "avg_logprob": -0.21725407650596218, "compression_ratio": 1.5598086124401913, "no_speech_prob": 5.338128630683059e-06}, {"id": 697, "seek": 370492, "start": 3711.32, "end": 3717.7200000000003, "text": " So earlier on I took all of our classes and created a categories list.", "tokens": [407, 3071, 322, 286, 1890, 439, 295, 527, 5359, 293, 2942, 257, 10479, 1329, 13], "temperature": 0.0, "avg_logprob": -0.21725407650596218, "compression_ratio": 1.5598086124401913, "no_speech_prob": 5.338128630683059e-06}, {"id": 698, "seek": 370492, "start": 3717.7200000000003, "end": 3724.96, "text": " And so if we look up category number 7, which is what this is, category number 7 is a car.", "tokens": [400, 370, 498, 321, 574, 493, 7719, 1230, 1614, 11, 597, 307, 437, 341, 307, 11, 7719, 1230, 1614, 307, 257, 1032, 13], "temperature": 0.0, "avg_logprob": -0.21725407650596218, "compression_ratio": 1.5598086124401913, "no_speech_prob": 5.338128630683059e-06}, {"id": 699, "seek": 370492, "start": 3724.96, "end": 3726.6, "text": " Let's have a look at another example.", "tokens": [961, 311, 362, 257, 574, 412, 1071, 1365, 13], "temperature": 0.0, "avg_logprob": -0.21725407650596218, "compression_ratio": 1.5598086124401913, "no_speech_prob": 5.338128630683059e-06}, {"id": 700, "seek": 370492, "start": 3726.6, "end": 3731.64, "text": " Image number 17 has 2 bounding boxes.", "tokens": [29903, 1230, 3282, 575, 568, 5472, 278, 9002, 13], "temperature": 0.0, "avg_logprob": -0.21725407650596218, "compression_ratio": 1.5598086124401913, "no_speech_prob": 5.338128630683059e-06}, {"id": 701, "seek": 370492, "start": 3731.64, "end": 3734.32, "text": " One of them is of type 15, one is of type 13.", "tokens": [1485, 295, 552, 307, 295, 2010, 2119, 11, 472, 307, 295, 2010, 3705, 13], "temperature": 0.0, "avg_logprob": -0.21725407650596218, "compression_ratio": 1.5598086124401913, "no_speech_prob": 5.338128630683059e-06}, {"id": 702, "seek": 373432, "start": 3734.32, "end": 3736.7200000000003, "text": " That is a person and a horse.", "tokens": [663, 307, 257, 954, 293, 257, 6832, 13], "temperature": 0.0, "avg_logprob": -0.09406821544353779, "compression_ratio": 1.6974789915966386, "no_speech_prob": 2.1444791855174117e-05}, {"id": 703, "seek": 373432, "start": 3736.7200000000003, "end": 3741.2000000000003, "text": " So this would be much easier to understand if we can see a picture of these things.", "tokens": [407, 341, 576, 312, 709, 3571, 281, 1223, 498, 321, 393, 536, 257, 3036, 295, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.09406821544353779, "compression_ratio": 1.6974789915966386, "no_speech_prob": 2.1444791855174117e-05}, {"id": 704, "seek": 373432, "start": 3741.2000000000003, "end": 3743.76, "text": " So let's create some pictures.", "tokens": [407, 718, 311, 1884, 512, 5242, 13], "temperature": 0.0, "avg_logprob": -0.09406821544353779, "compression_ratio": 1.6974789915966386, "no_speech_prob": 2.1444791855174117e-05}, {"id": 705, "seek": 373432, "start": 3743.76, "end": 3752.28, "text": " So having just turned our height, width stuff into top left, bottom right stuff, we're now", "tokens": [407, 1419, 445, 3574, 527, 6681, 11, 11402, 1507, 666, 1192, 1411, 11, 2767, 558, 1507, 11, 321, 434, 586], "temperature": 0.0, "avg_logprob": -0.09406821544353779, "compression_ratio": 1.6974789915966386, "no_speech_prob": 2.1444791855174117e-05}, {"id": 706, "seek": 373432, "start": 3752.28, "end": 3759.0, "text": " going to create a method to do the exact opposite, because any time I want to call some library", "tokens": [516, 281, 1884, 257, 3170, 281, 360, 264, 1900, 6182, 11, 570, 604, 565, 286, 528, 281, 818, 512, 6405], "temperature": 0.0, "avg_logprob": -0.09406821544353779, "compression_ratio": 1.6974789915966386, "no_speech_prob": 2.1444791855174117e-05}, {"id": 707, "seek": 373432, "start": 3759.0, "end": 3762.38, "text": " that expects the opposite, I'm going to need to pass it in the opposite.", "tokens": [300, 33280, 264, 6182, 11, 286, 478, 516, 281, 643, 281, 1320, 309, 294, 264, 6182, 13], "temperature": 0.0, "avg_logprob": -0.09406821544353779, "compression_ratio": 1.6974789915966386, "no_speech_prob": 2.1444791855174117e-05}, {"id": 708, "seek": 376238, "start": 3762.38, "end": 3768.2000000000003, "text": " So here is something that converts a bounding box to a height and width, bbhw, bounding", "tokens": [407, 510, 307, 746, 300, 38874, 257, 5472, 278, 2424, 281, 257, 6681, 293, 11402, 11, 272, 65, 71, 86, 11, 5472, 278], "temperature": 0.0, "avg_logprob": -0.1746732411759623, "compression_ratio": 1.7941176470588236, "no_speech_prob": 3.089485062446329e-06}, {"id": 709, "seek": 376238, "start": 3768.2000000000003, "end": 3770.7000000000003, "text": " box to height and width.", "tokens": [2424, 281, 6681, 293, 11402, 13], "temperature": 0.0, "avg_logprob": -0.1746732411759623, "compression_ratio": 1.7941176470588236, "no_speech_prob": 3.089485062446329e-06}, {"id": 710, "seek": 376238, "start": 3770.7000000000003, "end": 3778.48, "text": " So it's again reversing the order and giving us the height and width.", "tokens": [407, 309, 311, 797, 14582, 278, 264, 1668, 293, 2902, 505, 264, 6681, 293, 11402, 13], "temperature": 0.0, "avg_logprob": -0.1746732411759623, "compression_ratio": 1.7941176470588236, "no_speech_prob": 3.089485062446329e-06}, {"id": 711, "seek": 376238, "start": 3778.48, "end": 3786.98, "text": " So we can now open an image in order to display it.", "tokens": [407, 321, 393, 586, 1269, 364, 3256, 294, 1668, 281, 4674, 309, 13], "temperature": 0.0, "avg_logprob": -0.1746732411759623, "compression_ratio": 1.7941176470588236, "no_speech_prob": 3.089485062446329e-06}, {"id": 712, "seek": 376238, "start": 3786.98, "end": 3791.42, "text": " And where we're going to get to is we're going to get it to show this.", "tokens": [400, 689, 321, 434, 516, 281, 483, 281, 307, 321, 434, 516, 281, 483, 309, 281, 855, 341, 13], "temperature": 0.0, "avg_logprob": -0.1746732411759623, "compression_ratio": 1.7941176470588236, "no_speech_prob": 3.089485062446329e-06}, {"id": 713, "seek": 379142, "start": 3791.42, "end": 3794.36, "text": " That's that car.", "tokens": [663, 311, 300, 1032, 13], "temperature": 0.0, "avg_logprob": -0.24688402244022914, "compression_ratio": 1.5884773662551441, "no_speech_prob": 8.801041076367255e-06}, {"id": 714, "seek": 379142, "start": 3794.36, "end": 3801.2400000000002, "text": " So one thing that I often get asked on the forums or through github is like, well, how", "tokens": [407, 472, 551, 300, 286, 2049, 483, 2351, 322, 264, 26998, 420, 807, 290, 355, 836, 307, 411, 11, 731, 11, 577], "temperature": 0.0, "avg_logprob": -0.24688402244022914, "compression_ratio": 1.5884773662551441, "no_speech_prob": 8.801041076367255e-06}, {"id": 715, "seek": 379142, "start": 3801.2400000000002, "end": 3805.04, "text": " did I find out about this open image thing?", "tokens": [630, 286, 915, 484, 466, 341, 1269, 3256, 551, 30], "temperature": 0.0, "avg_logprob": -0.24688402244022914, "compression_ratio": 1.5884773662551441, "no_speech_prob": 8.801041076367255e-06}, {"id": 716, "seek": 379142, "start": 3805.04, "end": 3806.04, "text": " Where did it come from?", "tokens": [2305, 630, 309, 808, 490, 30], "temperature": 0.0, "avg_logprob": -0.24688402244022914, "compression_ratio": 1.5884773662551441, "no_speech_prob": 8.801041076367255e-06}, {"id": 717, "seek": 379142, "start": 3806.04, "end": 3807.8, "text": " What does it mean?", "tokens": [708, 775, 309, 914, 30], "temperature": 0.0, "avg_logprob": -0.24688402244022914, "compression_ratio": 1.5884773662551441, "no_speech_prob": 8.801041076367255e-06}, {"id": 718, "seek": 379142, "start": 3807.8, "end": 3810.52, "text": " Who uses it?", "tokens": [2102, 4960, 309, 30], "temperature": 0.0, "avg_logprob": -0.24688402244022914, "compression_ratio": 1.5884773662551441, "no_speech_prob": 8.801041076367255e-06}, {"id": 719, "seek": 379142, "start": 3810.52, "end": 3813.76, "text": " And so I wanted to just take a moment, because one of the things we're going to be doing", "tokens": [400, 370, 286, 1415, 281, 445, 747, 257, 1623, 11, 570, 472, 295, 264, 721, 321, 434, 516, 281, 312, 884], "temperature": 0.0, "avg_logprob": -0.24688402244022914, "compression_ratio": 1.5884773662551441, "no_speech_prob": 8.801041076367255e-06}, {"id": 720, "seek": 379142, "start": 3813.76, "end": 3819.6, "text": " a lot, and I know a lot of you aren't professional coders, you have backgrounds in statistics", "tokens": [257, 688, 11, 293, 286, 458, 257, 688, 295, 291, 3212, 380, 4843, 17656, 433, 11, 291, 362, 17336, 294, 12523], "temperature": 0.0, "avg_logprob": -0.24688402244022914, "compression_ratio": 1.5884773662551441, "no_speech_prob": 8.801041076367255e-06}, {"id": 721, "seek": 381960, "start": 3819.6, "end": 3824.68, "text": " or you know, meteorology or physics or whatever, and I apologize for those of you that are", "tokens": [420, 291, 458, 11, 25313, 1793, 420, 10649, 420, 2035, 11, 293, 286, 12328, 337, 729, 295, 291, 300, 366], "temperature": 0.0, "avg_logprob": -0.16759545924299854, "compression_ratio": 1.7660377358490567, "no_speech_prob": 9.22333219932625e-06}, {"id": 722, "seek": 381960, "start": 3824.68, "end": 3828.96, "text": " professional coders, you know this already, you need, because we're going to be doing", "tokens": [4843, 17656, 433, 11, 291, 458, 341, 1217, 11, 291, 643, 11, 570, 321, 434, 516, 281, 312, 884], "temperature": 0.0, "avg_logprob": -0.16759545924299854, "compression_ratio": 1.7660377358490567, "no_speech_prob": 9.22333219932625e-06}, {"id": 723, "seek": 381960, "start": 3828.96, "end": 3832.62, "text": " a lot of stuff with the fastai library and other libraries, you need to be able to navigate", "tokens": [257, 688, 295, 1507, 365, 264, 2370, 1301, 6405, 293, 661, 15148, 11, 291, 643, 281, 312, 1075, 281, 12350], "temperature": 0.0, "avg_logprob": -0.16759545924299854, "compression_ratio": 1.7660377358490567, "no_speech_prob": 9.22333219932625e-06}, {"id": 724, "seek": 381960, "start": 3832.62, "end": 3835.52, "text": " very quickly through them.", "tokens": [588, 2661, 807, 552, 13], "temperature": 0.0, "avg_logprob": -0.16759545924299854, "compression_ratio": 1.7660377358490567, "no_speech_prob": 9.22333219932625e-06}, {"id": 725, "seek": 381960, "start": 3835.52, "end": 3840.12, "text": " And so let me give you a quick overview of how to navigate through code.", "tokens": [400, 370, 718, 385, 976, 291, 257, 1702, 12492, 295, 577, 281, 12350, 807, 3089, 13], "temperature": 0.0, "avg_logprob": -0.16759545924299854, "compression_ratio": 1.7660377358490567, "no_speech_prob": 9.22333219932625e-06}, {"id": 726, "seek": 381960, "start": 3840.12, "end": 3844.8399999999997, "text": " And for those of you that haven't used an editor properly before, this is going to blow", "tokens": [400, 337, 729, 295, 291, 300, 2378, 380, 1143, 364, 9839, 6108, 949, 11, 341, 307, 516, 281, 6327], "temperature": 0.0, "avg_logprob": -0.16759545924299854, "compression_ratio": 1.7660377358490567, "no_speech_prob": 9.22333219932625e-06}, {"id": 727, "seek": 381960, "start": 3844.8399999999997, "end": 3845.8399999999997, "text": " your minds.", "tokens": [428, 9634, 13], "temperature": 0.0, "avg_logprob": -0.16759545924299854, "compression_ratio": 1.7660377358490567, "no_speech_prob": 9.22333219932625e-06}, {"id": 728, "seek": 384584, "start": 3845.84, "end": 3851.08, "text": " For those of you that have, you're going to be like, check this out guys, check this out.", "tokens": [1171, 729, 295, 291, 300, 362, 11, 291, 434, 516, 281, 312, 411, 11, 1520, 341, 484, 1074, 11, 1520, 341, 484, 13], "temperature": 0.0, "avg_logprob": -0.19277256413509972, "compression_ratio": 1.623076923076923, "no_speech_prob": 1.147859074990265e-05}, {"id": 729, "seek": 384584, "start": 3851.08, "end": 3855.32, "text": " For the demo I'm going to show you in Visual Studio Code.", "tokens": [1171, 264, 10723, 286, 478, 516, 281, 855, 291, 294, 23187, 13500, 15549, 13], "temperature": 0.0, "avg_logprob": -0.19277256413509972, "compression_ratio": 1.623076923076923, "no_speech_prob": 1.147859074990265e-05}, {"id": 730, "seek": 384584, "start": 3855.32, "end": 3861.06, "text": " Personally my view is that on pretty much every platform, unless you're prepared to", "tokens": [21079, 452, 1910, 307, 300, 322, 1238, 709, 633, 3663, 11, 5969, 291, 434, 4927, 281], "temperature": 0.0, "avg_logprob": -0.19277256413509972, "compression_ratio": 1.623076923076923, "no_speech_prob": 1.147859074990265e-05}, {"id": 731, "seek": 384584, "start": 3861.06, "end": 3867.34, "text": " put in the decades of your life to learn BIM or Emax well, Visual Studio Code is probably", "tokens": [829, 294, 264, 7878, 295, 428, 993, 281, 1466, 363, 6324, 420, 462, 41167, 731, 11, 23187, 13500, 15549, 307, 1391], "temperature": 0.0, "avg_logprob": -0.19277256413509972, "compression_ratio": 1.623076923076923, "no_speech_prob": 1.147859074990265e-05}, {"id": 732, "seek": 384584, "start": 3867.34, "end": 3869.32, "text": " the best editor out there.", "tokens": [264, 1151, 9839, 484, 456, 13], "temperature": 0.0, "avg_logprob": -0.19277256413509972, "compression_ratio": 1.623076923076923, "no_speech_prob": 1.147859074990265e-05}, {"id": 733, "seek": 384584, "start": 3869.32, "end": 3871.6800000000003, "text": " It's free, it's open source.", "tokens": [467, 311, 1737, 11, 309, 311, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.19277256413509972, "compression_ratio": 1.623076923076923, "no_speech_prob": 1.147859074990265e-05}, {"id": 734, "seek": 384584, "start": 3871.6800000000003, "end": 3873.4, "text": " There are other perfectly good ones as well.", "tokens": [821, 366, 661, 6239, 665, 2306, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19277256413509972, "compression_ratio": 1.623076923076923, "no_speech_prob": 1.147859074990265e-05}, {"id": 735, "seek": 387340, "start": 3873.4, "end": 3877.8, "text": " Also, if you download a recent version of Anaconda, it will offer to install Visual", "tokens": [2743, 11, 498, 291, 5484, 257, 5162, 3037, 295, 1107, 326, 12233, 11, 309, 486, 2626, 281, 3625, 23187], "temperature": 0.0, "avg_logprob": -0.1271878201028575, "compression_ratio": 1.6901960784313725, "no_speech_prob": 1.202940347866388e-05}, {"id": 736, "seek": 387340, "start": 3877.8, "end": 3879.76, "text": " Studio Code for you.", "tokens": [13500, 15549, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.1271878201028575, "compression_ratio": 1.6901960784313725, "no_speech_prob": 1.202940347866388e-05}, {"id": 737, "seek": 387340, "start": 3879.76, "end": 3884.0, "text": " It integrates with Anaconda, sets it up with your Python interpreter, and comes with the", "tokens": [467, 3572, 1024, 365, 1107, 326, 12233, 11, 6352, 309, 493, 365, 428, 15329, 34132, 11, 293, 1487, 365, 264], "temperature": 0.0, "avg_logprob": -0.1271878201028575, "compression_ratio": 1.6901960784313725, "no_speech_prob": 1.202940347866388e-05}, {"id": 738, "seek": 387340, "start": 3884.0, "end": 3886.0, "text": " Python extensions and everything.", "tokens": [15329, 25129, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.1271878201028575, "compression_ratio": 1.6901960784313725, "no_speech_prob": 1.202940347866388e-05}, {"id": 739, "seek": 387340, "start": 3886.0, "end": 3889.2200000000003, "text": " So it's a good choice if you're not sure.", "tokens": [407, 309, 311, 257, 665, 3922, 498, 291, 434, 406, 988, 13], "temperature": 0.0, "avg_logprob": -0.1271878201028575, "compression_ratio": 1.6901960784313725, "no_speech_prob": 1.202940347866388e-05}, {"id": 740, "seek": 387340, "start": 3889.2200000000003, "end": 3894.64, "text": " If you've got some other editor you like, search for the right keywords.", "tokens": [759, 291, 600, 658, 512, 661, 9839, 291, 411, 11, 3164, 337, 264, 558, 21009, 13], "temperature": 0.0, "avg_logprob": -0.1271878201028575, "compression_ratio": 1.6901960784313725, "no_speech_prob": 1.202940347866388e-05}, {"id": 741, "seek": 387340, "start": 3894.64, "end": 3901.6, "text": " So if I fire up Visual Studio Code, the first thing to do of course is do a git clone of", "tokens": [407, 498, 286, 2610, 493, 23187, 13500, 15549, 11, 264, 700, 551, 281, 360, 295, 1164, 307, 360, 257, 18331, 26506, 295], "temperature": 0.0, "avg_logprob": -0.1271878201028575, "compression_ratio": 1.6901960784313725, "no_speech_prob": 1.202940347866388e-05}, {"id": 742, "seek": 390160, "start": 3901.6, "end": 3905.2, "text": " the Fastai library to your laptop.", "tokens": [264, 15968, 1301, 6405, 281, 428, 10732, 13], "temperature": 0.0, "avg_logprob": -0.2490747408433394, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.241135032614693e-05}, {"id": 743, "seek": 390160, "start": 3905.2, "end": 3911.48, "text": " You'll find in the root of the repo, as well as the environment.yml file that sets up a", "tokens": [509, 603, 915, 294, 264, 5593, 295, 264, 49040, 11, 382, 731, 382, 264, 2823, 13, 4199, 75, 3991, 300, 6352, 493, 257], "temperature": 0.0, "avg_logprob": -0.2490747408433394, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.241135032614693e-05}, {"id": 744, "seek": 390160, "start": 3911.48, "end": 3918.7999999999997, "text": " conda environment for GPU, one of the students has been kind enough to create an environment-cpu.yml", "tokens": [2224, 64, 2823, 337, 18407, 11, 472, 295, 264, 1731, 575, 668, 733, 1547, 281, 1884, 364, 2823, 12, 66, 34859, 13, 4199, 75], "temperature": 0.0, "avg_logprob": -0.2490747408433394, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.241135032614693e-05}, {"id": 745, "seek": 390160, "start": 3918.7999999999997, "end": 3919.7999999999997, "text": " file.", "tokens": [3991, 13], "temperature": 0.0, "avg_logprob": -0.2490747408433394, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.241135032614693e-05}, {"id": 746, "seek": 390160, "start": 3919.7999999999997, "end": 3923.88, "text": " Perhaps one of you that knows how to do this can add some notes to the wiki.", "tokens": [10517, 472, 295, 291, 300, 3255, 577, 281, 360, 341, 393, 909, 512, 5570, 281, 264, 261, 9850, 13], "temperature": 0.0, "avg_logprob": -0.2490747408433394, "compression_ratio": 1.5854922279792747, "no_speech_prob": 1.241135032614693e-05}, {"id": 747, "seek": 392388, "start": 3923.88, "end": 3932.2400000000002, "text": " But basically you can use that to create a local CPU-only Fastai installation.", "tokens": [583, 1936, 291, 393, 764, 300, 281, 1884, 257, 2654, 13199, 12, 25202, 15968, 1301, 13260, 13], "temperature": 0.0, "avg_logprob": -0.17248493017152297, "compression_ratio": 1.541871921182266, "no_speech_prob": 5.862777925358387e-06}, {"id": 748, "seek": 392388, "start": 3932.2400000000002, "end": 3937.6800000000003, "text": " The reason you might want to do that is so that as you navigate the code, you'll be able", "tokens": [440, 1778, 291, 1062, 528, 281, 360, 300, 307, 370, 300, 382, 291, 12350, 264, 3089, 11, 291, 603, 312, 1075], "temperature": 0.0, "avg_logprob": -0.17248493017152297, "compression_ratio": 1.541871921182266, "no_speech_prob": 5.862777925358387e-06}, {"id": 749, "seek": 392388, "start": 3937.6800000000003, "end": 3942.48, "text": " to navigate into PyTorch, you'll see all the stuff is there.", "tokens": [281, 12350, 666, 9953, 51, 284, 339, 11, 291, 603, 536, 439, 264, 1507, 307, 456, 13], "temperature": 0.0, "avg_logprob": -0.17248493017152297, "compression_ratio": 1.541871921182266, "no_speech_prob": 5.862777925358387e-06}, {"id": 750, "seek": 392388, "start": 3942.48, "end": 3948.84, "text": " So I open up Visual Studio Code, and it's as simple as saying, open folder, and then", "tokens": [407, 286, 1269, 493, 23187, 13500, 15549, 11, 293, 309, 311, 382, 2199, 382, 1566, 11, 1269, 10820, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.17248493017152297, "compression_ratio": 1.541871921182266, "no_speech_prob": 5.862777925358387e-06}, {"id": 751, "seek": 394884, "start": 3948.84, "end": 3954.44, "text": " you can just point it at the Fastai GitHub folder that you just downloaded.", "tokens": [291, 393, 445, 935, 309, 412, 264, 15968, 1301, 23331, 10820, 300, 291, 445, 21748, 13], "temperature": 0.0, "avg_logprob": -0.1716025296379538, "compression_ratio": 1.6099585062240664, "no_speech_prob": 3.4465665521565825e-06}, {"id": 752, "seek": 394884, "start": 3954.44, "end": 3960.28, "text": " And so the next thing you need to do is to set up Visual Studio Code to say, I want to", "tokens": [400, 370, 264, 958, 551, 291, 643, 281, 360, 307, 281, 992, 493, 23187, 13500, 15549, 281, 584, 11, 286, 528, 281], "temperature": 0.0, "avg_logprob": -0.1716025296379538, "compression_ratio": 1.6099585062240664, "no_speech_prob": 3.4465665521565825e-06}, {"id": 753, "seek": 394884, "start": 3960.28, "end": 3964.8, "text": " use the Fastai conda environment, please.", "tokens": [764, 264, 15968, 1301, 2224, 64, 2823, 11, 1767, 13], "temperature": 0.0, "avg_logprob": -0.1716025296379538, "compression_ratio": 1.6099585062240664, "no_speech_prob": 3.4465665521565825e-06}, {"id": 754, "seek": 394884, "start": 3964.8, "end": 3968.48, "text": " So the way you do that is with the select interpreter command.", "tokens": [407, 264, 636, 291, 360, 300, 307, 365, 264, 3048, 34132, 5622, 13], "temperature": 0.0, "avg_logprob": -0.1716025296379538, "compression_ratio": 1.6099585062240664, "no_speech_prob": 3.4465665521565825e-06}, {"id": 755, "seek": 394884, "start": 3968.48, "end": 3972.4, "text": " And there's a really nice idea which is kind of like the best of both worlds between a", "tokens": [400, 456, 311, 257, 534, 1481, 1558, 597, 307, 733, 295, 411, 264, 1151, 295, 1293, 13401, 1296, 257], "temperature": 0.0, "avg_logprob": -0.1716025296379538, "compression_ratio": 1.6099585062240664, "no_speech_prob": 3.4465665521565825e-06}, {"id": 756, "seek": 394884, "start": 3972.4, "end": 3977.36, "text": " command line interface and a GUI.", "tokens": [5622, 1622, 9226, 293, 257, 17917, 40, 13], "temperature": 0.0, "avg_logprob": -0.1716025296379538, "compression_ratio": 1.6099585062240664, "no_speech_prob": 3.4465665521565825e-06}, {"id": 757, "seek": 397736, "start": 3977.36, "end": 3981.76, "text": " This is the only command you need to know, Ctrl-Shift-P. You hit Ctrl-Shift-P, and then", "tokens": [639, 307, 264, 787, 5622, 291, 643, 281, 458, 11, 35233, 12, 7774, 2008, 12, 47, 13, 509, 2045, 35233, 12, 7774, 2008, 12, 47, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.21659593324403506, "compression_ratio": 1.8265682656826567, "no_speech_prob": 1.5446121324202977e-05}, {"id": 758, "seek": 397736, "start": 3981.76, "end": 3984.76, "text": " you start typing what you want to do, and watch what happens.", "tokens": [291, 722, 18444, 437, 291, 528, 281, 360, 11, 293, 1159, 437, 2314, 13], "temperature": 0.0, "avg_logprob": -0.21659593324403506, "compression_ratio": 1.8265682656826567, "no_speech_prob": 1.5446121324202977e-05}, {"id": 759, "seek": 397736, "start": 3984.76, "end": 3987.76, "text": " Ctrl-Shift-P, I want to change my interpreter.", "tokens": [35233, 12, 7774, 2008, 12, 47, 11, 286, 528, 281, 1319, 452, 34132, 13], "temperature": 0.0, "avg_logprob": -0.21659593324403506, "compression_ratio": 1.8265682656826567, "no_speech_prob": 1.5446121324202977e-05}, {"id": 760, "seek": 397736, "start": 3987.76, "end": 3991.4, "text": " And it appears.", "tokens": [400, 309, 7038, 13], "temperature": 0.0, "avg_logprob": -0.21659593324403506, "compression_ratio": 1.8265682656826567, "no_speech_prob": 1.5446121324202977e-05}, {"id": 761, "seek": 397736, "start": 3991.4, "end": 3996.08, "text": " If you're not sure, you can try a few different things.", "tokens": [759, 291, 434, 406, 988, 11, 291, 393, 853, 257, 1326, 819, 721, 13], "temperature": 0.0, "avg_logprob": -0.21659593324403506, "compression_ratio": 1.8265682656826567, "no_speech_prob": 1.5446121324202977e-05}, {"id": 762, "seek": 397736, "start": 3996.08, "end": 3998.6400000000003, "text": " So here we are, Python select interpreter.", "tokens": [407, 510, 321, 366, 11, 15329, 3048, 34132, 13], "temperature": 0.0, "avg_logprob": -0.21659593324403506, "compression_ratio": 1.8265682656826567, "no_speech_prob": 1.5446121324202977e-05}, {"id": 763, "seek": 397736, "start": 3998.6400000000003, "end": 4001.84, "text": " And you can see generally you can type stuff in, it'll give you a list of things if you", "tokens": [400, 291, 393, 536, 5101, 291, 393, 2010, 1507, 294, 11, 309, 603, 976, 291, 257, 1329, 295, 721, 498, 291], "temperature": 0.0, "avg_logprob": -0.21659593324403506, "compression_ratio": 1.8265682656826567, "no_speech_prob": 1.5446121324202977e-05}, {"id": 764, "seek": 397736, "start": 4001.84, "end": 4002.84, "text": " can.", "tokens": [393, 13], "temperature": 0.0, "avg_logprob": -0.21659593324403506, "compression_ratio": 1.8265682656826567, "no_speech_prob": 1.5446121324202977e-05}, {"id": 765, "seek": 397736, "start": 4002.84, "end": 4006.48, "text": " And so here's a list of all of the environments and interpreters I have set up, and here's", "tokens": [400, 370, 510, 311, 257, 1329, 295, 439, 295, 264, 12388, 293, 17489, 1559, 286, 362, 992, 493, 11, 293, 510, 311], "temperature": 0.0, "avg_logprob": -0.21659593324403506, "compression_ratio": 1.8265682656826567, "no_speech_prob": 1.5446121324202977e-05}, {"id": 766, "seek": 400648, "start": 4006.48, "end": 4011.12, "text": " my Fastai environment.", "tokens": [452, 15968, 1301, 2823, 13], "temperature": 0.0, "avg_logprob": -0.14715320330399734, "compression_ratio": 1.60352422907489, "no_speech_prob": 2.3687932753091445e-06}, {"id": 767, "seek": 400648, "start": 4011.12, "end": 4015.4, "text": " So that's basically the only setup that you have to do.", "tokens": [407, 300, 311, 1936, 264, 787, 8657, 300, 291, 362, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.14715320330399734, "compression_ratio": 1.60352422907489, "no_speech_prob": 2.3687932753091445e-06}, {"id": 768, "seek": 400648, "start": 4015.4, "end": 4019.56, "text": " The only other thing you might want to do is to know there's an integrated terminal.", "tokens": [440, 787, 661, 551, 291, 1062, 528, 281, 360, 307, 281, 458, 456, 311, 364, 10919, 14709, 13], "temperature": 0.0, "avg_logprob": -0.14715320330399734, "compression_ratio": 1.60352422907489, "no_speech_prob": 2.3687932753091445e-06}, {"id": 769, "seek": 400648, "start": 4019.56, "end": 4024.28, "text": " So if you hit Ctrl-Backtick, it brings up the terminal.", "tokens": [407, 498, 291, 2045, 35233, 12, 28404, 83, 618, 11, 309, 5607, 493, 264, 14709, 13], "temperature": 0.0, "avg_logprob": -0.14715320330399734, "compression_ratio": 1.60352422907489, "no_speech_prob": 2.3687932753091445e-06}, {"id": 770, "seek": 400648, "start": 4024.28, "end": 4028.84, "text": " And the first time you do it, it'll ask you what terminal do you want.", "tokens": [400, 264, 700, 565, 291, 360, 309, 11, 309, 603, 1029, 291, 437, 14709, 360, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.14715320330399734, "compression_ratio": 1.60352422907489, "no_speech_prob": 2.3687932753091445e-06}, {"id": 771, "seek": 400648, "start": 4028.84, "end": 4033.44, "text": " If you're on Windows, it'll be like PowerShell or Command Prompt or Bash.", "tokens": [759, 291, 434, 322, 8591, 11, 309, 603, 312, 411, 7086, 9526, 285, 420, 17901, 15833, 662, 420, 43068, 13], "temperature": 0.0, "avg_logprob": -0.14715320330399734, "compression_ratio": 1.60352422907489, "no_speech_prob": 2.3687932753091445e-06}, {"id": 772, "seek": 403344, "start": 4033.44, "end": 4036.92, "text": " If you're on Linux, you've got multiple shells installed, it'll ask.", "tokens": [759, 291, 434, 322, 18734, 11, 291, 600, 658, 3866, 22523, 8899, 11, 309, 603, 1029, 13], "temperature": 0.0, "avg_logprob": -0.18772984339185983, "compression_ratio": 1.6293436293436294, "no_speech_prob": 5.173895715415711e-06}, {"id": 773, "seek": 403344, "start": 4036.92, "end": 4041.36, "text": " So as you can see, I've got it set up to use Bash.", "tokens": [407, 382, 291, 393, 536, 11, 286, 600, 658, 309, 992, 493, 281, 764, 43068, 13], "temperature": 0.0, "avg_logprob": -0.18772984339185983, "compression_ratio": 1.6293436293436294, "no_speech_prob": 5.173895715415711e-06}, {"id": 774, "seek": 403344, "start": 4041.36, "end": 4048.2000000000003, "text": " And you'll see it automatically goes to the directory that I'm in.", "tokens": [400, 291, 603, 536, 309, 6772, 1709, 281, 264, 21120, 300, 286, 478, 294, 13], "temperature": 0.0, "avg_logprob": -0.18772984339185983, "compression_ratio": 1.6293436293436294, "no_speech_prob": 5.173895715415711e-06}, {"id": 775, "seek": 403344, "start": 4048.2000000000003, "end": 4052.54, "text": " So the main thing we wanted to do right now was find out what open underscore image is.", "tokens": [407, 264, 2135, 551, 321, 1415, 281, 360, 558, 586, 390, 915, 484, 437, 1269, 37556, 3256, 307, 13], "temperature": 0.0, "avg_logprob": -0.18772984339185983, "compression_ratio": 1.6293436293436294, "no_speech_prob": 5.173895715415711e-06}, {"id": 776, "seek": 403344, "start": 4052.54, "end": 4058.0, "text": " So the only thing you need to know to do that is Ctrl-T.", "tokens": [407, 264, 787, 551, 291, 643, 281, 458, 281, 360, 300, 307, 35233, 12, 51, 13], "temperature": 0.0, "avg_logprob": -0.18772984339185983, "compression_ratio": 1.6293436293436294, "no_speech_prob": 5.173895715415711e-06}, {"id": 777, "seek": 403344, "start": 4058.0, "end": 4062.44, "text": " If you hit Ctrl-T, you can now type the name of a class, a function, pretty much anything,", "tokens": [759, 291, 2045, 35233, 12, 51, 11, 291, 393, 586, 2010, 264, 1315, 295, 257, 1508, 11, 257, 2445, 11, 1238, 709, 1340, 11], "temperature": 0.0, "avg_logprob": -0.18772984339185983, "compression_ratio": 1.6293436293436294, "no_speech_prob": 5.173895715415711e-06}, {"id": 778, "seek": 406244, "start": 4062.44, "end": 4064.28, "text": " and you can find out about it.", "tokens": [293, 291, 393, 915, 484, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.178712990324376, "compression_ratio": 1.7172995780590716, "no_speech_prob": 5.422180947789457e-06}, {"id": 779, "seek": 406244, "start": 4064.28, "end": 4067.64, "text": " So open image, you can see it appears.", "tokens": [407, 1269, 3256, 11, 291, 393, 536, 309, 7038, 13], "temperature": 0.0, "avg_logprob": -0.178712990324376, "compression_ratio": 1.7172995780590716, "no_speech_prob": 5.422180947789457e-06}, {"id": 780, "seek": 406244, "start": 4067.64, "end": 4071.64, "text": " And it's kind of cool if there's something that's got like camel case capitalized or", "tokens": [400, 309, 311, 733, 295, 1627, 498, 456, 311, 746, 300, 311, 658, 411, 37755, 1389, 4238, 1602, 420], "temperature": 0.0, "avg_logprob": -0.178712990324376, "compression_ratio": 1.7172995780590716, "no_speech_prob": 5.422180947789457e-06}, {"id": 781, "seek": 406244, "start": 4071.64, "end": 4075.2000000000003, "text": " something with underscore, you can just type the first few letters of each bit.", "tokens": [746, 365, 37556, 11, 291, 393, 445, 2010, 264, 700, 1326, 7825, 295, 1184, 857, 13], "temperature": 0.0, "avg_logprob": -0.178712990324376, "compression_ratio": 1.7172995780590716, "no_speech_prob": 5.422180947789457e-06}, {"id": 782, "seek": 406244, "start": 4075.2000000000003, "end": 4080.32, "text": " So I could be like open image, for example.", "tokens": [407, 286, 727, 312, 411, 1269, 3256, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.178712990324376, "compression_ratio": 1.7172995780590716, "no_speech_prob": 5.422180947789457e-06}, {"id": 783, "seek": 406244, "start": 4080.32, "end": 4082.82, "text": " I do that, and it's found the function.", "tokens": [286, 360, 300, 11, 293, 309, 311, 1352, 264, 2445, 13], "temperature": 0.0, "avg_logprob": -0.178712990324376, "compression_ratio": 1.7172995780590716, "no_speech_prob": 5.422180947789457e-06}, {"id": 784, "seek": 406244, "start": 4082.82, "end": 4086.4, "text": " It's also found some other things that match.", "tokens": [467, 311, 611, 1352, 512, 661, 721, 300, 2995, 13], "temperature": 0.0, "avg_logprob": -0.178712990324376, "compression_ratio": 1.7172995780590716, "no_speech_prob": 5.422180947789457e-06}, {"id": 785, "seek": 406244, "start": 4086.4, "end": 4088.86, "text": " There it is.", "tokens": [821, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.178712990324376, "compression_ratio": 1.7172995780590716, "no_speech_prob": 5.422180947789457e-06}, {"id": 786, "seek": 406244, "start": 4088.86, "end": 4090.04, "text": " So that's kind of a good way.", "tokens": [407, 300, 311, 733, 295, 257, 665, 636, 13], "temperature": 0.0, "avg_logprob": -0.178712990324376, "compression_ratio": 1.7172995780590716, "no_speech_prob": 5.422180947789457e-06}, {"id": 787, "seek": 409004, "start": 4090.04, "end": 4094.7599999999998, "text": " You can see exactly where it's come from, and you can find out exactly what it is.", "tokens": [509, 393, 536, 2293, 689, 309, 311, 808, 490, 11, 293, 291, 393, 915, 484, 2293, 437, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.19510538578033448, "compression_ratio": 1.45, "no_speech_prob": 4.289318439987255e-06}, {"id": 788, "seek": 409004, "start": 4094.7599999999998, "end": 4098.68, "text": " And then the next thing I guess would be like, well, what's it used for?", "tokens": [400, 550, 264, 958, 551, 286, 2041, 576, 312, 411, 11, 731, 11, 437, 311, 309, 1143, 337, 30], "temperature": 0.0, "avg_logprob": -0.19510538578033448, "compression_ratio": 1.45, "no_speech_prob": 4.289318439987255e-06}, {"id": 789, "seek": 409004, "start": 4098.68, "end": 4115.36, "text": " So if it's used inside Fast.ai, you could say find references, which is Shift-F12.", "tokens": [407, 498, 309, 311, 1143, 1854, 15968, 13, 1301, 11, 291, 727, 584, 915, 15400, 11, 597, 307, 28304, 12, 37, 4762, 13], "temperature": 0.0, "avg_logprob": -0.19510538578033448, "compression_ratio": 1.45, "no_speech_prob": 4.289318439987255e-06}, {"id": 790, "seek": 409004, "start": 4115.36, "end": 4118.28, "text": " Open image, Shift-F12.", "tokens": [7238, 3256, 11, 28304, 12, 37, 4762, 13], "temperature": 0.0, "avg_logprob": -0.19510538578033448, "compression_ratio": 1.45, "no_speech_prob": 4.289318439987255e-06}, {"id": 791, "seek": 411828, "start": 4118.28, "end": 4122.12, "text": " And it brings up something saying, oh, it's used twice in this code base.", "tokens": [400, 309, 5607, 493, 746, 1566, 11, 1954, 11, 309, 311, 1143, 6091, 294, 341, 3089, 3096, 13], "temperature": 0.0, "avg_logprob": -0.15103421892438615, "compression_ratio": 1.880952380952381, "no_speech_prob": 1.628046788937354e-06}, {"id": 792, "seek": 411828, "start": 4122.12, "end": 4126.88, "text": " And I can go and I can have a look at each of those examples.", "tokens": [400, 286, 393, 352, 293, 286, 393, 362, 257, 574, 412, 1184, 295, 729, 5110, 13], "temperature": 0.0, "avg_logprob": -0.15103421892438615, "compression_ratio": 1.880952380952381, "no_speech_prob": 1.628046788937354e-06}, {"id": 793, "seek": 411828, "start": 4126.88, "end": 4130.48, "text": " If it's used in multiple different files, it'll tell you the multiple different files", "tokens": [759, 309, 311, 1143, 294, 3866, 819, 7098, 11, 309, 603, 980, 291, 264, 3866, 819, 7098], "temperature": 0.0, "avg_logprob": -0.15103421892438615, "compression_ratio": 1.880952380952381, "no_speech_prob": 1.628046788937354e-06}, {"id": 794, "seek": 411828, "start": 4130.48, "end": 4134.3, "text": " that it's used in.", "tokens": [300, 309, 311, 1143, 294, 13], "temperature": 0.0, "avg_logprob": -0.15103421892438615, "compression_ratio": 1.880952380952381, "no_speech_prob": 1.628046788937354e-06}, {"id": 795, "seek": 411828, "start": 4134.3, "end": 4139.28, "text": " Another thing that's really handy then is as you look at the code, you'll find that", "tokens": [3996, 551, 300, 311, 534, 13239, 550, 307, 382, 291, 574, 412, 264, 3089, 11, 291, 603, 915, 300], "temperature": 0.0, "avg_logprob": -0.15103421892438615, "compression_ratio": 1.880952380952381, "no_speech_prob": 1.628046788937354e-06}, {"id": 796, "seek": 411828, "start": 4139.28, "end": 4143.24, "text": " certain bits of the code call other parts of the code.", "tokens": [1629, 9239, 295, 264, 3089, 818, 661, 3166, 295, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.15103421892438615, "compression_ratio": 1.880952380952381, "no_speech_prob": 1.628046788937354e-06}, {"id": 797, "seek": 411828, "start": 4143.24, "end": 4147.32, "text": " So for example, if you're inside files dataset, and you're like, oh, this is calling something", "tokens": [407, 337, 1365, 11, 498, 291, 434, 1854, 7098, 28872, 11, 293, 291, 434, 411, 11, 1954, 11, 341, 307, 5141, 746], "temperature": 0.0, "avg_logprob": -0.15103421892438615, "compression_ratio": 1.880952380952381, "no_speech_prob": 1.628046788937354e-06}, {"id": 798, "seek": 414732, "start": 4147.32, "end": 4149.599999999999, "text": " called open image, what is that?", "tokens": [1219, 1269, 3256, 11, 437, 307, 300, 30], "temperature": 0.0, "avg_logprob": -0.19395651136125838, "compression_ratio": 1.6988847583643123, "no_speech_prob": 1.5294109516617027e-06}, {"id": 799, "seek": 414732, "start": 4149.599999999999, "end": 4154.44, "text": " Well, you can wave your pointer over it, and it'll give you the doc string.", "tokens": [1042, 11, 291, 393, 5772, 428, 23918, 670, 309, 11, 293, 309, 603, 976, 291, 264, 3211, 6798, 13], "temperature": 0.0, "avg_logprob": -0.19395651136125838, "compression_ratio": 1.6988847583643123, "no_speech_prob": 1.5294109516617027e-06}, {"id": 800, "seek": 414732, "start": 4154.44, "end": 4160.219999999999, "text": " Or you can hit F12, and it jumps straight to its definition.", "tokens": [1610, 291, 393, 2045, 479, 4762, 11, 293, 309, 16704, 2997, 281, 1080, 7123, 13], "temperature": 0.0, "avg_logprob": -0.19395651136125838, "compression_ratio": 1.6988847583643123, "no_speech_prob": 1.5294109516617027e-06}, {"id": 801, "seek": 414732, "start": 4160.219999999999, "end": 4164.92, "text": " So like often it's easy to get a bit lost in things call things call things, and if", "tokens": [407, 411, 2049, 309, 311, 1858, 281, 483, 257, 857, 2731, 294, 721, 818, 721, 818, 721, 11, 293, 498], "temperature": 0.0, "avg_logprob": -0.19395651136125838, "compression_ratio": 1.6988847583643123, "no_speech_prob": 1.5294109516617027e-06}, {"id": 802, "seek": 414732, "start": 4164.92, "end": 4167.48, "text": " you have to manually go to each bit, it's infuriating.", "tokens": [291, 362, 281, 16945, 352, 281, 1184, 857, 11, 309, 311, 1536, 9744, 990, 13], "temperature": 0.0, "avg_logprob": -0.19395651136125838, "compression_ratio": 1.6988847583643123, "no_speech_prob": 1.5294109516617027e-06}, {"id": 803, "seek": 414732, "start": 4167.48, "end": 4171.08, "text": " Whereas this way, it's always one button away.", "tokens": [13813, 341, 636, 11, 309, 311, 1009, 472, 2960, 1314, 13], "temperature": 0.0, "avg_logprob": -0.19395651136125838, "compression_ratio": 1.6988847583643123, "no_speech_prob": 1.5294109516617027e-06}, {"id": 804, "seek": 414732, "start": 4171.08, "end": 4177.24, "text": " Control T to go to something that you specifically know the name of, or F12 to jump to the definition", "tokens": [12912, 314, 281, 352, 281, 746, 300, 291, 4682, 458, 264, 1315, 295, 11, 420, 479, 4762, 281, 3012, 281, 264, 7123], "temperature": 0.0, "avg_logprob": -0.19395651136125838, "compression_ratio": 1.6988847583643123, "no_speech_prob": 1.5294109516617027e-06}, {"id": 805, "seek": 417724, "start": 4177.24, "end": 4179.719999999999, "text": " of something that you're clicking on.", "tokens": [295, 746, 300, 291, 434, 9697, 322, 13], "temperature": 0.0, "avg_logprob": -0.1895099686987606, "compression_ratio": 1.4572864321608041, "no_speech_prob": 6.048860086593777e-06}, {"id": 806, "seek": 417724, "start": 4179.719999999999, "end": 4189.8, "text": " When you're done, you probably want to go back where you came from.", "tokens": [1133, 291, 434, 1096, 11, 291, 1391, 528, 281, 352, 646, 689, 291, 1361, 490, 13], "temperature": 0.0, "avg_logprob": -0.1895099686987606, "compression_ratio": 1.4572864321608041, "no_speech_prob": 6.048860086593777e-06}, {"id": 807, "seek": 417724, "start": 4189.8, "end": 4198.5199999999995, "text": " So whatever you use, BIM, Emacs, Atom, whatever, they all have this functionality as long as", "tokens": [407, 2035, 291, 764, 11, 363, 6324, 11, 3968, 44937, 11, 1711, 298, 11, 2035, 11, 436, 439, 362, 341, 14980, 382, 938, 382], "temperature": 0.0, "avg_logprob": -0.1895099686987606, "compression_ratio": 1.4572864321608041, "no_speech_prob": 6.048860086593777e-06}, {"id": 808, "seek": 417724, "start": 4198.5199999999995, "end": 4202.92, "text": " you have an appropriate extension installed.", "tokens": [291, 362, 364, 6854, 10320, 8899, 13], "temperature": 0.0, "avg_logprob": -0.1895099686987606, "compression_ratio": 1.4572864321608041, "no_speech_prob": 6.048860086593777e-06}, {"id": 809, "seek": 417724, "start": 4202.92, "end": 4205.719999999999, "text": " If you use PyCharm, you can get that for free.", "tokens": [759, 291, 764, 9953, 6546, 4452, 11, 291, 393, 483, 300, 337, 1737, 13], "temperature": 0.0, "avg_logprob": -0.1895099686987606, "compression_ratio": 1.4572864321608041, "no_speech_prob": 6.048860086593777e-06}, {"id": 810, "seek": 420572, "start": 4205.72, "end": 4208.240000000001, "text": " That doesn't need any extensions because it's Python.", "tokens": [663, 1177, 380, 643, 604, 25129, 570, 309, 311, 15329, 13], "temperature": 0.0, "avg_logprob": -0.2783045570055644, "compression_ratio": 1.521551724137931, "no_speech_prob": 6.144148755993228e-06}, {"id": 811, "seek": 420572, "start": 4208.240000000001, "end": 4213.72, "text": " Whatever you're using, you want to know how to do this stuff.", "tokens": [8541, 291, 434, 1228, 11, 291, 528, 281, 458, 577, 281, 360, 341, 1507, 13], "temperature": 0.0, "avg_logprob": -0.2783045570055644, "compression_ratio": 1.521551724137931, "no_speech_prob": 6.144148755993228e-06}, {"id": 812, "seek": 420572, "start": 4213.72, "end": 4222.08, "text": " Finally, I'll mention there's a nice thing called ZenMode, Control KZ, which basically", "tokens": [6288, 11, 286, 603, 2152, 456, 311, 257, 1481, 551, 1219, 22387, 44, 1429, 11, 12912, 591, 57, 11, 597, 1936], "temperature": 0.0, "avg_logprob": -0.2783045570055644, "compression_ratio": 1.521551724137931, "no_speech_prob": 6.144148755993228e-06}, {"id": 813, "seek": 420572, "start": 4222.08, "end": 4224.12, "text": " gets rid of everything else so you can focus.", "tokens": [2170, 3973, 295, 1203, 1646, 370, 291, 393, 1879, 13], "temperature": 0.0, "avg_logprob": -0.2783045570055644, "compression_ratio": 1.521551724137931, "no_speech_prob": 6.144148755993228e-06}, {"id": 814, "seek": 420572, "start": 4224.12, "end": 4228.280000000001, "text": " But it does keep this nice little thing on the right-hand side, which kind of shows you", "tokens": [583, 309, 775, 1066, 341, 1481, 707, 551, 322, 264, 558, 12, 5543, 1252, 11, 597, 733, 295, 3110, 291], "temperature": 0.0, "avg_logprob": -0.2783045570055644, "compression_ratio": 1.521551724137931, "no_speech_prob": 6.144148755993228e-06}, {"id": 815, "seek": 420572, "start": 4228.280000000001, "end": 4234.280000000001, "text": " where you're at.", "tokens": [689, 291, 434, 412, 13], "temperature": 0.0, "avg_logprob": -0.2783045570055644, "compression_ratio": 1.521551724137931, "no_speech_prob": 6.144148755993228e-06}, {"id": 816, "seek": 423428, "start": 4234.28, "end": 4239.599999999999, "text": " So that's something that you should practice if you haven't played around with it before", "tokens": [407, 300, 311, 746, 300, 291, 820, 3124, 498, 291, 2378, 380, 3737, 926, 365, 309, 949], "temperature": 0.0, "avg_logprob": -0.23981114534231332, "compression_ratio": 1.6031128404669261, "no_speech_prob": 1.593650631548371e-05}, {"id": 817, "seek": 423428, "start": 4239.599999999999, "end": 4244.24, "text": " during the week because we're increasingly going to be digging deeper and deeper into", "tokens": [1830, 264, 1243, 570, 321, 434, 12980, 516, 281, 312, 17343, 7731, 293, 7731, 666], "temperature": 0.0, "avg_logprob": -0.23981114534231332, "compression_ratio": 1.6031128404669261, "no_speech_prob": 1.593650631548371e-05}, {"id": 818, "seek": 423428, "start": 4244.24, "end": 4247.12, "text": " faster Ion PyTorch libraries.", "tokens": [4663, 286, 266, 9953, 51, 284, 339, 15148, 13], "temperature": 0.0, "avg_logprob": -0.23981114534231332, "compression_ratio": 1.6031128404669261, "no_speech_prob": 1.593650631548371e-05}, {"id": 819, "seek": 423428, "start": 4247.12, "end": 4250.759999999999, "text": " As I say, if you're already a professional coder, know all this stuff, apologies for", "tokens": [1018, 286, 584, 11, 498, 291, 434, 1217, 257, 4843, 17656, 260, 11, 458, 439, 341, 1507, 11, 34929, 337], "temperature": 0.0, "avg_logprob": -0.23981114534231332, "compression_ratio": 1.6031128404669261, "no_speech_prob": 1.593650631548371e-05}, {"id": 820, "seek": 423428, "start": 4250.759999999999, "end": 4253.679999999999, "text": " telling you stuff you already know.", "tokens": [3585, 291, 1507, 291, 1217, 458, 13], "temperature": 0.0, "avg_logprob": -0.23981114534231332, "compression_ratio": 1.6031128404669261, "no_speech_prob": 1.593650631548371e-05}, {"id": 821, "seek": 423428, "start": 4253.679999999999, "end": 4262.4, "text": " So we're going to, well actually, since we did that, let's just talk about Open Image.", "tokens": [407, 321, 434, 516, 281, 11, 731, 767, 11, 1670, 321, 630, 300, 11, 718, 311, 445, 751, 466, 7238, 29903, 13], "temperature": 0.0, "avg_logprob": -0.23981114534231332, "compression_ratio": 1.6031128404669261, "no_speech_prob": 1.593650631548371e-05}, {"id": 822, "seek": 426240, "start": 4262.4, "end": 4266.0, "text": " You'll see that we're using CV2.", "tokens": [509, 603, 536, 300, 321, 434, 1228, 22995, 17, 13], "temperature": 0.0, "avg_logprob": -0.2074610392252604, "compression_ratio": 1.48, "no_speech_prob": 5.173870249564061e-06}, {"id": 823, "seek": 426240, "start": 4266.0, "end": 4272.28, "text": " CV2 is the library, is actually the OpenCV library.", "tokens": [22995, 17, 307, 264, 6405, 11, 307, 767, 264, 7238, 34, 53, 6405, 13], "temperature": 0.0, "avg_logprob": -0.2074610392252604, "compression_ratio": 1.48, "no_speech_prob": 5.173870249564061e-06}, {"id": 824, "seek": 426240, "start": 4272.28, "end": 4275.28, "text": " You might wonder why we're using OpenCV.", "tokens": [509, 1062, 2441, 983, 321, 434, 1228, 7238, 34, 53, 13], "temperature": 0.0, "avg_logprob": -0.2074610392252604, "compression_ratio": 1.48, "no_speech_prob": 5.173870249564061e-06}, {"id": 825, "seek": 426240, "start": 4275.28, "end": 4280.92, "text": " And I want to explain some of the innards of Fast.ai to you because some of them are", "tokens": [400, 286, 528, 281, 2903, 512, 295, 264, 7714, 2287, 295, 15968, 13, 1301, 281, 291, 570, 512, 295, 552, 366], "temperature": 0.0, "avg_logprob": -0.2074610392252604, "compression_ratio": 1.48, "no_speech_prob": 5.173870249564061e-06}, {"id": 826, "seek": 426240, "start": 4280.92, "end": 4285.0, "text": " kind of interesting and might be helpful to you.", "tokens": [733, 295, 1880, 293, 1062, 312, 4961, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.2074610392252604, "compression_ratio": 1.48, "no_speech_prob": 5.173870249564061e-06}, {"id": 827, "seek": 428500, "start": 4285.0, "end": 4295.76, "text": " The standard PyTorchVision library actually uses PyTorch tenses for all of its data augmentation", "tokens": [440, 3832, 9953, 51, 284, 339, 53, 1991, 6405, 767, 4960, 9953, 51, 284, 339, 256, 9085, 337, 439, 295, 1080, 1412, 14501, 19631], "temperature": 0.0, "avg_logprob": -0.19540668669201078, "compression_ratio": 1.518716577540107, "no_speech_prob": 4.222803909215145e-06}, {"id": 828, "seek": 428500, "start": 4295.76, "end": 4298.28, "text": " and stuff like that.", "tokens": [293, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.19540668669201078, "compression_ratio": 1.518716577540107, "no_speech_prob": 4.222803909215145e-06}, {"id": 829, "seek": 428500, "start": 4298.28, "end": 4305.24, "text": " A lot of people use Pillow, the standard Python limiting library.", "tokens": [316, 688, 295, 561, 764, 44656, 305, 11, 264, 3832, 15329, 22083, 6405, 13], "temperature": 0.0, "avg_logprob": -0.19540668669201078, "compression_ratio": 1.518716577540107, "no_speech_prob": 4.222803909215145e-06}, {"id": 830, "seek": 428500, "start": 4305.24, "end": 4308.2, "text": " I did a lot of testing of all of these.", "tokens": [286, 630, 257, 688, 295, 4997, 295, 439, 295, 613, 13], "temperature": 0.0, "avg_logprob": -0.19540668669201078, "compression_ratio": 1.518716577540107, "no_speech_prob": 4.222803909215145e-06}, {"id": 831, "seek": 428500, "start": 4308.2, "end": 4314.02, "text": " I found OpenCV was about 5-10 times faster than TorchVision.", "tokens": [286, 1352, 7238, 34, 53, 390, 466, 1025, 12, 3279, 1413, 4663, 813, 7160, 339, 53, 1991, 13], "temperature": 0.0, "avg_logprob": -0.19540668669201078, "compression_ratio": 1.518716577540107, "no_speech_prob": 4.222803909215145e-06}, {"id": 832, "seek": 431402, "start": 4314.02, "end": 4318.6, "text": " So early on, I actually teamed up with one of the students from an earlier class to do", "tokens": [407, 2440, 322, 11, 286, 767, 47426, 493, 365, 472, 295, 264, 1731, 490, 364, 3071, 1508, 281, 360], "temperature": 0.0, "avg_logprob": -0.21241934482867902, "compression_ratio": 1.5887096774193548, "no_speech_prob": 6.540376944030868e-06}, {"id": 833, "seek": 431402, "start": 4318.6, "end": 4321.68, "text": " the Planet Labs satellite competition back when that was on.", "tokens": [264, 22146, 40047, 16016, 6211, 646, 562, 300, 390, 322, 13], "temperature": 0.0, "avg_logprob": -0.21241934482867902, "compression_ratio": 1.5887096774193548, "no_speech_prob": 6.540376944030868e-06}, {"id": 834, "seek": 431402, "start": 4321.68, "end": 4329.320000000001, "text": " And we used TorchVision and because it was so slow, we could only get like 25% GPU utilization", "tokens": [400, 321, 1143, 7160, 339, 53, 1991, 293, 570, 309, 390, 370, 2964, 11, 321, 727, 787, 483, 411, 3552, 4, 18407, 37074], "temperature": 0.0, "avg_logprob": -0.21241934482867902, "compression_ratio": 1.5887096774193548, "no_speech_prob": 6.540376944030868e-06}, {"id": 835, "seek": 431402, "start": 4329.320000000001, "end": 4332.56, "text": " because we were doing a lot of data augmentation.", "tokens": [570, 321, 645, 884, 257, 688, 295, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.21241934482867902, "compression_ratio": 1.5887096774193548, "no_speech_prob": 6.540376944030868e-06}, {"id": 836, "seek": 431402, "start": 4332.56, "end": 4336.400000000001, "text": " And so then I used the profiler to find out what was going on and realized it was all", "tokens": [400, 370, 550, 286, 1143, 264, 1740, 5441, 281, 915, 484, 437, 390, 516, 322, 293, 5334, 309, 390, 439], "temperature": 0.0, "avg_logprob": -0.21241934482867902, "compression_ratio": 1.5887096774193548, "no_speech_prob": 6.540376944030868e-06}, {"id": 837, "seek": 431402, "start": 4336.400000000001, "end": 4340.76, "text": " in TorchVision.", "tokens": [294, 7160, 339, 53, 1991, 13], "temperature": 0.0, "avg_logprob": -0.21241934482867902, "compression_ratio": 1.5887096774193548, "no_speech_prob": 6.540376944030868e-06}, {"id": 838, "seek": 434076, "start": 4340.76, "end": 4347.8, "text": " Pillow or PIL is quite a bit faster, but it's not as fast as OpenCV.", "tokens": [44656, 305, 420, 430, 4620, 307, 1596, 257, 857, 4663, 11, 457, 309, 311, 406, 382, 2370, 382, 7238, 34, 53, 13], "temperature": 0.0, "avg_logprob": -0.2028905777704148, "compression_ratio": 1.5247524752475248, "no_speech_prob": 5.507562036655145e-06}, {"id": 839, "seek": 434076, "start": 4347.8, "end": 4354.6, "text": " It also is not nearly as thread safe.", "tokens": [467, 611, 307, 406, 6217, 382, 7207, 3273, 13], "temperature": 0.0, "avg_logprob": -0.2028905777704148, "compression_ratio": 1.5247524752475248, "no_speech_prob": 5.507562036655145e-06}, {"id": 840, "seek": 434076, "start": 4354.6, "end": 4360.76, "text": " So I actually talked to the guy who developed the thing that, Python has this thing called", "tokens": [407, 286, 767, 2825, 281, 264, 2146, 567, 4743, 264, 551, 300, 11, 15329, 575, 341, 551, 1219], "temperature": 0.0, "avg_logprob": -0.2028905777704148, "compression_ratio": 1.5247524752475248, "no_speech_prob": 5.507562036655145e-06}, {"id": 841, "seek": 434076, "start": 4360.76, "end": 4368.84, "text": " the global interpreter lock, which basically means that two threads can't do Pythonic things", "tokens": [264, 4338, 34132, 4017, 11, 597, 1936, 1355, 300, 732, 19314, 393, 380, 360, 9953, 392, 11630, 721], "temperature": 0.0, "avg_logprob": -0.2028905777704148, "compression_ratio": 1.5247524752475248, "no_speech_prob": 5.507562036655145e-06}, {"id": 842, "seek": 434076, "start": 4368.84, "end": 4370.56, "text": " at the same time.", "tokens": [412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.2028905777704148, "compression_ratio": 1.5247524752475248, "no_speech_prob": 5.507562036655145e-06}, {"id": 843, "seek": 437056, "start": 4370.56, "end": 4376.080000000001, "text": " It makes Python a really shitty language actually for modern programming, but we're stuck with", "tokens": [467, 1669, 15329, 257, 534, 30748, 2856, 767, 337, 4363, 9410, 11, 457, 321, 434, 5541, 365], "temperature": 0.0, "avg_logprob": -0.18265008413663475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 9.972735824703705e-06}, {"id": 844, "seek": 437056, "start": 4376.080000000001, "end": 4377.080000000001, "text": " it.", "tokens": [309, 13], "temperature": 0.0, "avg_logprob": -0.18265008413663475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 9.972735824703705e-06}, {"id": 845, "seek": 437056, "start": 4377.080000000001, "end": 4385.64, "text": " So I spoke to the guy on Twitter who actually made it so that OpenCV releases the GIL.", "tokens": [407, 286, 7179, 281, 264, 2146, 322, 5794, 567, 767, 1027, 309, 370, 300, 7238, 34, 53, 16952, 264, 460, 4620, 13], "temperature": 0.0, "avg_logprob": -0.18265008413663475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 9.972735824703705e-06}, {"id": 846, "seek": 437056, "start": 4385.64, "end": 4391.280000000001, "text": " So one of the reasons the fast AL library is so amazingly fast is because we don't use", "tokens": [407, 472, 295, 264, 4112, 264, 2370, 7056, 6405, 307, 370, 31762, 2370, 307, 570, 321, 500, 380, 764], "temperature": 0.0, "avg_logprob": -0.18265008413663475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 9.972735824703705e-06}, {"id": 847, "seek": 437056, "start": 4391.280000000001, "end": 4394.9400000000005, "text": " multiple processes like every other library does for our data augmentation.", "tokens": [3866, 7555, 411, 633, 661, 6405, 775, 337, 527, 1412, 14501, 19631, 13], "temperature": 0.0, "avg_logprob": -0.18265008413663475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 9.972735824703705e-06}, {"id": 848, "seek": 437056, "start": 4394.9400000000005, "end": 4396.96, "text": " We actually do multiple threads.", "tokens": [492, 767, 360, 3866, 19314, 13], "temperature": 0.0, "avg_logprob": -0.18265008413663475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 9.972735824703705e-06}, {"id": 849, "seek": 439696, "start": 4396.96, "end": 4401.0, "text": " And the reason we can do multiple threads is because we use OpenCV.", "tokens": [400, 264, 1778, 321, 393, 360, 3866, 19314, 307, 570, 321, 764, 7238, 34, 53, 13], "temperature": 0.0, "avg_logprob": -0.1840454677365861, "compression_ratio": 1.6651785714285714, "no_speech_prob": 4.2228093661833555e-06}, {"id": 850, "seek": 439696, "start": 4401.0, "end": 4408.4, "text": " Unfortunately OpenCV is like a really shitty API, it's kind of inscrutable, a lot of stuff", "tokens": [8590, 7238, 34, 53, 307, 411, 257, 534, 30748, 9362, 11, 309, 311, 733, 295, 1028, 10757, 32148, 11, 257, 688, 295, 1507], "temperature": 0.0, "avg_logprob": -0.1840454677365861, "compression_ratio": 1.6651785714285714, "no_speech_prob": 4.2228093661833555e-06}, {"id": 851, "seek": 439696, "start": 4408.4, "end": 4410.4, "text": " it does is poorly documented.", "tokens": [309, 775, 307, 22271, 23007, 13], "temperature": 0.0, "avg_logprob": -0.1840454677365861, "compression_ratio": 1.6651785714285714, "no_speech_prob": 4.2228093661833555e-06}, {"id": 852, "seek": 439696, "start": 4410.4, "end": 4418.72, "text": " When I say poorly documented, it's documented, but like in really obtuse kind of ways.", "tokens": [1133, 286, 584, 22271, 23007, 11, 309, 311, 23007, 11, 457, 411, 294, 534, 7464, 438, 733, 295, 2098, 13], "temperature": 0.0, "avg_logprob": -0.1840454677365861, "compression_ratio": 1.6651785714285714, "no_speech_prob": 4.2228093661833555e-06}, {"id": 853, "seek": 439696, "start": 4418.72, "end": 4424.28, "text": " So that's why I try to make it so like no one using fast AI needs to know that it's", "tokens": [407, 300, 311, 983, 286, 853, 281, 652, 309, 370, 411, 572, 472, 1228, 2370, 7318, 2203, 281, 458, 300, 309, 311], "temperature": 0.0, "avg_logprob": -0.1840454677365861, "compression_ratio": 1.6651785714285714, "no_speech_prob": 4.2228093661833555e-06}, {"id": 854, "seek": 439696, "start": 4424.28, "end": 4425.28, "text": " using OpenCV.", "tokens": [1228, 7238, 34, 53, 13], "temperature": 0.0, "avg_logprob": -0.1840454677365861, "compression_ratio": 1.6651785714285714, "no_speech_prob": 4.2228093661833555e-06}, {"id": 855, "seek": 442528, "start": 4425.28, "end": 4428.8, "text": " Like if you want to open an image, do you really need to know that you have to pass", "tokens": [1743, 498, 291, 528, 281, 1269, 364, 3256, 11, 360, 291, 534, 643, 281, 458, 300, 291, 362, 281, 1320], "temperature": 0.0, "avg_logprob": -0.18494680286508747, "compression_ratio": 1.7773109243697478, "no_speech_prob": 8.9395716713625e-06}, {"id": 856, "seek": 442528, "start": 4428.8, "end": 4431.719999999999, "text": " these flags to open to actually make it work?", "tokens": [613, 23265, 281, 1269, 281, 767, 652, 309, 589, 30], "temperature": 0.0, "avg_logprob": -0.18494680286508747, "compression_ratio": 1.7773109243697478, "no_speech_prob": 8.9395716713625e-06}, {"id": 857, "seek": 442528, "start": 4431.719999999999, "end": 4436.36, "text": " Do you actually need to know that if the reading fails, it doesn't show an exception, it just", "tokens": [1144, 291, 767, 643, 281, 458, 300, 498, 264, 3760, 18199, 11, 309, 1177, 380, 855, 364, 11183, 11, 309, 445], "temperature": 0.0, "avg_logprob": -0.18494680286508747, "compression_ratio": 1.7773109243697478, "no_speech_prob": 8.9395716713625e-06}, {"id": 858, "seek": 442528, "start": 4436.36, "end": 4438.96, "text": " silently returns none?", "tokens": [40087, 11247, 6022, 30], "temperature": 0.0, "avg_logprob": -0.18494680286508747, "compression_ratio": 1.7773109243697478, "no_speech_prob": 8.9395716713625e-06}, {"id": 859, "seek": 442528, "start": 4438.96, "end": 4444.2, "text": " It's these kinds of things that we try to do to actually make it work nicely.", "tokens": [467, 311, 613, 3685, 295, 721, 300, 321, 853, 281, 360, 281, 767, 652, 309, 589, 9594, 13], "temperature": 0.0, "avg_logprob": -0.18494680286508747, "compression_ratio": 1.7773109243697478, "no_speech_prob": 8.9395716713625e-06}, {"id": 860, "seek": 442528, "start": 4444.2, "end": 4449.88, "text": " But as you start to dig into it, you'll find yourself in these places and you'll want to", "tokens": [583, 382, 291, 722, 281, 2528, 666, 309, 11, 291, 603, 915, 1803, 294, 613, 3190, 293, 291, 603, 528, 281], "temperature": 0.0, "avg_logprob": -0.18494680286508747, "compression_ratio": 1.7773109243697478, "no_speech_prob": 8.9395716713625e-06}, {"id": 861, "seek": 442528, "start": 4449.88, "end": 4450.88, "text": " know why.", "tokens": [458, 983, 13], "temperature": 0.0, "avg_logprob": -0.18494680286508747, "compression_ratio": 1.7773109243697478, "no_speech_prob": 8.9395716713625e-06}, {"id": 862, "seek": 445088, "start": 4450.88, "end": 4458.36, "text": " And I mention this in particular to say, don't start using, you know, high torch your data", "tokens": [400, 286, 2152, 341, 294, 1729, 281, 584, 11, 500, 380, 722, 1228, 11, 291, 458, 11, 1090, 27822, 428, 1412], "temperature": 0.0, "avg_logprob": -0.2819089508056641, "compression_ratio": 1.4948453608247423, "no_speech_prob": 1.1842946150864009e-05}, {"id": 863, "seek": 445088, "start": 4458.36, "end": 4463.12, "text": " augmentation, don't start bringing in pillow, you'll find suddenly things slow down horribly", "tokens": [14501, 19631, 11, 500, 380, 722, 5062, 294, 18581, 11, 291, 603, 915, 5800, 721, 2964, 760, 45028], "temperature": 0.0, "avg_logprob": -0.2819089508056641, "compression_ratio": 1.4948453608247423, "no_speech_prob": 1.1842946150864009e-05}, {"id": 864, "seek": 445088, "start": 4463.12, "end": 4465.4400000000005, "text": " or the multi-threading won't work anymore or whatever.", "tokens": [420, 264, 4825, 12, 392, 35908, 1582, 380, 589, 3602, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2819089508056641, "compression_ratio": 1.4948453608247423, "no_speech_prob": 1.1842946150864009e-05}, {"id": 865, "seek": 445088, "start": 4465.4400000000005, "end": 4472.12, "text": " I try to stick to using OpenCV for your processing.", "tokens": [286, 853, 281, 2897, 281, 1228, 7238, 34, 53, 337, 428, 9007, 13], "temperature": 0.0, "avg_logprob": -0.2819089508056641, "compression_ratio": 1.4948453608247423, "no_speech_prob": 1.1842946150864009e-05}, {"id": 866, "seek": 447212, "start": 4472.12, "end": 4486.4, "text": " Okay, so we've got our image, we're just going to use it to demonstrate the Pascal library.", "tokens": [1033, 11, 370, 321, 600, 658, 527, 3256, 11, 321, 434, 445, 516, 281, 764, 309, 281, 11698, 264, 41723, 6405, 13], "temperature": 0.0, "avg_logprob": -0.11760213158347389, "compression_ratio": 1.4825581395348837, "no_speech_prob": 2.1568109787040157e-06}, {"id": 867, "seek": 447212, "start": 4486.4, "end": 4490.08, "text": " And so the next thing I wanted to show you in terms of like important coding stuff we're", "tokens": [400, 370, 264, 958, 551, 286, 1415, 281, 855, 291, 294, 2115, 295, 411, 1021, 17720, 1507, 321, 434], "temperature": 0.0, "avg_logprob": -0.11760213158347389, "compression_ratio": 1.4825581395348837, "no_speech_prob": 2.1568109787040157e-06}, {"id": 868, "seek": 447212, "start": 4490.08, "end": 4495.9, "text": " going to be using throughout this course is using Matplotlib a lot better.", "tokens": [516, 281, 312, 1228, 3710, 341, 1164, 307, 1228, 6789, 564, 310, 38270, 257, 688, 1101, 13], "temperature": 0.0, "avg_logprob": -0.11760213158347389, "compression_ratio": 1.4825581395348837, "no_speech_prob": 2.1568109787040157e-06}, {"id": 869, "seek": 449590, "start": 4495.9, "end": 4505.04, "text": " So Matplotlib is so named because it was originally a clone of Matlab's plotting library.", "tokens": [407, 6789, 564, 310, 38270, 307, 370, 4926, 570, 309, 390, 7993, 257, 26506, 295, 6789, 44990, 311, 41178, 6405, 13], "temperature": 0.0, "avg_logprob": -0.17166906992594402, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.9333358522999333e-06}, {"id": 870, "seek": 449590, "start": 4505.04, "end": 4510.48, "text": " Unfortunately, Matlab's plotting library is awful.", "tokens": [8590, 11, 6789, 44990, 311, 41178, 6405, 307, 11232, 13], "temperature": 0.0, "avg_logprob": -0.17166906992594402, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.9333358522999333e-06}, {"id": 871, "seek": 449590, "start": 4510.48, "end": 4516.839999999999, "text": " But at the time, it was what everybody knew.", "tokens": [583, 412, 264, 565, 11, 309, 390, 437, 2201, 2586, 13], "temperature": 0.0, "avg_logprob": -0.17166906992594402, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.9333358522999333e-06}, {"id": 872, "seek": 449590, "start": 4516.839999999999, "end": 4524.48, "text": " So at some point, the Matplotlib folks realized, or they probably always knew, that the Matlab", "tokens": [407, 412, 512, 935, 11, 264, 6789, 564, 310, 38270, 4024, 5334, 11, 420, 436, 1391, 1009, 2586, 11, 300, 264, 6789, 44990], "temperature": 0.0, "avg_logprob": -0.17166906992594402, "compression_ratio": 1.5909090909090908, "no_speech_prob": 1.9333358522999333e-06}, {"id": 873, "seek": 452448, "start": 4524.48, "end": 4526.599999999999, "text": " plotting library is awful.", "tokens": [41178, 6405, 307, 11232, 13], "temperature": 0.0, "avg_logprob": -0.19440578460693358, "compression_ratio": 1.5372549019607844, "no_speech_prob": 5.682358278136235e-06}, {"id": 874, "seek": 452448, "start": 4526.599999999999, "end": 4531.839999999999, "text": " So they added a second API to it, which was an object-oriented API.", "tokens": [407, 436, 3869, 257, 1150, 9362, 281, 309, 11, 597, 390, 364, 2657, 12, 27414, 9362, 13], "temperature": 0.0, "avg_logprob": -0.19440578460693358, "compression_ratio": 1.5372549019607844, "no_speech_prob": 5.682358278136235e-06}, {"id": 875, "seek": 452448, "start": 4531.839999999999, "end": 4537.599999999999, "text": " Unfortunately, because nobody who originally learned Matplotlib learned the OO API, they", "tokens": [8590, 11, 570, 5079, 567, 7993, 3264, 6789, 564, 310, 38270, 3264, 264, 422, 46, 9362, 11, 436], "temperature": 0.0, "avg_logprob": -0.19440578460693358, "compression_ratio": 1.5372549019607844, "no_speech_prob": 5.682358278136235e-06}, {"id": 876, "seek": 452448, "start": 4537.599999999999, "end": 4541.679999999999, "text": " then taught the next generation of people the old Matlab-style API.", "tokens": [550, 5928, 264, 958, 5125, 295, 561, 264, 1331, 6789, 44990, 12, 15014, 9362, 13], "temperature": 0.0, "avg_logprob": -0.19440578460693358, "compression_ratio": 1.5372549019607844, "no_speech_prob": 5.682358278136235e-06}, {"id": 877, "seek": 452448, "start": 4541.679999999999, "end": 4546.82, "text": " And now there's basically no examples or tutorials online I'm aware of that use the much, much", "tokens": [400, 586, 456, 311, 1936, 572, 5110, 420, 17616, 2950, 286, 478, 3650, 295, 300, 764, 264, 709, 11, 709], "temperature": 0.0, "avg_logprob": -0.19440578460693358, "compression_ratio": 1.5372549019607844, "no_speech_prob": 5.682358278136235e-06}, {"id": 878, "seek": 452448, "start": 4546.82, "end": 4550.58, "text": " better, easier to understand, simpler OO API.", "tokens": [1101, 11, 3571, 281, 1223, 11, 18587, 422, 46, 9362, 13], "temperature": 0.0, "avg_logprob": -0.19440578460693358, "compression_ratio": 1.5372549019607844, "no_speech_prob": 5.682358278136235e-06}, {"id": 879, "seek": 455058, "start": 4550.58, "end": 4554.48, "text": " So one of the things I'm going to try and show you, because plotting is so important", "tokens": [407, 472, 295, 264, 721, 286, 478, 516, 281, 853, 293, 855, 291, 11, 570, 41178, 307, 370, 1021], "temperature": 0.0, "avg_logprob": -0.12457266107069707, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.255358701106161e-06}, {"id": 880, "seek": 455058, "start": 4554.48, "end": 4557.64, "text": " in deep learning, is how to use this API.", "tokens": [294, 2452, 2539, 11, 307, 577, 281, 764, 341, 9362, 13], "temperature": 0.0, "avg_logprob": -0.12457266107069707, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.255358701106161e-06}, {"id": 881, "seek": 455058, "start": 4557.64, "end": 4560.8, "text": " And I've discovered some simple little tricks.", "tokens": [400, 286, 600, 6941, 512, 2199, 707, 11733, 13], "temperature": 0.0, "avg_logprob": -0.12457266107069707, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.255358701106161e-06}, {"id": 882, "seek": 455058, "start": 4560.8, "end": 4566.44, "text": " One simple little trick is plot.subplots is just a super handy wrapper.", "tokens": [1485, 2199, 707, 4282, 307, 7542, 13, 30131, 564, 1971, 307, 445, 257, 1687, 13239, 46906, 13], "temperature": 0.0, "avg_logprob": -0.12457266107069707, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.255358701106161e-06}, {"id": 883, "seek": 455058, "start": 4566.44, "end": 4571.04, "text": " I'm going to use it lots, right?", "tokens": [286, 478, 516, 281, 764, 309, 3195, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.12457266107069707, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.255358701106161e-06}, {"id": 884, "seek": 455058, "start": 4571.04, "end": 4573.24, "text": " And what it does is it returns two things.", "tokens": [400, 437, 309, 775, 307, 309, 11247, 732, 721, 13], "temperature": 0.0, "avg_logprob": -0.12457266107069707, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.255358701106161e-06}, {"id": 885, "seek": 455058, "start": 4573.24, "end": 4575.5199999999995, "text": " One of the things you probably won't care about.", "tokens": [1485, 295, 264, 721, 291, 1391, 1582, 380, 1127, 466, 13], "temperature": 0.0, "avg_logprob": -0.12457266107069707, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.255358701106161e-06}, {"id": 886, "seek": 455058, "start": 4575.5199999999995, "end": 4578.5199999999995, "text": " The other thing is an axes object.", "tokens": [440, 661, 551, 307, 364, 35387, 2657, 13], "temperature": 0.0, "avg_logprob": -0.12457266107069707, "compression_ratio": 1.6666666666666667, "no_speech_prob": 5.255358701106161e-06}, {"id": 887, "seek": 457852, "start": 4578.52, "end": 4585.68, "text": " And basically anywhere where you used to say plt.something, you now say ax.something, and", "tokens": [400, 1936, 4992, 689, 291, 1143, 281, 584, 499, 83, 13, 31681, 11, 291, 586, 584, 6360, 13, 31681, 11, 293], "temperature": 0.0, "avg_logprob": -0.15365320570925448, "compression_ratio": 1.6650485436893203, "no_speech_prob": 9.223360393662006e-06}, {"id": 888, "seek": 457852, "start": 4585.68, "end": 4590.6, "text": " it will now do that plotting to that particular subplot.", "tokens": [309, 486, 586, 360, 300, 41178, 281, 300, 1729, 1422, 564, 310, 13], "temperature": 0.0, "avg_logprob": -0.15365320570925448, "compression_ratio": 1.6650485436893203, "no_speech_prob": 9.223360393662006e-06}, {"id": 889, "seek": 457852, "start": 4590.6, "end": 4595.72, "text": " So a lot of the time you'll use this, or I'll use this during this course, to kind of plot", "tokens": [407, 257, 688, 295, 264, 565, 291, 603, 764, 341, 11, 420, 286, 603, 764, 341, 1830, 341, 1164, 11, 281, 733, 295, 7542], "temperature": 0.0, "avg_logprob": -0.15365320570925448, "compression_ratio": 1.6650485436893203, "no_speech_prob": 9.223360393662006e-06}, {"id": 890, "seek": 457852, "start": 4595.72, "end": 4601.900000000001, "text": " multiple plots that we can compare next to each other.", "tokens": [3866, 28609, 300, 321, 393, 6794, 958, 281, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.15365320570925448, "compression_ratio": 1.6650485436893203, "no_speech_prob": 9.223360393662006e-06}, {"id": 891, "seek": 457852, "start": 4601.900000000001, "end": 4605.84, "text": " But even in this case, I'm creating a single plot.", "tokens": [583, 754, 294, 341, 1389, 11, 286, 478, 4084, 257, 2167, 7542, 13], "temperature": 0.0, "avg_logprob": -0.15365320570925448, "compression_ratio": 1.6650485436893203, "no_speech_prob": 9.223360393662006e-06}, {"id": 892, "seek": 460584, "start": 4605.84, "end": 4609.76, "text": " But it's just nice to only know one thing, rather than lots of things.", "tokens": [583, 309, 311, 445, 1481, 281, 787, 458, 472, 551, 11, 2831, 813, 3195, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.15377271054971098, "compression_ratio": 1.614678899082569, "no_speech_prob": 5.682402843376622e-06}, {"id": 893, "seek": 460584, "start": 4609.76, "end": 4613.360000000001, "text": " So regardless of whether you're doing one plot or lots of plots, I always start now", "tokens": [407, 10060, 295, 1968, 291, 434, 884, 472, 7542, 420, 3195, 295, 28609, 11, 286, 1009, 722, 586], "temperature": 0.0, "avg_logprob": -0.15377271054971098, "compression_ratio": 1.614678899082569, "no_speech_prob": 5.682402843376622e-06}, {"id": 894, "seek": 460584, "start": 4613.360000000001, "end": 4617.04, "text": " with this, plot.subplots.", "tokens": [365, 341, 11, 7542, 13, 30131, 564, 1971, 13], "temperature": 0.0, "avg_logprob": -0.15377271054971098, "compression_ratio": 1.614678899082569, "no_speech_prob": 5.682402843376622e-06}, {"id": 895, "seek": 460584, "start": 4617.04, "end": 4623.4400000000005, "text": " And the nice thing is that this way I can pass in an axes object if I want to plot it", "tokens": [400, 264, 1481, 551, 307, 300, 341, 636, 286, 393, 1320, 294, 364, 35387, 2657, 498, 286, 528, 281, 7542, 309], "temperature": 0.0, "avg_logprob": -0.15377271054971098, "compression_ratio": 1.614678899082569, "no_speech_prob": 5.682402843376622e-06}, {"id": 896, "seek": 460584, "start": 4623.4400000000005, "end": 4631.02, "text": " into a figure I've already created, or if it hasn't been passed in, I can create one.", "tokens": [666, 257, 2573, 286, 600, 1217, 2942, 11, 420, 498, 309, 6132, 380, 668, 4678, 294, 11, 286, 393, 1884, 472, 13], "temperature": 0.0, "avg_logprob": -0.15377271054971098, "compression_ratio": 1.614678899082569, "no_speech_prob": 5.682402843376622e-06}, {"id": 897, "seek": 463102, "start": 4631.02, "end": 4637.120000000001, "text": " So this is also a nice way to make your matplotlib functions really versatile.", "tokens": [407, 341, 307, 611, 257, 1481, 636, 281, 652, 428, 3803, 564, 310, 38270, 6828, 534, 25057, 13], "temperature": 0.0, "avg_logprob": -0.18786545594533285, "compression_ratio": 1.5377777777777777, "no_speech_prob": 3.555969669832848e-06}, {"id": 898, "seek": 463102, "start": 4637.120000000001, "end": 4640.9400000000005, "text": " You'll kind of see this used throughout this course.", "tokens": [509, 603, 733, 295, 536, 341, 1143, 3710, 341, 1164, 13], "temperature": 0.0, "avg_logprob": -0.18786545594533285, "compression_ratio": 1.5377777777777777, "no_speech_prob": 3.555969669832848e-06}, {"id": 899, "seek": 463102, "start": 4640.9400000000005, "end": 4645.72, "text": " So now rather than plot.imshow, it's ax.imshow.", "tokens": [407, 586, 2831, 813, 7542, 13, 332, 34436, 11, 309, 311, 6360, 13, 332, 34436, 13], "temperature": 0.0, "avg_logprob": -0.18786545594533285, "compression_ratio": 1.5377777777777777, "no_speech_prob": 3.555969669832848e-06}, {"id": 900, "seek": 463102, "start": 4645.72, "end": 4653.92, "text": " And then rather than kind of weird stateful setting things in the odd-style API, you can", "tokens": [400, 550, 2831, 813, 733, 295, 3657, 1785, 906, 3287, 721, 294, 264, 7401, 12, 15014, 9362, 11, 291, 393], "temperature": 0.0, "avg_logprob": -0.18786545594533285, "compression_ratio": 1.5377777777777777, "no_speech_prob": 3.555969669832848e-06}, {"id": 901, "seek": 463102, "start": 4653.92, "end": 4660.040000000001, "text": " now use OOs, get access that returns an object, set visible, sets a property.", "tokens": [586, 764, 422, 31376, 11, 483, 2105, 300, 11247, 364, 2657, 11, 992, 8974, 11, 6352, 257, 4707, 13], "temperature": 0.0, "avg_logprob": -0.18786545594533285, "compression_ratio": 1.5377777777777777, "no_speech_prob": 3.555969669832848e-06}, {"id": 902, "seek": 466004, "start": 4660.04, "end": 4662.96, "text": " It's all pretty normal, straightforward stuff.", "tokens": [467, 311, 439, 1238, 2710, 11, 15325, 1507, 13], "temperature": 0.0, "avg_logprob": -0.1633985500143032, "compression_ratio": 1.6123348017621146, "no_speech_prob": 5.862770194653422e-06}, {"id": 903, "seek": 466004, "start": 4662.96, "end": 4669.48, "text": " So once you start getting the hang of a small number of these OO matplotlib things, hopefully", "tokens": [407, 1564, 291, 722, 1242, 264, 3967, 295, 257, 1359, 1230, 295, 613, 422, 46, 3803, 564, 310, 38270, 721, 11, 4696], "temperature": 0.0, "avg_logprob": -0.1633985500143032, "compression_ratio": 1.6123348017621146, "no_speech_prob": 5.862770194653422e-06}, {"id": 904, "seek": 466004, "start": 4669.48, "end": 4671.44, "text": " you'll find life a lot easier.", "tokens": [291, 603, 915, 993, 257, 688, 3571, 13], "temperature": 0.0, "avg_logprob": -0.1633985500143032, "compression_ratio": 1.6123348017621146, "no_speech_prob": 5.862770194653422e-06}, {"id": 905, "seek": 466004, "start": 4671.44, "end": 4674.76, "text": " So I'm going to show you a few right now.", "tokens": [407, 286, 478, 516, 281, 855, 291, 257, 1326, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.1633985500143032, "compression_ratio": 1.6123348017621146, "no_speech_prob": 5.862770194653422e-06}, {"id": 906, "seek": 466004, "start": 4674.76, "end": 4679.48, "text": " So let me show you a cool example, what I think is a cool example.", "tokens": [407, 718, 385, 855, 291, 257, 1627, 1365, 11, 437, 286, 519, 307, 257, 1627, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1633985500143032, "compression_ratio": 1.6123348017621146, "no_speech_prob": 5.862770194653422e-06}, {"id": 907, "seek": 466004, "start": 4679.48, "end": 4685.36, "text": " So one thing that kind of drives me crazy with people putting text on images, whether", "tokens": [407, 472, 551, 300, 733, 295, 11754, 385, 3219, 365, 561, 3372, 2487, 322, 5267, 11, 1968], "temperature": 0.0, "avg_logprob": -0.1633985500143032, "compression_ratio": 1.6123348017621146, "no_speech_prob": 5.862770194653422e-06}, {"id": 908, "seek": 468536, "start": 4685.36, "end": 4691.88, "text": " it be subtitles on TV, or people doing stuff with computer vision, is that it's like white", "tokens": [309, 312, 42045, 322, 3558, 11, 420, 561, 884, 1507, 365, 3820, 5201, 11, 307, 300, 309, 311, 411, 2418], "temperature": 0.0, "avg_logprob": -0.12389913006363629, "compression_ratio": 1.6906779661016949, "no_speech_prob": 6.33917807135731e-06}, {"id": 909, "seek": 468536, "start": 4691.88, "end": 4696.88, "text": " text on a white background, or black text on a dark background, and you can't read it.", "tokens": [2487, 322, 257, 2418, 3678, 11, 420, 2211, 2487, 322, 257, 2877, 3678, 11, 293, 291, 393, 380, 1401, 309, 13], "temperature": 0.0, "avg_logprob": -0.12389913006363629, "compression_ratio": 1.6906779661016949, "no_speech_prob": 6.33917807135731e-06}, {"id": 910, "seek": 468536, "start": 4696.88, "end": 4702.679999999999, "text": " And so a really simple thing that I like to do every time I draw on an image is to either", "tokens": [400, 370, 257, 534, 2199, 551, 300, 286, 411, 281, 360, 633, 565, 286, 2642, 322, 364, 3256, 307, 281, 2139], "temperature": 0.0, "avg_logprob": -0.12389913006363629, "compression_ratio": 1.6906779661016949, "no_speech_prob": 6.33917807135731e-06}, {"id": 911, "seek": 468536, "start": 4702.679999999999, "end": 4708.759999999999, "text": " make my text and boxes white with a little black border, or vice versa.", "tokens": [652, 452, 2487, 293, 9002, 2418, 365, 257, 707, 2211, 7838, 11, 420, 11964, 25650, 13], "temperature": 0.0, "avg_logprob": -0.12389913006363629, "compression_ratio": 1.6906779661016949, "no_speech_prob": 6.33917807135731e-06}, {"id": 912, "seek": 468536, "start": 4708.759999999999, "end": 4713.04, "text": " And so here's a cool little thing you can do in matplotlib.", "tokens": [400, 370, 510, 311, 257, 1627, 707, 551, 291, 393, 360, 294, 3803, 564, 310, 38270, 13], "temperature": 0.0, "avg_logprob": -0.12389913006363629, "compression_ratio": 1.6906779661016949, "no_speech_prob": 6.33917807135731e-06}, {"id": 913, "seek": 471304, "start": 4713.04, "end": 4722.96, "text": " You can take a matplotlib plotting object, and you can go set path effects, and say add", "tokens": [509, 393, 747, 257, 3803, 564, 310, 38270, 41178, 2657, 11, 293, 291, 393, 352, 992, 3100, 5065, 11, 293, 584, 909], "temperature": 0.0, "avg_logprob": -0.15292185003107245, "compression_ratio": 1.6706586826347305, "no_speech_prob": 4.7108933358686045e-06}, {"id": 914, "seek": 471304, "start": 4722.96, "end": 4727.56, "text": " a black stroke around it.", "tokens": [257, 2211, 12403, 926, 309, 13], "temperature": 0.0, "avg_logprob": -0.15292185003107245, "compression_ratio": 1.6706586826347305, "no_speech_prob": 4.7108933358686045e-06}, {"id": 915, "seek": 471304, "start": 4727.56, "end": 4734.1, "text": " And you can see that then when you draw that, it doesn't matter that here it's white on", "tokens": [400, 291, 393, 536, 300, 550, 562, 291, 2642, 300, 11, 309, 1177, 380, 1871, 300, 510, 309, 311, 2418, 322], "temperature": 0.0, "avg_logprob": -0.15292185003107245, "compression_ratio": 1.6706586826347305, "no_speech_prob": 4.7108933358686045e-06}, {"id": 916, "seek": 471304, "start": 4734.1, "end": 4739.08, "text": " a white background, or here it's on a black background, it's equally visible.", "tokens": [257, 2418, 3678, 11, 420, 510, 309, 311, 322, 257, 2211, 3678, 11, 309, 311, 12309, 8974, 13], "temperature": 0.0, "avg_logprob": -0.15292185003107245, "compression_ratio": 1.6706586826347305, "no_speech_prob": 4.7108933358686045e-06}, {"id": 917, "seek": 473908, "start": 4739.08, "end": 4744.36, "text": " And I know it's a simple little thing, but it kind of just makes life so much better", "tokens": [400, 286, 458, 309, 311, 257, 2199, 707, 551, 11, 457, 309, 733, 295, 445, 1669, 993, 370, 709, 1101], "temperature": 0.0, "avg_logprob": -0.15711048527767785, "compression_ratio": 1.5947136563876652, "no_speech_prob": 7.766891940264031e-06}, {"id": 918, "seek": 473908, "start": 4744.36, "end": 4748.44, "text": " when you can actually see your bounding boxes and actually read the text.", "tokens": [562, 291, 393, 767, 536, 428, 5472, 278, 9002, 293, 767, 1401, 264, 2487, 13], "temperature": 0.0, "avg_logprob": -0.15711048527767785, "compression_ratio": 1.5947136563876652, "no_speech_prob": 7.766891940264031e-06}, {"id": 919, "seek": 473908, "start": 4748.44, "end": 4757.8, "text": " So you can see, rather than just saying add a rectangle, I get the object that it creates,", "tokens": [407, 291, 393, 536, 11, 2831, 813, 445, 1566, 909, 257, 21930, 11, 286, 483, 264, 2657, 300, 309, 7829, 11], "temperature": 0.0, "avg_logprob": -0.15711048527767785, "compression_ratio": 1.5947136563876652, "no_speech_prob": 7.766891940264031e-06}, {"id": 920, "seek": 473908, "start": 4757.8, "end": 4759.76, "text": " and then pass that object to draw an outline.", "tokens": [293, 550, 1320, 300, 2657, 281, 2642, 364, 16387, 13], "temperature": 0.0, "avg_logprob": -0.15711048527767785, "compression_ratio": 1.5947136563876652, "no_speech_prob": 7.766891940264031e-06}, {"id": 921, "seek": 473908, "start": 4759.76, "end": 4764.88, "text": " Now everything I do, I'm going to get this nice path effect on it.", "tokens": [823, 1203, 286, 360, 11, 286, 478, 516, 281, 483, 341, 1481, 3100, 1802, 322, 309, 13], "temperature": 0.0, "avg_logprob": -0.15711048527767785, "compression_ratio": 1.5947136563876652, "no_speech_prob": 7.766891940264031e-06}, {"id": 922, "seek": 476488, "start": 4764.88, "end": 4770.32, "text": " You can see matplotlib is a perfectly convenient way of drawing stuff.", "tokens": [509, 393, 536, 3803, 564, 310, 38270, 307, 257, 6239, 10851, 636, 295, 6316, 1507, 13], "temperature": 0.0, "avg_logprob": -0.17174702938472, "compression_ratio": 1.6738197424892705, "no_speech_prob": 4.425479346537031e-06}, {"id": 923, "seek": 476488, "start": 4770.32, "end": 4777.28, "text": " So when I want to draw a rectangle, matplotlib calls that a patch, and then you can pass", "tokens": [407, 562, 286, 528, 281, 2642, 257, 21930, 11, 3803, 564, 310, 38270, 5498, 300, 257, 9972, 11, 293, 550, 291, 393, 1320], "temperature": 0.0, "avg_logprob": -0.17174702938472, "compression_ratio": 1.6738197424892705, "no_speech_prob": 4.425479346537031e-06}, {"id": 924, "seek": 476488, "start": 4777.28, "end": 4779.86, "text": " in all different kinds of patches.", "tokens": [294, 439, 819, 3685, 295, 26531, 13], "temperature": 0.0, "avg_logprob": -0.17174702938472, "compression_ratio": 1.6738197424892705, "no_speech_prob": 4.425479346537031e-06}, {"id": 925, "seek": 476488, "start": 4779.86, "end": 4785.64, "text": " So here's, again, rather than having to remember all that every time, please stick it in a", "tokens": [407, 510, 311, 11, 797, 11, 2831, 813, 1419, 281, 1604, 439, 300, 633, 565, 11, 1767, 2897, 309, 294, 257], "temperature": 0.0, "avg_logprob": -0.17174702938472, "compression_ratio": 1.6738197424892705, "no_speech_prob": 4.425479346537031e-06}, {"id": 926, "seek": 476488, "start": 4785.64, "end": 4786.64, "text": " function.", "tokens": [2445, 13], "temperature": 0.0, "avg_logprob": -0.17174702938472, "compression_ratio": 1.6738197424892705, "no_speech_prob": 4.425479346537031e-06}, {"id": 927, "seek": 476488, "start": 4786.64, "end": 4789.72, "text": " And now you can use that function every time.", "tokens": [400, 586, 291, 393, 764, 300, 2445, 633, 565, 13], "temperature": 0.0, "avg_logprob": -0.17174702938472, "compression_ratio": 1.6738197424892705, "no_speech_prob": 4.425479346537031e-06}, {"id": 928, "seek": 476488, "start": 4789.72, "end": 4792.16, "text": " You don't have to put it in a library somewhere.", "tokens": [509, 500, 380, 362, 281, 829, 309, 294, 257, 6405, 4079, 13], "temperature": 0.0, "avg_logprob": -0.17174702938472, "compression_ratio": 1.6738197424892705, "no_speech_prob": 4.425479346537031e-06}, {"id": 929, "seek": 479216, "start": 4792.16, "end": 4795.42, "text": " I always put lots of functions inside my notebook.", "tokens": [286, 1009, 829, 3195, 295, 6828, 1854, 452, 21060, 13], "temperature": 0.0, "avg_logprob": -0.16025006041234854, "compression_ratio": 1.5401785714285714, "no_speech_prob": 3.966977146774298e-06}, {"id": 930, "seek": 479216, "start": 4795.42, "end": 4801.36, "text": " If I use it in like 3 notebooks, then I know it's useful enough that I'll stick it in a", "tokens": [759, 286, 764, 309, 294, 411, 805, 43782, 11, 550, 286, 458, 309, 311, 4420, 1547, 300, 286, 603, 2897, 309, 294, 257], "temperature": 0.0, "avg_logprob": -0.16025006041234854, "compression_ratio": 1.5401785714285714, "no_speech_prob": 3.966977146774298e-06}, {"id": 931, "seek": 479216, "start": 4801.36, "end": 4805.16, "text": " separate library.", "tokens": [4994, 6405, 13], "temperature": 0.0, "avg_logprob": -0.16025006041234854, "compression_ratio": 1.5401785714285714, "no_speech_prob": 3.966977146774298e-06}, {"id": 932, "seek": 479216, "start": 4805.16, "end": 4806.88, "text": " You can draw text.", "tokens": [509, 393, 2642, 2487, 13], "temperature": 0.0, "avg_logprob": -0.16025006041234854, "compression_ratio": 1.5401785714285714, "no_speech_prob": 3.966977146774298e-06}, {"id": 933, "seek": 479216, "start": 4806.88, "end": 4811.76, "text": " And notice all of these take an axis object, so this is always going to be added to whatever", "tokens": [400, 3449, 439, 295, 613, 747, 364, 10298, 2657, 11, 370, 341, 307, 1009, 516, 281, 312, 3869, 281, 2035], "temperature": 0.0, "avg_logprob": -0.16025006041234854, "compression_ratio": 1.5401785714285714, "no_speech_prob": 3.966977146774298e-06}, {"id": 934, "seek": 479216, "start": 4811.76, "end": 4813.48, "text": " thing I want to add it to.", "tokens": [551, 286, 528, 281, 909, 309, 281, 13], "temperature": 0.0, "avg_logprob": -0.16025006041234854, "compression_ratio": 1.5401785714285714, "no_speech_prob": 3.966977146774298e-06}, {"id": 935, "seek": 479216, "start": 4813.48, "end": 4818.24, "text": " So I can add text, and draw an outline around it.", "tokens": [407, 286, 393, 909, 2487, 11, 293, 2642, 364, 16387, 926, 309, 13], "temperature": 0.0, "avg_logprob": -0.16025006041234854, "compression_ratio": 1.5401785714285714, "no_speech_prob": 3.966977146774298e-06}, {"id": 936, "seek": 481824, "start": 4818.24, "end": 4826.4, "text": " So having done all that, I can now take my show image, and notice here the show image,", "tokens": [407, 1419, 1096, 439, 300, 11, 286, 393, 586, 747, 452, 855, 3256, 11, 293, 3449, 510, 264, 855, 3256, 11], "temperature": 0.0, "avg_logprob": -0.16307632402441968, "compression_ratio": 1.7074468085106382, "no_speech_prob": 2.368790546825039e-06}, {"id": 937, "seek": 481824, "start": 4826.4, "end": 4829.88, "text": " if you didn't pass it an axis, it returns the axis it created.", "tokens": [498, 291, 994, 380, 1320, 309, 364, 10298, 11, 309, 11247, 264, 10298, 309, 2942, 13], "temperature": 0.0, "avg_logprob": -0.16307632402441968, "compression_ratio": 1.7074468085106382, "no_speech_prob": 2.368790546825039e-06}, {"id": 938, "seek": 481824, "start": 4829.88, "end": 4835.599999999999, "text": " So show image returns the axis that image is on, I then turn my bounding box into height", "tokens": [407, 855, 3256, 11247, 264, 10298, 300, 3256, 307, 322, 11, 286, 550, 1261, 452, 5472, 278, 2424, 666, 6681], "temperature": 0.0, "avg_logprob": -0.16307632402441968, "compression_ratio": 1.7074468085106382, "no_speech_prob": 2.368790546825039e-06}, {"id": 939, "seek": 481824, "start": 4835.599999999999, "end": 4839.08, "text": " and width for this particular image's bounding box.", "tokens": [293, 11402, 337, 341, 1729, 3256, 311, 5472, 278, 2424, 13], "temperature": 0.0, "avg_logprob": -0.16307632402441968, "compression_ratio": 1.7074468085106382, "no_speech_prob": 2.368790546825039e-06}, {"id": 940, "seek": 481824, "start": 4839.08, "end": 4842.32, "text": " I can then draw the rectangle.", "tokens": [286, 393, 550, 2642, 264, 21930, 13], "temperature": 0.0, "avg_logprob": -0.16307632402441968, "compression_ratio": 1.7074468085106382, "no_speech_prob": 2.368790546825039e-06}, {"id": 941, "seek": 484232, "start": 4842.32, "end": 4850.44, "text": " I can then draw the text in the top left corner, so remember the bounding box x and y are the", "tokens": [286, 393, 550, 2642, 264, 2487, 294, 264, 1192, 1411, 4538, 11, 370, 1604, 264, 5472, 278, 2424, 2031, 293, 288, 366, 264], "temperature": 0.0, "avg_logprob": -0.16352245330810547, "compression_ratio": 1.7692307692307692, "no_speech_prob": 5.422203685157001e-06}, {"id": 942, "seek": 484232, "start": 4850.44, "end": 4858.04, "text": " first 2 coordinates, so b, colon, 2 is the top left.", "tokens": [700, 568, 21056, 11, 370, 272, 11, 8255, 11, 568, 307, 264, 1192, 1411, 13], "temperature": 0.0, "avg_logprob": -0.16352245330810547, "compression_ratio": 1.7692307692307692, "no_speech_prob": 5.422203685157001e-06}, {"id": 943, "seek": 484232, "start": 4858.04, "end": 4864.099999999999, "text": " This is the, remember the tuple contains 2 things, the bounding box and then the class,", "tokens": [639, 307, 264, 11, 1604, 264, 2604, 781, 8306, 568, 721, 11, 264, 5472, 278, 2424, 293, 550, 264, 1508, 11], "temperature": 0.0, "avg_logprob": -0.16352245330810547, "compression_ratio": 1.7692307692307692, "no_speech_prob": 5.422203685157001e-06}, {"id": 944, "seek": 484232, "start": 4864.099999999999, "end": 4865.84, "text": " so this is the class.", "tokens": [370, 341, 307, 264, 1508, 13], "temperature": 0.0, "avg_logprob": -0.16352245330810547, "compression_ratio": 1.7692307692307692, "no_speech_prob": 5.422203685157001e-06}, {"id": 945, "seek": 484232, "start": 4865.84, "end": 4871.86, "text": " And then to get the text of it, I just pass it into my categories list, and there we go.", "tokens": [400, 550, 281, 483, 264, 2487, 295, 309, 11, 286, 445, 1320, 309, 666, 452, 10479, 1329, 11, 293, 456, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.16352245330810547, "compression_ratio": 1.7692307692307692, "no_speech_prob": 5.422203685157001e-06}, {"id": 946, "seek": 487186, "start": 4871.86, "end": 4876.12, "text": " So now that I've got all that set up, I can use that for all of my object detection stuff", "tokens": [407, 586, 300, 286, 600, 658, 439, 300, 992, 493, 11, 286, 393, 764, 300, 337, 439, 295, 452, 2657, 17784, 1507], "temperature": 0.0, "avg_logprob": -0.22074572856609637, "compression_ratio": 1.7522935779816513, "no_speech_prob": 1.1125526725663804e-05}, {"id": 947, "seek": 487186, "start": 4876.12, "end": 4881.5599999999995, "text": " from here on.", "tokens": [490, 510, 322, 13], "temperature": 0.0, "avg_logprob": -0.22074572856609637, "compression_ratio": 1.7522935779816513, "no_speech_prob": 1.1125526725663804e-05}, {"id": 948, "seek": 487186, "start": 4881.5599999999995, "end": 4885.719999999999, "text": " What I really want to do though is to package all that up, so here it is, packaging it all", "tokens": [708, 286, 534, 528, 281, 360, 1673, 307, 281, 7372, 439, 300, 493, 11, 370, 510, 309, 307, 11, 16836, 309, 439], "temperature": 0.0, "avg_logprob": -0.22074572856609637, "compression_ratio": 1.7522935779816513, "no_speech_prob": 1.1125526725663804e-05}, {"id": 949, "seek": 487186, "start": 4885.719999999999, "end": 4892.24, "text": " up, so here's something that draws an image with some annotations, so it shows the image,", "tokens": [493, 11, 370, 510, 311, 746, 300, 20045, 364, 3256, 365, 512, 25339, 763, 11, 370, 309, 3110, 264, 3256, 11], "temperature": 0.0, "avg_logprob": -0.22074572856609637, "compression_ratio": 1.7522935779816513, "no_speech_prob": 1.1125526725663804e-05}, {"id": 950, "seek": 487186, "start": 4892.24, "end": 4896.719999999999, "text": " it goes through each annotation, turns it into height and width, draws a rectangle,", "tokens": [309, 1709, 807, 1184, 48654, 11, 4523, 309, 666, 6681, 293, 11402, 11, 20045, 257, 21930, 11], "temperature": 0.0, "avg_logprob": -0.22074572856609637, "compression_ratio": 1.7522935779816513, "no_speech_prob": 1.1125526725663804e-05}, {"id": 951, "seek": 487186, "start": 4896.719999999999, "end": 4899.24, "text": " draws a text.", "tokens": [20045, 257, 2487, 13], "temperature": 0.0, "avg_logprob": -0.22074572856609637, "compression_ratio": 1.7522935779816513, "no_speech_prob": 1.1125526725663804e-05}, {"id": 952, "seek": 489924, "start": 4899.24, "end": 4906.36, "text": " If you haven't seen this before, each annotation remember contains a bounding box and a class,", "tokens": [759, 291, 2378, 380, 1612, 341, 949, 11, 1184, 48654, 1604, 8306, 257, 5472, 278, 2424, 293, 257, 1508, 11], "temperature": 0.0, "avg_logprob": -0.1772050045906229, "compression_ratio": 1.5774647887323943, "no_speech_prob": 6.643393135163933e-06}, {"id": 953, "seek": 489924, "start": 4906.36, "end": 4914.12, "text": " so rather than going for O in ANN and then going O0, O1, I can destructure it.", "tokens": [370, 2831, 813, 516, 337, 422, 294, 5252, 45, 293, 550, 516, 422, 15, 11, 422, 16, 11, 286, 393, 2677, 2885, 309, 13], "temperature": 0.0, "avg_logprob": -0.1772050045906229, "compression_ratio": 1.5774647887323943, "no_speech_prob": 6.643393135163933e-06}, {"id": 954, "seek": 489924, "start": 4914.12, "end": 4920.0, "text": " This is a destructuring assignment, so if you put something, something on the left,", "tokens": [639, 307, 257, 2677, 1757, 1345, 15187, 11, 370, 498, 291, 829, 746, 11, 746, 322, 264, 1411, 11], "temperature": 0.0, "avg_logprob": -0.1772050045906229, "compression_ratio": 1.5774647887323943, "no_speech_prob": 6.643393135163933e-06}, {"id": 955, "seek": 489924, "start": 4920.0, "end": 4926.32, "text": " then that's going to put the 2 parts of a tuple or a list into those 2 things.", "tokens": [550, 300, 311, 516, 281, 829, 264, 568, 3166, 295, 257, 2604, 781, 420, 257, 1329, 666, 729, 568, 721, 13], "temperature": 0.0, "avg_logprob": -0.1772050045906229, "compression_ratio": 1.5774647887323943, "no_speech_prob": 6.643393135163933e-06}, {"id": 956, "seek": 492632, "start": 4926.32, "end": 4934.12, "text": " So for the bounding box and the class in the annotations, go ahead and do all that, and", "tokens": [407, 337, 264, 5472, 278, 2424, 293, 264, 1508, 294, 264, 25339, 763, 11, 352, 2286, 293, 360, 439, 300, 11, 293], "temperature": 0.0, "avg_logprob": -0.2202811627774625, "compression_ratio": 1.5748502994011977, "no_speech_prob": 2.1233727238723077e-06}, {"id": 957, "seek": 492632, "start": 4934.12, "end": 4940.12, "text": " so then I can then say, okay, draw an image at a particular index by grabbing the image", "tokens": [370, 550, 286, 393, 550, 584, 11, 1392, 11, 2642, 364, 3256, 412, 257, 1729, 8186, 538, 23771, 264, 3256], "temperature": 0.0, "avg_logprob": -0.2202811627774625, "compression_ratio": 1.5748502994011977, "no_speech_prob": 2.1233727238723077e-06}, {"id": 958, "seek": 492632, "start": 4940.12, "end": 4949.179999999999, "text": " ID, opening it up, and then calling that draw, and so it's tested out, and there it is.", "tokens": [7348, 11, 5193, 309, 493, 11, 293, 550, 5141, 300, 2642, 11, 293, 370, 309, 311, 8246, 484, 11, 293, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.2202811627774625, "compression_ratio": 1.5748502994011977, "no_speech_prob": 2.1233727238723077e-06}, {"id": 959, "seek": 494918, "start": 4949.18, "end": 4958.280000000001, "text": " So that kind of seems like quite a few steps, but to me, when you're working with a new", "tokens": [407, 300, 733, 295, 2544, 411, 1596, 257, 1326, 4439, 11, 457, 281, 385, 11, 562, 291, 434, 1364, 365, 257, 777], "temperature": 0.0, "avg_logprob": -0.15671634674072266, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.0845151336980052e-06}, {"id": 960, "seek": 494918, "start": 4958.280000000001, "end": 4966.0, "text": " dataset, getting to the point that you can rapidly explore it, it pays off.", "tokens": [28872, 11, 1242, 281, 264, 935, 300, 291, 393, 12910, 6839, 309, 11, 309, 10604, 766, 13], "temperature": 0.0, "avg_logprob": -0.15671634674072266, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.0845151336980052e-06}, {"id": 961, "seek": 494918, "start": 4966.0, "end": 4969.92, "text": " You'll see as we start building our model, we're going to keep using these functions", "tokens": [509, 603, 536, 382, 321, 722, 2390, 527, 2316, 11, 321, 434, 516, 281, 1066, 1228, 613, 6828], "temperature": 0.0, "avg_logprob": -0.15671634674072266, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.0845151336980052e-06}, {"id": 962, "seek": 494918, "start": 4969.92, "end": 4978.12, "text": " now to kind of see how things are going.", "tokens": [586, 281, 733, 295, 536, 577, 721, 366, 516, 13], "temperature": 0.0, "avg_logprob": -0.15671634674072266, "compression_ratio": 1.5454545454545454, "no_speech_prob": 1.0845151336980052e-06}, {"id": 963, "seek": 497812, "start": 4978.12, "end": 4985.8, "text": " So step 1 from our presentation is to do a classifier.", "tokens": [407, 1823, 502, 490, 527, 5860, 307, 281, 360, 257, 1508, 9902, 13], "temperature": 0.0, "avg_logprob": -0.1474790782718868, "compression_ratio": 1.5108225108225108, "no_speech_prob": 4.9369491534889676e-06}, {"id": 964, "seek": 497812, "start": 4985.8, "end": 4990.44, "text": " And so I think it's always good, like for me, I didn't really have much experience before", "tokens": [400, 370, 286, 519, 309, 311, 1009, 665, 11, 411, 337, 385, 11, 286, 994, 380, 534, 362, 709, 1752, 949], "temperature": 0.0, "avg_logprob": -0.1474790782718868, "compression_ratio": 1.5108225108225108, "no_speech_prob": 4.9369491534889676e-06}, {"id": 965, "seek": 497812, "start": 4990.44, "end": 4996.32, "text": " I started preparing this course a few months ago in doing this kind of object detection", "tokens": [286, 1409, 10075, 341, 1164, 257, 1326, 2493, 2057, 294, 884, 341, 733, 295, 2657, 17784], "temperature": 0.0, "avg_logprob": -0.1474790782718868, "compression_ratio": 1.5108225108225108, "no_speech_prob": 4.9369491534889676e-06}, {"id": 966, "seek": 497812, "start": 4996.32, "end": 5003.32, "text": " stuff, so I was like, alright, I want to get this feeling of, even though it's deep learning,", "tokens": [1507, 11, 370, 286, 390, 411, 11, 5845, 11, 286, 528, 281, 483, 341, 2633, 295, 11, 754, 1673, 309, 311, 2452, 2539, 11], "temperature": 0.0, "avg_logprob": -0.1474790782718868, "compression_ratio": 1.5108225108225108, "no_speech_prob": 4.9369491534889676e-06}, {"id": 967, "seek": 497812, "start": 5003.32, "end": 5005.84, "text": " of continual progress.", "tokens": [295, 1421, 901, 4205, 13], "temperature": 0.0, "avg_logprob": -0.1474790782718868, "compression_ratio": 1.5108225108225108, "no_speech_prob": 4.9369491534889676e-06}, {"id": 968, "seek": 500584, "start": 5005.84, "end": 5008.4400000000005, "text": " So I'm like, what can I make work?", "tokens": [407, 286, 478, 411, 11, 437, 393, 286, 652, 589, 30], "temperature": 0.0, "avg_logprob": -0.20724803996535968, "compression_ratio": 1.6046511627906976, "no_speech_prob": 6.33914214631659e-06}, {"id": 969, "seek": 500584, "start": 5008.4400000000005, "end": 5013.96, "text": " I thought, alright, why don't I find the biggest object in each image and classify it.", "tokens": [286, 1194, 11, 5845, 11, 983, 500, 380, 286, 915, 264, 3880, 2657, 294, 1184, 3256, 293, 33872, 309, 13], "temperature": 0.0, "avg_logprob": -0.20724803996535968, "compression_ratio": 1.6046511627906976, "no_speech_prob": 6.33914214631659e-06}, {"id": 970, "seek": 500584, "start": 5013.96, "end": 5015.64, "text": " I know how to do that.", "tokens": [286, 458, 577, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.20724803996535968, "compression_ratio": 1.6046511627906976, "no_speech_prob": 6.33914214631659e-06}, {"id": 971, "seek": 500584, "start": 5015.64, "end": 5021.8, "text": " So it's like, this is one of the biggest problems I find, particularly with the younger students,", "tokens": [407, 309, 311, 411, 11, 341, 307, 472, 295, 264, 3880, 2740, 286, 915, 11, 4098, 365, 264, 7037, 1731, 11], "temperature": 0.0, "avg_logprob": -0.20724803996535968, "compression_ratio": 1.6046511627906976, "no_speech_prob": 6.33914214631659e-06}, {"id": 972, "seek": 500584, "start": 5021.8, "end": 5028.0, "text": " is they figure out the whole big solution they want, generally which involves a whole", "tokens": [307, 436, 2573, 484, 264, 1379, 955, 3827, 436, 528, 11, 5101, 597, 11626, 257, 1379], "temperature": 0.0, "avg_logprob": -0.20724803996535968, "compression_ratio": 1.6046511627906976, "no_speech_prob": 6.33914214631659e-06}, {"id": 973, "seek": 500584, "start": 5028.0, "end": 5032.72, "text": " lot of new speculative ideas that nobody's ever tried before, and they spend 6 months", "tokens": [688, 295, 777, 49415, 3487, 300, 5079, 311, 1562, 3031, 949, 11, 293, 436, 3496, 1386, 2493], "temperature": 0.0, "avg_logprob": -0.20724803996535968, "compression_ratio": 1.6046511627906976, "no_speech_prob": 6.33914214631659e-06}, {"id": 974, "seek": 503272, "start": 5032.72, "end": 5040.88, "text": " doing it, and then the day before the presentation, none of it works, and they're screwed.", "tokens": [884, 309, 11, 293, 550, 264, 786, 949, 264, 5860, 11, 6022, 295, 309, 1985, 11, 293, 436, 434, 20331, 13], "temperature": 0.0, "avg_logprob": -0.21869382137010077, "compression_ratio": 1.741444866920152, "no_speech_prob": 1.0289267265761737e-05}, {"id": 975, "seek": 503272, "start": 5040.88, "end": 5044.12, "text": " Where else, like I've talked about my approach to Kaggle competitions before, which is like", "tokens": [2305, 1646, 11, 411, 286, 600, 2825, 466, 452, 3109, 281, 48751, 22631, 26185, 949, 11, 597, 307, 411], "temperature": 0.0, "avg_logprob": -0.21869382137010077, "compression_ratio": 1.741444866920152, "no_speech_prob": 1.0289267265761737e-05}, {"id": 976, "seek": 503272, "start": 5044.12, "end": 5045.12, "text": " half an hour every day.", "tokens": [1922, 364, 1773, 633, 786, 13], "temperature": 0.0, "avg_logprob": -0.21869382137010077, "compression_ratio": 1.741444866920152, "no_speech_prob": 1.0289267265761737e-05}, {"id": 977, "seek": 503272, "start": 5045.12, "end": 5051.12, "text": " At the end of that half an hour, submit something, and try and make it a little bit better than", "tokens": [1711, 264, 917, 295, 300, 1922, 364, 1773, 11, 10315, 746, 11, 293, 853, 293, 652, 309, 257, 707, 857, 1101, 813], "temperature": 0.0, "avg_logprob": -0.21869382137010077, "compression_ratio": 1.741444866920152, "no_speech_prob": 1.0289267265761737e-05}, {"id": 978, "seek": 503272, "start": 5051.12, "end": 5052.12, "text": " yesterday's.", "tokens": [5186, 311, 13], "temperature": 0.0, "avg_logprob": -0.21869382137010077, "compression_ratio": 1.741444866920152, "no_speech_prob": 1.0289267265761737e-05}, {"id": 979, "seek": 503272, "start": 5052.12, "end": 5058.08, "text": " So I've kind of tried to do the same thing in preparing this lesson, which is try to", "tokens": [407, 286, 600, 733, 295, 3031, 281, 360, 264, 912, 551, 294, 10075, 341, 6898, 11, 597, 307, 853, 281], "temperature": 0.0, "avg_logprob": -0.21869382137010077, "compression_ratio": 1.741444866920152, "no_speech_prob": 1.0289267265761737e-05}, {"id": 980, "seek": 503272, "start": 5058.08, "end": 5060.76, "text": " create something that's a bit better than the last thing.", "tokens": [1884, 746, 300, 311, 257, 857, 1101, 813, 264, 1036, 551, 13], "temperature": 0.0, "avg_logprob": -0.21869382137010077, "compression_ratio": 1.741444866920152, "no_speech_prob": 1.0289267265761737e-05}, {"id": 981, "seek": 506076, "start": 5060.76, "end": 5067.360000000001, "text": " So the easiest thing I could come up with was my largest item classifier.", "tokens": [407, 264, 12889, 551, 286, 727, 808, 493, 365, 390, 452, 6443, 3174, 1508, 9902, 13], "temperature": 0.0, "avg_logprob": -0.12311500661513385, "compression_ratio": 1.5864197530864197, "no_speech_prob": 4.425472070579417e-06}, {"id": 982, "seek": 506076, "start": 5067.360000000001, "end": 5080.12, "text": " So the first thing I needed to do was to go through each of the bounding boxes in an image", "tokens": [407, 264, 700, 551, 286, 2978, 281, 360, 390, 281, 352, 807, 1184, 295, 264, 5472, 278, 9002, 294, 364, 3256], "temperature": 0.0, "avg_logprob": -0.12311500661513385, "compression_ratio": 1.5864197530864197, "no_speech_prob": 4.425472070579417e-06}, {"id": 983, "seek": 506076, "start": 5080.12, "end": 5083.54, "text": " and get the largest one.", "tokens": [293, 483, 264, 6443, 472, 13], "temperature": 0.0, "avg_logprob": -0.12311500661513385, "compression_ratio": 1.5864197530864197, "no_speech_prob": 4.425472070579417e-06}, {"id": 984, "seek": 506076, "start": 5083.54, "end": 5088.96, "text": " So I actually didn't write that first, I actually wrote this first.", "tokens": [407, 286, 767, 994, 380, 2464, 300, 700, 11, 286, 767, 4114, 341, 700, 13], "temperature": 0.0, "avg_logprob": -0.12311500661513385, "compression_ratio": 1.5864197530864197, "no_speech_prob": 4.425472070579417e-06}, {"id": 985, "seek": 508896, "start": 5088.96, "end": 5094.4800000000005, "text": " So normally I pretend that somebody else has created the exact API I want, and then go", "tokens": [407, 5646, 286, 11865, 300, 2618, 1646, 575, 2942, 264, 1900, 9362, 286, 528, 11, 293, 550, 352], "temperature": 0.0, "avg_logprob": -0.1893219702022592, "compression_ratio": 1.5957446808510638, "no_speech_prob": 6.339182164083468e-06}, {"id": 986, "seek": 508896, "start": 5094.4800000000005, "end": 5096.64, "text": " back and write it.", "tokens": [646, 293, 2464, 309, 13], "temperature": 0.0, "avg_logprob": -0.1893219702022592, "compression_ratio": 1.5957446808510638, "no_speech_prob": 6.339182164083468e-06}, {"id": 987, "seek": 508896, "start": 5096.64, "end": 5103.4, "text": " So I wrote this line first, and it's like, okay I need something which takes all of the", "tokens": [407, 286, 4114, 341, 1622, 700, 11, 293, 309, 311, 411, 11, 1392, 286, 643, 746, 597, 2516, 439, 295, 264], "temperature": 0.0, "avg_logprob": -0.1893219702022592, "compression_ratio": 1.5957446808510638, "no_speech_prob": 6.339182164083468e-06}, {"id": 988, "seek": 508896, "start": 5103.4, "end": 5111.12, "text": " bounding boxes for a particular image and finds the largest, and well, that's pretty", "tokens": [5472, 278, 9002, 337, 257, 1729, 3256, 293, 10704, 264, 6443, 11, 293, 731, 11, 300, 311, 1238], "temperature": 0.0, "avg_logprob": -0.1893219702022592, "compression_ratio": 1.5957446808510638, "no_speech_prob": 6.339182164083468e-06}, {"id": 989, "seek": 508896, "start": 5111.12, "end": 5112.88, "text": " straightforward.", "tokens": [15325, 13], "temperature": 0.0, "avg_logprob": -0.1893219702022592, "compression_ratio": 1.5957446808510638, "no_speech_prob": 6.339182164083468e-06}, {"id": 990, "seek": 508896, "start": 5112.88, "end": 5118.64, "text": " I can just sort the bounding boxes, and here again we've got a lambda function.", "tokens": [286, 393, 445, 1333, 264, 5472, 278, 9002, 11, 293, 510, 797, 321, 600, 658, 257, 13607, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1893219702022592, "compression_ratio": 1.5957446808510638, "no_speech_prob": 6.339182164083468e-06}, {"id": 991, "seek": 511864, "start": 5118.64, "end": 5122.240000000001, "text": " So again, if you haven't used lambda functions before, this is something you should study", "tokens": [407, 797, 11, 498, 291, 2378, 380, 1143, 13607, 6828, 949, 11, 341, 307, 746, 291, 820, 2979], "temperature": 0.0, "avg_logprob": -0.12526029951117013, "compression_ratio": 1.6227272727272728, "no_speech_prob": 2.9023051411058987e-06}, {"id": 992, "seek": 511864, "start": 5122.240000000001, "end": 5123.240000000001, "text": " during the week.", "tokens": [1830, 264, 1243, 13], "temperature": 0.0, "avg_logprob": -0.12526029951117013, "compression_ratio": 1.6227272727272728, "no_speech_prob": 2.9023051411058987e-06}, {"id": 993, "seek": 511864, "start": 5123.240000000001, "end": 5129.4400000000005, "text": " They're used all over the place to quickly define a function, like a once-off function.", "tokens": [814, 434, 1143, 439, 670, 264, 1081, 281, 2661, 6964, 257, 2445, 11, 411, 257, 1564, 12, 4506, 2445, 13], "temperature": 0.0, "avg_logprob": -0.12526029951117013, "compression_ratio": 1.6227272727272728, "no_speech_prob": 2.9023051411058987e-06}, {"id": 994, "seek": 511864, "start": 5129.4400000000005, "end": 5138.200000000001, "text": " And in this case, the Python built-in sorted function lets you pass in a function to say", "tokens": [400, 294, 341, 1389, 11, 264, 15329, 3094, 12, 259, 25462, 2445, 6653, 291, 1320, 294, 257, 2445, 281, 584], "temperature": 0.0, "avg_logprob": -0.12526029951117013, "compression_ratio": 1.6227272727272728, "no_speech_prob": 2.9023051411058987e-06}, {"id": 995, "seek": 511864, "start": 5138.200000000001, "end": 5144.72, "text": " how do you decide whether something's earlier or later in the sort order.", "tokens": [577, 360, 291, 4536, 1968, 746, 311, 3071, 420, 1780, 294, 264, 1333, 1668, 13], "temperature": 0.0, "avg_logprob": -0.12526029951117013, "compression_ratio": 1.6227272727272728, "no_speech_prob": 2.9023051411058987e-06}, {"id": 996, "seek": 514472, "start": 5144.72, "end": 5159.8, "text": " And so in this case, I took the product of the last two items of my bounding box list,", "tokens": [400, 370, 294, 341, 1389, 11, 286, 1890, 264, 1674, 295, 264, 1036, 732, 4754, 295, 452, 5472, 278, 2424, 1329, 11], "temperature": 0.0, "avg_logprob": -0.15997034027462914, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.611977490436402e-06}, {"id": 997, "seek": 514472, "start": 5159.8, "end": 5165.64, "text": " i.e. the bottom right-hand corner, minus the first two items of my bounding box list, i.e.", "tokens": [741, 13, 68, 13, 264, 2767, 558, 12, 5543, 4538, 11, 3175, 264, 700, 732, 4754, 295, 452, 5472, 278, 2424, 1329, 11, 741, 13, 68, 13], "temperature": 0.0, "avg_logprob": -0.15997034027462914, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.611977490436402e-06}, {"id": 998, "seek": 514472, "start": 5165.64, "end": 5166.64, "text": " the top left corner.", "tokens": [264, 1192, 1411, 4538, 13], "temperature": 0.0, "avg_logprob": -0.15997034027462914, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.611977490436402e-06}, {"id": 999, "seek": 514472, "start": 5166.64, "end": 5172.64, "text": " So bottom right minus top left is the size, the two sizes, and if you take the product", "tokens": [407, 2767, 558, 3175, 1192, 1411, 307, 264, 2744, 11, 264, 732, 11602, 11, 293, 498, 291, 747, 264, 1674], "temperature": 0.0, "avg_logprob": -0.15997034027462914, "compression_ratio": 1.8387096774193548, "no_speech_prob": 3.611977490436402e-06}, {"id": 1000, "seek": 517264, "start": 5172.64, "end": 5176.0, "text": " of those two things, you get the size of the bounding box.", "tokens": [295, 729, 732, 721, 11, 291, 483, 264, 2744, 295, 264, 5472, 278, 2424, 13], "temperature": 0.0, "avg_logprob": -0.15424946784973145, "compression_ratio": 1.7130044843049328, "no_speech_prob": 9.368696737510618e-06}, {"id": 1001, "seek": 517264, "start": 5176.0, "end": 5180.76, "text": " And so then that's the function, do that in descending order.", "tokens": [400, 370, 550, 300, 311, 264, 2445, 11, 360, 300, 294, 40182, 1668, 13], "temperature": 0.0, "avg_logprob": -0.15424946784973145, "compression_ratio": 1.7130044843049328, "no_speech_prob": 9.368696737510618e-06}, {"id": 1002, "seek": 517264, "start": 5180.76, "end": 5186.8, "text": " I mean often you can take something that's going to be a few lines of code and turn it", "tokens": [286, 914, 2049, 291, 393, 747, 746, 300, 311, 516, 281, 312, 257, 1326, 3876, 295, 3089, 293, 1261, 309], "temperature": 0.0, "avg_logprob": -0.15424946784973145, "compression_ratio": 1.7130044843049328, "no_speech_prob": 9.368696737510618e-06}, {"id": 1003, "seek": 517264, "start": 5186.8, "end": 5193.8, "text": " into one line of code, and sometimes you can take that too far, but for me, I like to do", "tokens": [666, 472, 1622, 295, 3089, 11, 293, 2171, 291, 393, 747, 300, 886, 1400, 11, 457, 337, 385, 11, 286, 411, 281, 360], "temperature": 0.0, "avg_logprob": -0.15424946784973145, "compression_ratio": 1.7130044843049328, "no_speech_prob": 9.368696737510618e-06}, {"id": 1004, "seek": 517264, "start": 5193.8, "end": 5201.96, "text": " that where I reasonably can, because again, it means rather than having to understand", "tokens": [300, 689, 286, 23551, 393, 11, 570, 797, 11, 309, 1355, 2831, 813, 1419, 281, 1223], "temperature": 0.0, "avg_logprob": -0.15424946784973145, "compression_ratio": 1.7130044843049328, "no_speech_prob": 9.368696737510618e-06}, {"id": 1005, "seek": 520196, "start": 5201.96, "end": 5206.72, "text": " a whole big chain of things, my brain can just say, I can just look at that at once", "tokens": [257, 1379, 955, 5021, 295, 721, 11, 452, 3567, 393, 445, 584, 11, 286, 393, 445, 574, 412, 300, 412, 1564], "temperature": 0.0, "avg_logprob": -0.20106285738657756, "compression_ratio": 1.6384180790960452, "no_speech_prob": 1.300704934692476e-05}, {"id": 1006, "seek": 520196, "start": 5206.72, "end": 5209.04, "text": " and say, okay, there it is.", "tokens": [293, 584, 11, 1392, 11, 456, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.20106285738657756, "compression_ratio": 1.6384180790960452, "no_speech_prob": 1.300704934692476e-05}, {"id": 1007, "seek": 520196, "start": 5209.04, "end": 5215.72, "text": " And also I find that over time, my brain kind of builds up this little library of idioms,", "tokens": [400, 611, 286, 915, 300, 670, 565, 11, 452, 3567, 733, 295, 15182, 493, 341, 707, 6405, 295, 18014, 4785, 11], "temperature": 0.0, "avg_logprob": -0.20106285738657756, "compression_ratio": 1.6384180790960452, "no_speech_prob": 1.300704934692476e-05}, {"id": 1008, "seek": 520196, "start": 5215.72, "end": 5224.04, "text": " you know, and more and more things I can look at a single line and know what's going on.", "tokens": [291, 458, 11, 293, 544, 293, 544, 721, 286, 393, 574, 412, 257, 2167, 1622, 293, 458, 437, 311, 516, 322, 13], "temperature": 0.0, "avg_logprob": -0.20106285738657756, "compression_ratio": 1.6384180790960452, "no_speech_prob": 1.300704934692476e-05}, {"id": 1009, "seek": 522404, "start": 5224.04, "end": 5235.2, "text": " So this now is a dictionary, and it's a dictionary because this is a dictionary comprehension.", "tokens": [407, 341, 586, 307, 257, 25890, 11, 293, 309, 311, 257, 25890, 570, 341, 307, 257, 25890, 44991, 13], "temperature": 0.0, "avg_logprob": -0.1372290901515795, "compression_ratio": 1.74375, "no_speech_prob": 3.84492250304902e-06}, {"id": 1010, "seek": 522404, "start": 5235.2, "end": 5237.44, "text": " A dictionary comprehension is just like a list comprehension.", "tokens": [316, 25890, 44991, 307, 445, 411, 257, 1329, 44991, 13], "temperature": 0.0, "avg_logprob": -0.1372290901515795, "compression_ratio": 1.74375, "no_speech_prob": 3.84492250304902e-06}, {"id": 1011, "seek": 522404, "start": 5237.44, "end": 5243.24, "text": " I'm going to use it a lot in this part of the course, except it goes inside curly brackets", "tokens": [286, 478, 516, 281, 764, 309, 257, 688, 294, 341, 644, 295, 264, 1164, 11, 3993, 309, 1709, 1854, 32066, 26179], "temperature": 0.0, "avg_logprob": -0.1372290901515795, "compression_ratio": 1.74375, "no_speech_prob": 3.84492250304902e-06}, {"id": 1012, "seek": 522404, "start": 5243.24, "end": 5247.84, "text": " and it's got a key colon value.", "tokens": [293, 309, 311, 658, 257, 2141, 8255, 2158, 13], "temperature": 0.0, "avg_logprob": -0.1372290901515795, "compression_ratio": 1.74375, "no_speech_prob": 3.84492250304902e-06}, {"id": 1013, "seek": 524784, "start": 5247.84, "end": 5259.56, "text": " So here the key is going to be the image ID and the value is the largest bound box.", "tokens": [407, 510, 264, 2141, 307, 516, 281, 312, 264, 3256, 7348, 293, 264, 2158, 307, 264, 6443, 5472, 2424, 13], "temperature": 0.0, "avg_logprob": -0.14677061353410994, "compression_ratio": 1.5696202531645569, "no_speech_prob": 2.4439800654363353e-06}, {"id": 1014, "seek": 524784, "start": 5259.56, "end": 5265.28, "text": " So now that we've got that, we can look at an example.", "tokens": [407, 586, 300, 321, 600, 658, 300, 11, 321, 393, 574, 412, 364, 1365, 13], "temperature": 0.0, "avg_logprob": -0.14677061353410994, "compression_ratio": 1.5696202531645569, "no_speech_prob": 2.4439800654363353e-06}, {"id": 1015, "seek": 524784, "start": 5265.28, "end": 5271.04, "text": " And here's an example of the largest bounding box for this image.", "tokens": [400, 510, 311, 364, 1365, 295, 264, 6443, 5472, 278, 2424, 337, 341, 3256, 13], "temperature": 0.0, "avg_logprob": -0.14677061353410994, "compression_ratio": 1.5696202531645569, "no_speech_prob": 2.4439800654363353e-06}, {"id": 1016, "seek": 524784, "start": 5271.04, "end": 5273.92, "text": " So obviously there's a lot of objects here.", "tokens": [407, 2745, 456, 311, 257, 688, 295, 6565, 510, 13], "temperature": 0.0, "avg_logprob": -0.14677061353410994, "compression_ratio": 1.5696202531645569, "no_speech_prob": 2.4439800654363353e-06}, {"id": 1017, "seek": 527392, "start": 5273.92, "end": 5281.56, "text": " 3 bicycles and 3 people, but here's the largest bounding box.", "tokens": [805, 47913, 293, 805, 561, 11, 457, 510, 311, 264, 6443, 5472, 278, 2424, 13], "temperature": 0.0, "avg_logprob": -0.14861523851435235, "compression_ratio": 1.550660792951542, "no_speech_prob": 3.5008333725272678e-06}, {"id": 1018, "seek": 527392, "start": 5281.56, "end": 5285.52, "text": " I feel like this ought to go without saying, but it definitely needs to be said because", "tokens": [286, 841, 411, 341, 13416, 281, 352, 1553, 1566, 11, 457, 309, 2138, 2203, 281, 312, 848, 570], "temperature": 0.0, "avg_logprob": -0.14861523851435235, "compression_ratio": 1.550660792951542, "no_speech_prob": 3.5008333725272678e-06}, {"id": 1019, "seek": 527392, "start": 5285.52, "end": 5287.08, "text": " so many people don't do it.", "tokens": [370, 867, 561, 500, 380, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.14861523851435235, "compression_ratio": 1.550660792951542, "no_speech_prob": 3.5008333725272678e-06}, {"id": 1020, "seek": 527392, "start": 5287.08, "end": 5293.72, "text": " You need to look at every stage when you've got any kind of processing pipeline, if you're", "tokens": [509, 643, 281, 574, 412, 633, 3233, 562, 291, 600, 658, 604, 733, 295, 9007, 15517, 11, 498, 291, 434], "temperature": 0.0, "avg_logprob": -0.14861523851435235, "compression_ratio": 1.550660792951542, "no_speech_prob": 3.5008333725272678e-06}, {"id": 1021, "seek": 527392, "start": 5293.72, "end": 5300.28, "text": " as bad at coding as I am, everything you do will be wrong the first time you do it.", "tokens": [382, 1578, 412, 17720, 382, 286, 669, 11, 1203, 291, 360, 486, 312, 2085, 264, 700, 565, 291, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.14861523851435235, "compression_ratio": 1.550660792951542, "no_speech_prob": 3.5008333725272678e-06}, {"id": 1022, "seek": 530028, "start": 5300.28, "end": 5304.759999999999, "text": " But there's lots of people that are as bad as me at coding, and yet lots of people write", "tokens": [583, 456, 311, 3195, 295, 561, 300, 366, 382, 1578, 382, 385, 412, 17720, 11, 293, 1939, 3195, 295, 561, 2464], "temperature": 0.0, "avg_logprob": -0.20132342406681605, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.223421329807024e-06}, {"id": 1023, "seek": 530028, "start": 5304.759999999999, "end": 5309.36, "text": " lines and lines of code assuming they're all correct, and then at the very end they've", "tokens": [3876, 293, 3876, 295, 3089, 11926, 436, 434, 439, 3006, 11, 293, 550, 412, 264, 588, 917, 436, 600], "temperature": 0.0, "avg_logprob": -0.20132342406681605, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.223421329807024e-06}, {"id": 1024, "seek": 530028, "start": 5309.36, "end": 5313.28, "text": " got a mistake and they don't know where it came from.", "tokens": [658, 257, 6146, 293, 436, 500, 380, 458, 689, 309, 1361, 490, 13], "temperature": 0.0, "avg_logprob": -0.20132342406681605, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.223421329807024e-06}, {"id": 1025, "seek": 530028, "start": 5313.28, "end": 5318.5199999999995, "text": " Particularly when you're working with images or text, things that humans can look at and", "tokens": [32281, 562, 291, 434, 1364, 365, 5267, 420, 2487, 11, 721, 300, 6255, 393, 574, 412, 293], "temperature": 0.0, "avg_logprob": -0.20132342406681605, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.223421329807024e-06}, {"id": 1026, "seek": 530028, "start": 5318.5199999999995, "end": 5321.8, "text": " understand, keep looking at it.", "tokens": [1223, 11, 1066, 1237, 412, 309, 13], "temperature": 0.0, "avg_logprob": -0.20132342406681605, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.223421329807024e-06}, {"id": 1027, "seek": 530028, "start": 5321.8, "end": 5327.44, "text": " So here I have it, that looks like the biggest thing, and that certainly looks like a person.", "tokens": [407, 510, 286, 362, 309, 11, 300, 1542, 411, 264, 3880, 551, 11, 293, 300, 3297, 1542, 411, 257, 954, 13], "temperature": 0.0, "avg_logprob": -0.20132342406681605, "compression_ratio": 1.7076923076923076, "no_speech_prob": 9.223421329807024e-06}, {"id": 1028, "seek": 532744, "start": 5327.44, "end": 5330.48, "text": " So let's move on.", "tokens": [407, 718, 311, 1286, 322, 13], "temperature": 0.0, "avg_logprob": -0.2787079603775688, "compression_ratio": 1.467005076142132, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1029, "seek": 532744, "start": 5330.48, "end": 5333.16, "text": " Here's another nice thing in pathlib, make directory.", "tokens": [1692, 311, 1071, 1481, 551, 294, 3100, 38270, 11, 652, 21120, 13], "temperature": 0.0, "avg_logprob": -0.2787079603775688, "compression_ratio": 1.467005076142132, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1030, "seek": 532744, "start": 5333.16, "end": 5336.48, "text": " So that's a handy little method.", "tokens": [407, 300, 311, 257, 13239, 707, 3170, 13], "temperature": 0.0, "avg_logprob": -0.2787079603775688, "compression_ratio": 1.467005076142132, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1031, "seek": 532744, "start": 5336.48, "end": 5345.759999999999, "text": " So I'm going to create a path called CSV, which is a path to my large objects CSV file.", "tokens": [407, 286, 478, 516, 281, 1884, 257, 3100, 1219, 48814, 11, 597, 307, 257, 3100, 281, 452, 2416, 6565, 48814, 3991, 13], "temperature": 0.0, "avg_logprob": -0.2787079603775688, "compression_ratio": 1.467005076142132, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1032, "seek": 532744, "start": 5345.759999999999, "end": 5349.679999999999, "text": " Why am I going to create a CSV file?", "tokens": [1545, 669, 286, 516, 281, 1884, 257, 48814, 3991, 30], "temperature": 0.0, "avg_logprob": -0.2787079603775688, "compression_ratio": 1.467005076142132, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1033, "seek": 532744, "start": 5349.679999999999, "end": 5350.879999999999, "text": " Pure laziness, right?", "tokens": [29474, 19320, 1324, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.2787079603775688, "compression_ratio": 1.467005076142132, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1034, "seek": 532744, "start": 5350.879999999999, "end": 5355.24, "text": " We have an image classifier.from.csv.", "tokens": [492, 362, 364, 3256, 1508, 9902, 13, 20579, 13, 14368, 85, 13], "temperature": 0.0, "avg_logprob": -0.2787079603775688, "compression_ratio": 1.467005076142132, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1035, "seek": 535524, "start": 5355.24, "end": 5359.08, "text": " I could go through a whole lot of work to create a custom data set and blah blah blah", "tokens": [286, 727, 352, 807, 257, 1379, 688, 295, 589, 281, 1884, 257, 2375, 1412, 992, 293, 12288, 12288, 12288], "temperature": 0.0, "avg_logprob": -0.1983786051252247, "compression_ratio": 1.5880149812734083, "no_speech_prob": 7.64649757911684e-06}, {"id": 1036, "seek": 535524, "start": 5359.08, "end": 5362.92, "text": " to use this particular format I have.", "tokens": [281, 764, 341, 1729, 7877, 286, 362, 13], "temperature": 0.0, "avg_logprob": -0.1983786051252247, "compression_ratio": 1.5880149812734083, "no_speech_prob": 7.64649757911684e-06}, {"id": 1037, "seek": 535524, "start": 5362.92, "end": 5363.92, "text": " But why?", "tokens": [583, 983, 30], "temperature": 0.0, "avg_logprob": -0.1983786051252247, "compression_ratio": 1.5880149812734083, "no_speech_prob": 7.64649757911684e-06}, {"id": 1038, "seek": 535524, "start": 5363.92, "end": 5369.679999999999, "text": " You know, it's so easy to create the CSV, chuck it inside a temporary folder, and then", "tokens": [509, 458, 11, 309, 311, 370, 1858, 281, 1884, 264, 48814, 11, 20870, 309, 1854, 257, 13413, 10820, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.1983786051252247, "compression_ratio": 1.5880149812734083, "no_speech_prob": 7.64649757911684e-06}, {"id": 1039, "seek": 535524, "start": 5369.679999999999, "end": 5371.639999999999, "text": " use something that already has.", "tokens": [764, 746, 300, 1217, 575, 13], "temperature": 0.0, "avg_logprob": -0.1983786051252247, "compression_ratio": 1.5880149812734083, "no_speech_prob": 7.64649757911684e-06}, {"id": 1040, "seek": 535524, "start": 5371.639999999999, "end": 5377.0, "text": " So this is kind of something I've seen a lot of times on the forum, is people will say", "tokens": [407, 341, 307, 733, 295, 746, 286, 600, 1612, 257, 688, 295, 1413, 322, 264, 17542, 11, 307, 561, 486, 584], "temperature": 0.0, "avg_logprob": -0.1983786051252247, "compression_ratio": 1.5880149812734083, "no_speech_prob": 7.64649757911684e-06}, {"id": 1041, "seek": 535524, "start": 5377.0, "end": 5384.719999999999, "text": " like how do I convert this weird structure into a way that fast AI can accept it, and", "tokens": [411, 577, 360, 286, 7620, 341, 3657, 3877, 666, 257, 636, 300, 2370, 7318, 393, 3241, 309, 11, 293], "temperature": 0.0, "avg_logprob": -0.1983786051252247, "compression_ratio": 1.5880149812734083, "no_speech_prob": 7.64649757911684e-06}, {"id": 1042, "seek": 538472, "start": 5384.72, "end": 5389.4400000000005, "text": " then normally somebody on the forum will say like print it to a CSV file.", "tokens": [550, 5646, 2618, 322, 264, 17542, 486, 584, 411, 4482, 309, 281, 257, 48814, 3991, 13], "temperature": 0.0, "avg_logprob": -0.15807675049368258, "compression_ratio": 1.705128205128205, "no_speech_prob": 8.93963806447573e-06}, {"id": 1043, "seek": 538472, "start": 5389.4400000000005, "end": 5393.68, "text": " So that's a good simple tip.", "tokens": [407, 300, 311, 257, 665, 2199, 4125, 13], "temperature": 0.0, "avg_logprob": -0.15807675049368258, "compression_ratio": 1.705128205128205, "no_speech_prob": 8.93963806447573e-06}, {"id": 1044, "seek": 538472, "start": 5393.68, "end": 5398.2, "text": " And the easiest way to create a CSV file is to create a pandas data frame.", "tokens": [400, 264, 12889, 636, 281, 1884, 257, 48814, 3991, 307, 281, 1884, 257, 4565, 296, 1412, 3920, 13], "temperature": 0.0, "avg_logprob": -0.15807675049368258, "compression_ratio": 1.705128205128205, "no_speech_prob": 8.93963806447573e-06}, {"id": 1045, "seek": 538472, "start": 5398.2, "end": 5401.72, "text": " So here's my pandas data frame.", "tokens": [407, 510, 311, 452, 4565, 296, 1412, 3920, 13], "temperature": 0.0, "avg_logprob": -0.15807675049368258, "compression_ratio": 1.705128205128205, "no_speech_prob": 8.93963806447573e-06}, {"id": 1046, "seek": 538472, "start": 5401.72, "end": 5406.08, "text": " I can just give it a dictionary with the name of a column and the list of things in that", "tokens": [286, 393, 445, 976, 309, 257, 25890, 365, 264, 1315, 295, 257, 7738, 293, 264, 1329, 295, 721, 294, 300], "temperature": 0.0, "avg_logprob": -0.15807675049368258, "compression_ratio": 1.705128205128205, "no_speech_prob": 8.93963806447573e-06}, {"id": 1047, "seek": 538472, "start": 5406.08, "end": 5412.58, "text": " column, so there's the file name, there's the category, and then you'll see here why", "tokens": [7738, 11, 370, 456, 311, 264, 3991, 1315, 11, 456, 311, 264, 7719, 11, 293, 550, 291, 603, 536, 510, 983], "temperature": 0.0, "avg_logprob": -0.15807675049368258, "compression_ratio": 1.705128205128205, "no_speech_prob": 8.93963806447573e-06}, {"id": 1048, "seek": 538472, "start": 5412.58, "end": 5413.58, "text": " do I have this?", "tokens": [360, 286, 362, 341, 30], "temperature": 0.0, "avg_logprob": -0.15807675049368258, "compression_ratio": 1.705128205128205, "no_speech_prob": 8.93963806447573e-06}, {"id": 1049, "seek": 541358, "start": 5413.58, "end": 5417.48, "text": " I've already named the columns in the dictionary, why is it here?", "tokens": [286, 600, 1217, 4926, 264, 13766, 294, 264, 25890, 11, 983, 307, 309, 510, 30], "temperature": 0.0, "avg_logprob": -0.16468786310266564, "compression_ratio": 1.7167381974248928, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1050, "seek": 541358, "start": 5417.48, "end": 5423.72, "text": " Because the order of columns matters, and a dictionary does not have an order.", "tokens": [1436, 264, 1668, 295, 13766, 7001, 11, 293, 257, 25890, 775, 406, 362, 364, 1668, 13], "temperature": 0.0, "avg_logprob": -0.16468786310266564, "compression_ratio": 1.7167381974248928, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1051, "seek": 541358, "start": 5423.72, "end": 5427.5199999999995, "text": " So this says the file name comes first and the category comes second.", "tokens": [407, 341, 1619, 264, 3991, 1315, 1487, 700, 293, 264, 7719, 1487, 1150, 13], "temperature": 0.0, "avg_logprob": -0.16468786310266564, "compression_ratio": 1.7167381974248928, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1052, "seek": 541358, "start": 5427.5199999999995, "end": 5431.32, "text": " So that's a good trick to creating your CSVs.", "tokens": [407, 300, 311, 257, 665, 4282, 281, 4084, 428, 48814, 82, 13], "temperature": 0.0, "avg_logprob": -0.16468786310266564, "compression_ratio": 1.7167381974248928, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1053, "seek": 541358, "start": 5431.32, "end": 5433.48, "text": " So now it's just dogs and cats.", "tokens": [407, 586, 309, 311, 445, 7197, 293, 11111, 13], "temperature": 0.0, "avg_logprob": -0.16468786310266564, "compression_ratio": 1.7167381974248928, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1054, "seek": 541358, "start": 5433.48, "end": 5439.5199999999995, "text": " I have a CSV file, it contains a bunch of file names, and for each one it contains the", "tokens": [286, 362, 257, 48814, 3991, 11, 309, 8306, 257, 3840, 295, 3991, 5288, 11, 293, 337, 1184, 472, 309, 8306, 264], "temperature": 0.0, "avg_logprob": -0.16468786310266564, "compression_ratio": 1.7167381974248928, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1055, "seek": 541358, "start": 5439.5199999999995, "end": 5442.58, "text": " plus of that object.", "tokens": [1804, 295, 300, 2657, 13], "temperature": 0.0, "avg_logprob": -0.16468786310266564, "compression_ratio": 1.7167381974248928, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1056, "seek": 544258, "start": 5442.58, "end": 5448.94, "text": " So this is the same two lines of code you've seen a thousand times.", "tokens": [407, 341, 307, 264, 912, 732, 3876, 295, 3089, 291, 600, 1612, 257, 4714, 1413, 13], "temperature": 0.0, "avg_logprob": -0.1866451899210612, "compression_ratio": 1.4011299435028248, "no_speech_prob": 3.7853053527214797e-06}, {"id": 1057, "seek": 544258, "start": 5448.94, "end": 5455.76, "text": " What we will do though is to take a look at this.", "tokens": [708, 321, 486, 360, 1673, 307, 281, 747, 257, 574, 412, 341, 13], "temperature": 0.0, "avg_logprob": -0.1866451899210612, "compression_ratio": 1.4011299435028248, "no_speech_prob": 3.7853053527214797e-06}, {"id": 1058, "seek": 544258, "start": 5455.76, "end": 5461.22, "text": " The one thing that's different is crop type.", "tokens": [440, 472, 551, 300, 311, 819, 307, 9086, 2010, 13], "temperature": 0.0, "avg_logprob": -0.1866451899210612, "compression_ratio": 1.4011299435028248, "no_speech_prob": 3.7853053527214797e-06}, {"id": 1059, "seek": 544258, "start": 5461.22, "end": 5472.5599999999995, "text": " So you might remember the default strategy for creating a 224x224 image in Fast AI is", "tokens": [407, 291, 1062, 1604, 264, 7576, 5206, 337, 4084, 257, 5853, 19, 87, 7490, 19, 3256, 294, 15968, 7318, 307], "temperature": 0.0, "avg_logprob": -0.1866451899210612, "compression_ratio": 1.4011299435028248, "no_speech_prob": 3.7853053527214797e-06}, {"id": 1060, "seek": 547256, "start": 5472.56, "end": 5481.56, "text": " to first of all resize it so the largest side, sorry the smallest side is 224, and then to", "tokens": [281, 700, 295, 439, 50069, 309, 370, 264, 6443, 1252, 11, 2597, 264, 16998, 1252, 307, 5853, 19, 11, 293, 550, 281], "temperature": 0.0, "avg_logprob": -0.21891888936360676, "compression_ratio": 1.6611111111111112, "no_speech_prob": 5.5075670388760045e-06}, {"id": 1061, "seek": 547256, "start": 5481.56, "end": 5487.76, "text": " take a random crop, assuming it's rectangular, a random square crop during training, and", "tokens": [747, 257, 4974, 9086, 11, 11926, 309, 311, 31167, 11, 257, 4974, 3732, 9086, 1830, 3097, 11, 293], "temperature": 0.0, "avg_logprob": -0.21891888936360676, "compression_ratio": 1.6611111111111112, "no_speech_prob": 5.5075670388760045e-06}, {"id": 1062, "seek": 547256, "start": 5487.76, "end": 5492.96, "text": " then during validation we take the center crop unless we use data augmentation, in", "tokens": [550, 1830, 24071, 321, 747, 264, 3056, 9086, 5969, 321, 764, 1412, 14501, 19631, 11, 294], "temperature": 0.0, "avg_logprob": -0.21891888936360676, "compression_ratio": 1.6611111111111112, "no_speech_prob": 5.5075670388760045e-06}, {"id": 1063, "seek": 547256, "start": 5492.96, "end": 5497.88, "text": " which case we do a few random crops.", "tokens": [597, 1389, 321, 360, 257, 1326, 4974, 16829, 13], "temperature": 0.0, "avg_logprob": -0.21891888936360676, "compression_ratio": 1.6611111111111112, "no_speech_prob": 5.5075670388760045e-06}, {"id": 1064, "seek": 549788, "start": 5497.88, "end": 5504.24, "text": " For bounding boxes we don't want to do that because unlike an image net where the thing", "tokens": [1171, 5472, 278, 9002, 321, 500, 380, 528, 281, 360, 300, 570, 8343, 364, 3256, 2533, 689, 264, 551], "temperature": 0.0, "avg_logprob": -0.1354436771844023, "compression_ratio": 1.6289592760180995, "no_speech_prob": 2.561276232881937e-06}, {"id": 1065, "seek": 549788, "start": 5504.24, "end": 5509.400000000001, "text": " we care about is pretty much in the middle and it's pretty big, a lot of the stuff in", "tokens": [321, 1127, 466, 307, 1238, 709, 294, 264, 2808, 293, 309, 311, 1238, 955, 11, 257, 688, 295, 264, 1507, 294], "temperature": 0.0, "avg_logprob": -0.1354436771844023, "compression_ratio": 1.6289592760180995, "no_speech_prob": 2.561276232881937e-06}, {"id": 1066, "seek": 549788, "start": 5509.400000000001, "end": 5513.96, "text": " object detection is quite small and close to the edge.", "tokens": [2657, 17784, 307, 1596, 1359, 293, 1998, 281, 264, 4691, 13], "temperature": 0.0, "avg_logprob": -0.1354436771844023, "compression_ratio": 1.6289592760180995, "no_speech_prob": 2.561276232881937e-06}, {"id": 1067, "seek": 549788, "start": 5513.96, "end": 5516.88, "text": " So we could crop it out and that would be bad.", "tokens": [407, 321, 727, 9086, 309, 484, 293, 300, 576, 312, 1578, 13], "temperature": 0.0, "avg_logprob": -0.1354436771844023, "compression_ratio": 1.6289592760180995, "no_speech_prob": 2.561276232881937e-06}, {"id": 1068, "seek": 549788, "start": 5516.88, "end": 5523.96, "text": " So when you create your transforms you can choose crop type equals crop type.no, and", "tokens": [407, 562, 291, 1884, 428, 35592, 291, 393, 2826, 9086, 2010, 6915, 9086, 2010, 13, 1771, 11, 293], "temperature": 0.0, "avg_logprob": -0.1354436771844023, "compression_ratio": 1.6289592760180995, "no_speech_prob": 2.561276232881937e-06}, {"id": 1069, "seek": 552396, "start": 5523.96, "end": 5530.1, "text": " no means don't crop, and therefore to make it square instead it squishes it.", "tokens": [572, 1355, 500, 380, 9086, 11, 293, 4412, 281, 652, 309, 3732, 2602, 309, 2339, 16423, 309, 13], "temperature": 0.0, "avg_logprob": -0.14158284505208332, "compression_ratio": 1.5578947368421052, "no_speech_prob": 3.966979420511052e-06}, {"id": 1070, "seek": 552396, "start": 5530.1, "end": 5535.6, "text": " So you'll see this guy now looks kind of a bit strangely wide, and that's because he's", "tokens": [407, 291, 603, 536, 341, 2146, 586, 1542, 733, 295, 257, 857, 39851, 4874, 11, 293, 300, 311, 570, 415, 311], "temperature": 0.0, "avg_logprob": -0.14158284505208332, "compression_ratio": 1.5578947368421052, "no_speech_prob": 3.966979420511052e-06}, {"id": 1071, "seek": 552396, "start": 5535.6, "end": 5541.76, "text": " been squished like this rather than cropped.", "tokens": [668, 2339, 4729, 411, 341, 2831, 813, 4848, 3320, 13], "temperature": 0.0, "avg_logprob": -0.14158284505208332, "compression_ratio": 1.5578947368421052, "no_speech_prob": 3.966979420511052e-06}, {"id": 1072, "seek": 552396, "start": 5541.76, "end": 5549.94, "text": " Generally speaking a lot of computer vision models work a little bit better if you crop", "tokens": [21082, 4124, 257, 688, 295, 3820, 5201, 5245, 589, 257, 707, 857, 1101, 498, 291, 9086], "temperature": 0.0, "avg_logprob": -0.14158284505208332, "compression_ratio": 1.5578947368421052, "no_speech_prob": 3.966979420511052e-06}, {"id": 1073, "seek": 554994, "start": 5549.94, "end": 5554.32, "text": " rather than squish, but they still work pretty well if you squish.", "tokens": [2831, 813, 31379, 11, 457, 436, 920, 589, 1238, 731, 498, 291, 31379, 13], "temperature": 0.0, "avg_logprob": -0.22526218273021556, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.748025498382049e-06}, {"id": 1074, "seek": 554994, "start": 5554.32, "end": 5560.58, "text": " In this case we definitely don't want to crop, so this is perfectly fine.", "tokens": [682, 341, 1389, 321, 2138, 500, 380, 528, 281, 9086, 11, 370, 341, 307, 6239, 2489, 13], "temperature": 0.0, "avg_logprob": -0.22526218273021556, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.748025498382049e-06}, {"id": 1075, "seek": 554994, "start": 5560.58, "end": 5568.28, "text": " If you had very long or very tall images, such that if a human looked at the squashed", "tokens": [759, 291, 632, 588, 938, 420, 588, 6764, 5267, 11, 1270, 300, 498, 257, 1952, 2956, 412, 264, 2339, 12219], "temperature": 0.0, "avg_logprob": -0.22526218273021556, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.748025498382049e-06}, {"id": 1076, "seek": 554994, "start": 5568.28, "end": 5573.0, "text": " version and thought that looks really weird, then that might be difficult to model.", "tokens": [3037, 293, 1194, 300, 1542, 534, 3657, 11, 550, 300, 1062, 312, 2252, 281, 2316, 13], "temperature": 0.0, "avg_logprob": -0.22526218273021556, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.748025498382049e-06}, {"id": 1077, "seek": 554994, "start": 5573.0, "end": 5576.839999999999, "text": " But in this case we're just like, looks a little bit strange, but it's fine.", "tokens": [583, 294, 341, 1389, 321, 434, 445, 411, 11, 1542, 257, 707, 857, 5861, 11, 457, 309, 311, 2489, 13], "temperature": 0.0, "avg_logprob": -0.22526218273021556, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.748025498382049e-06}, {"id": 1078, "seek": 554994, "start": 5576.839999999999, "end": 5579.32, "text": " So the computer won't mind.", "tokens": [407, 264, 3820, 1582, 380, 1575, 13], "temperature": 0.0, "avg_logprob": -0.22526218273021556, "compression_ratio": 1.653386454183267, "no_speech_prob": 6.748025498382049e-06}, {"id": 1079, "seek": 557932, "start": 5579.32, "end": 5589.36, "text": " Okay, so I'm going to kind of quite often just dig a little bit into some more depths", "tokens": [1033, 11, 370, 286, 478, 516, 281, 733, 295, 1596, 2049, 445, 2528, 257, 707, 857, 666, 512, 544, 28439], "temperature": 0.0, "avg_logprob": -0.16672908485709848, "compression_ratio": 1.5172413793103448, "no_speech_prob": 3.7853153571631992e-06}, {"id": 1080, "seek": 557932, "start": 5589.36, "end": 5595.5199999999995, "text": " of fast AI in PyTorch, and in this case I want to just look at data loaders a little", "tokens": [295, 2370, 7318, 294, 9953, 51, 284, 339, 11, 293, 294, 341, 1389, 286, 528, 281, 445, 574, 412, 1412, 3677, 433, 257, 707], "temperature": 0.0, "avg_logprob": -0.16672908485709848, "compression_ratio": 1.5172413793103448, "no_speech_prob": 3.7853153571631992e-06}, {"id": 1081, "seek": 557932, "start": 5595.5199999999995, "end": 5596.5199999999995, "text": " bit more.", "tokens": [857, 544, 13], "temperature": 0.0, "avg_logprob": -0.16672908485709848, "compression_ratio": 1.5172413793103448, "no_speech_prob": 3.7853153571631992e-06}, {"id": 1082, "seek": 557932, "start": 5596.5199999999995, "end": 5606.48, "text": " So you already know that, let's just make sure this is all run, so you already know", "tokens": [407, 291, 1217, 458, 300, 11, 718, 311, 445, 652, 988, 341, 307, 439, 1190, 11, 370, 291, 1217, 458], "temperature": 0.0, "avg_logprob": -0.16672908485709848, "compression_ratio": 1.5172413793103448, "no_speech_prob": 3.7853153571631992e-06}, {"id": 1083, "seek": 560648, "start": 5606.48, "end": 5611.2, "text": " that inside a model data object, there's lots of model data subclasses like image classifier", "tokens": [300, 1854, 257, 2316, 1412, 2657, 11, 456, 311, 3195, 295, 2316, 1412, 1422, 11665, 279, 411, 3256, 1508, 9902], "temperature": 0.0, "avg_logprob": -0.178804197765532, "compression_ratio": 1.7297297297297298, "no_speech_prob": 1.2606842574314214e-05}, {"id": 1084, "seek": 560648, "start": 5611.2, "end": 5617.719999999999, "text": " data, we have a bunch of things which include a training data loader and a training data", "tokens": [1412, 11, 321, 362, 257, 3840, 295, 721, 597, 4090, 257, 3097, 1412, 3677, 260, 293, 257, 3097, 1412], "temperature": 0.0, "avg_logprob": -0.178804197765532, "compression_ratio": 1.7297297297297298, "no_speech_prob": 1.2606842574314214e-05}, {"id": 1085, "seek": 560648, "start": 5617.719999999999, "end": 5618.719999999999, "text": " set.", "tokens": [992, 13], "temperature": 0.0, "avg_logprob": -0.178804197765532, "compression_ratio": 1.7297297297297298, "no_speech_prob": 1.2606842574314214e-05}, {"id": 1086, "seek": 560648, "start": 5618.719999999999, "end": 5622.5599999999995, "text": " And we'll talk much more about this soon.", "tokens": [400, 321, 603, 751, 709, 544, 466, 341, 2321, 13], "temperature": 0.0, "avg_logprob": -0.178804197765532, "compression_ratio": 1.7297297297297298, "no_speech_prob": 1.2606842574314214e-05}, {"id": 1087, "seek": 560648, "start": 5622.5599999999995, "end": 5628.719999999999, "text": " But the main thing to know about a data loader is that it's an iterator, that each time you", "tokens": [583, 264, 2135, 551, 281, 458, 466, 257, 1412, 3677, 260, 307, 300, 309, 311, 364, 17138, 1639, 11, 300, 1184, 565, 291], "temperature": 0.0, "avg_logprob": -0.178804197765532, "compression_ratio": 1.7297297297297298, "no_speech_prob": 1.2606842574314214e-05}, {"id": 1088, "seek": 560648, "start": 5628.719999999999, "end": 5634.08, "text": " grab the next iteration of stuff from it, you get a mini-batch.", "tokens": [4444, 264, 958, 24784, 295, 1507, 490, 309, 11, 291, 483, 257, 8382, 12, 65, 852, 13], "temperature": 0.0, "avg_logprob": -0.178804197765532, "compression_ratio": 1.7297297297297298, "no_speech_prob": 1.2606842574314214e-05}, {"id": 1089, "seek": 563408, "start": 5634.08, "end": 5640.72, "text": " And the mini-batch you get is of whatever size you asked for, and by default the batch", "tokens": [400, 264, 8382, 12, 65, 852, 291, 483, 307, 295, 2035, 2744, 291, 2351, 337, 11, 293, 538, 7576, 264, 15245], "temperature": 0.0, "avg_logprob": -0.2500999864325466, "compression_ratio": 1.5454545454545454, "no_speech_prob": 8.664615052111913e-06}, {"id": 1090, "seek": 563408, "start": 5640.72, "end": 5643.32, "text": " size is 64.", "tokens": [2744, 307, 12145, 13], "temperature": 0.0, "avg_logprob": -0.2500999864325466, "compression_ratio": 1.5454545454545454, "no_speech_prob": 8.664615052111913e-06}, {"id": 1091, "seek": 563408, "start": 5643.32, "end": 5647.92, "text": " You can ask for whatever you like.", "tokens": [509, 393, 1029, 337, 2035, 291, 411, 13], "temperature": 0.0, "avg_logprob": -0.2500999864325466, "compression_ratio": 1.5454545454545454, "no_speech_prob": 8.664615052111913e-06}, {"id": 1092, "seek": 563408, "start": 5647.92, "end": 5654.96, "text": " However, in Python, the way you grab the next thing from an iterator is with next, but you", "tokens": [2908, 11, 294, 15329, 11, 264, 636, 291, 4444, 264, 958, 551, 490, 364, 17138, 1639, 307, 365, 958, 11, 457, 291], "temperature": 0.0, "avg_logprob": -0.2500999864325466, "compression_ratio": 1.5454545454545454, "no_speech_prob": 8.664615052111913e-06}, {"id": 1093, "seek": 563408, "start": 5654.96, "end": 5658.2, "text": " can't just do that.", "tokens": [393, 380, 445, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2500999864325466, "compression_ratio": 1.5454545454545454, "no_speech_prob": 8.664615052111913e-06}, {"id": 1094, "seek": 563408, "start": 5658.2, "end": 5659.5599999999995, "text": " Why can't you just do that?", "tokens": [1545, 393, 380, 291, 445, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.2500999864325466, "compression_ratio": 1.5454545454545454, "no_speech_prob": 8.664615052111913e-06}, {"id": 1095, "seek": 565956, "start": 5659.56, "end": 5666.84, "text": " The reason you can't do that is because you need to say, start a new epoch now.", "tokens": [440, 1778, 291, 393, 380, 360, 300, 307, 570, 291, 643, 281, 584, 11, 722, 257, 777, 30992, 339, 586, 13], "temperature": 0.0, "avg_logprob": -0.17684014026935285, "compression_ratio": 1.7009345794392523, "no_speech_prob": 2.994435362779768e-06}, {"id": 1096, "seek": 565956, "start": 5666.84, "end": 5671.76, "text": " In general, this isn't just in PyTorch, but for any Python iterator, you kind of need", "tokens": [682, 2674, 11, 341, 1943, 380, 445, 294, 9953, 51, 284, 339, 11, 457, 337, 604, 15329, 17138, 1639, 11, 291, 733, 295, 643], "temperature": 0.0, "avg_logprob": -0.17684014026935285, "compression_ratio": 1.7009345794392523, "no_speech_prob": 2.994435362779768e-06}, {"id": 1097, "seek": 565956, "start": 5671.76, "end": 5676.0, "text": " to say, start at the beginning of the sequence please.", "tokens": [281, 584, 11, 722, 412, 264, 2863, 295, 264, 8310, 1767, 13], "temperature": 0.0, "avg_logprob": -0.17684014026935285, "compression_ratio": 1.7009345794392523, "no_speech_prob": 2.994435362779768e-06}, {"id": 1098, "seek": 565956, "start": 5676.0, "end": 5683.04, "text": " And so the way you do that, and this is a general Python concept, is you write iter.", "tokens": [400, 370, 264, 636, 291, 360, 300, 11, 293, 341, 307, 257, 2674, 15329, 3410, 11, 307, 291, 2464, 17138, 13], "temperature": 0.0, "avg_logprob": -0.17684014026935285, "compression_ratio": 1.7009345794392523, "no_speech_prob": 2.994435362779768e-06}, {"id": 1099, "seek": 565956, "start": 5683.04, "end": 5688.68, "text": " And iter says, please grab an iterator out of this object.", "tokens": [400, 17138, 1619, 11, 1767, 4444, 364, 17138, 1639, 484, 295, 341, 2657, 13], "temperature": 0.0, "avg_logprob": -0.17684014026935285, "compression_ratio": 1.7009345794392523, "no_speech_prob": 2.994435362779768e-06}, {"id": 1100, "seek": 568868, "start": 5688.68, "end": 5697.96, "text": " Specifically, as we'll learn later, it means this class has to have defined an __iter__method,", "tokens": [26058, 11, 382, 321, 603, 1466, 1780, 11, 309, 1355, 341, 1508, 575, 281, 362, 7642, 364, 49264, 1681, 10852, 5537, 2926, 11], "temperature": 0.0, "avg_logprob": -0.23306928362165177, "compression_ratio": 1.4974874371859297, "no_speech_prob": 5.594307367573492e-06}, {"id": 1101, "seek": 568868, "start": 5697.96, "end": 5705.400000000001, "text": " which returns some different object, which then has an __next__method.", "tokens": [597, 11247, 512, 819, 2657, 11, 597, 550, 575, 364, 49264, 716, 734, 10852, 5537, 2926, 13], "temperature": 0.0, "avg_logprob": -0.23306928362165177, "compression_ratio": 1.4974874371859297, "no_speech_prob": 5.594307367573492e-06}, {"id": 1102, "seek": 568868, "start": 5705.400000000001, "end": 5707.84, "text": " So that's how I do that.", "tokens": [407, 300, 311, 577, 286, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.23306928362165177, "compression_ratio": 1.4974874371859297, "no_speech_prob": 5.594307367573492e-06}, {"id": 1103, "seek": 568868, "start": 5707.84, "end": 5713.88, "text": " And so if you want to grab just a single batch, this is how you do it.", "tokens": [400, 370, 498, 291, 528, 281, 4444, 445, 257, 2167, 15245, 11, 341, 307, 577, 291, 360, 309, 13], "temperature": 0.0, "avg_logprob": -0.23306928362165177, "compression_ratio": 1.4974874371859297, "no_speech_prob": 5.594307367573492e-06}, {"id": 1104, "seek": 568868, "start": 5713.88, "end": 5717.76, "text": " x, y equals next, iter, data loader.", "tokens": [2031, 11, 288, 6915, 958, 11, 17138, 11, 1412, 3677, 260, 13], "temperature": 0.0, "avg_logprob": -0.23306928362165177, "compression_ratio": 1.4974874371859297, "no_speech_prob": 5.594307367573492e-06}, {"id": 1105, "seek": 571776, "start": 5717.76, "end": 5725.72, "text": " x, y because our data loaders, our data sets behind the data loaders always have an x,", "tokens": [2031, 11, 288, 570, 527, 1412, 3677, 433, 11, 527, 1412, 6352, 2261, 264, 1412, 3677, 433, 1009, 362, 364, 2031, 11], "temperature": 0.0, "avg_logprob": -0.2691860834757487, "compression_ratio": 1.6020942408376964, "no_speech_prob": 1.7502805349067785e-05}, {"id": 1106, "seek": 571776, "start": 5725.72, "end": 5731.0, "text": " the independent, and a y, the dependent variable.", "tokens": [264, 6695, 11, 293, 257, 288, 11, 264, 12334, 7006, 13], "temperature": 0.0, "avg_logprob": -0.2691860834757487, "compression_ratio": 1.6020942408376964, "no_speech_prob": 1.7502805349067785e-05}, {"id": 1107, "seek": 571776, "start": 5731.0, "end": 5737.280000000001, "text": " So here we can grab a mini-batch of x's and y's.", "tokens": [407, 510, 321, 393, 4444, 257, 8382, 12, 65, 852, 295, 2031, 311, 293, 288, 311, 13], "temperature": 0.0, "avg_logprob": -0.2691860834757487, "compression_ratio": 1.6020942408376964, "no_speech_prob": 1.7502805349067785e-05}, {"id": 1108, "seek": 571776, "start": 5737.280000000001, "end": 5742.68, "text": " And now I'm going to pass that to that show image command we had earlier.", "tokens": [400, 586, 286, 478, 516, 281, 1320, 300, 281, 300, 855, 3256, 5622, 321, 632, 3071, 13], "temperature": 0.0, "avg_logprob": -0.2691860834757487, "compression_ratio": 1.6020942408376964, "no_speech_prob": 1.7502805349067785e-05}, {"id": 1109, "seek": 571776, "start": 5742.68, "end": 5747.4400000000005, "text": " But we can't send that straight to show image.", "tokens": [583, 321, 393, 380, 2845, 300, 2997, 281, 855, 3256, 13], "temperature": 0.0, "avg_logprob": -0.2691860834757487, "compression_ratio": 1.6020942408376964, "no_speech_prob": 1.7502805349067785e-05}, {"id": 1110, "seek": 574744, "start": 5747.44, "end": 5760.679999999999, "text": " For example, here it is.", "tokens": [1171, 1365, 11, 510, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.1521647468445793, "compression_ratio": 1.2436974789915967, "no_speech_prob": 5.862800662725931e-06}, {"id": 1111, "seek": 574744, "start": 5760.679999999999, "end": 5770.44, "text": " For one thing, it's not a NumPy array, it's not on the CPU, and its shape is all wrong.", "tokens": [1171, 472, 551, 11, 309, 311, 406, 257, 22592, 47, 88, 10225, 11, 309, 311, 406, 322, 264, 13199, 11, 293, 1080, 3909, 307, 439, 2085, 13], "temperature": 0.0, "avg_logprob": -0.1521647468445793, "compression_ratio": 1.2436974789915967, "no_speech_prob": 5.862800662725931e-06}, {"id": 1112, "seek": 574744, "start": 5770.44, "end": 5774.639999999999, "text": " It's not 224x224x3, it's 3x224x224.", "tokens": [467, 311, 406, 5853, 19, 87, 7490, 19, 87, 18, 11, 309, 311, 805, 87, 7490, 19, 87, 7490, 19, 13], "temperature": 0.0, "avg_logprob": -0.1521647468445793, "compression_ratio": 1.2436974789915967, "no_speech_prob": 5.862800662725931e-06}, {"id": 1113, "seek": 577464, "start": 5774.64, "end": 5780.240000000001, "text": " Furthermore, these are not numbers between 0 and 1.", "tokens": [23999, 11, 613, 366, 406, 3547, 1296, 1958, 293, 502, 13], "temperature": 0.0, "avg_logprob": -0.20061649594988143, "compression_ratio": 1.4507042253521127, "no_speech_prob": 2.026137735811062e-06}, {"id": 1114, "seek": 577464, "start": 5780.240000000001, "end": 5781.68, "text": " Why not?", "tokens": [1545, 406, 30], "temperature": 0.0, "avg_logprob": -0.20061649594988143, "compression_ratio": 1.4507042253521127, "no_speech_prob": 2.026137735811062e-06}, {"id": 1115, "seek": 577464, "start": 5781.68, "end": 5789.280000000001, "text": " Because remember, all of the standard ImageNet pre-trained models expect our data to have", "tokens": [1436, 1604, 11, 439, 295, 264, 3832, 29903, 31890, 659, 12, 17227, 2001, 5245, 2066, 527, 1412, 281, 362], "temperature": 0.0, "avg_logprob": -0.20061649594988143, "compression_ratio": 1.4507042253521127, "no_speech_prob": 2.026137735811062e-06}, {"id": 1116, "seek": 577464, "start": 5789.280000000001, "end": 5793.96, "text": " been normalized to have a 0 mean and a 1 standard deviation.", "tokens": [668, 48704, 281, 362, 257, 1958, 914, 293, 257, 502, 3832, 25163, 13], "temperature": 0.0, "avg_logprob": -0.20061649594988143, "compression_ratio": 1.4507042253521127, "no_speech_prob": 2.026137735811062e-06}, {"id": 1117, "seek": 577464, "start": 5793.96, "end": 5799.240000000001, "text": " So if you look inside, let's use Visual Studio code for this, since that's what we've been", "tokens": [407, 498, 291, 574, 1854, 11, 718, 311, 764, 23187, 13500, 3089, 337, 341, 11, 1670, 300, 311, 437, 321, 600, 668], "temperature": 0.0, "avg_logprob": -0.20061649594988143, "compression_ratio": 1.4507042253521127, "no_speech_prob": 2.026137735811062e-06}, {"id": 1118, "seek": 577464, "start": 5799.240000000001, "end": 5800.240000000001, "text": " doing.", "tokens": [884, 13], "temperature": 0.0, "avg_logprob": -0.20061649594988143, "compression_ratio": 1.4507042253521127, "no_speech_prob": 2.026137735811062e-06}, {"id": 1119, "seek": 580024, "start": 5800.24, "end": 5816.84, "text": " So if you look inside, transformsFromModel, so Ctrl T, transformsFromModel, TFM, which", "tokens": [407, 498, 291, 574, 1854, 11, 35592, 26219, 44, 41147, 11, 370, 35233, 314, 11, 35592, 26219, 44, 41147, 11, 40964, 44, 11, 597], "temperature": 0.0, "avg_logprob": -0.4686271471854968, "compression_ratio": 1.2765957446808511, "no_speech_prob": 3.2699044822948053e-05}, {"id": 1120, "seek": 580024, "start": 5816.84, "end": 5822.679999999999, "text": " in turn calls transforms, so F12.", "tokens": [294, 1261, 5498, 35592, 11, 370, 479, 4762, 13], "temperature": 0.0, "avg_logprob": -0.4686271471854968, "compression_ratio": 1.2765957446808511, "no_speech_prob": 3.2699044822948053e-05}, {"id": 1121, "seek": 582268, "start": 5822.68, "end": 5840.92, "text": " And here you can see normalize, and it normalizes with some set of image statistics, and the", "tokens": [400, 510, 291, 393, 536, 2710, 1125, 11, 293, 309, 2710, 5660, 365, 512, 992, 295, 3256, 12523, 11, 293, 264], "temperature": 0.0, "avg_logprob": -0.21617009346945243, "compression_ratio": 1.6142857142857143, "no_speech_prob": 2.561277142376639e-06}, {"id": 1122, "seek": 582268, "start": 5840.92, "end": 5844.320000000001, "text": " set of image statistics, they're basically hard-coded.", "tokens": [992, 295, 3256, 12523, 11, 436, 434, 1936, 1152, 12, 66, 12340, 13], "temperature": 0.0, "avg_logprob": -0.21617009346945243, "compression_ratio": 1.6142857142857143, "no_speech_prob": 2.561277142376639e-06}, {"id": 1123, "seek": 582268, "start": 5844.320000000001, "end": 5849.240000000001, "text": " This is the ImageNet statistics, this is statistics used for inception models.", "tokens": [639, 307, 264, 29903, 31890, 12523, 11, 341, 307, 12523, 1143, 337, 49834, 5245, 13], "temperature": 0.0, "avg_logprob": -0.21617009346945243, "compression_ratio": 1.6142857142857143, "no_speech_prob": 2.561277142376639e-06}, {"id": 1124, "seek": 584924, "start": 5849.24, "end": 5856.04, "text": " So there's a whole bunch of stuff that's been done to the input to get it ready to be passed", "tokens": [407, 456, 311, 257, 1379, 3840, 295, 1507, 300, 311, 668, 1096, 281, 264, 4846, 281, 483, 309, 1919, 281, 312, 4678], "temperature": 0.0, "avg_logprob": -0.11075307060690487, "compression_ratio": 1.5803108808290156, "no_speech_prob": 4.6378563638427295e-06}, {"id": 1125, "seek": 584924, "start": 5856.04, "end": 5859.28, "text": " to a pre-trained model.", "tokens": [281, 257, 659, 12, 17227, 2001, 2316, 13], "temperature": 0.0, "avg_logprob": -0.11075307060690487, "compression_ratio": 1.5803108808290156, "no_speech_prob": 4.6378563638427295e-06}, {"id": 1126, "seek": 584924, "start": 5859.28, "end": 5865.639999999999, "text": " So we have a function called denorm for denormalize.", "tokens": [407, 321, 362, 257, 2445, 1219, 1441, 687, 337, 1441, 24440, 1125, 13], "temperature": 0.0, "avg_logprob": -0.11075307060690487, "compression_ratio": 1.5803108808290156, "no_speech_prob": 4.6378563638427295e-06}, {"id": 1127, "seek": 584924, "start": 5865.639999999999, "end": 5872.04, "text": " It doesn't only denormalize, it also fixes up the dimension order and all that stuff.", "tokens": [467, 1177, 380, 787, 1441, 24440, 1125, 11, 309, 611, 32539, 493, 264, 10139, 1668, 293, 439, 300, 1507, 13], "temperature": 0.0, "avg_logprob": -0.11075307060690487, "compression_ratio": 1.5803108808290156, "no_speech_prob": 4.6378563638427295e-06}, {"id": 1128, "seek": 584924, "start": 5872.04, "end": 5877.48, "text": " And the denormalization depends on the transform.", "tokens": [400, 264, 1441, 24440, 2144, 5946, 322, 264, 4088, 13], "temperature": 0.0, "avg_logprob": -0.11075307060690487, "compression_ratio": 1.5803108808290156, "no_speech_prob": 4.6378563638427295e-06}, {"id": 1129, "seek": 587748, "start": 5877.48, "end": 5882.48, "text": " And the dataset knows what transform was used to create it, so that's why you have to go", "tokens": [400, 264, 28872, 3255, 437, 4088, 390, 1143, 281, 1884, 309, 11, 370, 300, 311, 983, 291, 362, 281, 352], "temperature": 0.0, "avg_logprob": -0.21022496904645646, "compression_ratio": 1.625, "no_speech_prob": 8.990950277620868e-07}, {"id": 1130, "seek": 587748, "start": 5882.48, "end": 5889.4, "text": " modelData.and then someDataSet.denorm, and that's a function that's stored for you that", "tokens": [2316, 35, 3274, 13, 474, 550, 512, 35, 3274, 42718, 13, 1556, 687, 11, 293, 300, 311, 257, 2445, 300, 311, 12187, 337, 291, 300], "temperature": 0.0, "avg_logprob": -0.21022496904645646, "compression_ratio": 1.625, "no_speech_prob": 8.990950277620868e-07}, {"id": 1131, "seek": 587748, "start": 5889.4, "end": 5892.639999999999, "text": " will undo everything.", "tokens": [486, 23779, 1203, 13], "temperature": 0.0, "avg_logprob": -0.21022496904645646, "compression_ratio": 1.625, "no_speech_prob": 8.990950277620868e-07}, {"id": 1132, "seek": 587748, "start": 5892.639999999999, "end": 5900.919999999999, "text": " And then you can pass that, a mini-batch, but you have to turn it into NumPy first.", "tokens": [400, 550, 291, 393, 1320, 300, 11, 257, 8382, 12, 65, 852, 11, 457, 291, 362, 281, 1261, 309, 666, 22592, 47, 88, 700, 13], "temperature": 0.0, "avg_logprob": -0.21022496904645646, "compression_ratio": 1.625, "no_speech_prob": 8.990950277620868e-07}, {"id": 1133, "seek": 587748, "start": 5900.919999999999, "end": 5905.719999999999, "text": " So this is like all the stuff that you need to be able to do to grab batches and look", "tokens": [407, 341, 307, 411, 439, 264, 1507, 300, 291, 643, 281, 312, 1075, 281, 360, 281, 4444, 15245, 279, 293, 574], "temperature": 0.0, "avg_logprob": -0.21022496904645646, "compression_ratio": 1.625, "no_speech_prob": 8.990950277620868e-07}, {"id": 1134, "seek": 587748, "start": 5905.719999999999, "end": 5907.4, "text": " at them.", "tokens": [412, 552, 13], "temperature": 0.0, "avg_logprob": -0.21022496904645646, "compression_ratio": 1.625, "no_speech_prob": 8.990950277620868e-07}, {"id": 1135, "seek": 590740, "start": 5907.4, "end": 5911.299999999999, "text": " And so after you've done all that, you can show the image and we've got back our list.", "tokens": [400, 370, 934, 291, 600, 1096, 439, 300, 11, 291, 393, 855, 264, 3256, 293, 321, 600, 658, 646, 527, 1329, 13], "temperature": 0.0, "avg_logprob": -0.2512730064742062, "compression_ratio": 1.5493562231759657, "no_speech_prob": 3.3931335110537475e-06}, {"id": 1136, "seek": 590740, "start": 5911.299999999999, "end": 5916.04, "text": " So that's looking good.", "tokens": [407, 300, 311, 1237, 665, 13], "temperature": 0.0, "avg_logprob": -0.2512730064742062, "compression_ratio": 1.5493562231759657, "no_speech_prob": 3.3931335110537475e-06}, {"id": 1137, "seek": 590740, "start": 5916.04, "end": 5919.28, "text": " So in the end, we've just got the standard 4 lines of code.", "tokens": [407, 294, 264, 917, 11, 321, 600, 445, 658, 264, 3832, 1017, 3876, 295, 3089, 13], "temperature": 0.0, "avg_logprob": -0.2512730064742062, "compression_ratio": 1.5493562231759657, "no_speech_prob": 3.3931335110537475e-06}, {"id": 1138, "seek": 590740, "start": 5919.28, "end": 5926.879999999999, "text": " We've got our transforms, we've got our modelData, convoluna.pre-trained, we're using a ResNet34", "tokens": [492, 600, 658, 527, 35592, 11, 321, 600, 658, 527, 2316, 35, 3274, 11, 3754, 401, 5051, 13, 3712, 12, 17227, 2001, 11, 321, 434, 1228, 257, 5015, 31890, 12249], "temperature": 0.0, "avg_logprob": -0.2512730064742062, "compression_ratio": 1.5493562231759657, "no_speech_prob": 3.3931335110537475e-06}, {"id": 1139, "seek": 590740, "start": 5926.879999999999, "end": 5935.24, "text": " here, we're going to add accuracy as a metric, fix some optimization function, do an LR find,", "tokens": [510, 11, 321, 434, 516, 281, 909, 14170, 382, 257, 20678, 11, 3191, 512, 19618, 2445, 11, 360, 364, 441, 49, 915, 11], "temperature": 0.0, "avg_logprob": -0.2512730064742062, "compression_ratio": 1.5493562231759657, "no_speech_prob": 3.3931335110537475e-06}, {"id": 1140, "seek": 593524, "start": 5935.24, "end": 5938.28, "text": " and that looks kind of weird, not particularly helpful.", "tokens": [293, 300, 1542, 733, 295, 3657, 11, 406, 4098, 4961, 13], "temperature": 0.0, "avg_logprob": -0.13997146487236023, "compression_ratio": 1.7777777777777777, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1141, "seek": 593524, "start": 5938.28, "end": 5941.48, "text": " Normally we would expect to see an uptick on the right.", "tokens": [17424, 321, 576, 2066, 281, 536, 364, 493, 83, 618, 322, 264, 558, 13], "temperature": 0.0, "avg_logprob": -0.13997146487236023, "compression_ratio": 1.7777777777777777, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1142, "seek": 593524, "start": 5941.48, "end": 5948.719999999999, "text": " The reason we don't see it is because we intentionally remove the first few points and the last few", "tokens": [440, 1778, 321, 500, 380, 536, 309, 307, 570, 321, 22062, 4159, 264, 700, 1326, 2793, 293, 264, 1036, 1326], "temperature": 0.0, "avg_logprob": -0.13997146487236023, "compression_ratio": 1.7777777777777777, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1143, "seek": 593524, "start": 5948.719999999999, "end": 5949.719999999999, "text": " points.", "tokens": [2793, 13], "temperature": 0.0, "avg_logprob": -0.13997146487236023, "compression_ratio": 1.7777777777777777, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1144, "seek": 593524, "start": 5949.719999999999, "end": 5954.0, "text": " The reason is that often the last few points shoot so high up towards infinity that you", "tokens": [440, 1778, 307, 300, 2049, 264, 1036, 1326, 2793, 3076, 370, 1090, 493, 3030, 13202, 300, 291], "temperature": 0.0, "avg_logprob": -0.13997146487236023, "compression_ratio": 1.7777777777777777, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1145, "seek": 593524, "start": 5954.0, "end": 5955.44, "text": " basically can't see anything.", "tokens": [1936, 393, 380, 536, 1340, 13], "temperature": 0.0, "avg_logprob": -0.13997146487236023, "compression_ratio": 1.7777777777777777, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1146, "seek": 593524, "start": 5955.44, "end": 5960.44, "text": " So the vast majority of the time, removing the last few points is a good idea.", "tokens": [407, 264, 8369, 6286, 295, 264, 565, 11, 12720, 264, 1036, 1326, 2793, 307, 257, 665, 1558, 13], "temperature": 0.0, "avg_logprob": -0.13997146487236023, "compression_ratio": 1.7777777777777777, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1147, "seek": 593524, "start": 5960.44, "end": 5965.16, "text": " However, when you've got very few mini-batches, sometimes it's not a good idea.", "tokens": [2908, 11, 562, 291, 600, 658, 588, 1326, 8382, 12, 65, 852, 279, 11, 2171, 309, 311, 406, 257, 665, 1558, 13], "temperature": 0.0, "avg_logprob": -0.13997146487236023, "compression_ratio": 1.7777777777777777, "no_speech_prob": 7.0718601818953175e-06}, {"id": 1148, "seek": 596516, "start": 5965.16, "end": 5968.84, "text": " And so a lot of people ask this on the forum, here's how you fix it.", "tokens": [400, 370, 257, 688, 295, 561, 1029, 341, 322, 264, 17542, 11, 510, 311, 577, 291, 3191, 309, 13], "temperature": 0.0, "avg_logprob": -0.2196477692702721, "compression_ratio": 1.598326359832636, "no_speech_prob": 5.422159574663965e-06}, {"id": 1149, "seek": 596516, "start": 5968.84, "end": 5974.36, "text": " Just say skip, by default it skips 10 at the start, so in this case we just say 5, by default", "tokens": [1449, 584, 10023, 11, 538, 7576, 309, 1110, 2600, 1266, 412, 264, 722, 11, 370, 294, 341, 1389, 321, 445, 584, 1025, 11, 538, 7576], "temperature": 0.0, "avg_logprob": -0.2196477692702721, "compression_ratio": 1.598326359832636, "no_speech_prob": 5.422159574663965e-06}, {"id": 1150, "seek": 596516, "start": 5974.36, "end": 5977.08, "text": " it skips 5 at the end, we'll just say 1.", "tokens": [309, 1110, 2600, 1025, 412, 264, 917, 11, 321, 603, 445, 584, 502, 13], "temperature": 0.0, "avg_logprob": -0.2196477692702721, "compression_ratio": 1.598326359832636, "no_speech_prob": 5.422159574663965e-06}, {"id": 1151, "seek": 596516, "start": 5977.08, "end": 5981.44, "text": " So now we can see the shape properly.", "tokens": [407, 586, 321, 393, 536, 264, 3909, 6108, 13], "temperature": 0.0, "avg_logprob": -0.2196477692702721, "compression_ratio": 1.598326359832636, "no_speech_prob": 5.422159574663965e-06}, {"id": 1152, "seek": 596516, "start": 5981.44, "end": 5986.08, "text": " If your dataset's really tiny, you may need to use a smaller batch size.", "tokens": [759, 428, 28872, 311, 534, 5870, 11, 291, 815, 643, 281, 764, 257, 4356, 15245, 2744, 13], "temperature": 0.0, "avg_logprob": -0.2196477692702721, "compression_ratio": 1.598326359832636, "no_speech_prob": 5.422159574663965e-06}, {"id": 1153, "seek": 596516, "start": 5986.08, "end": 5992.28, "text": " Like if you only have 3 or 4 batches worth, there's nothing to see.", "tokens": [1743, 498, 291, 787, 362, 805, 420, 1017, 15245, 279, 3163, 11, 456, 311, 1825, 281, 536, 13], "temperature": 0.0, "avg_logprob": -0.2196477692702721, "compression_ratio": 1.598326359832636, "no_speech_prob": 5.422159574663965e-06}, {"id": 1154, "seek": 599228, "start": 5992.28, "end": 5997.24, "text": " But in this case, it's fine, we just have to plot a little bit more.", "tokens": [583, 294, 341, 1389, 11, 309, 311, 2489, 11, 321, 445, 362, 281, 7542, 257, 707, 857, 544, 13], "temperature": 0.0, "avg_logprob": -0.24879474024618825, "compression_ratio": 1.472636815920398, "no_speech_prob": 1.618742862774525e-05}, {"id": 1155, "seek": 599228, "start": 5997.24, "end": 6005.32, "text": " So we pick our learning rate, we say fit, after one epoch, just training the last layer,", "tokens": [407, 321, 1888, 527, 2539, 3314, 11, 321, 584, 3318, 11, 934, 472, 30992, 339, 11, 445, 3097, 264, 1036, 4583, 11], "temperature": 0.0, "avg_logprob": -0.24879474024618825, "compression_ratio": 1.472636815920398, "no_speech_prob": 1.618742862774525e-05}, {"id": 1156, "seek": 599228, "start": 6005.32, "end": 6007.5199999999995, "text": " it's 80%.", "tokens": [309, 311, 4688, 6856], "temperature": 0.0, "avg_logprob": -0.24879474024618825, "compression_ratio": 1.472636815920398, "no_speech_prob": 1.618742862774525e-05}, {"id": 1157, "seek": 599228, "start": 6007.5199999999995, "end": 6014.36, "text": " Let's unfreeze a couple of layers, do another epoch, 82%.", "tokens": [961, 311, 3971, 701, 1381, 257, 1916, 295, 7914, 11, 360, 1071, 30992, 339, 11, 29097, 6856], "temperature": 0.0, "avg_logprob": -0.24879474024618825, "compression_ratio": 1.472636815920398, "no_speech_prob": 1.618742862774525e-05}, {"id": 1158, "seek": 599228, "start": 6014.36, "end": 6019.2, "text": " Freeze the whole thing, not really improving.", "tokens": [48096, 264, 1379, 551, 11, 406, 534, 11470, 13], "temperature": 0.0, "avg_logprob": -0.24879474024618825, "compression_ratio": 1.472636815920398, "no_speech_prob": 1.618742862774525e-05}, {"id": 1159, "seek": 599228, "start": 6019.2, "end": 6020.2, "text": " Why are we stuck at 80%?", "tokens": [1545, 366, 321, 5541, 412, 4688, 4, 30], "temperature": 0.0, "avg_logprob": -0.24879474024618825, "compression_ratio": 1.472636815920398, "no_speech_prob": 1.618742862774525e-05}, {"id": 1160, "seek": 602020, "start": 6020.2, "end": 6024.4, "text": " It kind of makes sense, right?", "tokens": [467, 733, 295, 1669, 2020, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21676788330078126, "compression_ratio": 1.5990338164251208, "no_speech_prob": 1.49709503602935e-05}, {"id": 1161, "seek": 602020, "start": 6024.4, "end": 6029.92, "text": " Unlike ImageNet or Dogs vs Cats where each image has one major thing, they were picked", "tokens": [17657, 29903, 31890, 420, 35504, 12041, 40902, 689, 1184, 3256, 575, 472, 2563, 551, 11, 436, 645, 6183], "temperature": 0.0, "avg_logprob": -0.21676788330078126, "compression_ratio": 1.5990338164251208, "no_speech_prob": 1.49709503602935e-05}, {"id": 1162, "seek": 602020, "start": 6029.92, "end": 6033.5199999999995, "text": " because they have one major thing, and the one major thing is what you're asked to look", "tokens": [570, 436, 362, 472, 2563, 551, 11, 293, 264, 472, 2563, 551, 307, 437, 291, 434, 2351, 281, 574], "temperature": 0.0, "avg_logprob": -0.21676788330078126, "compression_ratio": 1.5990338164251208, "no_speech_prob": 1.49709503602935e-05}, {"id": 1163, "seek": 602020, "start": 6033.5199999999995, "end": 6039.32, "text": " for, a lot of the Pascal dataset has lots of little things.", "tokens": [337, 11, 257, 688, 295, 264, 41723, 28872, 575, 3195, 295, 707, 721, 13], "temperature": 0.0, "avg_logprob": -0.21676788330078126, "compression_ratio": 1.5990338164251208, "no_speech_prob": 1.49709503602935e-05}, {"id": 1164, "seek": 602020, "start": 6039.32, "end": 6045.92, "text": " And so a largest classifier is not necessarily going to do great.", "tokens": [400, 370, 257, 6443, 1508, 9902, 307, 406, 4725, 516, 281, 360, 869, 13], "temperature": 0.0, "avg_logprob": -0.21676788330078126, "compression_ratio": 1.5990338164251208, "no_speech_prob": 1.49709503602935e-05}, {"id": 1165, "seek": 604592, "start": 6045.92, "end": 6054.08, "text": " But of course, we really need to be able to see the results, to see whether it makes sense.", "tokens": [583, 295, 1164, 11, 321, 534, 643, 281, 312, 1075, 281, 536, 264, 3542, 11, 281, 536, 1968, 309, 1669, 2020, 13], "temperature": 0.0, "avg_logprob": -0.1966165542602539, "compression_ratio": 1.7120622568093384, "no_speech_prob": 8.801010153547395e-06}, {"id": 1166, "seek": 604592, "start": 6054.08, "end": 6056.68, "text": " So we're going to write something that creates this.", "tokens": [407, 321, 434, 516, 281, 2464, 746, 300, 7829, 341, 13], "temperature": 0.0, "avg_logprob": -0.1966165542602539, "compression_ratio": 1.7120622568093384, "no_speech_prob": 8.801010153547395e-06}, {"id": 1167, "seek": 604592, "start": 6056.68, "end": 6062.32, "text": " And in this case, I'm kind of like, after working with this a while, I know what the", "tokens": [400, 294, 341, 1389, 11, 286, 478, 733, 295, 411, 11, 934, 1364, 365, 341, 257, 1339, 11, 286, 458, 437, 264], "temperature": 0.0, "avg_logprob": -0.1966165542602539, "compression_ratio": 1.7120622568093384, "no_speech_prob": 8.801010153547395e-06}, {"id": 1168, "seek": 604592, "start": 6062.32, "end": 6065.26, "text": " 20 Pascal classes are.", "tokens": [945, 41723, 5359, 366, 13], "temperature": 0.0, "avg_logprob": -0.1966165542602539, "compression_ratio": 1.7120622568093384, "no_speech_prob": 8.801010153547395e-06}, {"id": 1169, "seek": 604592, "start": 6065.26, "end": 6069.28, "text": " So I know there's a person and a bicycle class, I know there's a dog and a sofa class, so", "tokens": [407, 286, 458, 456, 311, 257, 954, 293, 257, 20888, 1508, 11, 286, 458, 456, 311, 257, 3000, 293, 257, 28668, 1508, 11, 370], "temperature": 0.0, "avg_logprob": -0.1966165542602539, "compression_ratio": 1.7120622568093384, "no_speech_prob": 8.801010153547395e-06}, {"id": 1170, "seek": 604592, "start": 6069.28, "end": 6071.92, "text": " I know this is wrong, it should be sofa, but that's correct.", "tokens": [286, 458, 341, 307, 2085, 11, 309, 820, 312, 28668, 11, 457, 300, 311, 3006, 13], "temperature": 0.0, "avg_logprob": -0.1966165542602539, "compression_ratio": 1.7120622568093384, "no_speech_prob": 8.801010153547395e-06}, {"id": 1171, "seek": 604592, "start": 6071.92, "end": 6073.64, "text": " Bird, yes, yes.", "tokens": [15931, 11, 2086, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.1966165542602539, "compression_ratio": 1.7120622568093384, "no_speech_prob": 8.801010153547395e-06}, {"id": 1172, "seek": 604592, "start": 6073.64, "end": 6074.8, "text": " Chair, that's wrong.", "tokens": [8678, 11, 300, 311, 2085, 13], "temperature": 0.0, "avg_logprob": -0.1966165542602539, "compression_ratio": 1.7120622568093384, "no_speech_prob": 8.801010153547395e-06}, {"id": 1173, "seek": 607480, "start": 6074.8, "end": 6076.2, "text": " I think the table is bigger.", "tokens": [286, 519, 264, 3199, 307, 3801, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1174, "seek": 607480, "start": 6076.2, "end": 6078.400000000001, "text": " Motorbike is correct because there's no cactus.", "tokens": [18495, 30283, 307, 3006, 570, 456, 311, 572, 44287, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1175, "seek": 607480, "start": 6078.400000000001, "end": 6080.2, "text": " That should be a bus.", "tokens": [663, 820, 312, 257, 1255, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1176, "seek": 607480, "start": 6080.2, "end": 6081.2, "text": " Person is correct.", "tokens": [8443, 307, 3006, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1177, "seek": 607480, "start": 6081.2, "end": 6082.2, "text": " Bird is correct.", "tokens": [15931, 307, 3006, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1178, "seek": 607480, "start": 6082.2, "end": 6083.2, "text": " Car is correct.", "tokens": [2741, 307, 3006, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1179, "seek": 607480, "start": 6083.2, "end": 6084.2, "text": " Plant is correct.", "tokens": [28995, 307, 3006, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1180, "seek": 607480, "start": 6084.2, "end": 6085.2, "text": " Car is correct.", "tokens": [2741, 307, 3006, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1181, "seek": 607480, "start": 6085.2, "end": 6088.0, "text": " So it's looking pretty good.", "tokens": [407, 309, 311, 1237, 1238, 665, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1182, "seek": 607480, "start": 6088.0, "end": 6096.96, "text": " So when you see a piece of code like this, if you're not familiar with all the steps", "tokens": [407, 562, 291, 536, 257, 2522, 295, 3089, 411, 341, 11, 498, 291, 434, 406, 4963, 365, 439, 264, 4439], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1183, "seek": 607480, "start": 6096.96, "end": 6103.68, "text": " to get there, it can be a little overwhelming.", "tokens": [281, 483, 456, 11, 309, 393, 312, 257, 707, 13373, 13], "temperature": 0.0, "avg_logprob": -0.2107448214576358, "compression_ratio": 1.6507177033492824, "no_speech_prob": 3.1381307508127065e-06}, {"id": 1184, "seek": 610368, "start": 6103.68, "end": 6107.68, "text": " And I feel the same way when I see a few lines of code and something I'm not familiar with,", "tokens": [400, 286, 841, 264, 912, 636, 562, 286, 536, 257, 1326, 3876, 295, 3089, 293, 746, 286, 478, 406, 4963, 365, 11], "temperature": 0.0, "avg_logprob": -0.17771480480829874, "compression_ratio": 1.6682926829268292, "no_speech_prob": 2.6425541364005767e-06}, {"id": 1185, "seek": 610368, "start": 6107.68, "end": 6109.68, "text": " I feel overwhelmed as well.", "tokens": [286, 841, 19042, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.17771480480829874, "compression_ratio": 1.6682926829268292, "no_speech_prob": 2.6425541364005767e-06}, {"id": 1186, "seek": 610368, "start": 6109.68, "end": 6117.280000000001, "text": " But it turns out there's two ways to make it super, super simple to understand the code.", "tokens": [583, 309, 4523, 484, 456, 311, 732, 2098, 281, 652, 309, 1687, 11, 1687, 2199, 281, 1223, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.17771480480829874, "compression_ratio": 1.6682926829268292, "no_speech_prob": 2.6425541364005767e-06}, {"id": 1187, "seek": 610368, "start": 6117.280000000001, "end": 6118.92, "text": " Or there's one high-level way.", "tokens": [1610, 456, 311, 472, 1090, 12, 12418, 636, 13], "temperature": 0.0, "avg_logprob": -0.17771480480829874, "compression_ratio": 1.6682926829268292, "no_speech_prob": 2.6425541364005767e-06}, {"id": 1188, "seek": 610368, "start": 6118.92, "end": 6128.0, "text": " The high-level way is run each line of code step at step, print out the inputs, print", "tokens": [440, 1090, 12, 12418, 636, 307, 1190, 1184, 1622, 295, 3089, 1823, 412, 1823, 11, 4482, 484, 264, 15743, 11, 4482], "temperature": 0.0, "avg_logprob": -0.17771480480829874, "compression_ratio": 1.6682926829268292, "no_speech_prob": 2.6425541364005767e-06}, {"id": 1189, "seek": 610368, "start": 6128.0, "end": 6129.0, "text": " out the outputs.", "tokens": [484, 264, 23930, 13], "temperature": 0.0, "avg_logprob": -0.17771480480829874, "compression_ratio": 1.6682926829268292, "no_speech_prob": 2.6425541364005767e-06}, {"id": 1190, "seek": 612900, "start": 6129.0, "end": 6133.88, "text": " Most of the time, that'll be enough.", "tokens": [4534, 295, 264, 565, 11, 300, 603, 312, 1547, 13], "temperature": 0.0, "avg_logprob": -0.13350915908813477, "compression_ratio": 1.662037037037037, "no_speech_prob": 4.637845904653659e-06}, {"id": 1191, "seek": 612900, "start": 6133.88, "end": 6139.04, "text": " If there's a line of code where you don't understand how the outputs relate to the inputs,", "tokens": [759, 456, 311, 257, 1622, 295, 3089, 689, 291, 500, 380, 1223, 577, 264, 23930, 10961, 281, 264, 15743, 11], "temperature": 0.0, "avg_logprob": -0.13350915908813477, "compression_ratio": 1.662037037037037, "no_speech_prob": 4.637845904653659e-06}, {"id": 1192, "seek": 612900, "start": 6139.04, "end": 6141.12, "text": " go and have a look for the source.", "tokens": [352, 293, 362, 257, 574, 337, 264, 4009, 13], "temperature": 0.0, "avg_logprob": -0.13350915908813477, "compression_ratio": 1.662037037037037, "no_speech_prob": 4.637845904653659e-06}, {"id": 1193, "seek": 612900, "start": 6141.12, "end": 6145.72, "text": " So now all you need to know is what are the two ways you can step through the lines of", "tokens": [407, 586, 439, 291, 643, 281, 458, 307, 437, 366, 264, 732, 2098, 291, 393, 1823, 807, 264, 3876, 295], "temperature": 0.0, "avg_logprob": -0.13350915908813477, "compression_ratio": 1.662037037037037, "no_speech_prob": 4.637845904653659e-06}, {"id": 1194, "seek": 612900, "start": 6145.72, "end": 6148.44, "text": " code one at a time.", "tokens": [3089, 472, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.13350915908813477, "compression_ratio": 1.662037037037037, "no_speech_prob": 4.637845904653659e-06}, {"id": 1195, "seek": 612900, "start": 6148.44, "end": 6157.84, "text": " The way I use perhaps the most often is to take the contents of the loop, copy it, create", "tokens": [440, 636, 286, 764, 4317, 264, 881, 2049, 307, 281, 747, 264, 15768, 295, 264, 6367, 11, 5055, 309, 11, 1884], "temperature": 0.0, "avg_logprob": -0.13350915908813477, "compression_ratio": 1.662037037037037, "no_speech_prob": 4.637845904653659e-06}, {"id": 1196, "seek": 615784, "start": 6157.84, "end": 6165.72, "text": " a cell above it, paste it, outdent it, write i equals 0, and then put them all in separate", "tokens": [257, 2815, 3673, 309, 11, 9163, 309, 11, 484, 67, 317, 309, 11, 2464, 741, 6915, 1958, 11, 293, 550, 829, 552, 439, 294, 4994], "temperature": 0.0, "avg_logprob": -0.17689760526021323, "compression_ratio": 1.6296296296296295, "no_speech_prob": 5.95510755374562e-06}, {"id": 1197, "seek": 615784, "start": 6165.72, "end": 6172.84, "text": " cells and then run each one one at a time, printing out the input samples.", "tokens": [5438, 293, 550, 1190, 1184, 472, 472, 412, 257, 565, 11, 14699, 484, 264, 4846, 10938, 13], "temperature": 0.0, "avg_logprob": -0.17689760526021323, "compression_ratio": 1.6296296296296295, "no_speech_prob": 5.95510755374562e-06}, {"id": 1198, "seek": 615784, "start": 6172.84, "end": 6177.68, "text": " I know that's obvious, but the number of times I actually see people do that when they ask", "tokens": [286, 458, 300, 311, 6322, 11, 457, 264, 1230, 295, 1413, 286, 767, 536, 561, 360, 300, 562, 436, 1029], "temperature": 0.0, "avg_logprob": -0.17689760526021323, "compression_ratio": 1.6296296296296295, "no_speech_prob": 5.95510755374562e-06}, {"id": 1199, "seek": 615784, "start": 6177.68, "end": 6181.76, "text": " me for help is basically zero, because if they had done that, they wouldn't be asking", "tokens": [385, 337, 854, 307, 1936, 4018, 11, 570, 498, 436, 632, 1096, 300, 11, 436, 2759, 380, 312, 3365], "temperature": 0.0, "avg_logprob": -0.17689760526021323, "compression_ratio": 1.6296296296296295, "no_speech_prob": 5.95510755374562e-06}, {"id": 1200, "seek": 615784, "start": 6181.76, "end": 6186.08, "text": " for help.", "tokens": [337, 854, 13], "temperature": 0.0, "avg_logprob": -0.17689760526021323, "compression_ratio": 1.6296296296296295, "no_speech_prob": 5.95510755374562e-06}, {"id": 1201, "seek": 618608, "start": 6186.08, "end": 6190.68, "text": " Another method that's super handy, and there's particular situations where it's super super", "tokens": [3996, 3170, 300, 311, 1687, 13239, 11, 293, 456, 311, 1729, 6851, 689, 309, 311, 1687, 1687], "temperature": 0.0, "avg_logprob": -0.17595305067769598, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.2411396710376721e-05}, {"id": 1202, "seek": 618608, "start": 6190.68, "end": 6193.64, "text": " handy, is to use the Python debugger.", "tokens": [13239, 11, 307, 281, 764, 264, 15329, 24083, 1321, 13], "temperature": 0.0, "avg_logprob": -0.17595305067769598, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.2411396710376721e-05}, {"id": 1203, "seek": 618608, "start": 6193.64, "end": 6197.08, "text": " Who here has used a debugger before?", "tokens": [2102, 510, 575, 1143, 257, 24083, 1321, 949, 30], "temperature": 0.0, "avg_logprob": -0.17595305067769598, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.2411396710376721e-05}, {"id": 1204, "seek": 618608, "start": 6197.08, "end": 6200.3, "text": " So half to two-thirds.", "tokens": [407, 1922, 281, 732, 12, 38507, 13], "temperature": 0.0, "avg_logprob": -0.17595305067769598, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.2411396710376721e-05}, {"id": 1205, "seek": 618608, "start": 6200.3, "end": 6204.32, "text": " So for the other half of you, this will be life-changing.", "tokens": [407, 337, 264, 661, 1922, 295, 291, 11, 341, 486, 312, 993, 12, 27123, 13], "temperature": 0.0, "avg_logprob": -0.17595305067769598, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.2411396710376721e-05}, {"id": 1206, "seek": 618608, "start": 6204.32, "end": 6210.84, "text": " Actually a guy I know this morning who's actually a deep learning researcher wrote on Twitter", "tokens": [5135, 257, 2146, 286, 458, 341, 2446, 567, 311, 767, 257, 2452, 2539, 21751, 4114, 322, 5794], "temperature": 0.0, "avg_logprob": -0.17595305067769598, "compression_ratio": 1.6161137440758293, "no_speech_prob": 1.2411396710376721e-05}, {"id": 1207, "seek": 621084, "start": 6210.84, "end": 6216.28, "text": " and his message on Twitter was, how come nobody told me about the Python debugger before my", "tokens": [293, 702, 3636, 322, 5794, 390, 11, 577, 808, 5079, 1907, 385, 466, 264, 15329, 24083, 1321, 949, 452], "temperature": 0.0, "avg_logprob": -0.1832294353218966, "compression_ratio": 1.5147679324894514, "no_speech_prob": 2.318703081982676e-05}, {"id": 1208, "seek": 621084, "start": 6216.28, "end": 6219.32, "text": " life has changed?", "tokens": [993, 575, 3105, 30], "temperature": 0.0, "avg_logprob": -0.1832294353218966, "compression_ratio": 1.5147679324894514, "no_speech_prob": 2.318703081982676e-05}, {"id": 1209, "seek": 621084, "start": 6219.32, "end": 6224.9800000000005, "text": " And like this guy's an expert, but because nobody teaches basic software engineering", "tokens": [400, 411, 341, 2146, 311, 364, 5844, 11, 457, 570, 5079, 16876, 3875, 4722, 7043], "temperature": 0.0, "avg_logprob": -0.1832294353218966, "compression_ratio": 1.5147679324894514, "no_speech_prob": 2.318703081982676e-05}, {"id": 1210, "seek": 621084, "start": 6224.9800000000005, "end": 6232.92, "text": " skills in academic courses, nobody thought to say to him, hey Mark, do you know what?", "tokens": [3942, 294, 7778, 7712, 11, 5079, 1194, 281, 584, 281, 796, 11, 4177, 3934, 11, 360, 291, 458, 437, 30], "temperature": 0.0, "avg_logprob": -0.1832294353218966, "compression_ratio": 1.5147679324894514, "no_speech_prob": 2.318703081982676e-05}, {"id": 1211, "seek": 621084, "start": 6232.92, "end": 6238.28, "text": " There's something that shows you everything your code does one step at a time.", "tokens": [821, 311, 746, 300, 3110, 291, 1203, 428, 3089, 775, 472, 1823, 412, 257, 565, 13], "temperature": 0.0, "avg_logprob": -0.1832294353218966, "compression_ratio": 1.5147679324894514, "no_speech_prob": 2.318703081982676e-05}, {"id": 1212, "seek": 623828, "start": 6238.28, "end": 6243.84, "text": " So I replied on Twitter and I said, good news Mark, not only that, every single language", "tokens": [407, 286, 20345, 322, 5794, 293, 286, 848, 11, 665, 2583, 3934, 11, 406, 787, 300, 11, 633, 2167, 2856], "temperature": 0.0, "avg_logprob": -0.13884446115204782, "compression_ratio": 1.5913043478260869, "no_speech_prob": 2.9022974104009336e-06}, {"id": 1213, "seek": 623828, "start": 6243.84, "end": 6248.92, "text": " in existence in every single operating system also has a debugger, and if you Google for", "tokens": [294, 9123, 294, 633, 2167, 7447, 1185, 611, 575, 257, 24083, 1321, 11, 293, 498, 291, 3329, 337], "temperature": 0.0, "avg_logprob": -0.13884446115204782, "compression_ratio": 1.5913043478260869, "no_speech_prob": 2.9022974104009336e-06}, {"id": 1214, "seek": 623828, "start": 6248.92, "end": 6252.719999999999, "text": " language name debugger, it will tell you how to use it.", "tokens": [2856, 1315, 24083, 1321, 11, 309, 486, 980, 291, 577, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.13884446115204782, "compression_ratio": 1.5913043478260869, "no_speech_prob": 2.9022974104009336e-06}, {"id": 1215, "seek": 623828, "start": 6252.719999999999, "end": 6255.8, "text": " So there's a meta piece of information for you.", "tokens": [407, 456, 311, 257, 19616, 2522, 295, 1589, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.13884446115204782, "compression_ratio": 1.5913043478260869, "no_speech_prob": 2.9022974104009336e-06}, {"id": 1216, "seek": 623828, "start": 6255.8, "end": 6260.2, "text": " In Python, the standard debugger is called PDB.", "tokens": [682, 15329, 11, 264, 3832, 24083, 1321, 307, 1219, 10464, 33, 13], "temperature": 0.0, "avg_logprob": -0.13884446115204782, "compression_ratio": 1.5913043478260869, "no_speech_prob": 2.9022974104009336e-06}, {"id": 1217, "seek": 623828, "start": 6260.2, "end": 6263.0599999999995, "text": " And there's two main ways to use it.", "tokens": [400, 456, 311, 732, 2135, 2098, 281, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.13884446115204782, "compression_ratio": 1.5913043478260869, "no_speech_prob": 2.9022974104009336e-06}, {"id": 1218, "seek": 626306, "start": 6263.06, "end": 6270.04, "text": " The first is to go into your code, and the reason I'm mentioning this now is because", "tokens": [440, 700, 307, 281, 352, 666, 428, 3089, 11, 293, 264, 1778, 286, 478, 18315, 341, 586, 307, 570], "temperature": 0.0, "avg_logprob": -0.12322493680973642, "compression_ratio": 1.508849557522124, "no_speech_prob": 1.0289394595019985e-05}, {"id": 1219, "seek": 626306, "start": 6270.04, "end": 6276.52, "text": " during the next few weeks, if you're anything like me, 99% of the time you'll be in a situation", "tokens": [1830, 264, 958, 1326, 3259, 11, 498, 291, 434, 1340, 411, 385, 11, 11803, 4, 295, 264, 565, 291, 603, 312, 294, 257, 2590], "temperature": 0.0, "avg_logprob": -0.12322493680973642, "compression_ratio": 1.508849557522124, "no_speech_prob": 1.0289394595019985e-05}, {"id": 1220, "seek": 626306, "start": 6276.52, "end": 6278.92, "text": " where your code's not working.", "tokens": [689, 428, 3089, 311, 406, 1364, 13], "temperature": 0.0, "avg_logprob": -0.12322493680973642, "compression_ratio": 1.508849557522124, "no_speech_prob": 1.0289394595019985e-05}, {"id": 1221, "seek": 626306, "start": 6278.92, "end": 6284.84, "text": " And very often it'll have been on the 14th mini-batch inside the forward method of your", "tokens": [400, 588, 2049, 309, 603, 362, 668, 322, 264, 3499, 392, 8382, 12, 65, 852, 1854, 264, 2128, 3170, 295, 428], "temperature": 0.0, "avg_logprob": -0.12322493680973642, "compression_ratio": 1.508849557522124, "no_speech_prob": 1.0289394595019985e-05}, {"id": 1222, "seek": 626306, "start": 6284.84, "end": 6286.64, "text": " custom module.", "tokens": [2375, 10088, 13], "temperature": 0.0, "avg_logprob": -0.12322493680973642, "compression_ratio": 1.508849557522124, "no_speech_prob": 1.0289394595019985e-05}, {"id": 1223, "seek": 626306, "start": 6286.64, "end": 6289.120000000001, "text": " It's like, what do you do?", "tokens": [467, 311, 411, 11, 437, 360, 291, 360, 30], "temperature": 0.0, "avg_logprob": -0.12322493680973642, "compression_ratio": 1.508849557522124, "no_speech_prob": 1.0289394595019985e-05}, {"id": 1224, "seek": 628912, "start": 6289.12, "end": 6294.5599999999995, "text": " And the answer is, you go inside your module and you write that.", "tokens": [400, 264, 1867, 307, 11, 291, 352, 1854, 428, 10088, 293, 291, 2464, 300, 13], "temperature": 0.0, "avg_logprob": -0.22615459401120422, "compression_ratio": 1.542857142857143, "no_speech_prob": 1.0451448360981885e-05}, {"id": 1225, "seek": 628912, "start": 6294.5599999999995, "end": 6304.16, "text": " And if you know it's only happening on the 14th iteration, you type if i equals 13.", "tokens": [400, 498, 291, 458, 309, 311, 787, 2737, 322, 264, 3499, 392, 24784, 11, 291, 2010, 498, 741, 6915, 3705, 13], "temperature": 0.0, "avg_logprob": -0.22615459401120422, "compression_ratio": 1.542857142857143, "no_speech_prob": 1.0451448360981885e-05}, {"id": 1226, "seek": 628912, "start": 6304.16, "end": 6307.5599999999995, "text": " So you can set a conditional breakpoint.", "tokens": [407, 291, 393, 992, 257, 27708, 1821, 6053, 13], "temperature": 0.0, "avg_logprob": -0.22615459401120422, "compression_ratio": 1.542857142857143, "no_speech_prob": 1.0451448360981885e-05}, {"id": 1227, "seek": 628912, "start": 6307.5599999999995, "end": 6314.2, "text": " PDB is the Python debugger, fastai imports it for you, if you get the message that PDB", "tokens": [10464, 33, 307, 264, 15329, 24083, 1321, 11, 2370, 1301, 41596, 309, 337, 291, 11, 498, 291, 483, 264, 3636, 300, 10464, 33], "temperature": 0.0, "avg_logprob": -0.22615459401120422, "compression_ratio": 1.542857142857143, "no_speech_prob": 1.0451448360981885e-05}, {"id": 1228, "seek": 628912, "start": 6314.2, "end": 6317.46, "text": " is not there, then you can just say import PDB.", "tokens": [307, 406, 456, 11, 550, 291, 393, 445, 584, 974, 10464, 33, 13], "temperature": 0.0, "avg_logprob": -0.22615459401120422, "compression_ratio": 1.542857142857143, "no_speech_prob": 1.0451448360981885e-05}, {"id": 1229, "seek": 631746, "start": 6317.46, "end": 6319.44, "text": " So let's try that.", "tokens": [407, 718, 311, 853, 300, 13], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1230, "seek": 631746, "start": 6319.44, "end": 6323.44, "text": " It's not the most user-friendly experience.", "tokens": [467, 311, 406, 264, 881, 4195, 12, 22864, 1752, 13], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1231, "seek": 631746, "start": 6323.44, "end": 6325.52, "text": " It just pops up a box.", "tokens": [467, 445, 16795, 493, 257, 2424, 13], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1232, "seek": 631746, "start": 6325.52, "end": 6329.96, "text": " But the first cool thing to notice is, holy shit, the debugger even works in a notebook.", "tokens": [583, 264, 700, 1627, 551, 281, 3449, 307, 11, 10622, 4611, 11, 264, 24083, 1321, 754, 1985, 294, 257, 21060, 13], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1233, "seek": 631746, "start": 6329.96, "end": 6330.96, "text": " So that's pretty nifty.", "tokens": [407, 300, 311, 1238, 297, 37177, 13], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1234, "seek": 631746, "start": 6330.96, "end": 6335.12, "text": " It'll also work in the terminal.", "tokens": [467, 603, 611, 589, 294, 264, 14709, 13], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1235, "seek": 631746, "start": 6335.12, "end": 6336.92, "text": " And so what can you do?", "tokens": [400, 370, 437, 393, 291, 360, 30], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1236, "seek": 631746, "start": 6336.92, "end": 6340.08, "text": " You can type h for help.", "tokens": [509, 393, 2010, 276, 337, 854, 13], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1237, "seek": 631746, "start": 6340.08, "end": 6342.6, "text": " And there are plenty of tutorials here.", "tokens": [400, 456, 366, 7140, 295, 17616, 510, 13], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1238, "seek": 631746, "start": 6342.6, "end": 6346.08, "text": " The main thing to know is this is one of these situations where you definitely want to know", "tokens": [440, 2135, 551, 281, 458, 307, 341, 307, 472, 295, 613, 6851, 689, 291, 2138, 528, 281, 458], "temperature": 0.0, "avg_logprob": -0.1797988828548715, "compression_ratio": 1.615686274509804, "no_speech_prob": 3.5559683055907954e-06}, {"id": 1239, "seek": 634608, "start": 6346.08, "end": 6348.16, "text": " the one-letter mnemonics.", "tokens": [264, 472, 12, 21248, 275, 25989, 266, 1167, 13], "temperature": 0.0, "avg_logprob": -0.15442840420469947, "compression_ratio": 1.7263157894736842, "no_speech_prob": 5.771883479610551e-06}, {"id": 1240, "seek": 634608, "start": 6348.16, "end": 6351.8, "text": " So you could type next, but you definitely want to type in.", "tokens": [407, 291, 727, 2010, 958, 11, 457, 291, 2138, 528, 281, 2010, 294, 13], "temperature": 0.0, "avg_logprob": -0.15442840420469947, "compression_ratio": 1.7263157894736842, "no_speech_prob": 5.771883479610551e-06}, {"id": 1241, "seek": 634608, "start": 6351.8, "end": 6355.04, "text": " You could type continue, but you definitely want to type c.", "tokens": [509, 727, 2010, 2354, 11, 457, 291, 2138, 528, 281, 2010, 269, 13], "temperature": 0.0, "avg_logprob": -0.15442840420469947, "compression_ratio": 1.7263157894736842, "no_speech_prob": 5.771883479610551e-06}, {"id": 1242, "seek": 634608, "start": 6355.04, "end": 6357.26, "text": " I've listed the main ones you need.", "tokens": [286, 600, 10052, 264, 2135, 2306, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.15442840420469947, "compression_ratio": 1.7263157894736842, "no_speech_prob": 5.771883479610551e-06}, {"id": 1243, "seek": 634608, "start": 6357.26, "end": 6366.32, "text": " So what I can do now that I'm sitting here is, it shows me the line, it's about to run.", "tokens": [407, 437, 286, 393, 360, 586, 300, 286, 478, 3798, 510, 307, 11, 309, 3110, 385, 264, 1622, 11, 309, 311, 466, 281, 1190, 13], "temperature": 0.0, "avg_logprob": -0.15442840420469947, "compression_ratio": 1.7263157894736842, "no_speech_prob": 5.771883479610551e-06}, {"id": 1244, "seek": 634608, "start": 6366.32, "end": 6372.88, "text": " So one thing I might want to do is to print out something.", "tokens": [407, 472, 551, 286, 1062, 528, 281, 360, 307, 281, 4482, 484, 746, 13], "temperature": 0.0, "avg_logprob": -0.15442840420469947, "compression_ratio": 1.7263157894736842, "no_speech_prob": 5.771883479610551e-06}, {"id": 1245, "seek": 637288, "start": 6372.88, "end": 6381.08, "text": " And I can write any Python expression and hit enter and find it.", "tokens": [400, 286, 393, 2464, 604, 15329, 6114, 293, 2045, 3242, 293, 915, 309, 13], "temperature": 0.0, "avg_logprob": -0.2433522475393195, "compression_ratio": 1.5609756097560976, "no_speech_prob": 2.9480104331014445e-06}, {"id": 1246, "seek": 637288, "start": 6381.08, "end": 6384.76, "text": " So that's a useful thing to do.", "tokens": [407, 300, 311, 257, 4420, 551, 281, 360, 13], "temperature": 0.0, "avg_logprob": -0.2433522475393195, "compression_ratio": 1.5609756097560976, "no_speech_prob": 2.9480104331014445e-06}, {"id": 1247, "seek": 637288, "start": 6384.76, "end": 6389.84, "text": " I might want to find out more about, where am I in the code more generally?", "tokens": [286, 1062, 528, 281, 915, 484, 544, 466, 11, 689, 669, 286, 294, 264, 3089, 544, 5101, 30], "temperature": 0.0, "avg_logprob": -0.2433522475393195, "compression_ratio": 1.5609756097560976, "no_speech_prob": 2.9480104331014445e-06}, {"id": 1248, "seek": 637288, "start": 6389.84, "end": 6393.04, "text": " I just want to see this line, but what's the before it and after it?", "tokens": [286, 445, 528, 281, 536, 341, 1622, 11, 457, 437, 311, 264, 949, 309, 293, 934, 309, 30], "temperature": 0.0, "avg_logprob": -0.2433522475393195, "compression_ratio": 1.5609756097560976, "no_speech_prob": 2.9480104331014445e-06}, {"id": 1249, "seek": 637288, "start": 6393.04, "end": 6395.64, "text": " In this case I want l for list.", "tokens": [682, 341, 1389, 286, 528, 287, 337, 1329, 13], "temperature": 0.0, "avg_logprob": -0.2433522475393195, "compression_ratio": 1.5609756097560976, "no_speech_prob": 2.9480104331014445e-06}, {"id": 1250, "seek": 637288, "start": 6395.64, "end": 6398.3, "text": " And so you can see I'm about to run that line.", "tokens": [400, 370, 291, 393, 536, 286, 478, 466, 281, 1190, 300, 1622, 13], "temperature": 0.0, "avg_logprob": -0.2433522475393195, "compression_ratio": 1.5609756097560976, "no_speech_prob": 2.9480104331014445e-06}, {"id": 1251, "seek": 639830, "start": 6398.3, "end": 6403.400000000001, "text": " These are the lines above it and below it.", "tokens": [1981, 366, 264, 3876, 3673, 309, 293, 2507, 309, 13], "temperature": 0.0, "avg_logprob": -0.20184063461591611, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.507582500285935e-06}, {"id": 1252, "seek": 639830, "start": 6403.400000000001, "end": 6407.14, "text": " So I might be now like, okay, let's run this line and see what happens.", "tokens": [407, 286, 1062, 312, 586, 411, 11, 1392, 11, 718, 311, 1190, 341, 1622, 293, 536, 437, 2314, 13], "temperature": 0.0, "avg_logprob": -0.20184063461591611, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.507582500285935e-06}, {"id": 1253, "seek": 639830, "start": 6407.14, "end": 6409.360000000001, "text": " So go to the next line, hit n.", "tokens": [407, 352, 281, 264, 958, 1622, 11, 2045, 297, 13], "temperature": 0.0, "avg_logprob": -0.20184063461591611, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.507582500285935e-06}, {"id": 1254, "seek": 639830, "start": 6409.360000000001, "end": 6415.4800000000005, "text": " And you can see now it's about to run the next line.", "tokens": [400, 291, 393, 536, 586, 309, 311, 466, 281, 1190, 264, 958, 1622, 13], "temperature": 0.0, "avg_logprob": -0.20184063461591611, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.507582500285935e-06}, {"id": 1255, "seek": 639830, "start": 6415.4800000000005, "end": 6417.78, "text": " One handy tip, you don't even have to type n.", "tokens": [1485, 13239, 4125, 11, 291, 500, 380, 754, 362, 281, 2010, 297, 13], "temperature": 0.0, "avg_logprob": -0.20184063461591611, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.507582500285935e-06}, {"id": 1256, "seek": 639830, "start": 6417.78, "end": 6422.72, "text": " If you just hit enter, it repeats the last thing you did.", "tokens": [759, 291, 445, 2045, 3242, 11, 309, 35038, 264, 1036, 551, 291, 630, 13], "temperature": 0.0, "avg_logprob": -0.20184063461591611, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.507582500285935e-06}, {"id": 1257, "seek": 639830, "start": 6422.72, "end": 6426.0, "text": " So I now should have a thing called b.", "tokens": [407, 286, 586, 820, 362, 257, 551, 1219, 272, 13], "temperature": 0.0, "avg_logprob": -0.20184063461591611, "compression_ratio": 1.631578947368421, "no_speech_prob": 5.507582500285935e-06}, {"id": 1258, "seek": 642600, "start": 6426.0, "end": 6430.96, "text": " Unfortunately, single letters are often used for debugger commands.", "tokens": [8590, 11, 2167, 7825, 366, 2049, 1143, 337, 24083, 1321, 16901, 13], "temperature": 0.0, "avg_logprob": -0.23222452680641245, "compression_ratio": 1.6009615384615385, "no_speech_prob": 3.1875595141173108e-06}, {"id": 1259, "seek": 642600, "start": 6430.96, "end": 6435.6, "text": " So if I just type b, it'll run the b command rather than print b for me.", "tokens": [407, 498, 286, 445, 2010, 272, 11, 309, 603, 1190, 264, 272, 5622, 2831, 813, 4482, 272, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.23222452680641245, "compression_ratio": 1.6009615384615385, "no_speech_prob": 3.1875595141173108e-06}, {"id": 1260, "seek": 642600, "start": 6435.6, "end": 6438.16, "text": " So to force it to print, you use p.", "tokens": [407, 281, 3464, 309, 281, 4482, 11, 291, 764, 280, 13], "temperature": 0.0, "avg_logprob": -0.23222452680641245, "compression_ratio": 1.6009615384615385, "no_speech_prob": 3.1875595141173108e-06}, {"id": 1261, "seek": 642600, "start": 6438.16, "end": 6439.16, "text": " Print b.", "tokens": [34439, 272, 13], "temperature": 0.0, "avg_logprob": -0.23222452680641245, "compression_ratio": 1.6009615384615385, "no_speech_prob": 3.1875595141173108e-06}, {"id": 1262, "seek": 642600, "start": 6439.16, "end": 6442.16, "text": " So there's a bird.", "tokens": [407, 456, 311, 257, 5255, 13], "temperature": 0.0, "avg_logprob": -0.23222452680641245, "compression_ratio": 1.6009615384615385, "no_speech_prob": 3.1875595141173108e-06}, {"id": 1263, "seek": 642600, "start": 6442.16, "end": 6448.28, "text": " All right, fine, let's do next again.", "tokens": [1057, 558, 11, 2489, 11, 718, 311, 360, 958, 797, 13], "temperature": 0.0, "avg_logprob": -0.23222452680641245, "compression_ratio": 1.6009615384615385, "no_speech_prob": 3.1875595141173108e-06}, {"id": 1264, "seek": 642600, "start": 6448.28, "end": 6453.0, "text": " At this point, if I hit next, it'll draw the text.", "tokens": [1711, 341, 935, 11, 498, 286, 2045, 958, 11, 309, 603, 2642, 264, 2487, 13], "temperature": 0.0, "avg_logprob": -0.23222452680641245, "compression_ratio": 1.6009615384615385, "no_speech_prob": 3.1875595141173108e-06}, {"id": 1265, "seek": 642600, "start": 6453.0, "end": 6455.6, "text": " But I don't want to just draw the text.", "tokens": [583, 286, 500, 380, 528, 281, 445, 2642, 264, 2487, 13], "temperature": 0.0, "avg_logprob": -0.23222452680641245, "compression_ratio": 1.6009615384615385, "no_speech_prob": 3.1875595141173108e-06}, {"id": 1266, "seek": 645560, "start": 6455.6, "end": 6457.860000000001, "text": " I want to know how it's going to draw the text.", "tokens": [286, 528, 281, 458, 577, 309, 311, 516, 281, 2642, 264, 2487, 13], "temperature": 0.0, "avg_logprob": -0.18296342302662458, "compression_ratio": 1.8497652582159625, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1267, "seek": 645560, "start": 6457.860000000001, "end": 6459.4400000000005, "text": " So I don't want to go next over it.", "tokens": [407, 286, 500, 380, 528, 281, 352, 958, 670, 309, 13], "temperature": 0.0, "avg_logprob": -0.18296342302662458, "compression_ratio": 1.8497652582159625, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1268, "seek": 645560, "start": 6459.4400000000005, "end": 6461.72, "text": " I want to s-step into it.", "tokens": [286, 528, 281, 262, 12, 16792, 666, 309, 13], "temperature": 0.0, "avg_logprob": -0.18296342302662458, "compression_ratio": 1.8497652582159625, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1269, "seek": 645560, "start": 6461.72, "end": 6467.08, "text": " So if I now hit s-step into it, I'm now inside drawText.", "tokens": [407, 498, 286, 586, 2045, 262, 12, 16792, 666, 309, 11, 286, 478, 586, 1854, 2642, 50198, 13], "temperature": 0.0, "avg_logprob": -0.18296342302662458, "compression_ratio": 1.8497652582159625, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1270, "seek": 645560, "start": 6467.08, "end": 6468.56, "text": " And I now hit n.", "tokens": [400, 286, 586, 2045, 297, 13], "temperature": 0.0, "avg_logprob": -0.18296342302662458, "compression_ratio": 1.8497652582159625, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1271, "seek": 645560, "start": 6468.56, "end": 6472.76, "text": " I can see drawText and so forth.", "tokens": [286, 393, 536, 2642, 50198, 293, 370, 5220, 13], "temperature": 0.0, "avg_logprob": -0.18296342302662458, "compression_ratio": 1.8497652582159625, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1272, "seek": 645560, "start": 6472.76, "end": 6476.4800000000005, "text": " And then I'm like, okay, I know everything I want to know about this.", "tokens": [400, 550, 286, 478, 411, 11, 1392, 11, 286, 458, 1203, 286, 528, 281, 458, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.18296342302662458, "compression_ratio": 1.8497652582159625, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1273, "seek": 645560, "start": 6476.4800000000005, "end": 6479.120000000001, "text": " I will continue until I hit the next breakpoint.", "tokens": [286, 486, 2354, 1826, 286, 2045, 264, 958, 1821, 6053, 13], "temperature": 0.0, "avg_logprob": -0.18296342302662458, "compression_ratio": 1.8497652582159625, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1274, "seek": 645560, "start": 6479.120000000001, "end": 6485.56, "text": " So c will continue until I'm back at the breakpoint again.", "tokens": [407, 269, 486, 2354, 1826, 286, 478, 646, 412, 264, 1821, 6053, 797, 13], "temperature": 0.0, "avg_logprob": -0.18296342302662458, "compression_ratio": 1.8497652582159625, "no_speech_prob": 1.0289454621670302e-05}, {"id": 1275, "seek": 648556, "start": 6485.56, "end": 6493.88, "text": " What if I was zipping along, and this happens quite often, that like, let's step into denorm.", "tokens": [708, 498, 286, 390, 710, 6297, 2051, 11, 293, 341, 2314, 1596, 2049, 11, 300, 411, 11, 718, 311, 1823, 666, 1441, 687, 13], "temperature": 0.0, "avg_logprob": -0.15221658759160872, "compression_ratio": 1.6239669421487604, "no_speech_prob": 3.90547620554571e-06}, {"id": 1276, "seek": 648556, "start": 6493.88, "end": 6495.9400000000005, "text": " Here I am inside denorm.", "tokens": [1692, 286, 669, 1854, 1441, 687, 13], "temperature": 0.0, "avg_logprob": -0.15221658759160872, "compression_ratio": 1.6239669421487604, "no_speech_prob": 3.90547620554571e-06}, {"id": 1277, "seek": 648556, "start": 6495.9400000000005, "end": 6502.280000000001, "text": " And what will often happen is if you're debugging something in your PyTorch module, and it's", "tokens": [400, 437, 486, 2049, 1051, 307, 498, 291, 434, 45592, 746, 294, 428, 9953, 51, 284, 339, 10088, 11, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.15221658759160872, "compression_ratio": 1.6239669421487604, "no_speech_prob": 3.90547620554571e-06}, {"id": 1278, "seek": 648556, "start": 6502.280000000001, "end": 6508.3, "text": " hit an exception, and you're trying to debug, you'll find yourself like 6 layers deep inside", "tokens": [2045, 364, 11183, 11, 293, 291, 434, 1382, 281, 24083, 11, 291, 603, 915, 1803, 411, 1386, 7914, 2452, 1854], "temperature": 0.0, "avg_logprob": -0.15221658759160872, "compression_ratio": 1.6239669421487604, "no_speech_prob": 3.90547620554571e-06}, {"id": 1279, "seek": 648556, "start": 6508.3, "end": 6509.3, "text": " PyTorch.", "tokens": [9953, 51, 284, 339, 13], "temperature": 0.0, "avg_logprob": -0.15221658759160872, "compression_ratio": 1.6239669421487604, "no_speech_prob": 3.90547620554571e-06}, {"id": 1280, "seek": 648556, "start": 6509.3, "end": 6514.52, "text": " But you want to actually see back up what's happening where you called it from.", "tokens": [583, 291, 528, 281, 767, 536, 646, 493, 437, 311, 2737, 689, 291, 1219, 309, 490, 13], "temperature": 0.0, "avg_logprob": -0.15221658759160872, "compression_ratio": 1.6239669421487604, "no_speech_prob": 3.90547620554571e-06}, {"id": 1281, "seek": 651452, "start": 6514.52, "end": 6518.72, "text": " So in this case, I'm inside this property, but I actually want to know what was going", "tokens": [407, 294, 341, 1389, 11, 286, 478, 1854, 341, 4707, 11, 457, 286, 767, 528, 281, 458, 437, 390, 516], "temperature": 0.0, "avg_logprob": -0.13774520571869198, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.726632712641731e-06}, {"id": 1282, "seek": 651452, "start": 6518.72, "end": 6520.96, "text": " on up the call stack.", "tokens": [322, 493, 264, 818, 8630, 13], "temperature": 0.0, "avg_logprob": -0.13774520571869198, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.726632712641731e-06}, {"id": 1283, "seek": 651452, "start": 6520.96, "end": 6525.42, "text": " I just hit u, and that doesn't actually run anything.", "tokens": [286, 445, 2045, 344, 11, 293, 300, 1177, 380, 767, 1190, 1340, 13], "temperature": 0.0, "avg_logprob": -0.13774520571869198, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.726632712641731e-06}, {"id": 1284, "seek": 651452, "start": 6525.42, "end": 6531.02, "text": " It just changes the context of the debugger to show me what called it.", "tokens": [467, 445, 2962, 264, 4319, 295, 264, 24083, 1321, 281, 855, 385, 437, 1219, 309, 13], "temperature": 0.0, "avg_logprob": -0.13774520571869198, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.726632712641731e-06}, {"id": 1285, "seek": 651452, "start": 6531.02, "end": 6539.4400000000005, "text": " And now I can type, you know, things to find out about that environment.", "tokens": [400, 586, 286, 393, 2010, 11, 291, 458, 11, 721, 281, 915, 484, 466, 300, 2823, 13], "temperature": 0.0, "avg_logprob": -0.13774520571869198, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.726632712641731e-06}, {"id": 1286, "seek": 651452, "start": 6539.4400000000005, "end": 6543.14, "text": " And then if I'm going to go down again, it's d.", "tokens": [400, 550, 498, 286, 478, 516, 281, 352, 760, 797, 11, 309, 311, 274, 13], "temperature": 0.0, "avg_logprob": -0.13774520571869198, "compression_ratio": 1.5829596412556053, "no_speech_prob": 3.726632712641731e-06}, {"id": 1287, "seek": 654314, "start": 6543.14, "end": 6547.52, "text": " So I'm not going to show you everything about the debugger, but I just showed you all of", "tokens": [407, 286, 478, 406, 516, 281, 855, 291, 1203, 466, 264, 24083, 1321, 11, 457, 286, 445, 4712, 291, 439, 295], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1288, "seek": 654314, "start": 6547.52, "end": 6548.52, "text": " those commands.", "tokens": [729, 16901, 13], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1289, "seek": 654314, "start": 6548.52, "end": 6549.52, "text": " Right?", "tokens": [1779, 30], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1290, "seek": 654314, "start": 6549.52, "end": 6550.52, "text": " Yes, Aza?", "tokens": [1079, 11, 316, 2394, 30], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1291, "seek": 654314, "start": 6550.52, "end": 6557.1, "text": " Something that we found helpful as we've been doing this is using from ipython.core.debugger", "tokens": [6595, 300, 321, 1352, 4961, 382, 321, 600, 668, 884, 341, 307, 1228, 490, 28501, 88, 11943, 13, 12352, 13, 1479, 44455, 1321], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1292, "seek": 654314, "start": 6557.1, "end": 6560.64, "text": " imports that trace, and then you get it all prettily colored.", "tokens": [41596, 300, 13508, 11, 293, 550, 291, 483, 309, 439, 45421, 953, 14332, 13], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1293, "seek": 654314, "start": 6560.64, "end": 6563.64, "text": " You do indeed.", "tokens": [509, 360, 6451, 13], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1294, "seek": 654314, "start": 6563.64, "end": 6566.64, "text": " Excellent tip.", "tokens": [16723, 4125, 13], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1295, "seek": 654314, "start": 6566.64, "end": 6568.200000000001, "text": " Let's learn about some of our students here.", "tokens": [961, 311, 1466, 466, 512, 295, 527, 1731, 510, 13], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1296, "seek": 654314, "start": 6568.200000000001, "end": 6570.200000000001, "text": " Aza, tell us, I know you're doing an interesting project.", "tokens": [316, 2394, 11, 980, 505, 11, 286, 458, 291, 434, 884, 364, 1880, 1716, 13], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1297, "seek": 654314, "start": 6570.200000000001, "end": 6572.200000000001, "text": " Can you tell us about it?", "tokens": [1664, 291, 980, 505, 466, 309, 30], "temperature": 0.0, "avg_logprob": -0.2907595743659798, "compression_ratio": 1.5818181818181818, "no_speech_prob": 8.530159902875312e-06}, {"id": 1298, "seek": 657220, "start": 6572.2, "end": 6573.2, "text": " Hello, everyone.", "tokens": [2425, 11, 1518, 13], "temperature": 0.0, "avg_logprob": -0.16395226768825366, "compression_ratio": 1.4695652173913043, "no_speech_prob": 5.306241291691549e-05}, {"id": 1299, "seek": 657220, "start": 6573.2, "end": 6583.8, "text": " I'm Aza, here with my collaborator, Britt, and we're using this kind of stuff to try", "tokens": [286, 478, 316, 2394, 11, 510, 365, 452, 5091, 1639, 11, 30750, 11, 293, 321, 434, 1228, 341, 733, 295, 1507, 281, 853], "temperature": 0.0, "avg_logprob": -0.16395226768825366, "compression_ratio": 1.4695652173913043, "no_speech_prob": 5.306241291691549e-05}, {"id": 1300, "seek": 657220, "start": 6583.8, "end": 6588.639999999999, "text": " to build a Google Translate for animal communication.", "tokens": [281, 1322, 257, 3329, 6531, 17593, 337, 5496, 6101, 13], "temperature": 0.0, "avg_logprob": -0.16395226768825366, "compression_ratio": 1.4695652173913043, "no_speech_prob": 5.306241291691549e-05}, {"id": 1301, "seek": 657220, "start": 6588.639999999999, "end": 6594.639999999999, "text": " So that involves playing around a lot with unsupervised machine neural translation and", "tokens": [407, 300, 11626, 2433, 926, 257, 688, 365, 2693, 12879, 24420, 3479, 18161, 12853, 293], "temperature": 0.0, "avg_logprob": -0.16395226768825366, "compression_ratio": 1.4695652173913043, "no_speech_prob": 5.306241291691549e-05}, {"id": 1302, "seek": 657220, "start": 6594.639999999999, "end": 6595.639999999999, "text": " doing it on top of audio.", "tokens": [884, 309, 322, 1192, 295, 6278, 13], "temperature": 0.0, "avg_logprob": -0.16395226768825366, "compression_ratio": 1.4695652173913043, "no_speech_prob": 5.306241291691549e-05}, {"id": 1303, "seek": 657220, "start": 6595.639999999999, "end": 6598.679999999999, "text": " Where do you get data for that from?", "tokens": [2305, 360, 291, 483, 1412, 337, 300, 490, 30], "temperature": 0.0, "avg_logprob": -0.16395226768825366, "compression_ratio": 1.4695652173913043, "no_speech_prob": 5.306241291691549e-05}, {"id": 1304, "seek": 657220, "start": 6598.679999999999, "end": 6599.679999999999, "text": " That's sort of the hard problem.", "tokens": [663, 311, 1333, 295, 264, 1152, 1154, 13], "temperature": 0.0, "avg_logprob": -0.16395226768825366, "compression_ratio": 1.4695652173913043, "no_speech_prob": 5.306241291691549e-05}, {"id": 1305, "seek": 659968, "start": 6599.68, "end": 6603.52, "text": " So there you have to go and we're talking to a number of researchers to try to collect", "tokens": [407, 456, 291, 362, 281, 352, 293, 321, 434, 1417, 281, 257, 1230, 295, 10309, 281, 853, 281, 2500], "temperature": 0.0, "avg_logprob": -0.24773632979192653, "compression_ratio": 1.6216216216216217, "no_speech_prob": 3.071357787121087e-05}, {"id": 1306, "seek": 659968, "start": 6603.52, "end": 6607.76, "text": " and collate large data sets, but if we can't get it that way, we're thinking about building", "tokens": [293, 1263, 473, 2416, 1412, 6352, 11, 457, 498, 321, 393, 380, 483, 309, 300, 636, 11, 321, 434, 1953, 466, 2390], "temperature": 0.0, "avg_logprob": -0.24773632979192653, "compression_ratio": 1.6216216216216217, "no_speech_prob": 3.071357787121087e-05}, {"id": 1307, "seek": 659968, "start": 6607.76, "end": 6612.0, "text": " a living library of the audio of the species of Earth.", "tokens": [257, 2647, 6405, 295, 264, 6278, 295, 264, 6172, 295, 4755, 13], "temperature": 0.0, "avg_logprob": -0.24773632979192653, "compression_ratio": 1.6216216216216217, "no_speech_prob": 3.071357787121087e-05}, {"id": 1308, "seek": 659968, "start": 6612.0, "end": 6616.400000000001, "text": " That involves going out and collecting 100,000 hours of gelato monkey vocalizations.", "tokens": [663, 11626, 516, 484, 293, 12510, 2319, 11, 1360, 2496, 295, 4087, 2513, 17847, 11657, 14455, 13], "temperature": 0.0, "avg_logprob": -0.24773632979192653, "compression_ratio": 1.6216216216216217, "no_speech_prob": 3.071357787121087e-05}, {"id": 1309, "seek": 659968, "start": 6616.400000000001, "end": 6618.96, "text": " I didn't know that.", "tokens": [286, 994, 380, 458, 300, 13], "temperature": 0.0, "avg_logprob": -0.24773632979192653, "compression_ratio": 1.6216216216216217, "no_speech_prob": 3.071357787121087e-05}, {"id": 1310, "seek": 659968, "start": 6618.96, "end": 6621.96, "text": " That's kind of cool.", "tokens": [663, 311, 733, 295, 1627, 13], "temperature": 0.0, "avg_logprob": -0.24773632979192653, "compression_ratio": 1.6216216216216217, "no_speech_prob": 3.071357787121087e-05}, {"id": 1311, "seek": 659968, "start": 6621.96, "end": 6623.240000000001, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.24773632979192653, "compression_ratio": 1.6216216216216217, "no_speech_prob": 3.071357787121087e-05}, {"id": 1312, "seek": 659968, "start": 6623.240000000001, "end": 6627.0, "text": " That's great.", "tokens": [663, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.24773632979192653, "compression_ratio": 1.6216216216216217, "no_speech_prob": 3.071357787121087e-05}, {"id": 1313, "seek": 659968, "start": 6627.0, "end": 6629.08, "text": " So let's get rid of that set trace.", "tokens": [407, 718, 311, 483, 3973, 295, 300, 992, 13508, 13], "temperature": 0.0, "avg_logprob": -0.24773632979192653, "compression_ratio": 1.6216216216216217, "no_speech_prob": 3.071357787121087e-05}, {"id": 1314, "seek": 662908, "start": 6629.08, "end": 6635.28, "text": " The other place that the debugger comes in, particularly handy, is, as I say, if you've", "tokens": [440, 661, 1081, 300, 264, 24083, 1321, 1487, 294, 11, 4098, 13239, 11, 307, 11, 382, 286, 584, 11, 498, 291, 600], "temperature": 0.0, "avg_logprob": -0.20725408651060978, "compression_ratio": 1.6050420168067228, "no_speech_prob": 3.535547875799239e-05}, {"id": 1315, "seek": 662908, "start": 6635.28, "end": 6636.28, "text": " got an exception.", "tokens": [658, 364, 11183, 13], "temperature": 0.0, "avg_logprob": -0.20725408651060978, "compression_ratio": 1.6050420168067228, "no_speech_prob": 3.535547875799239e-05}, {"id": 1316, "seek": 662908, "start": 6636.28, "end": 6638.64, "text": " Particularly if it's deep inside Pipeswatch.", "tokens": [32281, 498, 309, 311, 2452, 1854, 35396, 279, 15219, 13], "temperature": 0.0, "avg_logprob": -0.20725408651060978, "compression_ratio": 1.6050420168067228, "no_speech_prob": 3.535547875799239e-05}, {"id": 1317, "seek": 662908, "start": 6638.64, "end": 6642.84, "text": " So if I went i times 100 here, obviously that's going to be an exception.", "tokens": [407, 498, 286, 1437, 741, 1413, 2319, 510, 11, 2745, 300, 311, 516, 281, 312, 364, 11183, 13], "temperature": 0.0, "avg_logprob": -0.20725408651060978, "compression_ratio": 1.6050420168067228, "no_speech_prob": 3.535547875799239e-05}, {"id": 1318, "seek": 662908, "start": 6642.84, "end": 6644.64, "text": " I've got rid of the set trace.", "tokens": [286, 600, 658, 3973, 295, 264, 992, 13508, 13], "temperature": 0.0, "avg_logprob": -0.20725408651060978, "compression_ratio": 1.6050420168067228, "no_speech_prob": 3.535547875799239e-05}, {"id": 1319, "seek": 662908, "start": 6644.64, "end": 6651.0, "text": " So if I run this now, something's wrong.", "tokens": [407, 498, 286, 1190, 341, 586, 11, 746, 311, 2085, 13], "temperature": 0.0, "avg_logprob": -0.20725408651060978, "compression_ratio": 1.6050420168067228, "no_speech_prob": 3.535547875799239e-05}, {"id": 1320, "seek": 662908, "start": 6651.0, "end": 6653.32, "text": " Now in this case, it's easy to see what's wrong.", "tokens": [823, 294, 341, 1389, 11, 309, 311, 1858, 281, 536, 437, 311, 2085, 13], "temperature": 0.0, "avg_logprob": -0.20725408651060978, "compression_ratio": 1.6050420168067228, "no_speech_prob": 3.535547875799239e-05}, {"id": 1321, "seek": 662908, "start": 6653.32, "end": 6658.0, "text": " But often it's not, so what do I do?", "tokens": [583, 2049, 309, 311, 406, 11, 370, 437, 360, 286, 360, 30], "temperature": 0.0, "avg_logprob": -0.20725408651060978, "compression_ratio": 1.6050420168067228, "no_speech_prob": 3.535547875799239e-05}, {"id": 1322, "seek": 665800, "start": 6658.0, "end": 6665.12, "text": " I run the debug, pops open the debugger, at the point the exception happens.", "tokens": [286, 1190, 264, 24083, 11, 16795, 1269, 264, 24083, 1321, 11, 412, 264, 935, 264, 11183, 2314, 13], "temperature": 0.0, "avg_logprob": -0.3790910270776642, "compression_ratio": 1.5359116022099448, "no_speech_prob": 2.3552365746581927e-05}, {"id": 1323, "seek": 665800, "start": 6665.12, "end": 6677.04, "text": " So now I can check, okay, preds dot, well, I don't know, len preds 64, i times 100, got", "tokens": [407, 586, 286, 393, 1520, 11, 1392, 11, 3852, 82, 5893, 11, 731, 11, 286, 500, 380, 458, 11, 40116, 3852, 82, 12145, 11, 741, 1413, 2319, 11, 658], "temperature": 0.0, "avg_logprob": -0.3790910270776642, "compression_ratio": 1.5359116022099448, "no_speech_prob": 2.3552365746581927e-05}, {"id": 1324, "seek": 665800, "start": 6677.04, "end": 6681.52, "text": " to print that because i is a command, 100, oh, no wonder.", "tokens": [281, 4482, 300, 570, 741, 307, 257, 5622, 11, 2319, 11, 1954, 11, 572, 2441, 13], "temperature": 0.0, "avg_logprob": -0.3790910270776642, "compression_ratio": 1.5359116022099448, "no_speech_prob": 2.3552365746581927e-05}, {"id": 1325, "seek": 665800, "start": 6681.52, "end": 6685.52, "text": " You can go down, you can go up, you can list, whatever.", "tokens": [509, 393, 352, 760, 11, 291, 393, 352, 493, 11, 291, 393, 1329, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.3790910270776642, "compression_ratio": 1.5359116022099448, "no_speech_prob": 2.3552365746581927e-05}, {"id": 1326, "seek": 668552, "start": 6685.52, "end": 6697.4400000000005, "text": " So I do all of my development, both of the library and of the lessons in Jupyter Notebook.", "tokens": [407, 286, 360, 439, 295, 452, 3250, 11, 1293, 295, 264, 6405, 293, 295, 264, 8820, 294, 22125, 88, 391, 11633, 2939, 13], "temperature": 0.0, "avg_logprob": -0.19611639519260354, "compression_ratio": 1.511111111111111, "no_speech_prob": 1.8162157857659622e-06}, {"id": 1327, "seek": 668552, "start": 6697.4400000000005, "end": 6706.8, "text": " I do it all interactively, and I use percent debug all the time, along with this idea of", "tokens": [286, 360, 309, 439, 4648, 3413, 11, 293, 286, 764, 3043, 24083, 439, 264, 565, 11, 2051, 365, 341, 1558, 295], "temperature": 0.0, "avg_logprob": -0.19611639519260354, "compression_ratio": 1.511111111111111, "no_speech_prob": 1.8162157857659622e-06}, {"id": 1328, "seek": 668552, "start": 6706.8, "end": 6711.280000000001, "text": " copying stuff out of a function and putting it into separate cells, running it step by", "tokens": [27976, 1507, 484, 295, 257, 2445, 293, 3372, 309, 666, 4994, 5438, 11, 2614, 309, 1823, 538], "temperature": 0.0, "avg_logprob": -0.19611639519260354, "compression_ratio": 1.511111111111111, "no_speech_prob": 1.8162157857659622e-06}, {"id": 1329, "seek": 668552, "start": 6711.280000000001, "end": 6712.280000000001, "text": " step.", "tokens": [1823, 13], "temperature": 0.0, "avg_logprob": -0.19611639519260354, "compression_ratio": 1.511111111111111, "no_speech_prob": 1.8162157857659622e-06}, {"id": 1330, "seek": 671228, "start": 6712.28, "end": 6716.4, "text": " There are similar things you can do inside, for example, Visual Studio Code.", "tokens": [821, 366, 2531, 721, 291, 393, 360, 1854, 11, 337, 1365, 11, 23187, 13500, 15549, 13], "temperature": 0.0, "avg_logprob": -0.17873300170898437, "compression_ratio": 1.721189591078067, "no_speech_prob": 9.972886800824199e-06}, {"id": 1331, "seek": 671228, "start": 6716.4, "end": 6721.54, "text": " There's actually a Jupyter extension, which lets you select any line of code inside Visual", "tokens": [821, 311, 767, 257, 22125, 88, 391, 10320, 11, 597, 6653, 291, 3048, 604, 1622, 295, 3089, 1854, 23187], "temperature": 0.0, "avg_logprob": -0.17873300170898437, "compression_ratio": 1.721189591078067, "no_speech_prob": 9.972886800824199e-06}, {"id": 1332, "seek": 671228, "start": 6721.54, "end": 6727.88, "text": " Studio Code, and it'll say run in Jupyter, and it'll run it in Jupyter and create a little", "tokens": [13500, 15549, 11, 293, 309, 603, 584, 1190, 294, 22125, 88, 391, 11, 293, 309, 603, 1190, 309, 294, 22125, 88, 391, 293, 1884, 257, 707], "temperature": 0.0, "avg_logprob": -0.17873300170898437, "compression_ratio": 1.721189591078067, "no_speech_prob": 9.972886800824199e-06}, {"id": 1333, "seek": 671228, "start": 6727.88, "end": 6730.5199999999995, "text": " window showing you the output.", "tokens": [4910, 4099, 291, 264, 5598, 13], "temperature": 0.0, "avg_logprob": -0.17873300170898437, "compression_ratio": 1.721189591078067, "no_speech_prob": 9.972886800824199e-06}, {"id": 1334, "seek": 671228, "start": 6730.5199999999995, "end": 6732.32, "text": " There's neat little stuff like that.", "tokens": [821, 311, 10654, 707, 1507, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.17873300170898437, "compression_ratio": 1.721189591078067, "no_speech_prob": 9.972886800824199e-06}, {"id": 1335, "seek": 671228, "start": 6732.32, "end": 6737.719999999999, "text": " Personally, I think Jupyter Notebook is better.", "tokens": [21079, 11, 286, 519, 22125, 88, 391, 11633, 2939, 307, 1101, 13], "temperature": 0.0, "avg_logprob": -0.17873300170898437, "compression_ratio": 1.721189591078067, "no_speech_prob": 9.972886800824199e-06}, {"id": 1336, "seek": 671228, "start": 6737.719999999999, "end": 6741.84, "text": " And perhaps by the time you watch this on the video, Jupyter Lab will be the main thing.", "tokens": [400, 4317, 538, 264, 565, 291, 1159, 341, 322, 264, 960, 11, 22125, 88, 391, 10137, 486, 312, 264, 2135, 551, 13], "temperature": 0.0, "avg_logprob": -0.17873300170898437, "compression_ratio": 1.721189591078067, "no_speech_prob": 9.972886800824199e-06}, {"id": 1337, "seek": 674184, "start": 6741.84, "end": 6748.6, "text": " Jupyter Lab is like the next version of Jupyter Notebook, but pretty similar.", "tokens": [22125, 88, 391, 10137, 307, 411, 264, 958, 3037, 295, 22125, 88, 391, 11633, 2939, 11, 457, 1238, 2531, 13], "temperature": 0.0, "avg_logprob": -0.37496286068322526, "compression_ratio": 1.289855072463768, "no_speech_prob": 0.00010889283294091001}, {"id": 1338, "seek": 674184, "start": 6748.6, "end": 6762.88, "text": " Wow, I just broke it totally.", "tokens": [3153, 11, 286, 445, 6902, 309, 3879, 13], "temperature": 0.0, "avg_logprob": -0.37496286068322526, "compression_ratio": 1.289855072463768, "no_speech_prob": 0.00010889283294091001}, {"id": 1339, "seek": 674184, "start": 6762.88, "end": 6767.04, "text": " We know exactly how to fix it, so we'll worry about that another time.", "tokens": [492, 458, 2293, 577, 281, 3191, 309, 11, 370, 321, 603, 3292, 466, 300, 1071, 565, 13], "temperature": 0.0, "avg_logprob": -0.37496286068322526, "compression_ratio": 1.289855072463768, "no_speech_prob": 0.00010889283294091001}, {"id": 1340, "seek": 676704, "start": 6767.04, "end": 6773.28, "text": " We'll debug it this evening.", "tokens": [492, 603, 24083, 309, 341, 5634, 13], "temperature": 0.0, "avg_logprob": -0.15911325767858706, "compression_ratio": 1.5783132530120483, "no_speech_prob": 8.664584129292052e-06}, {"id": 1341, "seek": 676704, "start": 6773.28, "end": 6780.84, "text": " So to kind of do the next stage, we want to create the bounding box.", "tokens": [407, 281, 733, 295, 360, 264, 958, 3233, 11, 321, 528, 281, 1884, 264, 5472, 278, 2424, 13], "temperature": 0.0, "avg_logprob": -0.15911325767858706, "compression_ratio": 1.5783132530120483, "no_speech_prob": 8.664584129292052e-06}, {"id": 1342, "seek": 676704, "start": 6780.84, "end": 6785.8, "text": " And now creating the bounding box around the largest object may seem like something you", "tokens": [400, 586, 4084, 264, 5472, 278, 2424, 926, 264, 6443, 2657, 815, 1643, 411, 746, 291], "temperature": 0.0, "avg_logprob": -0.15911325767858706, "compression_ratio": 1.5783132530120483, "no_speech_prob": 8.664584129292052e-06}, {"id": 1343, "seek": 676704, "start": 6785.8, "end": 6791.64, "text": " haven't done before, but actually it's totally something you've done before.", "tokens": [2378, 380, 1096, 949, 11, 457, 767, 309, 311, 3879, 746, 291, 600, 1096, 949, 13], "temperature": 0.0, "avg_logprob": -0.15911325767858706, "compression_ratio": 1.5783132530120483, "no_speech_prob": 8.664584129292052e-06}, {"id": 1344, "seek": 679164, "start": 6791.64, "end": 6801.08, "text": " And the reason it's something you've done before is we know that we can create a regression", "tokens": [400, 264, 1778, 309, 311, 746, 291, 600, 1096, 949, 307, 321, 458, 300, 321, 393, 1884, 257, 24590], "temperature": 0.0, "avg_logprob": -0.1503056754236636, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565929430100368e-06}, {"id": 1345, "seek": 679164, "start": 6801.08, "end": 6803.6, "text": " rather than a classification neural net.", "tokens": [2831, 813, 257, 21538, 18161, 2533, 13], "temperature": 0.0, "avg_logprob": -0.1503056754236636, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565929430100368e-06}, {"id": 1346, "seek": 679164, "start": 6803.6, "end": 6808.360000000001, "text": " In other words, a classification neural net is just one that has a sigmoid or softmax", "tokens": [682, 661, 2283, 11, 257, 21538, 18161, 2533, 307, 445, 472, 300, 575, 257, 4556, 3280, 327, 420, 2787, 41167], "temperature": 0.0, "avg_logprob": -0.1503056754236636, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565929430100368e-06}, {"id": 1347, "seek": 679164, "start": 6808.360000000001, "end": 6815.4800000000005, "text": " output and that we use a cross-entropy or binary cross-entropy negative log likelihood", "tokens": [5598, 293, 300, 321, 764, 257, 3278, 12, 317, 27514, 420, 17434, 3278, 12, 317, 27514, 3671, 3565, 22119], "temperature": 0.0, "avg_logprob": -0.1503056754236636, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565929430100368e-06}, {"id": 1348, "seek": 679164, "start": 6815.4800000000005, "end": 6816.4800000000005, "text": " loss function.", "tokens": [4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1503056754236636, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565929430100368e-06}, {"id": 1349, "seek": 679164, "start": 6816.4800000000005, "end": 6820.52, "text": " That's basically what makes it a classifier.", "tokens": [663, 311, 1936, 437, 1669, 309, 257, 1508, 9902, 13], "temperature": 0.0, "avg_logprob": -0.1503056754236636, "compression_ratio": 1.6666666666666667, "no_speech_prob": 4.565929430100368e-06}, {"id": 1350, "seek": 682052, "start": 6820.52, "end": 6826.120000000001, "text": " If we don't have the softmax of sigmoid at the end, and we use mean squared error as", "tokens": [759, 321, 500, 380, 362, 264, 2787, 41167, 295, 4556, 3280, 327, 412, 264, 917, 11, 293, 321, 764, 914, 8889, 6713, 382], "temperature": 0.0, "avg_logprob": -0.16216695876348586, "compression_ratio": 1.5377358490566038, "no_speech_prob": 4.029440788144711e-06}, {"id": 1351, "seek": 682052, "start": 6826.120000000001, "end": 6829.080000000001, "text": " a loss function, it's now a regression model.", "tokens": [257, 4470, 2445, 11, 309, 311, 586, 257, 24590, 2316, 13], "temperature": 0.0, "avg_logprob": -0.16216695876348586, "compression_ratio": 1.5377358490566038, "no_speech_prob": 4.029440788144711e-06}, {"id": 1352, "seek": 682052, "start": 6829.080000000001, "end": 6835.120000000001, "text": " So we can now use it to predict a continuous number rather than a category.", "tokens": [407, 321, 393, 586, 764, 309, 281, 6069, 257, 10957, 1230, 2831, 813, 257, 7719, 13], "temperature": 0.0, "avg_logprob": -0.16216695876348586, "compression_ratio": 1.5377358490566038, "no_speech_prob": 4.029440788144711e-06}, {"id": 1353, "seek": 682052, "start": 6835.120000000001, "end": 6842.52, "text": " We also know that we can have multiple outputs, like in the planet competition we did a multiple", "tokens": [492, 611, 458, 300, 321, 393, 362, 3866, 23930, 11, 411, 294, 264, 5054, 6211, 321, 630, 257, 3866], "temperature": 0.0, "avg_logprob": -0.16216695876348586, "compression_ratio": 1.5377358490566038, "no_speech_prob": 4.029440788144711e-06}, {"id": 1354, "seek": 682052, "start": 6842.52, "end": 6846.240000000001, "text": " object classification.", "tokens": [2657, 21538, 13], "temperature": 0.0, "avg_logprob": -0.16216695876348586, "compression_ratio": 1.5377358490566038, "no_speech_prob": 4.029440788144711e-06}, {"id": 1355, "seek": 684624, "start": 6846.24, "end": 6853.12, "text": " What if we combine the two ideas and do a multiple column regression?", "tokens": [708, 498, 321, 10432, 264, 732, 3487, 293, 360, 257, 3866, 7738, 24590, 30], "temperature": 0.0, "avg_logprob": -0.1591958812638825, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2887435281736543e-06}, {"id": 1356, "seek": 684624, "start": 6853.12, "end": 6859.76, "text": " So in this case we've got 4 numbers, top, left, x, and y, bottom, right, x, and y, and", "tokens": [407, 294, 341, 1389, 321, 600, 658, 1017, 3547, 11, 1192, 11, 1411, 11, 2031, 11, 293, 288, 11, 2767, 11, 558, 11, 2031, 11, 293, 288, 11, 293], "temperature": 0.0, "avg_logprob": -0.1591958812638825, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2887435281736543e-06}, {"id": 1357, "seek": 684624, "start": 6859.76, "end": 6863.36, "text": " we could create a neural net with 4 activations.", "tokens": [321, 727, 1884, 257, 18161, 2533, 365, 1017, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.1591958812638825, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2887435281736543e-06}, {"id": 1358, "seek": 684624, "start": 6863.36, "end": 6868.28, "text": " We could have no softmax or sigmoid and use a mean squared error loss function.", "tokens": [492, 727, 362, 572, 2787, 41167, 420, 4556, 3280, 327, 293, 764, 257, 914, 8889, 6713, 4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.1591958812638825, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2887435281736543e-06}, {"id": 1359, "seek": 684624, "start": 6868.28, "end": 6873.28, "text": " And this is kind of like where you're thinking about it like differentiable programming.", "tokens": [400, 341, 307, 733, 295, 411, 689, 291, 434, 1953, 466, 309, 411, 819, 9364, 9410, 13], "temperature": 0.0, "avg_logprob": -0.1591958812638825, "compression_ratio": 1.5327868852459017, "no_speech_prob": 3.2887435281736543e-06}, {"id": 1360, "seek": 687328, "start": 6873.28, "end": 6878.24, "text": " It's not like how do I create a bounding box model.", "tokens": [467, 311, 406, 411, 577, 360, 286, 1884, 257, 5472, 278, 2424, 2316, 13], "temperature": 0.0, "avg_logprob": -0.18872194290161132, "compression_ratio": 1.707070707070707, "no_speech_prob": 3.905476660293061e-06}, {"id": 1361, "seek": 687328, "start": 6878.24, "end": 6880.5199999999995, "text": " It's like, alright, what do I need?", "tokens": [467, 311, 411, 11, 5845, 11, 437, 360, 286, 643, 30], "temperature": 0.0, "avg_logprob": -0.18872194290161132, "compression_ratio": 1.707070707070707, "no_speech_prob": 3.905476660293061e-06}, {"id": 1362, "seek": 687328, "start": 6880.5199999999995, "end": 6882.5199999999995, "text": " I need 4 numbers.", "tokens": [286, 643, 1017, 3547, 13], "temperature": 0.0, "avg_logprob": -0.18872194290161132, "compression_ratio": 1.707070707070707, "no_speech_prob": 3.905476660293061e-06}, {"id": 1363, "seek": 687328, "start": 6882.5199999999995, "end": 6888.5599999999995, "text": " Therefore I need a neural network with 4 activations.", "tokens": [7504, 286, 643, 257, 18161, 3209, 365, 1017, 2430, 763, 13], "temperature": 0.0, "avg_logprob": -0.18872194290161132, "compression_ratio": 1.707070707070707, "no_speech_prob": 3.905476660293061e-06}, {"id": 1364, "seek": 687328, "start": 6888.5599999999995, "end": 6889.88, "text": " That's half of what I need to know.", "tokens": [663, 311, 1922, 295, 437, 286, 643, 281, 458, 13], "temperature": 0.0, "avg_logprob": -0.18872194290161132, "compression_ratio": 1.707070707070707, "no_speech_prob": 3.905476660293061e-06}, {"id": 1365, "seek": 687328, "start": 6889.88, "end": 6892.5199999999995, "text": " The other half I need to know is a loss function.", "tokens": [440, 661, 1922, 286, 643, 281, 458, 307, 257, 4470, 2445, 13], "temperature": 0.0, "avg_logprob": -0.18872194290161132, "compression_ratio": 1.707070707070707, "no_speech_prob": 3.905476660293061e-06}, {"id": 1366, "seek": 687328, "start": 6892.5199999999995, "end": 6899.5599999999995, "text": " In other words, what's a function that when it is lower means that the 4 numbers are better?", "tokens": [682, 661, 2283, 11, 437, 311, 257, 2445, 300, 562, 309, 307, 3126, 1355, 300, 264, 1017, 3547, 366, 1101, 30], "temperature": 0.0, "avg_logprob": -0.18872194290161132, "compression_ratio": 1.707070707070707, "no_speech_prob": 3.905476660293061e-06}, {"id": 1367, "seek": 689956, "start": 6899.56, "end": 6905.120000000001, "text": " Because if I can do those 2 things, I'm done.", "tokens": [1436, 498, 286, 393, 360, 729, 568, 721, 11, 286, 478, 1096, 13], "temperature": 0.0, "avg_logprob": -0.22947191510881695, "compression_ratio": 1.6201923076923077, "no_speech_prob": 3.6119765809417004e-06}, {"id": 1368, "seek": 689956, "start": 6905.120000000001, "end": 6911.52, "text": " Well if the x is close to the first activation and the y is close to the second and so forth,", "tokens": [1042, 498, 264, 2031, 307, 1998, 281, 264, 700, 24433, 293, 264, 288, 307, 1998, 281, 264, 1150, 293, 370, 5220, 11], "temperature": 0.0, "avg_logprob": -0.22947191510881695, "compression_ratio": 1.6201923076923077, "no_speech_prob": 3.6119765809417004e-06}, {"id": 1369, "seek": 689956, "start": 6911.52, "end": 6912.68, "text": " then I'm done.", "tokens": [550, 286, 478, 1096, 13], "temperature": 0.0, "avg_logprob": -0.22947191510881695, "compression_ratio": 1.6201923076923077, "no_speech_prob": 3.6119765809417004e-06}, {"id": 1370, "seek": 689956, "start": 6912.68, "end": 6915.200000000001, "text": " So that's it.", "tokens": [407, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.22947191510881695, "compression_ratio": 1.6201923076923077, "no_speech_prob": 3.6119765809417004e-06}, {"id": 1371, "seek": 689956, "start": 6915.200000000001, "end": 6921.84, "text": " I just need to create a model with 4 activations with a mean squared error loss function and", "tokens": [286, 445, 643, 281, 1884, 257, 2316, 365, 1017, 2430, 763, 365, 257, 914, 8889, 6713, 4470, 2445, 293], "temperature": 0.0, "avg_logprob": -0.22947191510881695, "compression_ratio": 1.6201923076923077, "no_speech_prob": 3.6119765809417004e-06}, {"id": 1372, "seek": 689956, "start": 6921.84, "end": 6923.080000000001, "text": " that should be it.", "tokens": [300, 820, 312, 309, 13], "temperature": 0.0, "avg_logprob": -0.22947191510881695, "compression_ratio": 1.6201923076923077, "no_speech_prob": 3.6119765809417004e-06}, {"id": 1373, "seek": 689956, "start": 6923.080000000001, "end": 6924.080000000001, "text": " Right?", "tokens": [1779, 30], "temperature": 0.0, "avg_logprob": -0.22947191510881695, "compression_ratio": 1.6201923076923077, "no_speech_prob": 3.6119765809417004e-06}, {"id": 1374, "seek": 689956, "start": 6924.080000000001, "end": 6925.72, "text": " Like we don't need anything new.", "tokens": [1743, 321, 500, 380, 643, 1340, 777, 13], "temperature": 0.0, "avg_logprob": -0.22947191510881695, "compression_ratio": 1.6201923076923077, "no_speech_prob": 3.6119765809417004e-06}, {"id": 1375, "seek": 689956, "start": 6925.72, "end": 6928.22, "text": " So let's try it.", "tokens": [407, 718, 311, 853, 309, 13], "temperature": 0.0, "avg_logprob": -0.22947191510881695, "compression_ratio": 1.6201923076923077, "no_speech_prob": 3.6119765809417004e-06}, {"id": 1376, "seek": 692822, "start": 6928.22, "end": 6932.16, "text": " So again, we'll use a CSV.", "tokens": [407, 797, 11, 321, 603, 764, 257, 48814, 13], "temperature": 0.0, "avg_logprob": -0.13750761205499823, "compression_ratio": 1.3868613138686132, "no_speech_prob": 9.818252692639362e-06}, {"id": 1377, "seek": 692822, "start": 6932.16, "end": 6940.88, "text": " And if you remember from part 1, to do a multiple label classification, your multiple labels", "tokens": [400, 498, 291, 1604, 490, 644, 502, 11, 281, 360, 257, 3866, 7645, 21538, 11, 428, 3866, 16949], "temperature": 0.0, "avg_logprob": -0.13750761205499823, "compression_ratio": 1.3868613138686132, "no_speech_prob": 9.818252692639362e-06}, {"id": 1378, "seek": 692822, "start": 6940.88, "end": 6946.72, "text": " have to be space-separated and then your file name is comma-separated.", "tokens": [362, 281, 312, 1901, 12, 405, 2181, 770, 293, 550, 428, 3991, 1315, 307, 22117, 12, 405, 2181, 770, 13], "temperature": 0.0, "avg_logprob": -0.13750761205499823, "compression_ratio": 1.3868613138686132, "no_speech_prob": 9.818252692639362e-06}, {"id": 1379, "seek": 694672, "start": 6946.72, "end": 6959.8, "text": " So I'll take my largest item dictionary, create a bunch of bounding boxes for each one separated", "tokens": [407, 286, 603, 747, 452, 6443, 3174, 25890, 11, 1884, 257, 3840, 295, 5472, 278, 9002, 337, 1184, 472, 12005], "temperature": 0.0, "avg_logprob": -0.17301829857162282, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.637843176169554e-06}, {"id": 1380, "seek": 694672, "start": 6959.8, "end": 6962.64, "text": " by a space using a list comprehension.", "tokens": [538, 257, 1901, 1228, 257, 1329, 44991, 13], "temperature": 0.0, "avg_logprob": -0.17301829857162282, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.637843176169554e-06}, {"id": 1381, "seek": 694672, "start": 6962.64, "end": 6965.04, "text": " I'll then create a data frame like I did before.", "tokens": [286, 603, 550, 1884, 257, 1412, 3920, 411, 286, 630, 949, 13], "temperature": 0.0, "avg_logprob": -0.17301829857162282, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.637843176169554e-06}, {"id": 1382, "seek": 694672, "start": 6965.04, "end": 6969.4800000000005, "text": " I'll turn that into a CSV and now I've got something that's got the file name and the", "tokens": [286, 603, 1261, 300, 666, 257, 48814, 293, 586, 286, 600, 658, 746, 300, 311, 658, 264, 3991, 1315, 293, 264], "temperature": 0.0, "avg_logprob": -0.17301829857162282, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.637843176169554e-06}, {"id": 1383, "seek": 694672, "start": 6969.4800000000005, "end": 6972.4400000000005, "text": " 4 bounding box coordinates.", "tokens": [1017, 5472, 278, 2424, 21056, 13], "temperature": 0.0, "avg_logprob": -0.17301829857162282, "compression_ratio": 1.5360824742268042, "no_speech_prob": 4.637843176169554e-06}, {"id": 1384, "seek": 697244, "start": 6972.44, "end": 6976.96, "text": " I will then pass that to from CSV.", "tokens": [286, 486, 550, 1320, 300, 281, 490, 48814, 13], "temperature": 0.0, "avg_logprob": -0.20306149281953512, "compression_ratio": 1.4473684210526316, "no_speech_prob": 1.8738686549113481e-06}, {"id": 1385, "seek": 697244, "start": 6976.96, "end": 6983.24, "text": " Again I will use crop type equals crop type.no.", "tokens": [3764, 286, 486, 764, 9086, 2010, 6915, 9086, 2010, 13, 1771, 13], "temperature": 0.0, "avg_logprob": -0.20306149281953512, "compression_ratio": 1.4473684210526316, "no_speech_prob": 1.8738686549113481e-06}, {"id": 1386, "seek": 697244, "start": 6983.24, "end": 6986.5599999999995, "text": " Next week we'll look at transform type.coordinate.", "tokens": [3087, 1243, 321, 603, 574, 412, 4088, 2010, 13, 1291, 37326, 13], "temperature": 0.0, "avg_logprob": -0.20306149281953512, "compression_ratio": 1.4473684210526316, "no_speech_prob": 1.8738686549113481e-06}, {"id": 1387, "seek": 697244, "start": 6986.5599999999995, "end": 6990.32, "text": " For now just realize that when we're doing scaling and data augmentation, that needs", "tokens": [1171, 586, 445, 4325, 300, 562, 321, 434, 884, 21589, 293, 1412, 14501, 19631, 11, 300, 2203], "temperature": 0.0, "avg_logprob": -0.20306149281953512, "compression_ratio": 1.4473684210526316, "no_speech_prob": 1.8738686549113481e-06}, {"id": 1388, "seek": 697244, "start": 6990.32, "end": 6994.48, "text": " to happen to the bounding boxes, not just to the images.", "tokens": [281, 1051, 281, 264, 5472, 278, 9002, 11, 406, 445, 281, 264, 5267, 13], "temperature": 0.0, "avg_logprob": -0.20306149281953512, "compression_ratio": 1.4473684210526316, "no_speech_prob": 1.8738686549113481e-06}, {"id": 1389, "seek": 699448, "start": 6994.48, "end": 7002.48, "text": " With classifier data.csv, it gets us to a situation where we can now grab one mini-batch", "tokens": [2022, 1508, 9902, 1412, 13, 14368, 85, 11, 309, 2170, 505, 281, 257, 2590, 689, 321, 393, 586, 4444, 472, 8382, 12, 65, 852], "temperature": 0.2, "avg_logprob": -0.22313417434692384, "compression_ratio": 1.6009389671361502, "no_speech_prob": 6.144136023067404e-06}, {"id": 1390, "seek": 699448, "start": 7002.48, "end": 7006.959999999999, "text": " of data, we can denormalize it, we can turn the bounding box back into a height width", "tokens": [295, 1412, 11, 321, 393, 1441, 24440, 1125, 309, 11, 321, 393, 1261, 264, 5472, 278, 2424, 646, 666, 257, 6681, 11402], "temperature": 0.2, "avg_logprob": -0.22313417434692384, "compression_ratio": 1.6009389671361502, "no_speech_prob": 6.144136023067404e-06}, {"id": 1391, "seek": 699448, "start": 7006.959999999999, "end": 7010.2, "text": " so that we can show it, and here it is.", "tokens": [370, 300, 321, 393, 855, 309, 11, 293, 510, 309, 307, 13], "temperature": 0.2, "avg_logprob": -0.22313417434692384, "compression_ratio": 1.6009389671361502, "no_speech_prob": 6.144136023067404e-06}, {"id": 1392, "seek": 699448, "start": 7010.2, "end": 7014.24, "text": " Remember we're not doing classification so I don't know what kind of thing this is, it's", "tokens": [5459, 321, 434, 406, 884, 21538, 370, 286, 500, 380, 458, 437, 733, 295, 551, 341, 307, 11, 309, 311], "temperature": 0.2, "avg_logprob": -0.22313417434692384, "compression_ratio": 1.6009389671361502, "no_speech_prob": 6.144136023067404e-06}, {"id": 1393, "seek": 699448, "start": 7014.24, "end": 7017.74, "text": " just a thing, but there is the thing.", "tokens": [445, 257, 551, 11, 457, 456, 307, 264, 551, 13], "temperature": 0.2, "avg_logprob": -0.22313417434692384, "compression_ratio": 1.6009389671361502, "no_speech_prob": 6.144136023067404e-06}, {"id": 1394, "seek": 701774, "start": 7017.74, "end": 7029.84, "text": " So I now want to create a convnet based on resnet34, but I don't want to add the standard", "tokens": [407, 286, 586, 528, 281, 1884, 257, 3754, 7129, 2361, 322, 725, 7129, 12249, 11, 457, 286, 500, 380, 528, 281, 909, 264, 3832], "temperature": 0.0, "avg_logprob": -0.17247740881783621, "compression_ratio": 1.4850299401197604, "no_speech_prob": 1.6536866951355478e-06}, {"id": 1395, "seek": 701774, "start": 7029.84, "end": 7033.5199999999995, "text": " set of fully connected layers that create a classifier.", "tokens": [992, 295, 4498, 4582, 7914, 300, 1884, 257, 1508, 9902, 13], "temperature": 0.0, "avg_logprob": -0.17247740881783621, "compression_ratio": 1.4850299401197604, "no_speech_prob": 1.6536866951355478e-06}, {"id": 1396, "seek": 701774, "start": 7033.5199999999995, "end": 7038.76, "text": " I want to just add a single linear layer with 4 outputs.", "tokens": [286, 528, 281, 445, 909, 257, 2167, 8213, 4583, 365, 1017, 23930, 13], "temperature": 0.0, "avg_logprob": -0.17247740881783621, "compression_ratio": 1.4850299401197604, "no_speech_prob": 1.6536866951355478e-06}, {"id": 1397, "seek": 701774, "start": 7038.76, "end": 7042.08, "text": " So Fast.ai has this concept of a custom head.", "tokens": [407, 15968, 13, 1301, 575, 341, 3410, 295, 257, 2375, 1378, 13], "temperature": 0.0, "avg_logprob": -0.17247740881783621, "compression_ratio": 1.4850299401197604, "no_speech_prob": 1.6536866951355478e-06}, {"id": 1398, "seek": 704208, "start": 7042.08, "end": 7048.2, "text": " If you say my model has a custom head, the head being the thing that's added to the top", "tokens": [759, 291, 584, 452, 2316, 575, 257, 2375, 1378, 11, 264, 1378, 885, 264, 551, 300, 311, 3869, 281, 264, 1192], "temperature": 0.0, "avg_logprob": -0.09547027257772592, "compression_ratio": 1.7685185185185186, "no_speech_prob": 1.370954350932152e-06}, {"id": 1399, "seek": 704208, "start": 7048.2, "end": 7054.08, "text": " of the model, then it's not going to create any of that fully connected network for you,", "tokens": [295, 264, 2316, 11, 550, 309, 311, 406, 516, 281, 1884, 604, 295, 300, 4498, 4582, 3209, 337, 291, 11], "temperature": 0.0, "avg_logprob": -0.09547027257772592, "compression_ratio": 1.7685185185185186, "no_speech_prob": 1.370954350932152e-06}, {"id": 1400, "seek": 704208, "start": 7054.08, "end": 7060.28, "text": " it's not going to add the adaptive average pooling for you, but instead it will add whatever", "tokens": [309, 311, 406, 516, 281, 909, 264, 27912, 4274, 7005, 278, 337, 291, 11, 457, 2602, 309, 486, 909, 2035], "temperature": 0.0, "avg_logprob": -0.09547027257772592, "compression_ratio": 1.7685185185185186, "no_speech_prob": 1.370954350932152e-06}, {"id": 1401, "seek": 704208, "start": 7060.28, "end": 7062.6, "text": " model you ask for.", "tokens": [2316, 291, 1029, 337, 13], "temperature": 0.0, "avg_logprob": -0.09547027257772592, "compression_ratio": 1.7685185185185186, "no_speech_prob": 1.370954350932152e-06}, {"id": 1402, "seek": 704208, "start": 7062.6, "end": 7067.96, "text": " So in this case I've created a tiny model, it's a model that flattens out the previous", "tokens": [407, 294, 341, 1389, 286, 600, 2942, 257, 5870, 2316, 11, 309, 311, 257, 2316, 300, 932, 1591, 694, 484, 264, 3894], "temperature": 0.0, "avg_logprob": -0.09547027257772592, "compression_ratio": 1.7685185185185186, "no_speech_prob": 1.370954350932152e-06}, {"id": 1403, "seek": 704208, "start": 7067.96, "end": 7069.58, "text": " layer.", "tokens": [4583, 13], "temperature": 0.0, "avg_logprob": -0.09547027257772592, "compression_ratio": 1.7685185185185186, "no_speech_prob": 1.370954350932152e-06}, {"id": 1404, "seek": 706958, "start": 7069.58, "end": 7076.36, "text": " So remember normally you would have a 7x7x512 previous layer in resnet34, so it just flattens", "tokens": [407, 1604, 5646, 291, 576, 362, 257, 1614, 87, 22, 87, 20, 4762, 3894, 4583, 294, 725, 7129, 12249, 11, 370, 309, 445, 932, 1591, 694], "temperature": 0.0, "avg_logprob": -0.20247548654538775, "compression_ratio": 1.5224489795918368, "no_speech_prob": 4.710895154858008e-06}, {"id": 1405, "seek": 706958, "start": 7076.36, "end": 7083.0, "text": " that out into a single vector of length 25088, and then I just add a linear layer that goes", "tokens": [300, 484, 666, 257, 2167, 8062, 295, 4641, 11650, 16919, 11, 293, 550, 286, 445, 909, 257, 8213, 4583, 300, 1709], "temperature": 0.0, "avg_logprob": -0.20247548654538775, "compression_ratio": 1.5224489795918368, "no_speech_prob": 4.710895154858008e-06}, {"id": 1406, "seek": 706958, "start": 7083.0, "end": 7085.0, "text": " from 25088 to 4.", "tokens": [490, 11650, 16919, 281, 1017, 13], "temperature": 0.0, "avg_logprob": -0.20247548654538775, "compression_ratio": 1.5224489795918368, "no_speech_prob": 4.710895154858008e-06}, {"id": 1407, "seek": 706958, "start": 7085.0, "end": 7086.9, "text": " There's my 4 output.", "tokens": [821, 311, 452, 1017, 5598, 13], "temperature": 0.0, "avg_logprob": -0.20247548654538775, "compression_ratio": 1.5224489795918368, "no_speech_prob": 4.710895154858008e-06}, {"id": 1408, "seek": 706958, "start": 7086.9, "end": 7092.36, "text": " So that's the simplest possible final layer you could add.", "tokens": [407, 300, 311, 264, 22811, 1944, 2572, 4583, 291, 727, 909, 13], "temperature": 0.0, "avg_logprob": -0.20247548654538775, "compression_ratio": 1.5224489795918368, "no_speech_prob": 4.710895154858008e-06}, {"id": 1409, "seek": 706958, "start": 7092.36, "end": 7097.54, "text": " I stick that on top of my pre-trained resnet34 model, so this is exactly the same as usual", "tokens": [286, 2897, 300, 322, 1192, 295, 452, 659, 12, 17227, 2001, 725, 7129, 12249, 2316, 11, 370, 341, 307, 2293, 264, 912, 382, 7713], "temperature": 0.0, "avg_logprob": -0.20247548654538775, "compression_ratio": 1.5224489795918368, "no_speech_prob": 4.710895154858008e-06}, {"id": 1410, "seek": 709754, "start": 7097.54, "end": 7099.96, "text": " except I've just got this custom head.", "tokens": [3993, 286, 600, 445, 658, 341, 2375, 1378, 13], "temperature": 0.0, "avg_logprob": -0.19082246615192083, "compression_ratio": 1.6865671641791045, "no_speech_prob": 1.5206764146569185e-05}, {"id": 1411, "seek": 709754, "start": 7099.96, "end": 7103.6, "text": " Optimize it with Adam, use a criteria.", "tokens": [35013, 1125, 309, 365, 7938, 11, 764, 257, 11101, 13], "temperature": 0.0, "avg_logprob": -0.19082246615192083, "compression_ratio": 1.6865671641791045, "no_speech_prob": 1.5206764146569185e-05}, {"id": 1412, "seek": 709754, "start": 7103.6, "end": 7107.08, "text": " I'm actually not going to use MSC, I'm going to use L1 loss.", "tokens": [286, 478, 767, 406, 516, 281, 764, 7395, 34, 11, 286, 478, 516, 281, 764, 441, 16, 4470, 13], "temperature": 0.0, "avg_logprob": -0.19082246615192083, "compression_ratio": 1.6865671641791045, "no_speech_prob": 1.5206764146569185e-05}, {"id": 1413, "seek": 709754, "start": 7107.08, "end": 7111.32, "text": " So I can't remember if we covered this last week, we can revise it next week if we didn't,", "tokens": [407, 286, 393, 380, 1604, 498, 321, 5343, 341, 1036, 1243, 11, 321, 393, 44252, 309, 958, 1243, 498, 321, 994, 380, 11], "temperature": 0.0, "avg_logprob": -0.19082246615192083, "compression_ratio": 1.6865671641791045, "no_speech_prob": 1.5206764146569185e-05}, {"id": 1414, "seek": 709754, "start": 7111.32, "end": 7116.68, "text": " but L1 loss means rather than adding up the squared errors, add up the absolute values", "tokens": [457, 441, 16, 4470, 1355, 2831, 813, 5127, 493, 264, 8889, 13603, 11, 909, 493, 264, 8236, 4190], "temperature": 0.0, "avg_logprob": -0.19082246615192083, "compression_ratio": 1.6865671641791045, "no_speech_prob": 1.5206764146569185e-05}, {"id": 1415, "seek": 709754, "start": 7116.68, "end": 7117.68, "text": " of the errors.", "tokens": [295, 264, 13603, 13], "temperature": 0.0, "avg_logprob": -0.19082246615192083, "compression_ratio": 1.6865671641791045, "no_speech_prob": 1.5206764146569185e-05}, {"id": 1416, "seek": 709754, "start": 7117.68, "end": 7121.76, "text": " So it's like it's normally actually what you want.", "tokens": [407, 309, 311, 411, 309, 311, 5646, 767, 437, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.19082246615192083, "compression_ratio": 1.6865671641791045, "no_speech_prob": 1.5206764146569185e-05}, {"id": 1417, "seek": 709754, "start": 7121.76, "end": 7127.4, "text": " Adding up the squared errors really penalizes bad misses by too much.", "tokens": [31204, 493, 264, 8889, 13603, 534, 13661, 5660, 1578, 29394, 538, 886, 709, 13], "temperature": 0.0, "avg_logprob": -0.19082246615192083, "compression_ratio": 1.6865671641791045, "no_speech_prob": 1.5206764146569185e-05}, {"id": 1418, "seek": 712740, "start": 7127.4, "end": 7131.32, "text": " So L1 loss is generally better to work with.", "tokens": [407, 441, 16, 4470, 307, 5101, 1101, 281, 589, 365, 13], "temperature": 0.0, "avg_logprob": -0.17845187344393887, "compression_ratio": 1.5794871794871794, "no_speech_prob": 1.4738887330167927e-05}, {"id": 1419, "seek": 712740, "start": 7131.32, "end": 7136.639999999999, "text": " Okay, I'll come back to this next week, but basically you can see what we do now is we", "tokens": [1033, 11, 286, 603, 808, 646, 281, 341, 958, 1243, 11, 457, 1936, 291, 393, 536, 437, 321, 360, 586, 307, 321], "temperature": 0.0, "avg_logprob": -0.17845187344393887, "compression_ratio": 1.5794871794871794, "no_speech_prob": 1.4738887330167927e-05}, {"id": 1420, "seek": 712740, "start": 7136.639999999999, "end": 7145.12, "text": " do our LR find, find our learning rate, learn for a while, freeze2-2, learn a bit more,", "tokens": [360, 527, 441, 49, 915, 11, 915, 527, 2539, 3314, 11, 1466, 337, 257, 1339, 11, 15959, 17, 12, 17, 11, 1466, 257, 857, 544, 11], "temperature": 0.0, "avg_logprob": -0.17845187344393887, "compression_ratio": 1.5794871794871794, "no_speech_prob": 1.4738887330167927e-05}, {"id": 1421, "seek": 712740, "start": 7145.12, "end": 7151.679999999999, "text": " freeze2-3, learn a bit more, and you can see this validation loss, which remember is the", "tokens": [15959, 17, 12, 18, 11, 1466, 257, 857, 544, 11, 293, 291, 393, 536, 341, 24071, 4470, 11, 597, 1604, 307, 264], "temperature": 0.0, "avg_logprob": -0.17845187344393887, "compression_ratio": 1.5794871794871794, "no_speech_prob": 1.4738887330167927e-05}, {"id": 1422, "seek": 715168, "start": 7151.68, "end": 7158.16, "text": " absolute value, mean of the absolute value of pixels we're off by gets lower and lower,", "tokens": [8236, 2158, 11, 914, 295, 264, 8236, 2158, 295, 18668, 321, 434, 766, 538, 2170, 3126, 293, 3126, 11], "temperature": 0.0, "avg_logprob": -0.13896490545833812, "compression_ratio": 1.68348623853211, "no_speech_prob": 4.222812094667461e-06}, {"id": 1423, "seek": 715168, "start": 7158.16, "end": 7164.84, "text": " and then when we're done, we can print out the bounding boxes, and lo and behold, it's", "tokens": [293, 550, 562, 321, 434, 1096, 11, 321, 393, 4482, 484, 264, 5472, 278, 9002, 11, 293, 450, 293, 27234, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.13896490545833812, "compression_ratio": 1.68348623853211, "no_speech_prob": 4.222812094667461e-06}, {"id": 1424, "seek": 715168, "start": 7164.84, "end": 7167.9800000000005, "text": " done a damn good job.", "tokens": [1096, 257, 8151, 665, 1691, 13], "temperature": 0.0, "avg_logprob": -0.13896490545833812, "compression_ratio": 1.68348623853211, "no_speech_prob": 4.222812094667461e-06}, {"id": 1425, "seek": 715168, "start": 7167.9800000000005, "end": 7174.320000000001, "text": " So we'll revise this a bit more next week, but you can see this idea of like if I said", "tokens": [407, 321, 603, 44252, 341, 257, 857, 544, 958, 1243, 11, 457, 291, 393, 536, 341, 1558, 295, 411, 498, 286, 848], "temperature": 0.0, "avg_logprob": -0.13896490545833812, "compression_ratio": 1.68348623853211, "no_speech_prob": 4.222812094667461e-06}, {"id": 1426, "seek": 715168, "start": 7174.320000000001, "end": 7179.52, "text": " to you before this class, do you know how to create a bounding box model, you might", "tokens": [281, 291, 949, 341, 1508, 11, 360, 291, 458, 577, 281, 1884, 257, 5472, 278, 2424, 2316, 11, 291, 1062], "temperature": 0.0, "avg_logprob": -0.13896490545833812, "compression_ratio": 1.68348623853211, "no_speech_prob": 4.222812094667461e-06}, {"id": 1427, "seek": 717952, "start": 7179.52, "end": 7182.96, "text": " have said, no, nobody's taught me that.", "tokens": [362, 848, 11, 572, 11, 5079, 311, 5928, 385, 300, 13], "temperature": 0.0, "avg_logprob": -0.20934413563121448, "compression_ratio": 1.5691056910569106, "no_speech_prob": 2.1907753762206994e-06}, {"id": 1428, "seek": 717952, "start": 7182.96, "end": 7188.040000000001, "text": " But the question actually is, can you create a model with 4 continuous outputs?", "tokens": [583, 264, 1168, 767, 307, 11, 393, 291, 1884, 257, 2316, 365, 1017, 10957, 23930, 30], "temperature": 0.0, "avg_logprob": -0.20934413563121448, "compression_ratio": 1.5691056910569106, "no_speech_prob": 2.1907753762206994e-06}, {"id": 1429, "seek": 717952, "start": 7188.040000000001, "end": 7189.64, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.20934413563121448, "compression_ratio": 1.5691056910569106, "no_speech_prob": 2.1907753762206994e-06}, {"id": 1430, "seek": 717952, "start": 7189.64, "end": 7195.56, "text": " Can you create a loss function that is lower if those 4 outputs are near to 4 other numbers?", "tokens": [1664, 291, 1884, 257, 4470, 2445, 300, 307, 3126, 498, 729, 1017, 23930, 366, 2651, 281, 1017, 661, 3547, 30], "temperature": 0.0, "avg_logprob": -0.20934413563121448, "compression_ratio": 1.5691056910569106, "no_speech_prob": 2.1907753762206994e-06}, {"id": 1431, "seek": 717952, "start": 7195.56, "end": 7196.56, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.20934413563121448, "compression_ratio": 1.5691056910569106, "no_speech_prob": 2.1907753762206994e-06}, {"id": 1432, "seek": 717952, "start": 7196.56, "end": 7197.56, "text": " Then you're done.", "tokens": [1396, 291, 434, 1096, 13], "temperature": 0.0, "avg_logprob": -0.20934413563121448, "compression_ratio": 1.5691056910569106, "no_speech_prob": 2.1907753762206994e-06}, {"id": 1433, "seek": 717952, "start": 7197.56, "end": 7203.360000000001, "text": " Now you'll see if I scroll a bit further down, it starts looking a bit crappy any time we've", "tokens": [823, 291, 603, 536, 498, 286, 11369, 257, 857, 3052, 760, 11, 309, 3719, 1237, 257, 857, 36531, 604, 565, 321, 600], "temperature": 0.0, "avg_logprob": -0.20934413563121448, "compression_ratio": 1.5691056910569106, "no_speech_prob": 2.1907753762206994e-06}, {"id": 1434, "seek": 717952, "start": 7203.360000000001, "end": 7205.200000000001, "text": " got more than one object.", "tokens": [658, 544, 813, 472, 2657, 13], "temperature": 0.0, "avg_logprob": -0.20934413563121448, "compression_ratio": 1.5691056910569106, "no_speech_prob": 2.1907753762206994e-06}, {"id": 1435, "seek": 717952, "start": 7205.200000000001, "end": 7207.320000000001, "text": " And that's not surprising.", "tokens": [400, 300, 311, 406, 8830, 13], "temperature": 0.0, "avg_logprob": -0.20934413563121448, "compression_ratio": 1.5691056910569106, "no_speech_prob": 2.1907753762206994e-06}, {"id": 1436, "seek": 720732, "start": 7207.32, "end": 7214.2, "text": " Because how the hell do you decide which bird, so it's just said I'll just pick the middle,", "tokens": [1436, 577, 264, 4921, 360, 291, 4536, 597, 5255, 11, 370, 309, 311, 445, 848, 286, 603, 445, 1888, 264, 2808, 11], "temperature": 0.0, "avg_logprob": -0.2226407987262131, "compression_ratio": 1.7252252252252251, "no_speech_prob": 4.15734393754974e-06}, {"id": 1437, "seek": 720732, "start": 7214.2, "end": 7217.44, "text": " which cow, I'll pick the middle.", "tokens": [597, 8408, 11, 286, 603, 1888, 264, 2808, 13], "temperature": 0.0, "avg_logprob": -0.2226407987262131, "compression_ratio": 1.7252252252252251, "no_speech_prob": 4.15734393754974e-06}, {"id": 1438, "seek": 720732, "start": 7217.44, "end": 7221.639999999999, "text": " How much of this is actually potted plant, I'll pick the middle.", "tokens": [1012, 709, 295, 341, 307, 767, 280, 11252, 3709, 11, 286, 603, 1888, 264, 2808, 13], "temperature": 0.0, "avg_logprob": -0.2226407987262131, "compression_ratio": 1.7252252252252251, "no_speech_prob": 4.15734393754974e-06}, {"id": 1439, "seek": 720732, "start": 7221.639999999999, "end": 7226.36, "text": " This one it could probably improve, but it's got close to the car, but it's a pretty weird", "tokens": [639, 472, 309, 727, 1391, 3470, 11, 457, 309, 311, 658, 1998, 281, 264, 1032, 11, 457, 309, 311, 257, 1238, 3657], "temperature": 0.0, "avg_logprob": -0.2226407987262131, "compression_ratio": 1.7252252252252251, "no_speech_prob": 4.15734393754974e-06}, {"id": 1440, "seek": 720732, "start": 7226.36, "end": 7227.36, "text": " car.", "tokens": [1032, 13], "temperature": 0.0, "avg_logprob": -0.2226407987262131, "compression_ratio": 1.7252252252252251, "no_speech_prob": 4.15734393754974e-06}, {"id": 1441, "seek": 720732, "start": 7227.36, "end": 7232.759999999999, "text": " But nonetheless, for the ones that are reasonably clear, I would say it's done a pretty good", "tokens": [583, 26756, 11, 337, 264, 2306, 300, 366, 23551, 1850, 11, 286, 576, 584, 309, 311, 1096, 257, 1238, 665], "temperature": 0.0, "avg_logprob": -0.2226407987262131, "compression_ratio": 1.7252252252252251, "no_speech_prob": 4.15734393754974e-06}, {"id": 1442, "seek": 720732, "start": 7232.759999999999, "end": 7236.5599999999995, "text": " job.", "tokens": [1691, 13], "temperature": 0.0, "avg_logprob": -0.2226407987262131, "compression_ratio": 1.7252252252252251, "no_speech_prob": 4.15734393754974e-06}, {"id": 1443, "seek": 723656, "start": 7236.56, "end": 7238.8, "text": " So that's time for this week.", "tokens": [407, 300, 311, 565, 337, 341, 1243, 13], "temperature": 0.0, "avg_logprob": -0.12810809795673078, "compression_ratio": 1.7072243346007605, "no_speech_prob": 1.777825309545733e-05}, {"id": 1444, "seek": 723656, "start": 7238.8, "end": 7243.92, "text": " I think it's been a kind of gentle introduction for the first lesson.", "tokens": [286, 519, 309, 311, 668, 257, 733, 295, 6424, 9339, 337, 264, 700, 6898, 13], "temperature": 0.0, "avg_logprob": -0.12810809795673078, "compression_ratio": 1.7072243346007605, "no_speech_prob": 1.777825309545733e-05}, {"id": 1445, "seek": 723656, "start": 7243.92, "end": 7250.120000000001, "text": " If you're a professional coder, there's probably not heaps of new stuff here for you.", "tokens": [759, 291, 434, 257, 4843, 17656, 260, 11, 456, 311, 1391, 406, 415, 2382, 295, 777, 1507, 510, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.12810809795673078, "compression_ratio": 1.7072243346007605, "no_speech_prob": 1.777825309545733e-05}, {"id": 1446, "seek": 723656, "start": 7250.120000000001, "end": 7255.92, "text": " And so in that case I would suggest practicing learning about bounding boxes and stuff.", "tokens": [400, 370, 294, 300, 1389, 286, 576, 3402, 11350, 2539, 466, 5472, 278, 9002, 293, 1507, 13], "temperature": 0.0, "avg_logprob": -0.12810809795673078, "compression_ratio": 1.7072243346007605, "no_speech_prob": 1.777825309545733e-05}, {"id": 1447, "seek": 723656, "start": 7255.92, "end": 7262.92, "text": " If you aren't so experienced with things like debuggers and matplotlib API and stuff like", "tokens": [759, 291, 3212, 380, 370, 6751, 365, 721, 411, 3001, 3562, 433, 293, 3803, 564, 310, 38270, 9362, 293, 1507, 411], "temperature": 0.0, "avg_logprob": -0.12810809795673078, "compression_ratio": 1.7072243346007605, "no_speech_prob": 1.777825309545733e-05}, {"id": 1448, "seek": 723656, "start": 7262.92, "end": 7265.88, "text": " that, there's going to be a lot for you to practice, because we're going to be really", "tokens": [300, 11, 456, 311, 516, 281, 312, 257, 688, 337, 291, 281, 3124, 11, 570, 321, 434, 516, 281, 312, 534], "temperature": 0.0, "avg_logprob": -0.12810809795673078, "compression_ratio": 1.7072243346007605, "no_speech_prob": 1.777825309545733e-05}, {"id": 1449, "seek": 726588, "start": 7265.88, "end": 7268.32, "text": " assuming you know it well from next week.", "tokens": [11926, 291, 458, 309, 731, 490, 958, 1243, 13], "temperature": 0.0, "avg_logprob": -0.2785805138674649, "compression_ratio": 1.0256410256410255, "no_speech_prob": 4.2638876038836315e-05}, {"id": 1450, "seek": 726832, "start": 7268.32, "end": 7296.24, "text": " Thanks everybody, see you next Monday.", "tokens": [50364, 2561, 2201, 11, 536, 291, 958, 8138, 13, 51760], "temperature": 0.0, "avg_logprob": -0.40666177056052466, "compression_ratio": 0.8260869565217391, "no_speech_prob": 0.00033418909879401326}], "language": "en"}